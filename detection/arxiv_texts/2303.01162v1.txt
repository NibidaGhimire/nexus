© 2020 IEEE
Personal use of this material is permitted. Permission from IEEE must
be obtained for all other uses, in any current or future media, including
reprinting or republishing this material for advertising or promotional
purposes, creating new collective works, for resale or redistribution to
servers or lists, or reuse of any copyrighted component of this work in
other works.arXiv:2303.01162v1  [cs.RO]  2 Mar 2023© IEEE, 2020. ACCEPTED TO IEEE RA-L. DOI: 10.1109/LRA.2020.2970646 1
Autonomous Reﬂectance Transformation Imaging
by a Team of Unmanned Aerial Vehicles
V´ıt Kr ´atk´y, Pavel Petr ´aˇcek , V ojt ˇech Spurn ´y, and Martin Saska
Abstract —A Reﬂectance Transformation Imaging technique
(RTI) realized by multi-rotor Unmanned Aerial Vehicles (UA Vs)
with a focus on deployment in difﬁcult to access buildings is
presented in this paper. RTI is a computational photographic
method that captures a surface shape and color of a subject and
enables its interactive re-lighting from any direction in a software
viewer, revealing details that are not visible with the naked eye.
The input of RTI is a set of images captured by a static camera,
each one under illumination from a different known direction. We
present an innovative approach applying two multi-rotor UA Vs
to perform this scanning procedure in locations that are hardly
accessible or even inaccessible for people. The proposed system
is designed for its safe deployment within real-world scenarios
in historical buildings with priceless historical value.
Index Terms —Aerial Systems: Applications, Cooperating
Robots, Multi-Robot Systems
I. INTRODUCTION
REFLECTANCE Transformation Imaging (RTI) is an
image-based rendering method widely used by experts in
the ﬁeld of archaeology, restoration and historical science [1]–
[7]. Based on the set of images with varying known lighting, a
representation of an image is produced by RTI, that enables to
view a captured object lit from an arbitrary direction and there-
fore to easily inspect the three-dimensional character of the
object without the need to capture thousands of photographs
with lighting from all possible directions.
The most traditional approaches for gathering the desired
set of images is an RTI dome (see Fig. 1a) and the Highlight
RTI method [8]. The RTI dome includes tens of light-emitting
diodes (LEDs) placed on the inner surface of a hemisphere
and a camera placed on its top. During the image capturing
phase, the RTI dome is placed above the scanned object, and
the LEDs are sequentially lit up while the camera is capturing
images. Each image is then labelled with the corresponding
lighting vector computed from the known position of particular
LEDs.
Using the Highlight RTI method (H-RTI), a source of
light is manually placed at unknown positions in a constant
distance from the scanned object, while a camera mounted
Manuscript received: September 10, 2019; Revised December 19, 2019;
Accepted January 15, 2020.
This paper was recommended for publication by Editor Jonathan Roberts
upon evaluation of the Associate Editor and Reviewers’ comments. This work
was supported by project no. DG18P02OVV069 in program NAKI II, by CTU
grant no. SGS17/187/OHK3/3T/13, and by the Grant Agency of the Czech
Republic under grant no. 17-16900Y .
Authors are with the Faculty of Electrical Engineering,
Czech Technical University in Prague, Technick ´a 2, Prague 6,
fkratkvit|petrapa6|spurnvoj|saskam1 g@fel.cvut.cz .
Digital Object Identiﬁer (DOI): see top of this page.on the tripod is capturing images. Respective lighting vectors
are then computed from the reﬂection detected on the high
reﬂective object (metal ball) placed next to the scanned artifact.
An example of a setup for the H-RTI method is illustrated
in Fig. 1b.
(a) RTI dome
 (b) highlight RTI
Fig. 1: Illustration of traditional approaches to the realization
of RTI method. Image sources: https://www.idigbio.org/wiki/images/7/70/Graham 0429.pdf and https://
historicengland.org.uk/images-books/publications/multi-light-imaging-heritage-applications/heag069-multi-light-imaging/
The drawback of both methods is that the scanned object
has to be directly accessible to humans, which is difﬁcult
to achieve in large historical and sacred buildings. Thus it
signiﬁcantly limits the usage of this very powerful technique.
We propose to solve this problem by applying two cooperating
multi-rotor UA Vs equipped with a camera and light source.
The UA V team is able to gather the set of images with
corresponding lighting vectors of objects located at places
hardly accessible or even inaccessible for people, and much
faster than using the H-RTI approach. During the scanning
process, the UA V carrying a camera is hovering steadily in
the air, while the UA V equipped with a light source is ﬂying
around to provide the lighting from different directions.
Although the scanning process could be performed man-
ually, regardless of the experience of operators, the manual
navigation of UA Vs to desired positions is typically less
precise than in the case of autonomous control. Moreover,
the desired scanning locations are assumed to be located
high above the ground and hence far from the operators,
which increases the difﬁculty and danger of manual con-
trol of two UA Vs ﬂying close to each other. Therefore,
the proposed method relies on using two fully autonomous
and self-localized UA Vs. Although we present the system as
autonomous, each UA V is supposed to be monitored by an
operator, who is prepared to take over the control in case
of an unexpected behavior. This requirement is given by
the aviation authority for ﬂying outdoors (e.g., for scanning
statues, mosaics and plasters on the exteriors of churches and
castles - see video https://youtu.be/lTRqd1gQOAI) and by the2 © IEEE, 2020. ACCEPTED TO IEEE RA-L. DOI: 10.1109/LRA.2020.2970646
heritage institute for ﬂying indoors (see Fig. 2 and videos
from Saint Nicholas Church at Old Town Square in Prague
(https://youtu.be/g1NuPnLCFTg), Grotto Gorzanow, Poland
(https://youtu.be/6mRYxciDLCM), and St. Anne’s and St.
Jacob’s Church in Star ´a V oda (https://youtu.be/yNc1WfebIag),
where autonomous UA Vs have been applied).
The presented application is speciﬁc due to cooperation
with experts from the Czech National Heritage Institute
(https://www.npu.cz/en), who have introduced requirements
and constraints, which are untraditional from the robotic point
of view. Therefore, two different approaches to the generation
of lighting positions and determination of an ideal sequence
of these positions to achieve sufﬁciently good coverage of
lighting for the RTI technique are presented in this paper. One
of them is based on the method using Fibonacci lattice [9] for
achieving approximately equal distribution of points on the
sphere, and it applies the approaches for the solution of the
Traveling Salesman Problem (TSP) to ﬁnd a path connecting
these positions. The second proposed approach is aimed to
ﬁnd a compromise among the optimality, robotic constraints,
and requirements of the aviation authorities and the heritage
institute that require paths producing predictable and easy to
follow movement of UA Vs, which is optimal regarding the
UA V deployment in historical buildings.
Fig. 2: Deployment of the proposed system for autonomous RTI
by a team of UA Vs in Church of St. Mary Magdalene in
Chlum ´ın. Multimedia material of the experiment is available at
http://mrs.felk.cvut.cz/papers/rti2020ral.
A. State-of-the-art and contribution
Single manually controlled UA Vs are being commercially
used in numerous scenarios, both outdoor and indoor. Nev-
ertheless, the number of possible applications can be sig-
niﬁcantly increased by introducing autonomous cooperative
teams of UA Vs, which is the aim of this paper. One of such
applications is the documentation of interiors of historical
buildings with distributed lighting, which is motivated by
the preservation of cultural heritage in the form of digital
documentation [10]. It provides the ability to perform later
reconstructions of already destroyed historical buildings or art
pieces, and also provides the ability to analyze this data and
plan the future restoration work without repetitive direct access
to particular artifacts.
The documentation of buildings is problematic due to its
time complexity and limited accessibility by humans, which
naturally leads to the introduction of semi-autonomous or
autonomous systems developed for this purpose. Works related
to the scanning of buildings are mostly interested in the
planning of the best sensing locations [11]–[13] and only afew of them aim to exploit autonomous vehicles. In [14],
an unmanned ground vehicle (UGV) equipped with a laser
scanner capable of autonomous planning of scanning locations
and moving through a large scale outdoor environment is
introduced. In [15], authors exploit advantage of UA V systems
to operate in larger space by applying them to autonomous in-
spection of industrial chimneys. Regarding the documentation
of particular artifacts in interiors of historical buildings, the
only work we have found is [16], where technology assisting
an operator of a single UA V explicitly developed for this
application is described.
Regarding the multi-robot systems works presenting sys-
tems deploying UGVs or UA Vs for the documentation or
mapping of buildings, the robotic groups are focused on
reducing the overall mission time or on expanding the scanned
area [17], [18], but the direct cooperation of robots is not
exploited. The cooperative lighting by a UA V team introduced
in [10], and extended for use of the RTI technique in this
paper, is unique in comparison to all the aforementioned works
since it employs a team of cooperating UA Vs in tasks that
cannot be solved by a single UA V only in principle. The
proposed method in [10] is exceptional in its approach to
actively inﬂuence its surrounding environment in order to
increase quality and variety of gathered digital material.
In this work, we introduce the ﬁrst system for autonomous
realization of the RTI technique independent on the location
of scanned objects, which takes the advantage of our previous
works on formation control [10], [19]–[21].
II. PROBLEM DESCRIPTION
The problem of autonomous realization of Reﬂectance
Transformation Imaging technique consists of 1) determining
a set of desired positions of a light source, 2) ﬁnding a feasible
trajectory so that a UA V can provide illumination from these
positions, 3) precise mutual localization of UA Vs, and 4)
processing the captured images for computation of the desired
representation of an image. The team of UA Vs consists of one
UA V equipped with a high-resolution camera and one UA V
carrying a light source. Both UA Vs are assumed to be capable
of steady hovering in the air and controlling the orientation of
the camera and the light independently of their motion.
We suppose that the UA Vs operate in a known environment
represented by a map, obtained from a three-dimensional scan
of the historical building, and they are equipped with necessary
sensors and software for their precise localization and state
estimation [22]. The map of the environment is obtained
from a three-dimensional terrestrial laser scanner, providing
an incomplete map with missing data in occluded out-of-view
locations. Such map is sufﬁcient for localization, however
does not provide sufﬁciently precise and complete models of
particular artifacts. Requirements on the scanning process of
an object are given by speciﬁcation of the RTI technique [23]
and a position of the object selected for scanning is known
prior the mission. Both UA Vs are able to accurately follow
the trajectory given by the sequence of conﬁgurations in an
available map of the environment [24].
The output of the system is the requested representation of
the image computed from the set of images taken with the© IEEE, 2020. ACCEPTED TO IEEE RA-L. DOI: 10.1109/LRA.2020.2970646 3
camera carried by the UA V . Corresponding lighting vectors,
which are needed for computation of this representation, are
obtained from a known position of the scanned object and
positions of the UA V carrying the light.
III. PRELIMINARIES
A. Reﬂectance Transformation Imaging
Reﬂectance Transformation Imaging (RTI) is an image-
based rendering method used for obtaining a representation
of an image that enables it to be displayed under arbitrary
lighting conditions. One type of such representation is the
Polynomial Texture Map (PTM), which was proposed by
T. Malzbender [23]. In contrast to the common representation
of an image, where each pixel has assigned three static
values for red, green and blue color (RGB), the simpliﬁed
version of PTM represents the intensity of each color channel
Ic;x;y; c2fred; green; bluegof the pixel at position (x;y)
by function
Ic;x;y=f(lu;lv); (1)
whereluandlvare elements of lighting vector and the func-
tionf()is a second-order bi-quadratic polynomial function
with varying coefﬁcients i;cfor particular pixels (x;y). Thus
the intensity Ic;x;y of each color can be interpreted as
Ic;x;y=1;cl2
u+2;cl2
v+3;clulv+4;clu+
+5;clv+6;c; c2fred; green; blueg:(2)
The input of the RTI method is a set of images taken from
the same viewpoint under varying known lighting conditions,
where each image in the set has assigned corresponding
lighting vector. With the use of this data, coefﬁcients in
equation (2) can be computed for all pixels and their color
channels (see [23] for details).
B. Localization
Precise determination of position and orientation of UA Vs
is a crucial assumption for the good performance of the intro-
duced documentation method. Since we aim at the deploying
of the system mostly in indoor environments, we rely on the
approach presented in [25], which is capable of working in en-
vironments without a sufﬁcient signal from Global Navigation
Satellite Systems (GNSS). The method requires UA Vs to be
equipped with one 360laser scanner (such as a lightweight
RP-Lidar), and two distance sensors (e.g., Garmin LIDAR-
Lite v3) oriented downwards and upwards with respect to the
frame of UA V . A combination of Iterative Closest Point (ICP)
and particle ﬁlter algorithm is applied to ﬁnd the position
and orientation of the UA V relative to a three-dimensional
point cloud of the environment obtained from a terrestrial laser
scanner.
IV. DISTANT AUTONOMOUS RTI METHOD
Methods designed for the realization of the RTI scanning
technique by a team of UA Vs, which are described in the
following sections, are highly inﬂuenced by the requirements
of experts from the ﬁeld of restoration and historical science,
where key factors are safety and deployability independently
to an external infrastructure.A. Generation of the set of lighting positions
To achieve a good coverage of lighting to a general object
during RTI scanning, the lighting vectors need be uniformly
distributed over the range deﬁned by the minimum and
maximum lighting angles in horizontal ( h;min ,h;max ) and
vertical (v;min ,v;max ) direction. The intensity of lighting
presented at the scanned object should be the same for all
lighting directions.
Given these two requirements and assumption that the
intensity of the light source is constant, we can determine that
the desired positions of light sources are distributed on a cap of
the sphere with its center located at the position of the scanned
object. This task can be deﬁned as the problem of uniform
distribution of points on the sphere. Since this problem has
an exact solution only for particular cases [26], we apply an
approximate approach based on the Fibonacci lattice. Inputs
of this process are the number of desired lighting positions
to be uniformly distributed over the area deﬁned by angles
d;m; d2fh;vg; m2fmin;maxg, position of an Object of
Interest (OoI), and the desired lighting distance. The resulting
set of points ccomputed within this process is constructed
as
c= [Pi; (3)
where is the set of desired lighting positions and Pi2R3
is the initial position of the UA V carrying the light.
B. Determination of the optimal sequence
An optimal closed path connecting all the desired RTI
lighting positions in the set cwith respect to a certain
criterion (minimum energy, shortest path, minimum time)
needs to be found. This problem can be deﬁned as TSP,
which is usually solved by splitting it into two subproblems
- ﬁnding paths between all possible pairs of positions from
the set cand ﬁnding the optimal sequence of these paths
with respect to a certain criterion. The ﬁnal path is then given
as a connection of paths in the optimal sequence. Using this
approach, it is difﬁcult to guarantee feasibility of a composed
path with respect to constraints given by the kinematic model
of a moving robot. Nevertheless, the RTI method requires a
static illumination while capturing an image, and so the UA V
carrying the light has to be static for taking each picture in
the sequence. Therefore, the UA V should stop at every position
from cand the problem of an unfeasible path in connections
of curve segments does not need to be considered here.
Considering the expected application of the system, we
propose to use the minimum energy as the optimization
criterion for the solution of proposed alternative of TSP, which
also leads to maximization of possible ﬂight time. Based on
our experiments, the energy consumption along the closed
trajectory ﬂown at constant velocity is proportional to the
length of this trajectory and does not depend on the direction
of ﬂight. By combining the observations mentioned above
and considering an obstacle-free environment, the problem
of ﬁnding the optimal sequence of the lighting positions
is completely deﬁned as the Euclidean TSP (ETSP). For
solution of this problem, we have applied the solver using4 © IEEE, 2020. ACCEPTED TO IEEE RA-L. DOI: 10.1109/LRA.2020.2970646
Lin-Kernighan heuristic [27] (LKH solver), which belongs to
the most efﬁcient approximate algorithms for solution of TSP.
An example of path produced with the described approach
(further referenced as Fib-LKH) is presented in Fig. 7c.
C. Safety pilot predictable approach (SPPA)
In this section, we present an alternative approach to the ob-
taining of scanning plan that aims at the generation of lighting
positions close to uniform distribution and ﬁnding a short path
connecting these positions while complying to requirements
on human predictability of the resulting trajectory. Thus this
method decreases the time needed for recognition of the faulty
behavior by a safety pilot, who monitors the UA V during the
scanning process. This approach is motivated by a technique
used by restorers during the manual acquisition of images for
RTI method in [28].
The proposed method for obtaining the set of desired
lighting positions uses as inputs the border lighting angles
d;m; d2fh;vg; m2fmin;maxg, the position of scanned
objectPOoI2R3, the orientation of camera deﬁned with yaw
and pitch angle ( cam;cam), the desired distance between the
light and scanned object dl, and the desired number of samples
of the lighting angles vsin vertical direction for which holds
vs2. In the ﬁrst step of the method, a set of samples of
vertical lighting angles vfrom intervalhv;max; v;miniis
obtained so that they are equally distributed over this interval,
jvj=vs,min( v) =v;min andmax( v) =v;max . Sub-
sequently one spline on which possible positions of the light lie
is constructed for each sample vfrom v. These splines are
parts of a circle and with given POoI= [xOoI;yOoI;zOoI]T
are deﬁned as
xs=xOoI dlcos(v+cam) cos(h+ cam);
h2hh;min;h;maxi
ys=yOoI dlcos(v+cam) sin(h+ cam);
h2hh;min; h;maxi
zs=zOoI dltan(v+cam):(4)
The splines deﬁned by equation (4) are graphically illustrated
in Fig. 3a. The desired distance between the lighting positions
OoI
(a) illustration
 (b) experiment in real environment
Fig. 3: The example of the generated set of RTI goals marked
with green dots and arrows. The yellow rectangle identiﬁes the
scanned object, and the blue curves indicate the horizontal splines,
that represent possible positions of the RTI goals.
on one spline sdis determined by the equation
sd=dl(v;max v;min )
vs; (5)which corresponds to the shortest distance between two neigh-
boring splines traveled on the surface of the spherical cap. The
number of lighting positions on each spline is deﬁned as
ns(v) = 1 +dlcos(v)(h;max h;min )
sd
:(6)
The set of sample positions h(v)on spline corresponding
to anglevis obtained as
h(v) =
h;min +h;max h;min
2
; (7)
ifns(v) = 1 and
h(v) =
h;min +kh;max h;min
ns 1
k2f0;1;:::;n s 1g
;(8)
ifns= (v)2. The complete set of the desired lighting
positions cgenerated with the SPPA is deﬁned as
c=fh(v)jv2vg[Pi: (9)
As the ﬁrst step of the SPPA, the current position of the
UA V carrying the light is added at the beginning of the ideal
sequence of the RTI positions Sp. Then the closest pair of the
RTI positions Ps; Pe2R3on the vertical boundaries needs
to be found to select the higher one as the start point and the
lower one as the end point among RTI positions. For Ps; Pe
holds
Ps;Pe= arg min
Pi;j;Pk;ldist(Pi;j;Pi) +dist(Pk;l;Pi);
s:t: i =k+ 1; (10)
(j;l)2f(1;1);(jh;ij;jh;kj)g;
wherePi;jstands for the RTI position in the i-th row and
j-th column, function dist ()returns the Euclidean distance
between two positions given as arguments, and h;istands
for the set of RTI positions in the i-th row. The position Ps
is then added to the sequence of positions Sp. After that,
all positions on the vertical boundary on the way up to the
highest row are added to Sp. By these three steps, one of the
corner positions in the highest row is reached. In the following
stages, the procedure depends on the number of rows.
In the case of an even number of horizontal rows, the RTI
positions are added line by line with switching the left-right
and the right-left direction, and omitting the points that lie
on the same vertical boundary as Ps. After reaching the last
admissible position in the most bottom row, the remaining
points are added from the bottom row up to and including
thePeintoSp. Finally, the Piis added at the end of the
Spto ensure the return to the initial position. The graphical
illustration of this process is shown in Figures 4a, 4b and 4c.
The solution for an odd number of horizontal lines is
derived from the solution for even number of rows with
several modiﬁcations. Firstly, the pair of consequent horizontal
lines (indicated by pair of indices (ho;1;ho;2)) with minimum
number of RTI positions is determined. Then, the solution
for an odd number of rows is the same as in the case of© IEEE, 2020. ACCEPTED TO IEEE RA-L. DOI: 10.1109/LRA.2020.2970646 5
(a)
 (b)
 (c)
Fig. 4: Illustration of the procedure of determining the safety pilot
predictable sequence of RTI positions for even number of horizontal
rows. The green dot marks the initial state Pi, the blue dots stand
for the unvisited RTI positions, and the red dots for already visited
RTI positions. The arrows show the transitions between particular
RTI positions, where the red arrows stand for the transitions added
during the last step.
even number of rows until the procedure reaches the pair
(ho;1;ho;2). The particular RTI positions within this pair of
rows are traversed either in an up-side-down-side manner
(see Fig. 7a for example), or by following the positions in
rowho;1to the opposite side, then ﬂying back to the starting
side of row ho;2and again following this row to the opposite
side. From there, the situation and also the solution is again
the same as in the case of an even number of rows.
D. Trajectory Generation and Tracking
The desired trajectory for the RTI ( 
) is generated by
the sampling of direct straight paths between consequent RTI
positions with the sampling distance dRTI (computed based
on the desired velocity), without considering any obstacles.
To achieve precise lighting conditions, the UA V carrying the
light is supposed to hover at the desired position while taking
a photo. This requirement is introduced into the presented
system by multiple recurrences of the desired RTI position
as the transition point of 
after each ﬂy-over to the next RTI
position. The number of these repetitions is proportional to
the time required for the stabilization.
To achieve a reliable following of the desired trajectory

in an environment with obstacles and in the presence of
disturbances, which cannot be omitted in real systems, the
trajectory tracking during the RTI procedure is deﬁned as an
optimization task within the MPC framework in the proposed
system. Thanks to the independence of the position and ori-
entation control in case of multi-rotor UA Vs, the optimization
loop can be divided into two separate tasks.
The position control is deﬁned as a nonlinear constrained
optimization task over a sequence of control inputs Up(t)
starting at time twith an objective function Jp, and set of
nonlinear constraints gp()on the horizon of length Nas
Up(t)= arg minJp(Up(t));
s:t: g p(Up(t);O(t))0;(11)
whereO(t)is the set of all obstacles present at time tin the
environment, including the UA V carrying the camera.
The objective function Jp()is deﬁned as the weighted sum
Jp=Jpos+Jc+Jobs+Jrti; (12)
whereJposstands for the part penalizing the deviations from
the desired trajectory, Jcis the part penalizing the changes
in sequence of control inputs, and Jobsresponds for thepenalization of trajectories in the proximity of obstacles. The
value ofJpis increased by adding Jrtifor trajectories that
lead to occlusions caused by the UA V carrying light or lead
to shades in the image caused by the lighting from behind
the UA V carrying the camera. Coefﬁcients ;;; andare
weights used for the scaling of particular parts of the objective
function.
The function Jrti, which was proposed speciﬁcally for this
application, is deﬁned as
Jrti=NX
k=1
min
0;dFoV(k) rd;FoV
dFoV(k) ra;FoV 2
; (13)
whererd;FoV andra;FoV are detection and avoidance radii
with respect to camera Field of View (FoV), and dFoV()
stands for the distance from the nearest border of the FoV .
This distance can be computed according to equations
dxy(k) =p
(xc(k) xl(k))2+ (yc(k) yl(k))2;
diff;h (k) = minfdiff;h (k); diff;h (k)g;
diff;v (k) = minfdiff;v (k); diff;v (k)g;
dFoV;xy (k) =dxy(k) sin
diff;h (k) AoVh
2
; (14)
dFoV;z (k) =dist(Pl(k);Pc(k)) sin
diff;v (k) AoVv
2
;
dFoV(k) =q
dFoV;z (k)2+dFoV;xy (k)2 rd;
wherePl(k) = [xl;yl;zl]TandPc(k) = [xc;yc;zc]Tis the
position of UA V carrying light and UA V carrying camera at
the time corresponding to k-th transition point. AoVhand
AoVvare horizontal and vertical angles of the camera FoV ,
dFoV;xy (k)is the distance to the nearest vertical border of
FoV ,dFoV;z (k)is the distance to the nearest horizontal border
of FoV , and rdmarks the radius of the UA V . diff;h (k)and
diff;v (k)stand for the angle between the nearest vertical
respectively horizontal border of the FoV and connecting
line between UA V carrying camera and UA V providing light.
diff;h (k)anddiff;v (k)are equivalent to diff;h (k)and
diff;v (k), but besides the FoV of the camera, they include
also the FoV of the virtual camera pointed in the exact opposite
direction than the real camera. With this alteration, the Jrti
penalizes not only the occlusion caused by the UA V carrying
the light but also the shadows visible in the FoV caused by
lighting from behind the UA V carrying the camera, which
is important for the RTI image processing. The graphical
illustration of symbols used in equation (14) is shown in Fig. 5.
The set of nonlinear constraints gp()0can be broken
down into the following constraints
gc(Up(k))0;8k2f1;:::;Ng;
gobs(Pl(k);O(t))0;8k2f1;:::;Ng;
grti(Pl(k);O(t); c(k))0;8k2f1;:::;Ng;(15)
where c(k)stands for the conﬁguration of the UA V carry-
ing camera, gc()includes the limitations on control inputs,
gobs()deﬁnes the infeasibility of trajectories colliding with
obstacles, and grti()complements the objective function Jrti6 © IEEE, 2020. ACCEPTED TO IEEE RA-L. DOI: 10.1109/LRA.2020.2970646
 
Fj 𝐴𝑜𝑉ℎ 
 
𝜑𝐿 
 𝑑𝑥𝑦 
 𝛼𝑑𝑖𝑓𝑓,ℎ 
 . 𝑑𝐹𝑜𝑉,𝑥𝑦 
 
L 
(a) top view
 
L Fj 
𝜉𝐿 
𝐴𝑜𝑉𝑣 
 𝛼𝑑𝑖𝑓𝑓,𝑣 
 . 𝑑𝐹𝑜𝑉,𝑧 
 𝑑𝑥𝑦𝑧 
 (b) side view
Fig. 5: Graphical illustration of meaning of particular symbols used
in equations (14) for computation of part of the objective function
penalizing the occlusion caused by the UA V carrying a light
by deﬁning the entire FoV as an unfeasible region.
In a similar manner, the process of ﬁnding the optimal
sequence of orientation control inputs Uo(t)on the horizon
of lengthNcan be deﬁned as the quadratic constrained
optimization task with the objective function Jo()and set of
nonlinear constraints go()as
Uo(t)= arg minJo(Uo(t));
s: t: g o(uo(k);Oj(k))0;8k2f1;:::;Ng:(16)
The objective function Jo()consists of two parts
Jo=Jor+Jco; (17)
whereJoris the part penalizing the deviation from the desired
orientation of light, Jcostands for the part penalizing the
fast changes in consequent control inputs uo(), andand
are weights used for scaling of parts of the objective
functionJo(). The set of nonlinear constraints go()0;
8k2f1;:::;Ngcan be split into the following constraints
gco(uo(k))0;8k2f1;:::;Ng;
gor(Ol(k))0;8k2f1;:::;Ng;(18)
whereOl()is the orientation of the light carried by the
UA V ,gco()stands for the constraints introducing the limits on
control inputs, and gor()introduces the limitations on angles
that deﬁne the orientation of the light.
V. EXPERIMENTAL RESULTS
A. Performance of generation of lighting positions sequence
The purpose of this section is to qualitatively and quanti-
tatively compare algorithm SPPA, FIB-LKH and their com-
bination which applies SPPA part for the generation of
the desired lighting positions and LKH solver for ﬁnd-
ing a path connecting these positions (further referenced
as LKH). The test was performed on the testing case
of 10000 samples, each with randomly chosen parameters
v;min;v;max;h;min;h;max;dl;vs, and initial position of
the UA V carrying the light Pi.
The quality of solutions was compared regarding time re-
quirements and the length of the resulting path. Concerning the
CPU time, the SPPA is faster than the others. However, since
the total CPU time needed by any method does not exceed
0.5 s for all considered problems (computed on the single-
core CPU Intel CORE i7 8250), this aspect is not importantfor our application. More signiﬁcant parameter is the length
of the paths produced by particular methods. Considering this
criterion as the comparison value, SPPA is better or equals
to LKH solution in 9%of test samples and is not longer
by more than 50% in98% of test samples. Paths generated
by FIB-LKH approach are mostly the shortest among all
methods. However, they do not fully exploit the borders of the
deﬁned scanning area (see Fig. 7c). More detailed results of
the quantitative comparison are shown in Fig. 6. Examples of
generated sequences by particular methods used for qualitative
comparison are shown in Fig. 7.
0 20 40 60 80 1000.751.001.251.501.752.00
n-th percentile (-)distance ratio (-)LKH vs. Fib-LKH
SPPA vs. Fib-LKH
SPPA vs. LKH
Fig. 6: Comparison of length of paths obtained by SPPA, LKH, and
Fib-LKH approach
(a)
 (b)
 (c)
Fig. 7: Comparison of the solution obtained with SPPA (a), the
solution generated by LKH method (b), and the solution generated
by Fib-LKH approach (c). The orange dashed line marks the borders
of the deﬁned scanning area.
B. Veriﬁcation of the overall RTI approach
The deployability of the SPPA method for the realization
of RTI scanning, which was chosen together with experts
from the Czech National Heritage Institute, who are potential
end users of the proposed system, as the best variant for its
real deployment, was veriﬁed through several experiments in
the realistic robotic simulator Gazebo and within real-world
experiments deploying two autonomous UA Vs in the interior
of the Church of St. Mary Magdalene in Chlum ´ın.
The presented simulation in which the RTI scanning proce-
dure is performed on the statue situated above the altar leads to
the generation of 56 RTI positions and the resulting trajectory
of the overall length 110.55 m. The set of generated points
together with the trajectory ﬂown by the UA V carrying the
light are shown in Figure 8. In compliance with the theory
presented in section IV, the UA V carrying light stops at each
reachable RTI position and waits until an image is taken by the
UA V carrying the camera. In this way, the system collects 56
images of the scanned object under various lighting conditions.
The images are then registered to each other to compensate
for the motion of UA V carrying a camera during the scanning
process. Based on the registered images and the ﬁle containing
the information about corresponding lighting directions, the
PTM representation of the image is computed with the use of
program PTM Fitter.© IEEE, 2020. ACCEPTED TO IEEE RA-L. DOI: 10.1109/LRA.2020.2970646 7
(a)xy-view
 (b)yz-view
0 100 200 300 101
Time (s)'2(rad)
(c) yaw - light0 100 200 300 101
Time (s)2(rad)
(d) pitch - light
Fig. 8: The generated RTI positions and the trajectory ﬂown by the
UA V carrying the light during the RTI scanning procedure. The blue
dots mark particular RTI positions, the red dot marks the position of
the scanned object, and the blue line shows the trajectory.
The main advantage of obtaining the PTM from the set
of images is that the image can be displayed under arbitrary
lighting conditions. Since this result can be hardly presented
within the printed work, the resulting PTM representation
of the scanned object, obtained from the images taken by
an onboard camera, is shown in the video available at http:
//mrs.felk.cvut.cz/papers/rti2020ral.
The real experiment was adapted to ﬁt into the restricted
space of the church in Chlum ´ın. To enable the comparison
of results of the proposed method and H-RTI, the object
of interest (part of the pulpit) was chosen in the height
accessible by people and it was illuminated from the same
12 positions (see Fig. 3b) by two different approaches - with
the camera carried by an autonomous UA V (see Fig. 2) and
with the camera mounted on a static tripod (see Fig. 12c).
The latter approach eliminates the imprecision caused by the
camera motion and hence enables the objective comparison
of the results obtained from the same set of images with
lighting vectors computed from the reﬂections on the black
ball (H-RTI) and from the position of the light-carrying UA V
provided by the application-tailored localization system [25].
The images generated based on the PTM representation of the
scanned object are shown in Fig. 9 and in the video available
at http://mrs.felk.cvut.cz/papers/rti2020ral.
(a) upper-left light
 (b) left light
 (c) bottom-right light
Fig. 9: Presentation of the PTM representation of the scanned object
obtained from images taken by UA V during the RTI experiment
performed in Church of St. Mary Magdalene in Chlum ´ın. For video
see http://mrs.felk.cvut.cz/papers/rti2020ral.C. Dependence of PTM quality on precision of localization
To examine how the precision of localization affects the
quality of the resulting PTM, a simulation-based quantitative
comparison was conducted. The whole RTI procedure was
performed on a lion statue with localization error sampled
from the normal distribution with zero mean and multiple
distinct values of standard deviation. The normal map obtained
using SPPA (60 positions) and a modelled localization error
is compared to the normal map obtained with SPPA (360
positions and zero localization error) used as ground truth.
The results of this comparison are presented in Fig. 10. The
average difference from the ground truth normals for the nor-
mal map obtained for the precision of localization presented
in [25] is 0.026 rad (see Fig. 11 for details). This value is lower
than the average difference caused by the misplacement of
the reﬂective ball with respect to the center of the scanned
object within the H-RTI procedure, which is unavoidable in
this method.
0 0:2 0:4 0:6 0:8 10.020.040.060.08
(-)(rad)
Fig. 10: The dependence of the average error in normals on the
simulated localization error represented by N(0;2)for positional
error (m) and N(0;(2
36)2)for orientation error (rad). Values of 
for a particular is computed as an average result of 20 experiments.
(a)
 (b)
 (c)
Fig. 11: Comparison of the normal map obtained with SPPA (360
positions and zero localization error) (a) used as a ground truth
and normal map obtained with SPPA (60 positions and localization
error (m) modeled by N(0;0:09)for position and N(0;0:003) for
orientation) (b). Figure (c) shows the size of angle between normal
vectors in maps (a) and (b) for particular pixels.
D. Comparison of the proposed approach with H-RTI
For comparison of the proposed approach and H-RTI,
results of the RTI method in the form of normal maps are
presented in Fig. 12. These two normal maps were obtained
with lighting vectors computed by H-RTI method and with
lighting vectors computed based on the pose of UA V obtained
by the application-tailored localization system. Although the
ground truth measurement is not available, we can, based
on the known structure of the pulpit, claim that the results
obtained with H-RTI method are more precise especially in
the surroundings of the reﬂective ball.
However, the proposed method has an undeniable advantage
in realization of the RTI method in hardly accessible places.8 © IEEE, 2020. ACCEPTED TO IEEE RA-L. DOI: 10.1109/LRA.2020.2970646
Moreover, under the condition of sufﬁciently precise localiza-
tion, which is achieved by the applied localization system [25],
the determination of lighting vectors is more precise than
its detection from reﬂections on the ball, which cannot be
placed directly in the center of a scanned object. The main
drawbacks with respect to manually performed RTI lie in the
inability to eliminate any camera motion. This issue is partially
solved by the image registration process, however, on the high
level of details, the imperfections of the alignment can cause
unsharpness in images generated from the PTM representation.
The camera motion, together with the high exposure time
required in dark conditions, also causes the blur in images
taken by the camera. However, this problem can be suppressed
by the mechanical stabilization of the camera or by use of light
source with higher power output, which enables the reduction
of exposure time.
(a)
 (b)
 (c)
Fig. 12: Comparison of the normal map obtained with SPPA (12
positions) with lighting vectors computed by H-RTI method (a)
and with lighting vectors computed based on the pose of UA V (b)
obtained by the application-tailored localization system [25]. The
setup for this experiment is shown in (c).
VI. CONCLUSION
The method for the realization of Reﬂectance Transforma-
tion Imaging with the use of a team of autonomous cooperative
UA Vs is described in this paper. The method is designed
for two multi-rotor UA Vs equipped with a camera and light
source that are capable of self-localization within a given
map of an environment. Three approaches to the generation
of sequences of RTI positions are presented, but only one
was approved by representatives of the heritage institute for
its deployment in historical objects. This solution includes
self-designed methods for generation of human-predictable
trajectories to enable simple monitoring of correct behavior
of particular UA Vs by safety pilots, while preserving an effort
to generate short trajectories. The compromise between these
two criteria enables the safe deployment of the system in real-
world scenarios. The main advantage of the proposed solution
in comparison to already existing methods is the ability to
perform the RTI scanning procedure in places that are hardly
accessible or even inaccessible to humans.
The proposed approach was integrated into the system for
documentation of historical buildings proposed in [10] and its
practical applicability was tested in numerous experiments in
interiors of churches in realistic simulator Gazebo and within
the real experiment in Church of St. Mary Magdalene in
Chlum ´ın. Outputs of these tests were evaluated by experts
from the ﬁeld of historical science, who found the results
comparable with the results produced by already existing
methods, which are limited to accessible locations.REFERENCES
[1] H. Mytum et al. , “The application of reﬂectance transformation imaging
(rti) in historical archaeology,” Historical Archaeology , vol. 52, no. 2,
pp. 489–503, 2018.
[2] D. Selmo et al. , “Underwater reﬂectance transformation imaging: a tech-
nology for in situ underwater cultural heritage object-level recording,”
Journal of Electronic Imaging , vol. 26, no. 1, pp. 1–18, 2017.
[3] J. Miles et al. , “New applications of photogrammetry and reﬂectance
transformation imaging to an easter island statue,” Antiquity , vol. 88,
no. 340, pp. 596––605, 2014.
[4] H. Mytum et al. , “Reﬂectance transformation imaging (rti) : Capturing
gravestone detail via multiple digital images,” in Association for Grave-
stone Studies Quarterly , 2017.
[5] J. Valcarcel Andr ´eset al. , “Applications of reﬂectance transformation
imaging for documentation and surface analysis in conservation,” Inter-
netional Journal of Conservation Science , no. 4, pp. 535–548, 2013.
[6] D. Saunders et al. , “Reﬂectance transformation imaging and imagej:
Comparing imaging methodologies for cultural heritage artefacts,” in
EVA, 2017.
[7] Y . H. Kim et al. , “Reﬂectance transformation imaging method for large-
scale objects,” in CGiV , 2016.
[8] A. Cosentino, “Macro photography for reﬂectance transformation imag-
ing: A practical guide to the highlights method,” e-conservation Journal ,
no. 1, pp. 70–85, 2013.
[9] R. Swinbank et al. , “Fibonacci grids: A novel approach to global
modelling,” Quarterly Journal of the Royal Meteorological Society , vol.
132, pp. 1769 – 1793, 2006.
[10] M. Saska et al. , “Documentation of dark areas of large historical
buildings by a formation of unmanned aerial vehicles using model
predictive control,” in IEEE ETFA , 2017.
[11] M. Roberts et al. , “Submodular trajectory optimization for aerial 3d
scanning,” in IEEE ICCV , 2017.
[12] J. P. Fentanes et al. , “Algorithm for efﬁcient 3d reconstruction of outdoor
environments using mobile robots,” in IEEE IROS , 2011.
[13] B. Adler et al. , “Finding next best views for autonomous uav mapping
through gpu-accelerated particle simulation,” in IEEE/RSJ IROS , 2013.
[14] P. S. Blaer et al. , “Data acquisition and view planning for 3-d modeling
tasks,” in IEEE/RSJ IROS , 2007.
[15] M. Nieuwenhuisen et al. , “Chimneyspector: Autonomous mav-based
indoor chimney inspection employing 3d laser localization and textured
surface reconstruction,” in IEEE ICUAS , 2017.
[16] N. Hallermann et al. , “Vision-based monitoring of heritage monuments –
unmanned aerial systems (uas) for detailed inspection and high-accurate
survey of structures,” in STREMAH , 2015.
[17] H. Qin et al. , “Autonomous exploration and mapping system using
heterogeneous uavs and ugvs in gps-denied environments,” IEEE Trans-
actions on Vehicular Technology , vol. 68, no. 2, pp. 1339–1350, 2019.
[18] Y . Lyu et al. , “Simultaneously multi-uav mapping and control with visual
servoing,” in IEEE ICUAS , 2015.
[19] M. Saska et al. , “Coordination and Navigation of Heterogeneous MA V
& UGV Formations Localized by a ”hawk-eye”-like Approach Under
a Model Predictive Control Scheme,” International Journal of Robotics
Research , vol. 33, no. 10, pp. 1393–1412, 2014.
[20] V . Spurn ´yet al. , “Complex manoeuvres of heterogeneous mav-ugv
formations using a model predictive control,” in MMAR , 2016.
[21] M. Saska et al. , “Predictive control and stabilization of nonholonomic
formations with integrated spline-path planning,” Robotics and Au-
tonomous Systems , 2015.
[22] T. B ´aˇcaet al. , “Autonomous landing on a moving vehicle with an
unmanned aerial vehicle,” Journal of Field Robotics , vol. 36, pp. 874–
891, 2019.
[23] T. Malzbender et al. , “Polynomial Texture Maps,” in CGIT , 2001.
[24] T. B ´aˇcaet al. , “Model predictive trajectory tracking and collision
avoidance for reliable outdoor deployment of unmanned aerial vehicles,”
inIEEE/RSJ IROS , 2018.
[25] P. Petr ´aˇceket al. , “Dronument: Reliable deployment of unmanned aerial
vehicles in dark areas of large historical monuments,” IEEE RA-L , In
Press: Accepted for publication on January 9, 2020.
[26] E. B. Saff et al. , “Distributing many points on a sphere,” The Mathe-
matical Intelligencer , vol. 19, no. 1, pp. 5–11, 1997.
[27] S. Lin et al. , “An effective heuristic algorithm for the traveling-salesman
problem,” Operations Research , vol. 21, no. 2, pp. 498–516, 1973.
[28] M. Dellepiane et al. , “High quality ptm acquisition: Reﬂection transfor-
mation imaging for large objects,” in International Symposium on VAST ,
2006.