RESEARCH ARTICLE
A machine-learning approach to thunderstorm
forecasting through post-processing of simulation
data
Kianusch Vahid Yousefnia1| Tobias BÃ¶lle1| Isabella
ZÃ¶bisch1| Thomas Gerz1
1Deutsches Zentrum fÃ¼r Luft- und Raumfahrt
(DLR), Institut fÃ¼r Physik der AtmosphÃ¤re,
Oberpfaffenhofen, Germany
Correspondence
Kianusch Vahid Yousefnia, DLR
Oberpfaffenhofen, Institut fÃ¼r Physik der
AtmosphÃ¤re, MÃ¼nchner Str. 20, D-82234
Wessling, Germany
Email: kianusch.vahidyousefnia@dlr.de
Funding information
Internal DLR project DIALThunderstorms pose a major hazard to society and economy,
which calls for reliable thunderstorm forecasts. In this work, we
introduceaSignature-basedApproachofidentifyingLightning
ActivityusingMAchinelearning(SALAMA),afeedforwardneu-
ral network model for identifying thunderstorm occurrence in
numerical weather prediction (NWP) data. The model is trained
on convection-resolving ensemble forecasts over Central Europe
and lightning observations. Given only a set of pixel-wise in-
putparametersthatareextractedfromNWPdataandrelatedto
thunderstormdevelopment,SALAMAinferstheprobabilityof
thunderstorm occurrence in a reliably calibrated manner. For
lead times up to eleven hours, we find a forecast skill superior
to classification based only on NWP reflectivity. Varying the
spatiotemporal criteria by which we associate lightning obser-
vationswithNWPdata,weshowthatthetimescaleforskillful
thunderstorm predictions increases linearly with the spatial scale
of the forecast.
KEYWORDS
thunderstorms / lightning / atmospheric electricity, severe weather,
convection, machine learning, numerical methods and NWP, forecasting
(methods), ensembles
1arXiv:2303.08736v3  [physics.ao-ph]  26 Apr 20242 VAHIDYOUSEFNIA ET AL .
1|INTRODUCTION
Whilethunderstormsundoubtedlyconstituteinspiringnatural
spectacles that move any human being to a certain extent,
their impact in the form of lightning, strong winds and heavy
precipitation(includinghail)ishazardoustosocietyandecon-
omy. Besides the small but real chance of being struck by
lightning (Holle, 2016), thunderstorms pose a threat to crops
andlifestock(Holle,2014)aswell,andareknowntotrigger
wild fires (Veraverbeke et al., 2017). In addition, they con-
stituteamajorsafetyconcernforaviation(Gerzetal.,2012;
Borsky and Unterberger, 2019). Furthermore, thunderstorms
andlightningdamageelectricalinfrastructuresuchaswind
turbines(Yasudaetal.,2012),whichjeopardizesthetransition
tosustainableenergyproduction. Finally,sincethenumber
ofseverethunderstormsisexpectedtoincreaseduetoclimate
change(Diffenbaughetal.,2013;RÃ¤dleretal.,2019),accurate
thunderstorm forecasts become ever more relevant.
Thunderstorm forecasts with lead times of more than one
hour usually rely on numerical weather prediction (NWP).
This method consists of simulating the future atmospheric
state by numerically solving equations derived from the laws
of physics. The accuracy of NWP has improved with the
adventofhigh-performancecomputing,theincreasedavail-
abilityofobservationaldatathroughsatelliteimagery,aswell
asadvancesindataassimilation(Baueretal.,2015;Yanoetal.,
2018). InordertouseNWPdataforthunderstormpredictions,
oneneedstoknowhowthunderstormsmanifestthemselves
in terms of the NWP output fields. In a post-processing step,
this knowledge is then used to identify signs of thunderstorm
occurrence in simulation data.
Various ideas for identifying signs of thunderstorm occur-
rence have been put forward in recent years. For instance,
post-processing of NWP data has been blended with now-
casting methods (Kober et al., 2012; Hwang et al., 2015).
Empiricalknowledgeonconvectiveactivityhasbeentrans-
latedintoexpertsystemsusingfuzzylogic(Linetal.,2012;
Lietal.,2021). Thefuzzylogictechniqueallowstheconstruc-
tionofdecisionrulesforthunderstormoccurrencebasedon
domainknowledge. Lately,machinelearning(ML)methods
based on artificial neural networks have gained popularity.
These methods generalize the fuzzy logic approach in the
sense that decision rules are constructed by solving a data-driven optimization problem. Previous studies include neural
networkswithrelativelyfewneurons(UkkonenandMÃ¤kelÃ¤,
2019; Kamangir et al., 2020; Sobash et al., 2020; Jardines
et al., 2021), as well as deep neural networks with convolu-
tionallayersandmillionsoftrainableparameters(Gengetal.,
2021;Zhouetal.,2022). Findingssuggestthatneuralnetwork
models are more skillful at predicting thunderstorm occur-
rence than comparable ML approaches like random forests
(HermanandSchumacher,2018;UkkonenandMÃ¤kelÃ¤,2019).
Inordertolearnpredictingthunderstormoccurrence,super-
vised ML methods require a ground truth of thunderstorm
activity. It may be provided by satellite imagery (Jardines
etal.,2021;Zhouetal.,2022),radardata(Gagneetal.,2017;
Burke et al., 2020; Leinonen et al., 2022), storm reports (Lo-
kenetal.,2020;Sobashetal.,2020),andlightning(Ukkonen
and MÃ¤kelÃ¤, 2019; Geng et al., 2021).
The promising results in ML have encouraged us to apply
neural network methods to historical simulation data of the
ICOsahedralNonhydrostaticD2EnsemblePredictionSystem
(ICON-D2-EPS), an NWP ensemble model for Central Eu-
rope with a horizontal resolution of ca. 2km(ZÃ¤ngl et al.,
2015;Reinertetal.,2020). ICON-D2-EPSisalimited-area
modelwhichexplicitly resolvesconvectionandisrunopera-
tionallybytheGermanMeteorologicalService(DWD).To
the best of our knowledge, neural networks have not yet been
employedfortheidentificationofthunderstormoccurrence
in ensemble data with a comparable horizontal resolution. In
this work, we present the neural network model SALAMA
(Signature-based Approach of identifying Lightning Activ-
ity using MAchine learning). It has been trained to predict
thunderstorm occurrence through the post-processing of sim-
ulation data.
In section 2, we describe how independent datasets for
the training, testing and validation of our model have been
compiled from NWP forecasts and lightning data. Details on
the ML architecture are provided in section 3. While thun-
derstorm occurrence is identified in a pixel-wise manner, we
systematicallyvarythespatiotemporalcriteriabywhichthe
lightningobservationsareassociatedwiththeNWPdata. This
enables us to study the effect of different spatial scales on the
model identification skill and allows us to estimate the advec-
tion speed of thunderstorms. Further results are presented
in section 4 and demonstrate that, for lead times up to atVAHIDYOUSEFNIA ET AL . 3
least eleven hours, SALAMA is more skillful than a baseline
methodbasedonlyonNWPreflectivity. Inaddition,weshow
a linear relationship between the spatial resolution scale of
our model and the time scale during which skill decreases
with lead time. This is consistent with earlier findings that
resolving smaller scales brings faster growing forecast errors
about (Lorenz, 1969; Selz and Craig, 2015).
2|DATA
We collected simulation data from the ICON-D2-EPS ensem-
blemodel,aswellaslightningobservationsfromthelightning
detection network LINET (LIghtning detection NETwork,
Betzetal.,2009). Thesimulationswereusedtoextractpredic-
torsofthunderstormoccurrence,whilelightningobservations
serve as ground truth.
2.1|Study region and period
The model domain of ICON-D2-EPS covers the areas of Ger-
many,Switzerland,Austria,Denmark,Belgium,theNether-
landsandpartsoftheneighboringcountries. Forourstudy,
wecroppedthemodeldomainatitsbordersbyapproximately
100kmto reduce boundary computation errors. In a cylin-
drical projection, our study region corresponds to a rectangle
with the southwest corner located at 45â—¦N,1â—¦E, the north-
east corner located at 56â—¦N,16â—¦E and all sides being either
parallels or meridians (fig. 5).
There are daily model runs every three hours starting at
00UTC.WecollectedsimulationdatafromJunetoAugust
2021overtheentirestudyregioninhourlysteps,takingalways
the latest available forecast for each hour. Following this
procedure results in forecasts with lead times of 0h,1hor
2h.
Each model run has 20 ensemble members which differ
from each other in a manner consistent with the NWP un-
certainty in the initial conditions, model error, and boundary
conditions(Reinertetal.,2020). Insection4.2,wewillrelate
NWP forecast uncertainty, estimated by ensemble variability,
to ML model skill.2.2|NWP predictors
The atmospheric fields used as predictors of thunderstorm
occurrence in this study are given in table 1. They have been
selectedasfollows: Weconsideredascandidatepredictorsall
two-dimensionalfieldsprovidedinICON-D2-EPS,aswellas
two ICON-D2-EPS pressure-level fields associated with deep
moistconvectionintheliterature,namelytherelativehumidity
at700hPaandtheverticalwindspeedinpressurecoordinates
at500hPa(Lietal.,2021). Inaddition,westipulatedthatthe
predictorsbeavailableontheopen-dataserveroftheDWD
(https://opendata.dwd.de,lastvisit: 2023-03-14),suchthatthe
trainedmodelcaneventuallybeusedinreal-time. Foragiven
candidate input field, we compared histograms of the field
value distribution during and in the absence of thunderstorm
occurrenceandkeptonlyfieldsthatdifferedsignificantlyin
the two distributions.
Asshownintable1,allpredictorscanberelatedtothun-
derstormactivitythroughphysicalmechanismslikeinstability
andmoisture. Inparticular,ourselectionprocesshasledto
predictors that agree with findings in the literature (Ukkonen
andMÃ¤kelÃ¤,2019;Jardinesetal.,2021;Leinonenetal.,2022).
Conversely, convective inhibition (CIN), which is sometimes
listedasaconvectivepredictor(Kamangiretal.,2020),has
not passed the selection process. This is likely due to the
fact that we have checked for predictive power in terms of
developed thunderstorms. CIN, however, correlates with the
hours leading up to a thunderstorm and has been removed
once the storm reaches its mature stage.
It is worth stressing that we have excluded certain parame-
tersonpurpose,namelythegeographicallocationofathun-
derstormevent,thetimeoftheday,andthetimeoftheyear.
In doing so, we assume the existence of a universal signature
sharedbyallthunderstorms,irrespectivelyofwhereandwhen
they occur. In addition, the list of predictors does not include
theleadtimeoftheforecast. Wecheckinsection4whether
our model, which has been trained on data with lead times
between0hand2h, displays skill on data with longer lead
times.4 VAHIDYOUSEFNIA ET AL .
TABLE 1 List of the 21 input parameters used in the study ("DIA": including sub-grid scale).
physical significance ICON parameter name description
instability CAPE_ML mixed-layer convective available potential energy
CEILING ceiling height
OMEGA500 vertical wind speed in pressure coordinates at 500hPa
PS surface pressure
PMSL surface pressure reduced to mean sea level
cloud cover CLCH high level clouds (0- 400hPa)
CLCM mid-level clouds (400- 800hPa)
CLCL low-level clouds ( 800hPato soil)
CLCT total cloud cover
precipitation and DBZ_CMAX maximal radar reflectivity
moisture ECHOTOP echotop pressure
RELHUM700 relative humidity at 700hPa
RELHUM_2M 2mrelative humidity
column-integrated TQC, TQC_DIA cloud water
water quantities TQG graupel
TQI, TQI_DIA ice
TQV, TQV_DIA water vapor
TWATER total water content
2.3|Lightning observations
In supervised learning, ML models are trained on data for
whichthegroundtruthisknown. Forthisreason,werequired
knowledge of thunderstorm occurrence for our study domain
andperiod. Byreasonoftheirhighdetectionefficiencyand
spatial accuracy over the entire study region, we employed
lightning observations to assess the occurrence of thunder-
storms. Specifically,weresortedtotheLINETnetwork(Betz
etal.,2009),whichexploitstheradiospectrumtocontinuously
measure strokes of lightning over Europe. The technology
achievesadetectionefficiencyofmorethan 95%andanav-
erage location accuracy of 150m. While the technology is
able to differentiate between cloud-to-ground and intracloud
flashes,wehaveconsideredalllightningeventsasweareonly
interested in the yes/no occurrence of thunderstorm activity.
Given a set of predictors retrieved from a grid point ğ±
on the study domain at time ğ‘¡during the study period, we
considered thunderstorm activity to occur at (ğ±,ğ‘¡)if a flashwas detected at any (ğ±ğ‘™,ğ‘¡ğ‘™)with
â€–â€–ğ±âˆ’ğ±ğ‘™â€–â€–<Î”ğ‘Ÿ,|ğ‘¡âˆ’ğ‘¡ğ‘™|<Î”ğ‘¡, (1)
whereâ€–â‹…â€–denotes the great-circle distance between ğ±andğ±ğ‘™.
We trained our model with different values for the spatial and
temporal thresholds Î”ğ‘ŸandÎ”ğ‘¡in order to study the relation-
ship between them and classification skill systematically.
2.4|Compiling independent data sets
The data obtained from NWP and lightning observations can
be considered a set of tuples (Î¾,ğ‘¦), where Î¾âˆˆâ„ğ‘›denotes
theğ‘›=21inputparametersand ğ‘¦âˆˆ{0,1}correspondstoa
labelofthegroundtruth(1: thunderstormoccurrence,0: no
thunderstorm occurrence). As the input fields were provided
on a triangular grid, we first performed an interpolation onto
a0.125â—¦Ã—0.125â—¦longitude/latitude grid. The labels were
producedonthesamegrid. Foreachfullhourduringthestudy
period, for each ensemble member and for each grid point,
wefetchedthecorrespondingtuple (Î¾,ğ‘¦),takingalwaystheVAHIDYOUSEFNIA ET AL . 5
latest available forecast.
Theresultinglargecollectionoftupleswasthendivided
into three statistically independent data sets: The training set
is used only for training the neural network model (a precise
definition of training is given in section 3.1), while its skill is
measuredonatestsetwithdatathatthemodelhasnotseen
during training. A third data set, the validation set, is used to
monitortrainingprogress(section3.1). Inanattempttoassure
statisticalindependencebetweenthedatasets,wetooktwo
measures. First, assuming possible day-to-day correlations in
theinputparameters(e.g. inducedbythesynopticscale)to
benegligibleforconvectiveeventswithlifespansoftheorder
of a few hours, we used separate days for training, testing
and validation. In addition, we took into account that intense
thunderstorms that form in the afternoon may well live on
after 0 UTC. We therefore defined days to begin at 8 UTC, a
timeofthedaychosenbycheckingwhenlightningactivityin
thecollecteddataisminimal. Thelattermeasurepreventsdata
fromonethunderstormatdifferenttimestoappearinseparate
datasets. Figure1offersanoverviewofthedayscontainedin
each data set. The days were randomly distributed among the
three sets. Additionally, we randomly subsampled the data
such that the training set consists of 4Ã—105tuples, and the
test and validation sets each contain 105tuples.
1 2 3 4 5 6 7 8 910 11
12 13 14 15 16 17 18 19 20 21 22
23 24 25 26 27 28 29 30 June
1 2 3 4 5 6 7 8 910 11
12 13 14 15 16 17 18 19 20 21 22
23 24 25 26 27 28 29 30 31 July
1 2 3 4 5 6 7 8 910 11
12 13 14 15 16 17 18 19 20 21 22
23 24 25 26 27 28 29 30 August
FIGURE 1 Days (from 8 UTC to 8 UTC) during the
summer of 2021 which were used for compiling the datasets
for training (dark brown), testing (light blue with bold
numerals) and validation (light green). The days have been
distributed at random among the three sets.The rarity of thunderstorms makes predicting their occur-
rencemorechallengingasMLmodelstendtostrugglewith
learning from unbalanced datasets (Sun et al., 2009). As a
matter of fact, we verified that when trained on a climatologi-
callyconsistentdataset,ourmodelwouldpredictthemajority
class(i.e. nothunderstorm)ateveryoccasion. Wetherefore
undersampled the majority class in the training set, such that
both labels appear equally frequently (class balance). On the
other hand, the validation and testing set remain climatologi-
callyconsistentsincewewishtoquantifymodelperformance
inarealisticsetting. Havingdifferentsampleclimatologies
in the training and test set, however, requires model output
calibration, which is discussed in section 3.2.
3|METHODS
In this section, we provide details on SALAMA, focusing
on how it has been trained and calibrated. In addition, we
introducemetricsfortheevaluationofmodelskillandpresent
a baseline model for comparison.
3.1|Model description
ItisworthwhiletointroducesomeMLterminology. Thethree
data sets used for training, testing and validation (section 2.4)
aremadeupofexamples (Î¾,ğ‘¦). Eachexampleconsistsofa
pattern Î¾âˆˆâ„ğ‘›ofğ‘›input features and a label ğ‘¦âˆˆ{0,1}.
Given a pattern Î¾, the problem at hand is to infer the prob-
abilityofthunderstormoccurrence, whichconstitutesatask
known as binary classification. In the following, we consider
both the pattern and its corresponding label to originate from
arandomexperiment. Therefore,let ğšµbeanğ‘›-dimensional
randomvariableforthepatternandlet ğ‘Œbearandomvariable
of thunderstorm occurrence (1: thunderstorm, 0: no thunder-
storm). We are interested in ğ‘ƒ(ğ‘Œ= 1|ğšµ=Î¾), namely the
conditional probability of thunderstorm occurrence if the pat-
tern is known. A feedforward artificial neural network model
is a function ğ‘“âˆ¶â„ğ‘›â†’(0,1)that models the relationship
betweentheinputpatternandthecorrespondingprobability
ofthunderstormoccurrence. Wereferto ğ‘“simplyasneural
network. Neural networks use compositions of matrix mul-
tiplications, as well as non-linear operations referred to as6 VAHIDYOUSEFNIA ET AL .
activationfunctions. Thearchitectureofourneuralnetworkis
presented in fig. 2: It consists of the input and output layer as
wellashiddenlayers,whereeachlayerisavectorofnumbers
obtained from the previous layer by one matrix multiplica-
tionandbyapplyinganactivationfunctiontotheresultina
component-wisemanner. Thecomplexityof ğ‘“isadjustable
through the number of hidden layers and the size of each hid-
den layer, i.e. the number of nodes. Our model has three
hidden layers and 20 nodes per hidden layer. Moreover, we
userectifiedlinearunitsforthehiddenlayersandasigmoid
functiontomaptheoutputlayertoaprobabilitybetweenzero
and one.
21 thunderstorm
features3 hidden layers ` a 20 nodes
thunderstorm
probability
FIGURE 2 (Color online) The architecture of
SALAMA: Input features are scaled to order 1. We use
rectified linear units as activation functions in the hidden
layers. A sigmoid function maps the output layer to the open
interval(0,1).
The entries, also referred to as weights, of the matrices
thatconnectthelayersareadjustedaccordingtothedatain
the training set. We therefore add a subscript ğ°âˆˆâ„ğ‘‘toğ‘“to
express the dependence on the ğ‘‘weights. Ifğ‘“ğ°constitutes
an accurate representation of the conditional probability of
thunderstorm occurrence, i.e. ğ‘“ğ°(Î¾) =ğ‘ƒ(ğ‘Œ= 1|ğšµ=Î¾),
then the likelihood of observing a label ğ‘¦for a given input
feature Î¾reads
ğ¿(ğ°|Î¾,ğ‘¦)=â§
âª
â¨
âªâ©ğ‘“ğ°(Î¾), ğ‘¦=1
1âˆ’ğ‘“ğ°(Î¾), ğ‘¦=0(2)
Denoteby(Î¾(ğ‘–),ğ‘¦(ğ‘–))ğ‘–=1â€¦ğ‘thetrainingsetwith ğ‘exam-
ples. The most likely configuration of weights, given the
trainingset,isthenobtainedbyminimizingthenegativeloga-rithm of the likelihood function,
âˆ’logîˆ¸(ğ°)=âˆ’ğ‘âˆ‘
ğ‘–=1logğ¿(ğ°|Î¾(ğ‘–),ğ‘¦(ğ‘–)),(3)
with respect to the weights. The expression in eq. (3) is re-
ferredtoasbinarycross-entropylossfunctioninMLtermi-
nology. Theprocessofdeterminingtheweightsthatminimize
loss is called training. We trained SALAMA using the robust
iterative stochastic method Adam (Kingma and Ba, 2014).
However, ifoneusedtheconfigurationofweightswhichmin-
imizes eq. (3) exactly, a neural network would likely suffer
from overfitting, i.e. learning parts of the noise in the data
aswell. Tothisend,weimplementedanearlystoppingpro-
cedure, in which loss was monitored on the validation set
during training. Once the validation loss no longer decreased,
training was stopped.
Before training, each input feature has been scaled in a
way that its sample standard deviation in the training set is
oftheorderofunity. Inaddition,wetrainednotonlyonthe
architecture presented in fig. 2 but also varied the number of
hiddenlayers,aswellasthenumberofnodesperlayer. We
found that once a certain complexity was reached in terms
of the size of the network, adding new nodes or layers had
no effect on the validation loss at the end of training. The
architectureinfig.2constitutesthesmallestnetworkforwhich
this complexity threshold has been exceeded.
A conceptional issue we would like to address concerns
our use of ensemble data. In our data sets, a given Î¾(ğ‘–)has
beenretrievedfromaspecific(butarbitrary)memberofthe
NWPensemble. Consequently, ğ‘“ğ°(Î¾)referstotheprobability
of thunderstorm occurrence associated with this individual
member. With the exception of a study of ensemble spread
in section 4.2, the results in the remainder of this work are,
therefore, based on probabilities for one individual member.
3.2|Analytic model calibration
Inorder toaddresstheclimatological rarityofthunderstorm
occurrence, we have artificially increased the fraction of posi-
tiveexamplesinthedatasetusedforthetrainingofourneural
network (section 2.4). In this section, we explain why this
dataset modification causes our model to be miscalibrated,VAHIDYOUSEFNIA ET AL . 7
andderiveananalyticcorrectionformodeloutputcalibration.
It is crucial to understand that if the trained model were
naivelyappliedtoatestsetwithadifferentfractionofpositive
examplesthaninthetrainingset,theproducedprobabilities
would be inconsistent with the observed relative frequency of
thunderstorm occurrence. In order to see this, we use Bayesâ€™
theoremtoexpandtheconditionalprobabilityofthunderstorm
occurrence given a pattern Î¾, which yields:
ğ‘ƒ(ğ‘Œ=1|ğšµ=Î¾)=ğ‘ƒ(ğšµ=Î¾|ğ‘Œ=1)ğ‘ƒ(ğ‘Œ=1)
ğ‘ƒ(ğšµ=Î¾).(4)
The denominator can be expressed as
ğ‘ƒ(ğšµ=Î¾)=ğ‘ƒ(ğšµ=Î¾|ğ‘Œ=1)ğ‘ƒ(ğ‘Œ=1)
+ğ‘ƒ(ğšµ=Î¾|ğ‘Œ=0)ğ‘ƒ(ğ‘Œ=0).(5)
Letğ‘ƒ(ğ‘Œ= 1) = 1âˆ’ ğ‘ƒ(ğ‘Œ= 0) =ğ‘”, whereğ‘”denotes the
climatologicalprobabilityofthunderstormoccurrencewith
no prior knowledge. Then,
ğ‘ƒ(ğ‘Œ=1|ğšµ=Î¾)=1
1+(1âˆ’ğ‘”)ğ‘…(Î¾)âˆ•ğ‘”,(6)
where the residual function ğ‘…(Î¾)=ğ‘ƒ(ğšµ=Î¾|ğ‘Œ=0)âˆ•ğ‘ƒ(ğšµ=
Î¾|ğ‘Œ= 1)is not expected to depend on ğ‘”. Nevertheless,
eq.(6)showsthattheconditionalprobabilityofthunderstorm
occurrence does carryan implicit ğ‘”-dependence throughthe
prefactor(1âˆ’ğ‘”)âˆ•ğ‘”. The training set contains an increased
fractionÌƒ ğ‘”ofpositiveexamples(inourwork: Ìƒ ğ‘”=1âˆ•2),while
the corresponding fraction in the test set is (up to fluctuations
duetothefinitesamplesize)equaltotheclimatologicalvalue
ğ‘”. During training, the neural network, therefore, learns to
produce the following model output
ğ‘“ğ°(Î¾,Ìƒ ğ‘”)=1
1+(1âˆ’Ìƒ ğ‘”)ğ‘…(Î¾)âˆ•Ìƒ ğ‘”. (7)
When wewant to applyour neural networkto a datasetwith
ğ‘”â‰ Ìƒ ğ‘”, the correct probability output reads
ğ‘“ğ°(Î¾,ğ‘”)=ğ‘“ğ°(Î¾,Ìƒ ğ‘”)
ğ‘“ğ°(Î¾,Ìƒ ğ‘”)+1âˆ’ğ‘”
ğ‘”Ìƒ ğ‘”
1âˆ’Ìƒ ğ‘”(1âˆ’ğ‘“ğ°(Î¾,Ìƒ ğ‘”)),(8)
whichcanbederivedbysolvingeq.(7)for ğ‘…(Î¾)andsubsti-
tuting the result into eq. (6). On the other hand, if the sampleclimatology of training set and test set are equal ( Ìƒ ğ‘”=ğ‘”),
eq. (8)yields ğ‘“ğ°(Î¾,ğ‘”)=ğ‘“ğ°(Î¾,Ìƒ ğ‘”), i.e. noprobability correc-
tion is needed.
Ifthemodelprobabilityoutputisconsistentwiththeob-
served relative frequency of thunderstorm occurrence, the
modelforecastsarereferredtoasreliable. Inordertocheck
whether our neural network provides reliable forecasts, we
used the test set to produce a reliability diagram. For this
purpose, one partitions the interval (0,1)of possible forecast
probabilities into bins. For each bin, one considers all exam-
ples whose model probability falls into the bin. Then, one
computes the relative frequency of thunderstorm occurrence
and plots it against the bin-averaged model probability per
bin. The resulting curve is referred to as calibration func-
tion. An example for one configuration of lightning labels is
showninfig.3(a), forwhich10equidistantbinshavebeen
used. Shownaretwocalibrationfunctions: Thelightgreyline
corresponds to a calibration function withoutany probability
correction, while the solid black line results from applying
(8)to our model output. The uncertainty on the observed
frequencyspansthe5thand95thpercentilesoffluctuations
and hasbeen estimated througha bootstrap resampling proce-
dure similar to BrÃ¶cker and Smith (2007a): By drawing with
replacement,oneproducesvariationsoftheoriginaltestset
and considers the sample-to-sample fluctuations of observed
relative frequencies.
Theuncalibratedlineseverelyoverestimatestherelative
frequency of thunderstorm occurrence at all model probabil-
ities. As has been worked out, this is not a result of faulty
trainingbutstemsfromhavingdifferentsampleclimatologies
in the training and test sets. After calibration, however, our
model produces reliable forecasts for probabilities close to 0
and 1. Onthe otherhand, ourmodel slightlyunderestimates
therelativefrequencyofthunderstormoccurrenceforforecast
probabilities below 0.6. Further calibration could be done
using statistical methods like isotonic regression (Niculescu-
Mizil and Caruana, 2005), which is beyond the scope of this
work. Instead,weconsiderourmodelsufficientlyreliableand
appreciate that the level of reliability has been attained by
means of the analytical correction (8) alone.
Inadditiontocalibrationcurves,binningtheforecastprob-
abilities allows the introduction of two useful metrics of clas-
sification skill. Of the ğ‘examples in the test set, let ğ‘ğ‘–8 VAHIDYOUSEFNIA ET AL .
fall into binğ‘–with bin width Î”ğ‘ğ‘–, bin-averaged model proba-
bilityğ‘ğ‘–andobservedrelativefrequency ğ‘œğ‘–ofthunderstorm
occurrence. Wethendefinethefollowingtwobin-wiseterms:
RESğ‘–=1âˆ•Î”ğ‘ğ‘–
ğ‘”(1âˆ’ğ‘”)ğ‘ğ‘–
ğ‘(ğ‘ğ‘–âˆ’ğ‘”)2(9)
RELğ‘–=1âˆ•Î”ğ‘ğ‘–
ğ‘”(1âˆ’ğ‘”)ğ‘ğ‘–
ğ‘(ğ‘ğ‘–âˆ’ğ‘œğ‘–)2(10)
Uptoa factor ğ‘”(1âˆ’ğ‘”)knownasuncertainty term,thesums
âˆ‘
ğ‘–Î”ğ‘ğ‘–RESğ‘–andâˆ‘
ğ‘–Î”ğ‘ğ‘–RELğ‘–are called the resolution and
reliability, respectively, of the model. Resolution measures
forecast variance, with higher values of resolution indicating
a better ability of the model to differentiate between thun-
derstormandnon-thunderstormpatterns(Tothetal.,2003).
Reliability quantifies the meansquared deviation of the cali-
bration curve from the diagonal. The bin-wise terms defined
in eqs. (9) to (10) and shown in fig. 3 (b) offer an overview
of how much each probability bin contributes to reliability
andresolution. Forinstance,resolutionismostimpactedby
exampleswithmodelprobabilitiesofca. 0.3anddominates
over reliability.
0.00.20.40.60.81.0oi(a)
0.0 0.2 0.4 0.6 0.8 1.0
pi0.000.25RES, RELBSS = 0.21(b)RES
REL100102104
Ni
FIGURE 3 Reliability diagram of SALAMA, evaluated
for the test set with the label configuration
Î”ğ‘Ÿ=15km,Î”ğ‘¡=30min (section 2.3). (a) Calibration
curve after applying probability correction (8) (black solid
line), and before (grey light dotted line), and histogram of
examplesperbin. Perfectreliabilityisindicatedbyadashed
diagonal. Shaded band corresponds to the symmetric 90%
confidence interval obtained by 200bootstrap resamples. (b)
Bin-wise resolution and reliability (eqs. (9) to (10)) and their
relation to the Brier skill score (BSS, section 3.3) as a
function of model probability.3.3|Skill evaluation metrics
Metrics for evaluating classification skill using a test set with
ğ‘examples include the Brier score (BS),
BS=ğ‘âˆ‘
ğ‘˜=1(ğ‘(ğ‘˜)âˆ’ğ‘¦(ğ‘˜))2, ğ‘(ğ‘˜)=ğ‘“ğ°(Î¾(ğ‘˜),ğ‘”),(11)
which is known for being strictly proper (BrÃ¶cker and Smith,
2007b). NormalizationwithareferenceBrierscore BSref=
âˆ‘ğ‘
ğ‘˜=1(ğ‘”âˆ’ğ‘¦(ğ‘˜))2of a random climatological model yields the
Brier skill score (BSS)
BSS=1âˆ’BS
BSref(12)
Murphy (1973) showed that BSS can be written as the differ-
encebetweenresolutionandreliability(section3.2). Thus, in
terms of eqs. (9) to (10), BSS is given by the area between
RES and REL as functions of ğ‘. This is illustrated in fig. 3
(b).
WhiletheBSSdirectlyactsontheprobabilityoutputs ğ‘(ğ‘˜)
(eq. (11)) of the model, a large class of classification metrics
requiretheconversionofprobabilitiestobinaryoutputfirst.
Thisisdonebyintroducingadecisionthreshold Ìƒ ğ‘. Ifğ‘> Ìƒ ğ‘,
thunderstorm occurrence for the corresponding example is
deemed "true", otherwise "false". In combination with the
two options from the label, there are four possible outcomes
foreachexample. Theyarepresentedasacontingencymatrix
in table 2.
TABLE 2 Contingency matrix for binary classification.
observed thunderstorm
true false
forecast thunderstormtruehitfalse alarm
false miss correct reject
While there is an infinite number of options to combine
the four possible outcomes to a single skill score, we selected
the scores in this study based on their suitability for tasks
withsignificantclassimbalance. Namely,wedonotwishto
reward our model for correctly classifying the majority class.
ThisamountstodismissingscoreswhichexplicitlyusecorrectVAHIDYOUSEFNIA ET AL . 9
rejects.
Given a test set and a fixed decision threshold, the prob-
ability of detection (POD) and false-alarm ratio (FAR) are
defined by
POD=hits
hits+misses, (13)
FAR=false alarms
hits+false alarms. (14)
Here,e.g. "hits"referstothenumberofexamplesinthetest
set that qualify as "hit" according to table 2. POD is often
referred to as recall in the ML literature, while 1âˆ’FARis
also known as precision.
Precisionandrecallneedtobesimultaneouslyoptimized
for a useful classifier. For instance, perfect recall is easily
achievedbypredictingthethunderstormclassateveryocca-
sion. For problems with class imbalance, a popular choice
of combining the two scores consists of taking the harmonic
mean, which yields the ğ¹1-score:
ğ¹1=2
PODâˆ’1+(1âˆ’FAR)âˆ’1=2hits
2hits+misses+false alarms
(15)
Anotheroptionofcombiningthecontingencymatrixelements
is given by the critical success index (CSI):
CSI=hits
hits+misses+false alarms(16)
A modification of the CSI consists of subtracting as many
hitsasamodelrandomlyclassifyingaccordingtoclimatology
would obtain. The equitable threat score (ETS) reads
ETS=hitsâˆ’hits by accident
hitsâˆ’hits by accident +misses+false alarms,
(17)
wherethehitsbyaccidentamountto ğ‘”Ã—(hits+false alarms).
3.4|Baseline model
As thunderstorms are accompanied by convective precipi-
tation, radar reflectivity constitutes a natural surrogate for
thunderstormstormoccurrenceinthenowcastingcommunity
(DixonandWiener,1993;Wilsonetal.,1998;Turneretal.,
2004). ICON-D2-EPS outputs the column-maximal radar
reflectivity (DBZ_CMAX in table 1), which we refer to asreflectivityinwhatfollows. Inordertoconstructabaselinefor
comparison toSALAMA, we repeattraining our model, but
use only reflectivity as input. The architecture of the baseline
model is identical to the one presented in fig. 2 except for
the input layer, which has now only a single node. Just like
forSALAMA,thebaselinemodeloutputstheprobabilityof
thunderstorm occurrence (for the one ensemble member that
produced the input reflectivity).
Figure 4 shows the resulting reliability diagram. The light
dottedlinecorrespondstotheuncorrectedcalibrationcurve,
whilethedash-dottedlineresultsfromapplyingprobability
correction (8). Thebaselinemodelproduceswell-calibrated
output for small model probabilities while the model displays
underconfidenceaboveprobabilitiesofapproximately 0.2. As
exampleswithhigherprobabilitiesthan 0.2makeuplessthan
1%oftheexamplesinthetestset,weassumethattheseex-
amples therefore did not contribute sufficiently to the loss
function,whichinsteadfavored well-calibratedsmallproba-
bilities. Inanefforttoconstructacompetitivebaselinemodel,
we used the validation set to fit a linear function to the part
of the dash-dotted calibration curve with probabilities higher
than0.15. Then, if the output of the baseline model after
applicationofprobabilitycorrectioneq.(8)isdenotedby ğ‘,
thecalibratedoutputreads ğ¶(ğ‘)forğ‘>0.15,andğ‘otherwise.
The resulting well-calibrated calibration curve is given by the
solid line in the reliability diagram. The histogram and the
lower panel in fig. 4 (a) refer to the latter calibration curve.
OnecanseethatBSSisessentiallydeterminedbythebaseline
resolution,justlikeforSALAMA(fig.3). Thebaselinescores
comparably to SALAMA in terms of reliability. On the other
hand, the baseline resolution is significantly worse, which
results in a lower BSS compared to SALAMA.
Figure 4 (b) shows the learned and calibrated relation-
shipbetweenNWPreflectivityandthecorrespondingprob-
ability of thunderstorm occurrence. The herein observed
monotonously increasing relationship implies that thunder-
stormsbecomemorelikelyasreflectivityincreases. Atypical
thresholdfordefiningthunderstormsinnowcastingis 35dBZ
(DixonandWiener,1993;Muelleretal.,2003),forwhichthe
probability of thunderstorm occurrence reads 0.22.10 VAHIDYOUSEFNIA ET AL .
0.00.20.40.60.81.0oicorrection (8)
uncalibratedfull calibration(a)
0.0 0.2 0.4 0.6 0.8 1.0
pi0.000.050.10RES, RELBSS = 0.06RES
REL100102104
Ni
40
 20
 0 20 40 60
NWP reflectivity (dBZ)0.00.10.20.30.40.50.60.70.8model probability(b)
FIGURE 4 Training of the baseline model. (a) Reliability diagram panels as in fig. 3, but for the baseline model. (b)
Learned relationship between the baseline input field and the corresponding probability of thunderstorm occurrence.
4|RESULTS
SALAMA provides a general post-processing framework for
NWP ensemble forecasts. While we trained SALAMA on
lead times up to two hours, we apply the same model to all
lead times and all ensemble members individually, using nei-
ther the lead time nor the ensemble member index as input
feature. Working with ensemble data, our framework read-
ily allows us to study the ensemble spread of thunderstorm
occurrence. Forexample,ifwehave,foragivenlocation,a
3h-forecast of ICON-D2-EPS at hand, it consists of 20 input
feature tuples (one tuple for each ensemble member). One
can now compute a thunderstorm probability according to
eq.(8)foreachmember. Aswewilldiscussinsection4.2,the
ensemble spread of thunderstorm probability is linked to the
NWP forecast uncertainty of the input features. In the follow-
ing,wecompareSALAMAtothebaselinemodelbasedon
reflectivity(section3.4)andmoveontoinvestigatinghowthe
spatiotemporal thresholds of the lightning label configuration
(section 2.3) influence the classification skill of SALAMA as
a function of lead time.
4.1|Comparison to baseline model
In this section, we keep the thresholds of the lightning la-
belconfiguration(section2.3)fixedtotheparticularchoice
Î”ğ‘Ÿ= 15km,Î”ğ‘¡= 30min . The climatological fraction of
thunderstormexamplesinthetestsetamountsto ğ‘”=0.021
in this configuration. The results of this section, however, donot change qualitatively if another configuration is used.
As a first step, we visually compare the performance of
SALAMA and the baseline model in a case study. For this
purpose, we run SALAMA for three consecutive hours of
an evening with thunderstorm occurrence over Southern Ger-
many. ThisdayhasnotbeenusedforthetrainingofSALAMA.
In fig. 5, we plot the probability of thunderstorm occurrence
foranarbitrarymemberoftheNWPensemblefortheentire
study domain. Observed thunderstorm occurrence is given
byblackcontours. Thecorrespondingplotsforthebaseline
modelareaddedbelowthepanelsofSALAMA.Inthispartic-
ular case study, SALAMA tends to detect more thunderstorm
pixels than the baseline model. On the other hand, SALAMA
seems to produce more false alarms.
In order to compare the skill of SALAMA and our base-
line quantitatively for the entire study period, we evaluate
the skill scores introduced in section 3.3. We use for this
purpose the test setintroduced in section 2.4, which consists
ofexamplesoftheentiresummerof2021. Forsomeofthe
scores, we need to set a decision threshold. As a criterion,
we demand that forecasts be unbiased (average fraction of
examples classified as thunderstorms is equal to the observed
fraction of thunderstorm examples), yielding thresholds of
0.193(SALAMA)and 0.119(baseline). Thethresholdsare
also indicated in the color bars of fig. 5. The threshold found
for reflectivity corresponds to 28dBZand is slightly below
the typical literature threshold cited in section 3.4.
TheperformanceofSALAMAandthebaselineissumma-
rized in table 3. Irrespectively of the skill score under consid-VAHIDYOUSEFNIA ET AL . 11
SALAMA
19 UTC
SALAMA
20 UTC
SALAMA
21 UTC
0.150.300.450.600.750.90
Baseline
19 UTC
Baseline
20 UTC
Baseline
21 UTC
0.150.300.450.600.750.90
FIGURE 5 (Color online) Probability of thunderstorm occurrence for June 23, 2021 from 19 UTC on, for SALAMA (upper
row) and the baseline model (lower row). The model lead times for the three hours are 1h,2h, and0h, respectively. The color
maps display the result for the first ensemble member of ICON-D2-EPS, while lightning labels ( Î”ğ‘Ÿ=15km,Î”ğ‘¡=30min,
section 2.3) are shown as black contours. A jump in the color maps indicates the decision thresholds used for the evaluation of
the skill scores in table 3.12 VAHIDYOUSEFNIA ET AL .
eration,SALAMAscoresbetterthanthebaselinemodel. The
uncertaintiesarecomputedhere,aswellasforthesubsequent
evaluations,bythebootstrapresamplingmethodintroduced
in section 3.2. Note that we obtain POD= 1âˆ’FAR=ğ¹1
for both models. This is a result from our choice of deci-
sionthreshold: Recallgenerallyequalsprecisionforunbiased
forecasts (Wilks, 2011).
TABLE 3 Scores for classification skill, evaluated on the
test set, for SALAMA and the baseline model. The
probability thresholds used for evaluation are chosen such
that the forecast is unbiased and amount to 0.193
(SALAMA), 0.119(baseline). Uncertainties are obtained
from 200 bootstrap resamples and show the symmetric 90%
confidence interval.
skill score SALAMA Baseline
PR-AUC0.358(18) 0 .141(12)
BSS0.209(10)0.063(7)
POD0.403(16) 0 .189(12)
1-FAR0.402(17)0.188(13)
ğ¹10.403(15) 0 .189(12)
CSI0.252(12)0.104(7)
ETS0.241(12) 0 .093(7)
Drawing(POD,1âˆ’FAR)fordifferentdecisionthresholds
into onediagram, one obtains the precision-recall(PR) dia-
gram in fig. 6. A random model with no skill corresponds to
the dashed horizontal curve 1âˆ’FAR=ğ‘”, whereğ‘”denotes
theclimatologicalfractionofpositiveexamplesinthetestset.
ModelswithskilldisplayPRcurvesabovethehorizontalline,
with higher areas under the curve (AUC) indicating higher
classification skill. Both models considered in this study dis-
play higher skill than a random model following climatology
would. SALAMA, however, has higher classification skill
than the baseline, as can be seen from the higher AUC in the
PR curve in fig. 6. The enhanced skill of SALAMA with
respecttothebaselinemodelillustratesthatamulti-parameter
approachtothunderstormforecastingissuperiortoemploying
a single input feature.
0.2 0.4 0.6 0.8
POD0.20.40.60.81-FAR
1%5%19.3%30%
5%11.9%30%
AUC = 0.36
AUC = 0.14SALAMA
BaselineFIGURE 6 (Color online) PR curve for SALAMA
(solid) and the baseline model (dashed), evaluated on the test
set. The annotations added to the curves correspond to
different decision thresholds (section 3.3). Grey dotted line
denotes models with no identification skill. Uncertainties are
obtained from 200 bootstrap resamples and show the
symmetric90%confidence interval.
4.2|Lead time dependence of
classification skill
The data sets for training, testing and validation introduced in
section2.4andusedinsection4.1arecomprisedofNWPfore-
castswithleadtimesupto 2h. Thereasonforthischoicewas
to train and evaluate our model in a setting of minimal NWP
forecast uncertainty. On the other hand, this procedure raises
thequestionwhetherthethunderstormsignaturelearnedby
the model generalizes to NWP data with longer lead times
(and higher forecast uncertainty). For this purpose, we gener-
ate test sets in which the examples come from NWP forecasts
withfixedleadtime. Eachsetcontains 105examples. Weuse
thesamedatesasforthetestsetsintroducedinsection2.4. In
fig. 7, we plot the SALAMA classification skill, measured in
termsoftheskillscoresintroducedinsection3.3asafunction
of lead time and compare it to the dependence obtained for
the baseline model. Figure 7 shows that, for SALAMA, clas-
sificationskilldecreasesapproximatelyexponentially(note
the log-scaling of the ğ‘¦-axis) for lead times longer than 1h,
irrespectivelyoftheskillscoreunderconsideration. Theclas-
sification skill of SALAMA at a lead time of 1his actually
higher than at 0h, which is likely a spin-up effect from the
NWPmodel(Sunetal.,2014). Ontheotherhand, SALAMA
skill is systematically superior to baseline skill for all lead
times. In fact, even the 11-hour-lead-time skill of SALAMAVAHIDYOUSEFNIA ET AL . 13
0 2 4 6 8 10
Lead time (h)102
101
skill scorePOD
BSSSALAMA
1-FAR
F1
CSIETS
PR-AUC
0 2 4 6 8 10
Lead time (h)POD
BSSBaseline
FIGURE 7 Classification skill as a function of lead time for SALAMA (left) and the baseline model (right). The probability
thresholds used for evaluation are chosen such that the forecast is unbiased and amount to 0.193(SALAMA), 0.119(baseline).
Uncertainties are obtained from 200 bootstrap resamples and show the symmetric 90%confidence interval.
is higher than the baseline skill for any of the considered lead
times.
Itistemptingtoassumethatthedecreaseinskillwithlead
time originates from an increasing NWP forecast uncertainty
for longer lead times. We can use ensemble data to check
this hypothesis. Let ğ‘be either one of the 21 input features
orthemodelthunderstormprobability,i.e. aquantitythatis
given for each ensemble member and each lead time. Then
define the ensemble spread ğœâ€²
ğ‘ofğ‘as the ensemble standard
deviation of ğ‘,
ğœâ€²
ğ‘(ğ‘¡lead)=âˆš
âŸ¨ğ‘(ğ‘¡lead)2âŸ©âˆ’âŸ¨ğ‘(ğ‘¡lead)âŸ©2,(18)
where we make the dependence on the lead time ğ‘¡leadexplicit.
The brackets âŸ¨â‹…âŸ©denote the average over all 20 ensemble
members. Denote by ğœâ€²
ğ‘(ğ‘¡lead)the expression obtained by
performing the average of ğœâ€²
ğ‘over the entire study region and
all times associated with the test set. Lastly, we define the
normalized ensemble spread of ğ‘,
ğœğ‘(ğ‘¡lead)=ğœâ€²
ğ‘(ğ‘¡lead)
ğœâ€²
ğ‘(0h), (19)
as a function of lead time. It quantifies ensemble spread
in such a way that different input features can be directly
compared to each other. In fig. 8, the normalized ensemblespread ofeach of the21 inputfeatures is shownas thinsolid
lines and the corresponding curve for the model output of
SALAMA is drawn in thick and dashed. One can see that
theensemblespreaddoes indeedincreasewithleadtimefor
mostinputfeatures,theincreasebeingapproximatelylinear.
The ensemble spread of the SALAMA output increases in
line with the majority of the input features and with a similar
slope. This suggests that the decrease in classification skill
observedinfig.6issolelyduetotheincreasingvariancein
the simulation data.
4.3|Effect of the label size
So far, the temporal and spatial thresholds of the label con-
figuration have been fixed to Î”ğ‘Ÿ=15km andÎ”ğ‘¡=30min
(henceforthreferredtoasdefaultconfiguration). Inthissec-
tion, we study how varying the spatiotemporal thresholds
affects the classification skill of SALAMA.
As a first step, we compute reliability diagrams for dif-
ferentlabelconfigurations. Inpanel(a)offig.9,westudya
configurationwithsmallerthresholdsthanfortheconfigura-
tion studied so far. Panel (b) displays a configuration with
reducedÎ”ğ‘¡andincreased Î”ğ‘Ÿ. Inpanel(c),boththresholdsare
increased with respect to the default configuration. The exact
choiceofÎ”ğ‘¡andÎ”ğ‘Ÿforthethreepanelsissomewhatarbitrary14 VAHIDYOUSEFNIA ET AL .
0 2 4 6 8 10
Lead time (h)1.01.52.0norm. ens. spreadinput feature
SALAMA
FIGURE 8 Normalized ensemble spread (as defined in
eq. (19)) of input features in comparison to spread of model
thunderstorm probability as a function of lead time. Each
thin solid linerefersto one ofthe 21 inputfeatures. Thethick
dashed green line is associated with SALAMA. A shaded
band represents the symmetric 90%confidence interval of
uncertainty, estimated with 200 bootstrap resamples.
but still allows for qualitative insight: Irrespectively of the
configuration,forecastsarewell-calibratedforsmallandlarge
model probabilities. In addition, model skill, quantified in
termsofBSS,increasesfromlefttoright. Thediagramsshow
thatthe increasein BSSismainly dueto enhancedcontribu-
tion to resolution from probabilities larger than 0.3, though a
reliability improvement from probabilities around 0.2adds to
the increase in BSS as well.
As we have seen in section 4.2 that the qualitative lead
timedependenceofSALAMAskilldoesnotdependonthe
skillscore,weconsiderfromnowononlyPR-AUCforfurther
investigations. We start by computing PR-AUC for several
label configurations, which is shown in fig. 10. The color
patterninthefiguresuggeststhatthetwothresholdsarenot
independent variables of classification skill. Instead, one
can find a parameter ğ‘with the units of a velocity such that
classification skill is nearly constant along lines
ğ‘ =Î”ğ‘Ÿ+ğ‘Î”ğ‘¡=const. (20)
Indeed,ğ‘ corresponds to a spatial resolution scale; it deter-
minestheminimalspatialaccuracythatcanbeexpectedfrom
amodeltrainedwithagivenlabelconfiguration. Weexpect
theparameter ğ‘toroughlyquantifythespeedatwhichregions
ofthunderstormoccurrenceareadvectedintheatmosphere.
A fit to the data provides ğ‘=5.6(3)msâˆ’1, which is similarto typical low- to mid-tropospheric wind speeds in Central
Europe. We can now motivate the spatiotemporal thresholds
for the reliability diagram in the middle panel (fig. 9): they
havebeenchosensuchthat ğ‘ takesonthesamevalueasthe
default configuration.
Lines of constant ğ‘ appear as dashed lines in fig. 10 and
indicate that classification skill increases with ğ‘ . This is in
linewiththedisplayedobservationofincreasedBSSinthe
reliability diagrams. This is also consistent with the work
of Roberts (2008), which investigates the spatial variation of
precipitation forecast skill. Note that sample climatology ğ‘”
increaseswith ğ‘ aswell. Infact,itamountsto ğ‘”=1.7Ã—10âˆ’3
in the lower left pixel of fig. 10, and to ğ‘”=4.6Ã—10âˆ’2in the
upperrightcorner. Sincearandommodelwithnoskillhas
PR-AUC=ğ‘”(section 4.1), the increase in skill as a function
ofğ‘ is to a slight extent also due to the increase in ğ‘”.
Next, we investigate how the decrease of classification
skillwithleadtimedependsonthespatialscale. Motivated
by the observed decay of classification skill with lead time
(section 4.2), we fit an exponential function exp(âˆ’ğ‘¡leadâˆ•ğœ)to
the lead time dependence of classification skill (measured
againbytheareaunderthePRcurve). Theskilldecaytime
ğœthen provides a characteristic time scale for the decrease
of classification skill. For each label configuration infig. 10,
wecomputethecorrespondingspatialscaleaswellas ğœ. In
fig. 11, we present a scatter plot of ğœandğ‘ . The figure shows
a tight positive linear correlation between the two quantities,
whichmeansthatclassificationskilldecreasesmoreslowlyfor
coarserlabelconfigurations. Thisisinagreementwiththean-
ticipation(Lorenz,1969)thatresolvingsmallerscalesinNWP
models is associated with a more rapid growth of forecast er-
rors. Our finding is complementary to convection studies
involvingascale-dependentskillscore(Roberts,2008),and
high-resolution simulations (Selz and Craig, 2015).
5|CONCLUSION AND PERSPEC-
TIVES
Addressingtheneedforaccuratethunderstormforecastingand
leveragingadvancesinhigh-resolutionNWPandML,wehave
presentedSALAMA,afeedforwardneuralnetworkmodelthat
identifies thunderstorm occurrence in NWP forecasts up toVAHIDYOUSEFNIA ET AL . 15
0.00.51.0oi(a)
0.0 0.2 0.4 0.6 0.8 1.0
pi0.000.25RES, REL0.16RES
REL100103
Ni
0.00.51.0oi(b)
0.0 0.2 0.4 0.6 0.8 1.0
pi0.000.25RES, REL0.20RES
REL100103
Ni
0.00.51.0oi(c)
0.0 0.2 0.4 0.6 0.8 1.0
pi0.000.25RES, REL0.25RES
REL100103
Ni
FIGURE 9 Reliability diagrams as in fig. 3, but with label configurations (a) Î”ğ‘¡=15min,Î”ğ‘Ÿ=9km(ğ‘ =14km), (b)
Î”ğ‘¡=10min,Î”ğ‘Ÿ=21km(ğ‘ =24km), (c)Î”ğ‘¡=40min,Î”ğ‘Ÿ=24km(ğ‘ =36km). The spatial scale ğ‘ is introduced in eq. (20).
10 20 30 40
Time threshold t (min)
369121518212427Spatial threshold r (km)
s=10kms=15kms=20kms=25kms=30kms=35km
0.150.200.250.300.350.400.45
FIGURE 10 (Color online) Classification skill of
SALAMA, expressed in terms of the area under the PR
curve, as a function of the label configuration (section 2.3).
The slope of the dashed lines is chosen such that
classification skill is approximately constant along the lines.
Each line corresponds to a specific spatial scale ğ‘ (eq. (20)).
0 10 20 30 40
Spatial scale s (km)010203040Skill decay time  (h)
=as+b
a=1.03 h/km
b=1.41 h
Pearson: 0.97FIGURE 11 Decay time of classification skill
(quantified by the area under the PR curve) as a function of
the spatial scale. Each data point corresponds to one label
configurationinfig.10. Theparametersofalinearfitarealso
shown, as well as the Pearson coefficient of correlation.
11hin advance in a pixel-wise manner. The inference of
the probability of thunderstorm occurrence is based on input
parametersthatarephysicallyrelatedtothunderstormactivity
and do not explicitly feature information on location, time or
forecast range. This gives reason to expect that the signature
learned by the model generalizes to thunderstorms outside
the study region of this work and remains valid in a changing
climate. In addition, the availability of all input features in
real-timemakesSALAMAreadilyavailableforoperational
use.
Wehaveaddressedthetechnicalchallengecausedbythe
rarity of thunderstorms and the corresponding small fraction
ofpositiveexamplesbyincreasingthisfractionduringtrain-
ing and analytically accounting for the increase when testing.
This approach has allowed us to ensure reasonable reliability
without calibration fits. Furthermore, we have proposed a16 VAHIDYOUSEFNIA ET AL .
novelvisualizationofreliabilityandresolutionasafunction
of bin-wise model probability. The visualization arguably
proves useful for evaluating how examples with a certain
model probability contribute to classification skill.
Working with ensemble data, we have studied how the
NWP forecast uncertainty depends on the lead time of the
forecast and have related it to the classification skill decrease
of SALAMA. This has suggested that the decrease in skill
istheresultofanincreasinguncertaintyintheinputfeature
forecasting.
Duringthetrainingprocess,wehavesystematicallyvaried
the spatiotemporal criteria by which we associate lightning
observations with NWP data. This has allowed us to test
SALAMA with different spatial scales and to estimate the
orderofmagnitudeofthespeedatwhichthunderstormsare
advected in the atmosphere. We have shown that classifica-
tionskillincreaseswiththespatialscaleoftheforecastandis
higherthanforabaselinemodelbasedonNWPreflectivity
alone. Furthermore, we have found that the decay time of
classification skill is proportional to the spatial scale. In com-
bination with the result that the SALAMA classification skill
is correlated with the NWP forecast uncertainty, our findings
have indicated that resolving thunderstorms at smaller scales
reduces the predictability of thunderstorm occurrence.
Inafuturework,itisusefultochecktheuniversalityofthe
thunderstorm signature learned by SALAMA, e.g. by testing
it on data outside of Central Europe or for a different time
period than the summer of 2021. Moreover, one may explore
whether classification skill can be improved by shifting from
a pixel-wise consideration of input features to taking their
spatiotemporal structure into account as well.
6|AUTHOR CONTRIBUTIONS
K. Vahid Yousefnia: Methodology; software; investigation;
resources; visualization; writing - original draft; writing -
review and editing. T. BÃ¶lle: Conceptualization; writing -
reviewandediting. I.ZÃ¶bisch: Conceptualization;resources;
writing-reviewandediting. T.Gerz: Writing-reviewand
editing; supervision.7|DATA AVAILABILITY
ThePython codefor SALAMAwill bemade availableupon
reasonable request.
8|ACKNOWLEDGEMENTS
We thank George Craig and Tobias Selz for helpful discus-
sions. This work was funded through the internal project
DIALoftheGermanAerospaceCenter(DLR).Wegratefully
acknowledgethecomputationalanddataresourcesprovided
through the joint high-performance data analytics (HPDA)
project "terrabyte" of the DLR and the Leibniz Supercom-
puting Center (LRZ). The authors declare that there are no
conflicts of interest to disclose.
REFERENCES
Bauer, P., Thorpe, A. and Brunet, G. (2015) The quiet revolution
of numerical weather prediction. Nature,525, 47â€“55.
Betz, H. D., Schmidt, K., Laroche, P., Blanchet, P., Oettinger,
W.P.,Defer,E.,Dziewit,Z.andKonarski,J.(2009)Linetâ€”an
international lightning detection network in europe. Atmo-
sphericResearch ,91,564â€“573.13thInternationalConference
on Atmospheric Electricity.
Borsky, S. and Unterberger, C. (2019) Bad weather and
flight delays: The impact of sudden and slow onset
weather events. Economics of Transportation ,18, 10â€“
26. URL: https://www.sciencedirect.com/science/
article/pii/S2212012218300753 .
BrÃ¶cker, J. and Smith, L. A. (2007a) Increasing the reliabil-
ity of reliability diagrams. Weather and Forecasting ,22,
651 â€“ 661. URL: https://journals.ametsoc.org/view/
journals/wefo/22/3/waf993_1.xml .
â€” (2007b) Scoring probabilistic forecasts: The importance of
being proper. Weather and Forecasting ,22, 382 â€“ 388.
URL: https://journals.ametsoc.org/view/journals/
wefo/22/2/waf966_1.xml .
Burke,A.,Snook,N.,II,D.J.G.,McCorkle,S.andMcGovern,A.
(2020)Calibrationofmachinelearningâ€“basedprobabilistic
hailpredictionsforoperationalforecasting. WeatherandFore-
casting,35, 149â€“ 168. URL: https://journals.ametsoc.
org/view/journals/wefo/35/1/waf-d-19-0105.1.xml .VAHIDYOUSEFNIA ET AL . 17
Diffenbaugh,N.S.,Scherer,M.andTrapp,R.J.(2013)Robust
increases in severe thunderstorm environments in response to
greenhouse forcing. Proceedings of the National Academy
of Sciences ,110, 16361â€“16366. URL: https://www.pnas.
org/doi/abs/10.1073/pnas.1307758110 .
Dixon, M. and Wiener, G. (1993) Titan: Thunderstorm
identification, tracking, analysis, and nowcastingâ€”a
radar-based methodology. Journal of Atmospheric and
Oceanic Technology ,10, 785 â€“ 797. URL: https:
//journals.ametsoc.org/view/journals/atot/10/6/
1520-0426_1993_010_0785_ttitaa_2_0_co_2.xml .
Gagne, D. J., McGovern, A., Haupt, S. E., Sobash, R. A.,
Williams, J. K. and Xue, M. (2017) Storm-based proba-
bilistic hail forecasting with machine learning applied to
convection-allowing ensembles. Weather and Forecasting ,
32,1819â€“1840. URL: https://journals.ametsoc.org/
view/journals/wefo/32/5/waf-d-17-0010_1.xml .
Geng, Y.-a., Li, Q., Lin, T., Yao, W., Xu, L., Zheng, D., Zhou,
X., Zheng, L., Lyu, W. and Zhang, Y. (2021) A deep learn-
ing framework for lightning forecasting with multi-source
spatiotemporaldata. QuarterlyJournaloftheRoyalMeteo-
rological Society ,147, 4048â€“4062. URL: https://rmets.
onlinelibrary.wiley.com/doi/abs/10.1002/qj.4167 .
Gerz,T.,Forster,C.andTafferner,A.(2012) MitigatingtheImpact
ofAdverseWeatheronAviation ,645â€“659. Berlin,Heidelberg:
Springer Berlin Heidelberg. URL: https://doi.org/10.
1007/978-3-642-30183-4_39 .
Herman, G. R. and Schumacher, R. S. (2018) Money doesnâ€™t
grow on trees, but forecasts do: Forecasting extreme pre-
cipitation with random forests. Monthly Weather Review ,
146,1571â€“1600. URL: https://journals.ametsoc.org/
view/journals/mwre/146/5/mwr-d-17-0250.1.xml .
Holle, R. L. (2014) Some aspects of global lightning impacts.
In2014 International Conference on Lightning Protection
(ICLP), 1390â€“1395.
â€” (2016) A summary of recent national-scale lightning fatal-
ity studies. Weather, Climate, and Society ,8, 35 â€“ 42.
URL: https://journals.ametsoc.org/view/journals/
wcas/8/1/wcas-d-15-0032_1.xml .
Hwang, Y., Clark, A. J., Lakshmanan, V. and Koch, S. E.
(2015) Improved nowcasts by blending extrapolation and
modelforecasts. WeatherandForecasting ,30,1201â€“1217.
URL: https://journals.ametsoc.org/view/journals/
wefo/30/5/waf-d-15-0057_1.xml .
Jardines, A., Soler, M., Cervantes, A., GarcÃ­a-Heras, J. and
Simarro, J. (2021) Convection indicator for pre-tacticalair traffic flow management using neural networks. Ma-
chine Learning with Applications ,5, 100053. URL:
https://www.sciencedirect.com/science/article/
pii/S2666827021000256 .
Kamangir, H., Collins, W., Tissot, P. and King, S. A. (2020)
Adeep-learningmodeltopredictthunderstormswithin400
km2southtexasdomains. MeteorologicalApplications ,27,
e1905. URL: https://rmets.onlinelibrary.wiley.com/
doi/abs/10.1002/met.1905 .
Kingma,D. P.andBa, J.(2014)Adam: A methodforstochastic
optimization. URL: https://arxiv.org/abs/1412.6980 .
Kober,K.,Craig,G.C.,Keil,C.andDÃ¶rnbrack,A.(2012)Blend-
ing a probabilistic nowcasting method with a high-resolution
numerical weather prediction ensemble for convective pre-
cipitation forecasts. Quarterly Journal of the Royal Mete-
orological Society ,138, 755â€“768. URL: https://rmets.
onlinelibrary.wiley.com/doi/abs/10.1002/qj.939 .
Leinonen, J., Hamann, U., Germann, U. and Mecikalski, J. R.
(2022)Nowcastingthunderstormhazardsusingmachinelearn-
ing: theimpactofdatasourcesonperformance. NaturalHaz-
ards and Earth System Sciences ,22, 577â€“597. URL: https:
//nhess.copernicus.org/articles/22/577/2022/ .
Li, J., Forster, C., Wagner, J. and Gerz, T. (2021) Cb-fusionâ€“
forecastingthunderstormcellsupto6hours. Meteorologische
Zeitschrift , 169â€“184.
Lin, P.-F., Chang, P.-L., Jou, B. J.-D., Wilson, J. W. and Roberts,
R. D. (2012) Objective prediction of warm season after-
noon thunderstorms in northern taiwan using a fuzzy logic
approach. Weather and Forecasting ,27, 1178 â€“ 1197.
URL: https://journals.ametsoc.org/view/journals/
wefo/27/5/waf-d-11-00105_1.xml .
Loken, E. D., Clark, A. J. and Karstens, C. D. (2020)
Generating probabilistic next-day severe weather fore-
casts from convection-allowing ensembles using random
forests. Weather and Forecasting ,35, 1605 â€“ 1631.
URL: https://journals.ametsoc.org/view/journals/
wefo/35/4/wafD190258.xml .
Lorenz,E.N.(1969)Thepredictabilityofaflowwhichpossesses
many scales of motion. Tellus,21, 289â€“307. URL: https:
//doi.org/10.3402/tellusa.v21i3.10086 .
Mueller, C., Saxen, T., Roberts, R., Wilson, J., Betancourt, T.,
Dettling,S.,Oien,N.andYee,J.(2003)Ncarauto-nowcast
system. Weather and Forecasting ,18, 545 â€“ 561. URL:
https://journals.ametsoc.org/view/journals/wefo/
18/4/1520-0434_2003_018_0545_nas_2_0_co_2.xml .18 VAHIDYOUSEFNIA ET AL .
Murphy, A. H. (1973) A new vector partition of the
probability score. Journal of Applied Meteorol-
ogy and Climatology ,12, 595 â€“ 600. URL: https:
//journals.ametsoc.org/view/journals/apme/12/4/
1520-0450_1973_012_0595_anvpot_2_0_co_2.xml .
Niculescu-Mizil,A.andCaruana,R.(2005)Predictinggoodprob-
abilities with supervised learning. In Proceedings of the
22ndInternational Conferenceon MachineLearning , ICML
â€™05, 625â€“632. New York, NY, USA: Association for Comput-
ingMachinery. URL: https://doi.org/10.1145/1102351.
1102430.
RÃ¤dler, A. T., Groenemeijer, P. H., Faust, E., Sausen, R. and
PÃºÄik, T. (2019) Frequency of severe thunderstorms across
europeexpectedtoincreaseinthe21stcenturyduetorising
instability. npj Climate and Atmospheric Science ,2, 30.
Reinert,D.,Prill,F.,Frank,H.,Denhard,M.,Baldauf,M.,Schraff,
C., Gebhardt, C., Marsigli, C. and ZÃ¤ngl, G. (2020) Dwd
databasereferencefortheglobalandregionaliconandicon-
eps forecasting system. Technical report Version 2.1. 8,
Deutscher Wetterdienst . URL: https://www.dwd.de/DWD/
forschung/nwv/fepub/icon_database_main.pdf .
Roberts,N.(2008)Assessingthespatialandtemporalvariationin
theskillofprecipitationforecastsfromannwpmodel. Meteo-
rological Applications ,15, 163â€“169. URL: https://rmets.
onlinelibrary.wiley.com/doi/abs/10.1002/met.57 .
Selz, T. and Craig, G. C. (2015) Upscale error growth in a
high-resolution simulation of a summertime weather event
over europe. Monthly Weather Review ,143, 813 â€“ 827.
URL: https://journals.ametsoc.org/view/journals/
mwre/143/3/mwr-d-14-00140.1.xml .
Sobash, R. A., Romine, G. S. and Schwartz, C. S. (2020) A com-
parison of neural-network and surrogate-severe probabilis-
tic convective hazard guidance derived from a convection-
allowingmodel. WeatherandForecasting ,35,1981â€“2000.
URL: https://journals.ametsoc.org/view/journals/
wefo/35/5/wafD200036.xml .
Sun, J., Xue, M., Wilson, J. W., Zawadzki, I., Ballard, S. P.,
Onvlee-Hooimeyer, J., Joe, P., Barker, D. M., Li, P.-W., Gold-
ing, B., Xu, M. and Pinto, J. (2014) Use of nwp for now-
casting convective precipitation: Recent progress and chal-
lenges.Bulletin ofthe AmericanMeteorological Society ,95,
409 â€“ 426. URL: https://journals.ametsoc.org/view/
journals/bams/95/3/bams-d-11-00263.1.xml .
Sun,Y.,Wong,A.K.andKamel,M.S.(2009)Classificationof
imbalanceddata: Areview. Internationaljournalofpattern
recognition and artificial intelligence ,23, 687â€“719.Toth,Z.,Talagrand,O.,Candille,G.andZhu,Y.(2003)Probabil-
ity and ensemble forecasts. Forecast verification: A practi-
tionerâ€™s guide in atmospheric science ,137, 163.
Turner, B. J., Zawadzki, I. and Germann, U. (2004) Predictability
of precipitation from continental radar images. part iii:
Operational nowcasting implementation (maple). Journal
of Applied Meteorology ,43, 231 â€“ 248. URL: https:
//journals.ametsoc.org/view/journals/apme/43/2/
1520-0450_2004_043_0231_popfcr_2.0.co_2.xml .
Ukkonen, P. and MÃ¤kelÃ¤, A. (2019) Evaluation of machine
learning classifiers for predicting deep convection. Jour-
nal of Advances in Modeling Earth Systems ,11, 1784â€“
1802. URL: https://agupubs.onlinelibrary.wiley.
com/doi/abs/10.1029/2018MS001561 .
Veraverbeke, S., Rogers, B. M., Goulden, M. L., Jandt, R. R.,
Miller, C. E., Wiggins, E. B. and Randerson, J. T. (2017)
Lightning as a major driver of recent large fire years in north
american boreal forests. Nature Climate Change ,7, 529â€“534.
Wilks, D. S. (2011) Statistical methods in the atmospheric sci-
ences. Internationalgeophysicsseries.Amsterdam;Heidel-
berg [u.a.]: Elsevier Acad. Press, 3. ed. edn.
Wilson, J. W., Crook, N. A., Mueller, C. K., Sun, J. and
Dixon, M. (1998) Nowcasting thunderstorms: A sta-
tus report. Bulletin of the American Meteorological
Society,79, 2079 â€“ 2100. URL: https://journals.
ametsoc.org/view/journals/bams/79/10/1520-
0477_1998_079_2079_ntasr_2_0_co_2.xml .
Yano,J.-I.,ZiemiaÅ„ski,M.Z.,Cullen,M.,Termonia,P.,Onvlee,J.,
Bengtsson, L., Carrassi, A., Davy, R., Deluca, A., Gray, S. L.,
Homar, V., KÃ¶hler, M., Krichak, S., Michaelides, S., Phillips,
V. T. J., Soares, P. M. M. and Wyszogrodzki, A. A. (2018)
Scientificchallengesofconvective-scalenumericalweather
prediction. Bulletin of the American Meteorological Soci-
ety,99,699â€“710. URL: https://journals.ametsoc.org/
view/journals/bams/99/4/bams-d-17-0125.1.xml .
Yasuda, Y., Yokoyama, S., Minowa, M. and Satoh, T. (2012)
Classification of lightning damage to wind turbine blades.
IEEJ Transactions on Electrical and Electronic Engineering ,
7, 559â€“566. URL: https://onlinelibrary.wiley.com/
doi/abs/10.1002/tee.21773 .
Zhou, K., Sun, J., Zheng, Y.andZhang, Y.(2022)Quantitative
precipitationforecastexperimentbasedonbasicnwpvariables
usingdeeplearning. AdvancesinAtmosphericSciences ,39,
1472â€“1486.
ZÃ¤ngl,G.,Reinert,D.,RÃ­podas,P.andBaldauf,M.(2015)The
icon(icosahedralnon-hydrostatic)modellingframeworkofVAHIDYOUSEFNIA ET AL . 19
dwdandmpi-m: Descriptionofthenon-hydrostaticdynami-
calcore.QuarterlyJournaloftheRoyalMeteorologicalSoci-
ety,141, 563â€“579. URL: https://rmets.onlinelibrary.
wiley.com/doi/abs/10.1002/qj.2378 .