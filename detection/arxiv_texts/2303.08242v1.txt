Submitted to the Annals of Applied Statistics
OPTIMAL SAMPLING DESIGNS FOR MULTI-DIMENSIONAL STREAMING
TIME SERIES WITH APPLICATION TO POWER GRID SENSOR DATA
BYRUIXIE1, SHUYANG BAI2,*AND PINGMA2,†
1Department of Statistics and Data Science, University of Central Florida, Orlando, FL 32826 USA, rui.xie@ucf.edu
2Department of Statistics, University of Georgia, Athens, GA 30602 USA,*bsy9142@uga.edu;†pingma@uga.edu
The Internet of Things (IoT) system generates massive high-speed tem-
porally correlated streaming data and is often connected with online inference
tasks under computational or energy constraints. Online analysis of these
streaming time series data often faces a trade-off between statistical efﬁciency
and computational cost. One important approach to balance this trade-off is
sampling, where only a small portion of the sample is selected for the model
ﬁtting and update. Motivated by the demands of dynamic relationship analy-
sis of IoT system, we study the data-dependent sample selection and online
inference problem for a multi-dimensional streaming time series, aiming to
provide low-cost real-time analysis of high-speed power grid electricity con-
sumption data. Inspired by D-optimality criterion in design of experiments,
we propose a class of online data reduction methods that achieve an opti-
mal sampling criterion and improve the computational efﬁciency of the on-
line analysis. We show that the optimal solution amounts to a strategy that
is a mixture of Bernoulli sampling and leverage score sampling. The lever-
age score sampling involves auxiliary estimations that have a computational
advantage over recursive least squares updates. Theoretical properties of the
auxiliary estimations involved are also discussed. When applied to European
power grid consumption data, the proposed leverage score based sampling
methods outperform the benchmark sampling method in online estimation
and prediction. The general applicability of the sampling-assisted online es-
timation method is assessed via simulation studies.
1. Introduction. In the era of Internet of things (IoT), the prevalence of sensor networks,
wearable devices, and power grid networks has led to an enormous amount of data streams
being automatically collected every second, or even every millisecond. Examples range from
security monitoring in power grids (Li et al., 2019) to trafﬁc monitoring in smart trafﬁc sys-
tem (Nellore and Hancke, 2016), from health surveillance through smart wearable devices
(Islam et al., 2015) to soil condition sensors in precision agriculture (Mat et al., 2016). These
IoT data streams carry rich and time-sensitive information on the targeted subjects or sys-
tems, offering an unprecedented potential for real-time monitoring, forecasting and control.
This potential, however, has not yet been sufﬁciently exploited, because the computing infras-
tructure still lags far behind the exponential growth of data sources. For instance, a network
layer of IoT system deployed in a smart power grid usually consists of a large number of
low bandwidth, low energy, low processing power nodes for communication using WiFi, 3G,
4G or power line communication technologies, rendering sophisticated real-time analytics
infeasible (Jaradat et al., 2015). The IoT sensor data streams can arrive at a very high speed,
which will accumulate a large quantity of data to be analyzed in a short period of time. For
real-time tasks in IoT applications, such as prediction or dynamic information ﬂow tracking,
the inference speed may lag behind the data arriving speed, especially for complex inference
tasks. To conquer the data overﬂow challenge in large-scale IoT applications, we aim to pro-
vide a sampling solution with reliable inference performance and low computation costs. We
Keywords and phrases: Streaming data, Sampling design, Multi-dimensional time series, D-optimality.
1arXiv:2303.08242v1  [stat.ML]  14 Mar 20232
use publicly available power grid electricity consumption data as a motivating example to
illustrate challenges and potential solutions.
EXAMPLE .Open Power System Data: Time series of electricity consumption
Electricity consumption, measured by electricity loads over time in a power grid system, is
a typical type of streaming data that arrives at a high speed. In the smart IoT application, elec-
tricity consumption recorded from smart meters are capable of observing data at very high
frequency, such as 25 kHz sampling frequency for the sinusoidal voltage signal (Jumar et al.,
2020). In a power system, real-time feedback of electricity loads, which includes prediction
and model ﬁtting, is important in optimizing energy consumption patterns (Marangoni and
Tavoni, 2021). The real-time inference helps effectively lower energy consumption by re-
ducing energy demand and leveling off the usage peaks. The accurate real-time prediction
will also beneﬁt effective scheduling and decision-making in the power system (Xu et al.,
2021). Therefore, online analysis of the electricity load time series plays an important role in
practice.
In 2020, the electricity consumption data in the United States has projected to use a total
of1;000million terabytes (TB) of storage (Siddik et al., 2021; Shehabi et al., 2016). There
are emerging needs for novel approaches to analyzing such massive data, especially the real-
time analysis of massive data streams. In our study, we shall work with the data streams from
publicly available power system data platform (Open Power System Data, 2020), given the
fact that energy data is often subject to restrictive terms of use. The Open Power System Data
(2020) consists of time series of electricity consumption (load) for 37European countries
with hourly resolution. The selected time series are recorded from 2006-01-01, 00:00:00
Coordinated Universal Time (UTC) to 2018-12-14, 23:00:00 UTC, which results in 113;544
time points. Electricity power consumption data from different countries are reported through
different platforms in the Open Power System Data. We use the actual load of ENTSO-E
power statistics from 19countries as the variables of interest. Figure 1 displays the dynamic
Fig 1: Load curves from 2006 to 2018 for 19European countries.
evolution of the load curves from 2006 to 2018 for those 19countries.OPTIMAL SAMPLING DESIGNS 3
The online analysis of the IoT systems usually starts from sampling (Zhou and Saad, 2019)
or ﬁltering (Akbar et al., 2017) algorithms to optimize the data collection process from the
IoT sensors, which results in massive volumes of regularly spaced multidimensional time
series data streams, the latter being a well-developed statistical subject (Hamilton, 1994;
Lütkepohl, 2005). Analyzing those large-scale high-frequency data streams posts challenges
in real-time inference of multidimensional time series model, where the computational cost
is in the order of K3n3withnsamples ofK-dimensional data. Real-time calculations, in-
cluding inference and prediction, are usually critical for decision making and resource opti-
mization in IoT applications.
Methodologically speaking, online analysis of classical multidimensional time series is of-
ten carried out under the framework of dynamic linear model or state space model (West and
Harrison, 1997; Petris et al., 2009). With dynamic linear models, online statistical computa-
tions including estimation and forecasting can often be aided by the efﬁcient Kalman ﬁlter
recursive algorithms (Kalman, 1960; Kalman and Bucy, 1961). However, for applications in
many IoT systems, the stringent computational resource often cannot afford to perform typi-
cal dynamic linear model computations such as likelihood optimization or Bayesian sampling
fast enough to achieve real-time analysis. In fact, even restricting to linear systems, for which
much less costly online estimation algorithms (e.g., recursive least squares) can be applied,
a real-time inference utilizing the whole data stream can still be challenging (Gabel et al.,
2015; Berberidis et al., 2016; Hooi et al., 2018).
For smart power gird analysis, due to the limited accessibility of the data, various sampling
techniques, including simple random sampling and Latin hypercube sampling (Cai et al.,
2013), are used to generate synthetic data points for Monte-Carlo simulation or static power
system model training (Balduin et al., 2022). The leverage score based sampling technique
was used for monitoring cyberattacks in IoT system but not for the online inference (Li et al.,
2019). To the best of our knowledge, the literature on sampling or data reduction method for
online analysis of large-scale dynamic power grid systems is still lacking. Such a situation
calls for the development of new approaches.
Broadly speaking, the problem described above belongs to a contemporary research di-
rection that considers the trade-off between statistical efﬁciency and computational cost (Jor-
dan, 2013). One natural and important approach to balance this trade-off is sampling . In this
approach, a small portion of the full observed data is chosen as a surrogate to carry out com-
putations of interest. Sampling, or more generally data reduction , has been considered in
various studies as a means to reduce computational cost. The majority of these studies aim to
achieve certain numerical approximation accuracy, which has sparked the popularity of no-
tions such as sketching (e.g., Drineas et al. (2012); Liberty (2013); Woodruff (2014); Zhang
et al. (2017)) and coreset (e.g., Agarwal et al. (2005); Dasgupta et al. (2009); Feldman et al.
(2013)).
Recently in the context of big data, some statistical investigations of sampling methods
with an emphasis on statistical estimation efﬁciency have emerged (Ma et al., 2015; Wang
et al., 2018, 2019; Ting and Brochu, 2018; Yu et al., 2020; Meng et al., 2020; Ma et al., 2020;
Wang et al., 2021). The aforementioned investigations are all carried out under the setup of
independent samples and ofﬂine computation where the whole data set is available from the
beginning. For online analysis of streaming time series exhibiting temporal dependence, rel-
evant statistical research is still largely lacking. Exceptions are the work Xie et al. (2019)
that considered online estimation of a Gaussian vector autoregression (V AR) model assisted
by the so-called leverage score sampling (LSS), and the work Eshragh et al. (2022) that ap-
plied leverage score-based sampling for the analysis of large-scale univariate time series data.
Leverage score sampling proposed in Xie et al. (2019) selects samples based on threshold-
ing a leverage score of the lagged covariate in vector autoregression. However, a number of4
questions regarding this sampling method were left unaddressed. Xie et al. (2019) showed
that LSS achieves an asymptotic efﬁciency superior to a naive Bernoulli sampler. However,
its optimality over other possible sampling methods was not clariﬁed. Furthermore, the sam-
ple selection rule of LSS focuses exclusively on high-leverage covariate points, which in
practice might lead to a lack of good ﬁt over low-leverage region and sensitivity to outliers.
In addition in Xie et al. (2019), the auxiliary estimations involved in implementing LSS were
not justiﬁed.
The overall objective of this paper is to develop methodologies for performing online anal-
ysis on high-speed multidimensional time series, where we apply them to provide a real-time
solution for massive power grid sensor data inference in IoT applications. On the methodol-
ogy side, we propose a computationally efﬁcient online sampling method called relaxed-LSS,
which can be applied to linear multivariate time series models including extraneous variables
and enjoys more robustness compared with LSS. The relaxed-LSS and the time series model
are used for online inference and prediction of the IoT power consumption data. On the
theory side, we establish the D-optimality of asymptotic estimation efﬁciency of LSS and
more generally relaxed-LSS in a broad class of online sampling methods. We also establish
consistency properties incorporating some auxiliary estimations in the sampling methods.
We organize the article as follows. In Section 2, we consider a framework that covers a
large class of models subsuming the Gaussian Vector Autoregression considered in Xie et al.
(2019). In Section 3, we formulate a class of online sampling methods within the framework
of Section 2 and show that LSS is the optimal choice among them for asymptotic estimation
efﬁciency. We then proceed to propose a novel relaxed version of LSS which keeps a pro-
portion of low-leverage covariate points. Section 4 addresses the auxiliary estimations and
practical implementation involved in the sampling algorithm, including an online estimate
of an inverse covariance matrix which is performed sparsely for computational advantage.
Section 5 considers an application to the electricity consumption time series in Open Power
System Data. Section 6 includes the simulation studies of LSS and its relaxed version. The
conclusion and future work are presented in Section 7. The proofs of the theoretical results
are collected in Supplementary Material.
2. Model Assumptions. By default, all vectors are column vectors. Throughout this pa-
per,kk denotes the matrix operator norm with respect to the Euclidean norm (so it is the
Euclidean norm for vectors).
Suppose (yt)is theK-dimensional time series of interest. For notional convenience, we
allowtto vary within the whole integer set Z, whereas the starting point of twill become
clear in a context. We shall model (yt)as aRK-valued ergodic (strictly) stationary pro-
cess with ﬁnite variance. Suppose, in addition, that we have a Rp-valued ergodic stationary
process (xt)with ﬁnite variance serving as explanatory variables for (yt). We impose the
following stationarity assumption, which will help simplify the formulation of the basic re-
sults. LetX=E[xt];Y=E[yt], we shall assume the following linear system model for
the centered time series,
(1) yt Y=B0(xt X) +et;
whereBis apKcoefﬁcient matrix and B0stands for its transpose, (et)is aRK-valued
ergodic stationary noise process satisfying the martingale difference property,
(2) E[etjFt] =0;
where the ﬁltration Ft=(xs;es 1; st), and the conditional expectation in (2) is taken
component-wise. We also assume a constant conditional covariance matrix for the error pro-
cess:
(3) E[et1e0
t2jFt] = 
1ft1=t2g; t 1;t22Z; t1;t2>tOPTIMAL SAMPLING DESIGNS 5
for some non-singular covariance matrix 
. Assume, in addition, that (xt;et)is jointly sta-
tionary. In literature (e.g., Box et al. (2015, Chapter 14)), the model (1) is often replaced by
one with the means absorbed into an intercept term in xt. Our formulation here singles out
the estimation of the means which is computationally trivial, and facilitates the development
of the optimality results.
It is worth pointing out that the components of the explanatory variable process (xt)are
allowed to contain lagged values of (yt). For instance, we may set
(4) xt= (y0
t 1;;y0
t p1;v0
t 1;;v0
t p2)02RK(p1+p2);
where (vt)is a stationary process extraneous to (yt), where eachvt2RK. The model (1)
with the speciﬁcation (4) is often known as a V ARX model (e.g., Lütkepohl (2005, Chapter
10)), which becomes the well-known vector autoregression model if the extraneous variables
are absent. The V ARX model is more commonly expressed as
(5) yt=p1X
i=1iyt i+p2X
j=1	jvt j+et
for someKKcoefﬁcient matrices i’s and 	i’s, where i’s must satisfy appropriate
constraints to allow the existence of stationary solution of (5) (e.g., Hamilton (1994, Section
10.1)).
The linear system model (1) and its variants have been applied in various IoT contexts
for real-time analysis of streaming time series: anomaly detection in streaming environmen-
tal sensor data (Hill and Minsker, 2010); tracking causal interactions between brain regions
based on MEG sensor streams (Michalareas et al., 2013); design of energy-efﬁcient operation
of low-power wireless medical sensors (Anagnostopoulos et al., 2014); trafﬁc forecasting in
large urban areas based on road network sensors (Schimbinschi et al., 2017).
For the development of optimal online sampling theory in Section 3, we shall impose an
additional assumption on the distributional shape of the covariate xt. Recall ap-dimensional
elliptical (contoured) distribution ECp(;;)(cf. Fang et al. (1990)) is speciﬁed by the
following three components: a vector 2Rpcalled location , appnon-negative deﬁnite
matrix called scatter , which coincides with the covariance matrix when the latter exists,
and a probability distribution onR+. In particular, ECp(;;)denotes the distribution
of random vector +1=2S, where 1=2is a symmetric square root of , the random
variablefollows the distribution and is called the generating variate , andSis the uniform
distribution on the p-dimensional unit sphere fx2Rp:kxk= 1gwhich is independent of
. A multivariate normal distribution is included in this family as a special case. For the rest
of the paper, we shall assume that for each ﬁxed t2Z, the covariate vector
(6) xtECp(X;;);
where the distribution is absolutely continuous and the scatter is also the positive deﬁnite
covariance matrix of xt. Hence the distribution of xtis absolutely continuous.
3. Optimal Online Sampling. To develop the main ideas, throughout this section we
shall also assume for simplicity that
(7) X=Y=0:
In practice, online estimation of these means can be achieved efﬁciently with a negligible
computational cost compared to that of estimating B. See also Section 4 below for more
details.6
3.1. A Class of Online Samplers. When a sample stream (yt;xt)n
t=1from the whole
stream (yt;xt)1
t=1satisfying (1) is observed and nKp, the least square estimator
bBn;LS= arg min
BnX
t=1jjyt B0xtjj2
may be used to estimate B. In the context of online estimation, the computation of bBn;LS can
be implemented in a recursive manner based on the Sherman–Morrison inversion formula
(Sherman and Morrison, 1950), an algorithm often known as the recursive least squares
(Plackett, 1950). However, when data stream arrives at an overwhelmingly fast rate with high
dimension (Kpis large), real-time update of bBn;LS can still be challenging given a limited
computational capacity in the context of streaming data (see Section 1).
The basic idea we shall propose is simple: instead of updating the estimation along the
whole stream of data (yt;xt)1
t=1, we shall skip some time points tand only update the esti-
mate along a subset IZ+. The problem becomes: how should Ibe selected, or how do we
select samples among (yt;xt)1
t=1?
It is useful to note that our problem bears similarity to the study of optimal designs (e.g.,
Pukelsheim (1993); Papalambros and Wilde (2000)). Generally speaking, an optimal design
aims at achieving an optimal estimation precision with a ﬁxed sample size (number of ex-
perimental runs). In optimal design for linear regression with response yand design matrix
X, i.e,y=X+, where random error has mean zero and constant variance 2I, one
often considers optimizing the matrix (X0X) 1(recall var[b] =2(X0X) 1, wherebis the
least square estimator) based on a certain criterion, e.g., the determinant (D-optimality). The
optimization is typically over a ﬁnite available set of candidate covariate points (treatment
runs) with the rows of X(number of runs) ﬁxed. In other words, given a limited sample size,
one needs to select appropriate covariate points among available ones to optimize (X0X) 1.
Motivated by this insight drawn from optimal design, we propose to base our online sample
selection criterion on the covariate xtas well. We consider the following class of samplers:
at each time point t, the selection of sample unit (yt;xt)is determined solely by xt2Rpup
to a randomization. This is made precise as follows.
DEFINITION 3.1. Suppose there is a measurable function s:Rp![0;1], called the sam-
pling function. A sampling method (or sampler) S(s)is deﬁned as follows: conditioning on
(yt;xt)1
t=1, for eacht2Z+, the sample (yt;xt)is selected independently with probability
s(xt).
The samplerS(s)can be alternatively described as follows: let (Ut)1
t=1be i.i.d.
Uniform (0;1)random variables which are independent of (yt;xt)1
t=1. The selected index
setIis given by
I=ft2Z+:Uts(xt)g:
The (unconditional) sampling rate of S(s)is given by
(8) q:=pr(Uts(xt)) =E[s(xt)]2[0;1]:
When a stream of total length npasses through, the size of selected sample is given by a
random number
N:=nX
t=11fUts(xt)g=jIj:
By the ergodic theorem (Kallenberg, 2002, Theorem 10.6), we have
(9)N
n!qOPTIMAL SAMPLING DESIGNS 7
a.s. asn!1 .
As an example, a constant sampling function s(x)qcorresponds to the Bernoulli sam-
pler, that is, each index tis independently selected with probability qregardless ofxt.
For an ideal stationary system, one may argue that there is no need to employ the sampling-
assisted approach for online estimation. Indeed, if the regression coefﬁcients in Bin (1) stays
invariant along the whole data stream, then the older data provides exactly the same informa-
tion as the newer data about B. Hence one may use the available computational capacity to
update the estimate up to the best speed even if it cannot catch up with the newest received
data. However, in the practice of real-time analysis of streaming time series, this approach
should be avoided since it fails to reﬂect the latest information about the streams. In fact,
the usefulness of sampling-assisted online estimation is necessarily tied to non-stationarity ,
be it for the detection of departure from stationarity, or for the predictive modeling of non-
stationary time series. For example, for predictive modeling, one may propose a time-varying
version of (1) and estimate time-varying Bby weighted least squares (e.g., Zhou and Wu
(2010); Zhang and Wu (2012)). Since such a system can be locally viewed as stationary, the
foundation laid in this paper will still be highly relevant in that context.
3.2. D-Optimality of Leverage Score Sampler. The next step is to formulate optimality
among the classfS(s)g. Note that unlike a conventional setup in optimal design, for online
estimation the number of rows of the design matrix Xkeeps increasing. So we propose to
formulate the optimization, in a sense, on an asymptotic version of (XTX) 1. LetbBn;Ibe
the least squares estimator of Busing only (yt;xt)t2I, namely,
(10)
bBn;I= X
t2Ixtx0
t! 1 X
t2Ixty0
t!
= nX
t=11fUts(xt)gxtx0
t! 1 nX
t=11fUts(xt)gxty0
t!
:
We have the following asymptotic normality result.
THEOREM 3.2. Under the assumptions in Section 2, suppose in addition that
(11)  (s) =E
s(xt)xtx0
t
is invertible. Then as the total stream size n!1 ,
(12)p
N(vec(bBn;I) vec(B))pnq(vec(bBn;I) vec(B))d!N (0;P(s) 1);
where vec(B)denotes the vectorization of matrix Bby stacking the columns (from left to
right) ofBinto a single column, and the asymptotic precision matrix is
(13) P(s) = 
 1
(q 1 (s));
where
denotes the Kronecker product and 
is the covariance matrix deﬁned in (3).
An extension of Theorem 3.2 incorporating auxiliary estimates for the means and the sam-
pling function is stated in Theorem 4.1 below.
It is now natural to consider the optimization of the precision (information) matrix P(s)
under the constraint that the sampling rate q=E[s(xt)]is ﬁxed at a value in the interval
(0;1). In general, one cannot expect to optimize P(s)with respect to the Loewner order,
namely, there is no P(s)which is optimal in every direction (e.g., Pukelsheim (1993, Chapter
4)). Instead, one may consider the optimization of a suitable scalar function of P(s), and most
popularly, the determinant, which leads to the so-called D-optimality (e.g., Pukelsheim (1993,
Chapter 9)). By a property of Kronecker product, det(P(s))is proportional to det( (s))K,
and hence we need to maximize det( (s)).8
THEOREM 3.3 (D-optimality). If the distribution of xtis elliptical as speciﬁed by (6),
then the following constrained optimization problem:
(14) arg max
sdet(P(s)) = arg max
sdet( (s))subject toE[s(xt)] =q2(0;1];
where the maximization is over all measurable s:Rp![0;1], has solution
(15) s(x) = 1fx0 1x>rg;
wherer>0is chosen so that
(16) pr(x0
t 1xt>r) =q:
This solution is almost everywhere unique with respect to the distribution of xt.
Theorem 3.3 is a special case of Theorem 3.4 below, which is provided in Section 3.3. We
note that the optimality problem in Theorem 3.3 can be regarded as a special case of the gen-
eral optimality problem formulated in Pronzato (2006); Pronzato and Wang (2020). Instead
of obtaining an explicit solution as in (15), the aforementioned studies focused on stochas-
tic approximation algorithms and were in general constrained to the setup of i.i.d. trials.
The explicit solution in Theorem 3.3, although obtained under a more restrictive framework
compared to Pronzato (2006); Pronzato and Wang (2020), enables one to formulate explicit
and efﬁcient online sampling algorithms which can be applied in the streaming time series
context.
The tail quantile rin (16) may not be unique if pr(x0
t 1xt>r)is not strictly decreasing
with respect to r(until reaching zero). One may eliminate this non-uniqueness by assuming
that the density of in (6) is positive.
Besides D-optimality, one may consider some other optimality criteria, e.g., A-optimality
which minimizes tr(P(s) 1), E-optimality which maximizes the minimum eigenvalue of
P(s), T-optimality which maximizes tr(P(s)), etc (e.g., Pukelsheim (1993, Chapter 9)).
Different criteria may lead to different optimal solutions of the sampling function s. We
have chosen D-optimality since the solution has intuitively appealing interpretation as well
as computational advantage.
Theorem 3.3 leads to the following simple deterministic sampling rule: (yt;xt)is selected
ifx0
t 1xtexceeds the threshold r. Such a sampling rule was proposed in Xie et al. (2019)
for the special case of Gaussian vector autoregression model, and was termed leverage score
sampling (LSS) since
`t=x0
t 1xt;
can be interpreted as a leverage score of thextwhich marks the inﬂuence of this covariate
point (cf. Seber and Lee (2012, Section 10.2)). In Xie et al. (2019) the superiority of LSS over
a Bernoulli sampler was established under the same sampling rate qin terms of the Loewner
order. Theorem 3.3 above takes a further step to show that under the D-optimality criterion,
LSS is the best choice among the S(s)class in Deﬁnition 3.1 which includes the Bernoulli
sampler.
To implement LSS in practice, one needs auxiliary estimations of the means of ytandxt
(recall that we have assumed centering (7)), the calculation of leverage score `tas well as the
q-quantile of `t. These issues will be discussed in a more general context in Section 4 below.OPTIMAL SAMPLING DESIGNS 9
3.3. Relaxed Leverage Score Sampling (Relaxed-LSS). The hard thresholding found in
(15) employed in LSS selects exclusively high-leverage xtpoints. There are two potential
risks of removing low-leverage design points in a linear regression: (a) if the linear regression
relationship between the response and the covariates fails to hold in the low-leverage design
region, then one would not be able to detect this departure; (b) relying on high-leverage points
may make the regression particularly susceptible to the inﬂuence of outliers. Recall that the
inﬂuence of an outlier is a combined effect of the magnitude of the regression residual and
the leverage of the design point, as measured by Cook’s distance (Cook, 1977) for instance.
These potential problems suggest us to relax LSS by including a reasonable fraction of
low-leverage points. This motivates the following optimization modiﬁed from that in Theo-
rem 3.3:
(17) arg max
sdet( (s))subject toE[s(xt)] =q2(0;1]; s(x)q0;
wheresis the sampling function in Deﬁnition 3.1, and q02[0;q]. In other words, we include
the additional constraint that there is a base sampling rate q0regardless of the design point
xt.
THEOREM 3.4. Under the same conditions as Theorem 3.3, the optimization problem
(17) has solution
(18) s(x) =q0+ (1 q0)1fx0 1x>rg;
whereris chosen so that
(19) pr(x0
t 1xt>r) =q q0
1 q0:
This solution is almost everywhere unique with respect to the distribution of xt.
Theorem 3.4 includes Theorem 3.3 as a special case when q0= 0. This solution has the
following interpretation: at each time point t, with a small probability q0, the sample unit
(yt;xt)will be selected regardless of the leverage score `tofxt; with a large probability
1 q0, the hard thresholding of `tis applied to select sample. Such a strategy is also called
rejection control in Monte Carlo computing (Liu, 2004). With a fractional of small-leverage
points included, one may perform model diagnostics, e.g., using regression residuals, to as-
sess the goodness of ﬁt (Lütkepohl, 2005, Chapter 13) over low-leverage design region.
4. Auxiliary Estimates, Algorithm and Practical Implementation.
4.1. Practical Implementation and Computational Complexity. The Algorithm 1 sum-
marizes the relaxed-LSS-assisted online estimation procedure involving some of the ingredi-
ents discussed below.
Incremental estimation of means
In practice, the means Y=E[yt]andX=E[xt]are often not zero and unknown. Since
the computational cost of updating the means XandYis minimal and having them es-
timated accurately is important for ensuring the consistency of bBn;I, we propose to update
them frequently, even at every step. We suggest starting the LSS-assisted online estimation
using initialized means based on a pilot stream sample, and then have them updated incre-
mentally.
Real-time calculation of leverage score10
An effective real-time calculation of leverage score requires less computational effort than
updating the least square. In practice, the inverse covariance matrix  1is unknown. To
gain the computational advantage, a real-time calculation of leverage score approach is used
by incorporating a crude estimate of precision matrix. A crude estimate of  1will affect
only the efﬁciency of the leverage score sampling but not the consistency of bBn;I. We hence
propose to use pilot estimation P0:=b 1
n0based on pilot data of size n0as a crude estimation
of leverage score, i.e.
(20) `tx0
tP0xt;
so that we can update the leverage score with one vector-matrix multiplication, which has
costO(p2)per time point; or, alternatively, we update P0sparsely in time, which has total
costO(cp2)withcn, givennas the total length of the observed stream size.
Computational Complexity
The running time for the LSS-assisted online estimation depends on both the time to cal-
culate the leverage scores and the time to update the model estimation using sampled data.
For an observed stream of size n, calculating leverage scores requires total O(cp2)time,
and updating least squares estimation for sampled data requires O 
(qn)p2
time with sam-
pling rateq1. So the total computational complexity of Algorithm 1 is O 
(qn+c)p2
,
where (qn+c)n. The computational complexity of LSS or relaxed-LSS sampling meth-
ods hence is lower than the recursive least squares methods, where the latter needs to up-
date the least squares estimates at every time point resulting in total O(np2)time. For the
Bernoulli sampler (i.e., sampling function s(x)q), the running time is trivial. To gain a
further computational advantage in practice, one may use an efﬁcient approximate compu-
tation of the leverage scores to perform relaxed-LSS algorithm (cf. Ma et al. (2015)). The
approximation error analysis of the leverage scores can be found in Drineas et al. (2012) and
Gittens and Mahoney (2013).
Determination of the threshold r
Another important practical issue is the determination of the threshold r. If eachxtis
Gaussian, it can be shown that the sampling rate
(21) pr(`t>r) =pr(2
p>r);
where2
pdenotes a Chi-square distribution with pdegrees of freedom. Hence for a pre-
determined sampling rate q2(0;1), one can choose rbased on (21). In reality, data often
exhibit heavier-tailed ﬂuctuation compared to Gaussian. So one may start the sampling using
a thresholdrdetermined by (21), and then replace it with the empirical quantile of `tob-
served thus far. It is also possible to perform a pre-estimation of the tail quantile rbased on
a pilot sample of x0
t 1xt(with  1also pre-estimated).
4.2. Auxiliary Estimates. Below we formulate a general asymptotic result extending
Theorem 3.2 which incorporates auxiliary estimates. Suppose the assumptions in Section
2 hold, but now we do not assume (7). We shall suppose that for some >2,
Ekxtk<1; t2Z+; (22)
as well as
sup
tt1=2[Ekbt;X Xk]1=<1;sup
tt1=2[Ekbt;Y Yk]1=<1: (23)
The latter two relations are moderate strengthening of the usual root- nconsistency. If bt;X
andbt;Yare sample means up to time tandEkxtk<1,Ekytk<1, then (23) holds if aOPTIMAL SAMPLING DESIGNS 11
strong mixing condition holds for (xt)and(yt)(Yokoyama, 1980), or if they are short-range
dependent linear processes (Surgailis et al., 2012, Proposition 4.4.3).
Next, we assume that there is a family of sampling functions s=sqindexed by the sam-
pling rateq, which satisﬁes
lim
q!0q1 2=max( (s))1=2
min( (s))= 0; (24)
whereq=E[s(xt)]is the sampling rate and max( (s))andmin( (s))stand for the largest
and the smallest eigenvalue of  (s)respectively. Condition (24), roughly speaking, ensures
that the magnitude of  (s)decays slower than a power of qasq!0. This will be veriﬁed
for the sampling function corresponding to the relaxed-LSS method in Lemma 4.2 below.
We suppose that bst2[0;1]is an estimate of the plugged-in sampling function s(xt X)
based on the data stream observed up to time tsuch that as t!1 (qﬁxed),
bst s(xt X)P!0: (25)
This consistency condition will also be veriﬁed in Lemma 4.2 below for the auxiliary esti-
mates involved in the relaxed-LSS method.
THEOREM 4.1. Suppose that the conditions (22),(23),(24) and(25) hold. Let the esti-
mator ofBbased on stream up to time nbe as
bBn;s= nX
t=1extex0
t1fUtbstg! 1 nX
t=1extey0
t1fUtbstg!
;
whereUt’s are as in Deﬁnition 3.1, and ext=xt bt;X;eyt=yt bt;Y:Then we have the
decomposition
(26)p
N(bBn;s B) =Mn+Rn;
where as the total stream size n!1 ,
(27) vec(Mn)d!N (0;P(s) 1)
asn!1 withP(s)as in (13) but with  (s)in(11) redeﬁned as
(28)  (s) =E
s(xt X)(xt X)(xt X)0
;
which we assume to be non-singular. The term Rnsatisﬁes for any >0,
(29) lim
q!0lim sup
npr(kP(s)1=2vec(Rn)k>) = 0:
The double limit in (29) says that when the sampling rate is small, as typically desired in
practice, the term Rnis negligible compared to Mn. Note that the same double limit with Rn
replaced by Mnwill not be zero due to (27).
The following lemma shows that the conditions (24) and (25) are satisﬁed in the context
of relaxed-LSS, and hence justify the procedure in Algorithm 1.
LEMMA 4.2.
(a)Supposes(x) =sq(x) =q0+(1 q0)1fx0 1x>rg(q0andrdepend onq) is the sampling
function of the relaxed-LSS as in Theorem 3.4, where q0=q0(q)satisﬁes that for some
constantc2(0;1)
(30) q0cq:12
Algorithm 1: Relaxed-LSS-Assisted Online Estimation of Stationary Linear System
Initialization :
Choose a sampling rate q2(0;1);
Choose a base sampling rate q0< q;
Initialize the estimates of X,Y, 1andBbased on a pilot sample;
Online Estimation :
while New sample (yt;xt)at time tarrives do
UpdateXandY;
Calculate `tbased on P0in (20);
ifBernoulli( q0) random number = 1 then
Update the estimates of Band
with new centered sample (yt Y;xt X);
else
if`t> rthen
Update the estimates of Band
with new centered sample (yt Y;xt X);
end
end
Update rbased on (35) (or use (21) when the sample size is small).
end
When2(2;4], assume in addition that for some constant c>0and2(;4=(4 ))
(right boundary understood as +1when= 4), we have
(x;1)>cx (31)
for all sufﬁcient large x, whereis as in (6). Then the condition (24) holds.
(b)Suppose thatb 1
nis a consistent estimate of  1based on the stream observed up to
timen, which can be realized by
(32) b 1
n= 
1
MnnX
t=1Jt(xt bt;X)(xt bt;X)0! 1
;
with a desirable small update rate u2(0;1), which corresponds to i.i.d. Bernoulli( u)
random variables (Jt)independent of everything else, where bt;Xandbt;Ybe estimators
ofX,Ybased on the stream observed up to time t, respectively.
Deﬁne the leverage score incorporating the auxiliary estimates as
e`t=ex0
tb 1
text: (33)
Letq0be the base sampling rate for relaxed-LSS in Section 3.3. Suppose that brnis a
consistent estimate of
(34)r(q;q0) := inf
r0 :pr((xt X)0 1(xt X)r)q q0
1 q0
based on the stream observed up to time n, which can be realized by
(35) brn= inf(
r0 :1
nnX
t=11fe`trgq q0
1 q0)
:
Let the estimated plugged-in sample function be
bst=q0+ (1 q0)1fe`t>brtg: (36)
Then the condition (25) holds.OPTIMAL SAMPLING DESIGNS 13
Examining the proof reveals that the condition (30) can be relaxed by allowing a power
ofq. We omit such a generalization here for simplicity. We also note that the assumption
(31) is not stringent. In particular, suppose the tail probability (x;1)is regularly varying
with index (see Bingham et al. (1989), which roughly speaking, says (x;1)behaves
likex ) asx!1 ,>2. This regular variation assumption includes common heavy-tailed
distributions such as Pareto distributions and t-distributions. Then in view of Potter’s bound
(Bingham et al., 1989, Theorem 1.5.6), one can ﬁnd andsatisfying 2<<<<
4=(4 )so that the conditions (22) and (31) both hold.
5. The Open Power System Data Application. In this section, we apply our LSS and
relaxed-LSS methods and benchmark Bernoulli method to the Open Power System Data
(2020) for real-time inference on the dynamics of power grid load proﬁles and one-step
ahead prediction. We compare the proposed LSS-based methods to the benchmark sampling
method and “full sample” estimation and demonstrate the strengths of real-time estimation
and prediction of the proposed methods.
5.1. Open Power System Data. Geographically, the Open Power System Data consist 37
European countries that cover European Union and neighboring countries. The data mea-
sures the total load (in Terawatt hour, TWh) for a country, control area or bidding zone. The
total load is a power statistic, which is deﬁned as, roughly speaking, the total power gener-
ated or imported minus the power being consumed at power plant, stored or exported. More
speciﬁcally, the data reported by ENTSO-E Transparency Platform are used due to its high
efﬁciency in data reporting, which results in a subset of 19 countries. The selected multivari-
ate time series streams are recorded from 2006-01-01, 00:00:00 Coordinated Universal Time
(UTC) to 2018-12-14, 23:00:00 UTC. There are total 113;544time points been observed in
the19-dimensional electricity load stream, which are complete without missing values.
0.91.01.11.2
1e+01 1e+03 1e+05
TimeEstimation errors
Method Bernoulli LSS Relaxed−LSS
Fig 2: Comparison of estimation errors for each of the time points of power load data.
5.2. Seasonal VARX modeling and accuracy measurements. Electricity loads exhibit
strong seasonality compared to loads one day (24 hours) earlier since it was aggregated14
Fig 3: Visualization of the estimated coefﬁcient matrices 1,2and1at timet= 113;424
using relaxed-LSS method.
to hourly temporal resolution. We consider the seasonal vector autoregression model with
centering:
(37) yt=p1X
i=1iyt i+p2X
i=1iyt 24i+et;
where we choose the model order as p1= 2,p2= 1incorporating the daily seasonality. The
weather, electricity prices, and clean energy generation and capacities can be added in to this
seasonal V ARX model as exogenous variables. However, due to the large portion and com-
plicated missing pattern in the database, we did not include them in the real-time analysis.
Our goals are to estimate the model parameters 0sand0sin real time, which represent
the dynamic dependence of the electricity loads, and the one-hour ahead forecasting (predic-
tion) of electricity loads, which is crucial for effective scheduling and energy management in
power grids.
We denote the ^Btas the real time estimation of model parameter matrix Bat time point t,
and^BFullis the ofﬂine model parameter estimation based on the entire dataset as a substitute
of the unknown population B. We use the relative errors to measure the parameter matrix
estimation accuracy jj^Bt ^BFulljjF=jj^BFulljjF.
At time point t, if the sample unit (yt;xt)is sampled, we will update the estimation ^Bt
using least squares; otherwise the estimation from previous time point will be retained as the
current estimation. The results are demonstrated in Figure 2, where the x-axis represents the
time of updates.
For the pointwise prediction accuracy, we compute the one-step (one-hour) ahead relative
prediction errors for each of the time points as: jj^yt+1 yt+1jj=jjyt+1jj. We visualized the
prediction errors in Figure 4, where x-axis represents hourly time.
5.3. Results. We compare our LSS and relaxed-LSS methods to the benchmark Bernoulli
sampling method for parameter matrix estimation accuracy and prediction accuracy. For all
three methods, we use the same pilot data of size 500to estimate the model order and initial
values for model parameter Band precision matrix P0. The sampling rate is q= 0:05for all
three methods, and the base sampling rate for relaxed-LSS is q0= 0:025. The update rate for
the inverse covariance matrix is 0:025. We handle the data in a streaming fashion and take
data samples and estimate the model in real time.
As an illustration, Figure 3 depicts the estimated coefﬁcient matrices 1,2and1at
timet= 113;424, which is the last update, using relaxed-LSS method. The cross-correlationsOPTIMAL SAMPLING DESIGNS 15
0246
0 30000 60000 90000
TimePrediction errors
Method Bernoulli LSS Relaxed−LSS
Fig 4: Comparison of one-step ahead prediction errors for each of the time point of power
load data.
at lag 1 (coefﬁcient matrix 1) between Italy and Portugal, Austria and France, as well as
Italy and Spain are higher than others, which reﬂect their positive interdependence in elec-
tricity consumption. For the cross-correlations at lag 2 (coefﬁcient matrix 2), Austria and
several countries are negatively correlated, and Poland and several countries are positively
correlated with magnitudes higher than others. We also notice that Germany has higher auto-
correlation at lag 1 (positively) and lag 2 (negatively). France, Bosnia Herzegovina, Croatia
and Macedonia have higher daily-seasonal correlation than other countries. It is also worth
noting that those auto and cross correlations are dynamically evolving so that the Figure 3
is just a snapshot of the relationships at the time point. The computational cost of online es-
timation of those model coefﬁcient matrices could be higher if other variables of the power
grid system are included in the model, such as electricity prices, wind and solar power gener-
ation and capacities. Those additional variables are available at different temporal resolutions
or time frames on Open Power System Data platform. The need for real-time inference un-
der complicated models and high computing costs reinforce the necessity of data reduction
methods in analyzing IoT sensor streams.
In terms of estimation accuracy, LSS and relaxed-LSS methods behave similarly and out-
perform the Bernoulli sampling most of the time during updates. Overall, estimation errors
for all three methods are decreasing along the update time, which suggests that the online
estimates converge to the “full sample” estimate. However, in practice, one cannot afford to
wait for the “full sample” due to the need for real-time monitoring in the power grid. Thus,
given limited access to the data under computational constraint, the faster it converges to the
“full sample” estimate the better. Especially, given the same initial values, LSS and relaxed-
LSS methods achieve better estimation accuracy at the early stage of updates than those of
the Bernoulli method. Eventually, LSS, relaxed-LSS and even Bernoulli sampling estimates
are close to the “full sample” estimate since a large enough amount of samples are used for
updating in all three sampling methods.
It is worth mentioning that there are a few sudden increases of estimation errors shortly
after time at 1000 . We believe they are caused by the abnormal points observed in dimension
12 Luxembourg on 2011-03-27 at 22:00:00 UTC and in dimension 13 Macedonia on 2010-
03-28 at 01:00:00 UTC. Those abnormal points were high leverage score points and thus16
were sampled by the LSS and relaxed-RSS methods. The corresponding model estimates de-
viated from the “full sample” estimates, which lead to sudden increases in estimation errors
but were soon corrected by new data points. This phenomenon reﬂects the advantage of LSS-
based sampling methods in capturing the inﬂuential or abnormal data points during stream
monitoring. It is an important feature that LSS can be applied in the online monitoring of the
dynamic dependence of the power grid system for security or online decision-making pur-
poses. However, the phenomenon also reﬂects the limitation of the leverage based sampling
method in lacking of robustness. The online estimation based on leverage score sampling is
sensitive to the changes in underlying data generating processes or outliers.
−0.2−0.10.00.10.2
25600 25700 25800 25900 26000 26100
TimeResidual
Leverage Scores45000
5000055000
6000065000
70000Relaxation No YesResidual: dimension 8 France
Fig 5: Residual plot from regression ﬁts for France, which is calculated based on the ﬁnal
estimate of relaxed-LSS along all historical data. A ﬁlled circle denotes a point selected by
the leverage score thresholding rule with the size of the ﬁlled circle indicating the leverage
score, and a triangle point indicates a point selected by the Bernoulli sampling rule.
In addition to theoretically veriﬁed properties of LSS-based methods in parameter estima-
tion, we also consider the prediction as a practical performance measurement. The accurate
prediction of the electricity loads is crucial for power grid system in resource allocation and
demand management. Prediction is also an important task for general IoT sensor data stream
analysis due to similar reasons. For prediction accuracy, the relaxed-LSS method consistently
achieves the smallest prediction errors among the three compared methods; while Bernoulli
method always delivers the largest prediction errors. The superiority of relaxed-LSS over
LSS in prediction may be due to its inclusion of low-leverage covariate points. We also note
the two peaks in prediction errors before and after time 30000, which are also caused by the
abnormal points in Macedonia and Luxembourg.
Lastly, to examine the goodness of model ﬁtting with relaxed-LSS sampling, we display
the regression residuals from a segment of a selected sample of size 500 from France in
Figure 5, which are calculated based on the ﬁnal estimate of relaxed-LSS on all historical
data. In Figure 5, a ﬁlled circle denotes a point selected by the leverage score thresholding
rule with the size of the ﬁlled circle indicating the leverage score, and a triangle indicates
the low leverage score point. The residual plot shows that the linear relation proposed in the
relaxed-LSS sampler holds equally well for both the points selected by a high leverage score
and by Bernoulli sampling.OPTIMAL SAMPLING DESIGNS 17
6. Simulation Studies for general applicability. Although the proposed relaxed-LSS
demonstrates better performance in inference and prediction on Open Power System Data,
we also conduct simulation studies to evaluate the effectiveness of LSS and its relaxed version
in general settings. We compare the LSS, relaxed-LSS and the Bernoulli sampling method,
which corresponds to s(x)qin Deﬁnition 3.1. We generate the multi-dimensional time
series which follows the V ARX model deﬁned in (5) with K= 10 ,p1= 1, andp2= 1. We
consider the multivariate Gaussian and the multivariate StudentT distributions for noise
process (et)and extraneous process (vt).
-0.200.20.40.6
Fig 6: Visualization of the coefﬁcient matrices and	, and covariance matrix for the error
process 
.
Fig 7: Comparison of estimation errors for simulated 10dimensional time series under
Gaussian setting. Visualized for the ﬁrst 2;500 updates with underlying time series of
length 25;000. The average and one standard deviation error bar of the estimation errors are
plotted over 1;000independent replicates.
6.1. Multivariate Gaussian Distribution Case. We ﬁrst consider the Gaussian case
where the noise process (et)follows the i.i.d. multivariate Gaussian distribution N(0;
)
and the extraneous process (vt)follows i.i.d. multivariate Gaussian distribution N(0;IKp2),18
whereIKp22RKp2is the identity matrix. We follow Qiu et al. (2015) to generate the coef-
ﬁcient matrices and	, and the covariance matrix for the error process 
, see Figure 6 for
visualization.
We generate the 10-dimensional time series of length n= 25;000. The sampling rate is
q= 0:1and base sampling rate for relaxed-LSS is q0= 0:05. The update rate for the inverse
covariance matrix is 0:1. A pilot sample of size 100is used to calculate initial estimations.
We deﬁne the estimation error as jj^B BjjF=jjBjjF, where ^Bis theth update of the
estimation of model parameter matrix B(here we use to denote the number of updates to
distinguish from the notation of time point t) andjjjjFdenotes the Frobenius norm.
Figure 7 displays the average and one standard deviation error bar of the estimation er-
rors at each update for each of the compared methods over 1;000independent replicates.
Focusing on the ﬁrst 2;500updates for each of the compared methods, we observe that LSS
method achieve smallest estimation errors compared to relaxed-LSS and Bernoulli methods
as predicted by our optimality theory. We note that the estimation errors for both LSS and
relaxed-LSS are signiﬁcantly smaller than those of Bernoulli method.
Fig 8: Comparison of estimation errors for simulated 10dimensional time series under Stu-
dentT setting. Visualized for the ﬁrst 2;500updates with underlying time series of length
25;000. The average and one standard deviation error bar of the estimation errors are plotted
over1;000independent replicates.
6.2. Multivariate Student T Distribution Case. We next consider the StudentT case.
The noise process (et)follows the i.i.d. multivariate student tdistribution with location 0,
degree of freedom 3and scale matrix 
, and the extraneous process (vt)follows i.i.d. multi-
variate student tdistribution with location 0, degree of freedom 3and scale matrix IKp2.
We generate the time series following Rémillard et al. (2012); Qiu et al. (2015). Partic-
ularly, we ﬁrst simulate an initial observation y1, extraneous variables v1;:::;vt 1, and
innovationse2;:::;et. After generating (y0
1;e0
2;:::;e0
t)0and(v0
1;:::;v0
t 1)0, one can form
(y0
1;y0
2;:::;y0
t)0recursively following the iterative algorithm in Rémillard et al. (2012). The
model coefﬁcient matrices and	, and the covariance matrix 
are the same as the Gaus-
sian case. We generate the multi-dimensional time series of length t= 25;000and set theOPTIMAL SAMPLING DESIGNS 19
sampling rate q= 0:1, the base sampling rate q0= 0:05and the update rate for the inverse
covariance matrix is 0:1. The pilot sample size is 100.
Figure 8 presents the average and one standard deviation error bar of estimation errors
against number of estimate updates, which are based on 1;000independent replicates. Sim-
ilar to the Gaussian case, the LSS method achieves the best performance as predicted by
our optimality theory; the LSS and relaxed-LSS methods are comparable; both methods are
signiﬁcantly better than the Bernoulli method in terms of estimation errors, where the wider
difference compared to the Gaussian case is due to the fact that the t-distribution has a heavier
tail and hence generates a larger leverage effect.
7. Conclusion. We introduced a class of online sample selection (sampling) methods for
large scale streaming time series with application in the online analysis of electricity power
grid data. We provide a solution to online statistical inference of high speed multidimensional
time series streams under computational constraint. The proposed methods were motivated
by optimal designs in design of experiments and were applied to the high temporal resolution
data streams in power grid system as an example of IoT sensor network data stream analy-
sis. The proposed methods were based on a relaxed version of leverage score sampling and
achieved an optimality criterion. Therefore, the proposed methods enjoyed the optimality in
online sampling theoretically and improved the computational efﬁciency of the online anal-
ysis. The elliptical distributed synthetic data and electricity consumption real data analysis
demonstrated the effectiveness of the proposed sampling methods. Our proposed relaxed-
LSS method provides online analysis of electricity loads through data selection without loss
of identiﬁcation of electricity consumption patterns and ﬂexibility. Our work was based on the
stationary linear multivariate time series models for streaming data modeling, which serves
as a foundation for tackling the more involved non-stationary case. We shall leave the study
of sampling of non-stationary data to future work.
Acknowledgments. We thank the Editor, Associate Editor, and two anonymous review-
ers for many valuable comments and suggestions.
Funding. This work is partially supported by NIH awards R01MD018025, R03AG069799,
NSF awards DMS-1903226, DMS-1925066 and DMS-2124493.
REFERENCES
Agarwal, P. K., S. Har-Peled, and K. R. Varadarajan (2005). Geometric approximation via coresets. Combinatorial
and Computational Geometry 52 , 1–30.
Akbar, A., A. Khan, F. Carrez, and K. Moessner (2017). Predictive analytics for complex IoT data streams. IEEE
Internet of Things Journal 4 (5), 1571–1582.
Anagnostopoulos, C., S. Hadjiefthymiades, A. Katsikis, and I. Maglogiannis (2014). Autoregressive energy-
efﬁcient context forwarding in wireless sensor networks for pervasive healthcare systems. Personal and Ubiq-
uitous Computing 18 (1), 101–114.
Balduin, S., E. Veith, and S. Lehnhoff (2022). Sampling strategies for static powergrid models. arXiv preprint
arXiv:2204.09053 .
Berberidis, D., V . Kekatos, and G. B. Giannakis (2016). Online censoring for large-scale regressions with appli-
cation to streaming big data. IEEE Transactions on Signal Processing 64 (15), 3854–3867.
Bingham, N. H., C. M. Goldie, and J. L. Teugels (1989). Regular Variation , V olume 27. Cambridge university
press.
Box, G. E. P., G. M. Jenkins, G. C. Reinsel, and G. M. Ljung (2015). Time Series Analysis: Forecasting and
Control (5 ed.). Wiley.
Cai, D., D. Shi, and J. Chen (2013). Probabilistic load ﬂow computation with polynomial normal transformation
and latin hypercube sampling. IET generation, transmission & distribution 7 (5), 474–482.
Cook, R. D. (1977). Detection of inﬂuential observation in linear regression. Technometrics 19 (1), 15–18.20
Dasgupta, A., P. Drineas, B. Harb, R. Kumar, and M. W. Mahoney (2009). Sampling algorithms and coresets for
`pregression. SIAM Journal on Computing 38 (5), 2060–2078.
Drineas, P., M. Magdon-Ismail, M. W. Mahoney, and D. P. Woodruff (2012). Fast approximation of matrix
coherence and statistical leverage. The Journal of Machine Learning Research 13 (1), 3475–3506.
Eshragh, A., F. Roosta, A. Nazari, and M. W. Mahoney (2022). LSAR: Efﬁcient leverage score sampling algorithm
for the analysis of big time series data. Journal of Machine Learning Research 23 , 1–36.
Fang, K.-T., S. Kotz, and K. W. Ng (1990). Symmetric Multivariate and Related Distributions . Chapman and
Hall.
Feldman, D., M. Schmidt, and C. Sohler (2013). Turning big data into tiny data: Constant-size coresets for K-
means, PCA and projective clustering. In Proceedings of the Twenty-Fourth Annual ACM-SIAM Symposium
on Discrete Algorithms , pp. 1434–1453. Society for Industrial and Applied Mathematics.
Gabel, M., D. Keren, and A. Schuster (2015). Monitoring least squares models of distributed streams. In Pro-
ceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pp.
319–328. ACM.
Gittens, A. and M. Mahoney (2013). Revisiting the nystrom method for improved large-scale machine learning.
InInternational Conference on Machine Learning , pp. 567–575. PMLR.
Hamilton, J. D. (1994). Time Series Analysis . Princeton University Press. Princeton, NJ.
Hill, D. J. and B. S. Minsker (2010). Anomaly detection in streaming environmental sensor data: A data-driven
modeling approach. Environmental Modelling & Software 25 (9), 1014–1022.
Hooi, B., H. A. Song, A. Pandey, M. Jereminov, L. Pileggi, and C. Faloutsos (2018). Streamcast: Fast and online
mining of power grid time sequences. In Proceedings of the 2018 SIAM International Conference on Data
Mining , pp. 531–539. SIAM.
Islam, S. R., D. Kwak, M. H. Kabir, M. Hossain, and K.-S. Kwak (2015). The Internet of things for health care:
a comprehensive survey. IEEE Access 3 , 678–708.
Jaradat, M., M. Jarrah, A. Bousselham, Y . Jararweh, and M. Al-Ayyoub (2015). The Internet of energy: smart
sensor networks and big data management for smart grid. Procedia Computer Science 56 , 592–597.
Jordan, M. I. (2013). On statistics, computation and scalability. Bernoulli 19 (4), 1378–1390.
Jumar, R., H. Maaß, B. Schäfer, L. R. Gorjão, and V . Hagenmeyer (2020). Database of power grid frequency
measurements. arXiv preprint arXiv:2006.01771 .
Kallenberg, O. (2002). Foundations of Modern Probability (2 ed.). Springer Science & Business Media.
Kalman, R. E. (1960). A new approach to linear ﬁltering and prediction problems. Journal of Basic Engineer-
ing 82 (1), 35–45.
Kalman, R. E. and R. S. Bucy (1961). New results in linear ﬁltering and prediction theory. Journal of Basic
Engineering 83 (1), 95–108.
Li, F., R. Xie, Z. Wang, L. Guo, J. Ye, P. Ma, and W. Song (2019). Online distributed IoT security monitoring
with multidimensional streaming big data. IEEE Internet of Things Journal 7 (5), 4387–4394.
Liberty, E. (2013). Simple and deterministic matrix sketching. In Proceedings of the 19th ACM SIGKDD Inter-
national Conference on Knowledge Discovery and Data Mining , pp. 581–588. ACM.
Liu, J. S. (2004). Monte Carlo Strategies in Scientiﬁc Computing . Springer.
Lütkepohl, H. (2005). New Introduction to Multiple Time Series Analysis . Springer Science & Business Media.
Ma, P., M. W. Mahoney, and B. Yu (2015). A statistical perspective on algorithmic leveraging. The Journal of
Machine Learning Research 16 (1), 861–911.
Ma, P., X. Zhang, X. Xing, J. Ma, and M. Mahoney (2020). Asymptotic analysis of sampling estimators for
randomized numerical linear algebra algorithms. In International Conference on Artiﬁcial Intelligence and
Statistics , pp. 1026–1035. PMLR.
Marangoni, G. and M. Tavoni (2021). Real-time feedback on electricity consumption: evidence from a ﬁeld
experiment in italy. Energy Efﬁciency 14 (1), 1–17.
Mat, I., M. R. M. Kassim, A. N. Harun, and I. M. Yusoff (2016). IoT in precision agriculture applications using
wireless moisture sensor network. In 2016 IEEE Conference on Open Systems (ICOS) , pp. 24–29. IEEE.
Meng, C., R. Xie, A. Mandal, X. Zhang, W. Zhong, and P. Ma (2020). Lowcon: A design-based subsampling
approach in a misspeciﬁed linear model. Journal of Computational and Graphical Statistics 0 , 1–32.
Michalareas, G., J.-M. Schoffelen, G. Paterson, and J. Gross (2013). Investigating causality between interacting
brain areas with multivariate autoregressive models of MEG sensor data. Human Brain Mapping 34 (4), 890–
913.
Nellore, K. and G. P. Hancke (2016). A survey on urban trafﬁc management system using wireless sensor net-
works. Sensors 16 (2), 157.
Open Power System Data (2020). Data package time series. Version 2020-10-06. (Primary data from various
sources, https://doi.org/10.25832/time_series/2020-10-06 ).
Papalambros, P. Y . and D. J. Wilde (2000). Principles of Optimal Design: Modeling and Computation . Cambridge
University Press.OPTIMAL SAMPLING DESIGNS 21
Petris, G., S. Petrone, and P. Campagnoli (2009). Dynamic linear models. In Dynamic Linear Models with R , pp.
31–84. Springer.
Plackett, R. L. (1950). Some theorems in least squares. Biometrika 37 (1/2), 149–157.
Pronzato, L. (2006). On the sequential construction of optimum bounded designs. Journal of Statistical Planning
and Inference 136 (8), 2783–2804.
Pronzato, L. and H. Wang (2020). Sequential online subsampling for thinning experimental designs. arXiv
preprint arXiv:2004.00792 .
Pukelsheim, F. (1993). Optimal Design of Experiments , V olume 50. SIAM.
Qiu, H., S. Xu, F. Han, H. Liu, and B. Caffo (2015). Robust estimation of transition matrices in high dimensional
heavy-tailed vector autoregressive processes. In International Conference on Machine Learning , pp. 1843–
1851.
Rémillard, B., N. Papageorgiou, and F. Soustra (2012). Copula-based semiparametric models for multivariate
time series. Journal of Multivariate Analysis 110 , 30–42.
Schimbinschi, F., L. Moreira-Matias, V . X. Nguyen, and J. Bailey (2017). Topology-regularized universal vector
autoregression for trafﬁc forecasting in large urban areas. Expert Systems with Applications 82 , 301–316.
Seber, G. A. and A. J. Lee (2012). Linear Regression Analysis , V olume 329. John Wiley & Sons.
Shehabi, A., S. Smith, D. Sartor, R. Brown, M. Herrlin, J. Koomey, E. Masanet, N. Horner, I. Azevedo, and
W. Lintner (2016). United states data center energy usage report.
Sherman, J. and W. J. Morrison (1950). Adjustment of an inverse matrix corresponding to a change in one element
of a given matrix. The Annals of Mathematical Statistics 21 (1), 124–127.
Siddik, M. A. B., A. Shehabi, and L. Marston (2021). The environmental footprint of data centers in the united
states. Environmental Research Letters 16 (6), 064017.
Surgailis, D., H. L. Koul, and L. Giraitis (2012). Large Sample Inference for Long Memory Processes . World
Scientiﬁc Publishing Company.
Ting, D. and E. Brochu (2018). Optimal subsampling with inﬂuence functions. In Advances in Neural Information
Processing Systems , pp. 3654–3663.
Wang, H., M. Yang, and J. Stufken (2019). Information-based optimal subdata selection for big data linear
regression. Journal of the American Statistical Association 114 (525), 393–405.
Wang, H., R. Zhu, and P. Ma (2018). Optimal subsampling for large sample logistic regression. Journal of the
American Statistical Association 113 (522), 829–844.
Wang, L., J. Elmstedt, W. K. Wong, and H. Xu (2021). Orthogonal subsampling for big data linear regression.
The Annals of Applied Statistics 15 (3), 1273 – 1290.
West, M. and J. Harrison (1997). Bayesian Forecasting and Dynamic Models (2nd ed.). Springer Science &
Business Media.
Woodruff, D. P. (2014). Sketching as a tool for numerical linear algebra. Foundations and Trends® in Theoretical
Computer Science 10 (1–2), 1–157.
Xie, R., Z. Wang, S. Bai, P. Ma, and W. Zhong (2019). Online decentralized leverage score sampling for streaming
multidimensional time series. In The 22nd International Conference on Artiﬁcial Intelligence and Statistics ,
pp. 2301–2311.
Xu, X., Y . Chen, Y . Goude, and Q. Yao (2021). Day-ahead probabilistic forecasting for french half-hourly elec-
tricity loads and quantiles for curve-to-curve regression. Applied Energy 301 , 117465.
Yokoyama, R. (1980). Moment bounds for stationary mixing sequences. Zeitschrift für Wahrscheinlichkeitstheorie
und verwandte Gebiete 52 (1), 45–57.
Yu, J., H. Wang, M. Ai, and H. Zhang (2020). Optimal distributed subsampling for maximum quasi-likelihood
estimators with massive data. Journal of the American Statistical Association (just-accepted), 1–29.
Zhang, K., C. Liu, J. Zhang, H. Xiong, E. Xing, and J. Ye (2017). Randomization or condensation?: Linear-cost
matrix sketching via cascaded compression sampling. In Proceedings of the 23rd ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining , pp. 615–623. ACM.
Zhang, T. and W. B. Wu (2012). Inference of time-varying regression models. The Annals of Statistics 40 (3),
1376–1402.
Zhou, B. and W. Saad (2019). Joint status sampling and updating for minimizing age of information in the internet
of things. IEEE Transactions on Communications 67 (11), 7468–7482.
Zhou, Z. and W. B. Wu (2010). Simultaneous inference of linear models with time varying coefﬁcients. Journal
of the Royal Statistical Society: Series B (Statistical Methodology) 72 (4), 513–531.