FIT-SLAM - Fisher Information and Traversability
estimation-based Active SLAM for exploration in
3D environments
Suchetan Saravanan
ISAE-SUPAERO ,
University of Toulouse
Toulouse, France
BITS Pilani, India
suchetan.saravanan@isae.frCorentin Chauffaut
ISAE-SUPAERO ,
University of Toulouse
Toulouse, France
corentin.chaffaut@isae.frCaroline Chanel
ISAE-SUPAERO ,
University of Toulouse
Toulouse, France
caroline.chanel@isae.frDamien Vivet
ISAE-SUPAERO ,
University of Toulouse
Toulouse, France
damien.vivet@isae.fr
*Corresponding author
Abstract —Active visual SLAM finds a wide array of applica-
tions in GNSS-Denied sub-terrain environments and outdoor en-
vironments for ground robots. To achieve robust localization and
mapping accuracy, it is imperative to incorporate the perception
considerations in the goal selection and path planning towards
the goal during an exploration mission. Through this work,
we propose FIT-SLAM (Fisher Information and Traversability
estimation-based Active SLAM), a new exploration method
tailored for unmanned ground vehicles (UGVs) to explore 3D
environments. This approach is devised with the dual objectives
of sustaining an efficient exploration rate while optimizing SLAM
accuracy. Initially, an estimation of a global traversability map
is conducted, which accounts for the environmental constraints
pertaining to traversability. Subsequently, we propose a goal
candidate selection approach along with a path planning method
towards this goal that takes into account the information provided
by the landmarks used by the SLAM backend to achieve robust
localization and successful path execution . The entire algorithm
is tested and evaluated first in a simulated 3D world, followed
by a real-world environment and is compared to pre-existing
exploration methods. The results obtained during this evaluation
demonstrate a significant increase in the exploration rate while
effectively minimizing the localization covariance.
Index Terms —Active SLAM, Fisher information, Traversabil-
ity analysis, 3D Exploration
I. I NTRODUCTION
For mobile systems to be robustly localized, actively con-
sidering the perception requirement in the planning stage is
essential. On-board visual sensing and computing permit sys-
tems to operate autonomously but bring additional constraints
to motion planning algorithms. Specifically, the robot’s motion
impacts the information the visual sensors will capture and
thus influences the performance of perception and localization
algorithms. Therefore, the requirement of visual perception
has to be taken into consideration in motion planning in order
to improve localization accuracy. This problem is known as
active vision [1] or active perception [2]. The central paradigm
This research was funded by Defense Innovation Agency (AID) of the
French Ministry of Defense, Research Project CONCORDE No 2019 65
0090004707501. This paper is a draft and unauthorized use of the presented
work is strictly prohibited.ΦvwiΘ∗
s C1
w3
w2
w1C2
xy
Fig. 1: Overview of the proposed framework: A 2D thresh-
olded traversability map is analyzed to extract frontiers goals
(stars). Each goal candidate Ciis ranked based on the informa-
tion computed for the planned path. Such information is linked
to the observed landmarks (red dots) in the camera field-of-
view (FOV) Φ(blue area) but also the maximal reduction in
entropy after reaching the goal with robot orientation Θ∗
s. This
allows to ensure good localizability while exploring new areas,
resulting in a more accurate mapping.
of active simultaneous localization and mapping (ASLAM) is
to plan the sensor motion based on the information that can
be attained and the covariance that can be maintained during
the exploration mission.
The critical goal in UGV-based exploration is to achieve
good long-term mission planning that has a competitive ex-
ploration rate while also maintaining good mapping and local-
ization accuracy during the mission. The algorithms adeptly
tackle the exploration-exploitation dilemma. That is, to strike
a balance between exploring new parts of the environment and
exploiting the already explored portion of the map.arXiv:2401.09322v1  [cs.RO]  17 Jan 2024B. Yamuchi [1] introduced the concept of Frontiers , a set
of points which acts as the transition region between the
areas of a map that are already explored from those not yet
visited. Since this work, where a greedy frontier-based explo-
ration was performed, several contributions and improvements
have been made to the exploration strategy. In the realm of
goal determination for exploration, there exists a variety of
methodologies. The frontier-based approach is still popular
and can be found in recent works such as [2]. An alternative
method to select possible goals is proposed by Umari et al.
[3], where they detect the frontier on a 2D occupancy grid
map using rapidly-exploring random trees (RRTs). The use of
this strategy concatenated with computer vision algorithms can
be found in works such as [4]. These approaches, however are
limited to the robot exploring a 2D planar environment, which
vastly reduces the capabilities of a UGV . Some works in the
past focus on 3D UGV exploration, such as [5]–[7]. These
works showcase promising results in terms of the exploration
rate of the proposed algorithm. However, they do not account
for the localization accuracy estimated by the SLAM backend.
Unfortunately, high uncertainty in the robot state could
lead to a significantly unreliable map. In [8], Bourgault et
al. addressed this issue by incorporating a utility function
that has a trade-off between the information from the SLAM
backend and the reduction of the map entropy. Stachniss et
al. [9] employ a Rao-Blackwellized particle filter (RBPF) for
representing both the robot poses and the map. Through this,
they can determine the best possible action by estimating the
entropy of the particle filter. The use of Kullback-Leibler diver-
gence as a metric for the measure of information can be found
in [10]. Different optimality criterion from Theory of Optimal
Design (TOED) [11] is often used to quantify the uncertainity.
For example, Carillo et al. [12] show that the D-optimality
can be used as an information metric and is comparable to
the A-optimality criterion. The recent approaches, especially
the ones that incorporate graph-based optimization in SLAM
have proven to have better long-term prediction than the RBPF
approaches, which ultimately suffer from particle depletion as
the size of the environment grows. [13]
In this context, the presented work proposes a novel ex-
ploration strategy for Active SLAM devised with the dual
objectives of sustaining an efficient exploration rate while
optimizing SLAM accuracy. Our approach - denoted as ”FIT-
SLAM” - an acronym representing ’Fisher Information and
Traversability-Based Active SLAM’ aims to address the two
objectives. In detail, the 3D space exploration task is con-
ceptualized as a 2D traversability map, taking into account
the constraints posed by the 3D terrain and obstacles. This
transformation results in a notable decrease in the time taken
to find the frontier clusters as well as path generation to
the candidate goals. Transforming the 3D exploration space
to a 2D traversability map also eliminates the computational
burden posed by maintaining a 3D V oxel map during explo-
ration. Then, a goal selection approach taking into account
the information gained upon reaching a given goal position,
as well the information provided by the landmarks generatedImages
Odometry
Point cloudPoses
Local
TraversabilityGraph-based
SLAMGlobal
TraversabilityRover properties
Binary
traversabilityMapping
Current pose
PlanningN best
GoalsFrontier
detection
Best
Selected
pathLevel 1utility
(u1) = (∆ E, ρ)Candidate Goals
Level 2utility
(u2) = tr(Ip)
Fig. 2: Our ASLAM solution framework: First a global
traversability map is built based on graph-based SLAM and 3D
perception. Then, based on the rover capabilities, traversability
scores are thresholded and the frontiers are detected. Goals are
defined for each frontier and ranked on the basis of information
gain. Finally, path safety for each goal are evaluated using pre-
dicted perception entropies. Depending on the other constraints
of the mission, the final path is selected and executed.
from SLAM during possible path execution towards this goal,
is used to select the next destination point to be visited. The
Fig. 1 shows a simplified model of our approach. To the best
of our knowledge, this is the first work for UGVs exploring
a 3D environment where the strategy not only accounts for
the safety of the robot during exploration but also provides
promising results for the reduction of the uncertainty related
to both the pose of the robot as well as the map generated by
a SLAM backend.
The main contributions of this work encompass two key as-
pects: (i) the proposition of frontier-based exploration and path
planning strategies based on the use of a global traversability
map and (ii) the proposition of a candidate goal selection
approach which takes into account the information gained
upon reaching the goal as well as the information provided
by the landmarks generated from SLAM during the path
execution to this goal.
The paper is organized as follows: sections II-A and II-B
present the methodology used for the SLAM backend and the
traversability estimation, respectively. The parts II-C and II-D
deal with the proposed frontier-based exploration method. The
results are showcased in section III. Finally, conclusions and
future work are discussed in section IV.
II. M ETHODOLOGY
We propose a complete ASLAM framework to deal with the
active exploration problem of an unknown and unstructured
environment. Our solution is based on a graph-based SLAM
approach for localization and a traversability estimator for path
planning risk assessment. Finally, an analysis of the Fisherinformation calculated for each trajectory is used to select the
best path. The proposed solution is summarized in Fig. 2.
A. Graph-based SLAM
The proposed navigation solution uses a graph-based SLAM
approach in which nodes represent robot 6D poses xor
landmarks miof the map Mposes, and edges in the map
represent constraints between these poses. Such an approach
makes use of a sliding window optimization that consists of
finding the optimal state X∗={x,M}that minimizes the
summation of the norm of the residuals, that are the errors of
all factors eweighted by their respective covariances Σk, such
as:
X∗= arg min
X X
k∈G∥ek(X)∥2
Σk!
(1)
In the case of loop-closure detection, a similar optimization is
performed but over the entire problem.
Note that for this work, we use RTABMap [14] as our
SLAM backend. However, the proposed approach is not lim-
ited to RTABMap and can work with any other graph-based
SLAM providing both key-frame poses and a map composed
of landmarks.
B. Traversability estimation
Based on the pose-graph obtained by the SLAM approach,
the detections obtained from the 3D LiDAR sensor (or other
depth sensors) are registered in the world frame to process
the traversability estimation. Following [15], traversability
illustrates the difficulty of navigating through a specific region
and encompasses the suitability of the terrain for traversing
based on its physical properties, such as slope, roughness and
surface condition as well as the mechanical characteristics and
capabilities of the UGV .
In this work, we used a geometry-based traversability
estimator similar to the works in [16]–[18]. The objective
here is to model the environment as a grid of regularly
spaced cells, where each cell typically represents the size
of a UGV wheel. Each of these cells is populated with a
traversability score or is tagged as unknown. This score is
obtained by processing the statistics of the 3D points belonging
to each cell, as in [19] An example of the local traversability
obtained is presented in Fig. 3. This transformation allows us
to obtain a global georeferenced 2D map that represents the
traversability of the 3D environment. Depending on the robot’s
risk acceptance criteria and capabilities, the traversability score
can be thresholded to generate a 2D binary traversability grid
map. This grid map serves a function similar to that of an
occupancy grid and is employed in path planning to maintain
the robot’s safety throughout its operations.
C. Frontiers detection and clustering
1) Frontiers detection: Frontiers are regions in the map that
act as a boundary between explored and unexplored regions.
The proposed exploration algorithm begins with plotting an
exploration boundary within which the frontiers are searched.A conventional frontier search algorithm similar to the one
proposed in [1] is used.
2) Frontiers clustering and candidate goal determination:
In our case, the conventional frontier search algorithm is mod-
ified to perform frontier clustering constrained to a maximum
size. All linked frontier cells are treated together as one cluster,
and the frontier point with the median index of the cluster
is chosen as a candidate goal Ci. The path to reach each
candidate goal is then generated. The 2D global traversability
map coupled with the A* path planning algorithm from the
ROS 2 navigation stack is used for this purpose. In cases where
it is impossible to calculate a path to the goal or when the goal
has been previously identified as a frontier point in an earlier
iteration, it is designated for exclusion in a blacklist, indicating
that the goal is currently unreachable. If there are no frontiers
available in the map or in the area of interest, the exploration
mission is considered to be a success and the mission ends.
D. Utility computation and candidate goal selection
The utility of any candidate goal Ciis processed at two
levels: The first-level (u1)is based on the computation of
the total distance of the path from the current robot position
to the candidate frontier and on the information gained upon
reaching the said frontier. The second level (u2)is estimated
by the information gained along the path.
1) First-level utility computation (u1):Let Cx=
{C0, C1, . . . , C n}be a set of candidate goals. For each can-
didate Ci∈Cx, we have an associated path piwith a length
ρiand a measure of information gained upon reaching the
candidate goal ∆Ei, which represents the change in map
entropy upon observing the unknown cells after reaching the
candidate goal.
More precisely, to compute the possible information gain
upon reaching the candidate goal, we use a conventional ray
tracing algorithm to get the set of potentially observable cells.
Initially, we first determine the optimal arrival sensor orienta-
tionΘ∗
sthat maximizes the information gain. In practice, to
control the spatial density of the ray-tracing and expedite the
process, we approximate ∆Eiusing a finite number of rays
separated by ∆θ.
(a)
 (b)
Fig. 3: Estimated local traversability map. (a) The processed
geometric traversability was obtained with a 3D LiDAR
detection. (b) The reprojection of the traversability on the
synchronized image showing (in red) the navigability risks.LetΘ ={0,∆θ,2∆θ,···,2π}be the set of discretized
ray directions and Φis the camera field-of-view, we have the
optimal arrival sensor orientation Θ∗
sgiven by:
Θ∗
s= arg max
Θs∈Θ
Θs+Φ
2X
Θs−Φ
2∆EΘs
G
 (2)
where, G={c1, c2,···, cn}represents a 2D occupancy grid
composed of ncells. ∆EΘs
Gis the information gained along
the ray in the direction Θs. The information gain can be
calculated as the change in the occupancy grid entropy before
and after observing the cells along the ray in the direction Θs.
Following [20], the entropy EΘs
Gof a given occupancy
grid-map Gis computed based on the Shannon entropy as
a measure of map uncertainty. It is given by:
EΘs
G=nX
i=0EΘs[ci] =−nX
i=0(p(ci)·log2(p(ci))
+(1−p(ci))·log2(1−p(ci)))(3)
where, cirepresents a cell in G, and p(ci)represents the
occupancy probability of the cell ci. If the cell ciis unknown
then p(ci) = 0 .5. It is manifest that such a computation
requires the estimation of probabilities of all cells that can be
observed along the ray. The farther a ray travels into unknown
space, the more likely it is to be obstructed by an obstacle.
Thus, as proposed in [21], the observability of the cell is
dependent on the previous cells traversed along the ray, such
as:
p(xr|xr−1) =(
1 if ray intersects an occupied cell
γNotherwise(4)
where p(xr|xr−1)is the observability of a cell lying along
the ray composed of rcells, γis the degradation parameter
which controls how fast the probability degrades along the
ray,Nis the previous number of cells traversed by the ray.
Given the observability of a cell, we can estimate the posterior
occupancy probability of the cell cras:
p(cr) =1 +p(xr|xr−1)
2(5)
Finally, ∆Ei, which is the information gained upon reaching
the candidate goal Cican be processed with the optimal arrival
sensor orientation Θ∗
sby:
∆Ei=Θ∗
s+Φ
2X
Θ∗s−Φ
2∆EΘ∗
s
G (6)
At this step, the first-level utility (u1)can be computed for
each candidate goal Cias a trade-off between the path length
to be traversed by the robot ρiand the information gained
∆Eiupon reaching the goal:
u1(Ci) =α Nρ−1ρ−1
i+ (1−α)N∆E∆Ei (7)
where α∈[0,1](resp. ( 1−α)) represents the weight assigned
toρi(resp. ∆Ei) and Nρ−1,N∆Eare normalization factors.
By ranking the set of candidate goals Cxbased on their
corresponding first-level utility ( u1) values, we can determinetheNmost promising candidate goals in terms of distance to
the goal and overall map entropy reduction.
However, this selection criterion does not take into account
the information acquired during the travel to the intended goal.
In instances where the information gathered during the travel
phase is insufficient, the robot runs the risk of getting lost
in the map and becoming disoriented. This could lead to a
high localization uncertainty, which inherently could lead to a
poor map accuracy. The inclusion of the second utility level
mitigates this limitation.
2) Second level utility computation (u2):We propose to
add to the previous utility function the information gathered
during path traversal. The objective is to maximize the robot’s
overall pose accuracy to the utmost degree and as a conse-
quence, improve the map quality.
This level of utility computation will be used to determine
the most optimal candidate goal by estimating the information
gathered during the path execution. Given a path pito a
candidate goal Ci, we first sample the trajectory with a
sampling distance equal to the max-depth of the camera FOV
to obtain a set of waypoints Wi={w1, w2, . . . , w n}. For each
wk∈Wi, we compute the information of all the landmarks
from the map that lie within the FOV .
To do so, the Fisher Information Matrix (FIM) is used.
FIM represents the minimum reachable covariance of an
unbiased estimator [22] and allows to quantify the estimation
uncertainty. In our approach, we use the bearing vector repre-
sentation of the 3D landmark. Given a 3D landmark that lies
in a voxel vwiin the world frame with a covariance Qi, the
observation function can be modeled using the bearing vector
biof the detection vwisuch as:
bi=vci
∥vci∥2with vci=Tcwvwi (8)
where vciis the ithvoxel in the camera frame, Tcwthe
affine transform matrix from world to camera frame.
The Fisher information matrix Iicorresponding to the
considered landmark lying in the voxel vwican be derived
as:
Ii=JiQiJT
i (9)
Fig. 4: Our robotic platform equipped with the sensors (Depth
Camera, 3D LiDAR, IMU and wheel odometry) required for
the algorithm.0 1000 2000 3000 40000510152025
Time (s)tr(Covariance)FIT-SLAM
Greedy
Random
(a)0 1000 2000 3000 4000020406080100
Time (s)% unexplored MapFIT-SLAM
Greedy
Random
(b)
Fig. 5: Evaluation of the proposed approach for the experiment
conducted in simulation (a) Evolution of the trace of the robot
state covariance over time. (b) Evolution of the exploration rate
With Jithe jacobian of the observation model (8) given by:
Ji=∂bi
∂Twc=∂bi
∂vci∂vci
∂Twc(10)
where the elements in Eq. (10) are given using the Special
Euclidean group SE(3) [23] by:
∂bi
∂vci=1
∥vci∥2I3−vci(vci)T
(∥vci∥2)3(11)
∂vci
∂Twc=Rcw
−I3,[vwi]×
(12)
where Rcwis the rotation from world to camera frame and
[v]×is the cross-matrix of vector v.
Storage of the FIMs for all the voxels arguably consumes a
lot of memory. A common way to bypass this memory usage
is to use the theory of optimal experimental design (TOED)
[11], which utilizes the T-opt optimality criterion, i.e., the trace
of the FIM can be used to convert FIM to a scalar value
significantly reducing the memory usage.
Therefore, we can estimate the information of the path pi
by summing over all waypoints wk∈Wi.
Ipi=NIX
wk∈wxIwk=NIX
wk∈wxX
vwi∈vwkIi (13)
where Ipiis the information of the path, Iiis the information
of the voxel vwiandNIis the normalization factor. However,
it is important to note that even though the memory usage
is significantly reduced due to the inclusion of T-opt criteria,
the computation of the FIM, even with the incorporation of
voxelization is a computationally intensive task.
Following the computation of information along the path,
we are able to compute the second level utility ( u2) for a
candidate goal Ci, such as:
u2(Ci) =β·u1+ (1−β)Ipi (14)
where β∈[0,1]is a weighting parameter between u1andIpi.
We compute this information solely for the Nbest candidate
goals ranked after the computation of u1. Let C∗
xrepresents0 1000 2000 300000.511.522.5
Time (s)tr(Covariance)FIT-SLAM
Greedy
Random
(a)0 1000 2000 3000020406080100
Time (s)% unexplored MapFIT-SLAM
Greedy
Random
(b)
Fig. 6: Evaluation of the proposed approach for the real-
world experiment. (a) Evolution of the trace of the robot state
covariance over time. (b) Evolution of the exploration rate. The
jumps in the covariance trace correspond to the loop closure
detections.
theNbest candidate goals in Cx, the best candidate goal Cbest
is simply the one with the biggest utility value ( u2), such as:
Cbest= arg max
Ci∈C∗x(β·u1+ (1−β)Ipi) (15)
Finally, the path selected based on u2is the one that minimizes
the localization and map uncertainty as it has the most
informative landmarks observed during traversal while also
taking into account the distance of the goal and information
gained upon reaching the said goal.
III. R ESULTS
We validated our approach by comparing two metrics: (i)
the percentage of unexplored map with respect to time and
(ii) the evolution of the localization covariance (the marginal
error obtained after graph optimization from the SLAM) with
respect to time during exploration. The entirety of our system
is programmed using the ROS 2 framework and tested in a 3D
unstructured simulated environment on Gazebo running on a
standard computer. Our real-world experiment was conducted
in a planar environment with the Nvidia Jetson AGX Xavier
(CPU: 8 Core @ 2.26 GHz, RAM: 32 GB, GPU: unused)
as our on-board computer and the LeoRover as our robotic
platform. The Intel Realsense D435 and the Velodyne VLP-
16 LiDAR was used as our primary sensors. The parameters
used for our experiments are, α= 0.35, β= 0.4,∆θ= 8.5◦.
N= 7, traversability map resolution = 0.05mand the voxel
size is 0.25m.
Results for our experiments in simulation and real-world are
shown in Fig. 5 and Fig. 6. Three frontier-based exploration
methods have been tested. (i) Our approach (FIT-SLAM)
which uses the traversability estimation coupled with the most
informative path choice. (ii) A random selection of the frontier.
(iii) A greedy frontier selection approach which selects the
closest frontier to the robot. It is important to note that the
very same 2D traversability map is used to generate paths and
detect frontiers in all the three approaches.
The plot in Fig. 5 (a) shows that our approach has the
best accuracy. In Fig. 6 (a), several drops in covariance can
be observed. These indicate the points of loop-closure. Thehigh number of loop closures detected in our method is
a direct consequence of using the information provided by
the landmarks of the map in the goal selection. Regarding
exploration speed results, illustrated in Fig. 5 (b) and 6 (b), it
is interesting to observe that the greedy frontier approach maps
the environment very quickly in the initial phase. However,
during long-term planning, the greedy frontier exploration is
stuck exploring frontiers that yield very low information gain.
This result suggests that our first-level utility would play a
key role in exploration speed improvement. The results for
the real-world experiment are consistent with the results of
the simulation.
IV. C ONCLUSION AND FUTURE WORK
We proposed a novel Active-SLAM approach to explore a
3D unstructured environment based on a traversability map.
Our solution uses both the Shannon entropy to measure the
amount of information that could be gained by mapping new
areas and the Fisher information matrix as an information met-
ric to estimate the information gained during path execution
by observing the known and mapped landmarks. Our entire
approach has been tested in a 3D setting on simulation and
we showed substantial improvements in the exploration rate
and accuracy of the SLAM. We also validated the solution
with a real-time experiment with a real robot in a controlled
2D environment. In the near future, we plan to extend our real-
world experiment in a 3D environment and also compare our
algorithm against other existing methodologies. We also aim
to extend our approach to multi-robot exploration missions.
REFERENCES
[1] B. Yamauchi. A frontier-based approach for autonomous exploration.
InProceedings 1997 IEEE International Symposium on Computational
Intelligence in Robotics and Automation CIRA’97. ’Towards New Com-
putational Principles for Robotics and Automation’ , pages 146–151,
1997.
[2] Elia Bonetto, Pascal Goldschmid, Michael Pabst, Michael J. Black, and
Aamir Ahmad. irotate: Active visual slam for omnidirectional robots.
Robotics and Autonomous Systems , 154:104102, 2022.
[3] Hassan Umari and Shayok Mukhopadhyay. Autonomous robotic explo-
ration based on multiple rapidly-exploring randomized trees. In 2017
IEEE/RSJ International Conference on Intelligent Robots and Systems
(IROS) , pages 1396–1402, 2017.
[4] Cheng-Yan Wu and Huei-Yung Lin. Autonomous mobile robot ex-
ploration in unknown indoor environments based on rapidly-exploring
random tree. In 2019 IEEE International Conference on Industrial
Technology (ICIT) , pages 1345–1350, 2019.
[5] Yujie Tang, Jun Cai, Meng Chen, Xuejiao Yan, and Yangmin Xie. An
autonomous exploration algorithm using environment-robot interacted
traversability analysis. In 2019 IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS) , pages 4885–4890, 2019.
[6] Shakeeb Ahmad and J. Sean Humbert. Efficient sampling-based plan-
ning for subterranean exploration. In 2022 IEEE/RSJ International
Conference on Intelligent Robots and Systems (IROS) , pages 7114–7121,
2022.
[7] Magnus Selin, Mattias Tiger, Daniel Duberg, Fredrik Heintz, and Patric
Jensfelt. Efficient autonomous exploration planning of large scale 3d-
environments. IEEE Robotics and Automation Letters , PP:1–1, 02 2019.
[8] F. Bourgault, A.A. Makarenko, S.B. Williams, B. Grocholsky, and H.F.
Durrant-Whyte. Information based adaptive robotic exploration. In
IEEE/RSJ International Conference on Intelligent Robots and Systems ,
volume 1, pages 540–545 vol.1, 2002.
[9] Cyrill Stachniss, Giorgio Grisetti, and Wolfram Burgard. Information
gain-based exploration using rao-blackwellized particle filters. In Pro-
ceedings of Robotics: Science and Systems , pages 65–72, 06 2005.[10] Carlone Luca, Du Jingjing, Kaouk Miguel, Bona Basilio, and Indri
Marina. Active slam and exploration with particle filters using kullback-
leibler divergence. In Journal of Intelligent & Robotic Systems , pages
291–311, 2014.
[11] F. Pukelsheim. Optimal Design of Experiments . Classics in Applied
Mathematics. Society for Industrial and Applied Mathematics, 2006.
[12] Henry Carrillo, Ian Reid, and Jos ´e A. Castellanos. On the comparison
of uncertainty criteria for active slam. In 2012 IEEE International
Conference on Robotics and Automation , pages 2080–2087, 2012.
[13] Beipeng Mu, Liam Paull, Ali-akbar Agha-mohammadi, John J. Leonard,
and Jonathan P. How. Information-based active SLAM via topological
feature graphs. CoRR , abs/1509.08155, 2015.
[14] Mathieu Labb ´e and Franc ¸ois Michaud. Rtab-map as an open-source lidar
and visual simultaneous localization and mapping library for large-scale
and long-term online operation. Journal of field robotics , 36(2):416–446,
2019.
[15] H. Seraji. Traversability index: a new concept for planetary rovers.
InProceedings 1999 IEEE International Conference on Robotics and
Automation (Cat. No.99CH36288C) , volume 3, pages 2006–2013 vol.3,
1999.
[16] Timothy H. Chung, Viktor Orekhov, and Angela Maio. Into the robotic
depths: Analysis and insights from the darpa subterranean challenge. An-
nual Review of Control, Robotics, and Autonomous Systems , 6(1):477–
502, 2023.
[17] Chao Cao, Hongbiao Zhu, Fan Yang, Yukun Xia, Howie Choset, Jean
Oh, and Ji Zhang. Autonomous exploration development environment
and the planning algorithms. In 2022 International Conference on
Robotics and Automation (ICRA) , pages 8921–8928. IEEE, 2022.
[18] Nicolas Hudson, Fletcher Talbot, Mark Cox, Jason Williams, Thomas
Hines, Alex Pitt, Brett Wood, Dennis Frousheger, Katrina Lo Surdo,
Thomas Molnar, et al. Heterogeneous ground and air platforms, homo-
geneous sensing: Team csiro data61’s approach to the darpa subterranean
challenge. arXiv preprint arXiv:2104.09053 , 2021.
[19] Steven B Goldberg, Mark W Maimone, and Larry Matthies. Stereo
vision and rover navigation software for planetary exploration. In
Proceedings, IEEE aerospace conference , volume 5, pages 5–5. IEEE,
2002.
[20] R. Sim, G. Dudek, and N. Roy. Online control policy optimization for
minimizing map uncertainty during exploration. In IEEE International
Conference on Robotics and Automation, 2004. Proceedings. ICRA ’04.
2004 , volume 2, pages 1758–1763 V ol.2, 2004.
[21] Christian Potthast and Gaurav Sukhatme. A probabilistic framework for
next best view estimation in a cluttered environment. Journal of Visual
Communication and Image Representation , 25:148–164, 01 2014.
[22] Yongbo Chen, Liang Zhao, Yanhao Zhang, Shoudong Huang, and
Gamini Dissanayake. Anchor selection for slam based on graph
topology and submodular optimization. IEEE Transactions on Robotics ,
38(1):329–350, 2022.
[23] Zichao Zhang and Davide Scaramuzza. Beyond point clouds: Fisher
information field for active visual localization. In 2019 International
Conference on Robotics and Automation (ICRA) , pages 5986–5992,
2019.