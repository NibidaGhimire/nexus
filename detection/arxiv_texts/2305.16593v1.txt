 
1 A Multi -Resolution  Physics -Informed Recurrent Neural Network : Formulation and 
Application to  Musculo skeletal Systems  
Karan Tanejaa, Xiaolong Heb, Qizhi Hec and J . S. Chena* 
a Department of Structural Engineering, University of California San Diego, La Jolla , CA, USA  
b ANSYS Inc ., Livermore,  CA, USA  
c Department of Civil, Environmental, and Geo - Engineering, University of Minnesota, 
Minneapolis, MN, USA  
Abstract  
This work presents a  multi -resolution physics -informed recurrent neural network (MR PI -RNN) , 
for simultaneous  predict ion of musculoskeletal  (MSK) motion and parameter identification of the 
MSK systems . The MSK application was selected as the model problem due to its  challenging 
nature in mapping the high-frequency surface electromyography  (sEMG)  signals to the low-
frequency body joint motion  controlled by the MSK  and muscle  contraction  dynamics . The 
proposed method utilizes the fast wavelet transform to decompose the mixed frequency  input  
sEMG and output joint motion signals  into nested multi -resolution signals . The prediction model 
is subsequently trained on coarse r-scale input -output  signals using a gated recurrent unit (GRU), 
and then the trained parameters are transferred to the next level  of training with finer -scale signals . 
These training processes are repeated recursively  under a transfer -learning  fashion  until the full-
scale  training ( i.e., with unfiltered signal s) is achieved , while satisfying the underlying dynamic 
equilibrium . Numerical examples  on recorded subject data demonstrate the effectiveness of the 
proposed framework in generating a physics -informed forward -dynamics surrogate , which  yields 
higher accura cy in  motion predictions of elbow flexion -extension of a n MSK system compared to 
the case with single -scale training.  The framework is also  capable of  identify ing muscle parameters 
that are physiologica lly consistent with the subject‚Äôs  kinematics data.  
Keywords: multi -resolution recurrent  neural  network, p hysics -informed parameter identification, 
musculoskeletal  system , gated recurrent unit , fast wavelet transform  
 
* Corresponding author  
E-mail address : js-chen@ucsd.edu  (J. S. Chen)  
  
2  
1. Introduction  
The prediction of the evolution of state variables  in dynamical systems  has been a vital component 
to several scientific applications such as biology , geophysics , earthquake engineering , solid 
mechanics , robotics,  computer vision  [1‚Äì7] etc. Black -box techniques based on data -driven 
mapping and development of parameterized multi -physics models describing the progression of 
the data  have been previously  utilized for making predictions on the states. This task continues to 
be an active area of research due to challenges on many fronts,  such as, the quality and scarcity of 
relevant physical data,  the dynamics and complexity of the system , and the reliabili ty and accuracy 
of the prediction model.    
On the other hand, t he characterization of p arameter s in the multi -physics models  of these  
dynamical systems  is also critical  [8‚Äì14]. The task is challenging  due in parts to potential noise 
pollution  captured by  sensors in the system‚Äôs  measured data, as well as the potential of the 
parameter space being high-dimensional , leading to ill-posed problem s that pose difficulties in 
numerical solutions . Standard optimization techniques such as genetic algorit hms [15,16] , 
simulated annealing  [17], and non -linear least squares  [18,19]  have been employed  for parameter 
identification , but can be computationally expensive  and may not converge  for ill -posed , non -
convex optimization problems  that are encountered while  solving inverse problems on MSK 
systems  [15,20] . 
In recent years, machine learning (ML) or deep -learning -based approaches have gained  significant  
popularity  for solving forward and inverse problems, attributed  to their capability in effectively 
extracting complex features and patterns  from data [21]. This has been successfully demonstrated 
in numerous  engineering applications such as reduced -order modeling [22‚Äì26], and materials 
modeling [27‚Äì29], among others.  Data -driven computing  techniques that enforce constraints of 
conservation laws in the learning algorithms of a material database , have been developed in the 
field of computational  mechanics  [29‚Äì37]. More recently, physics -informed neural networks 
(PINNs) have been developed [11,3 8,39]  to approximate the solutions of given physical equations 
by using neural networks (NNs) . By minimizing the residuals of the governing partial differential 
equations (PDEs) and the associated initial and boundary conditions , PINN s have been 
successfully applied to solve forward problems [11,40,41] , and inverse problems [11,38,42 ‚Äì44],  
3 where the unknown system characteristics are considered trainable parameters or functions [38,45] . 
For biomechanics and biomedical applications [1,46 ‚Äì50], this method has been applied extensively 
along with other ML techniques [51,52] . These attempt to bridge the gap between ML -based data -
driven surrogate models and  the satisfaction of physical laws.  
In this study, we focus on the application to musculoskel etal systems , where we aim to utilize non-
invasive muscle activity measurements  such as surface  electromyography (sEMG) signals to 
predict joint kinetics or  kinematics  [1,18,19] , e.g., for health assessment and rehabilitation 
purposes  [15,16] . These sEMG signals can be used  as control inputs to drive the physiological 
subsyst ems, which are governed by parameterized non -linear differential equations , that form  the 
forward dynamics  problem . Hence, g iven information o n muscle activations , the joint motio n of a 
subject -specific MSK system can be obtained by solving a forward dynamics problem.  Data-driven 
approaches  for motion prediction have also been introduced to directly map the input sEMG signal 
to joint kinetics/kinematics, bypassing the forward dynamics equations and the need for parameter 
estimation [26‚Äì30]. However, the resulting ML -based surrogate models lack interpretability and 
may not s atisfy the underlying physics. Another challenge is that the sEMG signal usually exhibit s 
a wide range of frequencies that are non-trivial for ML  models  [1] to map to the joint motion . 
In our previous work  [1], a physics -informed parameter identification n eural network (PI-PINN) 
was proposed for the simultaneous prediction of motion and parameter identification with 
application to  MSK systems. Using the  raw transient sEMG signals obtained from the sensors and 
the corresponding joint motion data, the PI-PINN learn ed to predict the motion and identif y the 
parameters of the hill-type muscle models representing  the contractile muscle -tendon complex . A 
feature -encoded approach  was introduced  to enhance the training of the PI -PINN, which yield ed 
high motion prediction accuracy  and identif ied system parameters within a physiological range , 
with only a limited number of training samples . However, this method relies on mapping in a 
feature domain constituted by  Fouri er and polynomial bases , which require s the input sEMG signal 
to span over the entire duration of the motion . Thus , it prevents real-time predictions as the signal 
is obtained from the sensor.   
To enhance the predictive accuracy of the time-dependent signa ls, recurrent neural networks 
(RNNs) such as gated recurrent units (GRUs)  [29,53,54]  are utilized in this study to inform 
prediction s with the history information of the motion. To overcome the limitation of the size of  
4 the data  and provide more information from the composite frequency bands in the signal s, a multi -
resolution based (MR) approach  is proposed . Wavelets are used to decompose the raw sEMG  and 
joint motion signals into  coarse -scale components at various frequency sca les and the remaining 
fine-scale details . Using principles of multi -resolution theory  and transfer learning , multi -
resolution  training processes are repeated recursively from coarse -scale to  the full -scale to map the 
sEMG to the joint motion . To enhance the robustnes s and generalizability of the model , gaussian 
noise is introduced to the recorded  motion data  used for training  [29]. The trained model  can be 
applied for real-time motion  predictions  given  the raw sEMG signal obtained from the sensor . 
This manuscript  is organized as follows. Section 2 introduces the subsystems and mathematical 
formulations of MSK forward dynamics, followed by an introduction of the  proposed multi -
resolution PI-RNN  framework for simultaneous motion prediction and  system parameter 
identification  in Section 3 . The following sections  verify  the proposed framework  using synthetic 
data and validate  it by modeling the elbow flexion -extension movement using subject -specific 
sEMG signals and recorded motion data  in Sectio n 4 and 5 , respectively . Concluding remarks and 
future work are summarized  in Section 6 .  
 
2. Formulations for Muscle Mechanics  and Musculo skeletal Forward  
Dynamics  
This section provides a  brief  overview  of muscle mechanics and forward dynamics of the human 
MSK system , with details in Appendix A and B . As depicted  in Fig. 1, multiple subsystems within 
the MSK forward dynamics interact  hierarchically : 1) the neural excitation ùë¢(ùë°) transforms into 
muscle activation  ùëé(ùë°) (activation dynamics ); 2) Muscle activation  drives muscle fibers to produce 
force  ùêπùëÄùëá (muscle -tendon (MT) contraction dynamics ); 3) the result ant forces produce  joint 
motion q (translation and rotation) of MSK systems , called  the MSK forward  dynamics  [11,12,37] .  
5  
Fig. 1: The subsystems involved in the forward dynamics  of an MSK system are depicted in this 
flowchart . Neural excitations are  transmitted to muscle fibers (activation dynamics) that contract 
to produce force (muscle -tendon contraction  dynamics). These forces generate torques at the joints 
(structural level MSK dynamics) leading to joint motion  [1,55] . 
2.1 Neural Excitation -to-Activation Dynamics  
While a ctivations  ùëé(ùë°) in the muscle fibers  can be obtained  through  a non -linear transformation 
on neural excitations  ùë¢(ùë°), they are difficult to measure in-vivo. Therefore, the excitations are 
estimated from  [15,16]  the raw sEMG signals ùëí(ùë°) considering an electro -mechanical delay :  
 ùë¢(ùë°)=ùëí(ùë°‚àíùëë). (1) 
 
6 where ùëë measures the delay between the neural excitation originating and reaching the muscle 
group . The muscle activation signal ùëé(ùë°) is then expressed  as, 
 
ùëé(ùë°)=exp(ùê¥ùë¢(ùë°))‚àí1
exp(ùê¥)‚àí1 (2) 
where ùê¥ is a shape factor. These activations initiate muscle  fiber contraction leading to force 
production from the muscle group.  
 
2.2 Muscle -Tendon  Force Generation through Contraction Dynamics  
 
(a)                                                        (b) 
Fig. 2: A muscle -tendon complex in the arm modelled by  a homogenized hill-type model  where   
muscle group ‚Äôs in (a) are a homogenized muscle -tendon (MT) complex described by the model 
shown in (b).  
Forces in the muscle -tendon (MT) complex are generated  by the dynamics of MT contractions, 
where for structural length scale  behaviour of the  MT complex, homogenized  hill-type m uscle 
model s are utilized  (described in Appendix B)  . Each muscle group can be characterized by a 
parameter vector , 
 ùúø = [ùëô0ùëÄ,ùë£ùëöùëéùë•ùëÄ,ùëì0ùëÄ,ùëôùë†ùëá,ùúô0], (3) 
containing  constants such as  the maximum isometric force in the muscle ( ùëì0ùëÄ), the optimal muscle 
length (ùëô0ùëÄ) corresponding to the maximum isometric force, the maximum contraction velocity 
 
7 (ùë£ùëöùëéùë•ùëÄ), the slack length of the tendon ( ùëôùë†ùëá), and the initial pennation angle ( ùúô0) [56,57] . The total 
force produ ced by the MT complex, ùêπùëÄùëá, can be expressed as :  
 ùêπùëÄùëá(ùëé,ùëôÃÉùëÄ,ùë£ÃÉùëÄ,ùúô;ùúø)=ùêπùëÄ(ùëé,ùëôÃÉùëÄ,ùë£ÃÉùëÄ;ùúø)cosùúô. (4) 
where ùëé is the activation function in  Eq. (2), ùëôÃÉùëÄ is the normalized muscle length , ùë£ÃÉùëÄ is the 
normalized velocity of the muscle . In this study, the tendon is assumed to be rigid (ùëôùëá=ùëôùë†ùëá) which 
simplifies the MT contraction dynamics [58,59]  account ing for the interaction of the activation, 
force length , and force velocity properties of the MT complex. More details can be found i n 
Appendi ces A and B . 
2.3 MSK Forward Dynamics  of Motion  
Body m ovemen t is the result of the force produced by actuators (MT complexes), converted to 
torques at the joints of the body , leading to rotation and translation of joints , which are considered 
as the generalized degrees of freedom of an MSK system (ùíí). The dynamic equilibrium can be 
expressed as  
 ùë∞(ùíí) ùííÃà‚àíùëªùëÄùëá(ùíÇ,ùíí,ùííÃá;ùúø)‚àíùë¨(ùíí)=ùüé, (5) 
where ùíí,ùííÃá,ùííÃà are the vectors of generalized angular motion s, angular velocities, and angular 
accelerations, respectively; ùë¨(ùíí) is the torque from the external forces acting on the MSK system, 
e.g., ground reactions, gravitational loads etc.; ùë∞(ùíí) is the inertial matrix;  ùëªùëÄùëá is the torque  from  
all muscles in the model calculated by ùëªùëÄùëá(ùíÇ,ùíí,ùííÃá;ùúø)=ùëπ(ùíí)ùë≠ùëÄùëá(ùíÇ,ùíí,ùííÃá;ùúø),  where  ùëπ(ùíí) are 
the m oment arm ‚Äôs and ùë≠ùëÄùëá(ùíÇ,ùíí,ùííÃá;ùúø) are the forces from the MT complex . Given the muscle 
activation signals ùíÇ, initial conditions  and parameters of involved muscle groups  ùúø, the 
generalized angular motions  ùíí and angular velocities ùííÃá of the joints can be obtained by solving  
Eq. (5). An example of these vectors is shown in Section 4 and Appendix D.    
 
3. Multi -Resolution Recurrent Neural Network s for Physics -Informed  
Parameter Identification  
This section describes the recurrent neural network  algorithm s, followed by the physics -informed 
parameter identification  that enables the development  of a forward dynamics surrogate  and 
simultaneous parameter identification . The employment of multi -resolution analysis based on fast  
8 wavelet transform [60,61]  for training data augmentation is then defined . The computational 
framework for m ulti-resolution recurrent neural network for physics -informed parameter 
identification  is also discussed .  
3.1 Recurrent Neural Network s and Gated Recurrent Units   
 
Fig. 3: Computational graph of a standard recurrent neural netwo rk using ‚Äòm‚Äô history steps for 
prediction.  
The compu tational graph of a standard recurrent neural network  (RNN) and its unfolded graph is 
shown in  Fig. 3. The hidden state ùíâ allows for RNNs to learn important  history -dependent  features 
from the data  in sequential ti me steps [29,53,54] . The unfolded  graph shows  the sharing of 
parameters across the architecture of the network, allowing for efficient training.  The forward 
propagation  of an RNN starts with an initial hidden state  that embeds history -dependent features 
and propagates through all input steps . Considering an RNN with ùëö history steps  as shown in  Fig. 
3, the propagation of the hidden  state can be expressed as follows  [29]. 
 ùíâùëñ=ùëéùë°ùëéùëõ‚Ñé(ùëæ‚Ñé‚Ñéùíâùëñ‚àí1+ùëæùë•‚Ñéùíôùëñ+ùíÉ‚Ñé),    ùëñ=ùëõ‚àíùëö,‚Ä¶,ùëõ (6) 
 
The hidden state at the final (current)  step ùëõ is then used to inform  the prediction.  
 
 ùííÃÇùëõ=ùëæ‚Ñéùëûùíâùëõ+ùíÉùëû (7) 
Here, ùëéùë°ùëéùëõ‚Ñé is the hyperbolic tangent function ; ùëæùë•‚Ñé,ùëæ‚Ñé‚Ñé,  and ùëæ‚Ñéùëû are the trainable weight 
coefficients ; ùíÉ‚Ñé and ùíÉùëû are the trainable bias coefficients . The trainable parameters are shared 
 
9 across all RNN steps.  Let ùíôùëõ=[ùë°ùëõ,ùëíùëõ1,‚Ä¶,ùëíùëõùëÅùëé] be the  current  time and  current sEMG data of the 
ùëÅùëé muscle components and ùííÃÇùëõ be the predicted joint motion s at the current time ùë°ùëõ. Fig. 4(a) 
illustrates the computational graph of an RNN model trained to predict the motion at step ùëõ by 
using m history step s of ùíô and ùíí as well as the ùíô at step ùëõ. The forward propagation is defined as  
 ùíâùëñ=ùëéùë°ùëéùëõ‚Ñé(ùëæ‚Ñé‚Ñéùíâùëñ‚àí1+ùëæùë•‚Ñéùíôùëñ+ùëæùëû‚Ñéùííùëñ+ùíÉ‚Ñé), ùëñ=ùëõ‚àíùëö,‚Ä¶,ùëõ‚àí1 (8) 
 
 ùíâùëõ=ùëéùë°ùëéùëõ‚Ñé(ùëæ‚Ñé‚Ñéùíâùëõ‚àí1+ùëæùë•‚Ñéùíôùëõ+ùíÉ‚Ñé), (9) 
 
 ùííÃÇùëõ=ùëæ‚ÑéùëûÃÇùíâùëõ+ùíÉùëû (10) 
with trainable parameters including the weight coefficients ùëæ‚Ñé‚Ñé,ùëæùë•‚Ñé,ùëæùëû‚Ñé and ùëæ‚ÑéùëûÃÇ and bias 
coefficients ùíÉ‚Ñé and ùíÉùëû. During training, the ‚Äòteacher -forcing‚Äô method is used where the measured 
motion data is given to the model in the history steps. In test mode,  the model  is fed back to  the 
previous  predictions as input to inform  future predictions.  The inputs received in this  scenario 
could be quite different from those passed through in the training process, leading  the network to 
make extrapolative predictions and therefore, accumulate errors which  will pollute the predictions .   
To improve the testing performance and enhanc e model accuracy and robustness,  a user-controlled  
amount of  random Gaussian noise is added to the recorded  motion data to introduce stochasticity 
so that the network can learn variable input conditions, resembling those in the test mode , see [29] 
for deta ils. 
 
 
 
 
  
10  
                                   (a)                                                                              (b) 
Fig. 4: An example c omputational graph of an RNN that uses one history step : (a) The t rain mode  
and (b)  the test mode , where the motion predicted from the previous step is used as part of the 
input to predict motion at the current step . 
Standard RNNs , however, have difficulties in learning long -term dependencies due  to vanishing 
and exploding gradie nt issues  arising from the recurrent connections. To mitigate these issues, 
gated recurrent units (GRUs) have been developed [48,50].  A standard GRU consist s of a reset 
gate ùíìùëõ, that removes irrelevant history information, an update gate ùíñùëõ that controls the amount 
of history information that is passed to the next step, and a candidate hidden state ùíâÃÉùëõ that is used 
to calculate the current hidden state ùíâùëõ [53,62] . Consideri ng a GRU with  ùëö history step s, the 
forward propagation can be expressed as follows  [29]: 
 
ùíìùëñ=ùëéùúé(ùëæ‚Ñéùëüùíâùëñ‚àí1+ùëæùë•ùëüùíôùëñ+ùëæùëûùëüùííùëñ+ùíÉùëü)
ùíñùëñ=ùëéùúé(ùëæ‚Ñéùë¢ùíâùëñ‚àí1+ùëæùë•ùë¢ùíôùëñ+ùëæùëûùë¢ùííùëñ+ùíÉùë¢)
ùíõ(ùëñ,ùëñ‚àí1)=ùíìùëñ‚äôùëæ‚Ñé‚ÑéÃÉùíâùëñ‚àí1
ùíâÃÉùëñ=ùëéùë°ùëéùëõ‚Ñé(ùíõ(ùëñ,ùëñ‚àí1)+ùëæùë•‚ÑéÃÉùíôùëñ+ùëæùëû‚ÑéÃÉùííùëñ+ùíÉ‚ÑéÃÉ)
ùíÑ(ùëñ,ùëñ‚àí1)=ùíñùëñ‚äôùíâùëñ‚àí1
ùíÑÃÉ(ùëñ,ùëñ)=ùíñùëñ‚äôùíâÃÉùëñ
ùíâùëñ=ùíÑ(ùëñ,ùëñ‚àí1)+ùíâÃÉùëñ‚àíùíÑÃÉ(ùëñ,ùëñ)+ùíÉ‚Ñé 
‚àÄ ùëñ=ùëõ‚àíùëö,‚Ä¶,ùëõ‚àí1,  
 
(11) 
 
11  
ùíìùëõ=ùëéùúé(ùëæ‚Ñéùëüùíâùëõ‚àí1+ùëæùë•ùëüùíôùëõ+ùíÉùëü)
ùíñùëõ=ùëéùúé(ùëæ‚Ñéùë¢ùíâùëõ‚àí1+ùëæùë•ùë¢ùíôùëõ+ùíÉùë¢)
ùíõ(ùëõ,ùëõ‚àí1)=ùíìùëõ‚äôùëæ‚Ñé‚ÑéÃÉùíâùëõ‚àí1
ùíâÃÉùëõ=ùëéùë°ùëéùëõ‚Ñé(ùíõ(ùëõ,ùëõ‚àí1)+ùëæùë•‚ÑéÃÉùíôùëõ+ùíÉ‚ÑéÃÉ)
ùíÑ(ùëõ,ùëõ‚àí1)=ùíñùëõ‚äôùíâùëõ‚àí1
ùíÑÃÉ(ùëõ,ùëõ)=ùíñùëõ‚äôùíâÃÉùëõ
ùíâùëõ=ùíÑ(ùëõ,ùëõ‚àí1)+ùíâÃÉùëõ‚àíùíÑÃÉ(ùëõ,ùëõ)+ùíÉ‚Ñé  
 
(12) 
 
 ùííÃÇùëõ=ùëæ‚ÑéùëûÃÇùíâùëõ+ùíÉùëû (13) 
 
where ‚äô denotes the element -wise (Hadamard)  product; ùëéùúé(‚ãÖ) is the sigmoid activation function 
and ùëéùë°ùëéùëõ‚Ñé(‚ãÖ)  is the hyperbolic tangent function ; 
ùëæ‚Ñéùëü,ùëæùë•ùëü,ùëæùëûùëü,ùëæ‚Ñéùë¢,ùëæùë•ùë¢,ùëæùëûùë¢,   ùëæ‚Ñé‚ÑéÃÉ,ùëæùë•‚ÑéÃÉ,ùëæùëû‚ÑéÃÉ and ùëæ‚ÑéùëûÃÇ are the trainable weight coefficients; 
ùíÉùëü,ùíÉùë¢,ùíÉ‚ÑéÃÉ,ùíÉ‚Ñé and ùíÉùëû are the trainable bias coefficie nts. The current hidden state ùíâùëõ is calculated 
by a linear interpolation between the previous hidden state ùíâùëõ‚àí1 and the candidate hidden state ùíâÃÉùëõ, 
based on the update gate ùíñùëõ. The model is trained via the backpropagation through time algorithm 
applied to RNNs [21]. Training occurs  by plugging in the measured motion data in history steps 
(shown in Fig. 5), known as the teacher forcing procedure [21]. For predictions , the prediction 
from the previous step is used to predict the current step. The addition of gaussian noise to 
measured data , as described before,  is adopted in GRU models as well.    
12                                                                                                       
                                        (a)                                                                            (b) 
Fig. 5: An example computational graph of a GRU  in train  mode  that uses one history step : (a) 
Starting with an initial  or previously obtained  hidden state (ùíâùëõ‚àí2), the m ain GRU cell takes the 
input  ùíôùëõ‚àí1 and motion ùííùëõ‚àí1 that are used to obtain the GRU hidden state  ùíâùëõ‚àí1 at step ùëõ‚àí1 (Eq. 
(11))  and, (b) where the hidde n state  ùíâùëõ‚àí1 is plugged back in to the GRU along with input  ùíôùëõ at 
step ùëõ to predict the motion ùííÃÇùëõ (Eq. (12)-(13)). The ‚Äò+‚Äô cell produces an output  (arrow pointing 
outwards)  that is the summation of the inputs  (arrows pointing into the cell) .  
3.2 Simultaneous Forward Dynamics Learning and Parameter Identification  
With the governing equations for a general  MSK forward dynamics (Section 2.1), the following 
parameterized ODE  system  is defined  as 
 ùìõ[ùíí(ùë°);ùùÄ]=ùíî(ùë°;ùùé), ‚àÄ ùë°‚àà (0,T],ùìë[ùíí(0)]=ùíà , 
 (14) 
where the differential operator ùìõ[(‚ãÖ);ùùÄ] is parameterized by a set of parameters ùùÄ. The right -hand 
side ùíî(ùë°;ùùé) is parameterised by ùùé. ùìë[(‚ãÖ)] is the operator for initial conditions , and ùíà is the vector 
of prescribed initial conditions. To simpl ify notations, the ODE parameters are denoted by   ùúû=
{ùùÄ,ùùé}. The solution to the ODE system  ùíí:[0,ùëá]‚Üí‚Ñù depends on the choice of parameters ùúû. 
 
13 Here , an RNN  is used to relate data inputs  containing discrete sEMG signals and discrete time  
from all the ùëö previous history time -steps  of a trial , ‚à™ùëñ=ùëõ‚àíùëöùëõùíôùëñ‚àà‚Ñùùëõùëñùëõ,ùëö‚àà‚Ñ§+, to discrete joint 
motion data outputs  at the current time -step, ùííùëõ‚àà‚Ñù , approximat ing the MSK forward dynamics.  
Let the traini ng input at the ùëñùë°‚Ñé history step be defined as ùíôùëñ=[ùë°ùëñ,ùëíùëñ1,‚Ä¶,ùëíùëñùëÅùëé], where  ùë°ùëñ denote s 
the time at the ùëñùë°‚Ñé time step, and {ùëíùëñùëó}ùëó=1ùëÅùëé denotes the sEMG signals of ùëÅùëé muscle groups involved 
in the MSK joint motion  at ùë°ùëñ. The motion at time step ùëõ, is then predicted using the training input 
from all the previous ùëö steps using the RNN . 
 ùííÃÇùëõ(ùúΩ)=ùëìùëÖùëÅùëÅ(ùíôùëõ,ùíôùëõ‚àí1,ùííùëõ‚àí1,‚Ä¶,ùíôùëõ‚àíùëö,ùííùëõ‚àíùëö;ùúΩ) (15) 
 
where ùëìùëÖùëÅùëÅ denotes RNN evaluations  (depending on model chosen)  discussed  in Eq. (11)-(13). 
The optimal RNN  parameters ùúΩÃÉ and the ODE parameters ùúûÃÉ  are obtained by minimizing the 
composite loss function ùêΩ as follows , 
 ùúΩÃÉ,ùúû ÃÉ=argmin
ùúΩ,ùúû(ùêΩ)=argmin
ùúΩ,ùúû( ùêΩùëëùëéùë°ùëé+ùõΩ ùêΩùëüùëíùë†) (16) 
where ùõΩ is the parameter to regularize the loss contribution from the ODE residual term in the loss 
function and can be  estimated analytically  [1]. The data loss is defined by ,  
 
ùêΩùëëùëéùë°ùëé=1
ùëÅùëëùëéùë°ùëé‚àë‚ÄñùííÃÇùõº(ùúΩ)‚àíùííùõº‚Äñùêø22ùëÅùëëùëéùë°ùëé
ùõº=1 (17) 
where ùííÃÇùõº(ùúΩ) is the predicted motion , and ùííùõº is the recorded motion  of MSK joints . In addition to 
training a n MSK forward dynamics surrogate, the proposed framework aims to simultaneously 
identify important MSK parameters from the training data by minimizing residual of the governing 
equation of MSK system dynamics  in Eq. (5).  
 
ùêΩùëüùëíùë†=1
ùëÅùëëùëéùë°ùëé‚àë‚Äñùíì(ùííÃÇùõº(ùúΩ);ùúû)‚Äñùêø22ùëÅùëëùëéùë°ùëé
ùõº=1 
ùíì(ùííÃÇùõº(ùúΩ);ùúû)=ùìõ[ùííÃÇùõº(ùúΩ);ùùÄ]‚àíùíî(ùë°ùõº;ùùé) (18) 
   
where ùíì(ùííÃÇùõº(ùúΩ);ùúû)is the residual  associated with Eq. (14) for the ùõºùë°‚Ñé sample;  ùúû={ùùÄ,ùùé} 
represents the ODE parameters relevant to the MSK system.  The gradients of the network  outputs 
with respect to the network  parameters (ùúΩ), MSK parameters (ùúû), and inputs are needed in the  
14 loss function minimization  in Eq. (16), which  can be obtained efficiently by automatic 
differentiation [63]. The formulation  in Eq. (15) is general such that  more advanced RNN 
frameworks can be used such as the GRU described in Eq. (11)-(13). 
3.3 Multi -Resolution Training with Transfer Learning  
To improve the training efficiency of RNN  for MSK applications with mixed -frequency sEMG 
input signals and low -frequency output joint motion , a multi -resolution decomposition of the 
training input -output  data is introduced in Section  3.3.1, followed by the  transfer learning based  
multi -resolution  training protocols to be discussed in Section 3.3.2.  
3.3.1 Wavelet based Multi -Resolution Analysis  
Consider a sequence of nested subspaces ‚Ä¶‚äÇùëâ‚àí1‚äÇùëâ0‚äÇùëâ1‚äÇ‚ãØ‚äÇùêø2(ùëÖ) where  
‚ãÉùëâùëóùëó‚ààùíµ=ùêø2(ùëÖ), and ‚ãÇùëâùëóùëó‚ààùíµ=‚àÖ. Each subspace ùëâùëó of scale [ùëó] is spanned by a set  of scaling 
functions ùúôùëó,ùëò(ùë°), i.e.,  
ùëâùëó={ùúôùëó,ùëò(ùë°)|ùúôùëó,ùëò(ùë°)=2ùëó
2ùúô(2ùëóùë°‚àíùëò),ùëò‚ààùíµ} 
 
Each subspace is related to the finer subspace through the law of dilation i.e., if ùúô(ùë°)‚ààùëâùëó, then 
ùúô(2ùë°)‚ààùëâùëó+1,‚àÄùëó‚ààùíµ. Translations of the scaling function span the same subspace, i.e., if  ùúô(ùë°)‚àà
ùëâùëó,then ùúô(ùë°‚àíùëò)‚ààùëâùëó,‚àÄùëó,ùëò‚ààùíµ.  
A mutually orthogonal complement of ùëâùëó in ùëâùëó+1 is ùëäùëó, such that , 
 ùëâùëó+1=ùëâùëó‚äïùëäùëó,‚àÄùëó‚ààùíµ (19) 
where ‚äï is a direct sum. This subspace ùëäùëó is spanned by a set of wavelet functions ùúìùëó,ùëò(ùë°), i.e.,  
ùëäùëó={ùúìùëó,ùëò(ùë°)|ùúìùëó,ùëò(ùë°)=2ùëó
2ùúì(2ùëóùë°‚àíùëò),ùëò‚ààùíµ} 
where ùúì(ùë°) is the mother wavelet. It follows that , 
 ‚äïùëó‚ààùíµùëäùëó=ùêø2(ùëÖ) (20) 
and therefore,   
15  ùëâùëó=ùëâùëñ‚äï(‚äïùëò=0ùëó‚àíùëñ‚àí1ùëäùëñ+ùëò),ùëó>ùëñ.  (21) 
The two -scale dilation and translation relations for the scaling functions can be written as  
 
ùúô(ùë°)=‚àö2‚àëùëëùëòùúô(2ùë°‚àíùëò)‚àû
ùëò=‚àí‚àû. (22) 
Orthogonal wavelet functions can be obtained by imposing orthogonality conditions between 
scaling and wavelet functions in the frequency domain using Fourier transform,  
 
ùúì(ùë°)=‚àö2‚àë(‚àí1)ùëò‚àí1ùëë‚àíùëò‚àí1ùúô(2ùë°‚àíùëò)‚àû
ùëò=‚àí‚àû (23) 
where ùëëùëò is the coefficient.  
Orthogonal scaling functions can be constructed by choosing a candidate function ùúô‚àó(ùë°) such that 
ùúô‚àó(ùë°) have reasonable decay and a finite support. In addition, ‚à´ùúô‚àó(ùë°)ùëëùë°‚â†0. It should also sati sfy 
the two -scale relation , 
 ùúô‚àó(ùë°)=‚àëùëùùëòùúô‚àó(2ùë°‚àíùëò)
ùëò,ùëò‚ààùíµ. (24) 
With these, an orthogonal scaling function ùúô(ùë°) can be expressed in terms of ùúô‚àó(ùë°) as 
 
ùúô(ùë°)=‚àëùëéùëòùúô‚àó(ùë°‚àíùëò)‚àû
ùëò=‚àí‚àû. (25) 
It is then possible to define the scaling function at the coarse scale in terms of the scaling function 
at the fine scale and the wavelet functions at the coarser scale , 
 
ùúô(2ùë°‚àíùëô)=‚àëùëëùëô‚àí2ùëòùúô(ùë°‚àíùëò)+‚àë‚Ñéùëô‚àí2ùëòùúì(ùë°‚àíùëò),ùëô‚ààùíµ‚àû
ùëò=‚àí‚àû‚àû
ùëò=‚àí‚àû. (26) 
Any function can be approximated at scale  [ùëó] by using ùúôùëó,ùëò as a basis  as well as  using its coarse  
scale [ùëó‚àí1] representation and details at  the coarse scale , i.e.,   
16  
ùëÉùëóùëì=‚àëùëÜùëò[ùëó]ùúôùëó,ùëò‚àû
ùëò=‚àí‚àû=ùëÉùëó‚àí1ùëì +ùêªùëó‚àí1ùëì
=‚àëùëÜùëò[ùëó‚àí1]ùúôùëó‚àí1,ùëò‚àû
ùëò=‚àí‚àû+‚àëùëáùëò[ùëó‚àí1]ùúìùëó‚àí1,ùëò‚àû
ùëò=‚àí‚àû (27) 
where ùëÉùëó and ùêªùëó are the operators projecting ùëì onto the subspaces ùëâùëó and details of ùëì at scale [ùëó] in 
the orthogonal subspace ùëäùëó, respectively. ùëÜùëò[ùëó] and ùëáùëò[ùëó] are the corresponding basis coefficients  at 
the coarse scale [ùëó]. While the example shown here is for a one -dimensional case, t his multi -
resolution representation  can be extended to multi -dimension s. 
3.3.2 Multi -Resolution Data Representation  and Training Protocols  
In this approach, a  given signal ùëì(ùë°) is represented  using  the multi -resolution scaling functions 
and wavelets.  A scale [ùëó] representation of  signal  ùëì(ùë°) can be obtained from the scale [ùëü] (ùëó>ùëü) 
representation with the addition of wavelet components  (high frequency components) of the scales 
higher than [ùëü], using the discrete wavelet transform  modified from  Eq. (27),  
 
ùëÉùëóùëì(ùë°)=ùëÉùëüùëì(ùë°) +‚àëùêªùëèùëì(ùë°)ùëó‚àí1
ùëè=ùëü=‚àëùëÜùëò[ùëü]ùúôùëü,ùëò(ùë°)‚àû
ùëò=‚àí‚àû+‚àë‚àëùëáùëò[ùëè]ùúìùëè,ùëò(ùë°)‚àû
ùëò=‚àí‚àûùëó‚àí1
ùëè=ùëü 
 (28) 
where ùëÉùëü is the projection operator  at scale [ùëü] and ùêªùëè are the wavelet  projector s of the signal  that 
are added from scale [ùëü] to scale [ùëó‚àí1] to reconstruct the  signal at scale [ùëó]; ùëÜùëò[ùëü] and ùëáùëò[ùëè] are the 
scaling and wavelet function‚Äôs coefficients, obtained by the orthogonality condition  as given  in 
Section 3.3.1 .  
Using the Wavelet transform  to represent  a time series under multiple resolutions  offers advantages 
for feature extraction from signals. Compared to the Fourier transform which offers only  
localization in the  frequency domain , the Wavelet transform provides both frequency and time 
domain localization , making it more suitable for time history  (or sequence)  learning algorithms 
such as the standard RNN and its enhanced variant GRU. More specifically, one can enhance 
training  efficienc y by using a sequential training  strategy  for the time-history input (sEMG)  and 
output (joint motion)  data. Applying the Fast Wavelet Transform [57,58]  to obtain the in put and 
output  data from low to high resolutions  resul ts in better generalization performance of the RNN   
17 trained to map  from sEMG signals to joint motion time history  as described below . The second 
order Daubechies wavelets are used in this work.   
Here we consider a general MSK system described in Section 2. The original unfiltered data is 
denoted as  scale [0], which will be decomposed into a sequence of lower scales [‚àíùëó],ùëó‚àà‚Ñ§+ for 
multi -resolution training .  
Let ùë´[0] be the input training data at the full-scale  (ùëó=0) of the raw signals i.e.,  
 ùë´[0]=[ùíô1[0],ùíô2[0],‚Ä¶,ùíôùëÅùëëùëéùë°ùëé[0]], 
ùíôùëñ[0]=[ùë°ùëñ,ùëíùëñ1[0],‚Ä¶,ùëíùëñùëÅùëé[0]]. (29) 
and the  motion of joints of the  MSK system at the  ùëñùë°‚Ñé time-step at the full -scale (ùëó=0) is ùííùëñ[0] 
such that  the array of the unfiltered motion data for the duration  of the motion is  ùíí[0]=
[ùíí1[0],ùíí2[0],‚Ä¶ùííùëÅùëëùëéùë°ùëé[0]]. 
 From MR theory, subtracting details from the fine scale representations at the full-scale  of the 
signal , i.e., [0],  results in a course scale representation of the signal at scale [‚àíùëò],ùëò=1,‚Ä¶ùëó. The 
projected  training data at coarse scale [ -j] is defined as  
 ùë´[‚àíùëó]=[ùíô1[‚àíùëó],ùíô2[‚àíùëó],‚Ä¶,ùíôùëÅùëëùëéùë°ùëé[‚àíùëó]], (30) 
where ùëÅùëëùëéùë°ùëé is the total number of data points  and  
 ùíôùëñ[‚àíùëó]=[ùë°ùëñ,ùëíùëñ1[‚àíùëó],‚Ä¶,ùëíùëñùëÅùëé[‚àíùëó]], i=1‚Ä¶, ùëÅùëëùëéùë°ùëé (31) 
is the input data of scale [ -j] at time step ùëñ. The motion of the MSK joints at the  ùëñùë°‚Ñé time-step at 
the scale [‚àíùëó] is ùííùëñ[‚àíùëó]. The data sets  for a representative muscle group  ‚ÄòùëÄùëá‚Äô, ùëíùëñùëÄùëá[‚àíùëó] and motion  
ùííùëñ[‚àíùëó], are obtained from the original raw data ùëíùëñùëÄùëá[0] and ùííùëñ[0] by wavelet projection using  Eq. (27), 
that is,  
 ùëíùëÄùëá[‚àíùëó](ùë°)‚â°ùëÉùëóùëíùëÄùëá[0](ùë°)=ùëÉùëó‚àí1ùëíùëÄùëá[0](ùë°)+ùêªùëó‚àí1ùëíùëÄùëá[0](ùë°)
=ùëíùëÄùëá[0](ùë°)‚àí‚àëùêªùëèùëíùëÄùëá[0](ùë°)ùëó‚àí1
ùëè=0 (32)  
18 ùíí[‚àíùëó](ùë°)‚â°ùë∑ùëóùíí[0](ùë°)=ùë∑ùëó‚àí1ùíí[0](ùë°)+ùëØùëó‚àí1ùíí[0](ùë°)=ùíí[0](ùë°)‚àí‚àëùëØùëèùíí[0](ùë°)ùëó‚àí1
ùëè=0 
 
 
where ùë∑ùëó and ùëØùëó are the projection operators in multi -dimensions.  Hence, datasets that contain 
lower resolution representations of the original signal at scale s [0] can be expressed as: 
 ùë´[‚àíùëó]‚äÇùë´[‚àíùëó+1]‚äÇ‚ãØùë´[‚àí1]‚äÇùë´[0] 
ùíí[‚àíùëó]‚äÇùíí[‚àíùëó+1]‚äÇ‚ãØùíí[‚àí1]‚äÇùíí[0] (33) 
where ùíí[‚àíùëó]=[ùíí1[‚àíùëó],ùíí2[‚àíùëó],‚Ä¶,ùííùëÅùëëùëéùë°ùëé[‚àíùëó]]. 
Instead of learning the signal mapping from  input original raw sEMG data  ùë´[0] to motion data ùíí[0], 
we initiate  learn ing the mapping by starting from a coarse  scale representation of the input -output  
data at scale [‚àíùëó] and map ùë´[‚àíùëó] to ùíí[‚àíùëó]. For multi -resolution RNN, the init ial learning starts from 
the coarsest scale [‚àíùëó] as foll ows: 
 ùíâùëñ[ùëó]=ùëéùë°ùëéùëõ‚Ñé(ùëæ‚Ñé‚Ñé[‚àíùëó]ùíâùëñ‚àí1[‚àíùëó]+ùëæùë•‚Ñé[‚àíùëó]ùíôùëñ[‚àíùëó]+ùëæùëû‚Ñé[‚àíùëó]ùííùëñ[‚àíùëó]+ùíÉ‚Ñé[‚àíùëó]),  
‚àÄùëñ=ùëõ‚àíùëö,‚Ä¶,ùëõ‚àí1 (34) 
 ùíâùëõ[‚àíùëó]=ùëéùë°ùëéùëõ‚Ñé(ùëæ‚Ñé‚Ñé[‚àíùëó]ùíâùëõ‚àí1[‚àíùëó]+ùëæùë•‚Ñé[‚àíùëó]ùíôùëõ[‚àíùëó]+ùíÉ‚Ñé[‚àíùëó]), (35) 
 
 ùííÃÇùëõ[‚àíùëó]=ùëæ‚ÑéùëûÃÇ[‚àíùëó]ùíâùëõ‚àí1[‚àíùëó]+ùíÉùëû[‚àíùëó]. (36) 
 
 
At the next finer scale [‚àíùëó+1], the weights at scale [‚àíùëó] (using an early stopping [64]) are used 
as the initial values for ùëæ‚Ñé‚Ñé[‚àíùëó+1], ùëæùë•‚Ñé[‚àíùëó+1], ùëæùëû‚Ñé[‚àíùëó+1], ùëæ‚ÑéùëûÃÇ[‚àíùëó+1],ùíÉ‚Ñé[‚àíùëó],ùíÉùëû[‚àíùëó], similar to the concept of 
transfer learning [65]. 
Similarly, for multi -resolution GRU, the initial learning starts from the coarsest scale [‚àíùëó] as 
described in Appendix C. The s ame procedures to transfer the NN parameters  in Eq. (34)-(36) are 
repeate d with  [‚àíùëó]‚Üí[‚àíùëó+1] until it reaches scale [0]. To enhance model accuracy and 
robustness , variations based on Gaussian noise are added to the motion data  in each sequential step,  
as suggested by [29]. The sequential MR training process is described in Algorithm  1.   
19 Algorithm 1: Sequential Multi -Resolution PI-RNN  training process.  
Ste Step1: Initialize parameters.  
ùúΩ=ùúΩ0,ùúû=ùúû0 
Step 2: Sequential learning through parameter transfer from coarse -scale to fine -scale.  
For ùëô=0‚Üíùëó 
    1. Train the RNN on the dataset ùë´[‚àíùëó+ùëô] by calculating the predictions as  
ùííÃÇùëõ[‚àíùëó+ùëô](ùúΩ,ùúû)=ùëìùëÖùëÅùëÅ(ùíôùëõ[‚àíùëó+ùëô],ùíôùëõ‚àí1[‚àíùëó+ùëô],ùííùëõ‚àí1[‚àíùëó+ùëô],‚Ä¶,ùíôùëõ‚àíùëö[‚àíùëó+ùëô],ùííùëõ‚àíùëö[‚àíùëó+ùëô];ùúΩ,ùúû) 
                        ùëö‚Üí # of history steps   
                        ùëõ‚Üí current time step  
ùúΩÃÉ,ùúû ÃÉ=argmin
ùúΩ,ùúû(ùêΩ)=argmin
ùúΩ,ùúû( ùêΩùëëùëéùë°ùëé(ùúΩ)+ùõΩ ùêΩùëüùëíùë†(ùúΩ,ùúû)) 
    2. ùúΩ=ùúΩÃÉ,ùúû=ùúûÃÉ 
 
 
4. Verification  Example  
For verification of  the proposed MR PI-RNN framework , an elbow flexion -extension model [1] 
and s ynthetic sEMG signals with gaussian noise  and associated motion responses were considered . 
The flowchart  of the proposed computational framework for simultaneous forward dynamics 
prediction and parameter identification of MSK parameters is shown in Fig. 6.  
The model contai ned two rigid links corresponding to  the upper arm and forearm with lengths ùëôùë¢ùëé 
and ùëôùëìùëé, respectively . They wer e connected at a hinge resembling the elbow joint ‚ÄúA‚Äù, while the 
upper arm link was fixed at the top joint ‚ÄúB‚Äù, and the bicep s (Bi) and triceps  (Tri) muscle -tendon 
complex es (modeled by Hill-type model s with parameters ùúøùêµùëñ and ùúøùëáùëüùëñ) were represented by the 
lines connecting the links, as  shown in Fig. 6. The degree of freedom of the model was the elbow 
flexion angle ùëû. The mass in the forehand was  assumed to be  concentrated at the wrist location, 
hence, a mass ùëöùëìùëé was attached to one end of the forearm link with a moment ar m ùëôùëìùëé from the 
elbow joint. Tendons were assumed as rigid  [58] for ease of computation.  
  
20  
 
Fig. 6: An o verview of the application of this framework to the recorded motion data. The location 
of motion capture markers is circled in red and the sEMG sensor s on Biceps and Triceps muscle 
groups  in blue  and green , respectively . The simplified rigid body model was used in the forward 
dynamics equations within the framework with appropriately scaled anthropometric properties (for 
geometry) and physiological parameters (for muscle -tendon material models). The raw sEMG 
signals were mapped  to the  target  angular motion of the elbow  and used to simultaneously 
characterize the  MSK system using the proposed Multi -Resolution PI-RNN framework . 
 
The equation of motion for this rigid body system is given in Appendix D. Given the synthetic 
sEMG signals  (ùëíùêµùëñ(ùë°),ùëíùëáùëüùëñ(ùë°)), the initial conditions ùëû(0)=ùúã
6 radians  and ùëûÃá(0)=0 radians/
sec  and the parameters in Table 1, the motion of the elbow joint, ùëû, can be  obtained by solving 
the MSK forward dynamics problem using a  synthetic solver . 
 
21 Table 1: Parameters involved in the forward d ynamics setup of elbow flexion -extension motion . 
 
 
 
 
 
 
 Parameter  Type  Value  Parameter  Type  Value  
ùëô0,BiùëÄ Bicep s Muscle Model  0.6 m  ùëöùëìùëé Equation 
of motion  1.0 kg  
ùë£ùëöùëéùë•,ùêµùëñùëÄ Bicep s Muscle Model  6 m/sec ùëôùë¢ùëé Geometric  1.0 m  
ùëì0,BiùëÄ Bicep s Muscle Model  300 N  ùëôùëìùëé Geometric  1.0 m  
ùëôùë†,ùêµùëñùëá Bicep s Muscle Model  0.55 m  ùëô1,ùêµùëñ Geometric  0.3 m  
ùúôùêµùëñ Bicep s Muscle Model  0.0 
radians  ùëô2,ùêµùëñ Geometric  0.8 m  
ùëô0,TriùëÄ Triceps Muscle Model  0.4 m  ùëô1,ùëáùëüùëñ Geometric  0.2 m  
ùë£ùëöùëéùë•,ùëáùëüùëñùëÄ Triceps Muscle Model  4 m/sec ùëô2,ùëáùëüùëñ Geometric  0.7 m  
ùëì0,ùëáùëüùëñùëÄ Triceps Muscle Model  300 N  ùëë Activation 
Dynamics  0.08 sec  
ùëôùë†,ùëáùëüùëñùëá Triceps Muscle Model  0.33 m  
A Activation 
Dynamics  0.2 
ùúôùëáùëüùëñ Triceps Muscle Model  0.0 
radians  
  
22  
Fig. 7: The original ‚Äònoiseless ‚Äô input data set with the synthetic biceps and tricep s sEMG signals 
having variations in frequency for five trials  are shown at the top.  Increasing levels of noise are 
added to develop 3 cases of synthetic mixed frequency input sEMG , from which corresponding 
output motions are solved , using the forward dynamics equations. To verify  the MR framework , 
these  three cases  with their respective mixed frequency  input data  are then mapped to the ir 
corresponding  motion data . 
To verify  and check the robustness of the MR framework to different levels of noise in the input , 
the following test was performed. O riginally,  five synthetic samples i.e., Tria l's 1 to 5, of noiseless  
synthetic muscle sEMG signals  are assumed , as shown in Fig. 7. In practical applications, signals 
obtained from measurement devices  such as sEMG sensors  contain noise in their content. 
Therefore,  three cases were developed by adding Gaussian noise  (ùí©(ùúá,ùúé))  with zero mean  
(ùúá=0) and increasing  levels of  standard deviations  (ùúé) to the input  synthetic  sEMG signals  as 
mentioned in  Table 2. As the maximum value of the noiseless  sEMG signals is 1, the chosen ùúé's 
were kept within 10% - 20% of the signal maximum  for a reasonable level of noise . Then the 
corresponding  output  motions are generated by passing the noisy sEMG as input to the FD 
 
23 equations in Section 2.  The following training procedures were performed for each  of the three 
cases.  
1-scale  Training  
The mixed frequency  input sEMG signals  and corresponding output motion data ùíí at scale [0] , 
denoted by ùë´[0] and ùíí[0], respectively , are mapped to get a baseline performance. This is termed 
as 1-scale  training as only the full-scale  (i.e., [0]) of the mixed frequency  data is used for training.   
2-scale Training  
a. Initiate  learning from a coarse  scale representation of the mixed frequency  input data at 
scale [‚àí1] and map ùë´[‚àí1] to the corresponding motion data  at scale [ -1], ùíí[‚àí1], of that 
case. 
b. Transfer parameters  to the next scale training and finish the learning by mapping ùë´[0] to 
ùíí[0]. 
3-scale Training  
a. Start learning from a coarse  scale representation of the mixed frequency  input data at scale 
[‚àí2] and map ùë´[‚àí2] to the corresponding motion data  at scale [ -2] , ùíí[‚àí2], of that case .  
b. Transfer parameters  to the next scale training and continue learning by mapping ùë´[‚àí1] to 
ùíí[‚àí1]. 
c. Transfer parameters  to the next scale training and finish the learning by mapping ùë´[0] to 
ùíí[0]. 
Table 2: Input data and gaussian noise level for each case.  
Case ID  Input  Synthetic  sEMG data  + ùí©(ùúá,ùúé) 
1 Original + ùí©(0,0.1) 
2 Original + ùí©(0,0.15) 
3 Original + ùí©(0,0.2) 
  
24 For each case  and for each  of the training scale s in that case, the training data samples  contained 
the data of trial ‚Äôs 1, 2, 4, 5 while trial 3  was used for testing, each trial with ùëõ=500 data points.  
The MSK parameters ùúû={ùõ§ùëô}ùëô=14={ùëì0,ùêµùëñùëÄ,ùëô0,ùêµùëñùëÄ,ùëì0,ùëáùëüùëñùëÄ,ùëô0,ùëáùëüùëñùëÄ} were chosen  to be  identified from the 
training data using the proposed framework . Due to differences in  units and physiological nature 
of the parameters, the conditioning of the parameter identification system could be affected. To 
mitigate this issue, normalization [1,44]  was applied to  each of the parameters ,  
 ùõ§ÃÖùíç=ùõ§ùëô
ùõ§ùëô(0) (37) 
where ùõ§ùëô(0) was the initial value of the parameter. Therefore, the parameters to be identified 
became ùúûÃÖ={ùõ§ÃÖùëô}ùëô=14. 
The proposed  framework, as described in Section  3, was applied to each case to simultaneously 
learn the MSK forward dynamics surrogate and identify the MSK  parameters ùúûÃÖ by optimiz ing Eq. 
(16), where the residual of the governing equation  for the current time step ùëò, was expresse d as 
 ùëü(ùëûÃÇùëò[‚àíùëó](ùúΩùíí),ùëûÃÇÃáùëò[‚àíùëó](ùúΩùíí),ùëûÃÇÃàùëò[‚àíùëó](ùúΩùíí);ùúû(ùúûÃÖ;ùúû(0))) 
=ùêºùëûÃÇÃàùëò[‚àíùëó](ùúΩùíí)‚àíùê∏(ùëûÃÇùëò[‚àíùëó](ùúΩùíí))
‚àíùëáùëÄùëá(ùëéùêµùëñ(ùë°ùëò),ùëéùëáùëüùëñ(ùë°ùëò),ùëûÃÇùëò[‚àíùëó](ùúΩùíí),ùëûÃÇÃáùëò[‚àíùëó](ùúΩùíí);ùúû(ùúûÃÖ;ùúû(0)))   
(38) 
 
and is included in the residual term  ùêΩùëüùëíùë† in the loss function in Eq. (16). While the training happens 
sequentially  from coarse to fine -scales of the motion, the  final identification of parameters happens 
at the scale [0], i.e., the full-scale  in each of the 1 -, 2- and 3 -scale  MR training type s. 
 
A GRU  with 2 history steps, 1 hidden layer and 50 neurons in each layer was used . The training 
was performed using the Adam algorithm  [66] with a n initial  learning rate of 1√ó10‚àí3 and the 
penalty parameter for the  MSK residual term in the loss  function , ùõΩ‚àùŒîùë°2
ùêº=10‚àí3. Œîùë° is the time -
step between data points and ùêº is the moment of inertia  in Eq. (38). Multiple parameter 
initialization seeds were used for an averaged response of the MR training.   
25 To compare the  post-training  performance of 1-, 2- and 3-scale MR training‚Äôs, the average test ing 
mean squared error (MSE) and testing R2 scores were compared , where these measures for a single 
trial are defined as:   
 MSE=1
ùëõ‚Äñùíí‚àíùííÃÇ‚Äñùêø22 (39) 
 
 
 R2=1‚àí‚àë(ùëûùëñ‚àíùëûÃÇùëñ)2 ùëõ
ùëñ=1
‚àë(ùëûùëñ‚àíùëûÃÖ)2 ùëõ
ùëñ=1 (40) 
 
where ùíí is the  motion  data of the trial, ùííÃÇ is the trial‚Äôs predicted motion from the MR PI -RNN 
framework, and ùëûÃÖ is the mean of trial‚Äôs motion data  with ùëõ being the number of data points in the 
trial. At each epoch in the MR training,  the training loss  is calculated by using the  scale of the  
training data used in that training scale , i.e., scale [‚àíùëó] of the data is used in ùëó-scale training . 
The gradual im provement in these metrics is evident from Fig. 8 where , as further scales of 
information are added  and the training data is augmented , the generalization performance shows 
improvement from 1 -scale to 3 -scale . Overall,  it is noted that t he test metrics  such as  the MSE 
reduces, and the  R2 score  gets closer to one, indic ating an increase in the generalization accuracy  
as more traini ng scales are introduced . This can  be explained through the  theory of  bias-variance 
tradeoff ; training  on various scales of the data introduces more variance  to the training, helping 
the ML framework to  reduce the bias it develops  by just training on the full-scale  of the data.  
Together, this reduction in bias and growth in variance leads to a better generalization performance. 
Computationally , this method improves accuracy  in the same amount of training epochs  showing 
the efficiency  of this method . As generalization  predictions  post-training  are made using the full-
scale  of the data, there is no increase  in time  needed to perform the forward pass  for any scale .            
Meanwhile, the MSK parameters, ùëì0ùëÄ (maximum isometric force) and ùëô0ùëÄ (optimal muscle length 
corresponding to the maximum isometric force ), of both the biceps and the triceps were accurately 
identified from the motion data, as shown in  Table 3. Compared with the parameter identification  
from our previou s work  [1] where in addition to ùëì0ùëÄ, the maximum contraction velocity ùë£ùëöùëéùë•ùëÄ was 
independently identified , due to non -convergence of ùëô0ùëÄ by the time -domain and feature -encoded  
26 trainings , the proposed method  can accurately identify ùëô0ùëÄ. ùë£ùëöùëéùë•ùëÄ can then by obtain by the 
experiment ally obs erved  relationship of  ùë£ùëöùëéùë•ùëÄùëô0ùëÄ‚ÅÑ=10ùë†‚àí1 [58,67] . 
For the identification of optimal muscle length parameters (ùëô0ùëÄ), the initial points need to be chosen 
with respect to constraints applied by the geometry of the MSK system . The errors reported in 
Table 3 are calculated by taking  the average  of the percentage error  of the identified  MSK  
parameters from the  3-scale training  with the multiple  parameter  (ùúΩ,ùúû) initializations . It was 
observed that in MSK parameter identification , similar  accura cy in  characterization was obtained 
from  all training scale approaches  used within each case , with errors less than 1% . This  indicat es 
that the MR PI -RNN i mproves  the generalization performance of the motion prediction , without 
loss in parameter identification accuracy.   
 
Fig. 8:  The training loss and testing metrics  are shown.  The shaded area in the loss  and average 
test MSE and R2 score figures is one standard deviation from the mean (solid line). As more scales 
of data are introduced in the MR training, the average Test MSE and R2 score  calculated post-
training improve in each case.  
 
 
27 Table 3: The average percentage error  (shown as mean ¬± standard deviation ) between predicted  
and true values of the parameters  for 3-scale training for each case  from multiple initialization 
points . 
Parameter  Case 1  Case 2  Case 3  
ùëì0,ùêµùëñùëÄ 0.50¬±0.02 0.50¬±0.01 0.37¬±0.04 
ùëì0,ùëáùëüùëñùëÄ 0.06¬±0.02 ‚àí0.04¬±0.02 ‚àí0.02¬±0.03 
ùëô0,ùêµùëñùëÄ 0.10¬±0.03 0.10¬±0.02 0.05¬±0.05 
ùëô0,ùëáùëüùëñùëÄ ‚àí0.06¬±0.07 ‚àí0.05¬±0.02 ‚àí0.03¬±0.10 
 
5. Validation : Elbow Flexion -Extension Motion  
5.1 Application of MR  PI-RNN  method to Subject -Specific Data  
The recorded motion data  and sEMG  signals were  collected  and processed  as per the data 
acquisition protocols mentioned in  [1]. Three elbow  flexion -extension motion trials were 
performed by the  subject , with the sEMG sensors placed on  the biceps and triceps  muscle groups . 
The processed  sEMG signals were transformed as described in Section  2.1 to obtain muscle 
activation signals , used to calculate the MSK forward dynamics ODE residual . The same  
simplified rigid body model  was used as in Section  4 and appropriately scaled anthropometric 
properties (for the geometry  of the model ) and physiological parameters (for muscle -tendon 
material model s used for the muscle groups ) based on the generic upper body model defined in 
[68,69]  were used . Fig. 9 shows the measured data of the thr ee trials, including the transient raw 
sEMG signals and the corresponding angular motion of the elbow flexion -extension of the subject . 
 
Fig. 9: The measured raw sEMG signa ls and the corresponding angular motion of the elbow 
flexion -extension of the subject  are plotted . 
 
28 In this example, the raw sEMG signals were used as input . A 5-scale  MR training procedure as 
described in Section 4 was used on a GRU with 1 hidden layer with 50 neurons. The data of trials 
1 and 3 were used for training , while trial 2 was used for testing , where  each signal contained 500 
temporal data poi nts.  
5.1.1 Parameter Identification   
The muscle parameters to be identified by the framework include the maximum isometric force 
and the optimal muscle length from both muscle groups, which are denoted as  ùúû=
{ùëì0,ùêµùëñùëÄ,ùëô0,ùêµùëñùëÄ,ùëì0,ùëáùëüùëñùëÄ,ùëô0,ùëáùëüùëñùëÄ}. It was observed  in our tests  that despite  the normalization  process  
described in Eq. (37) and (38), the parameters obtained at the end of the MR training  with motion 
data either diverged or converged to non -physiological values. T o obtain physio logically 
consistent parameters, we use the values obtained from literature studies and constrain the space 
of parameter search  [44]. 
Let the  parameter to be identified be defined as  
 
ùõ§ùëô(ùùç)=1
ùëÅ‚àëùõæÃÖùëüsig(ùúìùëü)ùëÅ
ùëü=1,ùùç=[ùúì1,ùúì2,‚Ä¶,ùúìùëÅ] (41) 
 
where ùõæÃÖùëü is the value defined in  the ùëüùë°‚Ñé literature  study and ùúìùëü is the parameter to be optimized in 
the training such that it can be used to evaluate the sigmoid  function  sig(ùúìùëü) and ùùç is the vector 
of these trainable parameters . Using the optimized ùùç, the desired MSK parameters can be 
estimated.  This formulation constrains the identified parameters  to be consistent  with parameters 
obtained through experimental studies [68‚Äì70].      
The proposed  framework was then applied to simul taneously learn the MSK forward dynamics 
surrogate and identify the MSK parameters ùúû by optimiz ing Eq. (16), where the residual of the 
governing equation  for the current time step ùëò, was expresse d as 
 ùëü(ùëûÃÇùëò[‚àíùëó](ùúΩùíí),ùëûÃÇÃáùëò[‚àíùëó](ùúΩùíí),ùëûÃÇÃàùëò[‚àíùëó](ùúΩùíí);ùúû(ùùç)) 
=ùêºùëûÃÇÃàùëò[‚àíùëó](ùúΩùíí)‚àíùê∏(ùëûÃÇùëò[‚àíùëó](ùúΩùíí))‚àíùëáùëÄùëá(ùëéùêµùëñ(ùë°ùëò),ùëéùëáùëüùëñ(ùë°ùëò),ùëûÃÇùëò[‚àíùëó](ùúΩùíí),ùëûÃÇÃáùëò[‚àíùëó](ùúΩùíí);ùúû(ùùç))   
(42) 
  
29 and could be plugged into the residual term ùêΩùëüùëíùë† in the loss function such that the optimization 
problem becomes , 
 ùúΩÃÉ,ùùçÃÉ=argmin
ùúΩ,ùùç(ùêΩùëëùëéùë°ùëé(ùúΩ)+ùõΩùêΩùëüùëíùë†(ùúΩ,ùùç)). (43) 
As mentioned in the verification example  (Section 4) , the final parameter identification happens 
at the full-scale , i.e., at  [0]. 
 
5.2 Results  
The training was performed using the Adam algorithm [66] with an initial learning rate of 
1√ó10‚àí3 and 4 history steps were considered . Multiple parameter initialization seeds were used 
for an averaged response of the MR training. To quantify  the err or in th e testing predictions, a 
normalized mean squared error was defined,  
 NMSE=1
ùëõ‚àë(ùëûùëñ‚àíùëûÃÇùëñ)2 ùëõ
ùëñ=1
‚àë(ùëûùëñ‚àíùëûÃÖ)2 ùëõ
ùëñ=1 (44) 
 
where ùëûùëñ is the  ùëñùë°‚Ñé target  motion  data point , ùëûùëñÃÇ is the ùëñùë°‚Ñé predicted motion data point , from the MR 
PI-RNN framework, and ùëûÃÖ is the mean of target  motion data.  The R2 score was calculated using 
the metric defined in Eq. (40). From  Fig. 10, Fig. 11 and Table 4, it is clear that addition of training 
scales leads to improved motion predictions . The multi-resolution training leads to an increase in 
average  test R2 score  of more than 4 0% (bringing it closer to one ), averaged over multiple 
initialization seeds . With the addition of more scales , Fig. 10 clearly shows the progression in 
improvement of the predictions as more scales are involved in the training.   
  
30  
Fig. 10: Comparison of test predictions post-training for each MR training scale performed.  The 
solid dash line is the mean of the prediction s post -training  when various  initialization points are 
utilized to begin the  MR training , with shaded region indicating one standard deviation from the 
mean. 
 
Fig. 11: The test normalized mean squared error (NMSE)  and test R2 score are plot for the testing 
predictions  post-training , averaged over multiple initialization seeds . The mean of the metric is the 
solid marker line, the sha ded portion being one standard deviation from the mean.  
 
 
 
 
31 Table 4: The t est metrics such as NMSE and R2 score averaged over multiple initialization seeds , 
for the various training scales involved  are reported here . The % decrease in average NMSE and % 
increase in average R2 w.r.t 1 -scale training are shown in the 3rd and 5th columns respectively . 
Training 
Scale  Avg. Test 
NMSE  Decrease (%) in Avg. 
Test NMSE  w.r.t 1 -scale 
Training  Avg. Test ùêëùüê 
Score Increase  (%) in Avg. 
Test ùêëùüê score  w.r.t 1 -
Scale training  
1 8.00E -04 - 0.599  - 
2 5.74E -04 28% 0.713  19% 
3 4.14E -04 48% 0.793  32% 
4 2.33E -04 71% 0.884  47% 
 
The identified MSK parameters from  the MR PI-RNN training are summarized in  Table 5 with 
the mean of the final converged values  of ùëì0ùëÄ and ùëô0ùëÄ obtained from multiple parameter 
initializations  at 4-scale training , consistent with  the physiological estimates of these param eters 
reported in literature [68‚Äì70]. ùëô0,ùêµùëñùëÄ is slightly outside the estimated range, which could be 
attributed to t he variance in population . Similar values were obtained across all scales of training  
hence parameters obtained from a representative 4-scale training are shown here . The results 
demonstrate d the effectiveness of the proposed MR PI -RNN  framework and promising potential 
for real applications.  
Table 5: The identified parameter estimates using MR PI -RNN  training , and their values reported 
in literature [68‚Äì70]. 
 
Parameter  Identified values  Estimates from 
literature  
ùëì0,ùêµùëñùëÄ (N) 348.23¬±0.2 158.4 -845 
ùëô0,ùêµùëñùëÄ (m) 0.108¬±0.001 0.115-0.142 
ùëì0,ùëáùëüùëñùëÄ (N) 758.36¬±0.5 554.4-2332.916  
ùëô0,ùëáùëüùëñùëÄ (m) 0.069¬±0.001 0.067 -0.087   
32  
6. Discussion and Conclusion s 
In this work,  we proposed a  multi -resolution physics -informed recurrent neural  network  (MR PI-
RNN ) for an application to MSK systems , for time-domain motion prediction and parameter 
identification . A GRU with a physics -informed loss function that minimized the error in the 
training data and the residual of the MSK forward dynamics equilibrium was used for this purpose. 
Wavelet based multi -resolution techniques were used to decompose the input sEMG signals  and 
output joint motion data  into coarse -scale approximations at different scales and fine -scale details  
at those scales. The  sEMG and joint motion multi -scale components were then mapped to  each 
other  starting from a chosen coarse -scale  components and then sequentially train ed (via transfer 
learning)  to higher scales, completing the training on the full-scale  of the data .    
By initializing training on the coarse -scale of the  training data, the optimization reaches a local 
minim um that serves as a better initialization state for the training data that includes the  sequential  
fine-scale details.  The proposed transfer -learning based sequential training scheme  can be used  for 
learning datasets that have high frequency  signals  as shown in the verification example with 
synthetic  mixed frequency  sEMG data . The numerical examples show an improvement in  testing 
prediction and identifying the parameters . We observe from the loss profiles that the test ing loss 
decrease d while the training loss increased as more scales of data were brought in. It was also 
observed that the average test MSE and R2 metrics showed a clear  improvement in the 
generalization accuracy. These phenomena can be  explain ed through the theory of bias -variance 
tradeoff; training on various scales of the data introduces more variance to the training, helping 
the ML framework to reduce the bias it develops by just training on the full-scale  of the data. 
Computationally , it is noted that the proposed method achieves  improved accuracy by using the 
same amount of training epochs.  
The proposed MR framework was validated on recorded sEMG and motion data  from a subject  [1] 
and significant improvement s were observed in the testing prediction accuracy , with 1 -scale 
training often leading to large errors . The predicted motion at higher training scales showed 
improvements across all initialization points used , indicating the robustness of the method.  The 
ident ified parameters were also consistent with the  physiological range  observed in literature .   
33 This method also has the advantage of operating in the time -domain as compared to the feature -
encoded (FE) trainin g [1], where the input sEMG signals were projected on to the frequency 
domain using the Fourier basis. In the FE training, to make a prediction, the input signal for the 
entire duration of the movement  prediction  was needed whereas  the physics informed MR training  
of the RNN enables the trained model to make  real-time predictions by using the information of 
the previous time -steps  and the current sEMG signal . In addition, for mixed frequency signals, 
wavelet resolution can better capture  the local frequenc y information as compared to the Fourier 
basis which captures the global frequency information.   
This method is presented as a general  case where multi -resolution is applied to both input and 
output . For some applications , for e.g., those  that require only data mapping, the MR training can 
be applied by only considering the decomposition to the input , keeping the output at the full -scale 
(i.e., scale [0]) throughout , or vice versa . To further improve this method , we can consider the use 
of multi -resolution as activation functions of the ML framework, instead of relying on data 
filtration processes  for better computational efficiency . This method will also be tested on other  
physics -informed ML techniques to solve forward problems with  PDEs having  mixed frequency 
source terms .  
 
7. Acknowledgment   
The support of this work by the National Institute of Health under grant number 5R01AG056999 -
04 to K. Taneja & J. S. Chen are very much appreciated.  
 
8. References  
[1] Taneja, K., He, X., He, Q., Zhao, X., Lin, Y. -A., Loh, K. J., and Chen, J. -S., 2022, ‚ÄúA 
Feature -Encoded Physics -Informed Parameter Identification Neural Network for 
Musculoskeletal Systems,‚Äù J. Biomech. Eng., 144(12).  
[2] Costello, Z., and Martin, H. G., 2 018, ‚ÄúA Machine Learning Approach to Predict Metabolic 
Pathway Dynamics from Time -Series Multiomics Data,‚Äù npj Syst Biol Appl, 4(1), pp. 1 ‚Äì
14. 
[3] Damle, C., and Yalcin, A., 2007, ‚ÄúFlood Prediction Using Time Series Data Mining,‚Äù 
Journal of Hydrology, 333(2), pp. 305 ‚Äì316.  
34 [4] Nishino, T., and Hokugo, A., 2020, ‚ÄúA Stochastic Model for Time Series Prediction of the 
Number of Post -Earthquake Fire Ignitions in Buildings Based on the Ignition Record for 
the 2011 Tohoku Earthquake,‚Äù Earthquake Spectra, 36(1), pp.  232‚Äì249. 
[5] Manevitz, L., Bitar, A., and Givoli, D., 2005, ‚ÄúNeural Network Time Series Forecasting of 
Finite -Element Mesh Adaptation,‚Äù Neurocomputing, 63, pp. 447 ‚Äì463. 
[6] Frank, R. J., Davey, N., and Hunt, S. P., ‚ÄúTime Series Prediction and Neural Netwo rks.‚Äù  
[7] L√§ngkvist, M., Karlsson, L., and Loutfi, A., 2014, ‚ÄúA Review of Unsupervised Feature 
Learning and Deep Learning for Time -Series Modeling,‚Äù Pattern Recognition Letters, 42, 
pp. 11 ‚Äì24. 
[8] Calder√≥n -Mac√≠as, C., Sen, M. K., and Stoffa, P. L., 2000, ‚Äú Artificial Neural Networks for 
Parameter Estimation in Geophysics,‚Äù Geophysical Prospecting, 48(1), pp. 21 ‚Äì47. 
[9] Hubbard, S. S., and Rubin, Y., 2000, ‚ÄúHydrogeological Parameter Estimation Using 
Geophysical Data: A Review of Selected Techniques,‚Äù Journal of Contaminant Hydrology, 
45(1), pp. 3 ‚Äì34. 
[10] Ebrahimian, H., Astroza, R., and Conte, J. P., 2015, ‚ÄúExtended Kalman Filter for Material 
Parameter Estimation in Nonlinear Structural Finite Element Models Using Direct 
Differentiation Method,‚Äù Earthquake En gineering & Structural Dynamics, 44(10), pp. 
1495 ‚Äì1522.  
[11] Haghighat, E., Raissi, M., Moure, A., Gomez, H., and Juanes, R., 2021, ‚ÄúA Physics -
Informed Deep Learning Framework for Inversion and Surrogate Modeling in Solid 
Mechanics,‚Äù Comput. Methods Appl. Mech. Eng., 379, p. 113741.  
[12] Heine, C. B., and Menegaldo, L. L., 2018, ‚ÄúNumerical Validation of a Subject -Specific 
Parameter Identification Approach of a Quadriceps Femoris EMG -Driven Model,‚Äù Medical 
Engineering & Physics, 53, pp. 66 ‚Äì74. 
[13] Hirschvog el, M., Bassilious, M., Jagschies, L., Wildhirt, S. M., and Gee, M. W., 2017, ‚ÄúA 
Monolithic 3D -0D Coupled Closed -Loop Model of the Heart and the Vascular System: 
Experiment -Based Parameter Estimation for Patient -Specific Cardiac Mechanics,‚Äù 
International J ournal for Numerical Methods in Biomedical Engineering, 33(8), p. e2842.  
[14] Schmid, H., Nash, M. P., Young, A. A., and Hunter, P. J., 2006, ‚ÄúMyocardial Material 
Parameter Estimation ‚ÄîA Comparative Study for Simple Shear,‚Äù Journal of Biomechanical 
Engineer ing, 128(5), pp. 742 ‚Äì750. 
[15] Pau, J. W. L., Xie, S. S. Q., and Pullan, A. J., 2012, ‚ÄúNeuromuscular Interfacing: 
Establishing an EMG -Driven Model for the Human Elbow Joint,‚Äù IEEE Trans. Biomed. 
Eng., 59(9), pp. 2586 ‚Äì2593.  
[16] Zhao, Y., Zhang, Z., Li, Z.,  Yang, Z., Dehghani -Sanij, A. A., and Xie, S., 2020, ‚ÄúAn EMG -
Driven Musculoskeletal Model for Estimating Continuous Wrist Motion,‚Äù IEEE Trans. 
Neural Syst. Rehabil. Eng., 28(12), pp. 3113 ‚Äì3120.  
[17] Kian, A., Pizzolato, C., Halaki, M., Ginn, K., Lloyd, D.,  Reed, D., and Ackland, D., 2019, 
‚ÄúStatic Optimization Underestimates Antagonist Muscle Activity at the Glenohumeral 
Joint: A Musculoskeletal Modeling Study,‚Äù J. Biomech., 97, p. 109348.  
[18] Buchanan, T. S., Lloyd, D. G., Manal, K., and Besier, T. F., 200 4, ‚ÄúNeuromusculoskeletal 
Modeling: Estimation of Muscle Forces and Joint Moments and Movements from 
Measurements of Neural Command,‚Äù J. Appl. Biomech., 20(4), pp. 367 ‚Äì395. 
[19] Lloyd, D. G., and Besier, T. F., 2003, ‚ÄúAn EMG -Driven Musculoskeletal Model to 
Estimate Muscle Forces and Knee Joint Moments in Vivo,‚Äù J. Biomech., 36(6), pp. 765 ‚Äì
776.  
35 [20] Buongiorno, D., Barsotti, M., Barone, F., Bevilacqua, V., and Frisoli, A., 2018, ‚ÄúA Linear 
Approach to Optimize an EMG -Driven Neuromusculoskeletal Model for Movem ent 
Intention Detection in Myo -Control: A Case Study on Shoulder and Elbow Joints,‚Äù Front. 
Neurorobot., 12, p. 74.  
[21] Goodfellow, I., Bengio, Y., and Courville, A., 2016, Deep Learning , MIT Press, 
Cambridge, MA, USA.  
[22] Kaneko, S., Wei, H., He, Q., Che n, J.-S., and Yoshimura, S., 2021, ‚ÄúA Hyper -Reduction 
Computational Method for Accelerated Modeling of Thermal Cycling -Induced Plastic 
Deformations,‚Äù J. Mech. Phys. Solids, 151, p. 104385.  
[23] Kim, B., Azevedo, V. C., Thuerey, N., Kim, T., Gross, M., and Solenthaler, B., 2019, 
‚ÄúDeep Fluids: A Generative Network for Parameterized Fluid Simulations,‚Äù Comput. 
Graph. Forum, 38(2), pp. 59 ‚Äì70. 
[24] Xie, X., Zhang, G., and Webster, C., 2019, ‚ÄúNon -Intrusive Inference Reduced Order Model 
for Fluids Using Deep Multi step Neural Network,‚Äù Mathematics, 7(8), p. 757.  
[25] Fries, W., He, X., and Choi, Y., 2022, ‚ÄúLaSDI: Parametric Latent Space Dynamics 
Identification,‚Äù arXiv:2203.02076 [cs, math].  
[26] He, X., Choi, Y., Fries, W. D., Belof, J., and Chen, J. -S., 2022, ‚ÄúGLaS DI: Parametric 
Physics -Informed Greedy Latent Space Dynamics Identification,‚Äù arXiv:2204.12005 
[physics].  
[27] Ghaboussi , J., Garrett, J. H., and Wu, X., 1991, ‚ÄúKnowledge‚ÄêBased Modeling of Material 
Behavior with Neural Networks,‚Äù J. Eng. Mech. - ASCE, 117(1), pp. 132 ‚Äì153. 
[28] Lefik, M., Boso, D. P., and Schrefler, B. A., 2009, ‚ÄúArtificial Neural Networks in 
Numerical Model ling of Composites,‚Äù Comput. Methods Appl. Mech. Eng., 198(21), pp. 
1785 ‚Äì1804.  
[29] He, X., and Chen, J. -S., 2022, ‚ÄúThermodynamically Consistent Machine -Learned Internal 
State Variable Approach for Data -Driven Modeling of Path -Dependent Materials,‚Äù 
Comput.  Methods Appl. Mech. Eng., 402, p. 115348.  
[30] Kirchdoerfer, T., and Ortiz, M., 2017, ‚ÄúData Driven Computing with Noisy Material Data 
Sets,‚Äù Comput. Methods Appl. Mech. Eng., 326, pp. 622 ‚Äì641. 
[31] Eggersmann, R., Kirchdoerfer, T., Reese, S., Stainier, L. , and Ortiz, M., 2019, ‚ÄúModel -Free 
Data -Driven Inelasticity,‚Äù Comput. Methods Appl. Mech. Eng., 350, pp. 81 ‚Äì99. 
[32] He, Q., and Chen, J. -S., 2020, ‚ÄúA Physics -Constrained Data -Driven Approach Based on 
Locally Convex Reconstruction for Noisy Database,‚Äù Comp ut. Methods Appl. Mech. Eng., 
363, p. 112791.  
[33] He, X., He, Q., Chen, J. -S., Sinha, U., and Sinha, S., 2020, ‚ÄúPhysics -Constrained Local 
Convexity Data -Driven Modeling of Anisotropic Nonlinear Elastic Solids,‚Äù DCE, 1, p. e19.  
[34] He, Q., Laurence, D. W. , Lee, C. -H., and Chen, J. -S., 2021, ‚ÄúManifold Learning Based 
Data -Driven Modeling for Soft Biological Tissues,‚Äù J. Biomech., 117, p. 110124.  
[35] Bahmani, B., and Sun, W., 2022, ‚ÄúManifold Embedding Data -Driven Mechanics,‚Äù J. Mech. 
Phys. Solids, 166, p. 10 4927.  
[36] Carrara, P., De Lorenzis, L., Stainier, L., and Ortiz, M., 2020, ‚ÄúData -Driven Fracture 
Mechanics,‚Äù Comput. Methods Appl. Mech. Eng., 372, p. 113390.  
[37] He, X., He, Q., and Chen, J. -S., 2021, ‚ÄúDeep Autoencoders for Physics -Constrained Data -
Driven Nonlinear Materials Modeling,‚Äù Comput. Methods Appl. Mech. Eng., 385, p. 
114034.   
36 [38] Raissi, M., Perdikaris, P., and Karniadakis, G. E., 2019, ‚ÄúPhysics -Informed Neural 
Networks: A Deep Learning Framework for Solving Forward and Inverse Problems 
Involvi ng Nonlinear Partial Differential Equations,‚Äù J. Comput. Phys., 378, pp. 686 ‚Äì707. 
[39] Karniadakis, G. E., Kevrekidis, I. G., Lu, L., Perdikaris, P., Wang, S., and Yang, L., 2021, 
‚ÄúPhysics -Informed Machine Learning,‚Äù Nat. Rev. Phys., 3(6), pp. 422 ‚Äì440. 
[40] He, Q., and Tartakovsky, A. M., 2021, ‚ÄúPhysics‚ÄêInformed Neural Network Method for 
Forward and Backward Advection‚ÄêDispersion Equations,‚Äù Water Resour. Res., 57(7). 
[41] Zhu, Q., Liu, Z., and Yan, J., 2021, ‚ÄúMachine Learning for Metal Additive Manufacturing: 
Predicting Temperature and Melt Pool Fluid Dynamics Using Physics -Informed Neural 
Networks,‚Äù Comput. Mech., 67(2), pp. 619 ‚Äì635. 
[42] Xu, K., Tartakovsky, A. M., Burgha rdt, J., and Darve, E., 2021, ‚ÄúLearning Viscoelasticity 
Models from Indirect Data Using Deep Neural Networks,‚Äù Comput. Methods Appl. Mech. 
Eng., 387, p. 114124.  
[43] Tartakovsky, A. M., Marrero, C. O., Perdikaris, P., Tartakovsky, G. D., and Barajas -Solano , 
D., 2020, ‚ÄúPhysics -Informed Deep Neural Networks for Learning Parameters and 
Constitutive Relationships in Subsurface Flow Problems,‚Äù Water Resour. Res., 56(5), p. 
e2019WR026731.  
[44] He, Q., Stinis, P., and Tartakovsky, A. M., 2022, ‚ÄúPhysics -Constrained  Deep Neural 
Network Method for Estimating Parameters in a Redox Flow Battery,‚Äù J. Power Sources, 
528, p. 231147.  
[45] He, Q., Barajas -Solano, D., Tartakovsky, G., and Tartakovsky, A. M., 2020, ‚ÄúPhysics -
Informed Neural Networks for Multiphysics Data Assimi lation with Application to 
Subsurface Transport,‚Äù Adv. Water Resour., 141, p. 103610.  
[46] Kissas, G., Yang, Y., Hwuang, E., Witschey, W. R., Detre, J. A., and Perdikaris, P., 2020, 
‚ÄúMachine Learning in Cardiovascular Flows Modeling: Predicting Arterial Bl ood Pressure 
from Non -Invasive 4D Flow MRI Data Using Physics -Informed Neural Networks,‚Äù 
Comput. Methods Appl. Mech. Eng., 358, p. 112623.  
[47] Sahli Costabal, F., Yang, Y., Perdikaris, P., Hurtado, D. E., and Kuhl, E., 2020, ‚ÄúPhysics -
Informed Neural Netwo rks for Cardiac Activation Mapping,‚Äù Front. Phys., 8. 
[48] Alber, M., Buganza Tepole, A., Cannon, W. R., De, S., Dura -Bernal, S., Garikipati, K., 
Karniadakis, G., Lytton, W. W., Perdikaris, P., Petzold, L., and Kuhl, E., 2019, ‚ÄúIntegrating 
Machine Learning  and Multiscale Modeling ‚ÄîPerspectives, Challenges, and Opportunities 
in the Biological, Biomedical, and Behavioral Sciences,‚Äù npj Digit. Med., 2(1), pp. 1 ‚Äì11. 
[49] Yazdani, A., Lu, L., Raissi, M., and Karniadakis, G. E., 2020, ‚ÄúSystems Biology Informed 
Deep Learning for Inferring Parameters and Hidden Dynamics,‚Äù PLOS Comput. Biol., 
16(11), p. e1007575.  
[50] Zhang, J., Zhao, Y., Bao, T., Li, Z., Qian, K., Frangi, A. F., Xie, S. Q., and Zhang, Z. -Q., 
2022, ‚ÄúBoosting Personalised Musculoskeletal Modelling with  Physics -Informed 
Knowledge Transfer,‚Äù arXiv:2211.12315.[eess.SP].  
[51] Bartsoen, L., Faes, M. G. R., Andersen, M. S., Wirix -Speetjens, R., Moens, D., Jonkers, I., 
and Sloten, J. V., 2023, ‚ÄúBayesian Parameter Estimation of Ligament Properties Based on 
Tibio-Femoral Kinematics during Squatting,‚Äù Mech. Syst. Signal Process., 182, p. 109525.  
[52] Linden, N. J., Kramer, B., and Rangamani, P., 2022, Bayesian Parameter Estimation for 
Dynamical Models in Systems Biology , Systems Biology.  
[53] Chung, J., Gulcehre, C., Cho, K., and Bengio, Y., 2014, ‚ÄúEmpirical Evaluation of Gated 
Recurrent Neural Networks on Sequence Modeling.‚Äù   
37 [54] Lipton, Z. C., Berkowitz, J., and Elkan, C., 2015, ‚ÄúA Critical Review of Recurrent Neural 
Networks for Sequence Learning,‚Äù arXiv:1506.00 019 [cs].  
[55] Hamner, S. R., Seth, A., and Delp, S. L., 2010, ‚ÄúMuscle Contributions to Propulsion and 
Support during Running,‚Äù J Biomech, 43(14), pp. 2709 ‚Äì2716.  
[56] Zhang, Y., Chen, J., He, Q., He, X., Basava, R. R., Hodgson, J., Sinha, U., and Sinha, S., 
2020, ‚ÄúMicrostructural Analysis of Skeletal Muscle Force Generation during Aging,‚Äù Int. J. 
Numer. Methods Biomed. Eng., 36(1). 
[57] Chen, J. -S., Basava, R. R., Zhang , Y., Csapo, R., Malis, V., Sinha, U., Hodgson, J., and 
Sinha, S., 2016, ‚ÄúPixel -Based Meshfree Modelling of Skeletal Muscles,‚Äù Comput. Methods 
Biomech. Biomed. Eng. Imaging Vis., 4(2), pp. 73 ‚Äì85. 
[58] Millard, M., Uchida, T., Seth, A., and Delp, S. L., 201 3, ‚ÄúFlexing Computational Muscle: 
Modeling and Simulation of Musculotendon Dynamics,‚Äù J. Biomech. Eng., 135(2), p. 
021005.  
[59] Winters, J. M., 1990, ‚ÄúHill -Based Muscle Models: A Systems Engineering Perspective,‚Äù 
Multiple Muscle Systems , Springer New York,  New York, NY, pp. 69 ‚Äì93. 
[60] Mallat, S. G., 1989, ‚ÄúMultiresolution Approximations and Wavelet Orthonormal Bases of L 
2 (R),‚Äù Trans. Am. Math. Soc., 315(1), p. 69.  
[61] Mallat, S. G., 1989, ‚ÄúA Theory for Multiresolution Signal Decomposition: The Wavelet 
Representation,‚Äù IEEE Trans. Pattern Anal. Mach. Intell., 11(7), pp. 674 ‚Äì693. 
[62] Cho, K., van Merrienboer, B., Bahdanau, D., and Bengio, Y., 2014, ‚ÄúOn the Properties of 
Neural Machine Translation: Encoder -Decoder Approaches.‚Äù  
[63] Baydin, A. G., Pearlmutt er, B. A., Radul, A. A., and Siskind, J. M., 2018, ‚ÄúAutomatic 
DiÔ¨Äerentiation in Machine Learning: A Survey,‚Äù J. Mach. Learn. Res., 18, p. 43.  
[64] Yao, Y., Rosasco, L., and Caponnetto, A., 2007, ‚ÄúOn Early Stopping in Gradient Descent 
Learning,‚Äù Constr Appr ox, 26(2), pp. 289 ‚Äì315. 
[65] Weiss, K., Khoshgoftaar, T. M., and Wang, D., 2016, ‚ÄúA Survey of Transfer Learning,‚Äù J. 
Big Data, 3(1), p. 9.  
[66] Kingma, D. P., and Ba, J., 2017, ‚ÄúAdam: A Method for Stochastic Optimization,‚Äù 
arXiv:1412.6980 [cs].  
[67] Thelen , D. G., 2003, ‚ÄúAdjustment of Muscle Mechanics Model Parameters to Simulate 
Dynamic Contractions in Older Adults,‚Äù J. Biomech. Eng., 125(1), pp. 70 ‚Äì77. 
[68] Garner, B. A., and Pandy, M. G., 2003, ‚ÄúEstimation of Musculotendon Properties in the 
Human Upper L imb,‚Äù Ann. Biomed. Eng., 31(2), pp. 207 ‚Äì220. 
[69] Holzbaur, K. R. S., Murray, W. M., and Delp, S. L., 2005, ‚ÄúA Model of the Upper 
Extremity for Simulating Musculoskeletal Surgery and Analyzing Neuromuscular Control,‚Äù 
Ann. Biomed. Eng., 33(6), pp. 829 ‚Äì840. 
[70] An, K. N., Hui, F. C., Morrey, B. F., Linscheid, R. L., and Chao, E. Y., 1981, ‚ÄúMuscles 
across the Elbow Joint: A Biomechanical Analysis,‚Äù J. Biomech., 14(10), pp. 659 ‚Äì669. 
 
Appendix A: Muscle -Tendon  Force Generation  
The total muscle force ùêπùëÄ can b e expressed as  
 ùêπùëÄ(ùëé,ùëôÃÉùëÄ,ùë£ÃÉùëÄ;ùúø)=ùëì0ùëÄ(ùëìùê¥(ùëé,ùëôÃÉùëÄ,ùë£ÃÉùëÄ;ùúø)+ùëìùëÉ(ùëôÃÉùëÄ;ùúø)), (45)  
38 where ùëìùëÉ(ùëôÃÉùëÄ) is the passive muscle length dependent force generation function.  The active force 
ùëìùê¥ component can be expressed as : 
 ùëìùê¥(ùëé,ùëôÃÉùëÄ,ùë£ÃÉùëÄ;ùúø)=ùëéùëìùê¥,ùêø(ùëôÃÉùëÄ;ùúø)ùëìùëâ(ùë£ÃÉùëÄ;ùúø), 
ùëôÃÉùëÄ=ùëôùëÄùëô0ùëÄ‚ÅÑ,  
ùë£ÃÉùëÄ=ùë£ùëÄùë£ùëöùëéùë•ùëÄ‚ÅÑ , (46) 
where ùëé is the activation function in  Eq. (2), ùëôÃÉùëÄ is the normalized muscle length , ùë£ÃÉùëÄ is the 
normalized velocity of  the muscle . The total length of the MT system ùëôùëÄùëá is given by , 
 ùëôùëÄùëá=ùëôùëÄcosùúô+ùëôùëá. (47) 
Given the current joint angle ùëû and the angular velocity ùëûÃá, the current length, ùëôùëÄùëá of the MT 
system can be calculated using trigonometric relations.  
The ùëìùê¥,ùêø(ùëôÃÉùëÄ) and ùëìùëâ(ùë£ÃÉùëÄ)  are generic function s of the  length and velocity dependent  force 
generation  properties of the  active  muscle , represented by dimensionless quantities . In this study, 
the tendon is assumed to be rigid (ùëôùëá=ùëôùë†ùëá). The total force produced by the MT complex, ùêπùëÄùëá, 
can be expressed as :  
 ùêπùëÄùëá(ùëé,ùëôÃÉùëÄ,ùë£ÃÉùëÄ,ùúô;ùúø)=ùêπùëÄ(ùëé,ùëôÃÉùëÄ,ùë£ÃÉùëÄ;ùúø)cosùúô. (48) 
The rigid -tendon model simplifies the MT contraction dynamics [57,58]  which accounts for the 
interaction of the activation, force length , and force velocity properties of the MT complex.  
Appendix B. Hill -Type Muscle Models   
For the length dependent muscl e force relations, this work uses the equations given in [56]. The 
active muscle force dependent on variation in length is given as  
 
ùëìùê¥,ùêø(ùëôÃÉùëÄ)=
{  9(ùëôÃÉùëÄ‚àí0.4)2,ùëôÃÉùëÄ‚â§0.6
1‚àí4(1‚àíùëôÃÉùëÄ)2,0.6‚â§ùëôÃÉùëÄ‚â§1.4 
9(ùëôÃÉùëÄ‚àí1.6)2,ùëôÃÉùëÄ>1.4 (49)  
39  ùëìùëÉ(ùëôÃÉùëÄ)
={0,ùëôÃÉùëÄ‚â§1
ùõæ1(exp(ùõæ2(ùëôÃÉùëÄ‚àí1))‚àí1),1‚â§ùëôÃÉùëÄ‚â§1.4 
(ùõæ1ùõæ2exp(0.4ùõæ2))ùëôÃÉùëÄ+ùõæ1((1‚àí1.4ùõæ2)exp(0.4ùõæ2)‚àí1),ùëôÃÉùëÄ>1.4 (50) 
Where ùõæ1=0.075 and ùõæ2=6.6 correspond to parameters in the passive muscle force model 
related to an adult human. The muscle force velocity relationship ùëìùëâ(ùë£ÃÉùëÄ) is used directly from 
[67]. 
Appendix C: Multi -Resolution GRU Formulation  
For multi -resolution GRU, the initial learning starts from the coarsest scale [‚àíùëó] as follows  with 
notations according to Section 3.3.2 , 
 
ùíìùëñ[‚àíùëó]=ùëéùúé(ùëæ‚Ñéùëü[‚àíùëó]ùíâùëñ‚àí1[‚àíùëó]+ùëæùë•ùëü[‚àíùëó]ùíôùëñ[‚àíùëó]+ùëæùëûùëü[‚àíùëó]ùííùëñ[‚àíùëó]+ùíÉùëü[‚àíùëó])
ùíñùëñ[‚àíùëó]=ùëéùúé(ùëæ‚Ñéùë¢[‚àíùëó]ùíâùëñ‚àí1[‚àíùëó]+ùëæùë•ùë¢[‚àíùëó]ùíôùëñ[‚àíùëó]+ùëæùëûùë¢[‚àíùëó]ùííùëñ[‚àíùëó]+ùíÉùë¢[‚àíùëó])
ùíâÃÉùëñ[‚àíùëó]=ùëéùë°ùëéùëõ‚Ñé(ùíìùëñ[‚àíùëó]‚äôùëæ‚Ñé‚ÑéÃÉ[‚àíùëó]ùíâùëñ‚àí1[‚àíùëó]+ùëæùë•‚ÑéÃÉ[‚àíùëó]ùíôùëñ[‚àíùëó]+ùëæùëû‚ÑéÃÉ[‚àíùëó]ùííùëñ[‚àíùëó]+ùíÉ‚ÑéÃÉ[‚àíùëó])
ùíâùëñ[‚àíùëó]=ùíñùëñ[‚àíùëó]‚äôùíâùëñ‚àí1[‚àíùëó]+(ùüè‚àíùíñùëñ[‚àíùëó])‚äôùíâÃÉùëñ[‚àíùëó]+ùíÉ‚Ñé[‚àíùëó] 
‚àÄ ùëñ=ùëõ‚àíùëö,‚Ä¶,ùëõ‚àí1, (51) 
 
ùíìùëõ[‚àíùëó]=ùëéùúé(ùëæ‚Ñéùëü[‚àíùëó]ùíâùëõ‚àí1[‚àíùëó]+ùëæùë•ùëü[‚àíùëó]ùíôùëõ[‚àíùëó]+ùíÉùëü[‚àíùëó])
ùíñùëõ[‚àíùëó]=ùëéùúé(ùëæ‚Ñéùë¢[‚àíùëó]ùíâùëõ‚àí1[‚àíùëó]+ùëæùë•ùë¢[‚àíùëó]ùíôùëõ[‚àíùëó]+ùíÉùë¢[‚àíùëó])
ùíâÃÉùëõ[‚àíùëó]=ùëéùë°ùëéùëõ‚Ñé(ùíìùëõ[‚àíùëó]‚äôùëæ‚Ñé‚ÑéÃÉ[‚àíùëó]ùíâùëõ‚àí1[‚àíùëó]+ùëæùë•‚ÑéÃÉ[‚àíùëó]ùíôùëõ[‚àíùëó]+ùíÉ‚ÑéÃÉ[‚àíùëó])
ùíâùëõ[‚àíùëó]=ùíñùëõ[‚àíùëó]‚äôùíâùëõ‚àí1[‚àíùëó]+(ùüè‚àíùíñùëõ[‚àíùëó])‚äôùíâÃÉùëõ[‚àíùëó] +ùíÉ‚Ñé[‚àíùëó]  (52) 
 ùííÃÇùëõ[‚àíùëó]=ùëæ‚ÑéùëûÃÇ[‚àíùëó]ùíâùëõ[‚àíùëó]+ùíÉùëû[‚àíùëó] (53) 
where  the weights  ùëæ‚Ñéùëü[‚àíùëó],ùëæùë•ùëü[‚àíùëó],ùëæùëûùëü[‚àíùëó],ùëæ‚Ñéùë¢[‚àíùëó],ùëæùë•ùë¢[‚àíùëó],ùëæùëûùë¢[‚àíùëó],ùëæ‚Ñé‚ÑéÃÉ[‚àíùëó],ùëæùë•‚ÑéÃÉ[‚àíùëó],ùëæùëû‚ÑéÃÉ[‚àíùëó] and biases 
ùíÉùëü[‚àíùëó],ùíÉùë¢[‚àíùëó],ùíÉ‚ÑéÃÉ[‚àíùëó],ùíÉ‚Ñé[‚àíùëó],ùíÉùëû[‚àíùëó] are trainable parameters.   
40 Appendix D: Equation of Motion of the Simplified MSK Model  
The equation of motion for th e rigid body system  used in Section 4 is, 
 ùêºùëûÃà=ùê∏(ùëû)+ùëáùëÄùëá(ùëéùêµùëñ,ùëéùëáùëüùëñ,ùëû,ùëûÃá;ùúøùêµùëñ,ùúøùëáùëüùëñ) 
 (54) 
where,  
  ùêº=ùëöùëìùëéùëôùëìùëé2 
 (55) 
 ùê∏(ùëû)=‚àíùëöùëìùëéùëîùëôùëìùëésin(ùëû) 
 (56) 
 ùëáùëÄùëá(ùëéùêµùëñ,ùëéùëáùëüùëñ,ùëû,ùëûÃá;ùúøùêµùëñ,ùúøùëáùëüùëñ)=ùëáùêµùëñùëÄùëá(ùëéùêµùëñ,ùëû,ùëûÃá;ùúøùêµùëñ)‚àíùëáùëáùëüùëñùëÄùëá(ùëéùëáùëüùëñ,ùëû,ùëûÃá;ùúøùëáùëüùëñ) (57) 
 
ùëáùêµùëñùëÄùëá(ùëéùêµùëñ,ùëû,ùëûÃá;ùúøùêµùëñ)=ùêπùêµùëñùëÄùëá(ùëéùêµùëñ,ùëôÃÉùêµùëñùëÄ,ùë£ÃÉùêµùëñùëÄ,ùëôÃÉùêµùëñùëá;ùúøùêµùëñ)ùëô2,ùêµùëñsin(ùëû)ùëô1,ùêµùëñ
ùëôùêµùëñùëÄùëá(ùëû) (58) 
 
ùëáùëáùëüùëñùëÄùëá(ùëéùëáùëüùëñ,ùëû,ùëûÃá;ùúøùëáùëüùëñ)=ùêπùëáùëüùëñùëÄùëá(ùëéùëáùëüùëñ,ùëôÃÉùëáùëüùëñùëÄ,ùë£ÃÉùëáùëüùëñùëÄ,ùëôÃÉùëáùëüùëñùëá;ùúøùëáùëüùëñ)ùëô2,ùëáùëüùëñsin(ùëû)ùëô1,ùëáùëüùëñ
ùëôùëáùëüùëñùëÄùëá(ùëû). (59) 
 
 
 