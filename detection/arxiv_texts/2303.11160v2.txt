Noname manuscript No.
(will be inserted by the editor)
Explaining Recommendation System Using
Counterfactual Textual Explanations
Niloofar Ranjbar ·Saeedeh Momtazi* ·
MohammadMehdi Homayoonpour
the date of receipt and acceptance should be inserted later
Abstract Currently,thereisasignificantamountofresearchbeingconducted
in the field of artificial intelligence to improve the explainability and inter-
pretability of deep learning models. It is found that if end-users understand
the reason for the production of some output, it is easier to trust the system.
Recommender systems are one example of systems that great efforts have been
conducted to make their output more explainable. One method for producing
a more explainable output is using counterfactual reasoning, which involves
altering minimal features to generate a counterfactual item that results in
changing the output of the system. This process allows the identification of
input features that have a significant impact on the desired output, leading
to effective explanations. In this paper, we present a method for generating
counterfactual explanations for both tabular and textual features. We eval-
uated the performance of our proposed method on three real-world datasets
and demonstrated a +5% improvement on finding effective features (based on
model-based measures) compared to the baseline method.
Keywords Explainable Recommendation ·Counterfactual Explanation ·
Machine Learning ·Explainable AI ·Recommender Systems
Niloofar Ranjbar
Computer Engineering Department
Amirkabir University of Technology (Tehran Polytechnic)
E-mail: nranjbar@aut.ac.ir
Saeedeh Momtazi
Computer Engineering Department
Amirkabir University of Technology (Tehran Polytechnic)
E-mail: momtazi@aut.ac.ir
MohammadMehdi Homayounpour
Computer Engineering Department
Amirkabir University of Technology (Tehran Polytechnic)
E-mail: homayoun@aut.ac.irarXiv:2303.11160v2  [cs.IR]  1 Jun 20232 Niloofar Ranjbar et al.
1 Introduction
Deep neural models are commonly used in a variety of tasks, such as health-
care, decision support systems, and credit risk assessments. However, there is
a growing need to ensure the trustworthiness and reliability of these models
to make fair and robust decisions.
Recommendation systems aim to predict a score that a user would give to
an item, and then suggest the top-ranked items to the user. It is difficult for
users to understand why the system is suggesting a particular item, which can
make it difficult for them to trust the system’s recommendations. Additionally,
understanding the reasoning behind a recommendation can help developers
debug the system. As a result, this motivated researchers to focus on the
explainability of recommendation system outputs.
In this paper, we propose a feature-based method for predicting item scores
using a matrix of features. For users, this matrix is based on the items they
have interacted with. We then use a deep neural model to predict the score
that a new user would give to an item based on these features.
Some methods extract different aspects of an item from user reviews and
use these aspects as features. However, as many features may not be imme-
diately mentioned in user reviews, we also utilize metadata from the items’
descriptions to extract additional features. This allows for a combination of
continuous, categorical, and textual features to be used for training the model.
Inspired by counterfactual explanation generation methods, we introduce
methodsthatusecostfunctionstoidentifyandhighlightthefeaturesthathave
the greatest impact on the predicted item score. For example, if a particular
mobile phone is predicted to have a high score, these methods can identify the
features that contributed to this high score, such as the model, battery, RAM,
and camera. In one of these methods, we employ the Gumbel Softmax trick ,
allowing us to consider all types of important features (continuous, categorical,
and textual) simultaneously. To the best of our knowledge, this is the first time
that all types of features have been simultaneously included in counterfactual
explanations.
It is worth noting that we have chosen to use counterfactual explanation
generation methods, as they have been shown to be more understandable to
humans and more closely align with human thought processes, according to
Yang et al. (2020).
Ourpapermakesseveralcontributionstothefieldofrecommendersystems:
–We introduce a novel feature-based method for predicting item scores,
which allows for a combination of continuous, categorical, and textual fea-
tures to be used for training.
–We modify the counterfactual explanation generation method proposed by
Tan et al. (2021) to enable it to generate explanations when raw text is
used as a feature in a recommender system.
–We propose a new counterfactual explanation generation method that uti-
lizes a genetic algorithm to generate explanations when raw text is used as
a feature.Explaining Recommendation System Using Counterfactual Textual Explanations 3
–Weintroduceacounterfactualexplanationgenerationmethodbasedonthe
Gumbel-softmax method, which can generate explanations when all types
offeatures(continuous,categorical,andtextual)areusedinarecommender
system.
These contributions can have practical applications in various domains.
The paper is structured as follows: in Section 2, we review related works
in counterfactual explanations and explainable recommendations. In Section
3, we introduce our three explanation generation methods, which include
CountER, Genetic algorithm, and Gumbel-Softmax based method. In Section
4, we describe the experiments we conducted to evaluate the different meth-
ods. We then present the results of our experiments on the Amazon and Yelp
datasets. Finally, in Section 5, we conclude with a discussion of our findings
and suggestions for future work.
2 Related Works
As we introduce a counterfactual explanation method and test it for a recom-
mendation system, we divide the related works into two categories: counter-
factual explanation methods applied to text, and explainable recommendation
systems. Our method represents a novel combination of counterfactual expla-
nations and recommendation systems, and we expect it to be of interest to
researchers and practitioners in both fields.
2.1 Related works in Counterfactual explanations
In simple terms, a counterfactual explanation for a prediction identifies the
smallest alteration that can be made to the input features to produce a de-
sired or predefined outcome instead of the predicted one(Molnar, 2022). There
have been many efforts to apply counterfactual explanations to textual data.
In such cases, the explanations should appear natural to humans. Simply re-
moving words from the text to generate counterfactual explanations is not
effective. Yang et al. (2020) addressed this issue by ensuring that replaced
words are grammatically correct. They demonstrate their approach on a sen-
timent analysis task, introducing two lists of words: one containing words that
are suitable for replacement based on grammar, and another containing words
with opposite senses to those in the sentiment dictionary. They then identi-
fied the intersection of these two lists and replaced words in the main text
with words from this intersection until the predicted class was changed. This
approach helps to generate counterfactual explanations that are more under-
standable to humans.
Many works have addressed the issue of generating natural-sounding coun-
terfactual explanations in text using language representation models such as
BERT (Devlin et al., 2018). Fern and Pope (2021) proposed one example of
such an approach. They first generated a candidate set of words to replace4 Niloofar Ranjbar et al.
each word in the text. They then used BERT as a language model to de-
termine the probability of each candidate token for a given position. In the
second step, they found the best combination of changes using shapley values
(Kalai and Samet, 1987) and generated the explanations using beam search.
This approach allows the generation of more coherent and understandable
counterfactual explanations in text.
The proposed models by Madaan et al. (2021) and Wu et al. (2021) both
generated counterfactual explanations in a conditional manner using GPT2.
Madaan et al. (2021) defines named-entity tags, semantic role labels, or senti-
mentsasconditionsforthewords,whileWuetal.(2021)controlsthetypesand
locations of perturbations in the text. Both approaches allow more targeted
and controlled generation of counterfactual explanations in text.
Using pre-trained language models to generate alternative texts as adver-
sarial examples for text has become a popular approach in recent years. As
the goal of generating adversarial examples is similar to that of generating
counterfactual explanations (i.e., minimally changing the input text to change
the prediction class), works in this direction can be considered related to our
approach. Guo et al. (2021) attempted to generate the most probable sentence
using BERT as a language model, while Garg and Ramakrishnan (2020) and
Li et al. (2020) used BERT to suggest word replacements. These works demon-
strate the utility of language models in generating alternative text that can
fool prediction models.
There are many tasks, such as recommendations and healthcare, that in-
volve hybrid data comprising text, continuous features, and categorical fea-
tures. To generate counterfactual explanations for this type of data, a method
thatcanhandlealldatatypessimultaneouslyisneeded.Noneofthepreviously
mentioned methods address this issue. In this paper, we propose a method to
address this issue and generate counterfactual explanations for hybrid data.
2.2 Related works in Explainable Recommendations
There have been numerous efforts to make recommender systems more ex-
plainable. One approach involves extracting various aspects of items from user
reviews and using them as input features for black-box models. After training
the black-box model, the goal is to identify the minimal set of features that are
most important in ranking items for a particular user. Zhang et al. (2014) em-
ployed matrix factorization to achieve this, while Chen et al. (2016) and Wang
et al. (2018a) used tensor factorization instead. Other works have utilized
counterfactual reasoning to generate explanations. For example, Zhou et al.
(2021) employed three strategies to make white-box, gray-box, and black-box
models explainable by using attention weights, adversarial and counterfactual
perturbations, and extracting aspects from user reviews as features. Ghazi-
matin et al. (2020) attempted to find the minimal set of user actions, such as
ratings, that would cause a recommended item to change when removed. Tan
et al. (2021) introduced an aspect-based recommender system and attemptedExplaining Recommendation System Using Counterfactual Textual Explanations 5
to make it explainable through the use of counterfactual reasoning by trying to
solve a joint optimization problem that minimally changes item aspects such
that the new item is no longer recommended. Pan et al. (2021) attempted to
map uninterpretable features to interpretable ones by minimizing both predic-
tion and interpretation loss.
On the other hand, Wang et al. (2018b) argued that tree-based models are
interpretable and neural-based models have acceptable results in recommender
systems. Therefore, proposed combining these two types of models to create
an explainable recommender system.
Other works have utilized knowledge graphs to make recommender systems
more explainable. For example, Wang et al. (2020) attempted to represent
knowledge-graph paths with the semantic information of entities and their
relations in order to make recommendations generated by the knowledge graph
more explainable. Syed et al. (2022) used first-order logic to generate triples
from users’ complex queries and then tried to find entities that satisfy these
logicalqueriesusingaknowledgegraph.Theseentitiesweresortedbasedonthe
information they captured from the context, and explanations were generated
using the triples. Shimizu et al. (2022) introduced a knowledge graph attention
network that used side information of items to make recommendations and
generate explanations. Geng et al. (2022) trained a language model on the
paths of a knowledge graph consisting of entities and edges, which were based
on user actions and item features as well as the relationships between them.
Explanations were generated using the resulting graph.
While many of the explanations generated through these methods can help
users understand why an item is recommended to them, they do not necessar-
ily assist sellers and managers in better satisfying their users. Counterfactual
explanations, on the other hand, can provide sellers and managers with infor-
mation about which features of items need to be changed in order to more
effectively recommend them to users. In this paper, we utilize counterfactual
reasoning to generate accurate, trustworthy, and comprehensive explanations.
3 Explanation generation methods
In this section we introduce three methods to generate explanations.
3.1 CountER
Inspired by the work of Tan et al. (2021), we sought to identify a slight change
vector to add to the weights of textual feature vectors when averaging them.
In this section, we first discuss the base Counterfactual method, and then
propose our own method.6 Niloofar Ranjbar et al.
3.1.1 The base CountER model
Suppose we have a set of musers, U={u1, u2, ..., u m}, and a set of nitems,
V={v1, v2, ..., v n}.Foreach typeofitem(e.g., cellphones),we extractalistof
raspects, A={a1, a2, ..., a r}. We then construct the user-aspect preference
matrix, X ∈Rm×r, and the item-aspect quality matrix, Y ∈Rn×r, using
scores calculated as follows:
Xi,k=(
0,if user uidid not mentioned aspect ak
1 + (N−1)
2
1+exp(−ti,k)−1
,otherwise
Yj,k=(
0,if item vjis not reviewed on aspect ak
1 +
N−1
1+exp(−tj,k.sj,k)
,otherwise(1)
In this context, Nrepresents the rating scale, which is set to 5 in this case.
ti,kdenotes the frequency with which user uimentions aspect ak,tj,kdenotes
the frequency with which aspect akis mentioned in item vjreviews, and sj,k
represents the average sentiment of these mentions.
After training the black-box model, researchers identify the most effective
aspects by solving the following optimization problem:
minimize C (∆) =∥∆∥2
2+γ∥∆∥0
s.t. S (∆) =si,j∆≤si,jK +1(2)
∆={δ0, δ1, ..., δ r}is a vector with zero or negative values. In this optimization
problem, ∆is learned for item vjsuch that by applying it on the Yjvector
(Yj+∆), the item will no longer be in the top Klist of items recommended
to user ui. The term ∥∆∥2
2controls the amount of change in the ∆values,
while ∥∆∥0controls the number of values that change in ∆vector. si,jK +1
is the ranking score of the marginal item (the last item in the top K list of
recommended items), and si,j∆is the ranking score of item vjafter applying
∆to its aspect vector.
Byoptimizingthisequation, ∆islearnedsuchthattheitem’saspectvector
is minimally changed until it is removed from the top Krecommended items
for user ui.
Finally, the aspects that have negative values in ∆are important, and
removing them from the list of aspects causes a change in the system’s recom-
mendation decisions.
Sincetheterms ∥∆∥0andsi,j∆≤si,jK +1arenotdifferentiable,theychoose
∥∆∥1instead of ∥∆∥0and relax si,j∆≤si,jK +1as a hinge loss. Therefore, the
final optimization equation is as follows:
minimize
∆∥∆∥2
2+γ∥∆∥1+λmax (0, α+si,j∆−si,jK +1)(3)
where a= 0.2,λ= 100andγ= 1based on the proposed model by Tan et al.
(2021).Explaining Recommendation System Using Counterfactual Textual Explanations 7
3.1.2 CountER for word vectors
To determine which words in the text are more important and critical to the
model,weattempttolearnavector ∆={δ0, δ1, ..., δ z}asinthebaseCountER
model and add it to the basic weight vector Θ={1,1, ...,1}, for a list of word
features W={w0, w1, ..., w z}of item vj. The basic weight vector assigns a
weight of 1 to every word wtin the list of item vjfeatures. At the end, words
that have a weight less than a threshold tare considered important features,
so that removing them causes the item to no longer be in the top Klist.
Since the existence of words in the features is a binary decision, we remove
the term ∥∆∥2
2from Equation 3, as the amount of change is not important in
this case.
3.2 Genetic algorithm
As previously stated, the inclusion of words in the features is a binary deci-
sion, and thus, we introduce another algorithm based on genetic algorithms.
The Genetic Algorithm in its conventional form employs a collection of po-
tential solutions that act as representations of a resolution to the optimiza-
tion problem that requires solving (Kramer, 2017). For a list of word features
W={w0, w1, ..., w z}for item vj, we define chromosomes as binary vectors of
size z. The steps of the algorithm are as follows:
– Making random population: We considered population sizes of ∈
{100,200,400}. The first population was generated randomly, with a prob-
ability of 0.9 for the number of ones and 0.1 for the number of zeros in
each chromosome, as we aim to minimize the number of removed words.
– Selection: In order to select chromosomes for the next generation, we
first calculate the fitness score for each chromosome. The probability of a
chromosome being chosen is based on its fitness score, where chromosomes
with higher fitness scores are more likely to be selected. For a chromosome
cwith size z, we calculate the fitness as follows:
fitness c=1
λ×(α+si,jc−si,jK +1)+countScore c
countScore c=(
0.5×(1−P
r:cr ̸=01
z)si,jc> si,jK +1
β×(P
r:cr ̸=01
z) otherwise(4)
where si,jcis the ranking score of item vjafter applying the values of
chromosome c as weights to its main vector, and si,jK +1is the ranking
score of the marginal item. As can be seen, the fitness function has two
parts. The first part increases when the score of the item decreases. α= 1
is added to the difference of scores to prevent negative values. The second
part of the fitness function (countScore c)is a penalty term that aims to
minimize the number of removed features. When the ranking score of the
item is greater than the marginal ranking score, some features need to be8 Niloofar Ranjbar et al.
removed to decrease the ranking score, so in this situation, removing more
features is better, but we consider a low coefficient (0.5) for that. On the
other hand, when the ranking score of the item is less than the marginal
ranking score, it means that the item is no longer in the top-K items and
the goal has been met. Therefore the number of removed features should be
minimized as much as possible for this model. λandβare hyperparameters
that need to be tuned.
– Cross over: After the selection phase, it is time to perform crossover on
pairs of chromosomes. Crossover is done with a rate of 99%.
– Mutation: Mutation is performed with a rate of 10% on at most 50%
of the population. For each chromosome, at most 10% of its genes are
changed.
Steps 2 to 4 are repeated for 10 iterations if the best fitness score exceeds a
threshold (1 is chosen based on experiments), otherwise, the algorithm con-
tinues for up to 50 iterations to allow for the possibility of finding a better
solution.
3.3 Gumbel-Softmax based method
In counterfactual explanations, we need to make minimal changes to the fea-
tures such that the recommended item is no longer in the top Klist. For
continuous features, this is straightforward, but for textual features, chang-
ing them is equivalent to removing them or replacing them with other words.
Removing words from text can produce meaningless sentences. Therefore re-
placing them with other words is a better approach. This is also true for
categorical features, which must have predefined values. Since they cannot be
removed from features, changing them is equivalent to choosing a new value
from a predefined set.
For optimization problems where the parameters are discrete, such as this one,
a new gradient estimator called Gumbel-Softmax has been introduced by Jang
etal.(2016).ItisbasedonGumbel-Softmaxdistributionandisapowerfulgra-
dientestimatorthatswapsoutthenon-differentiablesamplefromacategorical
distribution with a differentiable sample from a Gumbel-Softmax distribution.
This distribution’s crucial characteristic is its ability to smoothly anneal into
a categorical distribution. Guo et al. (2021) used this trick to generate new
meaningful text, we use it to find the best alternative words. In the following,
we describe the method we use for textual features. As the textual features are
similar to categorical features, we can use this method for categorical features
as well.
Suppose we have a list of words (as textual features) w={w0, w1, ..., w z}
for item vj. Changing these words is equivalent to replacing them with other
probable words such that the meaning of the whole sentence does not change
much. We find the five most probable alternative words for each of them us-
ing BERT as a language model. We mask a word and make BERT predict
alternative words.Explaining Recommendation System Using Counterfactual Textual Explanations 9
Consider a distribution PΘparameterized by a matrix Θ∈Rz×(5×z). For
each word wr, we have a vector of token probabilities in the Θmatrix named
πr, where πr=Softmax (Θr). At first, we choose the probabilities such that
for each word, the word itself is chosen as the alternative word. After that,
the parameter matrix Θis optimized such that the score of the item decreases
with minimum replacements in the words. As the Softmax function is not
differentiable, the Gumbel-Softmax approximation is used. Samples from the
Gumbel-Softmax distribution ˜PΘare drawn as follows:
(˜πr)k:=exp((Θr,k+gr,k)/T)PV
v=1exp((Θr,v+gr,v)/T)(5)
where (˜πr)kis the kthvalue of the vector ˜πr,gr,k∼Gumbel (0,1),V= 5×z
is the size of the alternative words list, and T >0is a temperature parameter
that controls the smoothness of the Gumbel-softmax distribution. When T→
0this distribution converges to a categorical distribution.
To find the contextual vector for each alternative word, we replace the
main word in the sentence with the alternative word and then extract the
contextual word vector as will be discussed in Section 4.2.1. Finally, we have
a matrix C∈RV×768such that for each alternative word, we have a vector
of size 768. By multiplying the π∈Rz×Vmatrix by the C∈RV×768matrix,
we have a matrix with dimensions z×768. Therefore for each word wrin
w={w0, w1, ..., w z}we have a vector of size 768. The optimization equation
defined in equation 3 changes as follows:
minimize
Θλmax (0, α+si,jΘ−si,jK +1) (6)
where si,j,Θis the predicted score of item vifor user ujafter using Θto
calculate πvalues and then applying πon the word vectors, as previously
mentioned. In order to replace more probable words with each word, we define
a matrix L∈Rz×V. For each li,k∈L, if the word akis in the alternative list of
the word wi,li,kequals the BERT output layer logit for the word ak, otherwise
it equals -1. Note that higher values of logits indicate higher ranks in the top
5 alternative words list. Furthermore, we add the l1norm of the difference
between the main πcalculated with the main words (no words are replaced)
and the πcalculated while optimizing the Θmatrix, as the penalty term for
the number of replaced words. Therefore, the final optimization equation is as
follows:
minimize
Θλmax (0, α+si,jΘ−si,jK +1) +β1.0
˜π·L+γ∥˜πmain−˜π∥1(7)
where α= 0.2,λ= 100(as stated in Section 3.1), βandγare hyperparam-
eters, and ˜π·Lis the dot product of ˜πandL. It is worth noting that as the
model chooses more probable words, this dot product increases.
For categorical features, we use the same formulation, except that the al-
ternative values for each categorical feature are not words anymore. Addition-
ally, there is no need to calculate the second term in equation 7. Finally, for a10 Niloofar Ranjbar et al.
combination of continuous, categorical and textual features the optimization
problem is as follows:
minimize
∆,Θ 1,Θ2,Θ3lscore +ltextual +lcat+lcontinuous
lscore =λmax (0, α+si,j∆,Θ 1,Θ2,Θ3−si,jK +1)
ltextual =β1.0
˜π1·L+γ∥˜πmain 1−˜π1∥1
lcat=γ∥˜πmain 2−˜π2∥1
lcontinuous =∥∆∥2(8)
Here, lscoreis the same as the loss explained in equation 6, with one main
difference: all types of features are used to calculate the new score. Therefore,
all values of ∆, Θ 1, Θ2, Θ3are used to calculate this score. ltextualis the same
as the one defined in equation 7, in which Θ1is used to calculate ˜π1.lcat
is calculated for all categorical features, in which Θ2is used to calculate ˜π2.
Finally, lcontinuous is used to ensure that the ∆used for continuous features
changes minimally.
4 Experiments
In this section, we first specify datasets and settings needed for the exper-
iments. Next, we evaluate the introduced methods both quantitatively and
qualitatively. Finally, we discuss the results. Note that all experiments were
conducted on NVIDIA T4 Tensor Core GPUs using Colab.
4.1 Datasets
We test our methods on the Amazon and Yelp datasets. The Amazon dataset
contains 29 sub-datasets, each of them for a specific product category. We use
two sub-datasets of different scales, "Cell Phones and Accessories" and "CDs
and Vinyl". Each dataset contains user reviews of items, item descriptions,
and some additional features as textual data. The Yelp dataset, on the other
hand, contains information on various businesses such as their geographic lo-
cation (latitude and longitude), opening hours, and other special features (e.g.,
parking, food types for restaurants, etc.). It also includes user reviews and tips
on the businesses. We consider longitude and latitude as continuous features,
tips as textual features, and some other features as categorical features.
Table 1 shows the statistics of the datasets. For all datasets, we drop users
and items with less than 5 and 10 reviews, respectively. To prepare the train,
validation and test sets, we only use users with more than 15 items interacted
with. For each user, these items are considered as positive samples. We hold
out the last 10 items for validation and test sets (5 each) and use the remaining
items for the train set. We also sample negative instances randomly from the
non-interacted items with a ratio of 1:5, meaning for each positive instance,
we sample five negative instances.Explaining Recommendation System Using Counterfactual Textual Explanations 11
Table 1: Statistics of the datasets
Dataset Users Items Reviews Tips Train Test
Cell Phones and Accessories 6794 1945 36762 N/A 2871 93
CDs and Vinyl 11467 11677 224090 N/A 686172 3631
Yelp 243531 48089 1426442 626069 501606 3529
4.2 Data preparation
4.2.1 Preparing Amazon dataset
As can be seen in Figure 1 for amazon datasets we extract textual features
from descriptions, titles and features of items by using the BERT. The steps
to extract textual features are as follows:
– Cleaning texts: We remove URLs and some xml tags like “</b>" and
the text between them. We remove words which are the combination of
digits and characters, because there are many meaningless words like them
in the text.
– ExtractingcontextualvectorsusingBERT: Weuse“bert_base_uncased"
which produces a vector of size 768 for each word in each hidden layer. To
extract contextualized vectors for the words in the sentences, we use the
last hidden layer of the BERT.
– Preprocessing: To extract valuable words from the sentences we remove
stop-words and punctuation marks from the texts.
– Generatingfinalitemvector: Wecalculatetheaverageoftheremaining
word vectors and then concatenate descriptions, titles and features vectors
to get a vector of size 2304 as the final item vector. Note that for the
words which are not in the BERT vocabulary and BERT tokenizes them
into several parts, we calculate the average of all parts vectors as the word
vector.
4.2.2 Preparing Yelp dataset
The proposed method was tested on the Yelp dataset, which contains a
combination of textual, continuous, and categorical features. Textual fea-
tures were extracted from user tips on businesses, and vectors were gener-
ated as previously described for the Amazon dataset. Continuous features
included the latitude and longitude of each business, while categorical fea-
tures included information such as the time periods during which the busi-
ness is open, whether it has parking, and the types of food it serves. A
binary vector was created to represent the time periods, with a value of
1 indicating that the business is open during that hour and a value of 0
otherwise. The 87 categorical features were encoded with three values: -
1 for businesses that do not have the feature, 0 for businesses for which12 Niloofar Ranjbar et al.
Fig. 1: Preparing amazon data for black-box model
it is not specified whether or not they have the feature, and 1 for busi-
nesses that have the feature. All continuous and categorical features were
then scaled to have zero mean and unit variance. The final vector for each
business was obtained by concatenating the textual features vector with
the scaled continuous and categorical features, resulting in a vector of size
168+87+768=1023.
4.3 setup of experiments
4.3.1 Black-box model
The black-box model is a feed forward network with 2 hidden layers con-
taining 512 and 256 neurons. The input to the model is a concatenation of
two vectors. The first vector is for the item and the second one is for the
user. Any kind of textual features, as well as continuous and categorical
features can be used in this model based on their availability. Note that we
generate the user vector by averaging the items vectors he/she interacted
with.
We apply the ReLU activation function after each layer except the last
one, in which we use a Sigmoid activation function. The output layer maps
the ranking score, si,j, to a value within the range of (0,1), allowing us to
recommend top-K items for a user based on the predicted ranking scores.
A cross-entropy loss is used for training the model, and we employ a
stochastic gradient descent (SGD) optimizer with a learning rate of 0.01.Explaining Recommendation System Using Counterfactual Textual Explanations 13
4.3.2 Hyper-parameters
A stochastic gradient descent (SGD) optimizer with a learning rate (lr)
is employed to optimize all methods, with the exception of the genetic
method. A value of lr= 0.01is chosen for the countER methods, and it is
tuned for the Gumbel-softmax-based method.
As previously discussed in Section 3.1, for the main countER method,
we set the hyper-parameters in Equation 3 to the same values as those
used by Tan et al. (2021). However, for the countER for word vectors, we
tested different values for γin0.2,0.3,0.4, ...,1.0and for the threshold t
in0.01,0.1,0.2,0.3,0.4,0.5on the validation set and found that the best
values were γ= 0.7andt= 0.3.
For the genetic method, we tested different values for λin2,5,10and for
βin2,10,50on the validation set and found that the best values were
λ= 10andβ= 10.
The Gumbel-softmax-basedmethodhas temperature T,learning rate lr,β,
andγas hyper-parameters. We test different values for each dataset sepa-
rately. We tested different values for Tin{0.5,1.0,1.2,1.4,1.5,2.0,2.2,2.4}
(best= 2.0and2.2), for lrin{0.1,0.2, ...,0.7}, (best= 0.5and0.7) forβin
{1000,2000,10000}(best= 1000) and for γin{1,2,5}(best= 1).
4.3.3 Evaluation Metrics
We use NDCG (Normalized Discounted Cumulative Gain) as a metric for
measuring the ranking quality of the black-box model.
Inspired by Tan et al. (2021), we evaluate the explanation generation meth-
ods from two perspectives: user-oriented and model-oriented evaluations.
– user-oriented evaluation: In user-oriented evaluation, we examine
the extent to which the features of an item extracted by the explanation
generation method are mentioned in the user’s reviews of that item.
Therefore, for an item vjand user ui, if the explanation generation
method outputs E=e1, e2, ..., e Nas the important features, and the
useruimentions the words G=g1, g2, ..., g Min their review of item
vj, the precision, recall and F1 metrics for the user-oriented evaluation
are calculated as follows:
Precision =Pr
k=1pk
i,j
N, Recall =Pr
k=1pk
i,j
M
F1 = 2·Precision ·Recall
Precision +Recall
pk
i,j=(
1ek
i,j∈Gi,j
0otherwise(9)
where N is the number of features chosen by the explanation genera-
tion method and M is the number of words used by the user in their
review of the item. Finally, we average the scores of all pairs to obtain14 Niloofar Ranjbar et al.
the final precision, recall and F1. It should be noted that before using
the user’s reviews as ground-truth features, we preprocess them by re-
moving punctuation marks and stop-words. The review words are then
tokenized and used as the ground-truth features.
– model-oriented evaluation: In user-oriented evaluation, we deter-
mine whether the generated explanation features are consistent with
the user’s preferences. To check whether the generated explanation fea-
tures truly capture the model’s behavior, we use two additional metrics,
Probability of Necessity (PN) and Probability of Sufficiency (PS).
The PN metric answers the question "Are the generated features nec-
essary for the model to predict the rank correctly?" To answer this
question, we remove the specified features from the list of features, and
check whether the item is still recommended to the user.
The PS metric answers the question "Are the generated features suffi-
cient for the model to predict the rank correctly?" To answer this ques-
tion, we use only the specified features and remove other features from
the list of features and check whether the item is still recommended to
the user.
We calculate the harmonic mean of PN and PS as a third metric named
FNS, similar to the F1 measure.
Another important metric in evaluating explanation generation methods
is their stability. This metric measures how consistent the explanation fea-
tures generated by the model are across different runs. We define the sta-
bility of the model for an item vjand user uias follows:
Stability i,j=1
N(N−1)NX
k=1NX
l=1,k̸=l|rk∩rl|
|rk∪rl|(10)
where rkis the set of explanation features generated by the method in the
kthrun and N is the number of runs, which is set to 10 for all datasets.
The final stability of the model is determined by averaging the scores of
all pairs. We calculate the stability for all datasets by using 10 examples
from the test set, which are chosen randomly.
4.3.4 Comparable Baseline
In our experiments, we used the baseline method proposed by Tan et al.
(2021) as our sole competitor. This method was compared to other state-
of-the-art methods in their paper, and it was demonstrated to significantly
outperform them. Therefore, we chose to compare our method with the
baseline method, which itself outperformed other methods.
While we acknowledge that there may be other methods that could poten-
tially be used as competitors, we decided to focus on the baseline method
due to its superior performance and the fact that it has already been com-
pared to other competitors in the field. Additionally, given the changes in
the dataset, it would not be appropriate to directly compare our results toExplaining Recommendation System Using Counterfactual Textual Explanations 15
Table 2: Amazon Dataset Explanation Results, user-based and model-based
dataset User-based Model-based
Pre Rec F1 PN PS FNS
cell-phonesbaseline 0.273 0.298 0.250 0.950 0.918 0.934
countERText 0.1075 0.0497 0.057 0.915 0.971 0.9426
Genetic 0.085 0.092 0.072 0.890 0.995 0.940
Gumbel 0.110 0.068 0.073 0.970 0.990 0.980
CDsbaseline 0.223 0.329 0.228 0.778 0.679 0.725
countERText 0.177 0.016 0.025 0.820 0.997 0.90
Genetic 0.121 0.034 0.038 0.957 0.997 0.97
Gumbel 0.117 0.024 0.028 0.796 0.998 0.886
those of other papers without re-running their codes. Therefore, we chose
to re-run the code from Tan et al. (2021), which achieved the best results
in the field and has already been compared to other competitors.
4.4 Amazon dataset Results
As we use different types of features for the Amazon and Yelp datasets,
we present their results separately. The results of our experiments for the
Amazon dataset can be seen in Table 2 and 3. It should be noted that
the baseline method in these tables refers to the main countER method
presented by Tan et al. (2021).
4.4.1 Are generated features based on user preferences?
As can be seen in Table 2, the value of precision, recall and F1 score of
user-based measure decreases for all of the introduced methods compared
to the baseline. The reason is as follows: the baseline method uses a fixed
set of aspects with 88 and 230 aspects for the cell-phones and CDs datasets
respectively. and the model outputs a subset of these aspects as the im-
portant features. However, our methods output important words from the
item’s descriptions, titles and features which are not a specific set of words.
Besides, these words may be really important for the user while making
a decision but not used in his/her review directly. So this is not fair to
compare our methods with the baseline method with this measure.
By comparing our methods to each other with this measure, we can find
there is no significant difference between them.
4.4.2 Are generated features specifying the model’s behavior?
The results presented in Table 2 demonstrate that our proposed meth-
ods, which are based on model-based measures, significantly outperform
the baseline. Upon examination of the data, it becomes apparent that the
genetic and Gumbel-softmax algorithms yield the best results for both16 Niloofar Ranjbar et al.
Table 3: Amazon Explanation Results, Other measures
dataset NDCG Features Avg Exp Found Rate Stability Time(sec)
cell-phonesbaseline 0.3561 2.97 78% 0.862 1.28
countERText 0.4047 6.05 98.9% 0.862 1.69
Genetic 0.4047 15.94 98% 0.175 4
Gumbel 0.4047 9.61 99% 0.51 7.4
CDsbaseline 0.481 5.09 72% 0.68 1.35
countERText 0.712 2.567 98% 0.65 0.43
Genetic 0.712 7.32 95% 0.47 1.76
Gumbel 0.712 6.97 74% 0.54 4.8
datasets. Specifically, when analyzing the cell-phone dataset, the Gumbel-
softmax algorithm exhibits superior performance in regards to the PN and
FNSmeasures,withthedifferenceinperformanceforthePSmeasurebeing
negligible when compared to the Genetic algorithm. On the other hand,
when analyzing the cds dataset, the Genetic algorithm demonstrates a
marked improvement in PN and FNS measures in comparison to all other
methods, while its performance in regards to the PS measure is comparable
to that of the other methods.
4.4.3 The effect of changing features on ranking
As can be seen in Table 3, the NDCG value, which measures the rank-
ing quality of the black-box model, increases significantly compared to the
baseline for both datasets. This improvement is due to the use of different
feature inputs. However, it should be noted that the three models, coun-
tERText, Genetic, and Gumbel, have the same recommendation method,
while benefiting from different explanation generation models. Therefore,
NDCG shows the same results for all three models. This is because NDCG
only determines the accuracy and quality of the recommendation.
Overall, by using these features, it appears that it is possible to recommend
items to the user more reliably. The next step is to determine whether the
proposed methods are reliable enough to generate accurate explanations
based on user preferences.
4.4.4 Which method finds explanations with lower number of features in
average?
As can be seen in Table 3, the baseline (countER) and the countERText
methods generate explanations with the least number of features for the
cell-phones and cds datasets, respectively. The Gumbel-softmax method
is the next one in this ranking, and finally, the genetic algorithm finds
the most number of features. However, it is worth noting that the genetic
algorithm is also able to find more explanations, which may suggest that
it is able to find explanations for pairs that other algorithms cannot by
using a larger number of features. Another reason may be the differenceExplaining Recommendation System Using Counterfactual Textual Explanations 17
in the formulation and optimization of the genetic algorithm compared to
the other methods.
4.4.5 Which method finds explanations for more pairs?
One notable difference in the evaluation measures is the explanation found
rate, which assesses the number of user-item pairs for which an explanation
can be found. As can be seen in Table 3, in general, the countERText tech-
nique performed the best, with an Explanation Found Rate of 98.9% for
cell-phonesand98%forCDs.TheGeneticandGumbeltechniquesalsoper-
formed well, but with lower Explanation Found Rates. This discrepancy is
understandable, as the Gumbel-softmax algorithm requires changing words
to other, semantically appropriate words, which can make it more difficult
for the explanation generation method to find explanations. In contrast,
the genetic and countERText methods only need to remove some words
from the text, which is a simpler task. However, it is worth noting that
the Gumbel-softmax method is designed to work well with datasets that
contain a variety of feature types, such as textual, categorical, and numer-
ical features. Therefore, it should not be expected to perform particularly
well on a dataset that only contains textual features. Despite this, the
Gumbel-softmax method still outperforms the baseline in both datasets.
4.4.6 Stability
It is shown in Table 3 that, the baseline and countERText methods are
the most stable on both datasets. The Genetic method has low stability
on both datasets, with a stability score of 0.175 on the cell-phones dataset
and 0.47 on the CDs dataset. The Gumbel method also has low stability,
with a stability score of 0.51 on the cell-phones dataset and 0.54 on the
CDs dataset.
The low stability scores for the Genetic and Gumbel methods could be
due to the fact that these methods use randomness in their algorithms.
For example, the Genetic method uses a genetic algorithm that involves
random mutations and crossovers, which can lead to different results across
runs. Similarly, the Gumbel method involves generating random variables
and using them to calculate a probability distribution, which can also re-
sult in different results across runs. Moreover, the variance in the results
across different runs could be attributed to the types of features utilized
by each method. The baseline method employs a limited set of features,
which results in less variance across runs. Conversely, the other methods
utilize words as features, which can result in a greater degree of variabil-
ity. However, in the context of recommender systems, it may be beneficial
to obtain different sets of features in different runs to provide users with
diverse explanations from multiple perspectives. Thus, in this scenario, it
would not be appropriate to determine whether a higher or lower stability
is better.18 Niloofar Ranjbar et al.
4.4.7 Time Complexity
We evaluated the proposed method by measuring the average time spent
generating explanations for a user-item pair. The time taken is reported in
seconds in Table 3. For the cellphone and CD datasets, which only have
textualfeatures,thetimespentgeneratingexplanationsusingourproposed
methods depends entirely on the length of the textual descriptions, titles,
and features of each item. As can be seen from our three proposed ap-
proaches, Gumbel-softmax takes the most time, while countERText takes
theleasttime.However,thebaselinemethodtakesalmostthesameamount
of time as countERText and Genetic algorithm. This is because the num-
ber of words used as features in our proposed algorithms is greater than
the number of aspects used in the baseline method, and the search space is
larger than that of the baseline method. Therefore, this difference is logical.
4.5 Yelp dataset Results
For the Yelp dataset, we conduct three experiments to investigate the ef-
fect of various types of features on the accuracy of the black-box model.
Additionally, we examine the combination of multiple features on the ex-
planations generated by the model. The experiments aim to determine the
most effective features and feature combinations for both accurate predic-
tions and clear explanations of the model’s decisions.
In the first experiment, we use all features, including textual features (ex-
tracted from users’ tips), categorical features, and continuous features, to
train a black-box model. To find explanations, we combine Equations 3 and
7 to define a new loss function, which can be used to find explanations for
all types of features mentioned. Specifically, Equation 3 is used for contin-
uous features and Equation 7 is used for textual and categorical features.
The second experiment focused solely on textual features and compared
various methods for finding explanations, as previously conducted in the
experiments on the Amazon dataset in Section 4.4).The final experiment
employed only categorical and continuous features to train the black-box
model, and explanations were generated using the same methodology as in
the first experiment. The results of our experiments for the Yelp Dataset
can be seen in Tables 4 and 5.
4.5.1 Are generated features based on user preferences?
As can be observed in Table 4, the results of evaluating features based
on user preferences are consistent with those obtained from the Amazon
datasets. Given that user-preference ground-truth features are extracted
from textual features, it is not possible to evaluate methods that do not
utilize textual features. By comparing the results for textual features, it
can be inferred that the baseline method achieves better results in thisExplaining Recommendation System Using Counterfactual Textual Explanations 19
Table 4: Yelp Dataset Results, user-based and model-based
Feature Types User-based Model-based
Pre Rec F1 PN PS FNS
All Gumbel 0.101 0.059 0.044 0.607 0.609 0.608
Textualbaseline 0.080 0.1661 0.0909 0.9544 0.9619 0.9582
countERText 0.092 0.058 0.051 0.8966 0.9385 0.9171
Genetic 0.099 0.101 0.072 0.9712 0.956 0.9638
Gumbel 0.072 0.040 0.041 0.75 0.918 0.826
Non-Textual Gumbel N/A N/A N/A 0.647 0.495 0.555
Table 5: Yelp Dataset Results, Other measures
Feature Types NDCG Features Avg Exp Found Rate Stability Time(sec)
All Gumbel 0.8499 7.6 98.3% 0.59 5.4
Textualbaseline 0.515 7.51 68% 0.74 1.36
countERText 0.6172 13.819 93.4% 0.58 0.78
Genetic 0.6172 17.24 73.76% 0.21 4
Gumbel 0.6172 11.39 59.2% 0.51 2.8
Non-Textual Gumbel 0.8434 2.73 89.9% 0.77 2
aspect, as fewer features need to be identified by the method. The analysis
of results in this section aligns with the findings presented in Section 4.4.
4.5.2 Are generated features specifying the model’s behavior?
As can be seen in Table 4, when only textual features are used, the gener-
ated explanations provide a better understanding of the model’s behavior.
However, when using non-textual features, the generated explanations are
not as effective in specifying the model’s behavior. It may be due to the
fact that many of the non-textual features may be unrelated to certain
businesses, and thus their removal from the list of features does not sig-
nificantly impact the ranking score of these businesses. As a result, the
PN score is lower than that of other methods. Similarly, for the PS score,
the same phenomenon occurs, where some features are unrelated to certain
businesses and are thus insufficient to place them in the top K list, result-
ing in a lower score compared to other methods. One potential solution to
this issue is to consider categorical features related to each type of business
separately.
Additionally, when all features are utilized, the results are better than
using only non-textual features but not as favorable as when only textual
features are used. This is likely because non-textual features are included
among the textual features.
Furthermore, when utilizing textual features, the genetic algorithm per-
formed the best, but with a larger number of features found. Moreover, the
baseline and countERText methods were the next best performers, while
the Gumbel method performed the worst.
In conclusion, our contribution is the ability to find explanations that con-
tainmultipletypesoffeaturessimultaneouslythroughtheGumbel-softmax20 Niloofar Ranjbar et al.
method. By improving the formulation of categorical and continuous fea-
tures, it is hoped that the results will further improve.
4.5.3 The effect of changing features on ranking
AscanbeseeninTable5,whenallfeaturesareemployedoronlycategorical
and continuous features are utilized, the NDCG value is more favorable.
Conversely, the utilization of textual features resulted in a lower NDCG
value for the black-box model. This can be attributed to the fact that
the textual features used in this study were extracted from users’ tips
on the items, rather than from the items’ features directly. This trend is
consistent with the results observed when using user reviews to extract
textual features for the Amazon dataset. In that case, we use the item’s
descriptions and features directly instead of user reviews, to avoid this
issue.Nonetheless,non-textualfeaturesdemonstratedanoteworthyNDCG
score. By comparing the methods used for extracting textual features, it
can be inferred that the method of feature extraction plays a crucial role
in the NDCG score of the black-box model.
4.5.4 Which method finds explanations for more pairs with lower number
of features in average?
As can be seen in Table 5, when all features are used, the explanation gen-
eration algorithm is able to generate explanations for 98% of pairs with an
average of 7.6 features. This high success rate is achieved despite the need
to search through a large number of features, indicating that the algorithm
is able to generate explanations for a significant proportion of pairs with
relatively few features. On the other hand, the baseline method which only
utilizes textual features generates explanations for only 68% of pairs with
an average of 7.51 features. The countERText method performs well with
93.4% of explanation found rate but with a large number of features in
average (13.81). The genetic algorithm also performs well but with more
features in average 17.24. The Gumbel softmax method, however, performs
relatively poorly, generating explanations for only 59.2% of pairs with an
average of 11.39 features. Utilizing only non-textual features results in gen-
erating explanations for 89.9% of pairs with an average of 2.73 features.
Overall, it appears that the Gumbel method when using all features is able
to generate explanations for a high proportion of pairs with a relatively
low number of features on average.
4.5.5 Stability
As can be seen in Table 5, it becomes apparent that the stability of the
baselinemethodis0.74whenonlytextualfeaturesareused,whichishigher
than that of the other methods, consistent with the findings from the Ama-
zon dataset. On the other hand, the Gumbel method using all types ofExplaining Recommendation System Using Counterfactual Textual Explanations 21
Table 6: cell phones dataset example 1
user_id A3VVMIMMTYQV5
item_id B00U7YKO78
baseline phone, battery, lights
countERTextremoving words: ’version’,’international’
,’warranty’,’samsung’,’wireless’,’us’
Geneticremoving words: ’qi’,’galaxy’,’note’, ’go’,’select’,
’daydream’,’more’,’corner’,’samsung’,’international’,
’us’,devices’,’ micro’,’usb’,’charging’,’wpc’
Gumbelwords : [’cover’, ’samsung’, ’wireless’, ’international’, ’white’],
change to: [’daydream’, ’with’, ’galaxy’, ’board’, ’;’]
user review
on item[’plastic’, ’back’, ’I have a Spigen case that has a clear plastic back’],
[’charge’,’quick’,"It charged so quick I didn’t get the chance to really
figure out when it topped off"],
[’phone’, ’right’, ’I charged my phone right away to try it out’],
[’case’, ’clear’, ’I have a Spigen case that has a clear plastic back’],
[’case’, ’clear’, ’My Spigen case was a clear plastic’],
[’lights’, ’blue’, ’the blue lights will start blinking’],
[’lights’,’blue’,’it emits 2 deep blue tubular lights along the front side
to let you know
features shows a stability of 0.59, which is higher than when only textual
features are used. This suggests that the features generated by the Gumbel
method are more consistent when all types of features are used. When non-
textual features are used, the stability is higher than the other methods.
This can be attributed to the fact that the number of non-textual features
is much smaller than the number of textual features. These results high-
light the importance of selecting appropriate features for a given task and
using a robust method to generate stable features.
4.5.6 Time Complexity
The time spent generating explanations for the Yelp dataset is shown in
Table 5. This time not only depends on the length of tips used as textual
features but also on the number of categorical features we have. However,
since the tips in the Yelp dataset are generally shorter than the descrip-
tions, features, and titles in the Amazon dataset, the time spent generat-
ing explanations for only textual features is less than that for the Amazon
dataset on average. However, as other categorical features are added and
all types of features are used, the time spent generating explanations in-
creases. Nevertheless, as with the Amazon dataset, the feature space in
which we search for generating counterfactual explanations for our meth-
ods is larger than that of the baseline method, so the difference in the time
spent generating explanations is logical.22 Niloofar Ranjbar et al.
Table 7: cell phones dataset example 2
user_id A1F7YU6O5RU432
item_id B00Z7RQ0NC
baselinephone, quality, buttons,device, case, protection, cases,screen
,color, grip
countERTextremoving words:’lifetime’,’date’,’protects’,’graphic’,’plus’,’iphone’
,’absorbs’,’seamless’,’night’,’withstands’,’edge’,’white’
Geneticremoving words: ’phone’,’iphone’,’amp’,’iphone’,’only’,’date’
,’iphone’,’details’
Gumbel no explanation found
user review
on item[’case’,’pretty’,’Love the looks of it and when
the sun catches the silver flecks on the case its so pretty’],
[’case’,’clear’,’The case is clear so whatever color your iPhone
is youll be able to see it a bit through the sparkles’],
[’photos’,’online’, ’What might be hard to tell initially from the
online photos is this case has a bunch of gorgeous sparkles inside
the clear plastic\’
Table 8: CDs dataset example 1
user_id A3LEN0P07MGJE2
item_id B001TRDPB4
baseline no explanation found
countERText removing words: ’christmas’, ’cheers
Geneticremoving words: ’members’,’living’,’sell’,’sensation’,’2008’
,’nationwide’,’tour’,’bowl’,’bring’,’another’,’chaser’,’jingle’,
’christmas’,’cheers’
Gumbelwords : [’cheers’, ’christmas’, ’reindeer’]
change to: ["’", ’filmed’, ’tonight’, ’!’]
user review
on item[[’twists’,’new’,’There were some songs that were new to me
as well as new twists to old favorites – the introduction to
We Three Kings comes to mind with its hints of the
Mission Impossible theme’],
[’twists’, ’in’,’The twists in Rudolph the Red-Nosed Reindeer’]]
4.6 Qualitative Evaluation
In this section we present some examples of features found by different
methods for different datasets.
The examples of the cell-phones dataset are presented in Tables 6 and
7. Due to the length of the user reviews, only the ground-truth aspects
and the sentences containing them have been included. It should be noted
that without access to the full reviews, it may not be possible to fully
evaluate the effectiveness of each method. Nevertheless, as observed in
the first example, the word ’charge’ is an aspect identified by the genetic
algorithm and mentioned in the user review. Additionally, the words ’case’
and ’plastic’ are also found in the user review and are similar to the aspect
’cover’identifiedbytheGumbelmethod.Theaspect’light’isalsoidentified
by the baseline method as being important in the user reviews. However,
for a fair comparison, it is necessary to have access to the full descriptionsExplaining Recommendation System Using Counterfactual Textual Explanations 23
Table 9: CDs dataset example 2
user_id A1SCJWCMQ3W3KK
item_id B00006879E
baseline song , rock, blues, tune, release, disc, collection, hit
countERText removing words: ’jane’
Genetic removing words: ’first’, ’songs’
Gumbelwords:[’stevie’, ’jane’, ’songs’],
change to:[’their’, ’rhythms’, ’those’]
user review
on item[’release’, ’in’,"while ’Tangled’ is more reminiscent of something
Motown would have released back in the 1970s"],
[’release’, ’back’, 1, "while ’Tangled’ is more reminiscent of
something Motown would have released back in the 1970s"],
[’music’, ’fresh’, ’the record still holds up as fresh music’],
[’band’, ’in’, ’which takes the band into a slightly softer feel’]
[’blues’, ’little’, ’a little blues’]
[’rock’, ’in’, ’and rock and roll in a way that was previously
unknown (at least on a grand scale) on US airwaves’]
[’rock’, ’little’, ’a little rock’],
[’tracks’, ’first’, ’the first eight tracks are spectacular’]
[’funk’, ’little’, ’A little funk\’]
and features of the item and the entirety of the user reviews to understand
the context in which these words are used and the specific meaning they
convey. Due to the length of these texts, they have not been included in
this presentation.
The examples of the CDs dataset are presented in Tables 8 and 9. As can
be seen, the baseline method did not identify any explanations in the first
example, while the other methods found some explanations. However, as
with the cell-phones dataset, it is not possible to determine the relevance of
these identified aspects without access to the full reviews and descriptions.
In the second example, it is observed that the user expressed a preference
for the first tracks and the words "first" and "songs" are identified as
important by the genetic algorithm. Moreover, the user mentions the words
"rock", "blue", and "release" in their review and these words are identified
by the baseline method. The Gumbel method and CountER both identified
a name as an important aspect, which may be relevant to the user but may
alsobefoundinotherpartsofthereviewthatarenotincludedinthistable.
ExamplesfortheYelpdatasetarepresentedinTables10and11.Asdemon-
strated, when utilizing all types of features, the Gumbel method can iden-
tify changes in continuous, categorical, and textual features. For instance,
in the first example, there are slight modifications in the wording of the
tips and the latitude and longitude of the business, the establishment is no
longer recommended to the user.
Furthermore, the second example illustrates that when utilizing only non-
textual features, it is discovered that if the halal option is changed from
"not mentioned" to "False," indicating that the restaurant does not serve
halal food, the establishment is no longer recommended to the user.24 Niloofar Ranjbar et al.
Table 10: Yelp dataset example 1
user_id nlReKgQoRz6uPfVaEG93mw
item_id tU692E8N0xBQ7Ogc78gN2g
all featureslatitude change from 36.177038 to 36.17646826
longitude change from -86.749691 to -86.75116574
words : [ ’going’, ’anything’, ’rain’, ’potato’, ’house’]
change to : [ ’about’, ’spot’, ’much’, ’!’, ’black’]
textual
featuresbaseline staff, taste, inside
countER
Textremoving words:[’milky’,’going’,’way’,’table’,’coffee’,
’place’,’great’,’mocha’,’try’,’yummy’,’numb’,’best’
,’nashville’,’breakfast’,’amazing’,’hangout’,’get’]
Geneticremoving words:[’order’,’feastival’,’addictive’,’green’,
’love’,’atmosphere’,’milky’,’best’,’town’,’joe’,’everything’
,’wrong’,’brazilian’,’fuzzy’,’bomb’,’fishy’,’ever’,’roasted’,
’great’,’breakfast’,’simple’,’syrup’,’iris’,’flower’,’cream’,
’sliced’,’table’,’hangout’,’bloom’,’iced’,’americano’,
’grapefruit’,’tea’,’cucumber’,’sweet’,’super’,’latte’,
’office’,’bar’,’pizza’,’apple’,’sauce’, ’decent’,’coffee’]
Gumbel no explanation found
non-textual featureslatitude change from 36.177038 to 36.17698086
longitude change from -86.749691 to -86.7495435
user review on business It’s an awesome place to drop in and eat or get something to go
Ananalysisofuserreviewsforthebusinessrevealsthatthewords’chicken’,
’salad’ and ’food’ are identified as important by various explanation meth-
ods, indicating their results are acceptable.
It is noteworthy that for each business, changes in categorical features can
be identified separately, and recommendations can be made to the estab-
lishment to consider these features. For example, informing the manager
that serving halal food or providing bicycle parking may attract more cus-
tomers.
5 Conclusion and Future works
In this paper, we introduced three methods for generating explanations for
textual explanations and evaluated them on three real-world datasets of
recommender system tasks. CountERText and Genetic methods were able
to find only textual features as explanations, while the Gumbel method,
which employed Gumbel softmax, was able to be applied to all types of
features, including textual, categorical, and continuous features. We con-
ducted experiments to evaluate these methods and found that when item
textual features were used, our method outperforms the baseline in terms
of model-based measures, meaning that the features found as explanations
were both necessary and sufficient for the model to make accurate pre-
dictions. Although the models did not perform well when using user tips
on items as textual features, the Gumbel softmax-based method has theExplaining Recommendation System Using Counterfactual Textual Explanations 25
Table 11: Yelp dataset example 2
user_id 0du93EkEwKuxRG_x6hqVUg
item_id KnsY8rh5tigp5t6WpilGdA
all featureslatitude: change from 36.103133 to 36.10256344
longitude: change from -86.8185 to -86.81997484
Open24Hours: change from Not-mentioned to True
words: [’bars’,’gallon’,’sunday’,’bag’,’girl’, ’sausage’,
’breakfast’,’better’,’awesome’]
change to: [’chef’, ’?’, ’red’, ’guy’, ’salad’, ’foods’,
’you’, ’start’, ’dawn’]
textual
featuresbaselinecoffee, favorite, spot, cheese, tasting,
price, eating, hour, ingredients, tea,
chocolate, neighborhood, shop
countER
Textremoving words:[’mean’,class’,’includes’,’day’,’bar’,’run’,
’nashville’,’buffet’,’hour’,’hills’,’butter’,
’chai’,’guys’,’rush’,’come’,’food’,’beer’,
’thanksgiving’,’see’,’rules’,’pick’,’today’,’salad]
Geneticremoving words:[’bags’,’juice’, ’lunch’,’run’,’variety’, ’juice’,
’traditional’,’thanksgiving’,’feel’,’shopping’,’girl’,’thank’,’nice’,’butter’,
’meat’,’watch’,’hockey’,’pork’,’wonderful’,’act’,’ordered’,
’took’,’come’,’salad’,’get’,’thai’,’pump’,’saturdays’,’think’
,’come’,’hidden’,’bar’,’almond’,’including’,’beer’,’narragansett’,
’hot’,’figured’,’delicious’,’desert’,’breakfast’,’consistent’,’option’,
’selection’,’selection’,’breakfast’,’chicken’,’hot’,’rules’,
’looking’,’epic’,’grilled’,’nice’,’pepper’,’guys’,’great’,’organic’,
’pizza’,’order’,’table’,’awesome’,’orange’,’makings’,’free]
Gumbelwords:[’southern’,’saturdays’,’best’,’hills’,’locations’,’rules’,
’bar’,’guys’, ’today’,’wonderful’,’awesome’]
change to:
[’noon’,’was’,’any’,’village’,’;’, ’did’,’also’,’sausage’,
’like’,’get’,’.’,’to’,’eat’,’little’]
non-textual
featureslatitude: change from 36.103133 to 36.10318994
longitude: change from -86.8185 to -86.81864752
halal: change from to Not-mentioned to False
user review
on business[[’cheese’, "You’ll find interesting cheese"],
[’chicken salad’, "and awesome chicken salad"],
[’foods’, ’Their prepared foods are also pretty awesome’]]
potential to produce explanations based on multiple features, which could
be useful for tasks involving multi-modal features such as healthcare.
In future works, the model can be improved by generating explanations for
different types of businesses separately, so that their categorical features
are not combined. Additionally, one could consider only nouns as textual
features and generate explanations based on them. Furthermore, the way
of evaluating explanations based on user preferences can be improved by
considering the semantic similarity of user reviews and all found features.26 Niloofar Ranjbar et al.
References
Chen X, Qin Z, Zhang Y, Xu T (2016) Learning to rank features for rec-
ommendation over multiple categories. In: Proceedings of the 39th In-
ternational ACM SIGIR conference on Research and Development in
Information Retrieval, pp 305–314
Devlin J, Chang MW, Lee K, Toutanova K (2018) Bert: Pre-training
of deep bidirectional transformers for language understanding. arXiv
preprint arXiv:181004805
Fern X, Pope Q (2021) Text counterfactuals via latent optimization and
shapley-guided search. In: Proceedings of the 2021 Conference on Em-
pirical Methods in Natural Language Processing, pp 5578–5593
Garg S, Ramakrishnan G (2020) Bae: Bert-based adversarial examples for
text classification. arXiv preprint arXiv:200401970
GengS,FuZ,TanJ,GeY,DeMeloG,ZhangY(2022)Pathlanguagemod-
eling over knowledge graphsfor explainable recommendation. In: Pro-
ceedings of the ACM Web Conference 2022, pp 946–955
GhazimatinA,BalalauO,SahaRoyR,WeikumG(2020)Prince:Provider-
side interpretability with counterfactual explanations in recommender
systems. In: Proceedings of the 13th International Conference on Web
Search and Data Mining, pp 196–204
Guo C, Sablayrolles A, Jégou H, Kiela D (2021) Gradient-based adversarial
attacksagainsttexttransformers.In:Proceedingsofthe2021Conference
on Empirical Methods in Natural Language Processing, pp 5747–5757
Jang E, Gu S, Poole B (2016) Categorical reparameterization with gumbel-
softmax. arXiv preprint arXiv:161101144
Kalai E, Samet D (1987) On weighted shapley values. International journal
of game theory 16(3):205–222
Kramer O (2017) Genetic algorithms. In: Genetic algorithm essentials,
Springer, pp 11–19
Li L, Ma R, Guo Q, Xue X, Qiu X (2020) Bert-attack: Adversarial at-
tack against bert using bert. In: Proceedings of the 2020 Conference
on Empirical Methods in Natural Language Processing (EMNLP), pp
6193–6202
Madaan N, Padhi I, Panwar N, Saha D (2021) Generate your counter-
factuals: Towards controlled counterfactual generation for text. In: Pro-
ceedings of the AAAI Conference on Artificial Intelligence, vol 35, pp
13516–13524
Molnar C (2022) Interpretable Machine Learning, 2nd edn. URL https:
//christophm.github.io/interpretable-ml-book
Pan D, Li X, Li X, Zhu D (2021) Explainable recommendation via inter-
pretable feature mapping and evaluation of explainability. In: Proceed-
ingsoftheTwenty-NinthInternationalConferenceonInternationalJoint
Conferences on Artificial Intelligence, pp 2690–2696
Shimizu R, Matsutani M, Goto M (2022) An explainable recommendation
framework based on an improved knowledge graph attention networkExplaining Recommendation System Using Counterfactual Textual Explanations 27
with massive volumes of side information. Knowledge-Based Systems
239:107970
Syed MH, Huy TQB, Chung ST (2022) Context-aware explainable recom-
mendation based on domain knowledge graph. Big Data and Cognitive
Computing 6(1):11
Tan J, Xu S, Ge Y, Li Y, Chen X, Zhang Y (2021) Counterfactual explain-
able recommendation. In: Proceedings of the 30th ACM International
Conference on Information & Knowledge Management, pp 1784–1793
Wang N, Wang H, Jia Y, Yin Y (2018a) Explainable recommendation via
multi-task learning in opinionated text data. In: The 41st International
ACM SIGIR Conference on Research & Development in Information
Retrieval, pp 165–174
Wang T, Zheng X, He S, Zhang Z, Wu DD (2020) Learning user-item paths
for explainable recommendation. IFAC-PapersOnLine 53(5):436–440
Wang X, He X, Feng F, Nie L, Chua TS (2018b) Tem: Tree-enhanced
embedding model for explainable recommendation. In: Proceedings of
the 2018 world wide web conference, pp 1543–1552
Wu T, Ribeiro MT, Heer J, Weld DS (2021) Polyjuice: Generating counter-
factuals for explaining, evaluating, and improving models. In: Proceed-
ings of the 59th Annual Meeting of the Association for Computational
Linguistics and the 11th International Joint Conference on Natural Lan-
guage Processing (Volume 1: Long Papers), pp 6707–6723
Yang L, Kenny E, Ng TLJ, Yang Y, Smyth B, Dong R (2020) Generating
plausible counterfactual explanations for deep transformers in financial
text classification. In: Proceedings of the 28th International Conference
on Computational Linguistics, pp 6150–6160
Zhang Y, Lai G, Zhang M, Zhang Y, Liu Y, Ma S (2014) Explicit factor
models for explainable recommendation based on phrase-level sentiment
analysis. In: Proceedings of the 37th international ACM SIGIR confer-
ence on Research & development in information retrieval, pp 83–92
Zhou Y, Wang H, He J, Wang H (2021) From intrinsic to counterfactual:
On the explainability of contextualized recommender systems. arXiv
preprint arXiv:211014844