arXiv:2305.18558v1  [cs.LO]  29 May 2023DelBugV: Delta-Debugging Neural
Network Veriﬁers
Raya Elsaleh and Guy Katz
The Hebrew University of Jerusalem, Jerusalem, Israel
Abstract —Deep neural networks (DNNs) are becoming a key
component in diverse systems across the board. However, des pite
their success, they often err miserably; and this has trigge red
signiﬁcant interest in formally verifying them. Unfortuna tely,
DNN veriﬁers are intricate tools, and are themselves suscep tible
to soundness bugs. Due to the complexity of DNN veriﬁers, as
well as the sizes of the DNNs being veriﬁed, debugging such
errors is a daunting task. Here, we present a novel tool, name d
DELBUGV, that uses automated delta debugging techniques on
DNN veriﬁers. Given a malfunctioning DNN veriﬁer and a corre ct
veriﬁer as a point of reference (or, in some cases, just a sing le,
malfunctioning veriﬁer), D ELBUGV can produce much simpler
DNN veriﬁcation instances that still trigger undesired beh avior —
greatly facilitating the task of debugging the faulty veriﬁ er. Our
tool is modular and extensible, and can easily be enhanced wi th
additional network simpliﬁcation methods and strategies. For
evaluation purposes, we ran D ELBUGV on 4 DNN veriﬁcation
engines, which were observed to produce incorrect results a t the
2021 neural network veriﬁcation competition (VNN-COMP’21 ).
We were able to simplify many of the veriﬁcation queries that
trigger these faulty behaviors, by as much as 99%. We regard o ur
work as a step towards the ultimate goal of producing reliabl e
and trustworthy DNN-based software.
I. I NTRODUCTION
Deep neural networks (DNNs) [22] are software artifacts
that are generated automatically, through the generalizat ion of
a ﬁnite set of examples. These artifacts have been shown to
outdo manually crafted software in a variety of key domains,
such as natural language processing [20], [26], [38], image
recognition [26], [62], protein folding [27], [42], and man y
others. However, this impressive success comes at a price:
unlike traditional software, DNNs are opaque artifacts, an d are
incomprehensible to humans. This poses a serious challenge
when it comes to certifying, modifying, extending, repairi ng
or reasoning about them [23], [28], [33].
In an effort to address these issues, the formal methods
community has taken up an interest in DNN veriﬁcation [28],
[31], [47]: automated techniques that can determine whethe r
a DNN satisﬁes a prescribed speciﬁcation, and provide a
counter-example if it does not. DNN veriﬁcation technology
has been making great strides, and its applicability has bee n
demonstrated in various domains [2]–[4], [19], [31], [34].
In fact, this technology has progressed to a point where
DNN veriﬁers themselves have become quite complex, and
consequently error-prone; especially as they often perfor m
delicate arithmetic operations, which can also introduce b ugs
into the veriﬁcation process [31]. Thus, it is not surprisin g
that various bugs have been observed in these tools [30].
For example, in the VNN-COMP’21 competition [10], variousveriﬁers have been shown to disagree on the result of multipl e
veriﬁcation queries (each query is comprised of a neural
network and a property to be checked), or produce incorrect
counter-examples, indicating the existence of bugs. Moreo ver,
many of these veriﬁers are still being developed, with new an d
experimental features being introduced — potentially intr oduc-
ing new bugs as well. An inability to trust the results of DNN
veriﬁers could undermine the beneﬁts of DNN veriﬁcation
technology, and clearly needs to be addressed.
Here, we propose to mitigate this issue by adopting known
techniques from related ﬁelds (e.g., SMT solving [13]) —
speciﬁcally, that of delta debugging . The idea is to leverage
the fact that DNN veriﬁcation is at a point where many
veriﬁcation tools are available, and to allow engineers to
readily compare the results produced by their veriﬁcation t ool
to those produced by others, in order to identify and correct
bugs. When a veriﬁcation query that triggers some bug in a
veriﬁer is detected, we can initiate an automated process th at
repeatedly and incrementally simpliﬁes the veriﬁcation query.
After each simpliﬁcation step, we can check that the veriﬁer
in question still disagrees with the remaining, oracle veriﬁers,
until reaching the simplest veriﬁcation query that we can ﬁn d.
If this ﬁnal query is much simpler than the original, it will b e
that much easier for engineers to debug their tools, eventua lly
improving their overall soundness.
We present a new tool, D ELBUGV (Delta de Bugging Neural
Network Veriﬁers), that takes as input a veriﬁcation query, a
malfunctioning DNN veriﬁer that errs on the given veriﬁcati on
query, and an oracle DNN veriﬁer. Within D ELBUGV, we
implement a set of operations for simplifying the neural net -
work of the given veriﬁcation query into a network with fewer
layers and fewer neurons. We empirically design a strategy
that applies these operations sequentially in an order that pro-
duces much simpler veriﬁcation queries. In some cases, when
the malfunctioning DNN veriﬁer produces a faulty counter-
example, D ELBUGV can run in single solver mode – without
an oracle veriﬁer, where the query is repeatedly simpliﬁed a s
long as the malfunctioning DNN veriﬁer continues to produce
incorrect counter-examples.
For evaluation, we tested D ELBUGV on 4 DNN veriﬁers
“suspected” of errors, per the results of VNN-COMP’21 [10]:
Marabou [33], [43], [61], NNV [52]–[55], [63], NeuralVeriﬁ -
cation.jl(NV .jl) [37], and nnenum [8], [9], [52], [53]. We r an
DELBUGV on queries where pairs of these veriﬁers disagreed.
Our evaluation demonstrates that D ELBUGV could reduce the
size of the error-triggering queries by an average of 96.8%, andby as much as 99% in some cases, resulting in very simple
neural networks. We believe that these results highlight th e
signiﬁcant potential of our tool and approach.
The rest of the paper is organized as follows. In Sec. II
we provide the necessary background on DNNs and their
veriﬁcation. Next, in Sec. III we describe the design of D EL-
BUGV, focusing on its algorithm and network simpliﬁcation
methods and the strategy we use to apply those methods. The
implementation and evaluation of D ELBUGV is discussed in
Sec. IV. This is followed by a discussion of related work in
Sec. V, and we conclude in Sec. VI.
II. B ACKGROUND
Neural Networks. Aneural network is a directed acyclic
graph in which the nodes, called neurons, are organized in
layersl0,l1,...,ln.l0is called the input layer, lnthe output
layer, and layers l1,...,ln−1are called hidden layers. Each
hidden layer has an associated non-linear activation function .
In feed-forward networks, which are our subject matter here ,
neurons in layer lihave edges connecting them only to neurons
in the next layer, layer li+1.
Each neuron in the network (except the ones in the input
layer) has a bias value, and each edge has a weight. The biases
and weights belonging to neurons in layer liare organized into
a vectorBiand a matrix Wi, respectively. The j,j′-th entry
ofWiis the weight assigned to the edge out-going from the
j′-th neuron in layer li−1and entering the j-th neuron in layer
li. For a fully connected layer,Wiis a full matrix; whereas
for a convolutional layer,Wiis very sparse, and has a speciﬁc
structure (discussed later).
An input to neural network Nis a vector Iof values of the
neurons in the input layer, and it produces an output vector
N(I)which is the values of the neurons in the output layer. We
denote the values of neurons in layer li, prior to applying the
activation function, by Nli(I); and the values after applying
the activation function by Nai(I). The values of the neurons
are evaluated according to the rules:
Nl0(I) =I,Nli(I) =WiNai−1(I)+Bi,
Nai(I) =Acti(Nli(I))
whereActiis the activation function associated with layer li.
We deﬁne the size of a neural network to be the total number
of neurons in the graph (including the neurons in the input an d
output layers) and denote it by |N|. The automated training
(i.e., selection of weights and biases) of neural networks i s
beyond our scope here; see, e.g., [22].
Fig. 1 depicts a neural network, Ne, with a single input, a
single output, and 2 hidden layers with 3 neurons in each. It
uses the ReLU activation function, ReLU(x) = max(0 ,x).
The bias of each neuron is listed above it, and weights arelisted over the edges (zero values are omitted). In matrix
representation, the weights and biases are:
W1=
−5
−0.5
−1
,B1=
10
−2.5
7
,W2=
0.8−1−2
0 0.5 0
2 0.5−1
,
B2=
8
2
0
,W3=
0.25
2
0.5
T
,B3=/bracketleftbig0/bracketrightbig
Neis of size 8 (every li
jandri
jpair in the ﬁgure are counted
as one neuron; we split them only for visualization purposes ),
and has 4 layers. The ﬁgure also demonstrates an evaluation o f
the network, for the input x= 5. The assignment of each node
is listed below it; and we can see that the produced output in
this case is y= 5.
Input layer l0First hidden layer l1Second hidden layer l2
Output layer l3
x
5l1
0
l1
1
l1
2+10
−2.5
+7−15
−5
2r1
0
r1
1
r1
20
0
2l2
0
l2
1
l2
2+8
+24
2
−2r2
0
r2
1
r2
24
2
0y
5−5
−0.5
−1ReLU
ReLU
ReLU0.8
2
−1
0.5
0.5
−2
−1ReLU
ReLU
ReLU0.25
2
0.5
Fig. 1:NeAn example of a neural network with ReLU
activation functions.
Convolutional Neural Networks. Aconvolutional neural
network is a neural network with one or more convolutional
layers (typically, these are the ﬁrst layers of the network) .
The parameters of a convolutional layer include the height h
and width wof images in the input; the kernel size k; the
stride size s; the padding size p; the input channels ci; the
output channels co; the kernel weights W, given as a tensor
of dimensions (co×ci×k×k); and the biases, B, organized
in an array of length co. We assume for simplicity that the
kernel size, padding size, and stride size are equal along al l
axes, although this is not a limitation of our approach.
The convolutional layer ﬁlters its input, which is a (ci×
k×k)-dimensional matrix, using the above parameters and
outputs a multidimensional matrix which represents featur e
maps. For additional information on how a convolutional lay er
computes its output, see [22]. Note that convolutional laye rs
are comprised strictly of linear operations.
Neural Network Veriﬁcation. ApropertyPis a set of
constraints on the inputs and outputs of the neural network.
These constraints give rise to an input region I(P)and an
output region O(P). VerifyingP, with respect to some neuralnetwork, entails determining whether there exists an input in
I(P)that the neural network maps to an output in O(P)
(theSAT case), or not (the UNSAT case). Typically,Pis
speciﬁed so that O(P)represents undesirable behavior, and
so anUNSAT result indicates that the system is correct.
Pe= (5≤x≤10)∧(5≤y≤10)is an example of a
property ofNein Fig. 1.
Aneural network veriﬁer takes in a veriﬁcation query (a
neural network and a property) and attempts to automaticall y
verify it. When successful, it returns a SAT orUNSAT answer;
otherwise, it can return ERROR , orTIMEOUT . When a neural
network veriﬁer returns SAT, it also returns an input that
proves the satisﬁability of the query. Given a veriﬁer Vand
a veriﬁcation query Q= (N,P), we denote byV(Q)∈
{SAT,UNSAT,ERROR,TIMEOUT}the answer ofVonQ. If
V(Q) =SAT, we denote byVw(Q)∈I(P)the satisfying
assignment (the witness) returned by the veriﬁer.
Continuing with our running example, given a sound neural
network veriﬁerVeand the veriﬁcation query Qe= (Ne,Pe),
Ve(Qe) =SAT and a valid witness is (Ve)w(Qe) = (5) , since
Ne((5)) = (5)∈O(Pe).
Neural network veriﬁcation is complex, both theoretically
and practically [31]; and modern tools apply sophisticated
techniques to verify large networks [1]. These techniques a re
typically theoretically sound, but implementation bugs ca n
cause veriﬁers to produce incorrect results. These bugs are
easier to track and correct if the problem manifests for quer ies
with small networks.
In a situation where two veriﬁers disagree on the satisﬁ-
ability of a given query, at least one of them must answer
SAT and provide a satisfying assignment. We evaluate the
neural network on that assignment, and determine whether it
indeed satisﬁes the property at hand. If so, we conclude that
the other veriﬁer, which returned UNSAT , is faulty; otherwise,
if the satisfying assignment is incorrect, we determine tha t the
veriﬁer that answered SAT is faulty. The remaining veriﬁer
then takes the role of the oracle veriﬁer.
III. D ELBUGV: D ELTA -DEBUGGING VERIFICATION
QUERIES
A. General Flow
Applying delta-debugging techniques means automatically
simplifying an input xthat triggers a bug in the system into
a simpler input, x′, that also triggers a bug [41]. x′can often
trigger the bug faster, thus reducing overall debugging tim e;
and also trigger fewer code lines that are unrelated to the
bug, allowing engineers to more easily identify its root cau se.
In our setting, given a veriﬁcation query Q= (N,P)that
triggers a bug in a neural network veriﬁer, we seek to generat e
another query Q′= (N′,P), with a much smaller (simpliﬁed)
neural network:|N′|<|N|. The motivation for focusing on
the neural network, and not on the veriﬁcation conditions, i s
that common veriﬁcation conditions are typically already q uite
simple [58], whereas neural network sizes have a crucial eff ect
on veriﬁer performance [31].The general delta debugging framework that our tool follows
appears as Alg. 1. The inputs to the process are a faulty
veriﬁerV, an oracle veriﬁer VO, and a veriﬁcation query
Q= (N,P). The algorithm maintains a candidate result
neural networkNrthat triggers a bug in Vand make it produce
an incorrect answer, and whose size is iteratively decrease d.
In each iteration, the algorithm invokes Alg. 2 to attempt
simplifyingNr. The process terminates when Alg. 2 states
that it cannot simplify Nrany further, or when a timeout limit
is exceeded. Finally, it returns the veriﬁcation query with the
smallestNrit achieved.
Algorithm 1 Reduce Veriﬁcation Query
Input:V,VO,Q= (N,P)
//Faulty Veriﬁer, Oracle Veriﬁer, Veriﬁcation query
Output: Qr//A simpliﬁed query
1:Nr←N
2:progressMade←True
3:while noTimeout()∧progressMade do
4:Nr←N
5: progressMade,N← Simplify(V,VO,Q)
6:return(Nr,P)
Alg. 2 takes in the same arguments as Alg. 1, and its goal
is to perform one successful simpliﬁcation step on N, from
a pool of potential steps. The algorithm heuristically choo ses
a sequence of simpliﬁcation steps to attempt (Line 1), and
then performs them, one by one, until one is successful. We
propose several simpliﬁcation steps in Sec. III-B. Specify ing
the order according to which theses simpliﬁcation steps are
attempted (Line 1) is key, and different strategies may resu lt in
different simpliﬁed networks — we propose one such strategy
in Sec. III-B.
Algorithm 2 Simplify
Input:V,VO,Q= (N,P)
//Faulty Veriﬁer, Oracle Veriﬁer, Veriﬁcation query
Output: True/False, Qr//Whether the query was simpliﬁed,
and the simpliﬁed query
1:Attempts = (M0,M1,...)←
attemptsBySimpliﬁcationStrategy (N)
2:while Attempts/ne}ationslash=∅do
3:Mi←Attempts.pop()
4:Nr←Mi(N)
5: ifsuccessSimpliﬁcation( V,VO,(Nr,P))then
6: return True,Nr
7:return False,N
Line 5 of Alg. 2 invokes Alg. 3 to check whether the
simpliﬁcation step attempted succeeded or not. To do so,
Alg. 3 ﬁrst checks whether VanswersSAT, but returns an
incorrect counter-example. If so, this candidate should cl early
be kept. Otherwise, the algorithm checks whether VandVO
both answer UNSAT orSAT, but disagree; if so, it returnsTrue. In all other cases, i.e. where one of the veriﬁers times
out, or when there is no basis for comparison (one of the
veriﬁers returned an error), the algorithm returns False, a nd
an alternative simpliﬁcation step in Alg. 2 is attempted.
Algorithm 3 successSimpliﬁcation
Input:V,VO,Q= (N,P)
//Faulty Veriﬁer, Oracle Veriﬁer, Veriﬁcation query
Output: True/False //Was the query successfully simpliﬁed?
1:ifV(N,P) =SAT∧VW(Q)/∈I(P)then
2: return True
3:ifV(N,P) =SAT∧N(VW(Q))/∈O(P)then
4: return True
5:ifV(N,P),VO(N,P)∈{SAT,UNSAT}
∧V(N,P)/ne}ationslash=VO(N,P)then
6: return True
7:return False
One possible risk when using Alg. 1 is a “ﬂip” between the
two veriﬁers. This can happen when initially, VOproduces
a correct answer and Vdoes not; but after a simpliﬁcation
step,Vstarts producing the correct answer and VOstarts
producing an incorrect answer. This situation is unlikely: the
simpliﬁcation steps we propose later make local modiﬁcatio ns
to the network, and are consequently far more likely to
continue to trigger the same bug in Vthan to trigger a new
one inVO. Still, this concern can be mitigated even further
by using multiple oracle veriﬁers, and ensuring that they al l
agree amongst themselves while Vdissents.
Single Veriﬁer Mode. Our approach could also be applied
to delta-debug a single veriﬁer that returns incorrect sati sfy-
ing assignments, without using an oracle. As we explain in
Sec. III-B, the simpliﬁcation methods we apply require the
returned satisfying assignment from either the faulty or th e
oracle veriﬁer, thus, if the faulty veriﬁer returns an incor rect
satisfying assignment for the query at hand, we can drop the
oracle veriﬁer. This is achieved by removing the last “if”
condition from Alg. 3 and removing the oracle veriﬁer VO
from the inputs.
B. Simpliﬁcation Methods
A core component of Alg. 1 is the selection of simpliﬁcation
strategy to apply (Line 1 in Alg. 2). We now describe our pool
of neural network simpliﬁcation methods, and the strategy
that we suggest for selecting among them. The goal of all
the simpliﬁcation methods we propose here is to reduce
neural network sizes, while keeping the network’s behavior
(i.e., its outputs) similar to that of the original; especia lly on
the counter-example provided by either the faulty veriﬁer o r
the oracle veriﬁer. Note that a single simpliﬁcation method
can often be applied multiple times, in different ways, usin g
different input parameters.
Method 1: linearizing piecewise-linear activation functi ons
between fully-connected layers. In general, the presence of
activation functions is a major source of complexity in theveriﬁcation process of neural networks: they render the pro b-
lem NP-complete, require complex mechanisms for linearly
approximating them, and often entail case-splitting that s lows
down the veriﬁers [31], [40], [59]. Thus, in order to simplif y
the neural network, we propose to eliminate such activation
functions, by ﬁxing them to a single linear segment , effectively
replacing them with linear constraints. This procedure is
performed on an entire layer at a time; which, in turn, create s
a sequence of consecutive purely linear layers that can then be
merged into a single linear layer, reducing the overall numb er
of layers and neurons in the network.
In choosing the linear segment to which each function is
ﬁxed, we propose to use the counter-example Iprovided by
either the faulty veriﬁer or the oracle veriﬁer. The output o f the
new linear segment we choose, with respect to I, will match
the output of the activation function on I.
For simplicity, we focus here on the ReLU activation
function ( ReLU(x) = max( x,0)), although the technique
is applicable to any piecewise-linear function. Intuitive ly, in
such cases we propose to replace active ReLUs (x≥0) by
the identify function, and inactive ReLUs (x <0) by zero.
More formally, observe two consecutive layers, ltandlt+1, in
the neural network N, where layer lthas a ReLU activation
function. We construct an alternative layer, la, to replace both
ltandlt+1.lainherits the activation function of lt+1. The
weightsWaand the biases Baoflaare calculated as:
Wa=Wt+1W′Wt
Ba=Wt+1W′Bt+Bt+1
where
W′
i,j=/braceleftBigg
1i=j∧/parenleftBig
Nlt
Q(I)/parenrightBig
i≥0
0otherwise
HereW′is the new linear segment replacing the activation
function ReLU. Finally, the obtained simpliﬁed network Nr
is the networkNwhere layers ltandlt+1are deleted and
replaced with la.
Fig. 2 depicts the result of applying this method on layers
l2andl3from Fig. 1, using the assignment Ie= (5) . Fig. 2a
depicts the layers selected for merging; and Fig. 2b depicts the
resulting neural network. Notice that Nl2
e(Ie) = (4,2,−2),
meaning that only the ReLUs in neurons l2
0andl2
1are active.
Thus, these ReLUs are replaced by the identity function,
whereas the inactive ReLU of l2
2is replaced by 0. After this
step, layers l2andl3perform only linear operations, and are
merged into a single layer.
Method 2: linearizing piecewise-linear activation functi ons
between convolutional layers. In this method, a convolutional
layer is combined with the layer following it (either a fully
connected layer or a convolutional one), and replaced by a
single, fully connected layer.
For simplicity, we focus here on the case where the second
layer is fully connected. More formally, observe two consec u-
tive layers, ltandlt+1inN, whereltis a convolutional layerxl1
0
l1
1
l1
2+10
−2.5
+7r1
0
r1
1
r1
2l2
0
l2
1
l2
2+8
+2r2
0
r2
1
r2
2y−5
−0.5
−1ReLU
ReLU
ReLU0.8
2
−1
0.5
0.5
−2
−1ReLU
ReLU
ReLU0.25
2
0.5
(a)
xl1
0
l1
1
l1
2+10
−2.5
+7r1
0
r1
1
r1
2+6
y−5
−0.5
−1ReLU
ReLU
ReLU0.2
0.75
−0.5
(b)
Fig. 2:Newith layers l2andl3selected in orange (a), and
then merged (b).
andlt+1is a fully connected layer. Our goal is to construct
an alternative layer, la, that will replace ltandlt+1. Since a
convolutional layer is a particular case of fully connected layer,
we construct laby ﬁrst converting the convolutional layer lt
into a fully connected one, denoted lc; then linearizing the
activation functions, as in Method 1 ; and ﬁnally, combining
the two layers into one.
Denote by WtandWt+1the matrices representing the
weights of layer ltandlt+1respectively, and by Btand
Bt+1the vectors representing their respective biases. To
transform a convolutional layer into a fully connecting one ,
we calculate the weights, Wc, and the biases, Bc, of the fully
connected layer replacing the convolutional one, accordin g to
the conventional layer parameters. First, we turn its input and
output from a multidimensional tensors into 1-dimensional
vectors. The height and width (dimensions) of the feature ma ps
in the convolutional layer’s output are: ho,wowhere
ho=/floorleftbiggh+2p−k
s/floorrightbigg
+1, wo=/floorleftbiggw+2p−k
s/floorrightbigg
+1.
The convolutional layer’s output contains cofeature maps, i.e.,
the dimensions of the output are (co×ho×wo). Thus, the
dimensions of Wcare(cohowo×cihw).Wcis a sparse matrix.
To calculate the value of the i,j-th entry in Wc, we ﬁrstcompute the following values:
c′
i=/floorleftbiggj
hw/floorrightbigg
, c′
o=/floorleftbiggi
howo/floorrightbigg
,
i′=/floorleftbiggi−cihw
w/floorrightbigg
−/parenleftbigg/floorleftbiggj−cohowo
wo/floorrightbigg
·s−p/parenrightbigg
j′= ((i−cihw) modw)−(((j−cohowo) modwo)·s−p)
c′
iandc′
oare the input and output channels that the i,j-th
entry should be associated with. i′andj′are the indices in
the kernel that should match to the i,j-th entry. The weight
matrixWcis given by:
Wc
i,j=/braceleftBigg
Wt
c′
i,c′o,i′,j′0≤i′∧j′< k
Wc
i,j= 0 otherwise
Finally,
Bc
i=Bt
⌊i
howo⌋
According to this construction of WcandBc, they will
have the same functionality as the convolutional operation they
replace. This step may temporarily increase the number of
edges in the network (but not the number of neurons). This is
required to prepare for the minimization step.
The next step is to linearize the ReLU. This is done in a
similar manner to the linearization in the previous method,
from which we get W′. Next, we construct the weights Wa
and the biases Baof the alternative layer la:
Wa=Wt+1W′Wc
Ba=Wt+1W′Bc+Bt+1
And the activation function assigned to the new layer lais the
same as the one assigned to layer lt+1. Finally, the simpliﬁed
neural networkNris the networkN, where layers ltandlt+1
are deleted and replaced with la.
In caselt+1is also a convolutional layer, we convert it to
a fully connected layer, as we did with lt; and the remainder
of the process is unchanged.
Method 3: merging neurons. In this method, we seek to
merge a pair of neurons in the same layer into a single neuron,
thus decreasing the neural network size by one. Of course, th is
entails selecting the weights of this new neuron’s incoming and
outgoing edges, as well as its bias. Our motivation is to caus e
the merged neuron to produce values close to those of the
original neurons, and consequently cause little changes in the
neural network’s eventual output. We present ﬁrst the techn ical
process of merging neurons, and later discuss which pairs of
neurons should be merged.
We focus again on the case where the activation function is
ReLU. We ﬁrst use the counter-example I(returned by either
the faulty veriﬁer or the oracle veriﬁer) to check whether th e
activation functions of the neurons being merged have the
same phase — i.e., if they are both active, or both inactive. I f
they have the same phase, we compute the merged neuron’s
weights and biases using the original neurons’ weights andbiases. Speciﬁcally, the weight of each edge incoming to the
merged neuron is the mean of the original incoming edge
weights, and the neuron’s bias is the mean of the original
neurons’ biases; whereas the weights of its outgoing edges
are the weighted sum, according to I, of the original outgoing
edge weights (a weighted sum is needed, instead of a simple
sum, to ensure that the neurons in the following layer obtain
values similar to their original ones with respect to I). In
case one of the neurons is active and the other is inactive,
we simply delete the inactive one, since it does not contribu te
to the following layer’s neuron values (with respect to I).
Formally, given a neural network, N, two successive layers
in it,ltandlt+1, and two neurons indices b < c , we
construct two alternative layers laandla+1that will replace
ltandlt+1respectively. Additionally, laandla+1inherit the
activation functions of ltandlt+1respectively. If the ReLUs
of the neurons bandcin layer lthave the same phases: /parenleftBig
Nlt(I)/parenrightBig
b,/parenleftBig
Nlt(I)/parenrightBig
c>0or/parenleftBig
Nlt(I)/parenrightBig
b,/parenleftBig
Nlt(I)/parenrightBig
c<0,
the weights and the biases Wa,Wa+1,Ba,Ba+1of the alter-
native layers are calculated as follows:
Ba
i=

Bt
ii < b∨b < i < c
Bt
b+Bt
c
2i=b
Bt
i+1c≤i
Ba+1=Bt+1
Wa
i,j=

Wt
i,j i < b∨b < i < c
Wt
b,j+Wt
c,j
2i=b
Wt
i+1,jc≤i
Wa+1
i,j=

Wt+1
i,j j < b∨b < j < c
2·/parenleftBig
Wt+1
i,b/parenleftBig
Nlt+1(I)/parenrightBig
b+Wt+1
i,c/parenleftBig
Nlt+1(I)/parenrightBig
c/parenrightBig
(Nlt+1(I))b+(Nlt+1(I))cj=b
Wt+1
i,j+1 c≤j
Otherwise, if the ReLUs of the neurons bandcin layer
lthave different phases:/parenleftBig
Nlt(I)/parenrightBig
b>0∧/parenleftBig
Nlt(I)/parenrightBig
c<0
(assume w.l.o.g. that the c-th neuron is the inactive one), the
weights and biases Wa,Wa+1,Ba,Ba+1of the alternative
layers are calculated as follows:
Ba
i=/braceleftBigg
Bt
ii < c
Bt
i+1c≤i, Ba+1=Bt+1
Wa
i,j=/braceleftBigg
Wt
i,ji < c
Wt
i+1,jc≤i, Wa+1
i,j=/braceleftBigg
Wt+1
i,jj < c
Wt+1
i,j+1c≤j
Finally, the obtained simpliﬁed neural network Nr, is the
networkNwhere layers ltandlt+1are replaced with laand
la+1respectively. This method can be applied repeatedly, to
reduce the network size even further.
An example of applying this method on the pair of neurons
l2
0andl2
1inNefrom Fig. 1 using the assignment Ie= (5)
appears in Fig. 3. Fig. 3a shows the neurons selected for
merging, and Fig. 3b shows the result of the merge.
Choosing which pair of neurons to merge is crucial for
the success of this method. Every two neurons in the samexl1
0
l1
1
l1
2+10
−2.5
+7r1
0
r1
1
r1
2l2
0
l2
1
l2
2+8
+2r2
0
r2
1
r2
2y−5
−0.5
−1ReLU
ReLU
ReLU0.8
2
−1
0.5
0.5
−2
−1ReLU
ReLU
ReLU0.25
2
0.5
(a)
xl1
0
l1
1
l1
2+10
−2.5
+7r1
0
r1
1
r1
2l2
0
l2
l+5
r2
0
r2
1y−5
−0.5
−1ReLU
ReLU
ReLU0.4
2
−0.25
0.5
−1
−1ReLU
ReLU5/3
0.5
(b)
Fig. 3:Newith neurons l2
0andl2
1selected in orange (a), and
then merged (b).
layer are valid candidates; however, some pairs are more
likely to succeed than others by resulting in a simpliﬁed
neural network that behaves similarly to the original. We
consider the following possible approaches for prioritizi ng
between the pairs: (1) an arbitrary ordering; (2) prioritiz ing
pairs with neurons that are assigned similar values (prior t o
the activation function), when the network is evaluated on
assignment I. The motivation is that merging such pairs is
expected to have smaller effect on the overall functionalit y
of the neural network; (3) prioritizing pairs of neurons who se
ReLUs are inactive when evaluated on I. The motivation is
that inactive neurons may have little effect on the bug at han d.
This approach can be combined with Approach 2 to prioritize
pairs with similar values after categorizing them by the sta tus
of the ReLUs; (4) prioritizing pairs of neurons with positiv e
values with respect to I. This approach, too, can be combined
with Approach 2; and (5) prioritizing pairs of neurons with
negative values, and then pairs with positive values, with
respect to I. This approach is a combination of Approaches
3 and 4, and again uses Approach 2 for internal prioritizatio n
within each category.
Strategy for applying the simpliﬁcation rules. Within Alg. 1,
the simpliﬁcation steps mentioned above can be invoked in an y
order. We propose to attempt methods that signiﬁcantly redu ce
the neural network size ﬁrst, in order to reduce veriﬁcation
times. We empirically observed that this is achieved by the
following strategy: ﬁrst, attempt to linearize and merge co n-volutional layers ( Method 2 ). Second, attempt to linearize and
merge fully connected layers ( Method 1 ) — starting with the
output layer, and working backwards towards the input layer .
Finally, merge neurons ( Method 3 ) according to Approach 5.
However, our implementation is highly customizable, and
users can conﬁgure it to use any other strategy, according to
the task at hand.
To illustrate, applying our proposed strategy to Nefrom
Fig. 1, with respect to the assignment Ie= (5) in which
Nl1
e(Ie) = (−15,−5,2)andNl2
e(Ie) = (4,2,−2), would
result in attempting the simpliﬁcation methods in the follo wing
order: (1) merge the layers l2andl3; (2) merge the layers l1
andl2; (3) merge the pair of neurons l1
0,l1
1; (4) merge the pair
of neurons l2
1,l2
2; (5) merge the pair of neurons l2
0,l2
2; (6) merge
the pair of neurons l1
1,l1
2; and then, (7) merge the pair of
neuronsl1
0,l1
2. These steps are attempted, in order, until one
succeeds; after which the strategy is reapplied to the simpl iﬁed
network, and so on.
IV. I MPLEMENTATION AND EVALUATION
We designed our tool, D ELBUGV, to be compatible with
the standard input format used in the VNN-COMP competi-
tion [10], in which veriﬁcation queries are encoded using th e
VNN-LIB format [12]; and which, in turn, relies on the Open
Neural Network Exchange (ONNX ) format. This facilitated
integrating D ELBUGV with the various veriﬁers. D ELBUGV is
implemented in Python, and contains classes that wrap objec ts
of these formats. The tool has a modular design that allows
applying our proposed minimization methods in any order
desired.
VNN-COMP’21 included 12 participating neural network
veriﬁers, and these were tested on a set of veriﬁcation
queries. We began by extracting from the VNN-COMP’21
results pairs of dissenting veriﬁers, and the veriﬁcation q ueries
that triggered these discrepancies. Each such triple (two
veriﬁers and a query) constitutes an input to D ELBUGV.
This extraction led us to target the following veriﬁers:
(1) Marabou [33]; (2) NNV [52]–[55], [63]; (3) NeuralVer-
iﬁcation.jl (NV .jl) [37]; and (4) nnenum [8], [9], [52], [53 ]. In
the experiments described next, we used the same versions of
these veriﬁers that were used in VNN-COMP’21.
Neuron Merging and Prioritization Approaches. For our
ﬁrst experiment, we set out to determine which of the neuron-
pair prioritization schemes described as part of Method 3
in Sec. III-B is the most successful. We measured success
along two parameters: the size of the simpliﬁed network
obtained, and by the percentage of successful merging steps
along the way. We tested our algorithm on 5 input triples,
involving networks of size 310 each. Using only Method 3 ,
we ran D ELBUGV with each of the prioritization schemes,
and counted for each, the number of merging steps performed
and the number of the steps that succeeded. Table. I shows
the results of this comparison: the second column indicates ,
for every approach, the percentage of the successful steps o ut
of all the steps tried, aggregated for all 5 benchmarks.Looking at the average reduction sizes, the results indicat e
that all 5 approaches were able to achieve a similar reductio n
in size, with a slight advantage to approaches 1, 3 and 5.
However, the number of successful merges varied signiﬁcant ly
— from Approach 1, in which only 37.2% of the merge steps
were successful, and up to 75.9% for Approach 5 (in bold).
These results thus indicate that Approach 5 is the most efﬁci ent
of the 5, and so we used it as our default strategy for Method
3 in the subsequent experiments.
TABLE I: Comparing neurons merging approaches (Method
3) by size reduction and successful merges.
Successful merges (%) Average Reduction (%)
Approach 1 37.2% 96.0%
Approach 2 68.4% 95.9%
Approach 3 71.6% 96.0%
Approach 4 62.9% 95.8%
Approach 5 75.9% 96.0%
Linearizing ReLU Activations. InMethod 1 andMethod 2 in
Sec. III-B, we proposed to linearize activation functions, and
then merge them with the previous and following layers. Thes e
methods can be applied to any piecewise-linear activation
function in the network. The order in which they are applied
is customizable. In this experiment, we set out to compare li n-
earizing ReLUs in ascending order (from input layer towards
output layer), and in descending order (from output towards
input). Table II shows the results of this experiment.
Every row in the table corresponds to an input triple to
DELBUGV (two disagreeing veriﬁers and a veriﬁcation query
that they disagreed on), and the two simpliﬁcation approach es
that were attempted. For each such experiment, the second
column indicates the number of simpliﬁcation steps tried, u ntil
DELBUGV reached saturation (there were no additional steps
to try). The third column indicates the number of the success -
ful steps out of all the steps. In column four, the percentage
successful steps out of all steps is shown; and the ﬁnal colum n
shows the reduction percentage in the neural network size.
When one of the approaches was clearly superior, the entry
appears in bold.
To analyze the results, observe, e.g., the 5th experiment
in Table II. The results imply that when using the ascending
approach, 12 linearizing and merging steps were made, until
the network count not be simpliﬁed further with either Method
1orMethod 2 . Of these 12 steps, 5 were successful —
and consequently, the simpliﬁed network has 5 fewer layers
than the original. In contrast, with the descending approac h
only 9 steps were made until the network could not be
simpliﬁed further, 6 of which were successful. Consequentl y,
the simpliﬁed network in this case has 6 fewer layers compare d
to the original.
The results indicate that linearizing in descending order
slightly outperforms linearizing in ascending order, alth ough
the gap is not very signiﬁcant. The neural network in the
last row included a convolutional layer, and, according to
the results, linearizing it in ascending order preformed be tter.After investigating this query further, we noticed that in t he
ascending order approach, the convolutional layer was merg ed
into a fully connected one; whereas the descending approach
did not succeed in removing or merging any convolutional
layers. We thus conclude that, for a convolutional network, it
is advisable to apply Method 2 before applying Method 1 .
TABLE II: Comparing linearizing layers approaches by suc-
cessful steps. * indicates the existence of a convolutional layer.
Linearizing
approachNo. of
stepsNo. of
successful
stepsSuccessful
steps %Neuron
reduction %
1.Ascending 6 6 100.0% 96.7%
Descending 6 6 100.0% 96.7%
2.Ascending 6 6 100.0% 96.7%
Descending 6 6 100.0% 96.7%
3.Ascending 6 6 100.0% 96.7%
Descending 6 6 100.0% 96.7%
4.Ascending 6 0 0.0% 0.0%
Descending 6 0 0.0% 0.0%
5.Ascending 12 5 41.6% 80.6%
Descending 9 6 66.6% 96.7%
6.Ascending 3 2 66.6% 39.2%
Descending 2 2 100.0% 39.2%
7.Ascending 3* 2* 66.6% 65.8%
Descending 2* 1 50.0% 0.0%
Delta Debugging Discrepancies from VNN-COMP’21. For
our ﬁnal experiment, we considered 13 triples of veriﬁers,
oracle veriﬁers, and veriﬁcation queries. Of these triples , 11
contained DNNs from the ACAS-Xu family [31], 1 was a
DNN from the MNIST DNNs [36], and 1 was a DNN from
the Oval21 benchmark [10]. Using the optimal conﬁguration
of our tool as previously discussed, we applied the full-blo wn
delta-debugging algorithm to all of our 13 benchmarks. The
results appear in Table. III. Every row in the table represen ts
a triple, and the ﬁrst two columns indicate the number of
neurons in the original network, and the number of remaining
neurons after delta debugging was applied. The next two
columns indicate the number of layers in the original and
reduced networks; and the ﬁnal column indicates the percent
of neurons that were removed.
TABLE III: Delta-debugging using our algorithm. * indicate s
the existence of a convolutional layer.
Neurons Layers Reduction
percentage In Original In reduced In original In reduced
310 6 8 2 98%
310 7 8 2 97%
310 6 8 2 98%
310 12 8 8 96%
310 6 8 2 98%
9326 12 5* 3 99%
1306 11 4 2 99%
310 10 8 3 96%
310 6 8 2 98%
310 10 8 4 96%
310 10 8 4 96%
310 9 8 4 97%
310 13 8 6 95%
Overall, the algorithm performed exceedingly well, reduci ng
the network sizes by an average of 96.8% (!); and, in somecases, causing a size decrease of 99%, from a neural network
with 1306 neurons and 4 layers to just 11 neurons and 2 layers
(an input layer and an output layer, without any activation
functions). The minimal decrease observed was 95%, from
310 neurons to 13. We regard these results as a very strong
indication of the usefulness of delta debugging in the conte xt
of DNN veriﬁcation. Further analyzing the results, we obser ve
that the ReLU linearization simpliﬁcation rule was respons ible
for an average of 66% of the size reduction, whereas the
remaining two rules were responsible for an average of 34% —
indicating that the ReLU linearization simpliﬁcation rule is the
main workhorse of our approach at its current conﬁguration.
V. R ELATED WORK
With the increasing pervasiveness of DNNs, the veriﬁca-
tion community has been devoting growing efforts to veri-
fying them. Numerous approaches have been proposed, in-
cluding SMT-based approaches [24], [31]–[33], [50], [60],
approaches based on LP or MILP solvers [15], [17], [51],
reachability-based approaches [39], [63], abstraction an d
abstract-interpretation based approaches [6], [19], [25] , [28],
[40], [46], [48], [59], synthesis-based approaches [34], [ 44],
run-time optimization [5], [7], quantitative veriﬁcation [11],
veriﬁcation of recurrent networks [29], [65], and many othe rs.
These approaches, in turn, have been used in numerous appli-
cation domains [16], [18], [21], [49], [56], [57], [64]. Giv en
the scope of these efforts, and the number of available tools ,
it is not surprising that bugs are abundant, and that enginee rs
are in need of efﬁcient debugging tools.
To the best of our knowledge, no previous work has applied
delta debugging in the context of DNN veriﬁcation, although
similar approaches have been shown successful in the relate d
domains of SMT [13], [41] and SAT [14] solving. Related
efforts have attempted to reduce DNN sizes, with the purpose
of producing smaller-but-equivalent networks, or network s
smaller with a respect to a particular veriﬁcation property of
interest [6], [35], [45], [46]. In the future, principles fr om these
approaches could be integrated as simpliﬁcation strategie s
within our delta-debugging approach.
VI. C ONCLUSION
In this paper, we presented the D ELBUGV tool for automat-
ically reducing the size of a veriﬁcation query with respect to
an erroneous neural network veriﬁer. We focused on delta-
debugging techniques, and proposed multiple minimization
methods for reducing neural network sizes. These technique s
attempt to simplify the neural network in question, while mo d-
ifying it as little as possible. We also suggested a strategy for
the order in which to apply those methods. We demonstrated
the effectiveness of D ELBUGV on actual benchmarks from the
VNN-COMP’21 competition, and were able to signiﬁcantly
simplify them. We regard this work as another step towards
more sound tools for DNN veriﬁcation.
Acknowledgements. This work was partially supported by the
Israel Science Foundation (grant number 683/18).REFERENCES
[1] A. Albarghouthi. Introduction to Neural Network Veriﬁcation . veriﬁed-
deeplearning.com, 2021.
[2] G. Amir, Z. Freund, G. Katz, E. Mandelbaum, and I. Refaeli . veriFIRE:
Verifying an Industrial, Learning-Based Wildﬁre Detectio n. In Proc.
25th Int. Symposium on Formal Methods (FM) , pages 648–656, 2023.
[3] G. Amir, G. Katz, and M. Schapira. Veriﬁcation-Aided Dee p Ensemble
Selection. In Proc. 22nd Int. Conf. on Formal Methods in Computer-
Aided Design (FMCAD) , pages 27–37, 2022.
[4] G. Amir, M. Schapira, and G. Katz. Towards Scalable Veriﬁ cation
of Deep Reinforcement Learning. In Proc. 21st Int. Conf. on Formal
Methods in Computer-Aided Design (FMCAD) , pages 193–203, 2021.
[5] G. Anderson, S. Pailoor, I. Dillig, and S. Chaudhuri. Opt imization
and Abstraction: a Synergistic Approach for Analyzing Neur al Network
Robustness. In Proc. 40th ACM SIGPLAN Conf. on Programming
Languages Design and Implementations (PLDI) , pages 731–744, 2019.
[6] P. Ashok, V . Hashemi, J. Kretinsky, and S. Mohr. DeepAbst ract: Neural
Network Abstraction for Accelerating Veriﬁcation. In Proc. 18th Int.
Symp. on Automated Technology for Veriﬁcation and Analysis (ATVA) ,
pages 92–107, 2020.
[7] G. Avni, R. Bloem, K. Chatterjee, T. Henzinger, B. K¨ onig hofer, and
S. Pranger. Run-Time Optimization for Learned Controllers through
Quantitative Games. In Proc. 31st Int. Conf. on Computer Aided
Veriﬁcation (CAV) , pages 630–649, 2019.
[8] B. Bak. nnenum: Veriﬁcation of Relu Neural Networks with Optimized
Abstraction Reﬁnement. In Proc. 13th NASA Formal Methods Sympo-
sium (NFM) , pages 19–36, 2021.
[9] S. Bak. Execution-Guided Overapproximation (EGO) for I mproving
Scalability of Neural Network Veriﬁcation. In Proc. 3rd Int. Workshop
on Veriﬁcation of Neural Networks (VNN) , 2020.
[10] S. Bak, C. Liu, and T. Johnson. The Second International Veriﬁcation
of Neural Networks Competition (VNN-COMP 2021): Summary an d
Results, 2021. Technical Report. http://arxiv.org/abs/2 109.00498.
[11] T. Baluta, S. Shen, S. Shinde, K. Meel, and P. Saxena. Qua ntitative
Veriﬁcation of Neural Networks and its Security Applicatio ns. In Proc.
ACM SIGSAC Conf. on Computer and Communications Security (C CS),
pages 1249–1264, 2019.
[12] C. Barrett, G. Katz, D. Guidotti, L. Pulina, N. Narodyts ka, and A. Tac-
chella. The Veriﬁcation of Neural Networks Library (VNN-LI B), 2019.
www.vnnlib.org.
[13] R. Brummayer and A. Biere. Fuzzing and Delta-Debugging SMT
Solvers. In Proc. 7th Int. Workshop on Satisﬁability Modulo Theories
(SMT) , 2009.
[14] R. Brummayer, F. Lonsing, and A. Biere. Automated Testi ng and
Debugging of SAT and QBF Solvers. In Proc. 13th Int. Conf. on Theory
and Applications of Satisﬁability Testing (SAT) , pages 44–57, 2010.
[15] R. Bunel, I. Turkaslan, P. Torr, P. Kohli, and P. Mudigon da. A
Uniﬁed View of Piecewise Linear Neural Network Veriﬁcation . InProc.
32nd Conf. on Neural Information Processing Systems (NeurI PS), pages
4795–4804, 2018.
[16] G. Dong, J. Sun, J. Wang, X. Wang, and T. Dai. Towards
Repairing Neural Networks Correctly, 2020. Technical Repo rt.
http://arxiv.org/abs/2012.01872.
[17] R. Ehlers. Formal Veriﬁcation of Piece-Wise Linear Fee d-Forward
Neural Networks. In Proc. 15th Int. Symp. on Automated Technology
for Veriﬁcation and Analysis (ATVA) , pages 269–286, 2017.
[18] T. Eliyahu, Y . Kazak, G. Katz, and M. Schapira. Verifyin g Learning-
Augmented Systems. In Proc. Conf. of the ACM Special Interest Group
on Data Communication on the Applications, Technologies, A rchitec-
tures, and Protocols for Computer Communication (SIGCOMM) , pages
305–318, 2021.
[19] T. Gehr, M. Mirman, D. Drachsler-Cohen, E. Tsankov, S. C haudhuri,
and M. Vechev. AI2: Safety and Robustness Certiﬁcation of Ne ural
Networks with Abstract Interpretation. In Proc. 39th IEEE Symposium
on Security and Privacy (S&P) , 2018.
[20] Y . Goldberg. A Primer on Neural Network Models for Natur al Language
Processing. Journal of Artiﬁcial Intelligence Research , 57:345–420,
2016.
[21] B. Goldberger, Y . Adi, J. Keshet, and G. Katz. Minimal Mo diﬁcations
of Deep Neural Networks using Veriﬁcation. In Proc. 23rd Int. Conf. on
Logic for Programming, Artiﬁcial Intelligence and Reasoni ng (LPAR) ,
pages 260–278, 2020.[22] I. Goodfellow, Y . Bengio, and A. Courville. Deep Learning . MIT Press,
2016.
[23] I. Goodfellow, J. Shlens, and C. Szegedy. Explaining an d
Harnessing Adversarial Examples, 2014. Technical Report.
http://arxiv.org/abs/1412.6572.
[24] D. Gopinath, G. Katz, C. Pˇ asˇ areanu, and C. Barrett. De epSafe: A
Data-driven Approach for Checking Adversarial Robustness in Neural
Networks. In Proc. 16th. Int. Symp. on on Automated Technology for
Veriﬁcation and Analysis (ATVA) , pages 3–19, 2018.
[25] E. Goubault, S. Palumby, S. Putot, L. Rustenholz, and S. Sankara-
narayanan. Static Analysis of ReLU Neural Networks with Tro pical
Polyhedra. In Proc. 28th Int. Symposium on Static Analysis (SAS) , pages
166–190, 2021.
[26] J. Guo, H. He, T. He, L. Lausen, M. Li, H. Lin, X. Shi, C. Wan g, J. Xie,
S. Zha, et al. GluonCV and GluonNLP: Deep Learning in Compute r
Vision and Natural Language Processing. Journal of Machine Learning
Research , 21(23):1–7, 2020.
[27] J. Hou, B. Adhikari, and J. Cheng. DeepSF: Deep Convolut ional Neural
Network for Mapping Protein Sequences to Folds. Bioinformatics ,
34(8):1295–1303, 2018.
[28] X. Huang, M. Kwiatkowska, S. Wang, and M. Wu. Safety Veri ﬁcation
of Deep Neural Networks. In Proc. 29th Int. Conf. on Computer Aided
Veriﬁcation (CAV) , pages 3–29, 2017.
[29] Y . Jacoby, C. Barrett, and G. Katz. Verifying Recurrent Neural Networks
using Invariant Inference. In Proc. 18th Int. Symposium on Automated
Technology for Veriﬁcation and Analysis (ATVA) , pages 57–74, 2020.
[30] K. Jia and M. Rinard. Exploiting Veriﬁed Neural Network s
via Floating Point Numerical Error, 2020. Technical Report .
http://arxiv.org/abs/2003.03021.
[31] G. Katz, C. Barrett, D. Dill, K. Julian, and M. Kochender fer. Reluplex:
An Efﬁcient SMT Solver for Verifying Deep Neural Networks. I nProc.
29th Int. Conf. on Computer Aided Veriﬁcation (CAV) , pages 97–117,
2017.
[32] G. Katz, C. Barrett, D. Dill, K. Julian, and M. Kochender fer. Reluplex:
a Calculus for Reasoning about Deep Neural Networks, 2021.
[33] G. Katz, D. Huang, D. Ibeling, K. Julian, C. Lazarus, R. L im, P. Shah,
S. Thakoor, H. Wu, A. Zelji´ c, D. Dill, M. Kochenderfer, and C . Barrett.
The Marabou Framework for Veriﬁcation and Analysis of Deep N eural
Networks. In Proc. 31st Int. Conf. on Computer Aided Veriﬁcation
(CAV) , pages 443–452, 2019.
[34] B. K¨ onighofer, F. Lorber, N. Jansen, and R. Bloem. Shie ld Synthesis
for Reinforcement Learning. In Proc. Int. Symposium on Leveraging
Applications of Formal Methods, Veriﬁcation and Validatio n (ISoLA) ,
pages 290–306, 2020.
[35] O. Lahav and G. Katz. Pruning and Slicing Neural Network s using
Formal Veriﬁcation. In Proc. 21st Int. Conf. on Formal Methods in
Computer-Aided Design (FMCAD) , pages 183–192, 2021.
[36] Y . LeCun. The MNIST Database of Handwritten Digits, 199 8.
http://yann.lecun.com/exdb/mnist/.
[37] C. Liu, T. Arnon, C. Lazarus, C. Barrett, and M. Kochende rfer. Algo-
rithms for Verifying Deep Neural Networks, 2020. Technical Report.
http://arxiv.org/abs/1903.06758.
[38] X. Liu, P. He, W. Chen, and J. Gao. Multi-Task Deep Neural
Networks for Natural Language Understanding, 2019. Techni cal Report.
http://arxiv.org/abs/1901.11504.
[39] A. Lomuscio and L. Maganti. An Approach to Reachability Analysis
for Feed-Forward ReLU Neural Networks, 2017. Technical Rep ort.
http://arxiv.org/abs/1706.07351.
[40] M. M¨ uller, G. Makarchuk, G. Singh, M. P¨ uschel, and M. V echev.
PRIMA: General and Precise Neural Network Certiﬁcation via Scalable
Convex Hull Approximations. In Proc. 49th ACM SIGPLAN Symposium
on Principles of Programming Languages (POPL) , 2022.
[41] A. Niemetz, M. Preiner, and C. Barrett. Murxla: A Modula r and Highly
Extensible API Fuzzer for SMT Solvers. In Proc. 34th Int. Conf. on
Computer Aided Veriﬁcation (CAV) , pages 92–106, 2022.
[42] F. No´ e, G. De Fabritiis, and C. Clementi. Machine Learn ing for Protein
Folding and Dynamics. Current Opinion in Structural Biology , 60:77–
84, 2020.
[43] M. Ostrovsky, C. Barrett, and G. Katz. An Abstraction-R eﬁnement
Approach to Verifying Convolutional Neural Networks. In Proc. 20th.
Int. Symposium on Automated Technology for Veriﬁcation and Analysis
(ATVA) , pages 391–396, 2022.
[44] E. Polgreen, R. Abboud, and D. Kroening. Counterexampl e Guided Neu-
ral Synthesis, 2020. Technical Report. https://arxiv.org /abs/2001.09245.[45] P. Prabhakar. Bisimulations for Neural Network Reduct ion. In Proc.
23rd Int. Conf. Veriﬁcation on Model Checking, and Abstract Interpre-
tation (VMCAI) , pages 285–300, 2022.
[46] P. Prabhakar and Z. Afzal. Abstraction Based Output Ran ge
Analysis for Neural Networks, 2020. Technical Report.
https://arxiv.org/abs/2007.09527.
[47] L. Pulina and A. Tacchella. An Abstraction-Reﬁnement A pproach to
Veriﬁcation of Artiﬁcial Neural Networks. In Proc. 22nd Int. Conf. on
Computer Aided Veriﬁcation (CAV) , pages 243–257, 2010.
[48] G. Singh, T. Gehr, M. Puschel, and M. Vechev. An Abstract Domain for
Certifying Neural Networks. In Proc. 46th ACM SIGPLAN Symposium
on Principles of Programming Languages (POPL) , 2019.
[49] M. Sotoudeh and A. Thakur. Correcting Deep Neural Netwo rks with
Small, Generalizing Patches. In Workshop on Safety and Robustness in
Decision Making , 2019.
[50] C. Strong, H. Wu, A. Zelji´ c, K. Julian, G. Katz, C. Barre tt, and
M. Kochenderfer. Global Optimization of Objective Functio ns Repre-
sented by ReLU Networks. Journal of Machine Learning , pages 1–28,
2021.
[51] V . Tjeng, K. Xiao, and R. Tedrake. Evaluating Robustnes s of Neural
Networks with Mixed Integer Programming, 2017. Technical R eport.
http://arxiv.org/abs/1711.07356.
[52] H.-D. Tran, S. Bak, W. Xiang, and T. Johnson. Veriﬁcatio n of Deep
Convolutional Neural Networks Using ImageStars. In Proc. 32nd Int.
Conf. on Computer Aided Veriﬁcation (CAV) , pages 18–42, 2020.
[53] H.-D. Tran, D. Manzanas Lopez, P. Musau, X. Yang, L. Nguy en,
W. Xiang, and T. Johnson. Star-Based Reachability Analysis of Deep
Neural Networks. In Proc. Int. Symposium on Formal Methods (FM) ,
pages 670–686, 2019.
[54] H.-D. Tran, P. Musau, D. Lopez, X. Yang, L. Nguyen, W. Xia ng,
and T. Johnson. Parallelizable Reachability Analysis Algo rithms for
Feed-Forward Neural Networks. In Proc. 7th Int. Workshop on Formal
Methods in Software Engineering (FormaliSE) , pages 31–40, 2019.
[55] H.-D. Tran, X. Yang, D. Lopez, P. Musau, L. Nguyen, W. Xia ng, S. Bak,
and T. Johnson. NNV: The Neural Network Veriﬁcation Tool for Deep
Neural Networks and Learning-Enabled Cyber-Physical Syst ems, 2020.
Technical Report. http://arxiv.org/abs/2004.05519.
[56] C. Urban, M. Christakis, V . W¨ ustholz, and F. Zhang. Per fectly Parallel
Fairness Certiﬁcation of Neural Networks. In Proc. ACM Int. Conf.
on Object Oriented Programming Systems Languages and Appli cations
(OOPSLA) , pages 1–30, 2020.
[57] M. Usman, D. Gopinath, Y . Sun, Y . Noller, and C. Pˇ asˇ are anu. NNrepair:
Constraint-based Repair of Neural Network Classiﬁers, 202 1. Technical
Report. http://arxiv.org/abs/2103.12535.
[58] International Veriﬁcation of Neural Networks Competi tion (VNN-
COMP), 2020. https://sites.google.com/view/vnn20/vnnc omp.
[59] S. Wang, H. Zhang, K. Xu, X. Lin, S. Jana, C.-J. Hsieh, and Z. Kolter.
Beta-CROWN: Efﬁcient Bound Propagation with Per-Neuron Sp lit Con-
straints for Complete and Incomplete Neural Network Veriﬁc ation. In
Proc. 35th Conf. on Neural Information Processing Systems ( NeurIPS) ,
2021.
[60] H. Wu, A. Ozdemir, A. Zelji´ c, A. Irfan, K. Julian, D. Gop inath,
S. Fouladi, G. Katz, C. P˘ as˘ areanu, and C. Barrett. Paralle lization
Techniques for Verifying Neural Networks. In Proc. 20th Int. Conf. on
Formal Methods in Computer-Aided Design (FMCAD) , pages 128–137,
2020.
[61] H. Wu, A. Zelji´ c, G. Katz, and C. Barrett. Efﬁcient Neur al Network
Analysis with Sum-of-Infeasibilities. In Proc. 28th Int. Conf. on Tools
and Algorithms for the Construction and Analysis of Systems (TACAS) ,
pages 143–163, 2022.
[62] R. Wu, S. Yan, Y . Shan, Q. Dang, and G. Sun. Deep Image: Sca ling up
Image Recognition. Technical Report. http://arxiv.org/a bs/1501.02876.
[63] W. Xiang, H. Tran, and T. Johnson. Output Reachable Set E stimation
and Veriﬁcation for Multi-Layer Neural Networks. IEEE Transactions
on Neural Networks and Learning Systems (TNNLS) , 2018.
[64] X. Yang, T. Yamaguchi, H.-D. Tran, B. Hoxha, T. Johnson, and
D. Prokhorov. Neural Network Repair with Reachability Anal ysis, 2021.
Technical Report. https://arxiv.org/abs/2108.04214.
[65] H. Zhang, M. Shinn, A. Gupta, A. Gurﬁnkel, N. Le, and N. Na rodytska.
Veriﬁcation of Recurrent Neural Networks for Cognitive Tas ks via
Reachability Analysis. In Proc. 24th European Conf. on Artiﬁcial
Intelligence (ECAI) , pages 1690–1697, 2020.