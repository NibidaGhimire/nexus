1
Graph Learning Across Data Silos
Xiang Zhang, Student Member, IEEE, Qiao Wang, Senior Member, IEEE
Abstract —We consider the problem of inferring graph topology
from smooth graph signals in a novel but practical scenario where
data are located in multiple clients and prohibited from leaving
local clients due to factors such as privacy concerns. The main dif-
ficulty in this task is how to exploit the potentially heterogeneous
data of all clients under data silos. To this end, we first propose
an auto-weighted multiple graph learning model to jointly learn
a personalized graph for each local client and a single consensus
graph for all clients. The personalized graphs match local data
distributions, thereby mitigating data heterogeneity, while the
consensus graph captures the global information. Moreover, the
model can automatically assign appropriate contribution weights
to local graphs based on their similarity to the consensus graph.
We next devise a tailored algorithm to solve the induced problem,
where all raw data are processed locally without leaving clients.
Theoretically, we establish a provable estimation error bound
and convergence analysis for the proposed model and algorithm.
Finally, extensive experiments on synthetic and real data are
carried out, and the results illustrate that our approach can
learn graphs effectively in the target scenario.
Index Terms —Graph learning, smooth graph signals, graph
signal processing, data silos, privacy-preserving
I. I NTRODUCTION
Graphs are powerful tools for flexibly describing topo-
logical relationships between data entities [1], which have
been extensively applied in many celebrated models, e.g.,
spectral clustering [2] and graph neural networks (GNNs) [3].
Among these applications, a graph that accurately represents
the information inherent in the structured data is required,
which, however, is not available in many cases. An alternative
approach is to learn graphs directly from raw data, termed
graph learning (GL), for downstream tasks [1], [4].
In the literature, many studies learn graphs from statistical
models, such as Gaussian Graphical Models (GGMs) [5]. In
general, these models aim to infer precision matrices (inverse
covariance matrices), which encode conditional independence
between random variables. Furthermore, [6]–[8] introduce
(generalized) Laplacian constraints on the learned precision
matrices, which enjoy many downstream applications such as
graph spectral analysis [2]. Recently, with the rise of graph
signal processing (GSP) [9], various methods attempted to
learn graphs from a signal processing perspective. One of
the most studied GSP-based models—the smoothness-based
model—postulates that the observed graph signals are smooth
over the underlying graph [10], [11]. Intuitively, a smooth
graph signal means that the signal values corresponding to
two connected nodes of the underlying graph are similar [11].
Typically, learning graphs from smooth signals is equivalent
The authors are with the School of Information Science and En-
gineering, Southeast University, Nanjing 210096, China (e-mail: xi-
angzhang369@seu.edu.cn, qiaowang@seu.edu.cn).to minimizing a constrained quadratic Laplacian form prob-
lem, where the quadratic Laplacian form is related to signal
smoothness, and the constraints (regularizers) are used to
assign properties to the graphs, such as sparsity [10] and node
connectivity [11]. Many signals appear to be smooth over their
underlying graphs, e.g., meteorology data [10] and medical
data [12], implying numerous applications of smoothness-
based GL.
Here, we consider learning graphs in a previously unex-
plored scenario, where data are stored across multiple clients
(e.g., companies and organizations) and are not allowed to
leave their clients due to factors such as privacy concerns. This
scenario is known as data-silos [13], and a typical example
is medical data. Suppose some hospitals collect brain fMRI
data from autistic and non-autistic individuals separately to
learn the impact of autism on connectivity networks of brain
functional regions [12]. However, the data are prohibited
from leaving the hospital where they are stored as people
are reluctant to disclose their private data. A naive way is
for each client to infer graph topology independently, which
avoids any data leakage. Although feasible, this approach ig-
nores potential topological relationships between local graphs,
resulting in suboptimal results. Thus, it is more reasonable
to learn graphs using data information from all clients. The
task is not trivial and faces two main challenges. The first
challenge is how to leverage siloed data from all clients
collaboratively. Furthermore, graph signals across different
silos are inherently non-IID due to factors such as different
data collection protocols and heterogeneous underlying graphs
[14]. We still use the brain fMRI data as an example. The brain
functional connectivity networks of autistic and non-autistic
individuals are different due to the impact of autism. It is
unreasonable to utilize heterogeneous data to learn a single
global graph like traditional paradigms [10], [11]. Thus, the
second challenge is handling heterogeneous data.
Regarding the first challenge, federated learning (FL) [13],
[15], [16] is an emerging tool for learning models based
on datasets distributed across multiple clients under privacy
constraints. The primary feature of FL is that clients transmit
model updates instead of raw data to a central server to
collaboratively learn a global model [15]. Privacy can be
preserved in this schema to some extent since all data are
processed locally [16]. However, traditional FL algorithms,
e.g., FedAvg [17], learn a single global model from all data,
which may suffer from performance degradation when data
across different clients are heterogeneous. A widely used ap-
proach to handle data heterogeneity—the second challenge—is
personalized FL (PFL) [18]. The philosophy behind PFL is
that we learn for each client a personalized model that matches
its data distribution to mitigate the impact of heterogeneity.
The techniques for adapting global models for individualarXiv:2301.06662v4  [cs.LG]  17 Feb 20252
clients include transfer learning [19], multi-task learning [20],
and meta-learning [21].
Borrowing the idea from PFL, we learn a personalized graph
for each local client to handle data heterogeneity. However, it
poses two additional challenges due to the characteristics of
GL tasks. (i) Our goal is to learn all local graphs jointly by
exploiting their latent relationships so that each local graph
benefits from “borrowing” information from other datasets.
Thus, it is crucial to describe the relationships between local
graphs, which is the focus of multiple graph learning (MGL).
A common approach is to design regularization penalties, e.g.,
fused Lasso penalty [22], group Lasso penalty [23], Gram
matrix-based penalty [24], and those describing temporally
topological relationships [25]–[27]. These regularizers charac-
terize topological relationships among multiple graphs, but few
consider capturing common structures from all local graphs. In
practice, many graphs share common structures. For example,
connections between normally functioning brain regions in
autistic and non-autistic individuals should remain the same.
The common structures reflect the global information across
all local datasets, which may be useful for many downstream
tasks. (ii) It is infeasible to apply existing PFL algorithms,
such as [20], [28]–[31], to our task since their personalization
methods do not fit the GL problem. Besides, the problem of
concern can be categorized as cross-silo FL, where clients are
a few companies or organizations rather than massive devices
in cross-device FL [15], [17]. Thus, a tailored algorithm is
required to learn graphs in the target scenario.
To address these issues, we propose a framework to learn
graphs from smooth but heterogeneous data under data silos.
Our contributions can be summarized as follows:
•We propose an auto-weighted MGL model in which
local personalized graphs and a consensus graph are
jointly learned. The consensus graph can capture com-
mon structures representing global information across
all datasets, while the local graphs preserve the het-
erogeneity of local datasets. Furthermore, our model
can automatically assign contribution weights to local
graphs based on their similarity to the consensus graph.
Theoretically, we provide the estimation error bound of
the proposed method to reveal some key factors affecting
graph estimation performance.
•We develop a tailored algorithm to learn graphs under
privacy constraints. Our algorithm follows the commu-
nication protocol of FL, where model updates instead of
raw data are transmitted to a central server to learn all
graphs collaboratively. The convergence analysis of the
proposed algorithm is also provided.
•Extensive experiments with synthetic and real-world
data are conducted to validate our framework, and the
results show that our approach can effectively learn
graphs under data silos.
Organization: The rest of this paper is organized as fol-
lows. We start with background information and the problem
of concern in Section II. The proposed model for learning
graphs in the target scenario is presented in III, followed by the
corresponding algorithm in Section IV. Experimental setupsand results are provided in Section V. Finally, concluding
remarks are presented in Section VI.
Notations: Throughout this paper, vectors, matrices, and
sets are written in bold lowercase letters, bold uppercase
letters, and calligraphic uppercase letters, respectively. Given
a vector yand matrix Y,y[i]andY[ij]are the i-th entry of y
and the (i, j)entry of Y. Besides, 1,0, andIrepresent all-one
vectors, all-zero vectors, and identity matrices, respectively.
For a vector or matrix, the ℓ1,ℓ2,ℓ∞, and Frobenius norm are
represented by ∥·∥1,∥·∥2,∥·∥∞,∥·∥F, respectively. Moreover,
∥·∥F,offdenotes the Frobenius norm of off-diagonal elements
of a matrix, and diag(·)means converting a vector to a
diagonal matrix. The notations ◦,†,Tr(·)stand for Hadamard
product, pseudo inverse, and trace operator, respectively. For
a setY,conv [Y]is the affine and convex hulls of Y. Finally,
RandSrepresent the domain of real values and symmetric
matrices whose dimensions depend on the context.
II. B ACKGROUND AND PROBLEM STATEMENT
A. GSP Background
We consider undirected graphs with non-negative weights
and no self-loops. For such a graph G={V,E}with d
vertices, where VandEare the sets of vertices and edges,
respectively, its adjacency matrix A∈Sd×dis a symmet-
ric matrix with zero diagonal entries and non-negative off-
diagonal entries. The Laplacian matrix of GisL=D−A
[32], where the degree matrix D∈Sd×dis a diagonal matrix
satisfying D[ii] =Pd
j=1A[ij]. The matrices AandLencode
the topology of Gsince they have a one-to-one relationship.
We study the graph signal x= [x[1], . . . ,x[d]]⊤∈Rd
associated with G, where x[i]is the signal value of node i∈ V.
The smoothness of xoverGis defined as follows.
Definition 1. (Smoothness [10]). Given a graph signal xand
a graph Gwhose Laplacian matrix and adjacency matrix are
LandA, respectively, the smoothness of xoverGis
x⊤Lx=1
2X
i,jA[ij] (x[i]−x[j])2. (1)
The Laplacian quadratic form (1) is known as the Dirichlet
energy, which quantifies how much the signal xchanges w.r.t.
G. A small value of (1) indicates limited signal variability,
meaning that xis smooth over the corresponding graph [10].
B. Graph Learning From Smooth Signals
Given Nobservations X= [x1, . . . ,xN]∈Rd×N,
smoothness-based GL aims to infer the underlying graph
topology Gunder the assumption that the signals Xare smooth
overG. Formally, the problem is written as
min
L∈L1
NNX
n=1x⊤
nLxn−α1⊤log (diag( L)) +β∥L∥2
F,off,(2)
where the first term is to quantify the smoothness of X
overG, and the last two terms are regularizers that endow
Gwith desired properties. The first and second terms of the
regularizers control node connectivity and edge sparsity of the
learned graph [11], where αandβare predefined constants.3
Fig. 1: The illustration of the target scenario. The clients
C1, . . .CIstore graphs signals X1, . . . ,XIgenerated from I
distinct but related graphs. The data are not allowed to leave
their clients, but all clients can commute with a central server.
We use Laplacian matrix Lto represent graph topology of G,
which lies in the following set L
L≜
L:L∈Sd×d,L1=0,L[ij]≤0fori̸=j	
.(3)
Based on (1), problem (2) can be rephrased as
min
A∈A1
2N∥A◦C∥1,1−α1⊤log(A1) +β∥A∥2
F,(4)
where ∥·∥1,1is the element-wise ℓ1norm of a matrix. Besides,
C∈Rd×dis a pairwise distance matrix defined as
C[ij] =∥exi−exj∥2
2, (5)
whereexi∈RNis the i-th row vector of X. Similarly, Ais
the set containing all adjacency matrices,
A=
A:A∈Sd×d,A≥0,diag(A) =0	
, (6)
where A≥0means that all elements of Aare non-negative.
By the definition of A, the number of free variables of Ais
p:=d(d−1)
2[11]. For simplicity, we define a vector w∈Rp
whose elements are the upper triangle variables of A. Then,
problem (4) can be rewritten into a vector form as
min
w≥01
Nz⊤w−α1⊤log(Sw) + 2β∥w∥2
2, (7)
where Sis a linear operator satisfying Sw=A1, and zis
the vector form of the upper triangle elements of C1.
C. Problem Statement
As shown in Fig.1, suppose there are Iclients C1, . . . ,CI,
and the i-th client stores signals Xi∈Rd×Nigenerated from
the graph Gi, where Niis the size of the i-th dataset. All
graphs are defined over the same node set, and the data are
prohibited from leaving the client where they are stored due
to factors such as privacy concerns. However, the clients can
exchange information with a central server. We assume that
(i) graph signals Xiare smooth over Gi, and (ii) G1, . . . ,GI
may be heterogeneous, meaning that the corresponding graph
signals could be non-IID. Our goal is to infer the graphs from
X1, . . . ,XIin the case of data silos.
1The pairwise distance vector zis calculated from x1, . . . ,xN. Thus, zis
also referred to as observation data in the following sections.III. M ODEL FORMULATION
In this section, we first propose an auto-weighted MGL
model to learn graphs in the target scenario, and then analyze
its estimation error bound.
A. Basic Formulation
We assume that Ilocal graphs, which are denoted as
w1, . . . ,wI∈Rp, have some common structures named
consensus graphs wcon∈Rp. Intuitively, the consensus graph
should be close to local graphs since they share common
edges. Furthermore, the consensus graph should also be sparse
to remove redundant noisy edges [33]. Thus, we learn Ilocal
graphs and the consensus graph jointly via
min
wi,wcon∈WIX
i=11
Niz⊤
iwi−α1⊤log (Swi) + 2β∥wi∥2
2
| {z }
gi(wi)
+λνIX
i=1∥wi−wcon∥2+λ∥wcon∥1
= min
wi,wcon∈WG(W) +λR(W) (8)
where ziis the observed data in client Ci,W:={w:w≥0},
W = [w1, . . . ,wI,wcon]∈Rp×(I+1),G(W) :=PI
i=1gi(wi), and R(W) :=νPI
i=1∥wi−wcon∥2+∥wcon∥1.
Our model consists of two parts. The first part G(W)repre-
sents that local clients utilize the traditional smoothness-based
model (7) to learn graphs w1, . . . ,wIfrom locally stored data.
The second term R(W)is the regularizer that topologically
connects local graphs via the consensus graph. Specifically, the
first term νPI
i=1∥wi−wcon∥2ofR(W)measures difference
between local graphs and the consensus graph. We add the
ℓ1norm term because wconis expected to be sparse. The
constants νandλare predefined parameters. The parameters
of problem (8) are α, β, ν , and λ. However, as stated in [11],
tuning the importance of the log-degree term w.r.t. the other
graph terms has a scaling effect. We can fix αand search for
the other parameters. Therefore, the free parameters of our
model are β,ν, and λ.
The proposed model (8) enjoys the following advantages.
Firstly, our model provides a way to learn local personalized
graphs w1, . . . ,wIjointly. Compared to learning graphs inde-
pendently, our model utilizes the information from all datasets,
which could boost learning performance. Secondly, we learn
a personalized graph for each client, which alleviates the bias
of learning a single global graph using all data in the case
of data heterogeneity. Lastly, unlike most PFL methods that
only learn personalized local models [18], our model learns a
consensus graph reflecting global information.
B. Auto-weighted Multiple Graph Learning
At first glance, our model (8) treats Ilocal graphs equally
since they share the same weight in νPI
i=1∥wi−wcon∥2.
This is unreasonable because the similarity between the con-
sensus graph and different local graphs could vary widely.
Fortunately, we will show that our model (8) can implicitly
assign appropriate weights to local graphs, which we termed4
contribution weights, based on their similarity to wconvia the
inverse distance weighting schema [34].
Specifically, if we solve (8) by alternately updating
w1, . . . ,wIandwcon—which is exactly how we solve it in
Section IV—when we fix the consensus graph wcon, the sub-
problem of updating wiis
min
wi∈Wgi(wi) +ρ∥wi−wcon∥2, (9)
where we let ρ=λνfor simplicity. We take the derivative of
the Lagrange function of (9) and set it to zero, which yields
ρeγi∂∥wi−wcon∥2
2
∂wi+∂gi(wi)
∂wi−∂θ⊤
iwi
∂wi=0, (10)
where θi∈Rpis the Lagrange multiplier, and
eγi=1
2∥wi−wcon∥2. (11)
Note that (11) depends on wi, meaning that eγiandwiare
coupled with each other. However, if we set eγistationary, (10)
is the solution to the following problem
min
wi∈Wgi(wi) +ρeγi∥wi−wcon∥2
2. (12)
After solving (12), we can use the obtained wito update the
weight eγivia (11). Therefore, we can alternately update wi
andeγito solve (9). Similarly, it is not difficult to check that
we can update wconusing the same strategy as updating wi.
Combing the alternative updates of wi,wcon, andeγi, the
basic formulation (8) is rephrased as
min
wi,wconIX
i=11
Niz⊤
iwi−α1⊤log (Swi) + 2β∥wi∥2
2
+ρ
2IX
i=1γi∥wi−wcon∥2
2+λ∥wcon∥1
s.t.wi,wcon∈ W, γi=1
∥wi−wcon∥2. (13)
One merit of solving (8) via the reformulation (13) is that
it naturally produces a contribution weight γifor the local
graph wi. The weight value is determined by the similarity
between wiandwcon. For the wiclose to wcon, a larger γiis
assigned to the corresponding term, increasing the contribution
of the i-th local graph to the consensus graph. On the contrary,
the local graph far from the consensus graph obtains a small
γi. Thus, our model can implicitly and automatically assign
appropriate weights to local clients based on their similarity
to the consensus graph.
C. Theoretical Analysis
LetW∗= [w∗
1, . . . ,w∗
I,w∗
con]∈Rp×(I+1)be the true
graphs and cW= [bw1, . . . ,bwI,bwcon]∈Rp×(I+1)be the esti-
mated graphs of our model (8). We aim to derive the estimation
error bound of our proposed multiple graph estimator. Before
conducting the analysis, we make the following assumptions.
Assumption 1. The observed signals, as well as the corre-
sponding pairwise distance vectors ziare bounded, i.e., there
exists a constant Czsuch that ∥zi∥2≤Czfori= 1, . . . , I .Assumption 2. Leth(w) =−α1⊤log (Sw) + 2β∥w∥2
2. The
gradient of h(w)at the real graph is bounded, i.e., there exists
a constant Chsuch that ∥∇h(w∗
i)∥2≤Chfori= 1, . . . , I .
Assumption 1 naturally holds in the real world since un-
bounded signals do not make sense. Assumption 2 holds when
the true graph has limited edge weights and no isolated nodes,
which is common in the real world. Moreover, without loss
of generality, we assume the data sizes of Igraphs are the
same, i.e., Ni=Nfori= 1, . . . , I . The analysis can be
easily generalized to the case where data sizes vary across
different clients. We further suppose that the obtained data
vector (pairwise distance vector) zican be written as
zi[j] =z∗
i[j] +ei[j], j= 1, . . . , p, (14)
where z∗
iis the true data vector, and eiis the error vector
caused by factors such as noisy measurements. In our analysis,
we assume that ei∼ N (0, σ2
eI). Then, we present the
estimation error bound of the proposed graph estimator as
stated in the following theorem.
Theorem 1. Under Assumptions 1 and 2, given δandν >0,
letλsatisfy
λ≥Cz√
I+σe√pI+δ
CrN, (15)
where Cr:=νp
Iωmax(Lm) +√p,
Lm∈R(I+1)×(I+1)=
1 0 ··· 0−1
0 1 ··· 0−1
......··· 0−1
0 0 ··· 1−1
−1−1−1−1I
,(16)
andωmax(Lm)is the maximum eigenvalue of Lm. Then, we
have probability at least 1−exp
−1
2
δ−pIlog
1 +δ
pI
such that
cW−W∗
F≤Crλ
β+Ch√
I
2β. (17)
Proof. See Appendix A for details.
Theorem 1 characterizes the estimation error bound of our
proposed model w.r.t. some key factors, such as graph size d
(the number of the free variables p), data size N, the number of
local graphs I, and measurement noise level σe. The theorem
states that, if the weight λbefore the regularizer R(W)is
selected appropriately, the estimation error of our model is
bounded by the r.h.s. of (17) with high probability. The upper
bound consists of two parts. The first part is related to data
sizes. When Ngoes to infinity, (15) indicates that λcould be
small enough that the first part decreases to zero. The second
part is determined by the regularizer h(w∗)of the basic graph
learning model (7). This can be regarded as a systematic error
since h(w)is chosen using prior knowledge, and the error
will not decrease as Nincreases. We should mention that
our model is flexible, and one can choose any h(w)as the
regularizer of local models to bring desired properties to the
learned graphs. For the well-selected regularizer, the gradient5
ofh(w)atw∗will be bounded tightly, and we can obtain a
small upper bound on the estimation error.
D. Connections to Existing MGL Models
In the literature, there have been some works that learn mul-
tiple graphs based on the assumption of common structures.
These works differ mainly in how they describe structural
relationships among multiple graphs. To avoid notational con-
fusion, we use different notations to interpret existing works.
We let K∈Rd×ddenote the common graph structures and
U1, . . . ,UI∈Rd×drepresent the unique structures of Ilocal
graphs. Under these notations, the graph regularizer R(W)
in our model (8) can be roughly summarized as (not exactly
equivalent to) ∥K∥1,1+νPI
i=1∥Ui∥F. Unlike our model,
the work [35] defines the regularizer as ∥K∥1,1+ν∥U∥1,r,
where r∈[1,+∞),∥U∥1,r=Pd
i,j=1∥U[ij]∥r, andU[ij] =
[U1[ij], . . . ,UI[ij]]⊤∈RI. The term ∥U∥1,ris a group
lasso regularizer that can capture common sparsity structure
among all local graphs. The second work [36] assumes that
the common structure Kis the average of all local graphs,
i.e.,K=1
IPI
i=1Ai,Ui=Ai−K. A regularizer is then
designed as ∥K∥1,1+νPI
i=1∥Ui∥1,1. Unlike our work, [37]
proposes a regularizer ∥K∥1,1+νPI
i=1∥Ui∥2
F. Moreover, the
local graph learning model of [37] is different from ours, and
[37] requires all graphs, including the consensus graph, are
represented by Laplacian matrices. Recently, [38] designs two
regularizers, i.e.,PI
i=1∥Ui∥1,1and the other similar to [35].
In summary, our model differs from existing works in the
following aspects. (i) The regularizer R(W)is different from
existing works, which can implicitly assign a contribution
weight for each local graph. This is used for the first time in
the multiple graph learning problem. (ii) Our model and [37]
learn multiple graphs based on the smoothness assumption
(6), while [35], [36] are based on the GGMs. (iii) We further
consider the problem of learning graphs in the case of data
silos, which has not been explored in the existing GL-related
works.
IV. M ODEL OPTIMIZATION
In this section, we propose an algorithm with provable
convergence analysis for solving (8) in the target scenario.
A. The Proposed Algorithm
According to the reformulation (13), our algorithm consists
of two steps: (i) updating wiin the local client Ciand (ii)
updating γ= [γ1, . . . , γ I]⊤∈RIandwconin the central
server. The complete flow is displayed in Algorithm 1.
Updating wiin the local client Ci:This update corre-
sponds to lines 3-11 in Algorithm 1. In the t-th communication
round, Cifirst receives w(t)
conandγ(t)
ifrom the central server.
Letf(t)
i(wi,wcon) :=gi(wi) +ργ(t)
i
2∥wi−wcon∥2
22, and the
sub-problem of Cibecomes
w(t+1)
i =argmin
wi∈Wf(t)
i(wi,w(t)
con)
2f(t)
i(wi,w(t)
con)is a function of wiwith fixed w(t)
con. Similarly,
f(t)
i(w(t+1)
i,wcon)is a function of wconwith fixed w(t+1)
i.=argmin
wi∈W1
Niz⊤
iwi−α1⊤log (Swi+ζ1)
+ 2β∥wi∥2
2+ργ(t)
i
2∥wi−w(t)
con∥2
2, (18)
where ζis a small enough constant to avoid zero node degree.
We use the accelerated projected gradient descent algorithm to
update wi. At the beginning of local updates, Cifirst initializes
w(t,0)
i=w(t−1,K(t−1)
i)
i andw(t,−1)
i =w(t−1,K(t−1)
i−1)
i , where
K(t)
iis the number of local loops of Ciin the t-th outer
iteration. Besides, w(t,k)
i represents the updated graph of Ciin
thet-th outer iteration and the k-th local loop. We then update
thei-th local graph K(t)
itimes by
w(t,k)
i,ex=w(t,k)
i+ξ
w(t,k)
i−w(t,k−1)
i
(19)
˘w(t,k+1)
i =w(t,k)
i,ex−ηw
∇gi(w(t,k)
i,ex)
+ργ(t)
i
w(t,k)
i,ex−w(t)
con
(20)
w(t,k+1)
i = ProjW
˘w(t,k+1)
i
, (21)
where ξ∈[0,1)is an momentum weight. In (20), ∇gi(w)
is calculated as1
Nizi−αS⊤
1
Sw+ζ1
+ 4βw. Moreover,
ηwis the stepsize, the choice of which will be discussed in
the next subsection. The operator ProjW(·)means project-
ing variables into W. When local updates finish, Cisends
w(t+1)
i =w(t,K(t)
i)
i to the central server. Note that the local
update of wiis inexact in one communication round since
we run (19)-(21) for K(t)
itimes without convergence. We use
inexact updates because we aim to update all local graphs
synchronously. Due to system heterogeneity, the time required
for each client to update wiuntil convergence may vary
widely. It takes longer if the central server waits for all clients
to update their graphs until convergence.
Updating wcon and γin the central server: The
updates correspond to lines 12-14 in Algorithm 1. After
the central server receives all the updated local graphs,
w(t+1)
1, . . . ,w(t+1)
I , we update w(t+1)
con by solving the follow-
ing problem
w(t+1)
con = argmin
wcon∈WIX
i=1f(t)
i(w(t+1)
i,wcon) +λ∥wcon∥1
= argmin
wcon∈WIX
i=1ργ(t)
i
2∥w(t+1)
i−wcon∥2
2+λ∥wcon∥1.
(22)
The problem is equivalent to
w(t+1)
con =argmin
wcon∈W1
2wcon−PI
i=1γ(t)
iw(t+1)
iPI
i=1γ(t)
i2
2
+λ
ρPI
i=1γ(t)
i∥wcon∥1. (23)
By defining C(t)
γ:=PI
i=1γ(t)
iandµ(t):=λ
C(t)
γρ, we obtain
w(t+1)
con = proxµ(t)∥·∥1 PI
i=1γ(t)
iw(t+1)
i
C(t)
γ!
, (24)6
Algorithm 1 The algorithm for solving (8)
Input: α,β,ν,ξ,λ, and signals X1, . . . ,XI
1:Initialize γ(0)
i= 1/I,w(0)
con=w(0)
i=w(−1,0)
i =
w(−1,−1)
i fori= 1, . . . , I , and let K(−1)
i= 0
2:fort= 0, . . . , T −1do
3: / / Update w1, . . . ,wIin parallel in local clients
4: fori= 1, . . . , I in parallel do
5: Receive γ(t)
iandw(t)
confrom the central server
6: Initialize w(t,0)
i =w(t−1,K(t−1)
i)
i andw(t,−1)
i =
w(t−1,K(t−1)
i−1)
i
7: fork= 0, . . . , K(t)
i−1do
8: Update w(t,k+1)
i using (19)-(21)
9: end for
10: Letw(t+1)
i =w(t,K(t)
i)
i and send it to central server
11: end for
12: / / Update wconandγin central server
13: Update w(t+1)
con using (24)
14: Update γ(t+1)
i using (25), for i= 1, . . . , I
15: Sendw(t+1)
con andγ(t+1)
i to the i-th client Ci
16:end for
17:return w(T)
1, . . . ,w(T)
Iandw(T)
con
where proxµ(t)∥·∥1(·)is the proximal operator of ℓ1norm. It is
observed from (24) that w(t+1)
con∈ W since it is a combination
ofw(t+1)
i with positive weights, and the proximal operator
will not move the vector out of W.
After obtaining w(t+1)
con , we update γ(t+1)
i as3
γ(t+1)
i =1w(t+1)
i−w(t+1)
con
2,fori= 1, . . . , I. (25)
Finally, we send w(t+1)
con andγ(t+1)
i back to the client Ci.
B. Convergence Analysis
Before proceeding with the convergence analysis, let us first
discuss the properties of the objective function.
Proposition 1. The objective function f(t)
i(wi,w(t)
con)is
L(t)
i-Lipschitz smooth w.r.t. wionfW, where fW =
conv[∪0≤ξ≤1{y+ξ(y−y′)||y,y′∈ W} ]is the feasi-
ble set extended by the momentum update, and L(t)
i:=
4β+ 2α(d−1)/ζ2+ργ(t)
i. Moreover, f(t)
i(wi,w(t)
con)isS(t)
i-
strongly convex w.r.t. wi, where S(t)
i= 4β+ργ(t)
i.
Proof. We place the proof in Appendix B.
Proposition 1 points out that the objective function
f(t)
i(wi,w(t)
con)enjoys some nice properties, i.e., it is L(t)
i-
Lipschitz smooth and S(t)
i-strongly convex, which are essential
to the convergence of accelerated gradient descent algorithms
[39]. Next, we further make the following assumptions.
Assumption 3. The feasible set is convex and compact.
3To avoid dividing by zero, we can update γ(t+1)
ias
1w(t+1)
i−w(t+1)
con
2+ϵγ, where ϵγis a small enough constant.Assumption 4. The (constant) stepsize satisfies ηw≤
1/Lmax, where Lmax is the maximum value of L(t)
ifor all
iandt.
Assumption 3 is common in the constrained optimization
algorithms. Assumption 4 requires the (constant) stepsize to
be bounded. Based on these assumptions, we conduct conver-
gence analysis of our proposed algorithm as follows.
Theorem 2. Based on Assumptions 3 and 4, in each com-
munication round of Algorithm 1, the updated wconandwi
monotonically decrease the objective function of the proposed
model (8)until the solution converges to a local optimum of
the problem (8).
Proof. See Appendix C for details.
The theorem reveals that as communication round tin-
creases, the proposed algorithm will converge to a local opti-
mum of problem (8). In Section V-B, we will experimentally
test the convergence of the proposed algorithm.
C. Privacy Analysis
In our algorithm, each client Ciuses its private data Xi
to update the local graph wiby solving (18). After local
updates, clients send model updates instead of raw data to
the central server to update the consensus graph and weights.
Following the paradigm of FL, all data is kept locally without
any leakage during execution, which protects data privacy to
a certain extent. Therefore, the proposed algorithm can learn
graphs in the target scenario. However, inference attacks [40]
and model inversion attacks [41] show that the updates sent
by local clients may still reveal private information. To further
prevent information leakage, some popular techniques such as
differential privacy [42] may be helpful. This is beyond the
scope of this study and will be left to future work.
D. Some Discussions
Differences from distributed learning algorithms : Our
algorithm may look similar to distributed learning algorithms
at first glance, but there are actually fundamental differences.
(i) Our algorithm falls into the emerging field of federated
learning, which aims to train models on siloed datasets under
privacy constraints, while distributed learning aims to employ
multiple clients (computing nodes) to accelerate training on a
large but “flat” dataset [13]. (ii) In distributed learning, data
are centrally stored and can be shuffled and balanced across
clients. Thus, data of different clients are IID. In contrast,
in federated learning, data are generated locally and may
be non-IID. In our problem, the data are generated from
heterogeneous graphs and are hence non-IID. We propose
to learn personalized graphs to alleviate the impact of non-
IID data. (iii) Distributed learning divides the dataset into
multiple subsets uniformly and randomly, and data sizes across
different computing nodes are close. However, in federated
learning, all data are generated from local clients, which
may be geographically and functionally diverse organizations,
bringing widely varying data sizes of different clients.7
Differences from existing FL algorithms : On the other
hand, our algorithm differs from existing (personalized) FL
algorithms in the following ways due to the specificity of
our problem. (i) Unlike the algorithms of cross-device FL
[17], [28], our algorithm learns graphs in a cross-silo FL
scenario. Specifically, all clients, rather than a subset of clients,
participate in local updates in each communication round. In
addition, local clients utilize all stored data to update graphs
instead of sampling a batch of data like many cross-device
FL algorithms [17], [28]. (ii) The optimization problems
corresponding to local and global updates are customized.
For example, our algorithm updates the consensus graph by
solving a ℓ1norm regularized quadratic optimization problem,
whereas the global update of existing algorithms is a simple
aggregation of local models [20], [28], [30]. (iii) Finally,
compared to decentralized PFL algorithms [29], [31], our
algorithm follows the “central server-clients” schema.
V. E XPERIMENTS
In this section, we will test our proposed framework using
both synthetic data and real-world data. First, some experi-
mental setups are introduced.
A. Experimental Setups
1) Graph generation: We first generate Gaussian radial
basis function (RBF) graphs G0by following the method in
[10]. Specifically, we generate 20 vertices whose coordinates
are randomly in a unit square. Edge weights are calculated
using exp(−dist(i, j)2/2σ2
r), where dist(i, j)is the distance
between vertices iandj, and σr= 0.5is a kernel width
parameter. We remove the edges whose weights are smaller
than0.7. Then, we keep a certain proportion—say q—of edges
inG0unchanged to form the consensus graph. Finally, we add
(1−q)|E0|edges randomly to the consensus graph to form
heterogeneous graphs G1, . . . .,GI, where |E0|is the number of
edges in G0. We denote 1−qas the degree of heterogeneity.
2) Signal generation: For the i-th local graph Gi, we
generate Nismooth signals from the distribution [10]
Xi,n∼ N 
0,(L∗
i)†+σ2
wI
, n= 1, . . . , N i, (26)
where σwis noise scale and L∗
iis the real Laplacian matrix
ofGi, andXi,nis the n-th data (column) of Xi.
3) Evaluation metric: Four metrics are employed to evalu-
ate the learned graphs, as listed in (27). The first three metrics
are used to evaluate classification tasks since determining
whether two vertices are connected can be regarded as a binary
classification problem. Specifically, TP is the true positive
rate, TN is the true negative rate, FPis the false positive
rate and FNdenotes false negative rate. The third metric, F1-
score ( FS) is the harmonic mean of Precision andRecall . The
last metric is the relative error ( RE), where bwis the learned
graph, and w∗is the groundtruth. The results of all metrics
for local graphs are the average of Iclients.
Precision =TP
TP + FP,Recall =TP
TP + FN,
FS =2TP
2TP + FN + FP,RE =∥bw−w∗∥2
∥w∗∥2. (27)4) Baselines: We employ three categories of baselines. (i)
We learn all local graphs independently (IGL), which enjoys
full privacy as local clients do not release any data, including
model updates. (ii) We use two traditional FL algorithm, Fe-
dAvg [17] and FedProx [43], to solve the following problem
min
w∈W1
NallIX
i=1z⊤
iw−α1⊤log (Sw+ζ1) + 2β∥w∥2
2.(28)
The model learns a global graph collaboratively using data
from all clients regardless of data heterogeneity. (iii) We
leverage two personalized FL algorithms, MRMTL [44] and
Ditto [45], to jointly learn all local graphs by further consider-
ing data heterogeneity. See supplementary materials for more
details on how they are applied to multiple graph learning. For
our algorithm, we use PPGL-L and PPGL-C to represent the
learned local and consensus graphs, respectively.
5) Determination of parameters: For our model, αis
fixed as 1, and βis selected as the value achieving the
bestFSin IGL. Parameters νandλare determined by grid
search in [1,100] and[0.01,1]. On algorithmic side, we set
ξ= 0.9, K(t)
i=K= 5, T= 50 . The stepsize ηwis0.005,
which is small enough to satisfy ηw≤1/Lmax. Moreover, we
letI= 5 andσw= 0.1for synthetic data. All parameters of
baselines are selected as those achieving the best FSvalues.
B. Synthetic Data
1) Data size: We first test the effect of data size. We
fixqas 0.5 and assume that all clients have the same data
size, i.e., Ni=N, i = 1, . . . , I . We vary Nfrom 20 to
100, and the results are shown in Table.I. It is observed
that FedAvg and FedProx tend to obtain high Recall but
lowPrecision , meaning that the corresponding graphs contain
more edges. As Nincreases, FedAvg yields the worst FS,
which is a comprehensive metric for evaluating the learned
graph topology. The reason is that FedAvg learns a global
graph using data from all clients. However, local graphs are
heterogeneous in our experiment. Therefore, the learned global
graph is far from local graphs. In sharp contrast, IGL learns
local graphs independently and achieves better performance
than FedAvg when Nis large. Our model also learns a
personalized graph for each local client. Unlike IGL, we learn
all local graphs jointly via a consensus graph, leading to better
performance than IGL. Our model is also superior to Ditto and
MRMTL—two PFL algorithms—since it is tailored for graph
learning problems. Additionally, our model learns a consensus
graph that captures the common structures of local graphs.
We also test our model with different data sizes for different
clients. We set Nito 20, 40, 60, 80, and 100 for i= 1, . . . , 5,
respectively. As illustrated in Fig.2, clients with larger Ni
perform better than those with small Ni. However, our model
can improve the performance of clients with small Nibecause
they can “borrow” information from the clients with large Ni.
Figure 3 provides the visualization of the learned graphs.
We can observe that, compared with other methods, our model
can effectively capture the common and specific structures of
the real graph.8
TABLE I: Performance of varying data sizes.
N= 20 N= 50 N= 100
Precision ↑Recall ↑FS↑RE↓Precision ↑Recall ↑FS↑RE↓Precision ↑Recall ↑FS↑RE↓
IGL 0.594 0.469 0.521 0.915 0.692 0.620 0.651 0.778 0.776 0.739 0.755 0.698
FedAvg 0.434 0.759 0.552 0.802 0.464 0.792 0.584 0.768 0.519 0.789 0.624 0.744
FedProx 0.423 0.767 0.544 0.765 0.523 0.728 0.606 0.718 0.623 0.703 0.655 0.690
MRMTL 0.522 0.551 0.547 0.881 0.647 0.688 0.663 0.756 0.738 0.789 0.760 0.680
Ditto 0.582 0.547 0.557 0.884 0.662 0.671 0.663 0.775 0.732 0.780 0.750 0.696
PPGL-L 0.547 0.579 0.561 0.911 0.625 0.760 0.678 0.731 0.698 0.870 0.774 0.619
PPGL-C 0.636 0.516 0.566 0.874 0.781 0.656 0.710 0.701 0.881 0.736 0.800 0.627
1In this paper, ↑indicates that larger values are better, and ↓indicates that smaller values are better.
TABLE II: Performance of varying data heterogeneity.
q= 0.3 q= 0.6 q= 0.9
Precision ↑Recall ↑FS↑RE↓Precision ↑Recall ↑FS↑RE↓Precision ↑Recall ↑FS↑RE↓
IGL 0.701 0.593 0.640 0.783 0.736 0.645 0.685 0.758 0.822 0.706 0.759 0.717
FedAvg 0.385 0.841 0.527 0.835 0.460 0.867 0.599 0.783 0.811 0.922 0.862 0.672
FedProx 0.437 0.720 0.543 0.770 0.569 0.750 0.645 0.716 0.874 0.863 0.868 0.641
MRMTL 0.662 0.691 0.674 0.761 0.690 0.730 0.707 0.753 0.816 0.794 0.807 0.663
Ditto 0.667 0.675 0.668 0.765 0.698 0.714 0.704 0.739 0.821 0.783 0.804 0.667
PPGL-L 0.637 0.736 0.679 0.740 0.661 0.776 0.715 0.700 0.800 0.812 0.805 0.635
PPGL-C 0.462 0.516 0.487 0.874 0.653 0.726 0.687 0.752 0.825 0.927 0.873 0.634
(a)
 (b)
Fig. 2: The results of varying data sizes of different clients. The
data sizes N1, . . . , N 5are 20, 40, 60, 80, and 100, respectively.
2) Data heterogeneity: We next explore the effect of data
heterogeneity. In this experiment, we fix Ni= 50 for all
clients and vary qfrom 0.3 to 0.9. As listed in Table II, when
data heterogeneity is small (large q), FedAvg and FedProx
achieve satisfactory performance since the consensus graph
is close to local graphs. In this case, FedAvg and FedProx
benefit from using all data to learn a global graph. However,
with the increase in data heterogeneity, the personalized algo-
rithms outperform FedAvg and FedProx. Moreover, our model
outperforms Ditto and MRMTL due to the more reasonable
consensus graph learning formulation. Our model obtains the
best performance for all data heterogeneity since we learn
personalized graphs and a consensus graph simultaneously.
3) The impact of adaptive weight schema: Then, we test the
effectiveness of the method of adjusting weights. We conduct
an ablation experiment where the adaptive weight schema is
removed from our model and let all local clients share the
same weight. The local graphs and consensus graph output by
this model are denoted as “PPFL-L-w/o” and “PPFL-C-w/o”,
respectively. Two cases are considered, i.e., varying data sizes
and varying data heterogeneity. For Case 1, we let qbe 0.5 and
setNito 20, 40, 60, 80, and 100 for C1−C5, respectively. ForTABLE III: The results of removing adaptive weight schema.
Methods Precision ↑Recall ↑FS↑RE↓
Case 1PPFL-L 0.691 0.773 0.691 0.705
PPFL-C 0.743 0.702 0.722 0.689
PPFL-L-w/o 0.618 0.751 0.678 0.711
PPFL-C-w/o 0.702 0.692 0.697 0.701
Case 2PPFL-L 0.718 0.875 0.789 0.605
PPFL-C 0.888 0.744 0.810 0.611
PPFL-L-w/o 0.704 0.857 0.773 0.625
PPFL-C-w/o 0.880 0.730 0.798 0.632
Case 2, we fix Ni= 100 and first generate a graph G1forC1.
The graphs of C2-C5are generated based on G1withqequal
to 0.8, 0.6, 0.4, and 0.2, respectively. The results are listed in
Table III. Note that removing adaptive weight schema from our
model will degrade performance, indicating the effectiveness
of the proposed auto-weighted model.
Moreover, the learned average weights of different clients
are displayed in Fig.4, and two trends are observed. First, local
graphs with large data sizes contribute more to the consensus
graph. Second, local graphs close to the consensus graph
obtain larger weights. Thus, the weight adjustment strategy
can effectively allocate a reasonable weight for each client.
4) Parameter sensitivity: In this experiment, we set Ni=
100 andq= 0.5, and evaluate the learning performance of
different λandν. As displayed in Fig.5, local graphs are less
sensitive to the parameters than the consensus graph. When
νandλare too large, the performance of the consensus
graph degrades rapidly. However, there exist combinations of
νandλthat achieve the highest FSfor both local graphs and
the consensus graph. We need to grid search for the optimal
combination of νandλ, especially for consensus graphs.
5) Algorithm convergence: Finally, we test the convergence
of the proposed algorithms. Fig.6 shows that our algorithms
with different Kcan converge as stated in Theorem 2. When9
(a) Ground truth
 (b) PPGL
 (c) IGL
 (d) FedAvg
 (e) FedProx
 (f) Ditto
 (g) MRMTL
Fig. 3: The graphs of C1learned by different methods when Ni= 100 , q= 0.5. In (a)-(b), red edges are those in the consensus
(global) graph, while blue edges are only in the local graphs.
Fig. 4: The learned γof different clients
(a) Local graphs
 (b) The consensus graph
Fig. 5: The results of parameter sensitivity.
Kis small, fewer local updates are performed. In this case,
more communication rounds between local clients and the
central server are required. On the other hand, when Kis
large, our algorithm only takes a few rounds to converge.
C. Real-world Data
1) COIL-20 data: We employ the COIL-20 dataset4, which
is a collection of gray-scale images including 20 objects
taken from 360 degrees, to learn the relationships between
these images. Each object has 72 images (five degrees an
image) of size 32×32. We randomly select four objects
and divide the images of each object into three views. Each
view contains images taken in consecutive 60 degrees, e.g.,
[0◦,55◦]. Therefore, each view contains 48 images taken from
4 objects, i.e., 12 images per object. A basic assumption
is that the 48 images of different views are defined on the
same node set. The image itself is taken as graph signals,
i.e.,Xi∈R48×1024. Data distributions of different views are
4https://www.cs.columbia.edu/CA VE/software/softlib/coil-20.php
(a) Local graphs
 (b) The consensus graph
Fig. 6: The convergence of the proposed algorithm.
heterogeneous because they are from different shooting angles.
Furthermore, we assume that photos from three views are
taken by three photographers, and they are reluctant to share
their photos, which is the concern of this study. Our goal is
to learn a graph representing the relationships among these 48
images for each view, i.e., I= 3, under data silos. The three
graphs should share some common structures because they
come from the same objects. Moreover, there should be four
communities in the relation graphs since all images belong
to four objects. Therefore, to evaluate the learned graphs, we
employ the Louvain algorithm [46] to detect communities in
the learned graphs. Three metrics are leveraged to evaluate the
detection results, i.e., normalized mutual information ( NMI ),
Fowlkes and Mallows index ( FMI ) [47], and Rand Index ( RI).
The labels of images are taken as the ground truth, and the
results of local graphs are the average of three views. As
displayed in Table IV, the Louvain algorithm successfully
finds all communities in the consensus graph learned by our
models. Instead, some mistakes are made in the graphs learned
by IGL and FedAvg. This is expected since the consensus
graph captures the common structure of local graphs, which
may remove noisy edges of different views. Furthermore, the
local graphs learned by our model also outperform those of
other models since our proposed model is tailored for graph
learning problems. As shown in Fig.7, the communities can
be clearly observed in the consensus graph. However, more
confusing edges appear in the graphs of IGL and FedAvg.
2) Medical data: We finally employ blood-oxygenation-
level-dependent (BOLD) time series extracted from fMRI
data to learn brain functional connectivity graphs. The basic
assumption is that autism may affect brain functional connec-
tivity. If we can learn about the differences in brain functional
connectivity graphs between autistic and non-autistic people,10
/uni0000001b/uni00000014/uni00000019/uni00000015/uni00000017/uni00000016/uni00000015/uni00000017/uni00000013/uni00000017/uni0000001b/uni0000001b
/uni00000014/uni00000019
/uni00000015/uni00000017
/uni00000016/uni00000015
/uni00000017/uni00000013
/uni00000017/uni0000001b
 /uni00000013/uni00000011/uni00000013/uni00000013/uni00000013/uni00000011/uni00000013/uni00000018/uni00000013/uni00000011/uni00000014/uni00000013/uni00000013/uni00000011/uni00000014/uni00000018
(a) IGL- C2
/uni0000001b/uni00000014/uni00000019/uni00000015/uni00000017/uni00000016/uni00000015/uni00000017/uni00000013/uni00000017/uni0000001b/uni0000001b
/uni00000014/uni00000019
/uni00000015/uni00000017
/uni00000016/uni00000015
/uni00000017/uni00000013
/uni00000017/uni0000001b
 /uni00000013/uni00000011/uni00000013/uni00000013/uni00000013/uni00000011/uni00000013/uni00000018/uni00000013/uni00000011/uni00000014/uni00000013 (b) FedAvg
/uni0000001b/uni00000014/uni00000019/uni00000015/uni00000017/uni00000016/uni00000015/uni00000017/uni00000013/uni00000017/uni0000001b/uni0000001b
/uni00000014/uni00000019
/uni00000015/uni00000017
/uni00000016/uni00000015
/uni00000017/uni00000013
/uni00000017/uni0000001b
 /uni00000013/uni00000011/uni00000013/uni00000013/uni00000013/uni00000011/uni00000013/uni00000018/uni00000013/uni00000011/uni00000014/uni00000013/uni00000013/uni00000011/uni00000014/uni00000018 (c) PPGL-L- C2
/uni0000001b/uni00000014/uni00000019/uni00000015/uni00000017/uni00000016/uni00000015/uni00000017/uni00000013/uni00000017/uni0000001b/uni0000001b
/uni00000014/uni00000019
/uni00000015/uni00000017
/uni00000016/uni00000015
/uni00000017/uni00000013
/uni00000017/uni0000001b
 /uni00000013/uni00000011/uni00000013/uni00000013/uni00000013/uni00000011/uni00000013/uni00000018/uni00000013/uni00000011/uni00000014/uni00000013 (d) PPGL-C
Fig. 7: The figure depicts the communities in the learned graphs. The suffix −C2stands for the local graphs of C2.
TABLE IV: The community detection results of graphs learned
by different methods.
IGL FedAvg FedProx MRMTL Ditto PPGL-L PPGL-C
NMI ↑0.779 0.745 0.767 0.795 0.786 0.865 1
RI↑0.855 0.843 0.851 0.891 0.883 0.919 1
FMI ↑0.755 0.736 0.745 0.773 0.768 0.852 1
TABLE V: Comparison between the graphs learned from the
autism and non-autism groups.
#Edges Average Edge weights
Autism 114 0.091
Non-autism 125 0.109
it may help us better understand the mechanism of autism.
However, medical data are privacy-sensitive, and their trans-
mission to an unreliable central server is usually prohibited.
In this experiment, the used dataset5contains 539 autistic
individuals and 573 typical controls, from which we select fifty
autistic and fifty non-autistic subjects. Each client (subject)
contains 176 signals (the length of the BOLD time series
is 176). Following [12], we select 34 functional regions of
interest from 90 standard regions of the Anatomical Automatic
Labeling (AAL) template, indicating that Xi∈R34×176, i=
1, . . . , 100. Then, we use our method to learn the connectivity
graphs of the 34 regions, and the edges with weights less than
0.01 are removed. We should mention that the purpose of this
experiment is to show that our method can learn graphs that
reflect the impact of autism on brain functional connectivity.
Next, we will show that the selected 34 regions are sufficient
to achieve this goal.
Table V displays the average number of edges and their
average weights of the graphs learned from the autism and
non-autism subjects. It is observed the average number of
the graphs from autism subjects is smaller than those of
non-autism subjects. Furthermore, the graphs learned from
autism subjects exhibit smaller edge weights than those of
non-autism subjects, indicating weaker connectivity between
different functional regions. This is consistent with the study
[48], which shows that autism may cause underconnectivity
of brain functional regions. Furthermore, Fig.8 depicts the
learned graphs using our model. It is observed that graphs
5http://preprocessed-connectomes-project.org/abide/
(a) Sagittal
 (b) Axial
 (c) Coronal
(d) Sagittal
 (e) Axial
 (f) Coronal
Fig. 8: The figure depicts our learned graphs from three views.
The top and bottom rows show the graphs of non-autistic and
autistic subjects, respectively. The red edges are those in the
consensus graph, while the blue edges are those unique edges
in local graphs.
of autism and non-autism individuals share many common
edges learned in the consensus graph. On the other hand, there
are some noticeable topological changes between the graphs
of autism and non-autism individuals. These edges reflect
changes in the functional connectivity caused by autism, which
may aid in diagnosing autism. In the future, a domain expert
may help interpret the results from a medical perspective.
VI. C ONCLUSION
In this paper, we proposed a framework to learn graphs
under data silos. In our framework, we jointly learned a
personalized graph for each client to handle data heterogeneity,
and a consensus graph for all clients to capture global infor-
mation. Then, we devised a tailored algorithm in which all
private data are processed in local clients to preserve data pri-
vacy. Convergence analyses for the proposed algorithm were
provided. Extensive experiments showed that our approach
can efficiently learn graphs in the target scenario. Future
research may include generalizing our framework to other
graph learning models except for the smoothness assumption.11
APPENDIX A
PROOF OF THEOREM 1
We first provide the following lemmas necessary to prove
the Theorem 1.
Lemma 1. The function h(w)is4β-strongly convex.
Proof. For any w≥0, the Hessian matrix of h(w)w.r.t.w
isH= 4βI+αS⊤diag 
(Sw).(−2)
S. It is not difficult to
check that H≻4βI. Thus, h(w)is4β-strongly convex.
Lemma 2. For any Y= [y1, . . . ,yI+1]∈Rp×(I+1), we have
R(Y)≤
νp
Iωmax(Lm) +√p
∥Y∥F.
Proof. Leteyj∈RI+1be the j-th row vector of the matrix
Y, it is not difficult to obtain
R(Y) =νIX
i=1∥yi−yI+1∥2+∥yI+1∥1
≤ν√
IvuutIX
i=1∥yi−yI+1∥2
2+√p∥yI+1∥2
=ν√
IvuutpX
j=1eyjLmey⊤
j+√p∥yI+1∥2
≤ν√
IvuutpX
j=1ωmax(Lm)∥eyj∥2
2+√p∥Y∥F
=
νp
Iωmax(Lm) +√p
∥Y∥F, (29)
where the first inequality holds due to the basic inequalityPn
i=1ai
n≤qPn
i=1a2
i
nforai≥0and norm inequality
∥a∥1≤√p∥a∥2fora∈Rp. The second inequality holds due
to the definition of the ℓ2matrix norm and ∥yI+1∥2≤ ∥Y∥F.
Finally, we complete the proof.
With the two lemmas, we start the proof of Theorem 1.
First, the objective function (8) can be rewritten in a matrix
form. Let Z= [z1, . . . ,zI,0]∈Rp×(I+1), and we have
min
W≥0(1/N)⟨Z,W⟩+H(W) +λR(W), (30)
where H(W) =PI
i=1h(wi). Since cWis the solution of
(30), we have
(1/N)D
Z,cWE
+H(cW) +λR(cW)
≤(1/N)⟨Z,W∗⟩+H(W∗) +λR(W∗). (31)
Accordingly, we yield that
(1/N)D
Z∗,cW−W∗E
+H(cW)−H(W∗)
≤λR(W∗)−λR(cW) + (1 /N)D
E,W∗−cWE
, (32)
where E= [e1, . . . ,eI,0]∈Rp×(I+1)is the error matrix, and
Z∗= [z∗
1, . . . ,z∗
I,0]∈Rp×(I+1)is the real pairwise distance
matrix.
Then, we define a variable v=PI
i=1Pp
j=11
σ2e(ei[j])2=
1
σ2e∥E∥2
Fwhich follows a chi-squared distribution with thedegree of freedom as pI. Using the Wallace inequality [49],
forδ >0, we have
Pr(v≥pI+δ)≤exp
−1
2
δ−pIlog
1 +δ
pI
,
(33)
which will lead to
Pr
(1/N)∥E∥F≤(σe/N)p
pI+δ
≥1−exp
−1
2
δ−pIlog
1 +δ
pI
. (34)
According to (34), with probability at least
1−exp
−1
2
δ−pIlog
1 +δ
pI
, we obtain
(1/N)D
E,W∗−cWE
≤(1/N)∥E∥F∥W∗−cW∥F
≤(σe/N)p
pI+δ∥W∗−cW∥F. (35)
Next, we focus on Hrelated terms in (32) and yield
H(cW)−H(W∗) =IX
i=1h(bwi)−h(w∗
i)
≥IX
i=1⟨∇h(w∗
i),bwi−w∗
i⟩+ 2β∥bwi−w∗
i∥2
2
≥IX
i=1−∥∇ h(w∗
i)∥2∥bwi−w∗
i∥2+ 2β∥bwi−w∗
i∥2
2
≥ −Ch√
IcW−W∗
F+ 2βcW−W∗2
F. (36)
The first inequality holds due to that his a4β- strongly convex
function, as stated in Lemma 1. The second inequality holds
due to Cauchy-Schwarz inequality. The last inequality holds
due to Assumption 2 and the fact thatPI
i=1∥bwi−w∗
i∥2≤√
I∥cW−W∗∥F.
ForZ∗related terms, we have
(1/N)D
Z∗,cW−W∗E
≥ −(1/N)∥Z∗∥FcW−W∗
F
≥ −√
ICz/NcW−W∗
F. (37)
The second inequality holds due to Assumption 1.
Finally, we focus on the Rrelated terms and have
R(W∗)−R(cW)
=νIX
i=1(∥w∗
i−w∗
con∥2− ∥bwi−bwcon∥2)
+∥w∗
con∥1− ∥bwcon∥1
≤νIX
i=1∥(w∗
i−bwi)−(w∗
con−bwcon)∥2+∥w∗
con−bwcon∥1
=R(W∗−cW)≤
νp
Iωmax(Lm) +√p
∥W∗−cW∥F,
(38)
where the last inequality holds due to Lemma 2.
Plugging (35), (36), (37), and (38) into (32), it is not difficult
to yield
2βcW−W∗2
F≤(σe/N)p
pI+δW∗−cW
F12
+Ch√
IcW−W∗
F+√
ICz/NcW−W∗
F
+λ
νp
Iωmax(Lm) +√pcW−W∗
F. (39)
Finally, combining (39) and (15), we can obtain the conclusion
of Theorem 1.
APPENDIX B
PROOF OF PROPOSITION 1
The proof is mainly from [50] but with some modifications.
For two vectors yandy′infW, we have∇yf(t)
i(y,w(t)
con)− ∇y′f(t)
i(y′,w(t)
con)
2
=
4β+ργ(t)
i
(y−y′)−αS⊤1
Sy+ζ1−1
Sy′+ζ1
2
≤
4β+ργ(t)
i
∥y−y′∥2+αS⊤
21
Sy+ζ1−1
Sy′+ζ1
2
≤
4β+ργ(t)
i
∥y−y′∥2+α∥S∥2
ζ2∥Sy−Sy′∥2
≤
4β+ργ(t)
i
∥y−y′∥2+α∥S∥2
2
ζ2∥y−y′∥2
=
4β+2α(d−1)
ζ2+ργ(t)
i
∥y−y′∥2
:=L(t)
i∥y−y′∥2. (40)
The first inequality holds due to the triangle inequality, while
the second equality holds due to Lemma 1 in [50]. From (40),
we can conclude that f(t)
i(wi,w(t)
con)isL(t)
i-Lipschitz smooth
w.r.t.wionfW. On the other hand, the strong convexity of
f(t)
i(wi,w(t)
con)can be proved in the same way as Lemma 1.
APPENDIX C
PROOF OF THEOREM 2
First, let us provide a lemma that is essential to the proof.
Lemma 3. ( [51]) For any two positive constants a, b > 0,
we have
√a−a
2√
b≤√
b−b
2√
b. (41)
Proof. Fora, b > 0, it is not difficult to derive that
√a−√
b2
≥0
=⇒a−2√
ab+b≥0
=⇒√a−a
2√
b≤√
b
2
=⇒√a−a
2√
b≤√
b−b
2√
b. (42)
The proof of Lemma 3 completes.
Then, we start to prove Theorem 2. Let us consider the
t-th communication round. According to Proposition 1, the
objective function f(t)
i(wi,w(t)
con)isL(t)
i-Lipschitz smooth and
S(t)
i-strongly convex w.r.t. wi. Based on Assumption 3 and the
stepsize ηwdefined in Assumption 4, the accelerated projectedgradient descent algorithm (19)-(21) is proved to converge to
the optimal minimum [39]. Thus, after enough K(t)
iiterations,
we can obtain w(t+1)
i such that
f(t)
i(w(t+1)
i,w(t)
con)≤f(t)
i(w(t)
i,w(t)
con). (43)
On the other hand, when updating wconin the t-th commu-
nication round, the w(t+1)
con output by proximal operator (24)
is the solution of problem (22), i.e.,
w(t+1)
con = argmin
wconIX
i=1f(t)
i(w(t+1)
i,wcon) +λ∥wcon∥1.
Therefore, we have
IX
i=1f(t)
i(w(t+1)
i,w(t+1)
con) +λ∥w(t+1)
con∥1
≤IX
i=1f(t)
i(w(t+1)
i,w(t)
con) +λ∥w(t)
con∥1. (44)
Combining (43) and (44), we can obtain
IX
i=1f(t)
i(w(t+1)
i,w(t+1)
con) +λ∥w(t+1)
con∥1
≤IX
i=1f(t)
i(w(t)
i,w(t)
con) +λ∥w(t)
con∥1. (45)
Bring the updated γ(t)
iin (25) to (45), we obtain
IX
i=1gi(w(t+1)
i) +ρ∥w(t+1)
i−w(t+1)
con∥2
2
2∥w(t)
i−w(t)
con∥2+λ∥w(t+1)
con∥1
≤IX
i=1gi(w(t)
i) +ρ∥w(t)
i−w(t)
con∥2
2
2∥w(t)
i−w(t)
con∥2+λ∥w(t)
con∥1. (46)
According to Lemma 3, we have
IX
i=1∥w(t+1)
i−w(t+1)
con∥2−IX
i=1∥w(t+1)
i−w(t+1)
con∥2
2
2∥w(t)
i−w(t)
con∥2
≤IX
i=1∥w(t)
i−w(t)
con∥2−IX
i=1∥w(t)
i−w(t)
con∥2
2
2∥w(t)
i−w(t)
con∥2. (47)
Summing (46) and (47), we have
IX
i=1gi(w(t+1)
i) +ρ∥w(t+1)
i−w(t+1)
con∥2+λ∥w(t+1)
con∥1
≤IX
i=1gi(w(t)
i) +ρ∥w(t)
i−w(t)
con∥2+λ∥w(t)
con∥1. (48)
Thus, the update of the t-th communication round will mono-
tonically decrease the objective function of (8). As tincreases,
the optimization will converge. When the convergence reaches,
the KKT condition of problem (8) will hold, i.e., Algorithm
1 at least converges to a local optimal minimum.13
REFERENCES
[1] X. Dong, D. Thanou, M. Rabbat, and P. Frossard, “Learning graphs
from data: A signal representation perspective,” IEEE Signal Process.
Mag. , vol. 36, no. 3, pp. 44–63, 2019.
[2] U. V on Luxburg, “A tutorial on spectral clustering,” Stat. Comput. ,
vol. 17, pp. 395–416, 2007.
[3] Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and S. Y . Philip, “A
comprehensive survey on graph neural networks,” IEEE Trans. Neural
Netw. Learn. Syst. , vol. 32, no. 1, pp. 4–24, 2020.
[4] G. Mateos, S. Segarra, A. G. Marques, and A. Ribeiro, “Connecting the
dots: Identifying network structure via graph signal processing,” IEEE
Signal Process. Mag. , vol. 36, no. 3, pp. 16–43, 2019.
[5] J. Friedman, T. Hastie, and R. Tibshirani, “Sparse inverse covariance
estimation with the graphical lasso,” Biostatistics , vol. 9, no. 3, pp. 432–
441, 2008.
[6] H. E. Egilmez, E. Pavez, and A. Ortega, “Graph learning from data
under laplacian and structural constraints,” IEEE J. Sel. Topics Signal
Process. , vol. 11, no. 6, pp. 825–841, 2017.
[7] J. Ying, J. V . de Miranda Cardoso, and D. Palomar, “Nonconvex sparse
graph learning under laplacian constrained graphical model,” Proc. Adv.
Neural Inf. Process. Syst. , vol. 33, pp. 7101–7113, 2020.
[8] J.-F. Cai, J. V . de Miranda Cardoso, D. Palomar, and J. Ying, “Fast
projected newton-like method for precision matrix estimation under total
positivity,” Proc. Adv. Neural Inf. Process. Syst. , vol. 36, 2024.
[9] A. Ortega, P. Frossard, J. Kova ˇcevi´c, J. M. Moura, and P. Vandergheynst,
“Graph signal processing: Overview, challenges, and applications,” Proc.
IEEE , vol. 106, no. 5, pp. 808–828, 2018.
[10] X. Dong, D. Thanou, P. Frossard, and P. Vandergheynst, “Learning
Laplacian matrix in smooth graph signal representations,” IEEE Trans.
Signal Process. , vol. 64, no. 23, pp. 6160–6173, 2016.
[11] V . Kalofolias, “How to learn a graph from smooth signals,” in Proc. Int.
Conf. Artif. Intell. Stat., AISTATS . PMLR, 2016, pp. 920–929.
[12] X. Pu, T. Cao, X. Zhang, X. Dong, and S. Chen, “Learning to learn
graph topologies,” Proc. Adv. Neural Inf. Process. Syst. , vol. 34, pp.
4249–4262, 2021.
[13] P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N.
Bhagoji, K. Bonawitz, Z. Charles, G. Cormode, R. Cummings et al. ,
“Advances and open problems in federated learning,” Found. Trends
Mach. Learn. , vol. 14, no. 1–2, pp. 1–210, 2021.
[14] N. Rieke, J. Hancox, W. Li, F. Milletari, H. R. Roth, S. Albarqouni,
S. Bakas, M. N. Galtier, B. A. Landman, K. Maier-Hein et al. , “The
future of digital health with federated learning,” NPJ Digit. Med , vol. 3,
no. 1, pp. 1–7, 2020.
[15] T. Li, A. K. Sahu, A. Talwalkar, and V . Smith, “Federated learning:
Challenges, methods, and future directions,” IEEE Signal Process. Mag. ,
vol. 37, no. 3, pp. 50–60, 2020.
[16] T. Yang, X. Yi, J. Wu, Y . Yuan, D. Wu, Z. Meng, Y . Hong, H. Wang,
Z. Lin, and K. H. Johansson, “A survey of distributed optimization,”
Annu. Rev. Control , vol. 47, pp. 278–305, 2019.
[17] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in Proc. Int. Conf. Artif. Intell. Stat., AISTATS . PMLR, 2017,
pp. 1273–1282.
[18] A. Z. Tan, H. Yu, L. Cui, and Q. Yang, “Towards personalized federated
learning,” IEEE Trans. Neural Netw. Learn. Syst. , 2022.
[19] Y . Mansour, M. Mohri, J. Ro, and A. T. Suresh, “Three approaches for
personalization with applications to federated learning,” arXiv preprint
arXiv:2002.10619 , 2020.
[20] V . Smith, C.-K. Chiang, M. Sanjabi, and A. S. Talwalkar, “Federated
multi-task learning,” Proc. Adv. Neural Inf. Process. Syst. , vol. 30, 2017.
[21] C. Finn, P. Abbeel, and S. Levine, “Model-agnostic meta-learning for
fast adaptation of deep networks,” in Proc. Int. Conf. Mach. Learn.
PMLR, 2017, pp. 1126–1135.
[22] P. Danaher, P. Wang, and D. M. Witten, “The joint graphical lasso for
inverse covariance estimation across multiple classes,” J. R. Stat. Soc.
B., vol. 76, no. 2, pp. 373–397, 2014.
[23] P. J. Bickel and E. Levina, “Regularized estimation of large covariance
matrices,” Ann. Statist , vol. 36, no. 1, p. 199–227, 2008.
[24] Y . Yuan, D. W. Soh, X. Yang, K. Guo, and T. Q. Quek, “Joint network
topology inference via structured fusion regularization,” arXiv preprint
arXiv:2103.03471 , 2021.
[25] X. Zhang and Q. Wang, “Time-varying graph learning under structured
temporal priors,” in Proc. Eur. Signal Process. Conf. IEEE, 2022, pp.
2141–2145.[26] K. Yamada, Y . Tanaka, and A. Ortega, “Time-varying graph learning
based on sparseness of temporal variation,” in Proc. IEEE Int. Conf.
Acoust., Speech, Signal Process. IEEE, 2019, pp. 5411–5415.
[27] X. Zhang and Q. Wang, “A graph-assisted framework for multiple graph
learning,” IEEE Trans. Signal. Inf. Process. Netw. , pp. 1–16, 2024.
[28] C. T Dinh, N. Tran, and J. Nguyen, “Personalized federated learning
with moreau envelopes,” Proc. Adv. Neural Inf. Process. Syst. , vol. 33,
pp. 21 394–21 405, 2020.
[29] A. Bellet, R. Guerraoui, M. Taziki, and M. Tommasi, “Personalized and
private peer-to-peer machine learning,” in Proc. Int. Conf. Artif. Intell.
Stat., AISTATS . PMLR, 2018, pp. 473–481.
[30] O. Marfoq, G. Neglia, A. Bellet, L. Kameni, and R. Vidal, “Federated
multi-task learning under a mixture of distributions,” Proc. Adv. Neural
Inf. Process. Syst. , vol. 34, pp. 15 434–15 447, 2021.
[31] F. Chen, G. Long, Z. Wu, T. Zhou, and J. Jiang, “Personalized federated
learning with graph,” arXiv preprint arXiv:2203.00829 , 2022.
[32] L. Stankovi ´c, M. Dakovi ´c, and E. Sejdi ´c, “Introduction to graph signal
processing,” in Vertex-Frequency Analysis of Graph Signals . Springer,
2019, pp. 3–108.
[33] Z. Hu, F. Nie, W. Chang, S. Hao, R. Wang, and X. Li, “Multi-view
spectral clustering via sparse graph learning,” Neurocomputing , vol. 384,
pp. 1–10, 2020.
[34] F. Nie, J. Li, X. Li et al. , “Self-weighted multiview clustering with
multiple graphs.” in Int. Joint Conf. Artif. Intell. , 2017, pp. 2564–2570.
[35] S. Hara and T. Washio, “Learning a common substructure of multiple
graphical gaussian models,” Neur. Netw. , vol. 38, pp. 23–38, 2013.
[36] W. Lee and Y . Liu, “Joint estimation of multiple precision matrices with
common structures,” J. Mach. Learn. Res. , vol. 16, no. 1, pp. 1035–1062,
2015.
[37] A. Karaaslanli, S. Saha, S. Aviyente, and T. Maiti, “Multiview graph
learning for single-cell rna sequencing data,” bioRxiv , 2021.
[38] A. Karaaslanli and S. Aviyente, “Multiview graph learning with consen-
sus graph,” arXiv preprint arXiv:2401.13769 , 2024.
[39] Y . Nesterov, Introductory lectures on convex optimization: A basic
course . Springer Science & Business Media, 2013, vol. 87.
[40] R. Shokri, M. Stronati, C. Song, and V . Shmatikov, “Membership
inference attacks against machine learning models,” in Proc. IEEE Symp.
Secur. Privacy (SP) . IEEE, 2017, pp. 3–18.
[41] M. Al-Rubaie and J. M. Chang, “Reconstruction attacks against mobile-
based continuous authentication systems in the cloud,” IEEE Trans. Inf.
Forensics Security , vol. 11, no. 12, pp. 2648–2663, 2016.
[42] C. Dwork, F. McSherry, K. Nissim, and A. Smith, “Calibrating noise
to sensitivity in private data analysis,” in Proc. Theory of Cryptography
Conf. Springer, 2006, pp. 265–284.
[43] T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V . Smith,
“Federated optimization in heterogeneous networks,” Proceedings of
Mach. Learn. and Sys. , vol. 2, pp. 429–450, 2020.
[44] K. Liu, S. Hu, S. Z. Wu, and V . Smith, “On privacy and personalization
in cross-silo federated learning,” Proc. Adv. Neural Inf. Process. Syst. ,
vol. 35, pp. 5925–5940, 2022.
[45] T. Li, S. Hu, A. Beirami, and V . Smith, “Ditto: Fair and robust federated
learning through personalization,” in Proc. Int. Conf. Mach. Learn.
PMLR, 2021, pp. 6357–6368.
[46] S. Fortunato, “Community detection in graphs,” Phys. Rep. , vol. 486,
no. 3-5, pp. 75–174, 2010.
[47] J. Han, J. Pei, and M. Kamber, Data mining: concepts and techniques .
Elsevier, 2011.
[48] R. K. Kana, L. E. Libero, and M. S. Moore, “Disrupted cortical connec-
tivity theory as an explanatory model for autism spectrum disorders,”
Phys. Life Rev , vol. 8, no. 4, pp. 410–437, 2011.
[49] D. L. Wallace, “Bounds on normal approximations to student’s and the
chi-square distributions,” Ann. Inst. Stat. Math. , pp. 1121–1130, 1959.
[50] S. S. Saboksayr, G. Mateos, and M. Cetin, “Online discriminative graph
learning from multi-class smooth signals,” Signal Process. , vol. 186, p.
108101, 2021.
[51] F. Nie, H. Huang, X. Cai, and C. Ding, “Efficient and robust feature
selection via joint ℓ2,1-norms minimization,” Proc. Adv. Neural Inf.
Process. Syst. , vol. 23, 2010.