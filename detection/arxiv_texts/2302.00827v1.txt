Including stress relaxation in point-process model for seismic occurrence
Giuseppe Petrillo and Jiancang Zhuang
The Institute of Statistical Mathematics, Research Organization of Information and Systems, Tokyo, Japan
Eugenio Lippiello
Department of Mathematics and Physics, University of Campania \L. Vanvitelli", Viale Lincoln 5, 81100 Caserta, Italy
(Dated: February 3, 2023)
Physics-based and statistic-based models for describing seismic occurrence are two sides of the
same coin. In this article we compare the temporal organization of events obtained in a spring-block
model for the seismic fault with the one predicted by probabilistic models for seismic occurrence.
Thanks to the optimization of the parameters, by means of a Maximum Likelihood Estimation, it
is possible to identify the statistical model which ts better the physical one. The results show
that the best statistical model must take into account the non trivial interplay between temporal
clustering, related to aftershock occurrence, and the stress discharge following the occurrence of
high magnitude mainshocks. The two mechanisms contribute in dierent ways according to the
minimum magnitude considered in the data tting catalog.
I. INTRODUCTION
The description and understanding of seismic phenom-
ena is fascinating not only to add a piece to basic physics
knowledge, but also for the social impact it can have.
Seismic prediction is a longstanding and debated topic
in the geophysical community, with dierent scenarios,
ranging from the extreme position of a completely ran-
dom unpredictable (Poisson) process, up to deterministic
predictions [1]. The diculty in answering this debate
can be attributed to the complexity of the earthquake
process, presenting dierent mechanisms acting on very
dierent spatial and temporal scales [2].
Currently, epidemic-like probabilistic models [3{5] have
given and continue to provide a fundamental contribu-
tion to seismic forecasting. These class of models are able
to capture the spatio-temporal clustering of earthquakes,
with the majority of earthquakes, usually termed after-
shocks, occurring soon after large earthquakes and close
in space to their epicenter. Within these models seis-
mic hazard increases after the occurrence of large earth-
quakes. Nevertheless it is not possible to achieve informa-
tion on the timing of the next large earthquake in a given
region because magnitudes are randomly assigned to each
earthquake from the empirical magnitude distribution
and does not depend on the previous seismic history. On
the other hand, physical models originally implement the
idea that an earthquake is the sudden relaxation of the
stress accumulated over years or decades in such a region.
Accordingly one could expect that the region experienc-
ing the largest slip also relaxes most of the accumulated
stress and therefore is less prone to host a new earth-
quake, as in the original hypothesis of alternation pro-
posed by Gilbert in 1894 [6]. Subsequent models, devel-
oped along this direction, assume that consecutive earth-
quakes substantially re-rupture the same fault segment,
nucleating characteristic earthquakes which are roughly
equal in size and roughly periodic is time. These models
usually termed seismic gap or seismic cycle models [7, 8],
propose the possibility of quasi deterministic predictionof the timing of the next large earthquake. Testing of the
seismic gap hypothesis have shown its ineciency [9, 10]
even if it is still sometimes used in earthquake forecasting
[11]. Furthermore the seismic gap model does not pro-
vide any justication for the occurrence of aftershocks
which conversely, as anticipated, is a very distinctive fea-
ture of seismic catalogs. Nevertheless, aftershock occur-
rence, and as a consequence also short-term clustering,
is not incompatible within the seismic gap hypothesis if
aftershocks are located outside the region involved dur-
ing the mainshock slip or, at most, in regions with low
levels of the mainshock slip. This feature has been doc-
umented for 101 large subduction zone plate boundary
mainshocks with well determined coseismic slip distribu-
tions [12]. This study has indeed revealed a decit of
aftershocks inside the mainshock slip area, consistently
with the hypothesis of large slip areas re-locking. As a
further indication of compatibility between the seismic
gap hypothesis and aftershock occurrence is the obser-
vation that larger aftershocks occur farther away than
smaller aftershocks [13].
Interestingly, the interplay between the stress accumu-
lation/relaxation mechanism underlying the seismic gap
hypothesis and the occurrence of aftershocks described
by epidemic models, has been enlightened in a spring-
block model for the seismic fault. The model, is a gen-
eralization of the OFC model [14], which represents a
cellular automaton version of spring-block model for seis-
mic fault [15]. In particular, the considered model, de-
ned afterslip relaxation OFC (AROFC) model, belongs
to the class of models [16{24] which add a relaxation
mechanism introducing aftershock occurrence within the
OFC model [14]. In particular the AROFC model de-
scribes the seismogenic fault as an elastic layer, like in
the OFC description, and it takes into account its cou-
pling with a more ductile layer where stress is gradually
relaxed by a post-seismic deformation, usually termed
afterslip [25, 26]. The model is very ecient in quanti-
tatively reproducing the main statistical features of seis-
mic catalogs, as well as to explain the connection be-arXiv:2302.00827v1  [physics.geo-ph]  2 Feb 20232
tween aftershocks and afterslip [22, 24] or the eects of
Moho depth on magnitude distribution [27]. Interest-
ingly, in the AROFC model [28], even if the higher seismic
rate is observed after the occurrence of large mainshock,
some features of the seismic gap hypothesis are recovered,
with large earthquakes usually occurring in gap regions.
Nevertheless, the timing of mainshocks is irregular and
weakly depends on the time delay of that region from
the previous slip. Recent results therefore show that epi-
demic description and gap hypothesis, in a weaker form,
can coexist.
The main purpose of this study is to combine the two
mechanisms in a statistical model for seismic occurrence
which, on one side, preserves the epidemic description
and, on the other side, keeps into account the stress accu-
mulation/relaxation mechanism beyond the seismic gap
hypothesis. More precisely we show how the two scenar-
ios can be combined in various statistical models [29{32].
The problem is that an accurate statistical validation of
the dierent models is not possible in instrumental seis-
mic catalogs since the occurrence of large earthquakes,
with overlapping slip regions, is a rare event. For this
reason we search for the statistical model which better
reproduce the temporal organization of earthquakes in
the AORFC model, which conversely allows us to gen-
erate arbitrarily long simulated catalogs for a full sta-
tistical validation. More precisely we identify the best
parameters for each model via a Maximum Likelihood
Estimation (MLE) nding a non-trivial dependence of
the Log-Likelihood function on the minimum magnitude
of the catalog.
The paper is organized as follows. Section II is an
overview of the AROFC model that is used for the gen-
eration of the synthetic catalog. The section III is dedi-
cated to the introduction of the various statistical models
that are used subsequently. The optimization of the pa-
rameters by means of MLE and the comparison of the
eciency of the dierent models in tting the data, are
carried out in the following sections. The last section is
devoted to conclusions.
II. THE AROFC MODEL
The model is composed by two layers: a layer Hand
a layerU, which mimics the brittle and the ductile part
of the fault, respectively. The layer Uis driven by the
tectonic dynamics at the velocity VDand is elastically
coupled to a layer H. Each layer is an object that can
be considered as a set of blocks organized on a lattice
of sizeLxLy. For simplicity, we assume VDdirected
along thex-direction and, therefore, the displacement is
conned along x, denedhi(t) in the layer Handui(t) in
the layerU. We assume a short-range interaction where
each block is elastically connected only with its nearest
neighbor blocks. Within this approximation, the total
stress on block Hat position ican be divided into two
contributions: the intra-layer stress fi=khhiand theinter-layer stress gi=k(ui hi). In the last expres-
sions,  is the discretized Laplacian, whereas khand
krepresents the elastic constants of the inter-layer and
the intra-layer interactions, respectively. Regarding the
friction force, we assume two dierent forms. For the
brittle fault Hwe adopt a Coulomb failure criterion: as
soon as the total force fi+giovercomes a local frictional
thresholdfth
i, the position hibecomes unstable and the
i th block performs a slip of x quantity  h. The stress
evolves as follow:
fi!fi 4khh
fi!fj+khh
gi!gi 4khh
gj!gj kh( )h; (1)
where= (1 q0)(k
4kh) and= (1 q0 4q1)(k
4kh). The
rst quantity takes into account the coupling between
the two layers, while the second one is the dissipation.
The quantity khh= frepresents the stress drop
and it is extracted from a Gaussian distribution with
averagehfiand standard deviation . For the ductile
layer, we assume a velocity-strengthening friction, taking
the stationary form of the rate-and-state friction law
fU
i(t) =N(c+Alog(ui(t)
VD)), whereNis the normal
stress,cis the friction coecient when the block U
slides at the steady velocity VDandA>0 for a velocity-
strengthening material. The slip  hofhiinduces a
coseismic slip q0hofuiandq1hof the blocks uj
(wherejis a nearest neighbor of ui). When the total
stress acting on i-th block of layer Hexceeds the local
frictional stress threshold fth
i, i.e., when fi+gifth
i.
The in-depth explanation of the dynamics of the model
was studied in [22{24]. In this article we simulate a fault
with system size Ly= 200 andLx= 400 with absorbing
boundary conditions.
An earthquake is dened as a series of slips starting
from an initial instability of the block i, whose position
denes the epicentral coordinates of the earthquake
and terminating when fi+gifth
i. Taking into
account that the i-th block can slip more than one time
during an earthquake, we introduce the quantity nk(i)
for the number of slips performed by the i-th block
during the k-th earthquake. The seismic moment Mk
released during the k-th earthquake can be dened as
Mk/P
ink(i)h, where the sum extends over all
lattices sites. We nally dene the moment magnitude
mk= (2=3) log10Mk, where we have set to zero the
arbitrary additive constant.
Therefore, with the model described, it is possible to
obtain as output a collection of the magnitude of events
as a function of time, called the seismic catalogue.
We want to emphasize that this model reproduces all
the statistical laws of earthquakes correctly, such as
Gutenberg-Richter law, Omori-Utsu law, mvsLog(A)-
scaling, etc. [23].
We simulated two synthetic catalogues: the rst,3
CAT 1, consists of N= 1E6 events with no constraint
on the seismic moment; the second, CAT 2, is a subset
ofCAT 1obtained by considering only earthquakes with
a seismic moment Mless than 1000. In particular in
Fig.(1) the seismic moment versus the occurrence time
is shown. Here, each symbol corresponds to an event
with occurrence time tand moment magnitude Mk.
It is immediate to observe the presence of correlated
sequences, called clusters, in the catalog. Each cluster is
composed by a mainshock (dened as the biggest event
of the sequence) and some aftershocks/foreshocks (all
the events occurred after/before the mainshock). It is
common to observe a cluster with the rst event bigger
than all the others, this case is not a pathology of the
model, but represents a single seismic sequence without
the occurrence of foreshocks, which is often observed in
instrumental catalogs.
III. SELF TRIGGERING AND
STRAIN-RELEASE MODELS
A Point Process (PP) is a very popular mathemati-
cal model used in seismology, especially for earthquake
forecasting, implementing the assumption that an earth-
quake is an isolated point in time. PP can be dened by
means of the number of events Noccurred in a certain
time interval  t. If this time span is small, Ncan as-
sume a null value (event not happened) or a unit value
(event happened). Therefore the process is univocally
determined by the probability of observing an event in
a certain interval  tconditioned to the previous history
Ht. The limit
FIG. 1: The numerical earthquake catalogues obtained
with the OFCR model. (Top panel) Black circles
indicate the seismic moment Miof all the event i
occurred at time ti. (Bottom panel) Red squares
indicate the seismic moment Miof all the event i
occurred at time tiwith the extra constraint Mi1000.(tjHt) = lim
t!0P(Nt= 1jHt)
t(2)
then represents the probability density (usually called
"intensity function") of observing an earthquake at a cer-
tain timet, given its history up to time t.
Forecasting models also consider a point-process descrip-
tion for the spatial occurrence of earthquakes. In this
study, for simplicity, we only consider temporal models.
A. Self-Correcting Models
In the classical rebound model, one assumes that stress
slowly builds up to the breaking point when an earth-
quake occurs. The rupture of the fault following this
event, on the other hand, resulted in a reduction in stress.
In general, the conditional intensity rate of this model
can be written as:
SR(tjHt) =eF(t) G[0;t)(3)
whereG[0;t) is an history-related function and F(t) is
the stress loading which, in general, is considered a lin-
ear increasing function of the time. The exponential form
is chosen to ensure positivity of the rate SR.
The Stress Release Model (SR) belongs to the self-
correcting models introduced by [30]. In practice, the
elastic strain is accumulated due to the long-term tec-
tonic loading, and is released when it exceeds a certain
threshold level. After the release of the stress, a certain
period is needed to the re-accumulation of the stress and
the genesis of a subsequent event. Therefore Eq.(3) for a
SR model, as proposed by [30, 33{35], can be written as
SR(tjHt) =e+t S[0;t)(4)
whereF(t) =+tis a linear function of the time,
representing the tectonic loading, whilst S[0;t) is re-
lated to the reduction of stress due to the past history.
Indicating by Mithe seismic moment of the i-th event,
S[0;t) =P
i:ti<tSi, whereSiis the stress released by the
i-th earthquake, and the sum extends to all events oc-
curred atti<t. A reasonable hypothesis [36, 37] is that
Si,is proportional to square root of the energy released
Si/pEi, leading to Si/pMi. Therefore, the tting
parameter set for SR model in Eq.(4) is  SR= (;; ).
Sometimes a simplied version of the SR model is used in
the description of seismicity. In particular, in refs.[32, 38]
is has assumed that, on average, the total stress released
is proportional to the number of occurred earthquakes,
leading toS[0;t) =N[0;t), whereN[0;t) denotes the
number of earthquakes in the interval (0 ;t]. With this
position, we obtain
SC(tjHt) =e+t N[0;t)(5)
The tting parameter set is the same of the SR model
and, from now on, we call this model simply Self-
Correcting (SC) model since it does not take into account
the energy released by previous earthquakes.4
B. Triggering models
Self-exiting point process (SEPP) have been also used
to model the seismic occurrence and for seismic forecast-
ing. A typical Hawkes process [39] can be written as
(tjHt) =(t) +X
j:tj<t(t tj); (6)
where(t) represent the background seismicity and (t)
the triggering intensity function, in practice, controls
the clustering density. For the functional form of (t),
many proposals have been made [3, 31, 40{43].
Eq.(6) describes seismicity as a branching process where
each earthquake can have aftershocks, and these can have
their own aftershocks, leading to a cascade seismic pro-
cess.
In this paper we focus on two types of triggering form.
The rst one, suggested by the elastic aftereect theory,
gives for the probability density TR1(tjHt)
TR1(tjHt) =e+X
j:tj<te (t tj); (7)
where we have placed (t) =eand(t) =e t. The
second one is the ETAS model which implements the
Omori-Utsu law (t)/(t+c) 
ETAS (tjHt) =e+X
j:tj<t
(t tj+c); (8)
The parameters to t in the triggering models depend on
the functional choice of .
C. The ETASLC model
We propose to combine triggering with self-correcting
models to obtain the so-called Epidemic Type Aftershock
Sequence Long-term Correcting (ETAFLC) model.
Analytically, two terms of the conditional intensity rate
must be modied. The rst step is to set the background
seismicity(t) of the triggering models with the temporal
stress loading proposed in Eq.(7), that is
(t) =e+t(9)
while, the stress discharge mechanism after a large earth-
quake can be reasonably implemented in the functional
form of(t) simply subtracting a constant quantity ,
which represents the new parameters to be tted as in
Eqs.(4,5).
Overall, putting all this information together, employing
the exponential triggering form, the conditional rate of
the ETAFLC model can be written as:
ETAFLC 1(tjHt) =e+t+X
j:tj<t
e (t tj) 
;
(10)while, implementing the Omori-Utsu law for the trigger-
ing part
ETAFSLC 2(tjHt) =e+t+X
j:tj<t
(t tj+c) 
:
(11)
It is evident that the constant , present inside the sum,
is responsible for a correcting term proportional to the
number of earthquakes occurred up to time t, playing a
similar role ofN[0;t) in Eq.(5).
IV. LOG-LIKELIHOOD (LL) MAXIMIZATION
For asynchronous data, the likelihood for a non-
stationary Poisson process, characterized by an intensity
function(t), is
L(Yj) =NY
i=1(ti)e Rtfin
tin(t)dt(12)
whereY= (y1;:::;yN) are theNobserved data, tiis
the occurrence time of the i-th event in the time interval
[tin;tfin] and  is the parameter set.
The optimization of the parameters, for both models, is
carried out by a Maximum Likelihood Estimation (MLE)
[4, 44{46]. The parameter optimisation procedure is
carried out via a component-wise Markov-Chain-Monte-
Carlo (MCMC) procedure. The MLE algorithm used is
presented in App.A.
The model that best reproduces the data of the simu-
lated catalog is the one with the minimum AIC value.
The AIC value of a certain model is AIC = 2k 2LL,
wherekis the number of the parameters in the model.
In practice, this criterion avoids under-tting by choos-
ing the model with the highest LL, but assigns a penalty
for each additional parameter.
V. COMPARING MODEL AND SIMULATIONS
For the AROFC catalogue, the parameter estimates for
the dierent tting models are reported in Tabs.(I,II),
the set up values for the MCMC algorithm are shown
in Tab.(III) in the App.B. In Figs.(2,3,4,5,6,7) we plot
the evolution of parameters during the optimization pa-
rameter, for all the models considered. The algorithm is
carried out with 106Monte Carlo steps and it is also very
clear that the algorithm converges to a stationary value
for all parameters and all models.
We rst analyse the complete catalogue and results of
Tab.(I) clearly show that the triggering model is better
than both the self-correcting model and the stress release
model, but combining the two previous models results
in anAICETASLC 2much smaller than all the others,
moreover, both ETAS and ETASLC2 have an AIC value
smaller than corresponding model dened implementing5
an exponential triggering function. This results give us
two important information. The rst, as already well
known, is that the Omori-Utsu form is the most plausible
triggering function (t) for the description of the short
term triggering eects. This also conrms the correct im-
plementation in the physical model of the relaxation func-
tion after each event. The second, that both ETASLC1
to ETASLC2 models over-perform their respective trig-
gering models. Interestingly, if we carry out the same
study considering only the events of the numerical cat-
alog below a certain seismic moment Mmax= 1000, we
observe that the AIC values for both ETASLC models
dramatically increase becoming comparable to the trig-
gering model ETAS. This is strong evidence that events
of larger magnitude contribute to a much greater de-
crease in stress than do small events alone, in fact, the
AIC values of the triggering models remain almost un-
changed (see Tab.(II)) restricting the catalogue magni-
tude. Again, a comparison of the triggering models TR1
and ETAS shows how the Omori-Utsu functional form
is a more appropriate choice for describing short-term
seismicity. The results also conrm the recent ndings
of [28] which show a slight dependence of the recurrence
times two subsequent mainshocks. The magnitude de-
pendence is also observed by looking at the simple Self-
Correcting and Stress Release models. In fact, only in
the case in which large events are considered, we note an
improvement of the AIC for the SR model, which con-
tains precisely the information on the magnitude of the
earthquake. In the case of minor events, however, the
AIC remains almost unchanged between the two models.
VI. CONCLUSIONS
Two dierent types of models have been presented in
this article, a physical spring-block model and various
point process models. They are employed a lot in seis-
mology both for the intrinsic description of the physi-
cal phenomenon and for the practical use of statistical
forecasting. Trying to bridge the two types of models
could strengthen both sides. In particular, in this study,
a numerical catalog was produced by means of a cellular
automata algorithm from a spring-block model based on
[23]. This catalog has been tted with dierent types of
point process models. On a side, the self correcting model
and the stress release model, which take into account
that when the fault rupture the amount of strain present
around the earthquake location decreases. On the other
side, the self-exiting model, in which is implemented the
temporal clustering property of the earthquakes. In the
middle, there exist a mixing of the two previous type
of PP models, called Epidemic Type Aftershock Long-
term Correcting models. They take into account both
the short term triggering eect and the release of strain
by earthquake occurrence. In the triggering model, the
background seismicity is assumed constant, whereas for
the other models is a function of time. By means ofthe LogLikelihood maximization procedure, it is possible
to nd the best set of parameters of each model which
makes it better t the synthetic catalog.
The results of this study show that the choice of the best
statistical model is not trivial and could depend on the
minimum seismic moment at which the seismic catalog is
cut. In fact, large events are present in the catalog, it is
necessary to introduce the stress release ingredient in or-
der to better t the experimental catalog. It is important
to underline that a numerical catalog is characterized by
the absence of incompleteness. Thanks to this, it is possi-
ble to attribute this not trivial result certainly not to the
incompleteness of the experimental data, but to cluster-
ing phenomena and/or preponderant background eects.
We hope that our results will contribute to develop a new
generation PP models.
ACKNOWLEDGMENTS
This research activity has been supported by MEXT
Project for Seismology TowArd Research innovation with
Data of Earthquake (STAR-E Project), Grant Num-
ber: JPJ010217. E. Lippiello acknowledges support from
project PRIN201798CZLJ and from VALERE project of
the University of Campania \L. Vanvitelli".6
TABLE I: The parameters of the models used in this article obtained by means of Maximum Likelihood Estimation
procedure.
Model     c  AIC
Self-Correcting 6 :45 0 :11 6 :6510 4- - -  24942
Stress Release 6 :28 0 :15 1 :5510 5- - -  26202
Trigger (TR1)  8:41 - - 52 :25 - 150 :10  33004
ETAS  9:69 - - 0 :0016 6 :510 41:34  39032
ETASLC1  9:69  4428 0 :04 743 - 3035  41766
ETASLC2  9:69  4129 0 :037 1 :4710 47:1610 41:42  44290
TABLE II: The parameters of the models used in this article obtained by means of Maximum Likelihood Estimation
procedure for the numerical catalog with M1000.
Model     c  AIC
Self-Correcting 6 :74 0 :18 0 :001 - - -  24920
Stress Release 6 :06 0 :15 4 :510 5- - -  24896
Trigger (TR1)  8:20 - - 55 :73 - 157 :28  33104
ETAS  9:69 - - 0 :002 3 :610 41:26  38874
ETASLC1  9:69  4478 0 :042 1018 - 3755  39104
ETASLC2  9:69  4129 0 :038 1 :8110 44:0810 41:31  39002
Appendix A: LogLikelihood Maximization procedure
For the LL function maximization, we employ a
MCMC algorithm. Calling k=fk
igthe parameter set
for modelk, an initial value of ~k
0is chosen. Then, the
algorithm is carried out in the subsequent steps.
â€¢Computation of LL(Yjk
0).
â€¢A parameter k
iis randomly chosen and updated
following the rule k
i!k
i+i, whereiis tuned
by hand in order to obtain both a convergence
of the procedure and avoiding the Markov chain
moving very slow.
â€¢CompareLL(Yji;:::;k
i;:::) andLL(Yj~k
0). If
LL(Yji;:::;k
i;:::)>LL (Yj~k
0), thenLL(Yj~k
0) =
LL(Yji;:::;k
i;:::) and repeat the previous point.
Otherwise keep the old LL(Yj~k
0) and repeat the
previous point.
The procedure stops when it is no longer possible to nd a
likelihood value greater than the previous one. To ensure
the convergence of the algorithm, we produce a Markov
chain composed by 100000 steps.Appendix B: LogLikelihood estimation
1. SC and SR model
For the SC model, the intensity of the non-stationary
Poisson point process is Eq.(5). Then, the Likelihood
function for the Self-Correcting model can be written as
L(Yj;; ) = NY
i=1e+ti N[0;ti)!

e Rtfin
tinexp(+t N[0;t))dt(B1)
To simplify calculation, the Likelihood function is con-
verted to the Log-Likelihood (LL) function:
LL(Yj;; ) = NX
i=1+ti N[0;ti)!
 Ztfin
tine+t N[0;t)dt (B2)
In a very similar way, we can obtain the LL(Yj;; )
related to the SR model considering N[0;ti) =S[0;ti)
in the denition of . The optimized parameters are
listed in Tab.(I) whilst the MCMC dynamics for each
parameter of the model is plotted in Fig.(2,3).
2. Triggering model
As for the SC and SR models, the Log-Likelihood func-
tion for the triggering model (TR1) 7, can be written as7
Parameter Initial Value Std. Dev.
 0.1 0.1
 0.1 0.1
 0.1 0.1
Initial values and standard deviations for the SC model
parameters
Parameter Initial Value Std. Dev.
 0.1 0.1
 0.1 0.1
 0.1 0.1
Initial values and standard deviations for the SR model
parameters
Parameter Initial Value Std. Dev.
 1.0 0.1
 1.0 0.1
 1.0 0.1
Initial values and standard deviations for the TR1
model parameters
Parameter Initial Value Std. Dev.
 1.0 0.1
 0.1 0.1
 1.0 0.1
c 1.0 0.1
 1.0 0.1
Initial values and standard deviations for the ETAS
model parameters
Parameter Initial Value Std. Dev.
 1.0 0.1
 1.0 0.1
 0.1 0.1
 1.0 0.1
 1.0 0.1
Initial values and standard deviations for the STLC1
model parameters
Parameter Initial Value Std. Dev.
 1.0 0.1
 1.0 0.1
 0.1 0.1
 1.0 0.1
c 1.0 0.1
 1.0 0.1
Initial values and standard deviations for the STLC2
model parameters
TABLE III: Initial values employed for the MCMC
algorithm in all the dierent models.LL(Yj;;; ) =NX
i=1log0
@e+X
j:tj<tie (ti tj)1
A
 Ztfin
tin0
@e+X
j:tj<te (t tj)1
Adt
(B3)
Whereas, for ETAS, we obtain
LL(Yj;;; ) =NX
i=1log0
@e+X
j:tj<t
(t tj+c)1
A
 Ztfin
tin0
@e+X
j:tj<t
(t tj+c)1
Adt
(B4)
The best series ( ;; ), and (;;c; ) compatible
with the recorded data Yare the ones that maximize
the likelihood. The optimized parameters are listed in
Tab.(I).
FIG. 2: Parameters optimization for the
Self-Correcting model. Red curves (a), (b) and (c)
represents the evolution of the parameters ;; ,
respectively, during the MCMC algorithm for the
catalogue with only M1000. Black curves (d), (e)
and (f) represents the evolution of the parameter during
the MCMC algorithm for the whole numerical
catalogue.8
3. STLC model
The analytic expression of the Log-Likelihood function
for the ETASLC1 model employing the exponential trig-
gering form can be written as
LL(Yj;;; ) =
NX
i=1log2
4e+ti+X
j:tj<ti
e (ti tj) 3
5
 Ztfin
tin2
4e+t+X
j:tj<t
e (t tj) 3
5dt (B5)
Whereas, implementing the Omori-Utsu functional
form we obtain
LL(Yj;;;c; ) =
NX
i=1log2
4e+ti+X
j:tj<ti
(t tj+c) 3
5
 Ztfin
tin2
4e+t+X
j:tj<t
(t tj+c) 3
5dt(B6)
The best series ( ;;;c;; ) compatible with the
recorded data Yare the ones that maximize the likeli-
hood. The optimized parameters are listed in Tab.(I).
FIG. 3: Parameters optimization for the Stress Release
model. Red curves (a), (b) and (c) represents the
evolution of the parameter during the MCMC algorithm
for the catalogue with only M1000. Black curves
(d), (e) and (f) represents the evolution of the
parameter during the MCMC algorithm for the whole
numerical catalogue.
[1] I. Main, Is the reliable prediction of individual earth-
quakes a realistic scientic goal?, Nature , 1476 (1999).
[2] de Arcangelis L., C. Godano, G. J. R., and L. E., Sta-
tistical physics approach to earthquake occurrence and
forecasting, Physics Reports 628, 1 (2016).
[3] Y. Ogata, Journal of the American Statistical Associa-
tion83, 9 (1988).
[4] Y. Ogata, Space-time point-process models for earth-
quake occurrences, Annals of the Institute of Statistical
Mathematics 50, 379 (1998).
[5] G. Petrillo and Z. J., Bayesian earthquake forecasting
approach based on the epidemic type aftershock sequence
model, Research Square (2022).
[6] G. K. Gilbert, Earthquake forecasts introduction, Science
29, 121 (1909).
[7] W. McCann, S. Nishenko, L. Sykes, and J. Krause, Seis-
mic gaps and plate tectonics: Seismic potential for major
boundaries, Earthquake prediction and seismicity pat-
terns , 1082 (1979).
[8] S. P. Nishenko, Circum-Pacic seismic potential: 1989{
1999 (Springer, 1991).
[9] Y. Y. Kagan and D. D. Jackson, Seismic gap hypothesis:
Ten years after, Journal of Geophysical Research: Solid
Earth 96, 21419 (1991).
[10] Y. Rong, D. D. Jackson, and Y. Y. Kagan, Seismic gaps
and earthquakes, Journal of Geophysical Research: SolidEarth 108(2003).
[11] F. Mulargia, P. B. Stark, and R. J. Geller, Why is proba-
bilistic seismic hazard analysis (psha) still used?, Physics
of the Earth and Planetary Interiors 264, 63 (2017).
[12] N. Wetzler, T. Lay, E. Brodsky, and H. Kanamori, Sys-
tematic deciency of aftershocks in areas of high coseis-
mic slip for large subduction zone earthquakes, sci. adv.,
4, eaao3225 (2018).
[13] N. J. van der Elst and B. E. Shaw, Larger aftershocks
happen farther away: Nonseparability of magnitude and
spatial distributions of aftershocks, Geophysical Research
Letters 42, 5771 (2015).
[14] Z. Olami, H. J. S. Feder, and K. Christensen, Self-
organized criticality in a continuous, nonconservative cel-
lular automaton modeling earthquakes, Physical review
letters 68, 1244 (1992).
[15] R. Burridge and L. Knopo, Model and theoretical seis-
micity, Bullettin of the Seismological Society of America
, 341{371 (1967).
[16] S. Hainzl, G. Zoller, and J. Kurths, Similar power laws
for foreshock and aftershock sequences in a spring-block
model for earthquakes, Journal of Geophysical Research:
Solid Earth 104, 7243 (1999).
[17] E. Jagla, Realistic spatial and temporal earthquake dis-
tributions in a modied olami-feder-christensen model,
Physical Review E 81, 046117 (2010).9
[18] E. Jagla and A. Kolton, A mechanism for spatial and
temporal earthquake clustering, Journal of Geophysical
Research: Solid Earth 115(2010).
[19] A. Jagla, E., F. Landes, and A. Rosso, Viscoelastic eects
in avalanche dynamics: A key to earthquake statistics,
Phys. Rev. Lett. 112, 174301 (2014).
[20] X. Zhang and R. Shcherbakov, Power-law rheology con-
trols aftershock triggering and decay, Scientic reports 6,
1 (2016).
[21] J. Bar o and J. Davidsen, Universal avalanche statistics
and triggering close to failure in a mean-eld model
of rheological fracture, Physical Review E 97, 033002
(2018).
[22] E. Lippiello, G. Petrillo, F. Landes, and A. Rosso, Fault
heterogeneity and the connection between aftershocks
and afterslip, Bulletin of the Seismological Society of
America 109, 1156 (2019).
[23] G. Petrillo, E. Lippiello, F. P. Landes, and A. Rosso, The
inuence of the brittle-ductile transition zone on after-
shock and foreshock occurrence, Nature communications
11, 1 (2020).
[24] E. Lippiello, G. Petrillo, F. Landes, and A. Rosso, The
genesis of aftershocks in spring slider models, Statistical
Methods and Modeling of Seismogenesis , 131 (2021).
[25] H. Perfettini and J.-P. Avouac, Postseismic relaxation
driven by brittle creep: A possible mechanism to rec-
oncile geodetic measurements and the decay rate of af-
tershocks, application to the chi-chi earthquake, tai-
wan, Journal of Geophysical Research: Solid Earth 109
(2004).
[26] H. Perfettini and J.-P. Avouac, Modeling afterslip and af-
tershocks following the 1992 landers earthquake, Journal
of Geophysical Research: Solid Earth 112(2007).
[27] C. Godano, A. Tramelli, G. Petrillo, E. Bellucci Sessa,
and E. Lippiello, The Dependence on the Moho Depth of
FIG. 4: Parameters optimization for the TR1 model.
Red curves (a), (b) and (c) represents the evolution of
the parameter during the MCMC algorithm for the
catalogue with only M1000. Black curves (d), (e)
and (f) represents the evolution of the parameter during
the MCMC algorithm for whole numerical catalogue.the b-Value of the Gutenberg{Richter Law, Bulletin of
the Seismological Society of America (2022).
[28] G. Petrillo, A. Rosso, and E. Lippiello, Testing of the
seismic gap hypothesis in a model with realistic earth-
quake statistics, Journal of Geophysical Research: Solid
Earth 127(2022).
[29] D. Vere-Jones, On the variance properties of the stress
release model, Australian Journal of Statistics 30A, 123
(1988).
[30] D. Vere-Jones, Earthquake prediction - a statitician's
view, Journal of Physics of the Earth 26, 129 (1978).
[31] C. Lomnitz, Magnitude stability in earthquake se-
quences, Bulletin of the Seismological Society of America
56, 247 (1966).
[32] F. Schoenberg and B. Bolt, Short-term exciting, long-
term correcting models for earthquake catalogs, Bulletin
of the Seismological Society of America 90, 849 (2000).
[33] D. Vere-Jones and Y. L. Deng, A point process analysis
of historical earthquakes from north china, Earthq. Res.
China 2, 165 (1988).
[34] C. Lu, D. Harte, and M. Bebbington, A linked stress
release model for historical japanese earthquakes, Earth,
Planets and Space 51, 907 (1999).
[35] X. Zheng and D. Vere-Jones, Applications of stress re-
lease models to earthquakes from north china, Pure appl.
Geophys. 135, 559 (1991).
[36] C. G. Bufe and D. J. Varnes, Predictive modeling of
the seismic cycle of the greater san francisco bay region,
Journal of Geophysical Research: Solid Earth 98, 9871
(1993).
[37] N. Limnios, E. Papadimitriou, and G. Tsaklidis, Sta-
tistical Methods and Modeling of Seismogenesis (Wiley,
2021).
[38] V. Isham and M. Westcott, A self-correcting point pro-
cess, Stochastic Processes and their Applications 8, 335
FIG. 5: Parameters optimization for the ETAS model.
Red curves (a), (b), (c) and (d) represents the evolution
of the parameter during the MCMC algorithm for the
catalogue with only M1000. Black curves (e), (f), (g)
and (h) represents the evolution of the parameter during
the MCMC algorithm for whole numerical catalogue.10
(1979).
[39] A. G. Hawkes, Cluster models for earthquakes-regional
comparisons, Bull. Int. Stat. Inst. 45, 454 (1973).
[40] B. Epstein and C. Lomnitz, A model for the occurrence
of large earthquakes, Nature 211, 954 (1966).
[41] T. Utsu, Y. Ogata, and R. S. Matsu'ura, The centenary of
the omori formula for a decay law of aftershock activity,
Journal of Physics of the Earth 43, 1 (1995).
[42] D. Vere-Jones and T. Ozaki, Some examples of statistical
estimation applied to earthquake data - i. cyclic poisson
and self-exciting models, Ann. Inst. Statist. Math. 34,
189 (1982).
[43] Y. Ogata and H. Akaike, On linear intensity models
for mixed doubly stochastic poisson and self-exciting
point processes, Selected Papers of Hirotugu Akaike , 269
(1982).
[44] E. Lippiello, F. Giacco, L. d. Arcangelis, W. Marzocchi,
and C. Godano, Parameter estimation in the etas model:
Approximations and novel methods, Bulletin of the Seis-
mological Society of America 104, 985 (2014).
[45] I. Ogata, Estimation of the parameters in the modied
omori formula for aftershock frequencies by the max-
imum likelihood procedure, Journal of Physics of the
Earth 31, 115 (1983).
[46] Y. Ogata and J. Zhuang, Space{time etas models and an
improved extension, Tectonophysics 413, 13 (2006).
FIG. 6: Parameters optimization for the ETASLC1
model. Red curves (a), (b), (c) and (d) represents the
evolution of the parameter during the MCMC algorithm
for the catalogue with only M1000. Black curves (e),
(f), (g) and (h) represents the evolution of the
parameter during the MCMC algorithm for whole
numerical catalogue.11
FIG. 7: Parameters optimization for the ETASLC2
model. Red curves (a), (b), (c), (d) and (e) represents
the evolution of the parameter during the MCMC
algorithm for the catalogue with only M1000. Black
curves (f), (g), (h) and (i) represents the evolution of
the parameter during the MCMC algorithm for whole
numerical catalogue.