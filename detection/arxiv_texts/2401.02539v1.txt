1
Robot-Assisted Deep Venous Thrombosis
Ultrasound Examination using Virtual Fixture
Dianye Huang, Chenguang Yang, Mingchuan Zhou, Angelos Karlas, Nassir Navab, Zhongliang Jiang
Abstract —Deep Venous Thrombosis (DVT) is a common vas-
cular disease with blood clots inside deep veins, which may block
blood flow or even cause a life-threatening pulmonary embolism.
A typical exam for DVT using ultrasound (US) imaging is by
pressing the target vein until its lumen is fully compressed.
However, the compression exam is highly operator-dependent.
To alleviate intra- and inter-variations, we present a robotic US
system with a novel hybrid force motion control scheme ensuring
position and force tracking accuracy, and soft landing of the
probe onto the target surface. In addition, a path-based virtual
fixture is proposed to realize easy human-robot interaction for
repeat compression operation at the lesion location. To ensure
the biometric measurements obtained in different examinations
are comparable, the 6D scanning path is determined in a coarse-
to-fine manner using both an external RGBD camera and US
images. The RGBD camera is first used to extract a rough
scanning path on the object. Then, the segmented vascular lumen
from US images are used to optimize the scanning path to
ensure the visibility of the target object. To generate a continuous
scan path for developing virtual fixtures, an arc-length based
path fitting model considering both position and orientation is
proposed. Finally, the whole system is evaluated on a human-like
arm phantom with an uneven surface. The code1and intuitive
demonstration video2can be publicly accessed.
Note to Practitioners —Robotic ultrasound (US) systems have
attracted attention for various applications in the past decades.
However, the existing studies are not mature and intelligent
enough for some challenging applications, such as DVT exam,
which requires rich contact interaction between patients and
clinicians. To tackle with this challenge, this study presents
a novel human-centric robotic DVT exam program using the
technique of virtual fixture. The coarse-to-fine path planning
module ensures the repeatability of US acquisitions carried out
at different times. During DVT exam, the proposed continuous
6D path virtual fixture can guide clinicians to freely move the
probe along the scan path while limiting the probe motion in
other directions. In order to perform the compress-release exam,
a decoupled position/force controller is developed to precisely
generate the contact force conveyed by clinicians and to restrict
the probe motion along the probe centerline. We believe such
Corresponding author: Zhongliang Jiang
Dianye Huang, Zhongliang Jiang, and Nassir Navab are with the Chair
for Computer Aided Medical Procedures and Augmented Reality (CAMP),
Technical University of Munich (TUM), Garching, Germany (e-mail: di-
anye.huang@tum.de; zl.jiang@tum.de; nassir.navab@tum.de).
Chenguang Yang is with Bristol Robotics Laboratory, University of the
West of England, Bristol, BS16 1QY , UK (e-mail: cyang@ieee.org).
Mingchuan Zhou is with the College of Biosystems of
Engineering and Food Science, Zhejiang University, China (e-mail:
mingchuan.zhou@in.tum.de).
Angelos Karlas is with the Institute of Biological and Medical Imaging,
Helmholtz Zentrum Munchen, Neuherberg, Germany, and also the Department
for Vascular and Endovascular Surgery, rechts der Isar University Hospital,
Technical University of Munich, Germany (e-mail: angelos.karlas@tum.de).
1Code: https://github.com/dianyeHuang/RobDVTUS
2Video: https://www.youtube.com/watch?v=3xFyqU1rV8c
Fig. 1. An illustration of the DVT disease and the compression-release cycle
of the DVT US exam.
a robot-assisted system is a promising solution to take both
advantages of robots about the accuracy and repeatability and
human operators about the advanced physiological knowledge.
Index Terms —deep venous thrombosis (DVT), robotic ultra-
sound, hybrid force motion control, virtual fixture, path planning
I. I NTRODUCTION
DEEP Venous Thrombosis (DVT) disease is one of the
leading causes of postoperative morbidity and mortal-
ity [1]. It is an obstructive disease of the veins where the intra-
venous formation of blood clots may partially or completely
block the blood return to the heart (see Fig. 1) resulting in
the life-threatening pulmonary embolism [2]. DVT might be
symptomatic (e.g., with leg swelling or pain) or completely
asymptomatic, rendering its diagnosis a clinical challenge.
The gold-standard for diagnosing DVT is ultrasound (US)
imaging, for instance, the repetitive compression of the vein
at different cross-sectional positions along all the veins [2].
Even if the recording of other US-based information, such
as the intravenous color and spectral Doppler signal is also
recommended nowadays, the compression test readout is the
most useful information for the examiner. More specifically,
failure to completely compress the venous lumen until it
collapses indicates a vein thrombosis [3].
Although US imaging owns the advantages of being real-
time, non-invasive and ionizing radiation-free, it does not come
without limitations. The compression test is currently highly
operator-dependent, which limits its diagnostic accuracy andarXiv:2401.02539v1  [cs.RO]  4 Jan 20242
Fig. 2. Workflow of the robot-assisted DVT exam. Left: algorithm blocks for deriving a 6D path-based virtual fixture. Right: an illustrative guide on performing
the DVT US exam using the proposed system.
sensitivity, especially in challenging and follow-up or re-test
examinations aiming usually at quantifying the outcome of
an applied therapy (e.g., anticoagulation). Such a follow-up
control would require the conduction of the compression test
in a maximally standardized way, ideally by the same operator
in order to ensure directly and quantifiable comparability of
the actual findings with previous ones. Thus, the development
of approaches to limit the exertion of pressure to the minimum
needed in order to set the diagnosis would be useful.
To improve imaging quality and repeatability, robotic tech-
nologies have been employed by accurately controlling the
US acquisition parameters (probe orientation, contact point,
and force) [4]–[6]. Recently, various robotic US systems
(RUSS) have been developed for a wide range of clinical
applications, like autonomous screening of breast [7], lung [8],
and blood vessels [9]–[11], etc.. These systems focused on
automatizing the screening by using the US imaging feedback
or/and external RGBD cameras. To autonomously navigate
probe to standard planes, Jiang et al. presented a reward
learning framework based on a few expert demonstrations [12].
A comprehensive summary can be found in a recent article
detailing the fundamental and emerging technologies involved
in developing RUSS [13].
However, due to the characteristics that DVT compression
exams require rich interaction with the object vessel, the
robot-assisted DVT examination has not been well-researched
yet. To autonomously screen DVT, Meng et al. employed an
RGBD camera to compute the scanning path, while the diag-
nosis was purely based on the segmentation of cross-sectional
US images [14]. The missing performing compression exams
will decrease the accuracy of diagnosis results. On the con-
trary, Guerrero et al. presented a RUSS with autonomous lu-
men contour detection and an external force sensor to capture
the dynamical characters during the compression, while the
scanning locations were manually determined [3].
This work proposed a semi-autonomous DVT exam system
to assist clinicians in quantifying the level of thrombus through
a novel physical human-robot interaction (pHRI) interface
based on the virtual fixture (VF) technique. The scanning pathis autonomously determined coarse-to-fine using an RGBD
camera and US images sequentially for coarse path planning
and fine optimization. In addition, to guarantee the robot can
accurately follow the scanning path and desired force, a novel
hybrid force motion control scheme (HFMC) is developed
in which the soft landing of the US probe onto the contact
surface is taken into account. Furthermore, an arc-length scan
path fitting method is proposed to generate a continuous 6D
scanning trajectory with respect to a single variable. This
enables the further development of a 6D continuous VF, which
can assist sonographers to better perform compression exam
for the target vein. To the best of our knowledge, this is the
first RUSS targeting DVT diagnosis with an practical pHRI
to assist clinicians’ manipulation of the US probe in desired
direction (both scanning and compressing directions).
II. R ELATED WORK
A. Hybrid Force/Motion Control
Due to the safety concern for RUSS, impedance control
has been widely used to realize compliant interaction between
the probe and subjects [5], [9]. However, to accurately and
simultaneously control the contact force and pose of the
probe, impedance control requires accurate estimations of the
environment’s stiffness and damping information. To char-
acterize the varying interaction environment, Pappalardo et
al.used a simplified model to compute the interaction force
f=ke(x−xd)by considering elastic term ( keis environment
stiffness) [15]. The experimental results demonstrated that the
exact value of keis less important. The controller can still
perform well when distinct stiffness parameters are selected.
Regarding the robot-assisted US examinations, the probe
is often orientated by regulating the contact force along the
probe axis and motion for the other five degree of freedom in
Cartesian space. Thereby, the force and motion control laws
can be designed separately, and assembled using projection
matrices. To suppress force overshoot at the beginning of con-
tact establishment, Halt et al. [16] proposed a controller based
on prescribed performance control. This controller defined
hard force error constraints and thanks to the log-type barrier3
Lyapunov function [17], the control input tends to be infinite
to prevent constraint violation when the error approaches the
predefined constraints. However, due to the numerical prob-
lem in computing and the hardware limitations in practices,
the performance may decayed in real scenarios. To further
address this challenge, we proposed a velocity-based force
control law integrating the bounded barrier Lyapunov function
[18] to avoid the numerical problem, and building a contact
establishment detector to ensure a smooth transition from the
free motion space to the contact space.
B. Path Planning for US Scan
To autonomously plan a scanning path for RUSS, Huang et
al.presented a threshold-based method to extract the target of
interest using an external camera [19]. The scanning path was
computed based on the segmented surface on RGB images
by considering the full coverage. Goel et al. employed the
Bayesian optimization method to identify the vessel-rich part
of the leg to generate a scan path [20]. Jiang et al. proposed
a vision-based path planning pipeline that registers a CT
template with an annotated blood vessel to the online point
cloud streamed from an RGBD camera [21]. Then, a scanning
path for the target vessel was determined by transferring
the planned path from CT template to various volunteers.
However, for the compression exam of DVT-US exam, these
methods cannot guarantee that the US probe is placed above
the blood vessel as the external camera cannot observe the
internal patient-specific location of the target anatomical struc-
ture. Therefore, we proposed a coarse-to-fine pipeline for US
scanning path planning method that sequentially utilize the
external visual signals and the interior B-mode US images.
C. Physical Human-Robot Interaction
To fully take advantage of the physiological knowl-
edge (e.g., suitable contact force) from clinicians, a semi-
autonomous RUSS is designed to allow physical interaction by
operators. To assist the clinicians to qualitatively perform the
DVT-US compression exams, virtual fixture (VF) is employed
to restrict the robot’s workspace, which usually consists of
constraints definition, evaluation, and enforcement [22]. To
ensure safety and/or contact accuracy, VF has been widely
used in the field of surgical robotics. Feng el al. developed both
guidance and forbidden VFs for high-precise polyp dissec-
tion [23]. Li et al. constructed a protective VF from polygon
mesh representations for the skull-cutting application [24].
Regarding DVT-US examinations, the US probe should
adhere to the scanning path to generate comparable results
in various US compression exams. Thus, a 6D path virtual
fixture is expected to ease the interaction. A scan path is
often represented by a set of waypoints and orientation pairs.
To obtain a continuous path, Tan et al. fitted the waypoints
using the non-uniform rational B-spine (NURB) method [25].
However, this method is time-consuming and hard to conduct
constraint evaluation for a path VF. Therefore, in our case,
a spatially encoded curve fitting method is proposed, which
reduces the 6D scan path to a 1D manifold space to correlate
the examined cross-section with a one-dimensional variable,
thus realizing a path VF.
Fig. 3. An illustration of system setup and coordinate frames.
D. Proposed Workflow
The primary clinical indicators for the robot-assisted DVT-
US exam system include the precision of motion and force
control, and the system’s ability to position the target vein
at the central region of the acquired image. Precise control
ensures force and posture alignment with clinician intentions
during compression-release cycles. Furthermore, the system’s
optimization of the scanning path enhances the effectiveness
and repeatability of DVT US exams. Consequently, this work
focuses on the control design and the scan path determination.
The proposed robot-assisted DVT exam system’s workflow
depicted in the left side of Fig. 2 consists of four phases.
i).A coarse discrete path is first determined using external
visual signals captured from the RBG-D camera mounted at
the robot’s end-effector. By fitting the 6D discrete waypoints,
an initial continuous scan path is derived. ii).The next phase
involves performing an US sweep scan. Simultaneously, a
UNet model segments the acquired US image, enabling the
locating of the target vein in the cross-sectional view. iii).
The initial scan path is then optimized using the segmenta-
tion results. After fitting the optimized discrete scan path, a
6D path-based virtual fixture is established. iv).Finally, the
sonographers can physically interact with the robot, adhering
to the constraints imposed by the virtual fixture, to maneuver
the US probe along the optimized scan path. They can also
make adjustments to the contact forces in a smooth manner,
drawing upon their expertise and experience.
III. F ORCE MOTION CONTROL SCHEME
Developing a highly accurate force controller is important
in the context of the DVT exam. As depicted in Fig. 1, clin-
icians perform a compression-release cycle by incrementally
adjusting contact forces until one of the following conditions
is met: i) the target vein fully closes, indicating the absence of
thrombosis, or ii) the vein ceases to deform while remaining
partially open. This cycle is repeated multiple times. The pro-
posed framework aims to enhance the repeatability and utility
of the DVT exam for long-term disease monitoring, which
necessitates accurate force control. Therefore, this section
elaborates on the design of the proposed hybrid force motion
control scheme. The coordinate system is depicted in Fig. 3,
including frames of robot’s base {B}, robot’s Flange {F},
force/torque (F/T) sensor {S}, RGBD camera {C}, US probe
{P} and US image {I}. Unless otherwise stated, vectors and4
matrices are described in {B}, and the left upper script is
omitted for brevity. Three different calibrations are needed to
correlate the transformations among these frames, including:
1) Eye-in-hand calibration [26]: calibratingF
CTto trans-
form the scan path expressed from {C} to{F}.
2) F/T sensor calibration [27].: compensating for the pay-
load gravity to deriveSfcaliand calibratingP
STtwist to
obtain the contact forcePfcali=P
STtwistSfcali.
3) US probe calibration [28]: calibratingF
PTto transfer the
2D pixel location into 3D space by computingB
IT=
B
FTF
PTP
IT, where
P
IT=
0 0 −1 0
0 Lp/Wimg 0−Lp/2
Dimg/Himg 0 0 0
0 0 0 1

Lp,Dimg, and Himg×Wimg denote the footprint,
imaging depth and imaging resolution of the US probe.
A. Hybrid Force Motion Control Law
Since the force and the motion control axis are orthogonal,
we first decoupled them by projecting the tracking errors into
their respective space, and then assembled the designed two
control laws. We assume that the nonlinear gravity, Centrifugal
and Coriolis torques of the robot dynamic are fully resolved.
Thus, the hybrid force motion control law alongside Eq.
(2)∼(5) is given below:
τ=JT
−Kc
pxe−Kc
d˙ x
+N
Kq
pqe−Kq
d˙q
xe=
x−
Pmx′
d+Z
nzvfdtT
eT
oT (1)
where τis a torque-based control input, Jis the Jacobian
matrix of {P} w.r.t.{B} over the joint configuration q;
N=I7×7−JT(JT)−1projects the joint torques that try
maintaining the desired joint configuration qdinto the null
space of the Cartesian control with qe:=q−qd, and
Kq
p/Kq
dbeing the joint stiffness/damping configurations. For
the Cartesian control, Kc
p/Kc
d,x/x′
dandq/qdrepresent the
Cartesian stiffness/damping settings, current/desired position
and quaternion respectively; xedenotes the pose error where
the orientation error eo:=−B
PRvec(q∗qd)is formulated
by taking vec(·)the vector part of the transformed quaternion
difference withB
PRbeing the rotational matrix.BRpcan be
expanded as
nxnynz
where nx,ny,nz∈R3×1
andnzrepresents the force control direction. Regarding the
position error, Pm:=I3×3−nznT
zfilters the desired position
such that an updated desired position adapting along nz
is formulated to regulate the contact force. In this paper,
Kc
p=diag(1200I3×3,90I3×3),Kq
p= 1e−3I7×7, the damping
ratio is selected to be 0.8,qdequals to the initial joint
configuration before the sweep scanning.
In Eq. (1), the probe motion is regulated under the hierarchi-
cal Cartesian impedance control framework while the contact
force is controlled by adapting the velocity vf(to be designed
inSec. III-B ) along nz.
Fig. 4. A plot of force control law in Eq. (3) w.r.t.ef.
B. Velocity-based Force Control Law
As in [15] and [16], we adopted a spring model to approxi-
mate the interaction dynamics: f=ke(x−xenv)where xenv
is the boundary of the undeformed tissue, xis the current posi-
tion of the robot’s end-effector, keis the environment stiffness
term that reflects the level of resistance to the deformation. The
actual contact force f∈Ralong the probe axis is measured
by:f=nT
sB
PTtwPfcwhere ns:=
nT
z,0,0,0Tfilters the
measured torques, and the twist transformationB
PTtw∈R6×6
transforms the calibrated contact forcePfcfrom{P} to{B}.
Inspired by [16] where the force error is transformed
before being fed into the controller, in this paper, a bounded
barrier Lyapunov function [18] based error transformation is
designed to overcome the potential numerical problem. The
force tracking error efis considered as a soft constrained
variable ef=f−fdsubjected to |ef|< kc, where kc∈R+
denotes the user-defined force error constraint, fdandfdenote
the desired and actual contact forces, respectively.
Error transformation is then designed as below:
εf=|ef|knT(z)z (2)
where T(z) =khk2
s
kc1−z2
(1−k2sz2)2>0,Lim(ef,−kc, kc) :=
max(min( ef, kc),−kc),z= tanh 
khLim 
ef,−kc, kc
/kc
is an intermediate variable introduced to avoid the numerical
problem of the error transformation; knnormalizes the trans-
formed error; ksdetermines the derivative of εfw.r.t.ef. Note
that once ksis selected, knandkhin Eq. (2) remain constant
and are computed according to the following equation:
kn=1
T(ζ)ζ, kh= ln s
1 +ζ
1−ζ!
, ζ=s
3ks−p
4−3k2s
2ks
Below is the force control law in the contact space.
v′
f=−kmfεf−kfef (3)
where kmfandkfare feedback gains for the transformed force
error εfand actual force error efrespectively; v′
frepresents
the velocity command for regulating the contact force in the
contact space. Fig. 4 plots the control input of Eq. (3) w.r.t
efwhere parameters are selected empirically, kc= 0.4,ks=
0.99for the error transformation, and kmf= 0.008,kf=
0.0065 for the force control law in Eq. (3). Note that the
proposed control law smoothly transits between the nonlinear
and linear feedback gains wherein the predefined constraints
±kcserve as the transition boundaries.
C. Soft Landing Approach
In order to guarantee soft landing of US probe onto the
target surface, we designed and incorporated a low-pass filter5
into the control scheme (input: f, output: α, see Contact
Establishment Detector in Fig. 2).
˙α+f¯αkαα=kαClamp 
f, f α, f¯α
(4)
where
Clamp (f, f α, f¯α) =

0if f < f α
f if f ∈[fα, f¯α]
f¯αif f > f ¯α
Clamp (·,·,·)is introduced to clamp fwithin the predefined
limits fαandf¯α, and the contact is sensed when f > f α;kα
determines the sensitivity of the filter; α∈[0,1]serves as
a signal indicating the contact establishment. The final force
control law along the probe axis is given by:
vf=αv′
f+ (1−α)v0 (5)
where αis emerged into vfto govern the control law transition
between a predefined constant velocity v0for approaching the
scan target in free motion space and the proposed control law
v′
fin Eq. (3) for contact force regulation in the contact space.
In this paper, fα= 1.0,f¯α= 2.0,kα= 10 ,v0= 0.015.
IV. P HYSICAL HUMAN ROBOT INTERACTION INTERFACE
This section elaborates on the path planning and pHRI
strategies. As shown in Fig. 2, the discrete planned path on
the scanned surface right above the target vein is determined
in a coarse-to-fine manner using the external visual signals
and US images. The 6D discrete waypoints are then fitted
and parameterized over a one-dimensional variable s. This
enables the continuous output to serve as a motion generator
for the initial sweep scan, which captures US images for
path optimization. Additionally, it serves as a 6D path virtual
fixture for physical human-robot interaction. By correlating
the interaction forces with the change of desired contact force
ands, clinicians can smoothly adjust the imaging positions
and contact forces during the compression exams.
A. Arc-length-based 6D Path Fitting
The scan path extracted from an external camera is usually a
series of discrete waypoints and normal vectors of the contact
surface. These points and vectors are supposed to be converted
into a 6D trajectory before being fed into the HFMC. Inspired
by the arc length-dynamic movement primitive (AL-DMP)
Algorithm 1 Scan Path Fitting
Input: Scan point and normal vector pairs (P,N),
Euclidean distance threshold δp(1mm by default).
Output: Learned Fp(s),FQ(s)andsN.
1:Pnew← P Linear interpolation if∥P(i+1)−P(i)∥> δp
2:s,sN←Eq. (6).
3:Fp(s)←Eq. (8) with s,Pnew.
4:Q ←
R(i)=¯nx¯nyN(i)
,¯n′
x=Fp(s(i)+
δs/SN)−Fp(s(i)),¯ny=N(i)×¯n′
x,¯nx=¯ny×N(i)	N
i
5:Qnew← Q Slerp interpolation if∥P(i+1)− P(i)∥> δp
6:FQ(s)←Eq. (9) with (s,Qnew).Algorithm 2 Scan Path Optimization
Input: Finit
p(s),Finit
Q(s),sinit
N, scan velocity vs(m/s).
Output: Learned Fp(s),FQ(s)andsN.
1:Sets= 0,i= 0
2:repeat //sweep scan
3:xd← Finit
p(s),Qd← Finit
Q(s)
4: Eq. (1) ←Track xdandQd.
5:Iseg←Segment the US image by a UNet [21].
6:P(i)
ves←Extract center point of the blood vessel.
7: Update s←s+vs/sinit
N∆t; update i←i+ 1
8:until s≥1.0
9:P,N ← Project PvestoParm by Eq. (10).
10:Fp(s),FQ(s),sN←Alg. 1 with(P,N).
method [29], which separates the spatial and temporal compo-
nents of motion, we proposed a curve fitting model using arc-
length to remove temporal information and encode the scan
path spatially. Note that the proposed path fitting algorithm
does not mere fit the given data, but also parameterized the
6D scan path over a 1D variable. Alg. 1 summarizes the steps.
1) Accumulated Arc-Length Variable: Given a set of dis-
crete points P ∈RN×3. The normalized accumulated arc-
length variable s∈RN×1is defined as follows:
s={s(k)}, s(k)=kX
i=1∥P(k)− P(k−1)∥2/sN (6)
where s(0)= 0,sN=PN
i=1∥P(k)−P(k−1)∥2and the upper
right script (k)denotes the k-th element of the variable.
2) Curve Fitting Model: Given a set of input-output pairs
(s∈RN×1,X ∈RN×1). The one-dimensional fitting model
is designed as follows:
F(s) = ¯sX0+sXg+u(s,w) (7)
where u(s,w) =PN
i=0ψi(s)wiM(s)PN
i=0ψi(s),s∈(0,1)is a monoton-
ically increasing variable, ¯s:= 1−s,X0andXgare the first
and last sample of X,u(s,w)is a nonlinear term consisting of
weighted Truncated Gaussian Functions (TGF) [30]. Since the
AL-DMP based on arc-length suffers from not converging to a
unique attractor point, we induced M(s) =s(1−exp(−a¯s))
to overcome this issue by modulating ssuch that F(s= 0) =
x0and as s→1,F(s= 1)→xg.wdenotes a set of weights
wifor TGFs and is learned by the Local Weighted Regression
(LWR) algorithm [31].
3) Position Fitting: The position model is designed below:
Fp(s) = ¯sx0+sxg+u(s, ωp) (8)
where x0/xg∈R3×1denotes the initial/goal positions, and
ωp:={wx
p,wy
p,wz
p}is learned axis-by-axis.
4) Orientation Fitting: Unit quaternion is chosen for ori-
entation representation. Considering the geometric constraint,
the orientation fitting model FQ(s)is formulated below:
FQ(s) =exp (eQ/2)∗Qg
eQ= (1−s)eQ0+seQg+u(s, ωQ)(9)6
where ωQ:={wx
Q,wy
Q,wz
Q}is learned axis-by-axis; Q
denotes the conjugate of Q:={η, ϵ}:=η+xi+yj+zk∈ S3.
eQ= 2 log( Qg∗Q)denotes the deviation of the goal quater-
nion.eQ0/eQgdenotes the first/last sample of goal quaternion
deviation. The logarithmic and exponential operators (refer to
[32] for more details) are presented below:
r= log( Q) =(
arccos( η)ϵ
∥ϵ∥∥ϵ∥>0
[0,0,0]Totherwise
Q= exp( r) =

h
cos(∥r∥),sin(∥r∥)rT
∥r∥iT
∥r∥>0
[1,0,0,0]Totherwise
B. 6D Path-based Virtual Fixture
1) Initial Coarse Scan Path: As shown in the workflow
of Fig. 2 and the intermediate results presented in Fig. 7,
the initial scan path is planned using only visual signals. The
skeleton of the arm phantom Pis extracted and filtered after
segmenting the arm phantom in a depth image [21], [33]. The
starting and ending scan points are then determined by the two
manually attached stickers.
The initial scan path is finally obtained and fitted by Alg.
1. In this work, h= 3.0,θ= 3.5for all TFGs . The number
of kernels for Fp(s)andFQ(s)are empirically set to be 41
and81respectively, balancing the computational burden and
fitting performance.
2) Optimized Scan Path: Alg. 2 summarizes the steps of
path optimization. The initial scan path Finit
p(s)andFinit
Q(s)
serve as a motion generator guiding the robot to acquire US
images. Then the center point of the examined blood vessel
P(i)
vesis extracted by segmenting the blood vessel and detecting
the contour where idenotes the i-th US image. The initial
center point of the examined blood vessel P(0)
vesis selected
manually. The nearest center point in the next US image is
connected sequentially, such that the blood vessel center line
Pvesis obtained. Finally, Pvesis projected to the surface of
the point cloud vertically w.r.t.{B} to get updated PandN:
P(i)= arg min
P(i)∈ParmNv(P(i)
ves− Parm)2
(10)
where Parm represents the point cloud of the arm phantom;
P(i)/P(i)
vesdenote the i-th sample of P/Pves,Nv=I3×3−
nzbnT
zb,nzbis the z-axis of {B}.
3) Path Virtual Fixture: To develop a path VF for guidance,
e.g., avoiding large positional and/or rotational deviation from
the optimized scanning path, a continuous trajectory ( Fp(s),
FQ(s)) is required. Thanks to the proposed arc-length-based
path fitting algorithm, the path VF assisting clinicians freely
moving the probe along the determined scan path can be
easily realized by correlating the interaction force with the
1D accumulated arc-length variable s.
˙s=k−1
piDzone
Lim(Pfx
i, fx
i, fx
i), dx
s=LimZ
˙sdt,0,1(11)
wherePfx
i=Pfx
est−Pfx
mdenotes the interaction force
limited by the predefined upper and lower constraints fx
i,fx
i.Pfx
mandPfx
estrepresent the contact forces in {P} along x-
axis measured by the F/T sensor and estimated by the joint
torque sensors, respectively. Dzone(·,·)defined by the dead-
zone dis introduced to suppress the disturbances such that
pHRI is only activated when |f|> d.kpidetermines the
sensitivity to the interaction force.
Dzone (f, dx) =

0, if |f| ≤dx
f−dx, if f > dx
f+dx, if f < −dx
A similar interaction paradigm is applied to adjust the desired
contact forces along the z-axis of {P} as follows:
˙fd=k−1
fiDz
Lim(Pfz
est−Pfz
m, fz
i, fz
i), dz
fd=LimZ
˙fddt, f min, fmax(12)
V. E XPERIMENTAL RESULTS
As shown in Fig. 3, the proposed RUSS for DVT exam con-
sists of a redundant robotic manipulator (Franka Emika Panda,
Franka GmbH), an RGBD camera (Intel®Realsense™ D435),
a 6-axis F/T sensor (GAMMA, SI-32-2.5/SI-65-5, ATI), a US
machine (ACUSON Juniper, SIEMENS AG), a commercial
arm phantom (BPA304, Blue Phantom GmbH), and a foot
pedal for switching the operator’s interaction intention ( i.e.,
foot pedal pressed: change desired contact force; foot pedal
released: change the US imaging position along the scan
path). The Franka robot is controlled via the Robot Oper-
ating System (ROS) framework, running on a laptop (AMD
Ryzen 9 5900HX CPU, NVIDIA GeForce RTX 3070) with
Ubuntu 20.04 system. The B-mode US images are captured
from the US machine via a frame grabber (MAGEWELL)
at a frequency of 30 Hz. The scanning workspace of
the proposed RUSS is 400mm×500mm×300mm
(width×length×height) with a maximum allowable contact
force limit of 15.0Nand a maximum automatic scanning
speed set at 30mm/s .
A. Force Control Performance
To demonstrate the superiority of the proposed method, the
robot manipulator is commanded to perform a sweep scan on
Fig. 5. Comparison results of the US sweep scan performance.7
/uni00000013 /uni00000014/uni00000013 /uni00000015/uni00000013 /uni00000016/uni00000013 /uni00000017/uni00000013 /uni00000018/uni00000013 /uni00000019/uni00000013
/uni00000037/uni0000004c/uni00000050/uni00000048/uni00000003/uni0000000b/uni00000056/uni0000000c/uni00000013/uni00000015/uni00000017/uni00000019/uni0000001b/uni00000014/uni00000013/uni00000014/uni00000015/uni00000026/uni00000052/uni00000051/uni00000057/uni00000044/uni00000046/uni00000057/uni00000003/uni00000049/uni00000052/uni00000055/uni00000046/uni00000048/uni00000056/uni00000003/uni0000000b/uni00000031/uni0000000c
/uni00000046/uni00000052/uni00000050/uni00000053/uni00000044/uni00000055/uni0000004c/uni00000056/uni00000052/uni00000051/uni00000003/uni0000004e/uni00000020/uni00000013/uni00000011/uni00000013/uni00000013/uni00000018
/uni00000046/uni00000052/uni00000050/uni00000053/uni00000044/uni00000055/uni0000004c/uni00000056/uni00000052/uni00000051/uni00000003/uni0000004e/uni00000020/uni00000013/uni00000011/uni00000013/uni00000014/uni00000018/uni00000053/uni00000055/uni00000052/uni00000053/uni00000052/uni00000056/uni00000048/uni00000047
/uni00000016/uni00000031 /uni00000019/uni00000031 /uni00000014/uni00000015/uni00000031
/uni00000053/uni00000055/uni00000052/uni00000053/uni00000052/uni00000056/uni00000048/uni00000047/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000028/uni00000055/uni00000055/uni00000052/uni00000055/uni00000056/uni00000003/uni0000000b/uni00000031/uni0000000c
/uni00000016/uni00000031 /uni00000019/uni00000031 /uni00000014/uni00000015/uni00000031
/uni0000004e/uni00000003/uni00000020/uni00000003/uni00000013/uni00000011/uni00000013/uni00000013/uni00000018/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013
/uni00000016/uni00000031 /uni00000019/uni00000031 /uni00000014/uni00000015/uni00000031
/uni0000004e/uni00000003/uni00000020/uni00000003/uni00000013/uni00000011/uni00000013/uni00000014/uni00000018/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013
(a) sweep scan under 5mm/s
/uni00000013/uni00000011/uni00000013 /uni00000015/uni00000011/uni00000018 /uni00000018/uni00000011/uni00000013 /uni0000001a/uni00000011/uni00000018 /uni00000014/uni00000013/uni00000011/uni00000013 /uni00000014/uni00000015/uni00000011/uni00000018 /uni00000014/uni00000018/uni00000011/uni00000013 /uni00000014/uni0000001a/uni00000011/uni00000018 /uni00000015/uni00000013/uni00000011/uni00000013
/uni00000037/uni0000004c/uni00000050/uni00000048/uni00000003/uni0000000b/uni00000056/uni0000000c/uni00000013/uni00000015/uni00000017/uni00000019/uni0000001b/uni00000014/uni00000013/uni00000014/uni00000015/uni00000026/uni00000052/uni00000051/uni00000057/uni00000044/uni00000046/uni00000057/uni00000003/uni00000049/uni00000052/uni00000055/uni00000046/uni00000048/uni00000056/uni00000003/uni0000000b/uni00000031/uni0000000c
/uni00000046/uni00000052/uni00000050/uni00000053/uni00000044/uni00000055/uni0000004c/uni00000056/uni00000052/uni00000051/uni00000003/uni0000004e/uni00000020/uni00000013/uni00000011/uni00000013/uni00000013/uni00000018
/uni00000046/uni00000052/uni00000050/uni00000053/uni00000044/uni00000055/uni0000004c/uni00000056/uni00000052/uni00000051/uni00000003/uni0000004e/uni00000020/uni00000013/uni00000011/uni00000013/uni00000014/uni00000018/uni00000053/uni00000055/uni00000052/uni00000053/uni00000052/uni00000056/uni00000048/uni00000047
/uni00000016/uni00000031 /uni00000019/uni00000031 /uni00000014/uni00000015/uni00000031
/uni00000053/uni00000055/uni00000052/uni00000053/uni00000052/uni00000056/uni00000048/uni00000047/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000028/uni00000055/uni00000055/uni00000052/uni00000055/uni00000056/uni00000003/uni0000000b/uni00000031/uni0000000c
/uni00000016/uni00000031 /uni00000019/uni00000031 /uni00000014/uni00000015/uni00000031
/uni0000004e/uni00000003/uni00000020/uni00000003/uni00000013/uni00000011/uni00000013/uni00000013/uni00000018/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013
/uni00000016/uni00000031 /uni00000019/uni00000031 /uni00000014/uni00000015/uni00000031
/uni0000004e/uni00000003/uni00000020/uni00000003/uni00000013/uni00000011/uni00000013/uni00000014/uni00000018/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013 (b) sweep scan under 15mm/s
/uni00000013 /uni00000015 /uni00000017 /uni00000019 /uni0000001b /uni00000014/uni00000013
/uni00000037/uni0000004c/uni00000050/uni00000048/uni00000003/uni0000000b/uni00000056/uni0000000c/uni00000013/uni00000015/uni00000017/uni00000019/uni0000001b/uni00000014/uni00000013/uni00000014/uni00000015/uni00000026/uni00000052/uni00000051/uni00000057/uni00000044/uni00000046/uni00000057/uni00000003/uni00000049/uni00000052/uni00000055/uni00000046/uni00000048/uni00000056/uni00000003/uni0000000b/uni00000031/uni0000000c
/uni00000046/uni00000052/uni00000050/uni00000053/uni00000044/uni00000055/uni0000004c/uni00000056/uni00000052/uni00000051/uni00000003/uni0000004e/uni00000020/uni00000013/uni00000011/uni00000013/uni00000013/uni00000018
/uni00000046/uni00000052/uni00000050/uni00000053/uni00000044/uni00000055/uni0000004c/uni00000056/uni00000052/uni00000051/uni00000003/uni0000004e/uni00000020/uni00000013/uni00000011/uni00000013/uni00000014/uni00000018/uni00000053/uni00000055/uni00000052/uni00000053/uni00000052/uni00000056/uni00000048/uni00000047
/uni00000016/uni00000031 /uni00000019/uni00000031 /uni00000014/uni00000015/uni00000031
/uni00000053/uni00000055/uni00000052/uni00000053/uni00000052/uni00000056/uni00000048/uni00000047/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000028/uni00000055/uni00000055/uni00000052/uni00000055/uni00000056/uni00000003/uni0000000b/uni00000031/uni0000000c
/uni00000016/uni00000031 /uni00000019/uni00000031 /uni00000014/uni00000015/uni00000031
/uni0000004e/uni00000003/uni00000020/uni00000003/uni00000013/uni00000011/uni00000013/uni00000013/uni00000018/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013
/uni00000016/uni00000031 /uni00000019/uni00000031 /uni00000014/uni00000015/uni00000031
/uni0000004e/uni00000003/uni00000020/uni00000003/uni00000013/uni00000011/uni00000013/uni00000014/uni00000018/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013 (c) sweep scan under 30mm/s
Fig. 6. Results for sweep scan force control performance under different scan velocities and desired contact forces. The grey shading areas indicate the time
interval after contact establishment. The second row shows violin plots of absolute force control errors in the grey shading areas.
(a) intermediate results for path planning
 (b) center point’s horizontal deviation
Fig. 7. Results for the coarse-to-fine path planning strategy (see Section IV-B and Alg. 2 for more details). (a) Signals flowchart and intermediate results. 1⃝.
The initial 2D scan path is derived by extracting the skeleton from the arm phantom mask, which is obtained through thresholding the depth image. 2⃝. The
starting and ending points of the scan path are identified using color stickers detected from the color image. 3⃝. By estimating the normal vectors from the
point cloud data and transforming the 2D pixels into 3D scan positions, an initial discrete scan path is generated. 4⃝&5⃝. The optimized scan path is then
obtained by projecting the longitudinally distributed center points of the target vein onto the arm phantom’s point cloud using Alg. 2. (b) Horizontal deviation
of the examined vein’s center point from the solid green line in the US image when tracking along the initial and optimized paths.
a human-like arm phantom at a velocity of 15mm/s while
maintaining a desired contact force of 6N. We compared
the proposed method with the “Impedance Controller” from
[34] and the log-BLF-based “Constrained Controller” from
[16]. For the “Impedance Controller”, the stiffness in the
probe imaging direction is 100, and the stiffness of the other
dimensions is set to be the same values of the proposed method
for fair comparison. The penetration offset of the scan path is
6mm. In the case of the “Constrained Controller”, the con-
straint kcis0.4Nfor a fair comparison. From Fig. 5, we can
observe that “Impedance Controller” performs the worst. This
result can be attributed to the varying stiffness of the phantom,
as well as inaccuracies in skin surface extraction. These
inaccuracies stem from the US gel covering the phantom and
errors in hand-eye calibration. Consequently, the conventional
“Impedance Controller” exhibited significant tracking errors
during time intervals of 3.0s∼6.0sand11.0s∼13.0s.
In the case of “Constrained Controller”, we deliberately clip
the tracking error to the range of (−0.38,0.38)Nduring the
implementation to ensure safety and the feasibility condition
mentioned in [35]. As a result, the “Constrained Controller”had a longer settling time and larger tracking errors, as evident
in the violin plot at the bottom right of Fig. 5.
To further demonstrate the advantage of the proposed error
transformation, we compared the force control performance
of the proposed control law [Eq. (3)] with that of a linear
feedback-only approach, denoted as v′
f(cmp)=k efand re-
ferred to as the “Fundamental Controller”. Two different feed-
back gains are considered empirically: k={0.005,0.015}
with which the absolute force control errors stay within 1N
through out the sweep scans (see the violin plots in Fig. 6]).
Sweep scans are conducted on an arm phantom with an uneven
surface, varying the desired contact forces {3,6,12}Nand
desired velocities {5,15,30}mm/s .
The violin plots in Fig. 6 demonstrate the impacts of
varying desired contact force and scan velocity. It can be found
that the mean and maximum force errors increase when the
scan velocity increases. This observation can be explained
intuitively: a faster scan velocity will result in relatively
dramatic changes in contact force due to the uneven constraint
surface. In addition, the results demonstrated that the changes
of desired force would not significantly affect the controller’s8
performance. We consider this is because the US gel can
effectively limit the friction between probe and contact surface
during scans. From Fig. 6 (a), we can see that the comparison
controller with lower gain values k= 0.005 has comparable
performance in terms of mean errors of around 0.045Nat
v= 5mm/s . However, as the scan velocity increase the mean
errors increase to around 0.20N[see Fig. 6 (c)]. The average
settling time of the comparison controller k= 0.005 (0.70s)
is larger than the comparison controller k= 0.015(0.40s) and
the Proposed Controller ( 0.35s). The transient response of the
comparison controller k= 0.015 exhibited large overshoots
when v= 5mm/s ,fd= 3Nandv= 15mm/s ,fd= 6N.
To strike a balance between settling time and overshoot,
the proposed control law [see depicted in Fig. 4] allows users
to adjust the control hyperparameters (i.e., kcandksin Eq.
(2)), to realize a smooth transition between the two control
gains. The nonlinearity of the proposed control law achieves
soft-regulation at the expense of reduced sensitivity to the
disturbances within the error constraints ±kc. Although large
tracking errors [see Fig. 6 (c), fd= 12 N] were observed
when the tracking error is less than kc(0.4N), these errors
were effectively suppressed to less than 0.6Nonce the tracking
error exceeded ±kc. Additionally, comparing the oscillations
during the time periods of 11∼16s,fd= 3Nin Fig. 6
(b) and 7∼9s,fd= 3Nin Fig. 6 (c), the “Proposed
Controller” shows less oscillation and tracking error. There-
fore, the proposed control law exhibits the least settling time
(0.35s) during the contact establishment, and the maximum
tracking errors remain less than 0.6Nacross all combinations
of desired contact forces and scan velocities. Considering the
force accuracy and response time, we consider the proposed
force control suitable for US scanning on soft tissues.
B. Robot-Assisted DVT-US Examination
The DVT-US exam is performed using our proposed work-
flow. In this experiment, we evaluated the effectiveness of
the derived scan path virtual fixture and the tracking perfor-
mance when collaborating with clinicians. As depicted on the
right-hand side of Fig. 2, once the optimized scan path is
acquired, clinicians will maneuver the US probe along this
path. They will pause and execute a compression-release cycle
when observing a suspicious area. This procedure is repeated
multiple times until the entire target vein has been thoroughly
scanned. Accordingly, as presented in Fig. 8, the US probe is
maneuvered along a path virtual fixture marked separately by
1⃝,2⃝,3⃝,4⃝to reach three consecutive positions: a,b, and
c, to perform the compression-release cycle.
1) Scan Path Planning Results: The intermediate results
of the scan path planning module in a representative setup
have been demonstrated in Fig. 7 (a). The coarse-to-fine path
planning processes were consecutively carried out based on
RGB-D images and US images, respectively. The initial and
optimized paths are visualized in Fig. 7 (a). To ensure the tar-
get vessel in the US view throughout the screening, the vein’s
centroid was computed in real-time based on the segmented
binary masks. The deviation between the computed centroid
and the image’s horizontal center has been calculated. In this
Fig. 8. An illustration of the robot-assisted DVT-US exam settings. The
compression-release cycle will be executed at positions indicated by the blue
points.
TABLE I
STATISTICS OF FORCE TRACKING RESULTS (MEAN ±STD)
Controllers ferror (N) in Fig. 9 ferror (N) in Fig. 10
Proposed 0.099±0.079 0.35±0.20
Constrained 0.128±0.111 0.52±0.28
Fundamental 0.435±0.269 1.01±0.68
settings, we consider that the scanning speed and contact force
in a reasonable range will not result in significant difference
in path accuracy. To quantitatively assess the performance
variations, the deviation results obtained using initial and
optimized paths are depicted in Fig. 7 (b).
When tracking with the initial path, notable deviations
are observed (e.g., 12.5mm,7.9mm,4.0mm,2.1mm
deviations at the 0-th,50-th,100-th and 150-th frames). This is
because the location of the target vein does not align precisely
with the extracted skeleton line from RGB-D images [see Fig.
7 (a)]. After the US image-based fine path adjustment, the
centroid of the target vein can be much stably maintained
in the horizontal middle of the US images [see the first
two rows in Fig. 7 (b)]. It can be seen that the optimized
path results in stable deviations ( 0.8±0.4mm) across the
acquisitions than the ones obtained using the initial path
(7.1±3.4mm). Furthermore, the maximum deviation is
also much smaller ( 1.7mm vs12.5mm). Nevertheless, the
results still demonstrate that the optimized path can effectively
maintain the target vein in the center of the image view,
which is important for providing quantitative and repeatable
diagnosis in various examinations.
2) Physical Human-Robot Interaction Results: The pro-
posed pHRI module allows clinicians to freely move the
probe forward and backward along the optimized scanning
path using a 6-DOF path VF. In the meantime, clinicians can
perform compression exams for DVT at suspicious locations
by triggering the foot pedal. The probe’s motion was limited
to 1-DOF (probe centerline) direction in this process. To
evaluate the performance of the path VF and the tracking of
varying contact forces, the validations were carried out on an
arm phantom with an uneven surface. After positioning the
probe on the phantom’s surface, operators can only maneuver
the probe along the optimized scan path with the constraint
applied by the proposed path VF. The target position and force,
conveyed by the operator, are updated at 50Hz.
Fig. 9 presents comparison results of the tracking perfor-
mance during the physical interaction under the control of the
“Proposed Controller”, the “Constrained Controller”, and the
“Fundamental Controller”. The clinicians continuously moved
the probe along the scan path between different sections [see9
Fig. 9. Comparison results of the tracking performance of the VF-guided human-centric US probe motion. The grey shading areas represent the moving of
the US probe.
Fig. 10. Comparison results of the tracking performance of the VF-guided human-centric US motion for compression exam at varying imaging locations.
The grey, red and green shading areas denote the moving of the probe, the compression and the release tests, respectively. (first row: red and blue lines denote
desired and actual forces)
the Path VF in Fig. 8]. The grey shading areas correspond
to the continuous movement applied by clinicians, which
is constrained by the proposed path VF. Throughout the
VF-guided US probe movement, the “Proposed Controller”
consistently maintains the absolute force control error less than
0.36N(compared with 0.52Nfor “Constrained Controller”
and1.02Nfor the “Fundamental Controller”) with the least
tracking error [see Table I]. Considering the task of diagnosing
DVT, clinicians will select a few locations on the scanning path
to do compression examinations. The results for a representa-
tive experiment with three compression tests [see the blue dots
in Fig. 8] are presented in Fig. 10. At each location, clinicians
will manually repeat the compression-release cycle twice (red
and green shading areas). In this context, the “Proposed
Controller” still has the least force tracking error [see Table I]
and its maximum tracking error is 1.05N(compared with
1.62Nfor the “Constrained Controller”, 2.33Nfor the
“Fundamental Controller”). The path VF tracking performance
is shown in the second and third rows of Figs. 9 and 10. For
the compression-release cycle test in Fig. 10, we can observe
that all the controllers share similar orientation tracking errors,while the proposed behaves the best in terms of tracking
deviation ( 0.41±0.27mm). These findings lead to the
conclusion that the proposed pHRI framework can effectively
constrain the US probe to the optimized scan path during
physical interaction and the proposed controller can guarantee
higher force and motion tracking accuracy.
VI. D ISCUSSION
There is limited prior research that directly addresses robotic
scanning tasks or provides solutions seamlessly integrated into
a robotic US system for DVT US exam. To the best of our
knowledge, this is the first work that incorporates clinician
protocols into the robot-assisted system for the DVT US exam.
The coarse-to-fine scan path determination strategy effectively
leverages external visual signals as prior information, combin-
ing them with internal US images to optimize the scan path.
The proposed 6D-path fitting method eliminates the temporal
information and allows users to configure arbitrary constant
scan velocity on a curve scan path. Furthermore, the fitting
result is a 6D-path virtual fixture over the arc-length variable
s. These advantages collectively contribute to developing a10
robotic system that assists clinicians in more precisely locating
the target vein and revisiting suspicious regions.
In the context of clinical use, there is a need to expand the
capabilities of the robotic system to address imaging quality
and vein deformation detection. A potential risk factor arises
from the variability in maximum contact forces, which differs
from patient to patient. To mitigate this risk, the robotic system
would benefit from an integrated module capable of detect-
ing deformation and automatically adjusting the maximum
allowable forces to prevent harm to the patient. Besides, there
are still some practical challenges to be addressed, such as
patient’s motions [21], [36], and force-induced deformation
[37]–[39]. Future work of the proposed robotic system for the
DVT US exam will focus on improving US image quality and
enhancing patient safety.
VII. C ONCLUSION
This work presents a novel semi-autonomous DVT robotic
US exam system. The proposed HFMC enables the accurate
control of the probe to simultaneously follow both target
motion and contact force commands. Besides, the proposed
coarse-to-fine path planning method can stably maintain the
centroid of the target vein in the horizontal middle of the US
images. During the compression exam, the proposed pHRI can
assist the operators in adhering the probe to the optimized scan
path and performing the compression-release test at the current
imaging position. The experimental results demonstrated that
operators can freely move the probe along the scanning direc-
tion while the RUSS can maintain the contact force and path
following performance dynamically. We believe such a semi-
autonomous system with shared autonomy with clinicians is
a promising solution to take both advantages of robots about
the accuracy and repeatability and human operators about the
advanced physiological knowledge. In the future, more tests
on real patients are required to further analyze the clinical
constraints and advantages.
REFERENCES
[1] V . Kakkar, “Prevention of venous thrombosis and pulmonary embolism,”
The American journal of cardiology , vol. 65, no. 6, pp. C50–C54, 1990.
[2] B. Kassa ¨ı, J.-P. Boissel, M. Cucherat, S. Sonie, N. R. Shah, and
A. Leizorovicz, “A systematic review of the accuracy of ultrasound
in the diagnosis of deep venous thrombosis in asymptomatic patients,”
Thrombosis and haemostasis , vol. 91, no. 04, pp. 655–666, 2004.
[3] J. Guerrero, S. Salcudean, J. McEwen, B. Masri, and S. Nicolaou, “Deep
venous thrombosis screening system using numerical measures,” in Pro-
ceedings of the 25th Annual International Conference of the IEEE En-
gineering in Medicine and Biology Society (IEEE Cat. No.03CH37439) ,
vol. 1, 2003, pp. 894–897 V ol.1.
[4] Z. Jiang, M. Grimm, M. Zhou, J. Esteban, W. Simson, G. Zahnd, and
N. Navab, “Automatic normal positioning of robotic ultrasound probe
based only on confidence map optimization and force measurement,”
IEEE RAL , vol. 5, no. 2, pp. 1342–1349, 2020.
[5] M. W. Gilbertson and B. W. Anthony, “Force and position control system
for freehand ultrasound,” IEEE Transactions on Robotics , vol. 31, no. 4,
pp. 835–849, 2015.
[6] Z. Jiang, M. Grimm, M. Zhou, Y . Hu, J. Esteban, and N. Navab,
“Automatic force-based probe positioning for precise robotic ultrasound
acquisition,” IEEE Transactions on Industrial Electronics , vol. 68,
no. 11, pp. 11 200–11 211, 2020.
[7] M. K. Welleweerd, A. G. de Groot, V . Groenhuis, F. J. Siepel, and
S. Stramigioli, “Out-of-plane corrections for autonomous robotic breast
ultrasound acquisitions,” in 2021 IEEE International Conference on
Robotics and Automation (ICRA) . IEEE, 2021, pp. 12 515–12 521.[8] X. Ma, Z. Zhang, and H. K. Zhang, “Autonomous scanning target
localization for robotic lung ultrasound imaging,” in 2021 IEEE/RSJ
International Conference on Intelligent Robots and Systems (IROS) .
IEEE, 2021, pp. 9467–9474.
[9] Z. Jiang, Z. Li, M. Grimm, M. Zhou, M. Esposito, W. Wein, W. Stechele,
T. Wendler, and N. Navab, “Autonomous robotic screening of tubular
structures based only on real-time ultrasound imaging feedback,” IEEE
TIE, vol. 69, no. 7, pp. 7064–7075, 2021.
[10] D. Huang, Y . Bi, N. Navab, and Z. Jiang, “Motion magnification in
robotic sonography: enabling pulsation-aware artery segmentation,” in
2023 IEEE/RSJ International Conference on Intelligent Robots and
Systems (IROS) . IEEE, 2023, pp. 6565–6570.
[11] Z. Jiang, F. Duelmer, and N. Navab, “Dopus-net: Quality-aware robotic
ultrasound imaging based on doppler signal,” IEEE Transactions on
Automation Science and Engineering , 2023.
[12] Z. Jiang, Y . Bi, M. Zhou, Y . Hu, M. Burke et al. , “Intelligent robotic
sonographer: Mutual information-based disentangled reward learning
from few demonstrations,” The International Journal of Robotics Re-
search , 2023.
[13] Z. Jiang, S. E. Salcudean, and N. Navab, “Robotic ultrasound imaging:
State-of-the-art and future perspectives,” Medical image analysis , p.
102878, 2023.
[14] B. Meng and J. Liu, “Robotic ultrasound scanning for deep venous
thrombosis detection using rgb-d sensor,” in 2015 IEEE International
Conference on Cyber Technology in Automation, Control, and Intelligent
Systems (CYBER) , 2015, pp. 482–486.
[15] T. Gold, A. V ¨olz, and K. Graichen, “Model predictive interaction control
for robotic manipulation tasks,” IEEE Transactions on Robotics , pp. 1–
14, 2022.
[16] L. Halt, F. Pan, P. Tenbrock, A. Pott, and T. Seel, “A transferable force
controller based on prescribed performance for contact establishment in
robotic assembly tasks,” in 2019 IEEE 15th International Conference
on Automation Science and Engineering (CASE) , 2019, pp. 830–835.
[17] Y . Wu and X.-J. Xie, “Robust adaptive control for state-constrained
nonlinear systems with input saturation and unknown control direction,”
IEEE Transactions on Systems, Man, and Cybernetics: Systems , vol. 51,
no. 2, pp. 1192–1202, 2021.
[18] C. Yang, D. Huang, W. He, and L. Cheng, “Neural control of robot
manipulators with trajectory tracking constraints and input saturation,”
IEEE Transactions on Neural Networks and Learning Systems , vol. 32,
no. 9, pp. 4231–4242, 2021.
[19] Q. Huang, J. Lan, and X. Li, “Robotic arm based automatic ultrasound
scanning for three-dimensional imaging,” IEEE Transactions on Indus-
trial Informatics , vol. 15, no. 2, pp. 1173–1182, 2019.
[20] R. Goel, F. Abhimanyu, K. Patel, J. Galeotti, and H. Choset, “Au-
tonomous ultrasound scanning using bayesian optimization and hybrid
force control,” in 2022 International Conference on Robotics and
Automation (ICRA) , 2022, pp. 8396–8402.
[21] Z. Jiang, Y . Gao, L. Xie, and N. Navab, “Towards autonomous atlas-
based ultrasound acquisitions in presence of articulated motion,” IEEE
Robotics and Automation Letters , vol. 7, no. 3, pp. 7423–7430, 2022.
[22] S. A. Bowyer, B. L. Davies, and F. R. y Baena, “Active con-
straints/virtual fixtures: A survey,” IEEE Transactions on Robotics ,
vol. 30, no. 1, pp. 138–157, 2013.
[23] J. Feng, X. Li, X. Xiao, B. Ouyang, and J. Fang, “Virtual fixtures assis-
tance for safe polyp dissection in minimally invasive robotic surgery,” in
2021 5th International Conference on Automation, Control and Robots
(ICACR) , 2021, pp. 150–155.
[24] Z. Li, A. Gordon, T. Looi, J. Drake, C. Forrest, and R. H. Taylor,
“Anatomical mesh-based virtual fixtures for surgical robots,” in 2020
IEEE/RSJ International Conference on Intelligent Robots and Systems
(IROS) , 2020, pp. 3267–3273.
[25] J. Tan, Y . Li, B. Li, Y . Leng, J. Peng, J. Wu, B. Luo, X. Chen, Y . Rong,
and C. Fu, “Automatic generation of autonomous ultrasound scanning
trajectory based on 3d point cloud,” IEEE Transactions on Medical
Robotics and Bionics , pp. 1–1, 2022.
[26] R. Tsai and R. Lenz, “A new technique for fully autonomous and effi-
cient 3d robotics hand/eye calibration,” IEEE Transactions on Robotics
and Automation , vol. 5, no. 3, pp. 345–358, 1989.
[27] L.-J. Zhang, R.-Q. Hu, and W.-M. Yi, “Research on force sensing for
the end-load of industrial robot based on a 6-axis force/torque sensor,”
Acta Autom. Sin , vol. 43, pp. 439–447, 2017.
[28] Z. Jiang, N. Danis, Y . Bi, M. Zhou, M. Kroenke, T. Wendler, and
N. Navab, “Precise repositioning of robotic ultrasound: Improving
registration-based motion compensation using ultrasound confidence
optimization,” IEEE Transactions on Instrumentation and Measurement ,
vol. 71, pp. 1–11, 2022.11
[29] T. Ga ˇspar, B. Nemec, J. Morimoto, and A. Ude, “Skill learning and ac-
tion recognition by arc-length dynamic movement primitives,” Robotics
and Autonomous Systems , vol. 100, pp. 225–235, 2018.
[30] R. Wang, Y . Wu, W. L. Chan, and K. P. Tee, “Dynamic movement
primitives plus: For enhanced reproduction quality and efficient tra-
jectory modification using truncated kernels and local biases,” in 2016
IEEE/RSJ International Conference on Intelligent Robots and Systems
(IROS) , 2016, pp. 3765–3771.
[31] C. G. Atkeson, A. W. Moore, and S. Schaal, “Locally weighted learn-
ing,” Lazy learning , pp. 11–73, 1997.
[32] L. Koutras and Z. Doulgeri, “A correct formulation for the orientation
dynamic movement primitives for robot control in the cartesian space,”
inProceedings of the Conference on Robot Learning , ser. Proceedings of
Machine Learning Research, L. P. Kaelbling, D. Kragic, and K. Sugiura,
Eds., vol. 100. PMLR, 30 Oct–01 Nov 2020, pp. 293–302.
[33] T. Lee, R. Kashyap, and C. Chu, “Building skeleton models via 3-d
medial surface axis thinning algorithms,” CVGIP: Graphical Models
and Image Processing , vol. 56, no. 6, pp. 462–478, 1994.
[34] M. Dyck, A. Sachtler, J. Klodmann, and A. Albu-Sch ¨affer, “Impedance
control on arbitrary surfaces for ultrasound scanning using discrete
differential geometry,” IEEE Robotics and Automation Letters , vol. 7,
no. 3, pp. 7738–7746, 2022.
[35] Y . Cao, Y . Song, and C. Wen, “Practical tracking control of perturbed
uncertain nonaffine systems with full state constraints,” Automatica , vol.
110, p. 108608, 2019.
[36] Z. Jiang, H. Wang, Z. Li, M. Grimm, M. Zhou, U. Eck, S. V . Brecht,
T. C. Lueth, T. Wendler, and N. Navab, “Motion-aware robotic 3d
ultrasound,” in 2021 IEEE International Conference on Robotics and
Automation (ICRA) . IEEE, 2021, pp. 12 494–12 500.
[37] F. Abhimanyu, A. L. Orekhov, J. Galeotti, and H. Choset, “Unsupervised
deformable image registration for respiratory motion compensation in
ultrasound images,” arXiv preprint arXiv:2306.13332 , 2023.
[38] Z. Jiang, Y . Zhou, Y . Bi, M. Zhou, T. Wendler, and N. Navab,
“Deformation-aware robotic 3d ultrasound,” IEEE Robotics and Automa-
tion Letters , vol. 6, no. 4, pp. 7675–7682, 2021.
[39] Z. Jiang, Y . Zhou, D. Cao, and N. Navab, “Defcor-net: Physics-aware
ultrasound deformation correction,” Medical Image Analysis , vol. 90, p.
102923, 2023.
Dianye Huang (Student Member, IEEE) received
his B.Eng. degree in automation and the M.Sc.
degree in control science and engineering from the
School of Automation Science and Engineering,
South China University of Technology, Guangzhou,
China, in 2017 and 2020, respectively. He was
a junior researcher with the JiHua Lab, Foshan,
China.
He is currently pursuing his doctoral degree in
computer science at the Chair for Computer Aided
Medical Procedures (CAMP) at the Technical Uni-
versity of Munich, Germany. His research interests include intelligent control,
human-robot interaction, robot learning and robotic ultrasound.
Chenguang Yang (Senior Member, IEEE) received
the Ph.D. degree in control engineering from the Na-
tional University of Singapore, Singapore, in 2010.
He took the postdoctoral training in human robotics
from the Imperial College London, London, U.K.
His research interest lies in human robot interaction
and intelligent system design.
Dr. Yang was the recipient of U.K. EPSRC UKRI
Innovation Fellowship and individual EU Marie
Curie International Incoming Fellowship. As the
lead author, he was also the recipient of IEEE
Transactions on Robotics Best Paper Award in 2012 and IEEE Transactions on
Neural Networks and Learning Systems Outstanding Paper Award in 2022. He
is the Co-Chair of IEEE Technical Committee on Collaborative Automation
for Flexible Manufacturing and the Co-Chair of IEEE Technical Committee
on Bio-mechatronics and Biorobotics Systems.
Mingchuan Zhou (Member, IEEE) received the
Ph.D. degree in computer science from the Technical
University of Munich, Munich, Germany, in 2020.
He was a Visiting Scholar with the Laboratory for
Computational Sensing and Robotics, Johns Hopkins
University, Baltimore, MD, USA, in 2019. He held a
joint post-doctoral position at the Institute of Biolog-
ical and Medical Imaging (IBMI), Helmholtz Center
Munich, Oberschleißheim, Germany, and the Chair
for Computer Aided Medical Procedures Augmented
Reality (CAMP), Technical University of Munich,
from 2019 to 2021. He is currently an Assistant Professor with Zhejiang
University, Hangzhou, China, where he is leading multiscale robotic manipu-
lation laboratory for agriculture. His research interests include the autonomous
system, agricultural robotics, medical robotics, and image processing.
Angelos Karlas (Member, IEEE) studied Medicine
(M.D.) and Electrical and Computer Engineering
(Dipl.-Ing.) at the Aristotle University of Thessa-
loniki, Greece. He holds a Master of Science in
Medical Informatics (M.Sc.) from the same univer-
sity and a Master of Research (M.Res., DIC) in
Medical Robotics and Image-Guided Interventions
from Imperial College London, UK. He is currently
working as clinical resident at the Department for
Vascular and Endovascular Surgery at the ‘rechts
der Isar’ University Hospital in Munich, Germany.
He is also the ‘Tenure-Track’ Group Leader of the interdisciplinary Clinical
Bioengineering Group at the Helmholtz Center Munich, Germany. He com-
pleted his Ph.D. (Dr. rer. nat.) in Experimental Medicine at the Technical
University of Munich, Germany. His main research interests are in the areas
of vasometabolic and optoacoustic imaging/sensing, AI-based biomarkers as
well as imageguided vascular interventions.
Nassir Navab (Fellow, IEEE) received the Ph.D.
degree in computer and automation from INRIA,
Paris, France, and the University of Paris XI, Paris,
in 1993. He is currently a Full Professor and
the Director of the Laboratory for Computer-Aided
Medical Procedures, Technical University of Mu-
nich, Munich, Germany, and an Adjunct Professor
at Johns Hopkins University, Baltimore, MD, USA.
He has also secondary faculty appointments with
the both affiliated Medical Schools. He enjoyed two
years of a Post-Doctoral Fellowship with the MIT
Media Laboratory, Cambridge, MA, USA, before joining Siemens Corporate
Research (SCR), Princeton, NJ, USA, in 1994. He has authored hundreds of
peer-reviewed scientific articles, with more than 54 400 citations and enjoy
an H-index of 104 as of August 11, 2022. He has authored more than 30
awarded papers, including 11 at the International Conference on Medical
Image Computing and Computer Assisted Intervention (MICCAI), five at
the International Conference on Information Processing in Computer-Assisted
Interventions (IPCAI), and three at the IEEE International Symposium on
Mixed and Augmented Reality (ISMAR). He is the Inventor of 50 granted
U.S. patents and more than 50 International ones.
Dr. Navab is a fellow of the Academy of Europe, MICCAI, and Asia-Pacific
Artificial Intelligence Association (AAIA). He was a Distinguished Member
and was a recipient of the Siemens Inventor of the Year Award in 2001 at
SCR, the SMIT Society Technology Award in 2010 for the introduction of
Camera Augmented Mobile C-arm and Freehand SPECT technologies, and
the “10 Years Lasting Impact Award” of the IEEE ISMAR in 2015.
Zhongliang Jiang (Member, IEEE) received the
M.Eng. degree in Mechanical Engineering from the
Harbin Institute of Technology, Shenzhen, China,
in 2017, and Ph.D. degree in computer science
from the Technical University of Munich, Munich,
Germany, in 2022. From January 2017 to July 2018,
he worked as a research assistant in the Shenzhen
Institutes of Advanced Technology (SIAT) of the
Chinese Academy of Science (CAS), Shenzhen,
China.
He is currently a senior research scientist at the
Chair for Computer Aided Medical Procedures (CAMP) at the Technical
University of Munich. His research interests include medical robotics, robot
learning, human-robot interaction, and robotic ultrasound.