CFG2VEC: Hierarchical Graph Neural Network for
Cross-Architectural Software Reverse Engineering
Shih-Yuan Yu1, Yonatan Gizachew Achamyeleh1, Chonghan Wang1, Anton Kocheturov2, Patrick Eisen2,
Mohammad Abdullah Al Faruque1
1Dept. of Electrical Engineering and Computer Science, University of California, Irvine, CA, USA
fshihyuay, yachamye, chonghaw, alfaruqu g@uci.edu
2Siemens Technology, Princeton, NJ, USA, fanton.kocheturov, patrick.eisen g@siemens.com
Abstract ‚ÄîMission-critical embedded software is critical to
our society‚Äôs infrastructure but can be subject to new security
vulnerabilities as technology advances. When security issues
arise, Reverse Engineers (REs) use Software Reverse Engineering
(SRE) tools to analyze vulnerable binaries. However, existing tools
have limited support, and REs undergo a time-consuming, costly,
and error-prone process that requires experience and expertise
to understand the behaviors of software and vulnerabilities. To
improve these tools, we propose cfg2vec , a Hierarchical Graph
Neural Network (GNN) based approach. To represent binary, we
propose a novel Graph-of-Graph (GoG) representation, combining
the information of control-Ô¨Çow and function-call graphs. Our
cfg2vec learns how to represent each binary function compiled
from various CPU architectures, utilizing hierarchical GNN and
the siamese network-based supervised learning architecture. We
evaluate cfg2vec ‚Äôs capability of predicting function names from
stripped binaries. Our results show that cfg2vec outperforms the
state-of-the-art by 24.54% in predicting function names and can
even achieve 51.84% better given more training data. Addition-
ally, cfg2vec consistently outperforms the state-of-the-art for all
CPU architectures, while the baseline requires multiple training
to achieve similar performance. More importantly, our results
demonstrate that our cfg2vec could tackle binaries built from
unseen CPU architectures, thus indicating that our approach
can generalize the learned knowledge. Lastly, we demonstrate its
practicability by implementing it as a Ghidra plugin used during
resolving DARPA Assured MicroPatching (AMP) challenges.
Index Terms ‚ÄîSoftware Reverse Engineering; Binary Analysis;
Cross-Architecture; Machine Learning; Graph Neural Network;
I. I NTRODUCTION
In mission-critical systems, embedded software is vital in
manipulating physical processes and executing missions that
could pose risks to human operators. Recently, the Internet of
Things (IoT) has created a market valued at 19 trillion dollars
and drastically grown the number of connected devices to
approximately 35 billion in 2025 [1]‚Äì[3]. However, while IoT
brings technological growth, it unintendedly exposes mission-
critical systems to novel vulnerabilities [4]‚Äì[6]. The reported
This material is based upon work supported by the Defense Advanced
Research Projects Agency (DARPA) and Naval Information Warfare Center
PaciÔ¨Åc (NIWC PaciÔ¨Åc) under Contract Number N66001-20-C-4024 The
views, opinions, and/or Ô¨Åndings expressed are those of the author(s) and
should not be interpreted as representing the ofÔ¨Åcial views or policies of
the Department of Defense or the U.S. Government.
Distribution Statement ‚ÄùA‚Äù (Approved for Public Release, Distribution
Unlimited).number of IoT cyberattacks increased by 300% in 2019 [7],
while the discovered software vulnerabilities rose from 1.6k to
100k [8]. The consequence can be detrimental, as indicated in
[9], the Heartbleed bug [10] can lead to a leakage of up to 64K
memory, threatening not only personal but also organizational
information security. Besides, Shellshock is a bash command-
line interface shell bug, but it has existed for 30 years and
remains a threat to enterprises today [11], [12]. For mission-
critical systems, unexpected disruptions can incur millions of
dollars even if they only last for a few hours or minutes [13].
As a result, timely analyzing these impacted software and
patching vulnerabilities becomes critical.
Fig. 1. Legacy software life cycle.
However, mission-critical systems usually use software that
can last for decades due to the criticality of the missions.
Over time, these systems become legacy, and the number
of newly-discovered threats can increase (as illustrated in
Figure 1). Typically, for legacy software, the original devel-
opment environment, maintenance support, or source code
might no longer exist. To address vulnerabilities, vendors offer
patches in the form of source code changes based on the
current software version (e.g., ver 0.9). However, the only
available data in the legacy system is binary based on its
source code (e.g., ver 0.1). Such a version gap poses challenges
in applying patches to the legacy binaries, leaving the only
solution for applying patches to legacy software as direct
binary analysis. Today, as Figure 2 shows, Reverse Engineers
(REs) have to leverage Software Reverse Engineering (SRE)arXiv:2301.02723v1  [cs.SE]  6 Jan 2023tools such as Ghidra [14], HexRays [15], and radare2 [16]
to Ô¨Årst disassemble and decompile binaries into higher-level
representations (e.g., C or C++). Typically, these tools take
the debugging information, strings, and the symbol-table and
binary to reconstruct function names and variable names,
allowing REs to rebuild a software‚Äôs structure and functionality
without access to source code [17]. For REs, these symbols
encode the context of the source code and provide invaluable
information that could help them to understand the program‚Äôs
logic as they work to patch vulnerable binaries. However, sym-
bols are often excluded for optimizing the binary‚Äôs footprint
in mission-critical legacy systems where memory is limited.
Because recovering symbols from stripped binaries is not
straightforward, most decompilers assign meaningless symbol
names to coding elements. As for understanding the software
semantics, REs have to leverage their experience and expertise
to consume the information and then interpret the semantics
of each coding element.
Recent works tackle these challenges with Machine Learn-
ing(ML), aiming to recover the program‚Äôs information from
raw binaries. For example, [18], and [19] associate code fea-
tures to function names and model the relationships between
such code features and the corresponding source-level infor-
mation (variable names in [19], variable & function names
in [18]). Meanwhile, [20] and [21] use an encoder-decoder
network structure to predict function names from stripped
binary functions based on instruction sequences and control
Ô¨Çows. However, none of them support cross-architectural
debug information reconstruction. On the other side, there
exist works focusing on the cross-platform in their ML mod-
els [22]‚Äì[24]. These works focus on modeling the binary code
similarity, extracting a real-valued vector from each control-
Ô¨Çow graph (CFG) with attributed features, and then computing
theStructural Similarity between the feature vectors of binary
functions built from different CPU architectures.
In this paper, as part of a multi-industry-academia joint
initiative between Siemens, the Johns Hopkins University
Applied Physics Laboratory (JHU/APL), BAE Systems (BAE),
and UCI, we propose cfg2vec , which utilizes a hierarchical
Graph Neural Network (GNN) for reconstructing the name
of each binary function, aiming to develop the capacity for
quick patching of legacy binaries in mission-critical systems.
Our Cfg2vec forms a Graph-of-Graph (GoG) representation,
combining CFG and FCG to model the relationship between
binary functions‚Äô representation and their semantic names.
Besides, cfg2vec can tackle cross-architectural binaries thanks
to the design of Siamese-based network architecture, as shown
in Figure 3. One crucial use case of cross-architectural de-
compilation is patching , where the goal is to identify a known
vulnerability or a bug and apply a patch. However, there can be
architecture gaps when software with a bug can be compiled
into many devices with diverse hardware architectures. For
example, it is challenging to patch a stripped binary from an
exotic embedded architecture compiled ten years ago that is
vulnerable to a known attack such as Heartbleed [10]. While
the reference patch is available in software, the referencearchitecture may not be readily available or documented, or
the vendor may no longer exist. Under such circumstances,
mapping code features across architectures is very helpful.
It would allow for identifying similarities in code between a
stripped binary that is vulnerable and its reference patch, even
if the patch were built for a different type of CPU architecture.
Forcfg2vec , our targeted contributions are as follows:
We propose representing binary functions in Graph-of-
Graph (GoG) and demonstrate its usefulness in recon-
structing function names from stripped binaries.
We propose a novel methodology, cfg2vec that uses a
hierarchical Graph Neural Network (GNN) to model
control-Ô¨Çow and function-calling relations in binaries.
We propose using cross-architectural loss when training,
allowing cfg2vec to capture the architecture-agnostic rep-
resentations of binaries.
We release cfg2vec in a GitHub repository: https://github.
com/AICPS/mindsight cfg2vec.
We integrate our cfg2vec into an experimental Ghidra plu-
gin, assisting the realistic scenarios of patching DARPA
Assured MicroPatching (AMP) challenge binaries.
The paper is structured as follows: Section II discusses
related works and fundamentals to provide a better under-
standing of the paper. Section III describes cfg2vec , includ-
ing problem formulation, data preprocessing, and our main
pipeline introduction. Section IV shows our experimental
results. Lastly, we conclude the paper in Section V.
II. R ELATED WORK
This section introduces software reverse engineering back-
grounds, discusses the related works using machine learning
to improve reverse engineering, and ultimately covers graph
learning for binary analysis.
A. Software Reverse Engineering
Software Reverse Engineering (SRE) aims at understanding
the behavior of a program without having access to its source
code, often being used in many applications such as detecting
malware [25], [26], discovering vulnerabilities, and patching
bugs in legacy software [27], [28]. One primary tool that
Reverse Engineers (REs) use to inspect programs is disassem-
bler which translates a binary into low-level assembly code.
Examples of such tools include GNU Binutils‚Äô objdump [29],
IDA [15], Binary Ninja [30], and Hopper [31]. However, even
with these tools, reasoning at the assembly level still requires
considerable cognitive effort from RE experts.
More recently, REs use decompilers such as Hex-Rays [32],
orGhidra [14] to reverse the compiling process by further
translating the output of disassemblers into the code that
ensembles high-level programming languages such as C or
C++ to reduce the burden of understanding assembly code.
From assembly instructions, these decompilers can use pro-
gram analysis and heuristics to reconstruct variables, types,
functions, and control Ô¨Çow structure of a binary. However,
the decompilation is incomplete even if these decompilers
generate a higher-level output for better code understanding.Fig. 2. The RE Ô¨Çow to solve security issues.
The reason is that the compilation process discards the source-
level information and lowers its abstraction level in exchange
for a smaller footprint size, faster execution time, or even
security considerations. The source-level information such as
comments, variable names, function names, and idiomatic
structure can be essential for understanding a program but is
typically unavailable in the output of these decompilers.
As Figure 2 demonstrated, REs use disassemblers or de-
compilers to generate high-level source code. Besides, [33]
indicates REs will take notes and grant a name to those
critical functions related to the vulnerabilities. This will create
an annotated source code based on the high-level machine-
generated source code. While annotating the source code, REs
also analyze the signiÔ¨Åcant part related to the vulnerability
and ignore those general instructions or unrelated codes. At
the same time, understanding the logic Ô¨Çow among functions
is another major task they must focus on resolving their
tasks. After classiÔ¨Åcation, annotation, and understanding, REs
experiment with several viable remedies to Ô¨Ånd the correct
patch to Ô¨Åx the vulnerability.
B. Machine Learning for Reverse Engineering
Software binary analysis is a straightforward Ô¨Årst step to
enhance security as developers usually deploy software in
binaries [34]. Usually, experts conduct the patching process
or vulnerability analysis by understanding the compilation
source, function signatures, and variable information. How-
ever, after the compilation, such information is usually stripped
or confuscated deliberately (e.g., obfuscation ). Software binary
analysis becomes more challenging in this case as developers
have to recover the source-level information based on their
experience and expertise. The early recovery work for binaries
focuses on manual completion but suffers from low efÔ¨Åciency,
high cost, and the error-prone nature of reverse engineering.
AsMachine Learning (ML) has signiÔ¨Åcantly advanced in its
reasoning capability, applying ML and reconstructing higher-
level source code information as an alternative to manual-
based approaches has attracted considerable research attention.
For example, [35] was the Ô¨Årst approach that used neural
network-based and graph-based models, predicting the func-
tion types to assist the reverse engineer in understanding
the binary. [36] also predicted function names with neural
networks, aggregating the related features of sections of bi-
nary vectors. Then, it analyzes the connections between each
function in the source code (e.g., Java) and their corresponding
function names for function name prediction. [18], on the otherhand, did not use a neural network. It combined a decision-
tree-based classiÔ¨Åcation algorithm and a structured prediction
with a probabilistic graphical model, then matched the func-
tion name by analyzing symbol names, types, and locations.
However, [18] can only predict from a predetermined closed
set, incapable of generalizing to new names.
As the languages for naming functions are similar to nat-
ural language, recent research works start leaning toward the
use of Natural Language Processing (NLP) [20], [21], [37].
Precisely, these models predict semantic tokens based on the
function names in the library, comprising the function name
during inference. The underlying premise is that each token
corresponds in some way to the attributes and functionality of
the function. [20] uses Control-Flow Graph (CFG) to predict
function names. It combined static analysis with LSTM and
transformer neural model to realize the name of functions.
However, the dataset that consisted of unbalanced data and in-
sufÔ¨Åcient features was limited and hindered utter performance.
[37] was designed to solve the limitation of the dataset. It
provided UbuntuDataset that contained more than 9 million
functions in 22K software. [21] demonstrated the framework‚Äôs
effectiveness by building a large dataset. It considers the
Ô¨Åne-grained sequence and structure information of assembly
code when modeling and realizing function name prediction.
Meanwhile, [21] reduced the diversity of data (instructions or
words) while keeping the basic semantics unchanged, similar
to word stemming and semantics in NLP. However, these
works have low precision scores for prediction tasks, exampled
by [21], only achieving around 41% in correctly predicting
the function name subtokens. Moreover, the metrics for the
inference of unknown functions are substantially lower [21],
making it difÔ¨Åcult for REs to Ô¨Ånd it helpful in practice.
Although many existing works can reconstruct source-
level information, none of them supports reconstructing cross-
platform debug information. Cross-compilation is becoming
more popular in the development of software. Hardware
manufacturers, for instance, often reuse the same Ô¨Årmware
code base across several devices running on various archi-
tectures [38]. A tool that performs cross-architecture function
name prediction/matching would be beneÔ¨Åcial if we have a
stripped binary compiled for one architecture and a binary
of a comparable program compiled for another architecture
with debug symbols. We may use the binary with the debug
symbols to predict the names of functions in the stripped
binary, which signiÔ¨Åcantly aids debugging. A tool that could
capture the architecture-agnostic characteristics of binarieswould also help in malware detection as the source code of
malware can be compiled in different architectures [38], [39].
Comparing two binaries of different architectures becomes
more complicated because they will have different instruction
sets, calling conventions, register sets, etc. Furthermore, as-
sembly instructions from different architectures cannot often
be compared directly due to the slightly different behavior of
different architectures [40]. Cross-architecture function name
prediction will assist in Ô¨Ånding a malicious function in a
program compiled for different architectures by learning its
features from a binary compiled for just one architecture. The
tools mentioned above are not architecture-agnostic; thus, we
cannot utilize them for such applications. To address the Ô¨Çaws
mentioned above, aid in creating more efÔ¨Åcient decompilers,
and make reverse engineering more accessible, we propose
cfg2vec . Incorporating the cross-architectural siamese network
architecture, our cfg2vec can learn to extract robust features
that encompass platform-independent features, enhancing the
state-of-the-art by achieving function name reconstruction
across cross-architectural binaries.
C. Graph Learning for Binary Analysis
Graph learning has become a practical approach across
Ô¨Åelds [41]‚Äì[44]. Although conventional ML can effectively
capture the features hidden in Euclidean data, such as images,
text, or videos, our work focuses more on the application
where the core data is graph-structured. Graphs can be ir-
regular, and a graph may contain a variable size of unordered
nodes; moreover, nodes can have a varying number of neigh-
boring nodes, making deep learning mathematical operations
(e.g., 2D Convolution) challenging to apply. The operations in
conventional ML methods can only be applied by projecting
non-Euclidean data into low-dimensional embedding space.
In graph learning, Graph Embeddings (GE) can transform a
graph into a vector (embedding of a graph) or a set of vectors
(embedding of nodes or edges) while preserving the relevant
and structural information about the graph [41]. Graph Neural
Network (GNN) is a model aiming at addressing graph-related
tasks in an end-to-end manner, where the main idea is to
generate a node‚Äôs representation by aggregating its representa-
tion and the representations of its neighbors [42]. GNN stacks
multiple graph convolution layers, graph pooling layers, and a
graph readout to generate a low-dimensional graph embedding
from high-dimensional graph-structured data.
In software binary analysis, many approaches use Control-
Flow Graphs (CFGs) as the primary representations. For
example, Genius forms an Attributed Control-Flow Graph
(ACFG) representation for each binary function by extracting
the raw attributes from each Basic Block (BB), a straight-line
code sequence with no branching in or out except at the entry
and exit, in an ACFG [22]. Genius measures the similarity
of a pair of ACFGs through a bipartite graph matching algo-
rithm, and the ACFGs are then clustered based on similarity.
Genius leverages a codebook for retrieving the embedding
of an ACFG based on similarity. Another approach, Gemini ,
proposes a deep neural network-based model along with aSiamese architecture for modeling binary similarities with
greater efÔ¨Åciency and accuracy than other state-of-the-art mod-
els of the time [23]. Gemini takes in a pair of ACFGs extracted
from raw binary functions generated from known vulnerability
in code and then embeds them with a shared Structure2vec
model in their network architecture. Once embedded, Gemini
trains its model with a loss function that calculates the cosine
similarities between two embedded representations. Gemini
outperforms models like Genius or other approaches such as
bipartite graph matching. In literature, there exist other works
that consider the Function Call Graph (FCG) as their primary
data structures in binary analysis for malware detection [45].
Ourcfg2vec extracts relevant platform-independent features by
combining the usage of CFG and FCG, resulting in a Graph-
of-Graph (GoG) representation for cross-architectural high-
level information reconstruction tasks (e.g., function name).
III. CFG2VEC A RCHITECTURE
This section begins with problem formulation. Next, as
Figure 4 shows, we depict how our cfg2vec extracts the Graph-
of-Graph (GoG) representation from each software binary.
Lastly, we describe the network architecture in cfg2vec .
A. Problem Formulation
In our work, given a binary code, denoted as p, compiled
from different CPU architectures, we extract a graph-of-graph
(GoG) representation, G= (V;A)where Vis the set of
nodes and Ais the adjacency matrix (As Figure 3 shows). The
nodes in Vrepresent functions and the edges in Aindicate
their cross-referencing relationships. That says, each of the
nodefi2Vis a CFG, and we denote it as fi= (B;A; )
where the nodes in Brepresent the basic blocks and the edges
inAdenote their dependency relationships. is a mapping
function that maps each basic block in the assembly form to
its corresponding extracted attributes (vi) =Ckwhere C is a
numeric value, and k is the number of attributes for the basic
block (BB). Whereas the CFG structure is meant to provide
more information at the lower BB level, the GoG structure
is intended for recovering information at the overarching
function level between the CFGs. Figure 3 is an example of
a partial GoG structure with a closer inspection of one of its
CFG nodes and another of a single CFG BB node, showing
the set of features corresponding to that BB node. The goal is
to design an efÔ¨Åcient and effective graph embedding technique
that can be used for reconstructing the function names for each
functionfi2V.
B. Ghidra Data ToolKit for Graph Extraction
To extract the structured representation required for cfg2vec
we leverage the state-of-the-art decompiler Ghidra [14] and
theGhidra Headless Analyzer1. The headless analyzer is a
command-line version of Ghidra allowing users to perform
many tasks (such as analyzing a binary Ô¨Åle) supported by
Ghidra via a command-line interface. For extracting GoG
1Documentation of Ghidra Headless Analyzer : https://ghidra.re/ghidra
docs/analyzeHeadlessREADME.htmlFig. 3. An example of a Graph-of-Graph (GoG) of a binary compiled from a package Freecell with amd64 CPU architecture.
from a binary, we developed our Ghidra Data Toolkit (GDT);
GDT is a set of Java-based metadata extraction scripts used
for instrumenting Ghidra Headless Analyzer . First, GDT pro-
grammatically analyzes the given executable Ô¨Åle and stores the
extracted information in the internal Ghidra database. Ghidra
provides a set of APIs to access the database and retrieve the
information about the analyzed binary. GDT uses these APIs to
export information such as Ghirda‚Äôs PCode and call graph for
each function. SpeciÔ¨Åcally, the FunctionManager API allows
us to manipulate the information of each decompiled function
in the binary and acquire the cross-calling dependencies be-
tween functions. For each function, we utilized another Ghidra
API DecompInterface2to extract 12 attributes associated with
each basic block in a function. These attributes precisely corre-
spond to the total number of instructions, including arithmetic,
logic, transfer, call, data transfer, SSA, compare, and pointer
instructions, as well as other instructions not falling within
those categories and the total number of constants and strings
within that BB. Lastly, by integrating all of the information, we
form a GoG representation Gfor each binary p. We repeat this
process until all binaries are converted to the GoG structure.
We feed the resulting GoG representations to our model in
batches, with the batch size denoted as B.
C. Hierarchical Graph Neural Network
Once Gis extracted from the GDT, we then feed it to
our hierarchical network architecture (inspired from [46]) that
contains both CFG Graph Embedding layer and GoG Graph
Embedding Layer as Figure 4 shows. For each GoG structure,
we denote it as G= (V;A)where Vis a set of functions
associated with GandAindicates the calling relationships
between the functions in V. Each function in Vis in the form
of CFGfi= (B;A; )where each node b2Bis a BB
represented in a Ô¨Åxed-length attributed vector b2Rd, andd
is the dimension that we have mentioned earlier. Aencodes
the pair-wise control-Ô¨Çow dependency relationships between
these BBs.
1) CFG Graph Embedding Layer: Our network architec-
ture Ô¨Årst feeds all functions in a batch of GoGs to the
CFG Graph Embedding Layer consisting of multiple graph
2Documentation of Ghidra API DecompInterface : https://ghidra.re/ghidra
docs/api/ghidra/app/decompiler/DecompInterface.htmlconvolutional layers and a graph readout operations. The input
to this layer is a function fi= (B;A; )and the output is the
Ô¨Åxed-dimensional vector representing a function. For each BB
bkwe letb0
k=bk, and we update bt
ktobt+1
kwith the graph
convolution operation shown as follows:
bt+1
k=fG(Wbt
k+X
bm2AkMbt
m)
wherefGis a non-linear activation function such as ReLU,
Akis the list of adjacent BBs for bk, andW2Rddand
M2Rddare the weights to be learned during the training.
We runTiterations of such a convolution, which can be a
tunable hyperparameter in our model. During the updates, each
BB gradually aggregates the global information of the control-
Ô¨Çow dependency relations into its representation, utilizing the
representation of its neighbor. We obtain the Ô¨Ånal represen-
tation for each BB as bT
k. To acquire the representation for
the function fi, we apply a graph readout operation such as
sum-readout , described as follows,
g(T)=X
bk2BbT
k (1)
We assign the value of g(T)(a.k.a. CFG embedding) to fi. The
graph readout operation can be replaced with mean-readout or
max-readout .
2) GoG Graph Embedding Layer: Once all the functions
have been converted to Ô¨Åxed-length graph embeddings, we
then feed Gto the second layer of cfg2vec , the GoG Embed-
ding Layer . Here, for each function fiwe apply another L
iterations of graph convolution with FandC. The updates
can be illustrated as follows,
f(l+1)
k=fGoG(Ufl
k+X
fm2CkVf(l)
m) (2)
wherefGoG is a non-linear activation function and Ckis the
list of adjacent functions (calling) for the function fkandU2
RddandV2Rddare the weights to be learned during the
training. Lastly, we take the f(L)
kas the representation that
considers both CFG and GoG graph structures. We use these
updated representations to perform cross-architecture function
similarity learning.Fig. 4. The architecture of cfg2vec with a supervised hierarchical graph neural network approach.
3) Siamese-based Cross-Architectural Function Similarity:
Given a batch of GoGs B=fGoG 1;GoG 2;:::;GoG Bg,
we apply the hierarchical graph neural network to acquire
the set of updated function embeddings, denoted as BF=
ff(T)
1;f(T)
2;:::;f(T)
Kg. We calculate the function similarity
for each function pair with cosine similarity, denoted as
^y2[ 1;1]. The loss function Jbetween ^Yand a ground-
truth labely, which indicates whether a pair of functions have
the same function or not, is calculated as follows,
J(^y;y) =
1 y; if y=1,
MAX (0;^y m);if y=-1,(3)
the Ô¨Ånal loss Lis then calculated as follows,
L=H(Y;^Y) =X
i(J( ^yi;yi)); (4)
whereYstands for ground-truth labels (either similarity or
dissimilarity), and ^Yrepresents the corresponding predictions.
More speciÔ¨Åcally, we denote a pair of functions as simi-
lar if they are the same but compiled with different CPU
architectures. The mis a constant to prevent the learned
embeddings from becoming distorted (by default, 0:5). To
maintain the balance between positive and negative training
samples, we developed a custom batching algorithm. The
function leverages the knowledge gained by adding a binary
of some package to a given batch to Ô¨Ånd and add a binary
for the same package, built for a different architecture, to the
provided batch as a positive sample. It will also include a
binary from another package as a negative sample. This will
give any batch a balanced proportion of positive and negative
samples. Finally, we use the loss Lto update all the associated
weights in our neural networks with an Adam optimizer. Once
trained, we then use the model to perform function name
reconstruction tasks.
IV. E XPERIMENTAL RESULTS
In this section, we evaluate cfg2vec ‚Äôs capability in predicting
function names. We Ô¨Årst describe the dataset preparation and
the training setup processes. Then, we present the comparison
ofcfg2vec against baseline in predicting function names.
Although many baseline candidates tackle the same prob-
lem [18], [20], [21], [37], some require purchasing a paid
version of IDA Pro to preprocess datasets, and some even do
not open source their implementations. Therefore, [18] was
the only feasible choice, as running other models using ourdatasets was almost impossible. Next, we also show the result
of the ablation study over cfg2vec . Besides, we exhibit that
ourcfg2vec can perform architecture-agnostic prediction better
than the baseline. Lastly, we illustrate the real-world use case
where our cfg2vec is integrated as a Ghidra plugin applica-
tion for assisting in resolving challenging reverse engineering
tasks. We conducted all experiments on a server equipped with
Intel Core i7-7820X CPU @3.60GHz with 16GB RAM and
two NVIDIA GeForce GTX Titan Xp GPUs.
A. Dataset Preparation
Our evaluating data source is the ALLSTAR ( Assembled
Labeled Library for Static Analysis Research ) dataset, hosted
byApplied Physics Laboratory (APL) [47]. It has over 30,000
Debian Jessie packages pre-built from i386 ,amd64 ,ARM,
MIPS ,PPC, and s390x CPU architectures for software
reverse engineering research. The authors used a modiÔ¨Åed
Dockcross script in docker to build each package for each
supported architecture. Then, they saved each resulting ELF
with its symbols, the corresponding source code, header Ô¨Åles,
intermediate Ô¨Åles (.o, .class, .gkd, .gimple), system headers,
and system libraries altogether.
To form our datasets, we selected the packages that have
ELF binaries built for the amd64 ,armel ,i386 , and
mipsel CPU architectures. i386 andamd64 are widely
used by general computers, especially in the Intel and AMD
products, respectively. MIPS andARM are crucial in em-
bedded systems, smartphones, and other portable electronic
devices [48]. In practice, we excluded the packages with only
one CPU architecture in the ALLSTAR dataset. Additionally,
due to our limited local computing resources, we eliminated
packages that were too large to handle. We checked each
selected binary on whether the ground-truth symbol infor-
mation exists using the Ghidra decompiler and Linux file
command and removed the ones that do not have them. Lastly,
we assembled our primary dataset, called the AS-4cpu-30k-bin
dataset, that consists of 27572 pre-built binaries from 1117
packages and 4 CPU architectures, as illustrated in Table I.
Our preliminary experiment revealed that the evaluation
had a data leakage issue when splitting the dataset randomly.
Therefore, we performed a non-random variant train-test split
with a 4-to-1 ratio on the AS-4cpu-30k-bin dataset, selecting
roughly 80% of the binaries for the training dataset and
leaving the rest for the testing dataset. We referenced [23]
for their splitting methods, aiming to ensure that the binariesthat belong to the same packages stay in the same set, either
the training or testing sets. Such a variant splitting method
allows us to evaluate cfg2vec truly.
Next, we converted binaries in the AS-4cpu-30k-bin dataset
into their Graph-of-Graph (GoG) representations leveraging
the GDT mentioned previously in Section III-B. Notably,
we processed a batch of binaries related to one package
at one time as developers might deÔ¨Åne user functions in
different modules of the same package while putting prototype
declarations in that package‚Äôs main module. For this case,
Ghidra indeed recognizes two function instances while one
only contains the function declaration and another has its
actual function content. As these two instances correspond
to the same function name and one contains only dummy
instructions, they can thus create noise in our datasets, thus
affecting our model‚Äôs learning. To cope with this, our GDT
also searches from other binaries of the same package for the
function bodies. If found, our GDT associates that user func-
tion with the function graph node with the actual content data.
Besides user functions, library function calls may exist, and
searching their function bodies in the same package would fail
for dynamically loaded binaries. Under such circumstances,
Ghidra would recognize these functions as ThunkFunctions3
which only contain one dummy instruction. As a workaround,
we removed these ThunkFunctions from our data as they
might mislead the model‚Äôs learning. Applying this workaround
indicates that our model works in predicting function names
for the user and statically linked functions.
TABLE I
THE STATISTICS OF DATASETS USED IN OUR EXPERIMENTS .
Dataset / # pkg/bin func node/edge1bb node/edge2
AS-4cpu-30k-bin 1117/27,572 51.17/97.14 14.12/19.98
AS-3cpu-9k-bin 633/9,000 44.01/79.06 12.24/17.07
AS-i386-3k-bin 633/3,000 45.31/87.70 11.45/15.97
AS-amd64-3k-bin 633/3,000 42.28/74.07 12.28/17.18
AS-armel-3k-bin 633/3,000 44.45/75.41 13.00/18.07
1# of average functions and edges in each binary
2# of average bb blocks and edges from each function
We experimented [18] with our datasets, referencing to
their implementation4. As [18] used a dataset with 3,000
binaries for experiments, we followed accordingly, prepar-
ing datasets with smaller but similar sizes. We achieved
this by downsampling from our primary AS-4cpu-30k-bin
dataset, creating the AS-3cpu-9k-bin dataset which has 9,000
binaries for i386 ,amd64 , and armel CPU architectures.
Furthermore, as [18] supports only one CPU architecture at
a time, we then separated the AS-3cpu-9k-bin dataset into
different CPU architectures, generating three training datasets
for testing [18]: AS-i386-3k-bin ,AS-amd64-3k-bin , and AS-
armel-3k-bin . For training, we utilized the strip Linux
command, converting our original data into three: the original
binaries ( debug ), stripped binaries with debug information
3ThunkFunction Manual: https://ghidra.re/ghidra docs/api/ghidra/program/
model/listing/ThunkFunction.html
4Debin‚Äôs [18] repository: https://github.com/eth-sri/debin(stripped ), and stripped binaries without debug information
(stripped wosymtab ) to follow [18]‚Äôs required data format.
For evaluation, we sampled 100 binaries from our primary
dataset for each CPU architecture, labeled AS-amd-100-bin ,
AS-i386-100-bin ,AS-armel-100-bin , and AS-mipsel-100-bin .
We also have another evaluation dataset called AS-noMipsel-
300-bin , which contains roughly 300 binaries produced for the
amd64 ,i386 , and armel platforms. Table I summarizes the
data statistics for all these datasets, including the numbers of
packages and binaries, the average number of function nodes,
edges, and BB nodes. The following sections will detail how
we utilized these datasets during our experiments.
B. Evaluation: Function Name Prediction
Table II demonstrates the results of cfg2vec in predicting
function names. For the baseline, we followed [18]‚Äôs best
setting where the feature dimension of register or stack offset
are both 100 to train with our prepared datasets. For cfg2vec ,
we used three GCN layers and one GAT convolution layer
in both graph embedding layers. For evaluation, we calculate
the p@k (e.g., precision at k) metric, which refers to an
average hit ratio over the top-k list of predicted function
names. SpeciÔ¨Åcally, we feed each binary represented in GoG
into our trained model, converting each function f2Fand
acquiring its function embedding hf. Then, we calculate pair-
wise cosine similarities between hfand all the other function
embeddings, forming a top-k list by selecting k names in
which their embeddings are top-kth similar to hf. If the
ground-truth function name is among the top-k list of function
name predictions, we regard that as a hit; otherwise, it is a
miss. During experiments, we set the top-k value to be 5, so
our model can recommend the best Ô¨Åve possible names for
each function in a binary.
As shown in Table II, cfg2vec , trained with the AS-3cpu-9k-
bindataset, can achieve a 69.75% prediction accuracy (e.g.,
p@1) in inferring function names. For [18], we had to train
their models for each CPU architecture separately as it cannot
train in a cross-architectural manner. Even so, for amd64
binaries, [18] only achieves 29.32% precision, while for i386
andarmel , it performs 52.64% and 53.65%, respectively.
This result indicates that in any case, our cfg2vec outperforms
[18]. Besides, while [18] only yields one prediction, our
cfg2vec suggests Ô¨Åve choices, making it Ô¨Çexible for our users
(e.g., REs) to select what they believe best Ô¨Åts the function
among the best k predicted names. The p@2 to p@5 in Table II
demonstrate that our cfg2vec can provide enough hints of
function names for users. For example, p@5 of cfg2vec trained
with our AS-3cpu-9k-bin dataset can achieve 70.50% precision
across all the CPU architecture binaries. We also experimented
ourcfg2vec with larger datasets. From Table II, we can observe
that cfg2vec can have 5.04% performance gain in correctly
predicting function names (e.g., p@1). Moreover, the gain
increases to 28% when training cfg2vec with the AS-4cpu-30k-
bindataset. We believe training on a larger dataset implies
training with a more diversiÔ¨Åed set of binaries. This allows
our model to acquire more knowledge, thus being capableTABLE II
THE PERFORMANCE EVALUATION OF cfg2vec FOR FUNCTION NAME PREDICTION AGAINST [18].
Model Training dataset Testing dataset P@11P@21P@31P@41P@51
cfg2vec AS-4cpu-30k-bin AS-noMipsel-300-bin 97.05% 99.47% 99.47% 99.47% 99.47%
cfg2vec AS-4cpu-20k-bin AS-noMipsel-300-bin 74.22% 75.76% 75.78% 75.78% 78.78%
AS-amd-100-bin 69.18% 69.98% 69.98% 69.98% 69.98%
cfg2vec AS-3cpu-9k-bin AS-i386-100-bin 69.41% 70.39% 70.39% 70.39% 70.39%
AS-armel-100-bin 70.66% 71.04% 71.11% 71.11% 71.11%
AS-noMipsel-300-bin 69.75% 70.47% 70.50% 70.50% 70.50%
[18]-amd642AS-amd64-3k-bin AS-amd-100-bin 29.32% - - - -
[18]-i3862AS-i386-3k-bin AS-i386-100-bin 52.64% - - - -
[18]-armel2AS-armel-3k-bin AS-armel-100-bin 53.65% - - - -
1P@k measures if the actual function name is in the top k of the predicted function names.
2These models only provide the top 1 function name prediction; hence they only have P@1 value.
of extracting more robust features for binary functions. In
summary, this result indicates that compared to the baseline,
our model can effectively provide contextually relevant names
for functions in the decompiled code to our users.
TABLE III
THE COMPARISON BETWEEN cfg2vec AND ITS ABLATED VARIATIONS .
Arch [18] GCN-GAT 2GCN 2GCN-GAT cfg2vec
amd64 29.32%161.59% 69.49% 69.56% 70.66%
armel 52.64%266.40% 68.59% 68.92% 69.19%
mipsel 53.65%366.47% 68.17% 68.56% 69.41%
Overall 45.20% 64.82% 68.75% 69.01% 69.75%
1Evaluation results for [18]- amd64 model.
2Evaluation results for [18]- i386 model.
3Evaluation results for [18]- armel model.
We also experimented with various ablated network setups
to study how each component of cfg2vec contributes to per-
formance. First, we simpliÔ¨Åed our cfg2vec by stripping one
GCN layer from the original experimental setup. As shown
in Table III, we called this setup 2GCN-GAT which slightly
decreased the performance by 0.75%. Then, from 2GCN-GAT
setup, we further removed the GAT layer, calling it 2GCN .
We again observed a marginal performance decrease ( <1%).
Next, we eliminated another GCN layer from 2GCN-GAT ,
constructing the GCN-GAT setup. For GCN-GAT , we saw
a drastic drop (4.2%) which highlights that the number of
GCN layers can be an essential factor in the performance.
SpeciÔ¨Åcally, we found that going from 1 to 2 GCN layers
improves prediction accuracy by more than 4%. However, we
do not observe a signiÔ¨Åcant performance gain when increasing
the number of GCN layers to more than three. Therefore,
we retained the original cfg2vec model with its three GCN
layers. All in all, as shown in Table III, all these ablated
models, still outperform [18], which we attributed to the GoG
representation we made for each binary in the dataset.
C. Evaluation: Architectural-agnostic Prediction
Table IV demonstrates our cfg2vec ‚Äôs capability in terms
of cross-architecture support. As [18] supports training one
CPU architecture at a time, we had to train it multiple times
during experiments. SpeciÔ¨Åcally, we trained [18] on three
datasets: AS-amd64-3k-bin ,AS-i386-3k-bin , and AS-armel-3k-
bin, calling resulting trained models, [18]- amd64 , [18]- i386 ,
and [18]- armel , respectively. For these baseline models, weobserve that they perform well when tested with the binaries
built on the same CPU architecture but poorly with the ones
built on different CPU architectures. For instance, [18]- amd64
achieves 29.3% accuracy for amd64 binaries, but performs
worse for i386 andarmel binaries (13.8% and 7.1%). Sim-
ilarly, [18]- i386 achieves 52.6% accuracy for i386 binaries,
but performs worse for amd64 andarmel binaries (6.2%
and 1.1%). Lastly, [18]- armel achieves 53.6% accuracy for
armel binaries, but performs worse for amd64 andi386
binaries (11.8% and 8.9%). We used the top-1 prediction
generated from cfg2vec (a.k.a., p@1) as the comparing metric
as [18] produces only one prediction per each function. From
the results, we observe that cfg2vec outperforms [18] across all
three tested CPU architectures. The fact that cfg2vec performs
consistently well across all CPU architectures indicates that
ourcfg2vec supports cross-architecture prediction.
To evaluate the capability of generalizing the learned knowl-
edge, we tested all models with the AS-mipsel-100-bin dataset,
which has binaries built from another famous CPU architec-
ture,mipsel , that our cfg2vec does not train before. For [18],
it has lower performance when testing on binaries built from
the CPU architectures that it did not train before, exampled
by the highest accuracy of [18] to be 13.84% when trained on
amd64 binaries and evaluated on i386 binaries. In our work,
as Table IV shows, our cfg2vec achieves 36.69% accuracy
when trained with amd64 ,i386 , and armel binaries but
tested on mipsel binaries. For [18], it does not even support
analyzing mipsel binaries. In short, these results demonstrate
that our cfg2vec outperforms our baseline in the function name
prediction task on cross-architectural binaries and generalizes
better to the binaries built from unseen CPU architectures. To
further investigate cfg2vec ‚Äôs cross-architecture performance,
we trained it on three datasets, each consisting of binaries
built for two different architectures. We then gave the resulting
trained models names that indicated the architectures from
which the binaries were derived: cfg2vec -armel-i386, cfg2vec -
amd64-i386, and cfg2vec -armel-amd64. These results show
that our model performs well in the function name prediction
job across all of these scenarios, including when tested on
binaries compiled for unknown CPU architectures.TABLE IV
THE CROSS -ARCHITECTURAL COMPARISON BETWEEN CFG 2VEC AND [18]
Model Testing dataset P@1
AS-amd-100-bin 69.18%
cfg2vec -3-Arch AS-i386-100-bin 70.66%
AS-armel-100-bin 69.41%
AS-mipsel-100-bin36.69%
AS-amd-100-bin 68.53%
cfg2vec -amd64-armel AS-i386-100-bin39.23%
AS-armel-100-bin 69.11%
AS-mipsel-100-bin32.21%
AS-amd-100-bin 68.59%
cfg2vec -amd64-i386 AS-i386-100-bin 69.09%
AS-armel-100-bin34.20%
AS-mipsel-100-bin38.26%
AS-amd-100-bin42.96%
cfg2vec -armel-i386 AS-i386-100-bin 67.45%
AS-armel-100-bin 63.86%
AS-mipsel-100-bin36.61%
AS-amd-100-bin 29.32%
[18]-amd64 AS-i386-100-bin13.84%
AS-armel-100-bin7.08%
AS-mipsel-100-bin-
AS-amd-100-bin6.23%
[18]-i386 AS-i386-100-bin 52.64%
AS-armel-100-bin1.05%
AS-mipsel-100-bin-
AS-amd-100-bin11.82%
[18]-armel AS-i386-100-bin8.86%
AS-armel-100-bin 53.65%
AS-mipsel-100-bin-
indicates that dataset was not used during the training.
D. The Practical Usage of CFG2VEC
In this section, we demonstrate how cfg2vec assists REs
in dealing with Defense Advanced Research Projects Agency
(DARPA) Assured MicroPatching (AMP) challenges binaries.
The AMP program aims at enabling fast patching of legacy
mission-critical system binaries, enhancing decompilation and
guiding it toward a particular goal of a Reverse Engineer (RE)
by integrating the existing source code samples, the original
build process information, and historical software artifacts.
1) The MINDSIGHT project: our multi-industry-academia
initiative between Siemens, JHU/APL, BAE, and UCI jointly
developed a project, Making Intelligible Decompiled Source
by Imposing Homomorphic Transforms (MINDSIGHT). Our
team focused on building an automated toolchain integrated
with Ghidra , aiming to enable the decompilation process with
(1) a less granular identiÔ¨Åcation of modular units, (2) an
accurate reconstruction of symbol names, (3) the lifting of
binaries to stylized C code, (4) a principled and scalable
approach to reason about code similarity, and (5) the bench-
marking of new decompilation techniques using state-of-the-
art embedded software binary datasets. To date, our team
has developed an open-source tool, CodeCut5, to improve the
accuracy and completeness of Ghidra ‚Äôs module identiÔ¨Åcation,
providing an automated script-based decompilation analysis
toolchain to ease the RE‚Äôs expert interpretation. Besides, we
also developed a Homomorphic Transform Language (HTL) to
describe transformations on Abstract Syntax Tree (AST) lan-
guages and the rules of their composition. Our tool, integrated
5CodeCut ‚Äôs repository: https://github.com/DARPAMINDSIGHT/CodeCutwith ghidra , allows developers to transform the decompiled
code syntactically while keeping it semantically equivalent.
The key idea is to use this HTL to morph a Ghidra AST
into a GCC AST to lift the decompiled binary to a high-level
C representation. This process can make it easier for REs to
comprehend the binary code. cfg2vec is another tool developed
in the MINDSIGHT project, enabling the reconstruction of
function names, saving the manual guesswork from REs.
Fig. 5. The plugin screenshot integrated into Ghidra.
2) The cfg2vec plugin: InMINDSIGHT project, we incor-
porated cfg2vec into Ghidra decompiler as a plugin applica-
tion. Our cfg2vec plugin assists REs in comprehending the
binaries by providing a list of potential function names for
each function without its name. Technically, like all Ghidra
plugins, our cfg2vec plugin bases on Java with its core
inference modules implemented as a REST API in Python
3.8. Once the metadata of a stripped binary is extracted from
Ghidra decompiler, it is then sent to the cfg2vec end-point,
which calculates and returns the inferred mappings for all
the functions. Figure 5 demonstrates the user interface of
ourcfg2vec plugin. In this scenario, the user must provide
the vulnerable and the reference binary with extra debug
information, such as function names. The ‚ÄúMatch Functions‚Äù
button triggers cfg2vec functionality and displays the function
mapping results in three tables:
Matched Table : displays the mapping of similar functions.
Mismatched Table : displays the mapping of dissimilar
functions and, therefore, candidates for patching.
Orphan Table : displays the mapping of functions with a
low conÔ¨Ådence score.
The groupings reduce REs‚Äô workload. Rather than inspect-
ing all functions, they can focus on patching candidate func-
tions (mismatched functions) and the orphans. The ‚ÄúExplore
Functions‚Äù button invokes Ghidra‚Äôs function explorer, where
the two functions can be compared side-by-side, as shown
in Figure 5. This utility allows the user to switch between
C and assembly language, thus assisting in conÔ¨Årming or
modifying the mappings from the three tables. Regardingcfg2vec ‚Äôs function prediction, the ‚ÄúRename Function‚Äù button
takes the selected row from the tables and imposes the name
from the patched binary in the vulnerable binary. When the
‚ÄúMatch Functions‚Äù button Ô¨Åres, we invoke the FCG and CFG
generators for the two programs (vulnerable and patched).
3) The use-case for AMP challenge binaries: DARPA AMP
challenges is about REs to patch a vulnerability regarding a
weak encryption algorithm where the encryption of commu-
nication trafÔ¨Åc was accomplished with a deprecated cipher
suite, Triple DES or 3DES [49]. For this challenge, REs
have to analyze the vulnerable binary, identify functions and
instructions to be patched, 3DES cipher suite in this case, and
patch 3DES-related function calls and instructions with the
ones for AES [50]. All these steps happen at the decompiled
binary level, and the vulnerable binaries are optimized by
a compiler and stripped of the debugging information and
function names. Furthermore, these binaries are sometimes
statically linked against libraries such as GNU C Library [51]
or OpenSSL, which introduce many extra functions to the
binary (some of which will never be called/used). Given these
complications, it becomes a non-trivial task for an RE to make
sense of all these functions, Ô¨Ånd the problem, and successfully
patch the problem. The direct usage of our cfg2vec plugin was
to pick a function of interest with stripped information and see
predictions of potential function names or matching functions
from the available reference binary to conÔ¨Årm that whether this
function is in the critical path during RE‚Äôs problem solving.
As Figure 5 shows, our plugin allows users to see possible
matches between functions from a stripped vulnerable binary
and functions from a patched (reference) binary with extra
information. REs may then leverage such information and
make appropriate notes for that function, allowing them to
complete their jobs more efÔ¨Åciently. The main feedback we
received from REs who used the tool was that this is the
functionality REs would like to have. However, the accuracy
and usability of the tool were not high enough to truly utilize
the tool‚Äôs potential.
V. C ONCLUSION
This paper presents cfg2vec , a Hierarchical Graph Neural
Network-based approach for software reverse engineering.
Building on top of Ghidra , our cfg2vec plugin can extract
aGraph-of-Graph (GoG) representation for binary, combin-
ing the information from Control-Flow Graphs (CFG) and
Function-Call Graphs (FCG). Cfg2vec utilizes a hierarchical
graph embedding framework to learn the representation for
each function in binary code compiled into various archi-
tectures. Lastly, our cfg2vec utilizes the learned function
embeddings for function name prediction, outperforming the
state-of-the-art [18] by an average of 24.54% across all tested
binaries. By increasing the amount of data, our model achieved
51.84% better. While [18] requires training once for each
CPU architecture, our cfg2vec still can outperform consistently
across all the architectures, only with one training. Besides,
our model generalizes the learning better [18] to the binaries
built from untrained CPU architectures. Lastly, we demonstratethat our cfg2vec can assist the real-world REs in resolving
Darpa Assured MicroPatching (AMP) challenges.
ACKNOWLEDGMENT
This material is based upon work supported by the Defense
Advanced Research Projects Agency (DARPA) and Naval
Information Warfare Center PaciÔ¨Åc (NIWC PaciÔ¨Åc) under
Contract Number N66001-20-C-4024. The views, opinions,
and/or Ô¨Åndings expressed are those of the author(s) and should
not be interpreted as representing the ofÔ¨Åcial views or policies
of the Department of Defense or the U.S. Government.
REFERENCES
[1] K. Zhidanov, S. Bezzateev, A. Afanasyeva, M. Sayfullin, S. Vanurin,
Y . Bardinova, and A. Ometov, ‚ÄúBlockchain technology for smartphones
and constrained iot devices: A future perspective and implementation,‚Äù
in2019 IEEE 21st Conference on Business Informatics (CBI) , vol. 2.
IEEE, 2019, pp. 20‚Äì27.
[2] A. Panarello, N. Tapas, G. Merlino, F. Longo, and A. PuliaÔ¨Åto,
‚ÄúBlockchain and iot integration: A systematic survey,‚Äù Sensors , vol. 18,
no. 8, p. 2575, 2018.
[3] S. Dange and M. Chatterjee, ‚ÄúIot botnet: the largest threat to the iot
network,‚Äù in Data Communication and Networks . Springer, 2020, pp.
137‚Äì157.
[4] S. R. Chhetri, J. Wan, and M. A. Al Faruque, ‚ÄúCross-domain security
of cyber-physical systems,‚Äù in 2017 22nd Asia and South PaciÔ¨Åc design
automation conference (ASP-DAC) . IEEE, 2017, pp. 200‚Äì205.
[5] A. Sargolzaei, A. Abbaspour, M. A. Al Faruque, A. Salah Eddin,
and K. Yen, ‚ÄúSecurity challenges of networked control systems,‚Äù in
Sustainable interdependent networks . Springer, 2018, pp. 77‚Äì95.
[6] A. Barua, L. Pan, and M. A. A. Faruque, ‚ÄúBayesimposter: Bayesian
estimation based. bss imposter attack on industrial control systems,‚Äù in
Annual Computer Security Applications Conference , 2022, pp. 440‚Äì454.
[7] F-secure, ‚ÄúAttack landscape h1 2019,‚Äù 2019. [Online].
Available: https://blog-assets.f-secure.com/wp-content/uploads/2019/09/
12093807/2019 attack landscape report.pdf
[8] ‚ÄúCVE-2014-0160.‚Äù Available from MITRE, CVE-ID CVE-2014-0160.,
Dec. 3 2013. [Online]. Available: http://cve.mitre.org/cgi-bin/cvename.
cgi?name=CVE-2014-0160
[9] I. Ghafoor, I. Jattala, S. Durrani, and C. M. Tahir, ‚ÄúAnalysis of
openssl heartbleed vulnerability for embedded systems,‚Äù in 17th IEEE
International Multi Topic Conference 2014 . IEEE, 2014, pp. 314‚Äì319.
[10] ‚ÄúThe heartbleed vulnerability.‚Äù 2014. [Online]. Available: http:
//heartbleed.com/
[11] ‚ÄúShellshock: All you need to know about the bash bug vulnerability,‚Äù
2014. [Online]. Available: https://www.symantec.com/
[12] ‚ÄúShellshock in-depth: Why this old vulnerability won‚Äôt go
away,‚Äù Security Intelligence, 2020. [Online]. Available: https:
//securityintelligence.com/articles/shellshock-vulnerability-in-depth/
[13] S.-H. Kim, M. A. Cohen, S. Netessine, and S. Veeraraghavan, ‚ÄúContract-
ing for infrequent restoration and recovery of mission-critical systems,‚Äù
Management Science , vol. 56, no. 9, pp. 1551‚Äì1567, 2010.
[14] N. S. Agency, ‚ÄúGhidra - software reverse engineering framework.‚Äù 2019.
[Online]. Available: https://www.nsa.gov/resources/everyone/ghidra/
[15] S. Hex-Rays, ‚ÄúIda disassembler,‚Äù 2017.
[16] R. Team, Radare2 Book . GitHub, 2017.
[17] A. Keliris and M. Maniatakos, ‚ÄúIcsref: A framework for automated re-
verse engineering of industrial control systems binaries,‚Äù arXiv preprint
arXiv:1812.03478 , 2018.
[18] J. He, P. Ivanov, P. Tsankov, V . Raychev, and M. Vechev, ‚ÄúDebin:
Predicting debug information in stripped binaries,‚Äù in Proceedings of
the 2018 ACM SIGSAC Conference on Computer and Communications
Security , 2018, pp. 1667‚Äì1680.
[19] J. Lacomis, P. Yin, E. Schwartz, M. Allamanis, C. Le Goues, G. Neubig,
and B. Vasilescu, ‚ÄúDire: A neural approach to decompiled identiÔ¨Åer nam-
ing,‚Äù in 2019 34th IEEE/ACM International Conference on Automated
Software Engineering (ASE) . IEEE, 2019, pp. 628‚Äì639.
[20] Y . David, U. Alon, and E. Yahav, ‚ÄúNeural reverse engineering of stripped
binaries using augmented control Ô¨Çow graphs,‚Äù Proceedings of the ACM
on Programming Languages , vol. 4, no. OOPSLA, pp. 1‚Äì28, 2020.[21] H. Gao, S. Cheng, Y . Xue, and W. Zhang, ‚ÄúA lightweight framework
for function name reassignment based on large-scale stripped binaries,‚Äù
inProceedings of the 30th ACM SIGSOFT International Symposium on
Software Testing and Analysis , 2021, pp. 607‚Äì619.
[22] Q. Feng, R. Zhou, C. Xu, Y . Cheng, B. Testa, and H. Yin, ‚ÄúScalable
graph-based bug search for Ô¨Årmware images,‚Äù in Proceedings of the 2016
ACM SIGSAC Conference on Computer and Communications Security ,
2016, pp. 480‚Äì491.
[23] X. Xu, C. Liu, Q. Feng, H. Yin, L. Song, and D. Song, ‚ÄúNeural network-
based graph embedding for cross-platform binary code similarity detec-
tion,‚Äù in Proceedings of the 2017 ACM SIGSAC Conference on Computer
and Communications Security , 2017, pp. 363‚Äì376.
[24] I. U. Haq and J. Caballero, ‚ÄúA survey of binary code similarity,‚Äù arXiv
preprint arXiv:1909.11424 , 2019.
[25] K. Yakdan, S. Dechand, E. Gerhards-Padilla, and M. Smith, ‚ÄúHelping
johnny to analyze malware: A usability-optimized decompiler and
malware analysis user study,‚Äù in 2016 IEEE Symposium on Security
and Privacy (SP) . IEEE, 2016, pp. 158‚Äì177.
[26] L. ÀáDurÔ¨Åna, J. K Àároustek, and P. Zemek, ‚ÄúPsybot malware: A step-by-step
decompilation case study,‚Äù in 2013 20th Working Conference on Reverse
Engineering (WCRE) . IEEE, 2013, pp. 449‚Äì456.
[27] M. J. Van Emmerik, Static single assignment for decompilation . Uni-
versity of Queensland, 2007.
[28] D. Brumley, J. Lee, E. J. Schwartz, and M. Woo, ‚ÄúNative x86 decompila-
tion using semantics-preserving structural analysis and iterative control-
Ô¨Çow structuring,‚Äù in 22nd fUSENIX gSecurity Symposium ( fUSENIX g
Security 13) , 2013, pp. 353‚Äì368.
[29] ‚ÄúBinutils. (2019) objdump,‚Äù 2019. [Online]. Available: https://www.
gnu.org/software/binutils/
[30] ‚ÄúBinary ninja. (2022) interactive disassembler, decompiler, and binary
analysis platform,‚Äù 2022. [Online]. Available: https://binary.ninja/
[31] ‚ÄúHopper. (2022) reverse engineering tool that lets you disassemble,
decompile and debug your applications,‚Äù 2022. [Online]. Available:
https://www.hopperapp.com/
[32] ‚ÄúHex-rays. (2019) the hex-rays decompiler.‚Äù 2019. [Online]. Available:
https://www.hex-rays.com/products/decompiler/
[33] M. Nyre-Yu, K. Butler, and C. Bolstad, ‚ÄúA task analysis of static
binary reverse engineering for security,‚Äù Jan 2022. [Online]. Available:
https://scholarspace.manoa.hawaii.edu/handle/10125/79608
[34] W. Shao, Q. Yang, X. Guo, and R. Cai, ‚ÄúA survey of available
information recovery of binary programs based on machine learning,‚Äù
in2022 5th International Conference on ArtiÔ¨Åcial Intelligence and Big
Data (ICAIBD) . IEEE, 2022, pp. 125‚Äì132.
[35] Z. L. Chua, S. Shen, P. Saxena, and Z. Liang, ‚ÄúNeural nets can learn
function type signatures from binaries,‚Äù in Proceedings of the 26th
USENIX Conference on Security Symposium , ser. SEC‚Äô17. USA:
USENIX Association, 2017, p. 99‚Äì116.
[36] U. Alon, M. Zilberstein, O. Levy, and E. Yahav, ‚ÄúCode2vec:
Learning distributed representations of code,‚Äù Proc. ACM Program.
Lang. , vol. 3, no. POPL, jan 2019. [Online]. Available: https:
//doi.org/10.1145/3290353
[37] F. Artuso, G. A. Di Luna, L. Massarelli, and L. Querzoni, ‚ÄúIn nomine
function: Naming functions in stripped binaries with neural networks,‚Äù
arXiv preprint arXiv:1912.07946 , 2019.
[38] K. Redmond, L. Luo, and Q. Zeng, ‚ÄúA cross-architecture instruction
embedding model for natural language processing-inspired binary code
analysis,‚Äù arXiv preprint arXiv:1812.09652 , 2018.
[39] D. Vasan, M. Alazab, S. Venkatraman, J. Akram, and Z. Qin, ‚ÄúMthael:
Cross-architecture iot malware detection based on neural network ad-
vanced ensemble learning,‚Äù IEEE Transactions on Computers , vol. 69,
no. 11, pp. 1654‚Äì1667, 2020.
[40] M. Alhanahnah, Q. Lin, Q. Yan, N. Zhang, and Z. Chen, ‚ÄúEfÔ¨Åcient
signature generation for classifying cross-architecture iot malware,‚Äù in
2018 IEEE conference on communications and network security (CNS) .
IEEE, 2018, pp. 1‚Äì9.
[41] P. Goyal and E. Ferrara, ‚ÄúGraph embedding techniques, applications,
and performance: A survey,‚Äù CoRR , vol. abs/1705.02801, 2017.
[Online]. Available: http://arxiv.org/abs/1705.02801
[42] Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and S. Y . Philip, ‚ÄúA
comprehensive survey on graph neural networks,‚Äù IEEE transactions
on neural networks and learning systems , 2020.
[43] R. Yasaei, S.-Y . Yu, and M. A. Al Faruque, ‚ÄúGnn4tj: Graph neural
networks for hardware trojan detection at register transfer level,‚Äù in 2021Design, Automation & Test in Europe Conference & Exhibition (DATE) .
IEEE, 2021, pp. 1504‚Äì1509.
[44] S.-Y . Yu, A. V . Malawade, D. Muthirayan, P. P. Khargonekar, and
M. A. Al Faruque, ‚ÄúScene-graph augmented data-driven risk assessment
of autonomous vehicle decisions,‚Äù IEEE Transactions on Intelligent
Transportation Systems , 2021.
[45] M. Hassen and P. K. Chan, ‚ÄúScalable function call graph-based malware
classiÔ¨Åcation,‚Äù in Proceedings of the Seventh ACM on Conference on
Data and Application Security and Privacy , 2017, pp. 239‚Äì248.
[46] S. Harada, H. Akita, M. Tsubaki, Y . Baba, I. Takigawa, Y . Yamanishi,
and H. Kashima, ‚ÄúDual graph convolutional neural network for predict-
ing chemical networks,‚Äù BMC bioinformatics , vol. 21, pp. 1‚Äì13, 2020.
[47] J. Staff, ‚ÄúAssembled labeled library for static analysis research (allstar)
dataset,‚Äù Dec 2019. [Online]. Available: https://allstar.jhuapl.edu/
[48] ‚ÄúDebian gnu linux installation guide,‚Äù 2004. [Online]. Available:
https://www.debian.org/releases/bullseye/i386/ch02s01.en.html#idm186
[49] J. Callas, ‚ÄúTriple des: How strong is the data encryption standard?‚Äù May
2017. [Online]. Available: https://www.techtarget.com/searchsecurity/
tip/Expert-advice-Encryption-101-Triple-DES-explained
[50] C. Bernstein and M. Cobb, ‚ÄúWhat is the advanced
encryption standard (aes)? deÔ¨Ånition from searchsecurity,‚Äù Sep
2021. [Online]. Available: https://www.techtarget.com/searchsecurity/
deÔ¨Ånition/Advanced-Encryption-Standard
[51] T. Rothwell and J. Youngman, ‚ÄúThe gnu c reference manual,‚Äù Free
Software Foundation, Inc , p. 86, 2007.