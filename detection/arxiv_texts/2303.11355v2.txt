Here comes the SU(N): multivariate quantum gates and
gradients
Roeland Wiersema1,2, Dylan Lewis3, David Wierichs4, Juan Carrasquilla1,2, and Nathan Killoran4
1Vector Institute, MaRS Centre, Toronto, Ontario, M5G 1M1, Canada
2Department of Physics and Astronomy, University of Waterloo, Ontario, N2L 3G1, Canada
3Department of Physics and Astronomy, University College London, London WC1E 6BT, United Kingdom
4Xanadu, Toronto, ON, M5G 2C8, Canada
Variational quantum algorithms use
non-convex optimization methods to find
the optimal parameters for a parametrized
quantum circuit in order to solve a com-
putational problem. The choice of the
circuit ansatz, which consists of parame-
terized gates, is crucial to the success of
these algorithms. Here, we propose a gate
which fully parameterizes the special uni-
tary group SU(N). This gate is generated
byasumofnon-commutingoperators, and
we provide a method for calculating its
gradient on quantum hardware. In addi-
tion, we provide a theorem for the com-
putational complexity of calculating these
gradients by using results from Lie alge-
bra theory. In doing so, we further gen-
eralize previous parameter-shift methods.
We show that the proposed gate and its
optimization satisfy the quantum speed
limit, resulting in geodesics on the unitary
group. Finally, we give numerical evidence
to support the feasibility of our approach
and show the advantage of our gate over
a standard gate decomposition scheme. In
doing so, we show that not only the ex-
pressibility of an ansatz matters, but also
how it’s explicitly parameterized.
1 Introduction
Variational quantum computing is a paradigm of
quantum computing that uses optimization algo-
rithms to find the optimal parameters for a pa-
rameterized quantum circuit [1, 2]. Crucial for
the success of such algorithms is the choice of
circuit ansatz, which usually consists of multiple
parameterized one and two-qubit gates. Typi-cally, these gates are parameterized unitary ma-
trices generated by single Pauli-string operators
that can locally rotate a state around some axis:
U(t) = exp{itG}, wheretis a gate parameter
andGa Pauli string. For a specific family of cost
functions, there exist a variety of methods that
allow one to obtain the gradient with respect to
t[3, 4, 5, 6, 7, 8, 9] on quantum hardware. With
these gradients, the cost function can be mini-
mized via any gradient-descent-based algorithm.
Instead of considering a gate generated by a
single Pauli string, one can construct more gen-
eral parameterized gates that can perform an ar-
bitrary rotation in SU(N), the special unitary
group. Thesegeneral SU(N)rotationsareusedin
a variety of quantum algorithms [10, 11, 12, 13].
In practice, rotations in SU(N)can be imple-
mented by composing several simple parame-
terized gates together into a more complicated
one. For example, for single and two-qubit
gates (where N= 2,4, respectively), there ex-
ist several general decomposition schemes of such
gates into products of single-qubit gates and
CNOTs [14, 15, 16, 17, 18, 19]. In practice, this
compilation comes with hardware-specific chal-
lenges, since quantum hardware usually has a set
of native gates into which all others have to be
decomposed [20, 21].
Choosing the right parameterization for a func-
tion is important because it can significantly af-
fect the properties of its gradients. Reparam-
eterizing functions to obtain more useful gradi-
ents is a well-known method in statistics and ma-
chine learning. For example, in restricted maxi-
mum likelihood methods one can ensure numer-
ical stability of quasi-Newton methods by de-
composing covariance matrices into Cholesky fac-
tors [22]. In addition, methods like auxiliary lin-
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 1arXiv:2303.11355v2  [quant-ph]  29 Feb 2024ear transformations [23], batch normalization [24]
and weight normalization [25] are used to im-
prove the gradients in neural networks. In varia-
tional inference, the reparameterization trick [26]
is at the core of variational autoencoder ap-
proaches and allows for gradients for stochastic
back-propagation [27, 28]. In light of this, it may
be worthwhile to investigate alternative parame-
terizations of quantum gates for variational quan-
tum algorithms.
In this work, we propose a family of parame-
terized unitaries called SU(N)gates and provide
a method to evaluate their gradients on quan-
tum hardware. In doing so, we generalize the
prior literature one step further, since many past
schemes can be understood as special cases of our
proposal [3, 4, 5, 6, 7, 8, 9]. We provide numeri-
cal results to support the validity of our approach
and give several examples to illustrate the capa-
bilities of the SU(N)gate. We show that this
gate satisfies the quantum speed limit and that it
is easier to optimize compared to SU(N)param-
eterizations that consist of products of gates. We
argue that this is the case because the product of
unitaries creates a “bias” in the Lie algebra that
deforms the cost landscape. In addition, we high-
light the connections between our formalism and
the properties of semisimple Lie algebras and es-
tablish a bound on the computational complexity
of the gradient estimation using tools from repre-
sentation theory.
2SU(N)gates
A quantum gate is a unitary operation Uthat
acts on a quantum state ρin a complex Hilbert
space. If we ignore a global phase, then a gate U
acting onNqubitsqubits is an element of the spe-
cial unitary group SU(N)(see App. A), where
N= 2Nqubits. Note that all of the following works
for anyN > 1, but here we restrict ourselves to
the qubit case. We are interested in constructing
a quantum gate that parameterizes all of SU(N).
To achieve this, we make use of the theory of Lie
algebras. We will not be concerned with the for-
mal treatment of this topic, which can be found
in many excellent textbooks [29, 30, 31].
To construct our gate, we realize that SU(N)
is a (semisimple) Lie group and so there exists
a unique connection between its elements and
the Lie algebra su(N)via the so-called Lie corre-spondence, or Lie’s third theorem [32, 31]. In
particular, each g∈SU(N)can be identified
with anA∈su(N)via the exponential map
g= exp{A}. For our purposes, we can under-
stand the Lie algebra su(N)as a vector space
of dimension N2−1that is closed under the
commutator, [A,B] =AB−BA∈su(N)for
A,B∈su(N). For su(N), we choose as a basis
the tensor products of Pauli matrices multiplied
by the imaginary unit i:
P(Nqubits )=/braceleftig
i(σ1⊗...⊗σNqubits)/bracerightig
\{INqubits},
(1)
whereσi∈{I,X,Y,Z}andINqubits =iI⊗Nqubits.
We choose the following parameterization of
SU(N):
U(θ) = exp{A(θ)}, A (θ) =/summationdisplay
mθmGm,(2)
where θ= (θ1,θ2,...,θN2−1)∈RN2−1and
{Gm}∈P(Nqubits ). To distinguish between the
group and the gate, we call the parameterization
in Eq. (2) a SU(N)gate. The coordinates θare
called the canonical coordinates, which uniquely
parameterize Uthrough the Lie algebra su(N).
Since we typically cannot implement the above
gate in hardware, we will have to be decompose
it via a standard unitary decomposition algo-
rithm [14, 15, 16, 17, 18, 19]. We emphasize here
that even though the gate will be decomposed, it
is parameterized as an exponential map. Hence
we can understand Eq. (2) as a change of coordi-
nates from the SU(N)gate decomposition.
Ifwedonotwanttoparameterizeallof SU(N),
we can instead parameterize a more restricted
Hamiltonian by setting some of the parameters
θmto zero. This makes Eq. (2) a natural pa-
rameterization of several Hamiltonians available
on modern quantum hardware platforms. These
Hamiltonians often have multiple independently
tunable fields which can be active at the same
time and do not necessarily commute. One typ-
ically has local control on each qubit and access
to an interacting Hamiltonian between pairs of
qubits, depending on the topology of the quan-
tum device [33]. The interacting pair can for
example be a ZZinteraction for Josephson flux
qubits [34], a Heisenberg interaction for nuclear
spins in doped silicon [35] or an XYinteraction
in quantum dots interacting with a cavity [36].
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 2To use this gate in a gradient-based variational
quantum algorithm, we have to be able to ob-
tain partial derivatives of U(θ)with respect to
each parameter θl. Although there exist a vari-
ety of works that provide analytical expressions
for gradients through quantum circuits via the
parameter-shift rule [3, 4, 5, 6, 7, 8, 9, 37], these
works almost uniformly assume that the gate is
of the form U(θ) = exp{iθP}, wherePis a
Hermitian operator. As far as we are aware,
the only methods to obtain gradients of Eq. (2)
with respect to θare the stochastic and Nyquist
parameter-shift rules of [6] and [10], respectively.
The first approach relies on an integral iden-
tity for bounded operators that is estimated via
Monte Carlo [38], whereas the latter is based on
a theorem in Fourier analysis [39].
3 Obtaining the gradient
Here, we provide a new approach to obtain the
gradient of Eq. (2) that makes use of differen-
tiable programming, which is efficient for gates
acting on a small number of qubits. To start, we
note that the partial derivative with respect to a
parameterθlis given by
∂
∂θlU(θ) =∂
∂θlexp{A(θ)}
=U(θ)∞/summationdisplay
p=0(−1)p
(p+ 1)!(adA(θ))p∂
∂θlA(θ).
(3)
Here, adXdenotes the adjoint action of the Lie
algebra given by the commutator adX(Y) =
[X,Y ][31]. Furthermore, we write (adX)p(Y) =
[X,[X,... [X,Y ]]], hence (adX)pdenotes a
nested commutator of pterms. For more details,
see App. B. Note that the term on the right of
U(θ)in Eq. (3) is an element of the Lie algebra,
since∂/∂θlA(θ) =Gl∈su(N)and so the com-
mutator keeps the entire sum in the algebra. For
notational clarity we define
Ωl(θ) =∞/summationdisplay
p=0(−1)p
(p+ 1)!(adA(θ))p∂
∂θlA(θ),(4)
where Ωl(θ)∈su(N)is a skew-Hermitian oper-
ator that generates a unitary, which we call the
effective generator . Given that Eq. (4) is an in-
finite series of nested commutators it is not clearhowΩl(θ)∈su(N)can be calculated in practice
without truncating the sum.
We can think of Uas a function U:RN2−1→
SU(N)that we evaluate at the point θ. Since
SU(N)is a differentiable manifold, we can define
a set of local coordinates on the group and rep-
resentU(x)as a matrix described by N2−1real
numbers. Hence, we can think of our gate as a
coordinate transformation between the parame-
tersxand the entries of the matrix represent-
ing the unitary. Since U(x)depends smoothly
onxlvia the matrix exponential, this coordi-
nate transformation comes with a correspond-
ing Jacobian (or more accurately, pushforward)
dU(x) :TxRN2−1→TU(x)SU(N)that maps vec-
tors tangential to RN2−1to vectors tangential to
SU(N). We can obtain this Jacobian by differen-
tiating the elements Unm(x)with respect to xl:
∂
∂xlUnm(x) =∂xlRe[Unm(x)] +i∂xlIm[Unm(x)].
(5)
To obtain the above matrix function numerically,
we rely on the fact that the matrix exponential
and its derivative are implemented in differen-
tiableprogrammingframeworkssuchasJAX[40],
PyTorch [41] and Tensorflow [42] through auto-
matic differentiation. Here we make use of the
JAX implementation, which provides the matrix
exponentialthroughadifferentiablePadéapprox-
imation [43, 44].
Continuing, we note that evaluating
∂U(x)/∂xlat a point θproduces an ele-
ment of the tangent space TU(θ)SU(N). We can
move from the tangent space to the Lie algebra
by left multiplying the elementwise derivative of
Eq. (5) in Eq. (3) with U†(θ)(see App. A),
U†(θ)/parenleftigg
∂
∂xlU(x)/vextendsingle/vextendsingle/vextendsingle/vextendsingle
θ/parenrightigg
=U†(θ)U(θ)Ωl(θ) = Ωl(θ),
(6)
whichallowsustoobtain Ωl(θ)exactly, uptoma-
chine precision. We emphasize that these steps
can be performed on a classical computer, with
a cost that is only dependent on the number of
qubits the gate acts on, not the number of qubits
in the circuit.
We now make the following observation: Ωl(θ)
corresponds to a tangent vector on SU(N)and
generates the one-parameter subgroup V(t) =
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 3exp{tΩl(θ)}such that
Ωl(θ) =d
dtexp{tΩl(θ)}/vextendsingle/vextendsingle
t=0(7)
and
∂
∂θlU(θ) =U(θ)d
dtexp{tΩl(θ)}/vextendsingle/vextendsingle
t=0.(8)
We sketch this procedure schematically in Fig. 1.
Figure 1: Schematic depiction of our approach. We
move to the Lie algebra from the tangent space by left
multiplication with U†(θ)and obtain Ωl(θ). The orbit
generated by Ωl(θ)corresponds to the gate we have to
insert in the circuit to compute the gradient.
We now consider a typical variational setting,
where we are interested in minimizing the follow-
ing cost function:
C(θ) = Tr/braceleftig
U(θ)ρU†(θ)H/bracerightig
,(9)
whereHis some Hermitian operator and ρthe
initial state of the system. For simplicity we con-
sider a circuit consisting of a single SU(N)gate.
Differentiating the cost function with respect to
θlgives
∂
∂θlC(θ) = Tr/braceleftbigg/parenleftbigg∂
∂θlU(θ)/parenrightbigg
ρU†(θ)H/bracerightbigg
+ h.c.
(10)
Then, plugging in Eq. (8) we find,
∂
∂θlC(θ) =
d
dtTr/braceleftig/parenleftig
U(θ)etΩl(θ)ρe−tΩl(θ)U†(θ)/parenrightig
H/bracerightig/vextendsingle/vextendsingle/vextendsingle/vextendsingle
t=0,
(11)
where we used the skew-Hermitian property of
the tangent vector Ω†
l(θ) =−Ωl(θ). Note
that Eq. (11) corresponds to a new circuit with
the gate exp{tΩl(θ)}inserted before U(θ)(see
Fig. 2).
Figure 2: The partial derivative with respect to the gate
parameterθlcanbeobtainedbyaddingagatetothecir-
cuit that is generated by Ωl(θ). Calculating the deriva-
tive with respect to tand evaluating at t= 0then pro-
vides one with the correct gradient.
The gradient of this new circuit can be com-
puted on quantum hardware with a generalized
parameter-shift rule (GPSR) [8, 7, 9]. In Al-
gorithm 1, we outline the entire algorithm for
our gradient estimation and we denote the GPSR
subroutine with gpsr. An alternative to the
generalized shift rule is to decompose the ef-
fective generators and apply the original two-
term parameter-shift rule to the constituents (see
App. 3 for details). In [45], the authors proposed
the so-called stochastic parameter-shift rule for
multivariate gates, which is based on the Monte
Carlo approximation of an operator identity.
In Fig. 3 we consider a toy example using
a random Hamiltonian on a single qubit and
compare the exact derivative of an SU(2)gate
with our generalized parameter-shift method (Al-
gorithm 1), the stochastic parameter-shift rule
and the central finite difference derivative with
shifts±δ
2. In particular, we consider the gate
U(θ) = exp(iaX+ibY)withθ= (a,b)and com-
pute the partial derivative with respect to aover
the rangea∈[0,π]for three fixed values of bon a
state vector simulator (without shot noise). For
the finite difference recipe we use δ= 0.75, which
we found to be a reasonable choice for a shot bud-
get of 100shots per cost function evaluation (see
App. 2). We observe that the generalized SU(N)
derivative reproduces the exact value while the
finite difference derivative is slightly biased. This
is to be expected because the latter is an approx-
imate method. While decreasing the shift size δ
reduces the deterministic approximation error, it
leads to larger overall estimation errors in shot-
based computations like on quantum computers
(see App. 2 and e.g., [46]). Finally, the stochastic
parameter-shift rule yields an unbiased estimator
for the exact derivative but has a finite variance,
which we estimated using 100samples (see App.
1). We stress that this variance is a property of
the differentiation method itself and not due to
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 4sampling on the quantum computer. All meth-
ods require two unique circuits per derivative but
the stochastic shift rule needs additional circuits
in order to suppress the variance. We provide the
code for all our numerical experiments at [47].
0 π/2 π
a−2−1012∂aC(θ)b=0.5
b=1.0
b=2.0Exact value
SU(N) parameter-shift
Finite diﬀerence
Stochastic parameter-shift
Figure 3: Gradients of C(θ)for a single SU(2)gate
and a random single-qubit Hamiltonian, in the limit of
infinitely many shots on quantum hardware. We take
A(θ) =iaX+ibYwhere θ= (a,b)and consider the
fixed values b= 0.5,1.0,2.0together with a∈[0,π].
Our generalized shift rule (dotted) reproduces the ex-
act value (solid), whereas the central finite difference
(dashed) is biased and the stochastic shift rule (solid,
shaded) comes with a finite statistical error even with-
out shot noise from the quantum measurements. Since
we look at a single-qubit operation, Ωa(θ)has a single
spectral gap, so we require two shifted circuits to cal-
culate the gradient entry (see App. D for details). The
finite difference and the stochastic shift rule require two
circuits as well, but additional executions are need for
the latter to reduce the shown single-sample error.
In addition, we compare the three methods in
the presence of shot noise in Fig. 4. We show
the means and single-shot errors estimated with
1000shots, which we split over 100samples for
the stochastic shift rule. We observe that the
generalized SU(N)shift rule systematically per-
forms best. It is not only unbiased but also has
the smallest variance. Note that for smaller pa-
rametersb, the SU(N)shift rule and the stochas-
tic shift rule show very similar variances. This
is because U(θ)approaches the gate RX(a) =
exp(iaX), which can be differentiated with the
original parameter-shift rule, and both rules in-deed reduce to the two-term shift rule for RX.
−4−2024∂aC(θ)
b=0.5Exact value
SU(N) parameter-shift
Finite diﬀerence
Stochastic parameter-shift
−4−202∂aC(θ)
b=1.0
0 π/2 π
a−4−202∂aC(θ)
b=2.0
Figure 4: Gradients of C(θ)as in Fig. 3 but for
finitely many shots on quantum hardware. We show the
single-shot error for each method, estimated with 1000
shots, which varies with the gate parameters as noted
e.g., in [9]. Our generalized SU(N)shift rule systemat-
ically outperforms the other methods. For small b, the
SU(N)and the stochastic shift rule approach the single-
parameter shift rule and hence behave similarly. The fi-
nite difference shift δ= 0.75is chosen such that the bias
and variance are traded off reasonably for 100shots (see
App. 1 and e.g., [46]). For other shot numbers, δneeds
to be optimized anew, whereas the parameter-shift rules
are known to perform optimally at fixed shifts.
Finally, we note that Eq. (11) is closely related
to the Riemannian gradient on SU(N)[48, 49].
However, instead of a gradient flow on a Lie
group, we have defined a flow on the Lie algebra
su(N), which we retract back to the manifold via
the exponential map. This subtle difference in-
duces a different flow from the SU(N)one, as we
illustrate in App. C.
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 5Algorithm 1: SU(N)gradients.
Input:U(x),ρ,H,θ
Obtain the Jacobian function:
forl∈(1,...,N2−1)do
∂xlUl(x) =∂xlRe[U(x)] +i∂xlIm[U(x)]
end
For each gradient step:
forl∈(1,...,N2−1)do
Ωl(θ)←U†(θ)dUl(x)|θ
C(t)←
Tr/braceleftig
U(θ)etΩl(θ)ρe−tΩl(θ)U†(θ)H/bracerightig
∂
∂θlC(θ)←gpsr (Ωl(θ))
end
4 Comparison with decomposed uni-
taries
Previous parameterizations of SU(N)unitaries
consist of products of single-qubit gates and
CNOTs [14, 15, 16, 17, 18, 19]. We refer to this
parameterization as decomposed SU(N)gates.
On the other hand, Eq. (2) describes a general
SU(N)unitary by exponentiating a parameteri-
zation of the Lie algebra su(N). Here, we investi-
gate the effects of this alternative parameteriza-
tion.
4.1 Gate speed limit
First, we investigate a speed limit in terms of
the gate time. We slightly modify the definition
of Eq. (2) for a unitary evolution of the system,
U(θ;t)∈SU(N), to include a time t∈R+,
U(θ;t) = exp/braceleftig¯A(θ)t/bracerightig
, (12)
where ¯A(θ) =A(θ)//radicalig
Tr{A(θ)†A(θ)}is a
normalized time-independent Hamiltonian (the
imaginary unit iis included in A(θ)). The nor-
malization of ¯A(θ)is equivalent to the normal-
ization of θin Euclidean norm, see Lemma 3 in
App. F. The normalization of the Hamiltonian
(or, equivalently, θ) means that the total path
length covered by the evolution is directly pro-
portional to the evolution time t, since we are
effectively setting the speed of the evolution to 1.
The Lie group SU(N)can be turned into
a Riemannian manifold by equipping it with
the Hilbert-Schmidt inner product g(x,y) =Tr/braceleftig
x†y/bracerightig
. The unitary evolution U(θ;t), param-
eterized by t, is a one-parameter subgroup that
gives the geodesic [48, Theorem III.6] from the
identity element at time t= 0. Geodesics can
be defined as generalizations of straight lines in
Euclidean geometry. Using Lemma 4 (App. F),
the length of the path after time tis constant for
time-independent normalized Hamiltonians with
|θ|= 1,
L[U(θ;t),t] =√
Nt. (13)
In general, there is more than one geodesic be-
tween two points on the manifold. For example,
two points on the Bloch sphere can be connected
by rotations about the same axis moving in oppo-
site directions. Using Lemma 5 (App. F), one of
these geodesics must be the curve of the minimal
path length. Hence, the minimum time to gener-
ate the evolution U(θ;tg)istgalong the geodesic
of the minimal path. For an initial state ρand
final stateρf, the Fubini-Study metric is used to
find a minimum evolution time
tg=1√
Narccos/parenleftbigg/radicalig
Tr{ρρf}/parenrightbigg
,(14)
giving the Mandelstam-Tamm bound for time-
independent normalized Hamiltonians.
In practice, we may only have access to a re-
stricted family of gates within SU(N), for exam-
ple due to hardware limitations, in which case
we require a decomposition of a desired gate in
SU(N)into gates from this family. Here we want
tocomputetheadditionalevolutiontimerequired
by such a decomposition. The simplest gate
decomposition is to break the unitary into two
terms,U(θ;tg) =U(ϕ(2);t2)U(ϕ(1);t1). The pa-
rameters ϕ(1)andϕ(2)arealsonormalizedHamil-
tonians, i.e., they have the norm |ϕ(1)|=|ϕ(2)|=
1. The following theorem shows that using a de-
composed circuit over an SU(N)gate gives an
additional evolution time, which corresponds to
longer circuit run times.
Theorem 1. For unitary gates generated by
normalized time-independent Hamiltonians, con-
sider a general circuit decomposition of two gates
U(ϕ(2);t2)U(ϕ(1);t1). There exists an equiva-
lent evolution with an SU(N)gateU(θ;tg) =
U(ϕ(2);t2)U(ϕ(1);t1), with evolution time tg,
such that
tg≤t1+t2,
with equality if ϕ(1)+ϕ(2)=θ.
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 6The proof of the theorem is in App. F. As ex-
pected, a decomposition into two gates gives a
longer total evolution time than is possible with
anSU(N)gate due to the normalizations of ϕ(1),
ϕ(2), and θ. A decomposition into more gates
would generally lead to an even greater evolution
time. A corollary of Theorem 1 is that any cir-
cuit with multiple non-commuting layers of gates
cannot be optimal in total time.
4.2 Unbiased cost landscapes
An additional advantage of the SU(N)gate is
that it weighs all optimization directions equally.
In contrast, a parameterization of SU(N)in
termsofaproductofgateswillcreateabiasinthe
parameter space. We illustrate this point with
the following example. Consider the decomposed
SU(2)gateV(θ) =RZ(θ3)RY(θ2)RZ(θ1)where
RA(θ) = exp{iθA}andA=X,Y,Z. This is the
ZYZ decomposition. Using similar techniques as
in App. F, we can rewrite V(θ)to be parameter-
ized in terms of the Lie algebra:
V(θ) = exp{iϕ·σ}, (15)
where σ= (X,Y,Z )and
ϕ=arccos(cos(θ2) cos(θ1+θ3))/radicalbig
1−cos2(θ2) cos2(θ1+θ3)
×
sin(θ2) sin(θ1−θ3)
sin(θ2) cos(θ1−θ3)
cos(θ2) sin(θ1+θ3)
.(16)
If we look at the components of ϕ, we see that
the different directions in the Lie algebra are
stretchedorcompressedasaresultoftheparticu-
lar choice of parameterization. Consider the nor-
malization|θ1|+|θ2|+|θ3|= 1fortheZYZdecom-
position and|θ|= 1for the SU(N)gate. With
each Hamiltonian term normalized to 1, the pref-
actor gives the evolution time. These choices of
norm give equal total evolution times for the ZYZ
decomposition and SU(2)gate,TZYZ=TSU(N)=√
2,irrespectiveofthespecificparameterschosen.
In Fig. 5, we graphically illustrate the Lie algebra
deformation by showing the ϕsurface for both
the ZYZ decomposition and SU(2)gate. Note
that we have not considered any cost function
here; the bias occurs at the level of the parame-
terization of a specific unitary.
The effect of this bias is demonstrated in Fig. 6
for the simplest case of a single-qubit system with
������
ZYZ decomposition
SU(2) (unbiased )
Figure 5: The total unitary evolution for the ZYZ de-
composition (red) and the SU(2)gate (blue) can be
expressed in the form exp{iϕ·σ}. The components
ϕ= (ϕ1,ϕ2,ϕ3)give the magnitude of the respective
basis generators σ= (X,Y,Z ). The original parame-
terization in θwith norm|θ1|+|θ2|+|θ3|= 1gives
a surface of possible values of ϕand therefore possible
unitary evolutions. The SU(2)gate (blue) is unbiased
because its parameterization gives the correspondence
θ=ϕwith normalization ϕ2
1+ϕ2
2+ϕ2
3= 1. The uni-
tary evolution for the ZYZ decomposition (red) is biased
because the surface in the ϕcoordinates does not main-
tain an equal magnitude in all directions.
anSU(2)gate. Theoptimalparametersofthecir-
cuit are those that produce the state that gives
the minimum of the cost function C(θ) =−⟨Y⟩
(green star). We consider various initial param-
eters acting on the reference state ρ=|0⟩⟨0|.
The corresponding training paths are shown for
each initial parameter vector. The training paths
for the decomposed ZYZ circuit are depicted in
Fig. 6(a). As the initial parameter θ0acting on
the reference state ρ(purple dots) moves closer to
an unstable equilibrium point (orange diamond)
the training path becomes increasingly subopti-
mal. At the unstable equilibrium the only gradi-
entinformationisdirectlyawayfromtheinstabil-
ity rather than providing information about the
direction towards the global minimum. This be-
havior is further illustrated by the gradient vec-
tor field on the Bloch sphere in Fig. 6(c). For the
SU(N)gate, we see in Fig. 6(b) that the opti-
mization trajectories follow a direct path to the
minimum.
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 7/angbracketleftx/angbracketright-1-0.500.51/angbracketlefty/angbracketright-1
-0.5
0
0.5
1/angbracketleftz/angbracketright
-1-0.500.51(a)
/angbracketleftx/angbracketright-1-0.500.51/angbracketlefty/angbracketright-1
-0.5
0
0.5
1/angbracketleftz/angbracketright
-1-0.500.51(b)
/angbracketleftx/angbracketright-1
-0.5
0
0.5
1
/angbracketlefty/angbracketright-1-0.500.51/angbracketleftz/angbracketright
-1-0.500.51(c)
/angbracketleftx/angbracketright-1
-0.5
0
0.5
1
/angbracketlefty/angbracketright-1-0.500.51/angbracketleftz/angbracketright
-1-0.500.51(d)Figure 6: Comparison of the update of circuit parameters from various initial parameters acting on the initial state
ρ=|0⟩⟨0|. The training paths are depicted on the Bloch sphere for: (a) parameterized single-qubit rotations for the
ZYZ ansatz; and (b) using the SU(N)gate. The purple dots represent initial states generated by applying U(θ0)with
θ0= (0,a,0)wherea∈/braceleftbigπ
64,π
8,2π
8,3π
8,π
2/bracerightbig
toρ. Note that for this choice of initial parameters, U(θ0) =V(θ0).
The objective function is C(θ) =−⟨Y⟩, giving the target final state at the green star—the state that gives the global
minimum of C(θ). The unstable equilibrium points are given by orange diamonds, at (0,0,1)and(0,0,−1), and the
black point is at the maximum of the cost function, (0,1,0). (c) shows the gradient vector field of the decomposed
ZYZ ansatz. The vector field for the SU(2)gate, shown in (d), coincides with the geodesic flow towards the target
final state at all points which satisfies the gate speed limit.
4.3 Numerical experiment
To investigate the effect on the performance of
a typical optimization, we study how an SU(N)
gate compares with a decomposed gate in a larger
circuit. In Fig. 7 we provide a non-trivial ex-
ample, where we incorporate our gates into a
circuit and show that it performs better than
a decomposed SU(4)gate on a set of random
problem instances. We show the individual op-
timization trajectories in Fig. 8 which illustrate
the faster optimization of SU(N)gates compared
to decomposed gates. Like for the examples in
Fig. 3 and Fig. 4, we assume that there is no
gate or measurement noise. Additionally, we as-
sume that we can always implement the gate
generated by Ωl(θ), and have control over all
Pauli operators Gm. In practice, we typically
only have access to a fixed set of generators
span({Gm})<span( su(N)). If this is the case,
then we require a decomposition of exp{tΩl(θ)}
in terms of the available operations on the de-
vice [14, 19]. All numerical results were obtained
with PennyLane [50], and the SU(N)gates can
be accessed via the qml.SpecialUnitary class.
Although we do not explore this here, one could
make use of sparse optimization methods such as
stochastic optimization [51, 52] and frugal opti-
mization [53] for the GPSR subroutine in our al-
gorithm.5 Resource estimation
To obtain the partial derivative in Eq. (11) in
practice we need to estimate the gradient of a
circuit that contains a gate generated by Ωl(θ).
As noted in recent works on GPSR rules [8, 7, 9],
the computational cost of estimating this gradi-
ent is related to the spectral gaps of Ωl(θ). In
particular, if{λj}is the set of (possibly degen-
erate) eigenvalues of Ωl(θ), we define the set of
unique spectral gaps as Γ ={/vextendsingle/vextendsingleλj−λj′/vextendsingle/vextendsingle}where
j′> j. Note that for ddistinct eigenvalues,
the number of unique spectral gaps Ris at most
R≤d(d−1)/2. The total number of parameter-
shifted circuits is then 2Rfor a single partial
derivative∂θlC(θ)
Depending on the generator Ωl(θ), this com-
plexity can be improved. For instance, in [7],
a Cartan decomposition is used to improve the
number of circuits required from polynomial to
linear or even logarithmic in N. Additionally,
in [8], the different costs for first- and second-
order gradients are determined for specific vara-
tional quantum algorithms like QAOA [54] and
RotoSolve [55, 56, 57, 58]. Finally, in [9], the
computational cost of a variety of different gates
is investigated in detail and the variance across
the parameter regime is studied.
Instead of focusing on specific instances of the
generator Ωl(θ), we make a more general ob-
servation about the computational complexity of
parameter-shift gradient rules. In general, Ωl(θ)
has full support on su(N), since the consecutive
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 80 2500 5000 7500 10000
Step−0.10−0.08−0.06−0.04−0.020.00∆¯E
/lscript= 1
/lscript= 3
/lscript= 5
Figure 7: Comparison of decomposed gates versus
SU(N)gates in brick-layer circuits for random 10-qubit
Hamiltoniansandvariousdepths. Weconsiderthebrick-
layer circuit indicated with ℓ= 2in the inset, with gen-
eral two-qubit gates acting on the even and odd qubits
in each layer. The decomposed gate is the SU(4)pa-
rameterization of [16], which is optimal in the number
of CNOTs required. For each instance, we sample a
Hamiltonian from the Gaussian unitary ensemble and
minimize the cost in Eq. (9) via standard gradient de-
scent. We show the difference of the relative errors
in energy ¯E= (E−Emin)/(Emax−Emin)between
the decomposed gates and the SU(N)gates, that is
∆¯E=¯ESU(N)−¯EDecomp.The plotted lines are the
mean ¯E,averagedover50randomHamiltoniansforeach
circuit depth ℓ. We see that for all depths ∆¯E < 0at
all points during the optimization, hence the brick-layer
circuit with the SU(N)gates outperforms the circuit
where the two-qubit interactions are parametrized as a
gate composition.
applications of adA(θ)in Eq. (3) typically gener-
ate all of su(N)[59]. However, for specific choices
ofA(θ), the application of adA(θ)pto∂θlA(θ)
closes to form a subalgebra, called the dynamical
Lie algebra of A(θ), that is contained in su(N).
These algebras are well-known in the context of
quantum optimal control [60, 61], and have re-
cently been studied in the context of variational
quantum algorithms [62, 63]. We define the dy-
namical Lie algebra (DLA) L(A(θ))as the sub-
algebra formed under the closure of the non-zero
terms inA(θ)under the commutator. Ignoring
global phases, this will always result in a sub-
algebraL(A(θ))⊆su(N). For example, given
A(θ) =i(aX+bY),∀a,b∈R,wehaveL(A(θ)) =
span{iX,iY,iZ}, since adX(Y) = [X,Y ] =iZ
andsuccessivecommutatorsgeneratenonewcon-
tributions. Note that for this example the DLA
0 2000 4000 6000 8000 10000
Step0.20.30.40.5¯EDecomp.
SU(N)Figure 8: Trajectories from the optimizations in Fig. 7
for 50 random 10-qubit Hamiltonians sampled from the
Gaussian unitary ensemble and an ℓ= 5brick-layer cir-
cuit of 2-qubit building blocks. We compare the rel-
ative error energy (see Fig. 7 for the definition of ¯E)
when using a standard gate composition to that when
using SU(4)gates as building blocks. The optimiza-
tion is performed with vanilla gradient descent using a
learning rate of η= 10−3. The SU(4)gate consistently
leads to faster optimization and better approximations
of the ground state energy throughout all 105optimiza-
tion steps.
equals the full Lie algebra su(2). Explicit con-
structions of DLAs that span so(N)andsp(N)
aregivenin[64]. Inamorerecentwork,theDLAs
of several typical quantum many-body Hamilto-
nians are studied and their properties are used to
prepare efficient time-evolution circuits [65]. In
one dimension, the DLAs that are generated by
Pauli strings have recently been classified [66].
Interestingly, if the DLA is maximal, i.e., there
exists no smaller non-trivial subalgebra within
L(A(θ)), then the rootsof the Lie algebra can
be related directly to the computational cost of
estimating the gradients in Eq. (11). We formally
establish this connection with the following the-
orem:
Theorem 2. The number of unique spectral gaps
RofΩl(θ)is upper bounded by the number of
roots|Φ|of any maximal semi-simple DLA,
R≤|Φ|/2. (17)
We provide the proof of Theorem 2 in App.
G. We make use of the fact that any semisim-
ple Lie algebra can be written as a direct sum
of its weight spaces, which can be identified with
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 9its root system [67]. The number of roots |Φ|
can then be used to bound the total number
of unique spectral gaps of Ωl(θ). We can thus
use Theorem 2 to assess the run time of Algo-
rithm1. Wegiveseveralexamplesof SU(N)gates
in App. G together with the corresponding val-
ues ofR. Depending on the physical system or
hardware that we are working with, we have to
choose a representation for su(N), which is a map
su(N)→gl(N,C). In Eq. (1) we chose this rep-
resentation to be the tensor product of the fun-
damental representation, i.e., Pauli monomials.
Note however, that Eq. (11) and Theorem 2 hold
for any irreducible representation of su(N).
Additionally, by connecting the spectral gaps
to the root system of the DLA, we can make use
of a beautiful result in representation theory: the
classification of all maximal subalgebras of the
classical Lie algebras [68]. Each root system can
be uniquely identified with a particular subalge-
bra of a Lie algebra and it can be shown that
there exist a finite number of root systems. Since
a DLA is a subalgebra of su(N), we can identify
all possible DLAs and by extension all possible
families of SU(N)gates. We provide examples of
this procedure in App. G.
6 Conclusion
We have proposed an alternative parameteriza-
tion of general SU(N)gates and a method of op-
timizing these gates in prototypical variational
quantum algorithms. We have shown that our
gates are more powerful in toy example settings,
and motivated why we believe this is the case
based on quantum speed-limit arguments. A nat-
ural extension of our work would be to test our
method in experimental settings, both on gate-
based quantum computers or quantum simula-
tors [69, 70, 71]. With regards to the latter, sev-
eral methods have been investigated that could
provide pulse-level optimization of energy cost
functions [72, 73]. This would obviate the need
for a gate-based model of quantum computing
to prepare specific states on quantum hardware.
Instead, we work on the Hamiltonian level and
control the system directly. Our algorithm could
be applied to this setting as well, since we’re ef-
fectively learning the parameters of some fixed
Hamiltonian.
Wehaveshownthatthe SU(N)gateinacircuitoutperforms a decomposed gate. The number of
parameters in our proposed gate equals 4Nqubits,
hence SU(N)gates acting on a large number of
qubits will be impractical. Additionally, it is not
clear for which problems one would rather have
a deeper circuit with simple gates as opposed to
a shallow circuit with more powerful gates. This
also begs another question: will our gates suffer
from barren plateaus [74]? It is likely that a cir-
cuit of 2-qubit SU(N)gates that has linear depth
inNwill lead to a circuit that forms an approx-
imate 2-design, which will suffer from vanishing
gradients. However, appropriate choices of the
generators A(θ)of our gate could keep the cir-
cuit in a polynomially scaling DLA of the entire
circuit, which can avoid barren plateaus [62, 63].
Additionally, we can consider parameter initial-
ization strategies that can improve the optimiza-
tion [75, 76].
Finally, we believe that the connections be-
tween variational quantum circuits and represen-
tation theory merit further investigation. We
connected the classification of all SU(N)gates
with the classification of semisimple Lie algebras.
However, this could possibly be extended to a
classification of all variational quantum circuits
based on the DLA of an ansatz. It seems that the
tools to provide such a classification are available
and could provide one with a method to assess
thetrainabilityandexpressivityofvariationalcir-
cuits without explicitly referring to specific an-
sätze.
7 Acknowledgements
We want to thank Los Alamos National Lab for
their hospitality during the Quantum Comput-
ing Summer School where the initial stages of
this project took place. RW wants to thank
Lex Kemper and Efekan Kökcü for discussions on
the subject of dynamical Lie algebras and Matt
Duchenes for his suggestions with regards to the
experimental implications of our work. DL ac-
knowledges support from the EPSRC Centre for
Doctoral Training in Delivering Quantum Tech-
nologies, grant ref. EP/S021582/1. JFCA ac-
knowledges support from the Natural Sciences
and Engineering Research Council (NSERC), the
Shared Hierarchical Academic Research Comput-
ing Network (SHARCNET), Compute Canada,
and the Canadian Institute for Advanced Re-
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 10search (CIFAR) AI chair program. Resources
used in preparing this research were provided,
in part, by the Province of Ontario, the Gov-
ernment of Canada through CIFAR, and com-
panies sponsoring the Vector Institute https:
//vectorinstitute.ai/#partners .
References
[1] M. Cerezo, Andrew Arrasmith, Ryan Bab-
bush, Simon C. Benjamin, Suguru Endo,
Keisuke Fujii, Jarrod R. McClean, Kosuke
Mitarai, Xiao Yuan, Lukasz Cincio, and
Patrick J. Coles. “Variational quantum al-
gorithms”. Nature Reviews Physics 3, 625–
644 (2021).
[2] Jules Tilly, Hongxiang Chen, Shuxiang Cao,
Dario Picozzi, Kanav Setia, Ying Li, Ed-
ward Grant, Leonard Wossnig, Ivan Rung-
ger, George H. Booth, and Jonathan Ten-
nyson. “The Variational Quantum Eigen-
solver: A review of methods and best prac-
tices”. Physics Reports 986, 1–128 (2022).
[3] Jun Li, Xiaodong Yang, Xinhua Peng, and
Chang-Pu Sun. “Hybrid Quantum-Classical
Approach to Quantum Optimal Control”.
Phys. Rev. Lett. 118, 150503 (2017).
[4] K. Mitarai, M. Negoro, M. Kitagawa, and
K. Fujii. “Quantum circuit learning”. Phys.
Rev. A98, 032309 (2018).
[5] Maria Schuld, Ville Bergholm, Christian
Gogolin, Josh Izaac, and Nathan Killoran.
“Evaluating analytic gradients on quantum
hardware”. Phys. Rev. A 99, 032331 (2019).
[6] Gavin E. Crooks. “Gradients of parame-
terized quantum gates using the parameter-
shift rule and gate decomposition” (2019)
arXiv:1905.13311.
[7] Artur F. Izmaylov, Robert A. Lang, and
Tzu-Ching Yen. “Analytic gradients in vari-
ational quantum algorithms: Algebraic ex-
tensions of the parameter-shift rule to gen-
eral unitary transformations”. Phys. Rev. A
104, 062443 (2021).
[8] David Wierichs, Josh Izaac, Cody Wang,
andCedricYen-YuLin. “Generalparameter-
shift rules for quantum gradients”. Quantum
6, 677 (2022).[9] OleksandrKyriienkoandVincentE.Elfving.
“Generalized quantum circuit differentiation
rules”. Phys. Rev. A 104, 052417 (2021).
[10] Dirk Oliver Theis. “"Proper" Shift Rules for
Derivatives of Perturbed-Parametric Quan-
tum Evolutions”. Quantum 7, 1052 (2023).
[11] Lucas Slattery, Benjamin Villalonga, and
BryanK.Clark. “Unitaryblockoptimization
for variational quantum algorithms”. Phys.
Rev. Research 4, 023072 (2022).
[12] Jin-Guo Liu, Yi-Hong Zhang, Yuan Wan,
and Lei Wang. “Variational quantum eigen-
solver with fewer qubits”. Phys. Rev. Re-
search1, 023025 (2019).
[13] Abhinav Kandala, Antonio Mezzacapo,
Kristan Temme, Maika Takita, Markus
Brink, Jerry M. Chow, and Jay M. Gam-
betta. “Hardware-efficient variational quan-
tum eigensolver for small molecules and
quantum magnets”. Nature 549, 242–
246 (2017).
[14] Navin Khaneja and Steffen J. Glaser. “Car-
tan decomposition of SU(2n)and control of
spin systems”. Chemical Physics 267, 11–
23 (2001).
[15] Barbara Kraus and Juan I Cirac. “Optimal
creation of entanglement using a two-qubit
gate”. Physical Review A 63, 062309 (2001).
[16] Farrokh Vatan and Colin Williams. “Opti-
mal quantum circuits for general two-qubit
gates”. Phys. Rev. A 69, 032315 (2004).
[17] Farrokh Vatan and Colin P Williams. “Re-
alization of a general three-qubit quantum
gate” (2004). arXiv:quant-ph/0401178.
[18] Juha J. Vartiainen, Mikko Möttönen, and
Martti M. Salomaa. “Efficient Decomposi-
tion of Quantum Gates”. Phys. Rev. Lett.
92, 177902 (2004).
[19] Domenico D’Alessandro and Raffaele Ro-
mano. “Decompositions of unitary evolu-
tions and entanglement dynamics of bipar-
tite quantum systems”. Journal of Mathe-
matical Physics 47, 082109 (2006).
[20] Alwin Zulehner and Robert Wille. “Compil-
ing SU(4) Quantum Circuits to IBM QX Ar-
chitectures”. In Proceedings of the 24th Asia
and South Pacific Design Automation Con-
ference. Page 185–190. ASPDAC ’19New
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 11York,NY,USA(2019).AssociationforCom-
puting Machinery.
[21] B. Foxen, C. Neill, A. Dunsworth,
P. Roushan, B. Chiaro, A. Megrant, J. Kelly,
Zijun Chen, K. Satzinger, R. Barends,
F. Arute, K. Arya, R. Babbush, D. Bacon,
J. C. Bardin, S. Boixo, D. Buell, B. Burkett,
Yu Chen, R. Collins, E. Farhi, A. Fowler,
C. Gidney, M. Giustina, R. Graff, M. Har-
rigan, T. Huang, S. V. Isakov, E. Jeffrey,
Z. Jiang, D. Kafri, K. Kechedzhi, P. Klimov,
A. Korotkov, F. Kostritsa, D. Landhuis,
E. Lucero, J. McClean, M. McEwen, X. Mi,
M. Mohseni, J. Y. Mutus, O. Naaman,
M. Neeley, M. Niu, A. Petukhov, C. Quin-
tana, N. Rubin, D. Sank, V. Smelyanskiy,
A. Vainsencher, T. C. White, Z. Yao,
P. Yeh, A. Zalcman, H. Neven, and J. M.
Martinis. “Demonstrating a Continuous
Set of Two-Qubit Gates for Near-Term
Quantum Algorithms”. Phys. Rev. Lett.
125, 120504 (2020).
[22] E Groeneveld. “A reparameterization to im-
prove numerical optimization in multivari-
ate REML (co) variance component estima-
tion”. Genetics Selection Evolution 26, 537–
545 (1994).
[23] Tapani Raiko, Harri Valpola, and Yann Le-
cun. “Deep learning made easier by lin-
ear transformations in perceptrons”. In
Neil D. Lawrence and Mark Girolami, edi-
tors, Proceedings of the Fifteenth Interna-
tional Conference on Artificial Intelligence
and Statistics. Volume 22 of Proceedings
of Machine Learning Research, pages 924–
932. La Palma, Canary Islands (2012).
PMLR. url: https://proceedings.mlr.
press/v22/raiko12.html .
[24] Sergey Ioffe and Christian Szegedy. “Batch
normalization: Accelerating deep network
trainingbyreducinginternalcovariateshift”.
In International conference on machine
learning. Pages 448–456. PMLR (2015).
[25] Tim Salimans and Durk P Kingma. “Weight
normalization: A simple reparameterization
to accelerate training of deep neural net-
works”. In Advances in neural information
processing systems. Volume 29. (2016).
[26] Robert Price. “A useful theorem for non-
linear devices having Gaussian inputs”. IRETransactions on Information Theory 4, 69–
72 (1958).
[27] Danilo Jimenez Rezende, Shakir Mohamed,
and Daan Wierstra. “Stochastic back-
propagation and approximate inference in
deep generative models”. In Eric P.
Xing and Tony Jebara, editors, Proceed-
ings of the 31st International Conference
on Machine Learning. Volume 32 of Pro-
ceedings of Machine Learning Research,
pages 1278–1286. Bejing, China (2014).
PMLR. url: https://proceedings.mlr.
press/v32/rezende14.html .
[28] Diederik P. Kingma and Max Welling.
“Auto-Encoding Variational Bayes”. In
Yoshua Bengio and Yann LeCun, editors,
2nd International Conference on Learning
Representations, ICLR 2014, Banff, AB,
Canada,April14-16, 2014,ConferenceTrack
Proceedings. (2014). url: http://arxiv.
org/abs/1312.6114 .
[29] Brian C Hall. “Lie groups, Lie algebras, and
representations”. Springer. (2013). 2nd edi-
tion.
[30] William Fulton and Joe Harris. “Represen-
tation theory: a first course”. Volume 129.
Springer Science & Business Media. (2013).
[31] W. Rossmann. “Lie Groups: An Introduc-
tionThroughLinearGroups”. Oxfordgradu-
ate texts in mathematics. Oxford University
Press. (2002). 5th edition.
[32] Jean-Pierre Serre. “Lie algebras and Lie
groups: 1964 lectures given at Harvard Uni-
versity”. Springer. (2009).
[33] Norbert Schuch and Jens Siewert. “Natural
two-qubit gate for quantum computation us-
ing the XYinteraction”. Phys. Rev. A 67,
032301 (2003).
[34] T. P. Orlando, J. E. Mooij, Lin Tian, Cas-
par H. van der Wal, L. S. Levitov, Seth
Lloyd, and J. J. Mazo. “Superconducting
persistent-current qubit”. Phys. Rev. B 60,
15398–15413 (1999).
[35] B. E. Kane. “A silicon-based nuclear spin
quantum computer”. Nature 393, 133–
137 (1998).
[36] A. Imamog ¯lu, D. D. Awschalom,
G. Burkard, D. P. DiVincenzo, D. Loss,
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 12M. Sherwin, and A. Small. “Quantum
information processing using quantum dot
spins and cavity qed”. Phys. Rev. Lett. 83,
4204–4207 (1999).
[37] Jiaqi Leng, Yuxiang Peng, Yi-Ling Qiao,
Ming Lin, and Xiaodi Wu. “Differentiable
Analog Quantum Computing for Optimiza-
tion and Control” (2022). arXiv:2210.15812.
[38] R. M. Wilcox. “Exponential Opera-
tors and Parameter Differentiation in
Quantum Physics”. Journal of Math-
ematical Physics 8, 962–982 (1967).
arXiv:https://doi.org/10.1063/1.1705306.
[39] E. T. Whittaker. “XVIII.—On the Func-
tions which are represented by the Expan-
sions of the Interpolation-Theory”. Proceed-
ings of the Royal Society of Edinburgh 35,
181–194 (1915).
[40] James Bradbury, Roy Frostig, Peter
Hawkins, Matthew James Johnson, Chris
Leary, Dougal Maclaurin, George Necula,
Adam Paszke, Jake VanderPlas, Skye
Wanderman-Milne, and Qiao Zhang (2018).
code: google/jax.
[41] Adam Paszke, Sam Gross, Francisco Massa,
Adam Lerer, James Bradbury, Gregory
Chanan, TrevorKilleen, ZemingLin, Natalia
Gimelshein, Luca Antiga, et al. “Pytorch:
An imperative style, high-performance deep
learning library”. In Advances in neural in-
formation processing systems. Volume 32.
(2019).
[42] Martín Abadi, Ashish Agarwal, Paul
Barham, Eugene Brevdo, Zhifeng Chen,
Craig Citro, Greg S. Corrado, Andy Davis,
Jeffrey Dean, Matthieu Devin, Sanjay Ghe-
mawat, Ian Goodfellow, Andrew Harp,
Geoffrey Irving, Michael Isard, Yangqing
Jia, Rafal Jozefowicz, Lukasz Kaiser, Man-
junath Kudlur, Josh Levenberg, Dande-
lion Mané, Rajat Monga, Sherry Moore,
Derek Murray, Chris Olah, Mike Schus-
ter, Jonathon Shlens, Benoit Steiner, Ilya
Sutskever, Kunal Talwar, Paul Tucker, Vin-
cent Vanhoucke, Vijay Vasudevan, Fer-
nanda Viégas, Oriol Vinyals, Pete War-
den, Martin Wattenberg, Martin Wicke,
Yuan Yu, and Xiaoqiang Zheng (2015).
code: https://www.tensorflow.org/.[43] A JAX implementation of the ma-
trix exponential that can be differ-
entiated via automatic differentia-
tion: https://jax.readthedocs.io/
en/latest/_autosummary/jax.scipy.
linalg.expm.html .
[44] Awad H Al-Mohy and Nicholas J Higham.
“A new scaling and squaring algorithm for
the matrix exponential”. SIAM Journal on
Matrix Analysis and Applications 31, 970–
989 (2010).
[45] Leonardo Banchi and Gavin E. Crooks.
“Measuring Analytic Gradients of General
Quantum Evolution with the Stochastic Pa-
rameter Shift Rule”. Quantum 5, 386 (2021).
[46] Lennart Bittel, Jens Watty, and Mar-
tin Kliesch. “Fast gradient estimation
for variational quantum algorithms” (2022).
arXiv:2210.06484.
[47] Roeland Wiersema, Dylan Lewis, David
Wierichs, Juan Carrasquilla, and Nathan
Killoran (2023). code: dwierichs/Here-
comes-the-SUN.
[48] Thomas Schulte-Herbrüggen, Steffen j.
Glaser, Gunther Dirr, and Uwe Helmke.
“Gradient Flows for Optimization in Quan-
tum Information and Quantum Dynamics:
Foundations and Applications”. Reviews in
Mathematical Physics 22, 597–667 (2010).
[49] Roeland Wiersema and Nathan Killoran.
“Optimizing quantum circuits with rieman-
nian gradient flow” (2023).
[50] Ville Bergholm, Josh Izaac, Maria Schuld,
Christian Gogolin, M Sohaib Alam, Shah-
nawaz Ahmed, Juan Miguel Arrazola,
Carsten Blank, Alain Delgado, Soran Ja-
hangiri, et al. “Pennylane: Automatic differ-
entiation of hybrid quantum-classical com-
putations” (2018). arXiv:1811.04968.
[51] Ryan Sweke, Frederik Wilde, Johannes
Meyer, Maria Schuld, Paul K. Faehrmann,
Barthélémy Meynard-Piganeau, and Jens
Eisert. “Stochastic gradient descent for hy-
brid quantum-classical optimization”. Quan-
tum4, 314 (2020).
[52] Aram W. Harrow and John C. Napp. “Low-
Depth Gradient Measurements Can Im-
prove Convergence in Variational Hybrid
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 13Quantum-Classical Algorithms”. Phys. Rev.
Lett.126, 140502 (2021).
[53] Andrew Arrasmith, Lukasz Cincio,
Rolando D Somma, and Patrick J Coles.
“Operator sampling for shot-frugal opti-
mization in variational algorithms” (2020).
arXiv:2004.06252.
[54] Edward Farhi, Jeffrey Goldstone, and
Sam Gutmann. “A quantum approx-
imate optimization algorithm” (2014).
arXiv:1411.4028.
[55] Javier Gil Vidal and Dirk Oliver Theis.
“Calculus on parameterized quantum cir-
cuits” (2018). arXiv:1812.06323.
[56] Robert M Parrish, Joseph T Iosue, Asier
Ozaeta, and Peter L McMahon. “A Ja-
cobi diagonalization and Anderson accel-
eration algorithm for variational quantum
algorithm parameter optimization” (2019).
arXiv:1904.03206.
[57] Ken M. Nakanishi, Keisuke Fujii, and Synge
Todo. “Sequential minimal optimization for
quantum-classical hybrid algorithms”. Phys.
Rev. Res. 2, 043158 (2020).
[58] Mateusz Ostaszewski, Edward Grant, and
Marcello Benedetti. “Structure optimization
for parameterized quantum circuits”. Quan-
tum5, 391 (2021).
[59] Seth Lloyd. “Universal quantum simulators”.
Science273, 1073–1078 (1996).
[60] F. Albertini and D. D’Alessandro. “Notions
of controllability for quantum mechanical
systems”. In Proceedings of the 40th IEEE
Conference on Decision and Control (Cat.
No.01CH37228). Volume 2, pages 1589–1594
vol.2. (2001).
[61] Domenico d’Alessandro. “Introduction to
quantum control and dynamics”. Chapman
and hall/CRC. (2021). 2nd edition.
[62] Martin Larocca, Piotr Czarnik, Kunal
Sharma, Gopikrishnan Muraleedharan,
Patrick J. Coles, and M. Cerezo. “Diag-
nosing Barren Plateaus with Tools from
Quantum Optimal Control”. Quantum 6,
824 (2022).
[63] Martín Larocca, Nathan Ju, Diego García-
Martín, Patrick J. Coles, and Marco Cerezo.
“Theory of overparametrization in quantumneural networks”. Nature Computational
Science3, 542–551 (2023).
[64] S G Schirmer, I C H Pullen, and A I
Solomon. “Identification of dynamical Lie
algebras for finite-level quantum control sys-
tems”. Journal of Physics A: Mathematical
and General 35, 2327 (2002).
[65] Efekan Kökcü, Thomas Steckmann, Yan
Wang, J. K. Freericks, Eugene F. Du-
mitrescu, and Alexander F. Kemper. “Fixed
depth hamiltonian simulation via cartan
decomposition”. Phys. Rev. Lett. 129,
070501 (2022).
[66] Roeland Wiersema, Efekan Kökcü, Alexan-
der F Kemper, and Bojko N Bakalov.
“Classification of dynamical lie algebras for
translation-invariant 2-local spin systems in
one dimension” (2023). arXiv:2203.05690.
[67] Jean-Pierre Serre. “Complex semisimple Lie
algebras”. Springer Science & Business Me-
dia. (2000). 1st edition.
[68] Eugene Borisovich Dynkin. “American
MathematicalSocietyTranslations: FivePa-
pers on Algebra and Group Theory”. Amer-
ican Mathematical Society. (1957).
[69] I. M. Georgescu, S. Ashhab, and Franco
Nori. “Quantum simulation”. Rev. Mod.
Phys.86, 153–185 (2014).
[70] Sepehr Ebadi, Tout T Wang, Harry
Levine, Alexander Keesling, Giulia Semegh-
ini, Ahmed Omran, Dolev Bluvstein, Rhine
Samajdar, Hannes Pichler, Wen Wei Ho,
et al. “Quantum phases of matter on a
256-atom programmable quantum simula-
tor”. Nature 595, 227–232 (2021).
[71] P.Scholl, H.J.Williams, G.Bornet, F.Wall-
ner, D. Barredo, L. Henriet, A. Signoles,
C. Hainaut, T. Franz, S. Geier, A. Tebben,
A. Salzinger, G. Zürn, T. Lahaye, M. Wei-
demüller, and A. Browaeys. “Microwave En-
gineering of Programmable XXZHamilto-
nians in Arrays of Rydberg Atoms”. PRX
Quantum 3, 020303 (2022).
[72] Mohannad Ibrahim, Hamed Mohammad-
bagherpoor, Cynthia Rios, Nicholas T
Bronn, and Gregory T Byrd. “Pulse-
Level Optimization of Parameterized Quan-
tum Circuits for Variational Quantum Algo-
rithms” (2022). arXiv:2211.00350.
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 14[73] Oinam Romesh Meitei, Bryan T. Gard,
George S. Barron, David P. Pappas,
Sophia E. Economou, Edwin Barnes, and
Nicholas J. Mayhall. “Gate-free state prepa-
ration for fast variational quantum eigen-
solver simulations”. npj Quantum Informa-
tion7, 155 (2021).
[74] Jarrod R McClean, Sergio Boixo, Vadim N
Smelyanskiy, Ryan Babbush, and Hartmut
Neven. “Barren plateaus in quantum neural
network training landscapes”. Nature com-
munications 9, 1–6 (2018).
[75] Edward Grant, Leonard Wossnig, Mateusz
Ostaszewski, and Marcello Benedetti. “An
initialization strategy for addressing barren
plateaus in parametrized quantum circuits”.
Quantum 3, 214 (2019).
[76] Andrea Skolik, Jarrod R McClean, Masoud
Mohseni, Patrick van der Smagt, and Mar-
tin Leib. “Layerwise learning for quantum
neural networks”. Quantum Machine Intelli-
gence3, 1–11 (2021).
[77] Rüdiger Achilles and Andrea Bonfiglioli.
“The early proofs of the theorem of Camp-
bell, Baker, Hausdorff, andDynkin”. Archive
for History of Exact Sciences 66, 295–
358 (2012).
[78] Mario Lezcano-Casado and David Martınez-
Rubio. “Cheap orthogonal constraints in
neural networks: A simple parametrization
of the orthogonal and unitary group”. In
International Conference on Machine Learn-
ing. Pages 3794–3803. PMLR (2019).
[79] Andrea Mari, Thomas R. Bromley, and
Nathan Killoran. “Estimating the gradi-
ent and higher-order derivatives on quan-
tum hardware”. Phys. Rev. A 103,
012405 (2021).
[80] Benjamin Russell and Susan Stepney. “Ge-
ometric Methods for Analysing Quantum
Speed Limits: Time-Dependent Controlled
Quantum Systems with Constrained Con-
trol Functions”. In Giancarlo Mauri, Alberto
Dennunzio, Luca Manzoni, and Antonio E.
Porreca, editors, Unconventional Computa-
tion and Natural Computation. Pages 198–
208. Lecture Notes in Computer ScienceBer-
lin, Heidelberg (2013). Springer.[81] Andreas Arvanitoge¯ orgos. “An introduction
to Lie groups and the geometry of homoge-
neous spaces”. Volume 22. American Math-
ematical Soc. (2003).
[82] S Helgason. “Differential geometry, lie
groups, and symmetric spaces”. American
Mathematical Soc. (1978).
[83] JamesEHumphreys. “IntroductiontoLieal-
gebrasandrepresentationtheory”. Volume9.
Springer Science & Business Media. (2012).
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 15ASU(N)and its Lie algebra
Consider the special unitary Lie group SU(N):
SU(N) ={X∈CN×N|X†X=I,det{X}= 1}. (A1)
In general, quantum gates belong to the unitary group U(N), which drops the determinant 1 condition
and thus allows for an additional global phase. Restricting ourselves to SU(N)therefore is physically
equivalent. Consider a curve X(t) :R→SU(N),t∈(−1,1)such thatX(0) =Iandd/dtX (t)|t=0≡
˙X(0) = Ω. If we differentiate the unitarity condition with respect to t, we obtain
d
dt(X†(t)X(t))/vextendsingle/vextendsingle
t=0= 0, (A2)
˙X†(t)X(t) +X†(t)˙X(t)|t=0= 0 (A3)
Ω†+ Ω = 0, (A4)
and so we find that Ω†=−Ω, i.e., Ωis a skew-Hermitian matrix. The matrices Ωfrom all such curves
are elements of the Lie algebra
su(N) ={Ω∈CN×N|Ω†=−Ω,Tr{Ω}= 0}. (A5)
The second condition, Tr{Ω}= 0, can be found by realizing that the Lie algebra is connected to a Lie
group via the exponential map: etX∈SU(N),∀t∈RandX∈su(N)and so 1 = det/braceleftig
eX/bracerightig
=eTr{X}.
Instead of considering a curve going through the identity at t= 0, we can consider a curve going
through a point Uwith directional derivative Ω. All curves X(t)with directional derivative Ωat the
pointUform an equivalence class. The set of these equivalence classes forms a vector space called the
tangent space TUSU(N)at the point U, and in particular we may identify TISU(N) =su(N). The
group product LU, i.e., left multiplication by an element U, is a local homeomorphism, which induces a
linear map between two tangent spaces: d(LU)|V:TVSU(N)→TLU(V)SU(N)whereU,V∈SU(N).
d(LU)is called the differential of LU. If we take V=Ito be the identity, then we see that we can move
from the tangent space at the identity to the tangent space at any point in SU(N)by left multiplication
of the group d(LU)|I:su(N)→TUSU(N). Hence the tangent space at Uis given by
TUSU(N) ={UΩ|Ω∈su(N)}. (A6)
The above derivation can provide us with a different understanding of a what the Lie algebra is.
Starting from the group SU(N), we can consider all left-invariant vector fields XonSU(N),
d(LU)|V(XV) =X|U·V (A7)
whereX∈X(SU(N)), which is the space of vector fields on SU(N). The left-invariant vector fields
form a vector and since they are closed under the Lie bracket [X,Y ], they define a Lie algebra.
B The exponential map and its gradient
The following is due to [31, Chapter 1, Theorem 5]. Let Gbe a matrix Lie group G∈GL(N,C)with a
corresponding Lie algebra g. Define conjugation by h∈Gto be the transformation ch:G→Ggiven
bych(g) =hgh−1. Note that cis an (inner) automorphism of G, since it is a isomorphism from Gonto
itself. Let exp : g→Gbe the exponential map from the Lie algebra to the group. Taking X∈gand
t∈R, the differential of the conjugation map at the identity is
d(ch)(X) =d
dt(hetXh−1)/vextendsingle/vextendsingle/vextendsingle/vextendsingle
t=0=hXh−1, (B1)
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 1which maps an element of the Lie algebra to another element of the Lie algebra. This map is called
the adjoint representation Adh:g→gand takesX∝⇕⊣√∫⊔≀→hXh−1. GivenX,Y∈g, we compute
d
dtAdetXY/vextendsingle/vextendsingle/vextendsingle/vextendsingle
t=0=d
dtetXYe−tX/vextendsingle/vextendsingle/vextendsingle/vextendsingle
t=0(B2)
=XY−YX (B3)
= [X,Y ] (B4)
= adXY. (B5)
The operator ad :g×g→gis the Lie bracket on g, which for our purposes will be the standard
commutator. It now follows that
d
dtAdetXY=d
dt/parenleftig
etXYe−tX/parenrightig
(B6)
=XetXYe−tX+etXYe−tX(−X) (B7)
= adX(AdetXY). (B8)
With the boundary condition AdetX|t=0= Idwe find that the above differential equation is solved by
AdeX=eadX (B9)
att= 1. Consider now the following parameterized matrix function Y:R×R→G,
Y(s,t) =e−sX(t)∂
∂tesX(t), (B10)
whereX(t)is a curve on g. We then find
∂Y(s,t)
∂s=e−sX(t)(−X(t))∂
∂tesX(t)+e−sX(t)∂
∂t(X(t)esX(t)) (B11)
=−e−sX(t)X(t)∂
∂tesX(t)+e−sX(t)X(t)∂
∂tesX(t)+e−sX(t)dX(t)
dtesX(t)(B12)
=e−sX(t)dX(t)
dtesX(t)(B13)
= Ade−sX(t)dX(t)
dt. (B14)
Then with equation Eq. (B9), we find
∂Y(s,t)
∂s=e−adsX(t)dX(t)
dt. (B15)
Using that Y(0,t) = 0, we find by integration
Y(1,t) =/integraldisplay1
0ds∂Y(s,t)
∂s. (B16)
Estimating the above integral forms the basis of the stochastic parameter-shift rule (see App. 1).
Continuing,
Y(1,t) =/integraldisplay1
0ds∞/summationdisplay
n=0(−1)nsn
n!(adX)ndX(t)
dt(B17)
=/bracketleftigg∞/summationdisplay
n=0(−1)nsn+1
(n+ 1)!(adX)n/bracketrightiggs=1
s=0dX(t)
dt(B18)
=/parenleftigg∞/summationdisplay
n=0(−1)n
(n+ 1)!(adX)n/parenrightigg
dX(t)
dt. (B19)
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 2Hence we see that
d
dteX(t)=eX(t)Y(1,t) =eX(t)/parenleftigg∞/summationdisplay
n=0(−1)n
(n+ 1)!(adX)n/parenrightigg
dX(t)
dt, (B20)
which gives Eq. (3).
Note that at this point the Baker-Campbell-Hausdorff formula can be derived with Eq. (B20) by
considering the derivative of
eZ(t)=etXetY, (B21)
and subsequent integration of the derivative of Z(t)[77].
C Connection between Riemannian and standard gradient flow on SU(N)
Here, we highlight the connection between a Riemannian gradient flow on SU(N)with respect and
Eq. (11) [48, 49]. We take the Hilbert-Schmidt inner product ⟨A,B⟩= Tr/braceleftig
A†B/bracerightig
as a Riemannian
metric on SU(N)and write the cost as
C(U) = Tr/braceleftig
UρU†H/bracerightig
. (C1)
The differential of the cost dC(U) :TUSU(N)→R, evaluated at the point UΩ, where Ω∈su(N)and
U∈SU(N), is then
dC(U)(UΩ) =d(Tr)(UρU†H)◦d(UρU†H)(UΩ) (C2)
= Tr/braceleftig
d(U)ρU†H+Uρd(U†)H/bracerightig
(UΩ) (C3)
= Tr/braceleftig
UΩρU†H+UρΩ†U†H/bracerightig
(C4)
= Tr/braceleftig
ρU†HUΩ−U†HUρ Ω/bracerightig
(C5)
= Tr/braceleftig/bracketleftig
ρ,U†HU/bracketrightig
Ω/bracerightig
(C6)
=⟨−U/bracketleftig
ρ,U†HU/bracketrightig
,UΩ⟩ (C7)
via the chain rule and using that ⟨A,B⟩=⟨UA,UB⟩. The compatibility condition for the Riemannian
gradient tells us that
dC(U)(UΩ) =⟨gradC(U),UΩ⟩. (C8)
Hence we can identify
gradC(U) =−U/bracketleftig
ρ,U†HU/bracketrightig
(C9)
with the corresponding gradient flow
˙U=gradC(U). (C10)
Next, we follow the results of [78] in our notation. Consider the cost function
C(X) = Tr/braceleftig
eXρe−XH/bracerightig
(C11)
whereX∈su(N). Notethatalthoughtheminimumofthefunctionisunchanged, theparameterization
of a unitary via the Lie algebra changes the resulting gradient flow. To see this, we consider again the
differential,
d(C◦expX)(A) =d(Tr)(eXρe−XH)◦d(eXρe−XH)(A) (C12)
= Tr/braceleftig
d(eX)ρU†H+Uρd(e−X)H/bracerightig
(A), (C13)
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 3where nowd(C◦expX) :su(N)→RandA∈su(N). We can now make use of the result in Eq. (B20),
d(eX)(Y) =eX/parenleftigg∞/summationdisplay
n=0(−1)n
(n+ 1)!(adX)n/parenrightigg
(Y) (C14)
=eXΦX(Y) (C15)
to obtain
d(C◦expX)(A) = Tr/braceleftig
eXΦX(A)ρe−XH+eXρΦ†
X(A)e−XH/bracerightig
. (C16)
Using that Φ†
X(A) =−ΦX(A)andΦ†
X(ΦX(A)) =A, we then have
d(C◦expX)(A) = Tr/braceleftig/bracketleftig
ρ,e−XHeX/bracketrightig
ΦX(A)/bracerightig
(C17)
=⟨−/bracketleftig
ρ,e−XHeX/bracketrightig
,ΦX(A)⟩ (C18)
=⟨ΦX(/bracketleftig
ρ,e−XHeX/bracketrightig
),A⟩. (C19)
Hence the gradient on su(N)is
gradC(X) = ΦX(/bracketleftig
ρ,e−XHeX/bracketrightig
). (C20)
We therefore see that only when ΦX=Ido we obtain the Riemannian gradient on SU(N); hence
only ifX∈gwhere gis abelian. The optimization path followed by optimizing the parameters of an
SU(N)gate is thus different from the one following a Riemannian gradient descent on SU(N).
D The generalized parameter-shift rule
When using our SU(N)gate in an application that involves gradient-based optimization, like demon-
strated in the numerical experiments in this work, we require calculating the partial derivatives in
Eq. (11). Here we provide the details for how this can be achieved in practice via the generalized
parameter-shift rule (GPSR) [8, 7, 9]. Without loss of generality, we rewrite the cost function in
Eq. (9) as
C(t) = Tr/braceleftig˜HetΩ˜ρe−tΩ/bracerightig
, (D1)
where we absorbed the rest of the circuit into ˜ρ,˜Hand fixed any other parameters in the circuit.
Computing the derivative of Eq. (D1) with respect to tis equivalent to the problem of finding the
gradient in Eq. (11) at t= 0. For the numerical experiments in this paper we make use of the
particular implementation of the GPSR in [9] as well as the alternative method outlined in App. 3.
The skew-Hermitian operator Ωin Eq. (D1) has (possibly degenerate) eigenvalues {iλj}. We define
the set of unique spectral gaps as Γ ={/vextendsingle/vextendsingleλj−λj′/vextendsingle/vextendsingle}wherej′>j. Note that for ddistinct eigenvalues,
the number of unique spectral gaps Ris bounded via R≤d(d−1)/2. We relabel every unique spectral
gap with an integer, i.e. we write ∆r∈Γ, and define the corresponding vector ∆= (∆ 1,..., ∆R).
We pick a set of parameter shifts that are equidistant and create a vector of Rshifts δ= (δ1,...,δR)
where
δn=(2n−1)π
4R, n = 1,...,R. (D2)
Next, we create the length Rcost vector cand theR×Rmatrix M
c=
C(δ1)−C(−δ1)
C(δ2)−C(−δ2)
...
C(δR)−C(−δR)
,M(δ) =
2 sin(δ1∆1)... 2 sin(δ1∆R)
2 sin(δ2∆1)... 2 sin(δ2∆R)
.........
2 sin(δR∆1)...2 sin(δR∆R)
. (D3)
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 4We then calculate the coefficient vector as
r= (M( δ))−1·c, (D4)
which finally gives the gradient
dC(x)
dt/vextendsingle/vextendsingle/vextendsingle/vextendsingle
t=0=∆·r. (D5)
Since the final gradient is exact, finite shot estimates of all c(δn)’s will produce an unbiased estimate
ofdC(x)/dt,
dC(x)
dt/vextendsingle/vextendsingle/vextendsingle/vextendsingle
t=0=∆·(M(δ))−1·E[c], (D6)
where we pulled out ∆and(M(δ))−1since they are constant. The difficulty of obtaining an accurate
estimate of the gradient is determined by the variance of this estimator, which is given by
Var/bracketleftigg
dC(x)
dt/vextendsingle/vextendsingle/vextendsingle/vextendsingle
t=0/bracketrightigg
= (∆·(M(δ))−1)⊙2·/parenleftig
E/bracketleftig
c⊙2/bracketrightig
−E[c]⊙2/parenrightig
, (D7)
where we used⊙2to emphasize that the squares are taken elementwise. We assume that the estimates
for each shifted circuit obey normal statistics and so since these are independent, we can write
E/bracketleftig
c⊙2/bracketrightig
−E[c]⊙2≈1
Nshots
σ2(δ1) +σ2(−δ1)
σ2(δ2) +σ2(−δ2)
...
σ2(δR) +σ2(−δR)
, (D8)
whereσ2(±δn)is the variance of the cost for each shifted circuit. If we assume that the dependence
ofσon the shifts is mild, i.e., σ(δ)≈σ0then the total variance will only depend on the prefactor.
Setting the estimate E/bracketleftbigc⊙2/bracketrightbig−E[c]⊙2= (σ2
0,σ2
0,...,σ2
0)then finally gives
Var/bracketleftigg
dC(x)
dt/vextendsingle/vextendsingle/vextendsingle/vextendsingle
t=0/bracketrightigg
≈2σ2
0/parenleftigg/summationdisplay
n∆nM−1
nm(δ)/parenrightigg2
. (D9)
One can minimize this quantity with respect to δto find the optimal set of shifts for the gradient
estimation [9].
E Alternative differentiation of SU(N)gates
In this section we summarize a number of alternative differentiation techniques that may be applied
to the presented SU(N)gates. In particular, we discuss the stochastic parameter-shift rule, which
was created for multi-parameter gates, finite differences as a standard tool in numerical differentiation,
as well as an alternative to the general parameter-shift rule above which also exploits the notion of
effective generators.
1 The Stochastic parameter-shift rule
The stochastic parameter-shift rule [6] relies on the following operator identity [38]
∂eZ(x)
∂x=/integraldisplay1
0dsesZ(x)∂Z(x)
∂xe(1−s)Z(x), (E1)
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 5for any bounded operator Z(x). We now fix all parameters θmform̸=land rewrite the cost in Eq. (9)
as
c(x) = Tr/braceleftig
Hei(xGl+A′)ρe−i(xGl+A′)/bracerightig
, A′≡/summationdisplay
m̸=lθmGm. (E2)
Then, if we take Z(x)to be the operator Z(x) =i(xGl+A′)we can construct the gradient of Eq. (E2)
as
∂c(x)
∂x=/integraldisplay1
0ds(C+(x,s)−C−(x,s)), (E3)
where
C±(x,s) = Tr/braceleftig
HV±(x)ρV†
±(x)/bracerightig
(E4)
V±(x) =eis(xGl+A′)e±π
4Glei(1−s)(xGl+A′). (E5)
Hence,similartoourmethod,thegradientevaluationrequiresaddinggatestothecircuitandevaluating
the new circuit. However, the stochastic parameter-shift rule comes at a significant cost: the evaluation
oftheintegralinEq.(E3). Inpractice, oneapproximatesthisintegralbysamplingvaluesof suniformly
in the interval (0,1)and then calculating the costs C±(x,s)with a finite-shot estimate. Although this
produces an unbiased estimator, we find that the variance of this estimator is larger than ours, see
Fig. 4. In addition, this method leads to a bigger number of unique circuits to compute the derivative,
increasing the compilation overhead for both hardware and simulator implementations.
2 Finite differences
Finite differences are widely used to differentiate functions numerically. We briefly discuss this method
in the context of variational quantum computation (VQC) and refer the reader to recent works com-
paring and optimizing differentiation techniques for VQC [79, 46].
In particular, we consider the central difference recipe
∂FD,θjC(θ) =1
δ/bracketleftbigg
C/parenleftbigg
θ+δ
2ej/parenrightbigg
−C/parenleftbigg
θ−δ
2ej/parenrightbigg/bracketrightbigg
, (E6)
whereδis a freely chosen shift parameter and ejis thejth canonical basis vector. This recipe is an
approximation of ∂θjC(θ), making the corresponding estimator on a shot-based quantum computer
biased. This bias, which depends on δ, has to be traded off against the variance of the estimator, which
grows approximately with δ−2.
In classical computations, the numerical precision cutoff plays the role of the variance. Due to the
high precision in classical computers, this leads to optimal shifts δ≪1, which allows treating the bias
to leading order in δand thus enables rough estimates of the optimal δ∗in advance. On a quantum
computer, however, the variance typically is more than ten orders of magnitude larger, leading to a
very different δ∗, which furthermore depends on the function and derivative values. As a consequence,
shifts ofO(1)become a reasonable choice, highlighting the similarity of the central difference recipe to
the two-term parameter-shift rule [79].
As a demonstration of the above, and in preparation for the numerical experiments shown in Figs. 3
and4, wecomputethecentraldifferencegradientforarandomsingle-qubitHamiltonian, asingle SU(2)
gateU(θ) = exp(iaX+ibY)andδ∈{0.5,0.75,1.0}. For this, we evaluate the mean and standard
error 50times and show the difference to the exact derivative in Fig. E1. As expected, we observe that
the bias increases with δand that the variance is suppressed with larger δ. We determine δ= 0.75to
be a reasonable choice for the purpose of the demonstration in Figs. 3 and 4, but stress that for any
other circuit, qubit count, Hamiltonian, and even for a different parameter position θfor this circuit,
the optimal shift size needs to be determined anew.
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 60 π/2 π
a−0.4−0.20.00.20.4[∂FD,a−∂a]C(θ)
b=0.5
0 π/2 π
ab=1.0δ= 0.5 δ= 0.75 δ= 1.0
0 π/2 π
ab=2.0Figure E1: Error of the central difference gradients with δ= 0.5,0.75,1.0for the single-qubit example from Figs. 3
and 4. The value of the second parameter again is fixed to b= 0.5,1.0,2.0in the panels (from left to right). The
shift parameter δinfluences the strengths of bias and variance, leading to a trade-off. For smaller δ, the variance is
enhanced due to the coefficients in Eq. (E6) that scale with δ−1. For larger δ, the bias based on the approximate
nature of Eq. (E6) is increased. We find δ= 0.75to be a reasonable choice for this particular circuit, Hamiltonian
and parameter position θ.
3 Decomposing effective generators for differentiation
In Algorithm 1 we suggest to use the generalized parameter-shift rule [7, 8, 9] in order to compute the
partial derivatives∂
∂θlC(θ)independently. In addition, Theorem 2 bounds the number of frequencies
occurring in the univariate auxiliary cost function C(t) = Tr/braceleftig
U(θ)etΩl(θ)ρe−tΩl(θ)U†(θ)H/bracerightig
and the
corresponding number of parameter shifts required during differentiation.
Realizing the shift rule requires us to implement not only U(θ)—which is necessary to compute C(θ)
itself—but also the gate etrΩl(θ)for2Rshift values trand each Ωlseparately. Alternatively, we may
follow the approach to decompose all effective generators Ωland compute the derivative as a linear
combination of the derivatives for simpler auxiliary gates, similar to [7]. In particular, we again choose
the Pauli basis of su(N)for this decomposition.
Decompose the effective generators Ωl(θ)as
Ωl(θ) =/summationdisplay
mωlm(θ)Gm, ωlm(θ) =1
NTr{GmΩl(θ)}. (E7)
Note that the coefficients are purely imaginary due to the skew-Hermiticity of Ωl(θ). The partial
derivative we are interested in can then be written as
∂
∂θlC(θ) = Tr/braceleftigg
HU(θ)/bracketleftiggd/summationdisplay
m=1ωlm(θ)Gm,ρ/bracketrightigg
U†(θ)/bracerightigg
(E8)
=/summationdisplay
mωlm(θ) Tr/braceleftig
HU(θ)[Gm,ρ]U†(θ)/bracerightig
(E9)
=/summationdisplay
mωlm(θ)2id
dtTr/braceleftbigg
HU(θ)/bracketleftbigg
exp/braceleftbigg
−it
2Gm/bracerightbigg
,ρ/bracketrightbigg
U†(θ)/bracerightbigg/vextendsingle/vextendsingle/vextendsingle/vextendsingle
t=0(E10)
=/summationdisplay
m/tildewideωlm(θ)d
dtCGm(θ,t)/vextendsingle/vextendsingle
t=0. (E11)
Here we abbreviated /tildewideωlm(θ) = 2iωlm(θ)and wroteCGm(θ,t)for the cost function with a rotation gate
with parameter−t/2aboutGminserted before U(θ). This modified cost function can be differentiated
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 7with respect to tusing the original two-term parameter-shift rule, as the inserted gate is generated by
(the multiple of) a Pauli string.
The above linear combination of Pauli rotation derivatives can be reused for all partial derivatives,
so that the full gradient for one SU(N)gate is given by
∇C(θ) =/tildewideω(θ)·dC, (E12)
dC=
d
dtCG1(θ,t)/vextendsingle/vextendsingle
t=0...
d
dtCGd(θ,t)/vextendsingle/vextendsingle
t=0
. (E13)
So farwe did not discussthe number of Pauli stringsoccurringin the decomposition ofthe generators
Ωl. As can be seen from Eq. (6) and our definition of the DLA in Section 5, this number is bounded
by the size of the DLA, and we again remark that this bound will be saturated for most values of θ.
As two shifts are required for each Pauli rotation, the gradient ∇C(θ)can thus be computed using
2 dimL(A(θ))circuits, using Pauli rotations from the DLA and, e.g., shift angles ±π
2.
As we only required a linear decomposition of Ωl, any other basis for the DLA may be used as well,
potentially allowing for fewer shifted circuits or different inserted gates that may be more convenient
to realize on hardware.
F Gate speed limit
The following Lemmas are used in Section 4.1.
Lemma 3. For Hamiltonians of the form H=/summationtext
mθmGm, whereGmare strings of log2NPauli
operators, Tr/braceleftbigH2/bracerightbig=N/summationtext
mθ2
m.
Proof.All Pauli strings Gmare orthonormal with respect to the trace inner product, Tr/parenleftig
G†
mGn/parenrightig
=
δn,mN. Using this gives
Tr/braceleftig
H2/bracerightig
=/summationdisplay
m,nθmθnTr{GmGn} (F1)
=N/summationdisplay
m,nθmθnδn,m (F2)
=N/summationdisplay
mθ2
m. (F3)
Lemma 4. The length of a smooth curve on the Riemannian manifold SU(N), with metric g(x,y) =
Tr/braceleftig
x†y/bracerightig
, for a time-independent Hamiltonian Hafter a fixed time τonly depends on the norm of H
andτ.
Proof.The unitary evolution of U(θ;t), parameterized by t, corresponds to a smooth curve on SU(N)
with length according to the Riemannian metric, g(x,y) = Tr/braceleftig
x†y/bracerightig
[80]. Integrating over the metric
norm through the tangent spaces from t= 0to final time τgives the path length,
L[U(θ;t),τ] =/integraldisplayτ
t=0ds (F4)
=/integraldisplayτ
0/radicalig
g(˙U(θ;t),˙U(θ;t))dt (F5)
=/integraldisplayτ
0/radicalbigg
Tr/braceleftig˙U†(θ;t)˙U(θ;t)/bracerightig
dt, (F6)
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 8where ˙U=dU
dt. From Schrödinger evolution,
dU(θ;t)
dt=−iHU(θ;t), (F7)
we find
L[U(θ;t),τ] =τ/radicalig
Tr{H2}, (F8)
for time-independent Hamiltonians. Therefore for all Hamiltonians with fixed norm Tr/braceleftbigH2/bracerightbig, the path
distance travelled after time τis the same regardless of the specific unitary evolution.
Lemma 5. The minimal path between the identity element Iand a point Von the Riemannian
manifold of SU(N), with metric g(x,y) = Tr/braceleftig
x†y/bracerightig
, is a geodesic curve γ(t) =eXtwithX∈su(N).
Proof.From Proposition 3.10 [81], the geodesics of SU(N)are the one-parameter subgroups, given
byγ(t) =eXt. In general, multiple geodesics curves can give Vfrom the identity. The minimal path
is the curve with the minimum length. Since geodesic curves are the extrema of the path length
functional [82, Lemma 9.3], there must exist a geodesic, which is of the form γ(t) =eXt, that is the
minimal path to V.
1 Proof of Theorem 1
We restate Theorem 1 again for convenience.
Theorem 1. For unitary gates generated by normalized time-independent Hamiltonians, consider a
general circuit decomposition of two gates U(ϕ(2);t2)U(ϕ(1);t1). There exists an equivalent evolution
with an SU(N)gateU(θ;tg) =U(ϕ(2);t2)U(ϕ(1);t1), with evolution time tg, such that
tg≤t1+t2,
with equality if ϕ(1)+ϕ(1)=θ.
Proof.The product U(ϕ(2);t2)U(ϕ(1);t1)corresponds to a specific point Von the manifold SU(N).
By Lemma 5, there exists a geodesic between the identity IandV, given by the curve eXtthat is
of minimal length. We can parameterize this geodesic as U(ϕ(2);tg) = exp/braceleftig¯A(θ)tg/bracerightig
, which is always
possible since A(θ)parameterizes an arbitrary point in su(N)and is an SU(N)gate. By Lemma 4,
the length of this path only depends on the norm of ¯A(θ), which is 1, and ontg, which gives
tg=L[U(θ;t),tg)]. (F9)
Since this path is minimal, we have
tg≤t1+t2 (F10)
with equality if ϕ(1)+ϕ(1)=θ.
1.1 Special case of SU(2)
In the following we give the additional time for decomposing an optimal SU(2)gate into two gates.
Byoptimal, we refer to the geodesic along the minimal path length curve – see Lemma 5.
We consider the optimal SU(2)gateU(θ;tg)with geodesic evolution time tgtogether with a decom-
positionU(ϕ(2);t2)U(ϕ(1);t1) =U(θ;tg). The decomposed circuit is given by two unitary evolutions.
Each individual evolution U(˜ϕ(ν);tν)is aU(1)rotation such that only a single basis element is re-
quired. With two rotations, the overall evolution is an element of SU(2). The corresponding su(2)
algebra is spanned by three basis elements—the three Pauli matrices for example. The two rotations
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 9can be represented as lying on a Bloch sphere. A unitary transformation, K∈SU(N), can therefore
be applied to the evolution such that U(˜ϕ(ν);tν) =KU(ϕ(ν);tν)K†for
˜ϕ(ν)=
sin(αν) cos(βν)
sin(αν) sin(βν)
cos(αν)
, (F11)
whereν= 1,2, withανandβνparameterizing the rotations. By construction ˜ϕ(ν)·˜ϕ(ν)= 1is
normalised for all parameters ανandβν. The same transformation KdefinesU(˜θ;tg) =KU(θ;tg)K†
and gives the same relationship U(˜θ;tg) =U(˜ϕ(2);t2)U(˜ϕ(1);t1). This is straightfoward to show
U(˜θ;tg) =KU(θ;tg)K†(F12)
=KU(ϕ(2);t2)U(ϕ(1);t2)K†(F13)
=KU(ϕ(2);t2)K†KU(ϕ(1);t2)K†(F14)
=U(˜ϕ(2);t2)U(˜ϕ(1);t1). (F15)
We have
¯A(˜ϕ(ν)) = sin(αν) cos(βν)G1+ sin(αν) sin(βν)G2+ cos(αν)G3, (F16)
where we choose G1=iX,G2=iY, andG3=iZ. These basis elements of su(2)generate the
group SU(2). We also define the basis vector G= (G1,G2,G3). Exponentiation therefore gives the
closed-form expression
exp/braceleftig¯A(˜ϕ(ν))tν/bracerightig
= exp/braceleftig/parenleftig˜ϕ(ν)·G/parenrightig
tν/bracerightig
(F17)
= cos(tν)I⊗Nqubits + sin(tν)˜ϕ(ν)·G. (F18)
By the group composition law of SU(2), the product of two exponentials in SU(2)also gives a closed-
form expression,
exp/braceleftig¯A(˜ϕ(2))t2/bracerightig
exp/braceleftig¯A(˜ϕ(1))t1/bracerightig
=/parenleftig
cos(t2)I⊗Nqubits + sin(t2)˜ϕ(2)·G/parenrightig/parenleftig
cos(t1)I⊗Nqubits + sin(t1)˜ϕ(1)·G/parenrightig
.
(F19)
Collecting terms gives
exp/braceleftig¯A(˜ϕ(2))t2/bracerightig
exp/braceleftig¯A(˜ϕ(1))t1/bracerightig
=/parenleftig
cos(t1) cos(t2)−˜ϕ(1)·˜ϕ(2)sin(t1) sin(t2)/parenrightig
I⊗Nqubits
+/parenleftig
cos(t2) sin(t1)˜ϕ(1)+ cos(t1) sin(t2)˜ϕ(2)+isin(t1) sin(t2)˜ϕ(1)×˜ϕ(2)/parenrightig
·G.(F20)
The total evolution is
exp/braceleftig¯A(˜ϕ(2))t2/bracerightig
exp/braceleftig¯A(˜ϕ(1))t1/bracerightig
= exp/braceleftig¯A(˜θ)tg/bracerightig
(F21)
= cos(tg)I⊗Nqubits + sin(tg)˜θ·G. (F22)
By comparison of Eqs. (F20)and(F22), we find
˜θ=1
sin(tg)/parenleftig
cos(t2) sin(t1)˜ϕ(1)+ cos(t1) sin(t2)˜ϕ(2)+isin(t1) sin(t2)˜ϕ(1)×˜ϕ(2)/parenrightig
,(F23)
and
cos(tg) = cos(t1) cos(t2)−˜ϕ(1)·˜ϕ(2)sin(t1) sin(t2). (F24)
The additional evolution time is ∆t=td−tg, withtd=t1+t2the total decomposed unitary evolution
time. Duetotheinvarianceofthescalarproduct, ˜ϕ(1)·˜ϕ(2)=ϕ(1)·ϕ(2), theadditionaltime ∆t=td−tg
required by the decomposition is then given by
∆t=td−arccos/parenleftbigcos(t1) cos(t2)−ϕ(1)·ϕ(2)sin(t1) sin(t2)/parenrightbig≥0.
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 10G Unique spectral gaps of Dynamical Lie Algebras
1 Proof of Theorem 2
We restate Theorem 2 here for convenience.
Theorem 2. The number of unique spectral gaps RofΩl(θ)is upper bounded by the number of roots
|Φ|of any maximal semi-simple DLA,
R≤|Φ|/2. (G1)
In the following we set gto be a semisimple Lie algebra. A subspace a⊆gis called a subalgebra if
it is closed under the Lie bracket, i.e., if [a1,a2]∈a,∀a1,a2∈a. Since gis a semisimple Lie algebra,
it always contains a subalgebra called a Cartan subalgebra [29] (Chapter 7, Definition 7.10).
Definition 1. A Cartan subalgebra hofgis a subalgebra that satisfies the following conditions:
1. For allh1,h2∈h,[h1,h2] = 0.
2. For allx∈g, if[h,x] = 0for allh∈h, thenx∈h.
The first condition tells us that his a commutative subalgebra of g, while the second condition says
thathis maximal, i.e., there is no larger commutative subalgebra. The first step in proving Theorem 2
is to make use of the following result:
Theorem 3. [67, Chapter VI, Theorem 1]. If gis a semisimple Lie algebra, we can write gas a
direct sum of the root spaces gα:
g=/circleplusdisplay
αgα, (G2)
where
gα∈h∗={x∈g|adh(x) =α(h)x,∀h∈h}, (G3)
andα∈h∗are functionals on h. That is, a root space is a subspace of gon which the action of the
adjoint representation of his described by a functional (and scalar multiplication).
The above decomposition is called a root space decomposition, which is an essential tool in classifi-
cations of Lie algebras [68, 67]. Since
g0={x∈g|adh(x) = 0,∀h∈h}, (G4)
we find that h=g0and hence
g=h⊕/circleplusdisplay
α̸=0gα. (G5)
We then immediately see that
dimg= dim h+/summationdisplay
α̸=0dimgα. (G6)
We can thus relate the dimensionality of a Lie algebra to the dimensionality of its Cartan subalgebra
and its weight spaces. The second step of the proof relies on identifying the unique spectral gaps of
Ωl(θ)with the weight spaces gα. To achieve this, we will construct the linear operator adhand apply
it to the eigenbasis of Ωl(θ)to show that the maps αcan be identified with the spectral gaps of Ωl(θ).
Consider an element Ω∈g, where g⊆su(N)is a non-trivial subalgebra and his a Cartan subalgebra
ofg. Since his the Lie algebra of a maximally abelian group, we can represent elements of hby
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 11diagonal matrices. Since Ωis skew-Hermitian, there exists a unitary V∈SU(N)that diagonalizes Ω,
i.e.,V†ΩV=hwithh∈h. Here,Vis the matrix with columns equal to the eigenvectors vkofΩwith
corresponding eigenvalues λk. We can thus always choose a basis for gsuch that Ωis diagonal. If Ω
is non-degenerate, then it must be full rank, and therefore an element of h. All Cartan algebras are
equivalent up to conjugacy, hence we can choose the matrix hto be the diagonal matrix containing
the eigenvalues of Ωto represent the Cartan subalgebra h. We now take Enmto be the matrix with
entries (n,m)equal to 1 and all other entries to 0. Define the operator
enm=V†EnmV, (G7)
and apply adhto it:
adh(enm) =henm−enmh (G8)
=V†ΩEnmV−V†EnmΩV (G9)
=V†hEnmV−V†EnmhV (G10)
= (λn−λm)enm. (G11)
This means that adhhas the eigenvectors enmwith corresponding eigenvalues αnm(h) =λn−λm[83],
and so we have identified the eigenvalue differences with the roots of the Lie algebra. We define the
set of all roots as
Φ ={λn−λm,n̸=m= 1,...,N}. (G12)
Since the dimensionality of each weight space is one [67, Chapter VI, Theorem 2(a)], we can see that
/summationdisplay
α̸=0dimgα=|Φ|. (G13)
Therefore,
dimg= dim h+|Φ|. (G14)
We now set g=L(A(θ)). If we take the absolute value of the elements of Φ, we can identify R=|Φ|/2,
where the factor 1/2is to account for double the counting of the spectral gaps. Since Ωcan be
degenerate in general, we obtain the inequality R≤|Φ|/2. With this, the proof of Theorem 2 is
completed.
2 Examples
Here, we give several examples of maximal DLAs and their corresponding value of |Φ|/2. Analogous
to the main text, we choose the Pauli representation but these results should hold for any irreducible
representation of su(N).
1.su(2): For a 1-qubit system, there are no non-trivial subalgebras, hence we can only look at the
full special unitary Lie algebra su(2). AnyA(θ)that consists of two Pauli operators will generate
this algebra, e.g.,
A(θ) =i(θ1X+θ2Y) (G15)
will giveL(A(θ)) =su(2). A Cartan subalgebra of su(2)is given by h= span ({Z}). We therefore
find that dimg= 3anddimh= 1and so|Φ|= 2. Hence we have R≤1and need 2R≤2shifts.
This matches the result in [5], where the parameter-shift rule was generalized from single Pauli
matrices to Hermitian operators with two unique eigenvalues.
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 122. TFIM: A DLA that has been studied before [62, 65] is the 1D transverse field Ising-Model (TFIM)
Hamiltonian:
A(θ) =i(θ1X⊗I+θ2I⊗X+θ3Z⊗Z), (G16)
withL(A(θ)) = span ({X⊗I,I⊗X,Y⊗Y,Z⊗Z,Z⊗Y,Y⊗Z}). We can take h=
span ({X⊗I,I⊗X})as a Cartan subalgebra and so dimg= 6anddimh= 2, which gives
|Φ|= 4. Hence we need (at most) 4 shifts to obtain the gradient of an operator in the DLA of the
TFIM, which corresponds to so(4).
3.su(4): The full Lie algebra of su(4)is spanned by
A(θ) =/summationdisplay
mθmGm, (G17)
whereGm∈P4are the tensor products as defined in Eq. (1). A Cartan subalgebra of su(4)is
given by h={Z⊗I,I⊗Z,Z⊗Z}. This means that dimg= 15anddimh= 3, which gives
|Φ|= 12. Hence we have R= 6and need 12 shifts to obtain the gradient for a general operator
insu(4).
In the above examples, we have only been concerned with the dimensionality of the root system.
We could go one step further and look at the structure of the root systems. It turns out that there
exists only a finite set of root systems, which leads to the classification of all semisimple Lie algebras
(such a program was originally carried out by Dynkin [68] and is explained in most textbooks on
Lie algebras [31, 83, 29]). This allows us to make the following observation about DLAs and the
SU(N)gates in our work: there is a finite number of families of SU(N)gates for each N, given by
the possible DLAs. Again, we emphasize that this is independent of the representation of the algebra.
We summarize the above results together with the identification of the corresponding classical group
in Table 1 [31] (Chapter 3, Table 3.4).
Name dim(g)dim(h)|Φ|Classical group
su(2)3 12A1
so(4) 6 24A1×A1∼=D2
su(4)15 312 A2
Table 1: Examples of DLAs and the size of the root spaces. Each root system Φcan be identified with a Lie algebra
of one of the classical groups An,Bn,Cn,Dn. The classical group D2corresponds to SO(4), with the corresponding
Lie algebra so(4)which has dimension N(N−1)/2.
Accepted in Quantum2024-02-28, click title to verify. Published under CC-BY 4.0. 13