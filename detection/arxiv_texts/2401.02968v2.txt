 
 
Rule -Guided Joint Embedding Learning o ver Knowledge Graphs  
 
Qisong Li1, Ji Lin1, Sijia Wei 2, Neng Liu3 
1School of Computer Science, Wuhan University of Technology  
2School of Computer Science, Jianghan University  
3School of Computer Science, Wuhan University of Science and Technology  
 
Abstract  
Recent studies  focus on embedding learning  over knowledge 
graph s, which map entities and relations in knowledge graphs 
into low -dimensional vector spaces. While existing  models 
mainly consider the aspect  of graph structure , there  exists  a 
wealth of contextual and literal information that can be utilized 
for more effective embedding  learning . This paper introduces a 
novel model that incorporates both contextual and literal 
information into entity and relation embeddings  by utilizing 
graph convolutional networks. Specifically, for contextual 
information, we assess its significance through confidence and 
relatedness metrics. In addition, a  unique rule -based method is 
developed to calculate the confidence metric, and the relatedness 
metric is derived from the literal information's representations. 
We validate  our model  performance with thorough experiments 
on two established benchmark datasets.  
 
 
0 Introduction  
In recent years, knowledge graphs have been widely used 
to organize and publish structured data in various domains due 
to their advantages of high expressive power, low ambiguity, 
uniformity of schema, and support for reasoning. Typically, a 
knowledge grap h consists of entities, their attributes, and 
relationships between entities. For example, it may contain the 
entity China, the relationship capital, and the entity attribute 
"China". The base composition of a knowledge graph is a triple 
that describes the  relationship between two entities or the 
relationship between an entity and its attributes, e.g. (China, 
Capital, Beijing), (China, English label, "China").  
At present, knowledge map has been widely used in tasks 
such as intelligent question answering [1], recommendation 
system [2] and information retrieval [3], and its outstanding 
performance has been widely concerned by both academia and 
industry [4]. Howeve r, while benefiting from the rich 
information contained in knowledge map, its huge scale and data 
sparseness have also brought challenges to the application of 
knowledge map. For example, open domain knowledge maps 
such as Freebase [5], Yago  [6] and dbpedi a [7] usually contain 
millions of entities and hundreds of millions of triples describing 
the relationship between entities. Traditional graph algorithms 
like subgraph matching often struggle with computational 
efficiency when applied to large -scale knowledge maps. To 
address this, researchers have developed a knowledge graph 
embedding learning model. This model transforms the 
knowledge graph into a continuous, low -dimensional vector space, enabling the efficient learning of embedding 
representations for en tities and relationships.  
By designing a specific representation learning mechanism, 
information such as the structure and semantics of the knowledge 
map can be encoded in the learned embedded representation. On 
the one hand, large -scale knowledge maps originally needed to 
be frequ ently visited, such as structured query. Construction) [9], 
Logical Query Pro -Cessing [10] and query relaxation) [11] can 
all be completed by numerical calculation in the learned 
embedded representation space, which greatly improves the 
efficiency. On the o ther hand, the embedding learning of 
knowledge map provides a method to extract and efficiently 
represent the feature information of knowledge map, which is 
similar to word embedding, which is widely used in the field of 
natural language processing, and th e embedding representation 
of knowledge map also provides great convenience for deep 
learning based on knowledge map.  
Most of the existing knowledge map embedding learning 
models only pay attention to the structural information 
represented by triplets in the knowledge map. For example, 
Bordes et al. put forward the TransE model based on translation 
mechanism [12], whose t arget tasks are link prediction and link 
prediction.Triple classification, in a nutshell, is to judge whether 
there is a certain relationship between two given entities in the 
knowledge map. Therefore, the TransE model only pays 
attention to the encoding o f a single triple structure information 
by the learned embedding representation, which simplifies the 
knowledge map into a finite set of unrelated triples in the 
embedding learning process. Therefore, Transition and its 
subsequent improved models [13-16] have very weak coding 
ability for contextual information in knowledge maps, so it is 
difficult to be applied to semantically related tasks. To solve this 
problem, some embedded representation models based on 
contextual information have been proposed  one aft er another. 
However, they still only pay attention to contextual information 
represented by subgraphs, paths and other structures in 
knowledge maps. For example, When learning the embedded 
representation of the entity Beijing in Figure 1, the above method 
only pays attention to the triplets (China, capital, Beijing) and 
(Beijing, located in North China) which describe the relationship 
between entities, and ignores the text information such as the 
introduction of Beijing and English labels. Obviously, the la ck 
of text information limits the expression of semantic information 
in the learned embedded representation . 
In order to solve this problem, this paper proposes a rule -
guided knowledge map joint embedding learning model. 
Inspired by the graph convolution network, the model firstly 
encodes the context information of the entity in the knowledge  
graph into the embedded representation of the entity through 
multi -relational graph convolution. Different from the work of 
Vashishth and others, this paper holds that multiple pieces of 
context information of an entity should have different degrees of 
importance, and the degree of importance of a certain piece of 
context information depends on two factors: the confidence of 
the piece of context information and its relevance to the entity. 
Therefore, this paper puts forward a simple and effective rule to 
guide the calculation of the confidence of context information, 
and based on the text information representation in the 
knowledge map, puts forward a calculation method of the 
correlation degree between entities and their context information. 
Finally, the mo del integrates the embedded representation 
encoded by graph convolution network with the vector 
representation of text information, and takes the result of link 
prediction task as the training goal to learn the embedded 
representation of entities and relat ionships in knowledge map.  
The contribution of this paper is mainly reflected in three 
aspects:  
1) Based on the graph convolution network, an embedding 
representation learning model guided by rules is innovatively 
proposed, which considers the context information and text 
information in the knowledge map jointly.  
2) According to the importance of context information in 
graph volume product, a new method is proposed to calculate the 
confidence and correlation of single context information by 
applying rules and text information in knowledge map.  
3) Experiments are carried out on benchmark data sets and 
compared with related knowledge map embedding learning 
methods. The experimental results verify the effectiveness of this 
model.  
1 Related work  
In this section, the knowledge map embedding learning 
model related to this work is introduced. Because the model 
proposed in this paper is based on graph neural network, the 
knowledge map embedding learning model based on graph 
neural network and other non -graph neural networks are 
introduced respectively.  
1.1 Model based on graph neural network  
The models based on graph neural network mainly include 
R-GCN [20] W -GCN [21], COMPGCN [19] and so on. This 
kind of model usually uses the graph convolution network as the 
encoder to encode the graph structure data, and combines with 
the corresponding deco der to perform tasks such as link 
prediction and node classification on the knowledge graph. In R -
GCN, the characteristics of nodes and relationships in each layer 
of the network are calculated by using the weight matrix, and 
transmitted to the subsequent network layers through domain 
aggregation. Specifically, R -GCN uses base decomposition and 
block diagonal decomposition to construct the weight matrix of 
a specific relationship, so as to deal with different types of 
neighbor relationships, fuse them with neighbor node 
information, and transmit them to the target entity for updating. 
W-GCN assigns learnable weight parameters to each weight 
matrix in the process of graph -volume -product network 
aggregation, so that the model can obtain a better entity embeddi ng representation. CompGCN proposes a domain 
information aggregation method for the central node, using a 
variety of "entities" in theory.  
1.2 Non -graph neural network model  
There are many types of embedded learning models for 
non-graph neural networks, mainly including models based on 
translation mechanism, such as TransE[12] and its subsequent 
improved models, including TransH[13], TransR[14] and 
TransD[15]. A model based on rules, such as Neural -LP[16], 
TILP[17], a model based on context information, such as 
GAKE[1 8], RDF2Vec[1 9], a model based on tensor 
decomposition, such as ComplEx[22],  RESCAL[23]  
The translation mechanism of TransE is relatively simple, 
so it can be efficiently applied to large -scale knowledge maps, 
but at the same time, it limits the expressive ability of its models, 
making it difficult to deal with complex relationships of one -to-
many, many -to-one and many -to-many types [14]. In order to 
solve this problem, some models with more complicated 
translation mechanisms have been proposed after TransE. For 
example, TransH [13] designs the translation mechanism relative 
to the hyperplane space of the relations in the given triplet, while 
TransR[14] learns an extra matrix for each relation in the 
knowledge map, with which the head and tail entities are mapped 
into the corresponding relation vector space through linear 
transformation, and then calculates the loss value of its 
translation mechanism.  
2 Joint Embedding Representation Learning  
In this section, we first provide a formal definition of the 
knowledgegraphembedding learning problem, introduce the 
notationofrelated concepts, and then introduce the proposed rule -
guided joint embedding learning model indetail.  
2.1 Problem Definition  
In this paper, the knowledge map is expressed as ğ’¢=
(â„°,â„›), where â„°,â„› respectively represent the entity and relation 
set in the knowledge map. For a triple (ğ‘’h,ğ‘Ÿ,ğ‘’t)âˆˆğ’¢, in which 
the head and tail entities all belong to the entity set, that is, 
ğ‘’h,ğ‘’tâˆˆâ„°, and the relationship belongs to the relationship set, 
that is, ğ‘Ÿâˆˆâ„›. The embedding learning problem of knowledge 
map is to learn the vector representation e of any entity ğ‘’âˆˆâ„° 
and any relationship ğ‘Ÿâˆˆâ„› in a given knowledge map ğ’¢, ğ‘Ÿâˆˆâ„ğ‘‘, 
where is the dimension represented by ğ‘‘ embedding. A test task 
evaluates the learned embedded representation, this task may 
include two scenarios: given entity ğ‘’âˆˆâ„° and relation ğ‘Ÿâˆˆâ„›, 
based on them embedding represents ğ’†,ğ’“âˆˆâ„ğ‘‘, and predicts 
another entity ğ‘’â€²âˆˆâ„°, so that there are three groups (ğ‘’,ğ‘Ÿ,ğ‘’â€²)âˆˆğ’¢ 
or (ğ‘’â€²,ğ‘Ÿ,ğ‘’)âˆˆğ’¢; Or given two entities ğ‘’,ğ‘’â€²âˆˆâ„°, based on their 
embedded representations  ğ’†,ğ’†â€²âˆˆâ„ğ‘‘, predict a relation ğ‘Ÿâˆˆâ„›, 
so that triple (ğ‘’,ğ‘Ÿ,ğ‘’â€²)âˆˆğ’¢ exists or (ğ‘’â€²,ğ‘Ÿ,ğ‘’)âˆˆğ’¢. 
For any entity ğ‘’âˆˆâ„° and relation ğ‘Ÿâˆˆâ„›, this paper 
represents their corresponding text information as ğ‘™ğ‘’ and ğ‘™ğ‘Ÿ. For 
entity ğ‘’âˆˆâ„°, this paper regards the set ğ’©(ğ‘’) of all its neighbor 
triplets as the context of ğ‘’, specifically, ğ’©(ğ‘’) is the  union of the  
set {(ğ‘’,ğ‘Ÿ,ğ‘’â€²)âˆ£(ğ‘’,ğ‘Ÿ,ğ‘’â€²)âˆˆğ’¢,ğ‘’â€²âˆˆâ„°} and the set  {(ğ‘’â€²,ğ‘Ÿ,ğ‘’)âˆ£
(ğ‘’â€²,ğ‘Ÿ,ğ‘’)âˆˆğ’¢,ğ‘’â€²âˆˆâ„°}, and for any neighbor triplet in ğ’©(ğ‘’), We 
think that it expresses a piece of context information of node ğ‘’.  
Similar to Vashishth et al. [19], this paper also extends the 
relational set of knowledge map: â„›â†â„›âˆªâ„›inverseâˆªğ‘†ğ¿, where  
â„›inverse={ğ‘Ÿâˆ’1âˆ£ğ‘Ÿâˆˆâ„›} is an inverse relational set. Specifically, 
for any triplet (ğ‘’h,ğ‘Ÿ,ğ‘’t)âˆˆğ’¢, this paper adds an inverse relation 
ğ‘Ÿâˆ’1 to the relational set. and correspondingly adds triplet 
(ğ‘’t,ğ‘Ÿâˆ’1, ğ‘’h) to the knowledge graph ğ’¢, that is, ğ’¢â†ğ’¢âˆª
{(ğ‘’t,ğ‘Ÿâˆ’1,ğ‘’h)}. ğ‘†ğ¿ stands for a set of self -ring relations, that is, 
for any entity ğ‘’âˆˆâ„°, a self -ring triple is added to the knowledge 
map ğ’¢, that is, ğ’¢â†ğ’¢âˆª{(ğ‘’,ğ‘Ÿğ‘ , ğ‘’)},ğ‘Ÿsâˆˆğ‘†ğ¿. In addition, this 
paper uses ğ’©ğ‘’(ğ‘’) represents the set of neighboring entities 
around entity ğ‘’, and ğ’©ğ‘’(ğ‘’) represents the set of neighboring 
relationships around Entity ğ‘’. For example, for entity Beijing, its 
neighboring entity set is {North China, China, ...}, and the 
neighboring relationship set is located in, capital, introduction, 
English label, ...}.  
2.2 Overall Model Architecture  
The model proposed in this paper mainly consists of four 
parts: embedding layer, context encoding layer, feature fusion 
layer and decoding layer. First, the text is fed into the embedding 
layer to obtain the character -level embedding; then, the context 
features are extracted using Transformer and BiLSTM in the 
context encoding layer, and then fed into the feature fusion layer 
to be fused using the attention mechanism; finally, the 
conditional random fields are used in the decoding layer to 
decode and output  the labels.  
 
ehContext of eh
Relevance 
Calculation
heL
irL
jrL
jeL
jteejrirj
Confidence
CalculationCi,jRelevance 
Calculation
 
Fig. 1 An overview of the framework  
2.3 Embedding Layer  
In this paper, we use Word2Vector and a pre-trained model 
as the embedding layer, in which the pre -trained model uses the 
RoBERTawwm model pre -trained by Xunfei Joint Laboratory of 
HITU.  
Assuming that the initial input of the model is a sentence ğ‘º=
(ğ‘¥1,ğ‘¥2,â‹¯,ğ‘¥ğ‘›). When using the RoBERTawwm model, the 
output is the character -level embedded human ğ‘¹=
(ğ‘Ÿ1,ğ‘Ÿ2,â‹¯,ğ‘Ÿğ‘›) When using Word2Vector, the character -level 
embedding and binary character -level embedding are also 
obtained. When using Word2Vector word vectors, character -
level embeddings and binary character -level embeddings are 
also obtained as ğ‘=(ğ‘1,ğ‘2,â‹¯,ğ‘ğ‘›) and ğ’ƒ=(ğ‘1,ğ‘2,â‹¯,ğ‘ğ‘›), 
where the character -level embedding is in word units, and the 
binary character -level embedding is in double -word units, which 
are stitched together to get the final word vector, as shown in 
equation (1).  
ğ‘½Vec=[ğ’„;ğ’ƒ] 
HiddenAttention
Embedding layerMulti -Head 
AttentionAdd & NormFeed ForwardAdd & NormCRF CRF CRF CRF CRF
E5 E4 E3 E2 E1+Feature
FusionDecoder
Encoder
Embedding
InputPositional EncodingOutput B-LOC E-LOC O O O 
Fig. 2 The encoder -decoder structurte  
 
2.4 Improved Transformer Encoder  
In this paper, the left side of the context encoding layer is 
the structure of the Transformer encoder, which includes a multi -
head self -attention layer, a feed -forward neural network layer, 
and uses layer normalization and residual concatenation. The 
original Transformer encoder employs absolute coding to 
generate the positional codes, The position code of the ğ‘¡ -th 
character is shown in  (2):  
ğ‘ƒPE,ğ‘¡,2ğ‘–=sin (ğ‘¡/100002ğ‘–/ğ‘‘)
ğ‘ƒPE,ğ‘¡,2ğ‘–+1=cos (ğ‘¡/100002ğ‘–/ğ‘‘) 
where: The values range of  ğ‘– is [0,ğ‘‘
2];ğ‘‘ is the dimension of the 
input word vector. The resulting positional codes and word 
vectors are summed bitwise to obtain the input matrix of the 
multi -head self -attention layer ğ‘¯âˆˆâ„ğ‘™Ã—ğ‘‘, where ğ‘™ is the 
sequence length to be . ğ‘¯ H is mapped to ğ‘¸, ğ‘² and ğ‘½, as shown 
in  (3):  
ğ‘¸,ğ‘²,ğ‘½=ğ‘¯ğ‘¾ğ‘,ğ‘¯ğ‘¾ğ‘˜,ğ‘¯ğ‘¾ğ‘£ 
where: ğ‘¾ğ‘ã€ğ‘¾ğ‘˜,ğ‘¾ğ‘£ denotes the dimension of â„ğ‘‘Ã—ğ‘‘ğ‘˜ the 
variable weight matrix, the ğ‘‘ğ‘˜ is the hyperparameter. The scaled 
dot product attention is computed by the following equation: the  
ğ´Attention  (ğ‘²,ğ‘¸,ğ‘½)=Softmax (ğ‘¸ğ‘²T
âˆšğ‘‘ğ‘˜)ğ‘½ 
When multiple self -attention is used, it is calculated as 
shown in Eq. (5) Eq. (7).  
ğ‘¸â„,ğ‘²â„,ğ‘½â„=ğ‘¯ğ‘¾ğ‘â„,ğ‘¯ğ‘¾ğ‘˜â„,ğ‘¯ğ‘¾ğ‘£â„
ğ‘«â„=ğ´Attention  (ğ‘¸â„,ğ‘²â„,ğ‘½â„)
ğ‘€Multi -Head  (ğ‘¯)=[ğ‘«1,ğ‘«2,â‹¯,ğ‘«â„]ğ‘¾ğ‘š 
where: â„ stands for Head index. ï¼› [ğ‘«1,ğ‘«2,â‹¯,ğ‘«â„] denotes the 
splicing of the attention of multiple Heads; the ğ‘¾ğ‘š denotes the 
dimension of â„ğ‘‘Ã—ğ‘‘ of the variable weight matrix. The output of  
the multinomial self -attention layer ğ’™ will be further processed 
by the feed -forward neural network layer, as shown in Eq. (8).  
ğ¹FFN(ğ’™)=max(0,ğ’™ğ‘¾1+ğ’ƒ1)ğ‘¾2+ğ’ƒ2 
where: ğ‘¾1,ğ‘¾2, ğ’ƒ1 and ğ’ƒ2 are learnable parameters. ğ‘¾1âˆˆ
â„ğ‘‘Ã—ğ‘‘ğ‘“ğ‘“,ğ‘¾2âˆˆâ„ğ‘‘ğ‘“ğ‘—Ã—ğ‘‘,ğ’ƒ1âˆˆâ„ğ‘‘ğ‘“ğ‘“,ğ’ƒ2âˆˆâ„ğ‘‘,ğ‘‘ğ‘“ğ‘“ is a hyper -
parameter.  
In this paper, the original Transformer encoder is improved 
by using relative position coding [16] and modifying the 
attention calculation . Firstly, the ğ‘¯ maps to ğ‘„,ğ•‚, ,ğ‘‰,ğ¾ğ¾ are 
not linearly transformed to break the symmetry and enhance the 
distance perception, and the transformation process is shown in 
Eq. (9). 
ğ‘¸,ğ‘²,ğ‘½=ğ‘¯ğ‘¾ğ‘,ğ‘¯ğ‘‘ğ‘˜,ğ‘¯ğ‘¾ğ‘£ 
where. ğ‘¾ğ‘,ğ‘¾ğ‘ ldshendintweension of the â„ğ‘‘Ã—ğ‘‘ğ‘˜,ğ‘‘ğ‘˜ is the 
feature dimension of one of the Heads; the ğ‘¯ğ‘‘ğ‘˜ is the name of 
the ğ‘¯ vector assigned to each Head.  
Second, the absolute encoding of cos Functions are 
expressed in terms of sin function instead, the new relative 
position encoding is shown in equation (10).  
ğ‘¹ğ‘¡âˆ’ğ‘—=[â‹¯sin (ğ‘¡âˆ’ğ‘—
100002ğ‘–/ğ‘‘ğ‘˜)cos (ğ‘¡âˆ’ğ‘—
100002ğ‘–/ğ‘‘ğ‘˜)â‹¯]T
 
where : ğ‘¡ is the index of the target character ğ‘—ğ‘— is the index of the 
context character ;ğ‘– The range of values is [0,ğ‘‘ğ‘˜
2]. When 
calculating the attention score, the word vectors are calculated 
separately from the relative position encoding, and the bias term 
is added, and the calculation procedure is shown in Eq. (11).  
ğ‘¨rel,ğ‘¡ğ‘—=ğ‘¸ğ‘¡ğ‘²ğ‘—T+ğ‘¸ğ‘¡ğ‘¹ğ‘¡âˆ’ğ‘—T+ğ’–ğ‘²ğ‘—T+ğ’—ğ‘¹ğ‘¡âˆ’ğ‘—T 
where : ğ‘¸ğ‘¡ğ‘²ğ‘—T denotes the attention fraction of the two characters; 
the ğ‘¸ğ‘¡ğ‘¹ğ‘¡âˆ’ğ‘—T denotes the first ğ’• the deviation of individual 
characters in relative distance; the ğ’–ğ‘²ğ‘—T denotes the first ğ’‹ the 
deviation of the characters; the ğ’—ğ‘¹ğ‘¡âˆ’ğ‘—T denotes the relative 
distance and direction bias term; the ğ’– and ğ‘£ denotes the 
learnable parameters.  
Finally, the attention is computed without scaling the dot 
product as shown in Equation (12).  
ğ´Attention  (ğ‘¸,ğ‘²,ğ‘½)=Softmax (ğ‘¨rel )ğ‘½ 
After the above modification of the attention , the position 
perception and orientation perception of the Transformer 
encoder are improved, which makes the Transformer suitable for 
the Chinese named entity recognition task.  
2.5 Bidirectional Long Short -Term Memory Network  
Long Short Term Memory Network (LSTM) is a special 
kind of Recurrent Neural Network (RNN), which can alleviate 
the problems of gradient vanishing and gradient explosion of 
traditional RNNs. In LSTM, a forgetting gate is introduced to 
control the informatio n flow, so as to selectively memorize the 
information.  
In the task, for the target character, this paper not only 
needs the information from above but also needs the information 
from below, therefore, BiLSTM is used as the context encoder, 
and its structure is shown on the right side of the context 
encoding la yer of the overall model architecture in Fig. 2. BiLSTM adopts forward and backward inputs for the character -
level embedding output from the embedding layer, and the 
forward and backward vectors are computed, and the two vectors 
are spliced together and us ed as the output of the hidden layer, 
which is realized as shown in Eq. (13) and Eq. (15). 
ğ’‰âƒ—âƒ— ğ‘¡ =LSTM (ğ’™ğ‘¡,ğ’‰ğ‘¡âˆ’1âƒ—âƒ—âƒ—âƒ—âƒ—âƒ—âƒ—âƒ—âƒ— )
ğ’‰ğ‘¡ =LSTM (ğ’™ğ‘¡,ğ’‰ğ‘¡âˆ’1)
ğ’‰ğ‘¡ =[ğ’‰âƒ—âƒ— ğ‘¡;ğ’‰ğ‘¡] 
2.6 Feature Fusion Layer  
Transformer can model arbitrary distance dependencies, 
but it is not sensitive to position and orientation information; 
BiLSTM can fully capture orientation information, but cannot 
capture global information. In this paper, we borrow the gating 
mechanism a nd use the attention mechanism to dynamically fuse 
the context features extracted by the Transformer encoder and 
BiLSTM, so as to achieve the purpose of complementing each 
other's strengths. The dynamic fusion of attention mechanism is 
realized as shown in  Eqs. (16) and (17).  
ğ’›=ğœ(ğ‘¾ğ‘§3tanh (ğ‘¾ğ‘§1ğ’™ğ‘¡+ğ‘¾ğ‘§2ğ’™ğ‘))
ğ’™Ëœ=ğ’›â‹…ğ’™ğ‘¡+(1âˆ’ğ’›)â‹…ğ’™ğ‘ 
where : ğ‘¾ğ‘§ is a learnable weight matrix ï¼› ğœ is Sigmoid 
activation function. ï¼› ğ’™ğ‘¡ is the vector of outputs from the 
Transformer encoder; the ğ’™ğ‘ is the vector of BiLSTM output. 
The vector ğ’› has the same dimension as ğ’™ğ‘¡ and ğ’™ğ‘ which is the 
same dimension as the weight between the two vectors, allows 
the model to dynamically determine how much information to 
use from the Transformer encoder or BiLSTM, thus 
remembering the important information and avoiding to cause an 
informatio n light surplus.  
2.7 Decoding Layer  
In order to take advantage of the dependencies between 
different labels, this paper uses conditional random fields as the 
decoding layer. For a given sequence ğ’”=[ğ‘ 1,ğ‘ 2,â‹¯,ğ‘ ğ‘‡], the 
corresponding label sequence is ğ’š=[ğ‘¦1,ğ‘¦2,â‹¯,ğ‘¦ğ‘‡]. ğ’š The 
probability is calculated as shown in equation (18).  
ğ‘ƒ(ğ’šâˆ£ğ’”)=âˆ‘â€Šğ‘‡
ğ‘¡=1â€Šeğ‘“(ğ’šğ‘¡âˆ’1,ğ’šğ‘¡,ğ’”)
âˆ‘â€Šğ‘Œ(ğ’”)
ğ’šâ€²â€Šâˆ‘â€Šğ‘‡
ğ‘¡=1â€Šeğ‘“(ğ’šğ‘¡âˆ’1â€²,ğ’šğ‘¡â€²,ğ’”) 
where : ğ‘“(ğ’šğ‘¡âˆ’1,ğ’šğ‘¡,ğ’”) denotes the computation of the distance 
from ğ’šğ‘¡âˆ’1 to ğ’šğ‘¡ The state transition fractions of ğ’šğ‘¡ The fraction 
of the fraction, whose objective is ğ‘ƒ(ğ’šâˆ£ğ’”);ğ’€(ğ’”) denotes all 
valid label sequences. When decoding, the Viterbi algorithm is 
used to find the globally optimal sequence.  
3 Experiments  
In this section, we firstly explain the dataset,comparison 
model and evaluation indexes used in theexperiments,and then 
present the experimental results of theproposedmodel and 
compare and analyze them with otherbenchmark models.  
3.1 Introduction of datasets and comparison models   
In this paper, experiments are conducted on two widely 
used data sets, namely FB15K -237 [27] and Wn18 [12], and their 
statistical data are shown in Table 1:  
Table 1 Summary  Statistics  of Knowledge Graphs  
Dataset  FB15K -237 WN18  
#Relation  237 18 
#Entity  14541  40943  
#Train  271115  141442  
#Valid  17535  2500  
#Test  20466  2500  
 
In order to verify the validity of the proposed model, this 
paper widely selects the knowledge map embedded learning 
model which has been widely used as the analogy method, 
including transition [11], distmult [28] and complex [22],R -gcn 
[20], KB Gan [20], Conve [24], ConvKB [30] SACN [21], Hyper 
[31], Rotate [32], ConVR [33], VR -GCN [34], CompGCN [19]. 
It has been introduced in detail above. Complex [22] is similar 
to Rescal [23] model and belongs to the model of link prediction 
based on matrix/tensor decomposition. R -GCN [20], VR -GCN 
[34] and COMPGCN [19] belong to the embedding 
representa tion model based on the graph convolution network. 
Taking R -GCN [20] as an example, it encodes the relationship in 
the knowledge graph into a matrix, and transmits the embedding 
information of adjacent entities through the relationship matrix, 
and adopts t he multi -layer graph convolution network. KBGAN 
applies the Generative Adversary Network (Gan), which is 
generated in the training process. Conve [2] model is used as the 
decoder in this paper, and it is introduced in detail in Section 2. 
ConvKB [30], ConV R [33], SACN21] and Hyper [31] are all 
methods based on convolutional neural networks. Take Hyper 
[S1] as an example, it can generate a simplified convolution filter 
related to relationships, and it can be constructed as tensor 
decomposition. Rotate [32] i s similar to the translation 
mechanism -based model such as TRANSE [11], which 
represents the relationship between entities as the rotation from 
entity to entity in vector space.  
3.2 Evaluation Methodology Description  
In this paper, the validity of the model is evaluated by 
linking the prediction tasks. In the experiment, for the test triplets 
whose heads or tails have been turned off in advance, this paper 
speculates the head or tail entities that have been removed bas ed 
on the learned embedding representation. For each test triplet, 
this paper selects any entity in the knowledge map as the possible 
prediction result, and calculates the score value after completing 
the test triplet with this entity, as shown in Equation  (12). Finally, 
the score values are sorted. Here, taking the prediction of missing 
header entities as an example, for each triplet (ğ‘’h, ğ‘Ÿ,ğ‘’t ) in the 
test set, the header entity ğ‘’h is deleted in advance, and then any 
entity ğ‘’hcâˆˆâ„° in ğº is tried to complete the test triplet, thus 
generating a set of candidate triplets {(ğ‘’hc,ğ‘Ÿ,ğ‘’t)âˆ£ğ‘’hcâˆˆâ„°}. 
Based on the learned embedded representation, the scores of 
candidate triples are calculated and sorted. The higher the scores, the more reliable the learned model, that is, the embedded 
representation. By comparing with the real results, the quality of 
the learned embedded representation can be judged.  
Finally, MR(mean rank), MRR (mean reciprocal rank) and 
Hit@k are used as evaluation indicators [12]. Among them, both 
MR and MRR are indicators of the average ranking of prediction 
results, and Hit@k refers to the proportion of prediction results 
in the to p K, and this paper specifically adopts Hit@10, Hit@3 
and Hit@1. In short, the better.  
3.3 Experimental Setup  
The experimental code in this paper is implemented in 
Python, and it is completed on the server with Ubuntu16.04.6 
LTS operating system. Its CPU configuration is 16 -core Intel 
Core i7 -6900K 3.20 GHz, and its memory is 128 GB. The GPU 
configuration is 4 GeF orce GTX 1080 GPU cards.  
For the encoding of text representation vectors of entities 
and relationships, this paper uses the pre -trained -Bert-base-
uncased model 0, the initial dimension of text vectors is 768, and 
the transformed dimension is 200. In the graph -convolution 
network, the initialization vector dimension of entities and 
relationships is 100, that is, d=100, and the dimension of GCN is 
200. That is, ğ‘‘â€²=200. The height and width of dimension 
transformation in the decoder are 10 and 20 respectively, and the 
size of convolution filter is 7Ã— 7, and the number is 200. Adam 
optimizer is used to train the whole model, and the batch size is 
256 and the learning rate  is 0.001.  
In this paper, the TransE model is reproduced, and the 
other models refer to the results reported in the comparative 
model paper.  
3.4 Analysis of Experimental Results  
Table  2 reports the experimental results of this model and 
the comparison model for the link prediction task.  
The followingresultscan be observed from Table2:  
1) Our model significantly outperforms the benchmark 
models such as TransE ,DistMult andComplExinall evaluation 
metrics,andisvery closetotherecently proposed models such as 
SACN , HypERandCompGCN, which proves the validity of our 
model. FortheFB15K -237dataset ,thispaperranks first in 
theHit@10 index.  
2) InHit@1andHit@3,the difference between thispaper 
and CompGCN, ConvRand SACN isvery small. Specifically, 
theHit@1index is only 1.51% lower 
thanthehighestCompGCN,and theMRR index isonly0.8% lower 
thanthatof CompGCN.Forthe WN18dataset,the model ranks 
firstinthe MR index, and thegapbetweenthemodelandthe first one 
in the Hit@10 and Hit@3 indexes isalso very small. In 
particular,itis 0.2% lowerthanRotatEinHit@10,andonly 0.9% 
lowerthanConvRandHypERin Hit@3.  
3) Embedding learning methods based on graph neural 
networks generally outperform TransE andothermodels that only 
focus on structured information. In the case ofthemodel in this 
paper, its performance in the link prediction task is significantly 
improved by t he joint embedding of contextual and  textual  
information in the knowledge graph based on graph 
convolutional  networks.   
Table2 Link  Prediction  Results  on FB15K -237 and WN18  
Model  FB15K -237 WN18  
MRR  MR Hit@10  Hit@3  Hit@1  MRR MR Hit@10  Hit@3  Hit@1  
TransE[12]  0.294  357 0.330  0.330  0.146  0.454  251 0.891  0.803  0.064  
DistMul[28]  0.241  254 0.419  0.263  0.155  0.829   0.829  0.923  0.726  
ComplEx[22]  0.247  339 0.428  0.275  0.158   844 0.940   
R-GCN[20]  0.248   0.417   0.151  0.773   0.944  0.889  0.65 
KBGAN[29]  0.278   0.458    0.779   0.949    
ConvE [24]  0.325  244 0.501  0.356  0.237  0.943  374 0.956  0.946  0.935  
ConvKB[30]  0.243  311 0.421  0.371  0.155       
SACN[21]  0.350   0.540  0.390  0.260       
HypER[31]  0.341  250 0.520  0.376  0.252  0.951  431 0.958  0.955  0.947  
RotatE[32]  0.338  177 0.533  0.375  0.241   309 0.959    
ConvR[33]  0.350   0.528  0.385  0.261  0.951   0.958  0.955  0.947  
VR-GCN[34]  0.248   0.432  0.272  0.159  0.847   0.946  0.929  0.764  
CompGCN[19]  0.355  197 0.535  0.390  0.264       
OurMethods  0.352  186 0.536  0.385  0.385 0.260  0.928  240 0.957  0.946  0.909  
Note: The  best p erformance  is in bold.  
 
4 Conclusion  
This paper addresses the limitations of current knowledge 
map embedding learning methods, which typically focus on the 
structure information in triplets while overlooking the contextual 
and textual data within the knowledge map. To enhance link 
prediction and similar tasks, we introduce a novel approach 
utilizing a graph convolutional neural network, integrating 
context and textual information into the learning of embedding 
representations. To emphasize the significance of context at a 
finer granularity, we establish an efficient rule for gauging 
context confidence. Additionally, we dev ise a technique for 
assessing context relevance through vector representations of 
textual data, thereby augmenting the influence and guidance of 
context information. The efficacy of our model is demonstrated 
through comparative experiments on two extensive ly utilized 
benchmark datasets.  
References  
 
[1] Hu Sen, Zou Lei, Yu J. X., et al. "Answering Natural 
Language Questions by Subgraph Matching over Knowledge 
Graphs." IEEE Transactions on Knowledge and Data 
Engineering, vol. 30, no. 5, 2017, pp. 824 -837. 
[2] Palumbo E., Rizzo G., Troncy R. "Entity2rec: Learning User -
Item Relatedness from Knowledge Graphs for Top -N Item 
Recommendation." Proc of the 7th ACM Conf on Recommender 
Systems. New York: ACM, 2017, pp. 32 -36. 
[3] Corcoglioniti F., Dragoni M., Rospocher M., et al. 
"Knowledge Extraction for Information Retrieval." Proc of the 
European Semantic Web Conf. Berlin: Springer, 2016, pp. 317 -
333. 
[4] Zou Xiaohan. "A Survey on Application of Knowledge 
Graph." JPhCS, vol. 1487, no. 1, 2020, article no. 012016.  [5] Bollacker K., Evans C., Paritosh P., et al. "Freebase: A 
Collaboratively Created Graph Database for Structuring Human 
Knowledge." Proc of the 2008 ACM SIGMOD Int Conf on 
Management of Data. New York: ACM, 2008, pp. 1247 -1250.  
[6] Suchanek F. M., Kasneci G., Weikum G. "YAGO: A Core of 
Semantic Knowledge." Proc of the 16th Int Conf on World Wide 
Web. New York: ACM, 2007, pp. 697 -706. 
[7] Auer S., Bizer C., Kobilarov G., et al. "DBpedia: A Nucleus 
for a Web of Open Data." Proc of the Semantic Web. Berlin: 
Springer, 2007.  
[8] Liu Zhiyuan, Sun Maosong, Lin Yankai, et al. "Knowledge 
Representation Learning: A Review." Journal of Computer 
Research and Development, vol. 53, no. 2, 2016, pp. 247 -261. 
[9] Wang Ruijie, Wang Meng, Liu Jun, et al. "Leveraging 
Knowledge Graph Embeddings for Natural Language Question 
Answering." Proc of Int Conf on Database Systems for 
Advanced Applications. Berlin: Springer, 2019, pp. 659 -675. 
[10] Hamilton W., Bajaj P., Zitnik M., et al. "Embedding Logical 
Queries on Knowledge Graphs." Proc of Advances in Neural 
Information Processing Systems (NeurIPS 2018). Cambridge, 
Massachusetts: MIT Press, 2018, pp. 2026 -2037.  
[11] Wang Meng, Wang Ruijie, Liu Jun, et al. "Towards Empty 
Answers in SPARQL: Approximating Querying with RDF 
Embedding." Proc of Int Semantic Web Conf. Berlin: Springer, 
2018, pp. 513 -529. 
[12] Bordes A., Usunier N., Garcia -Duran A., et al. "Translating 
Embeddings for Modeling Multi -Relational Data." Proc of 
Advances in Neural Information Processing Systems (NIPS 
2013). Cambridge, Massachusetts: MIT Press, 2013, pp. 2787 -
2795.  
[13] Wang Zhen, Zhang Jianwen, Feng Jianlin, et al. 
"Knowledge Graph Embedding by Translating on Hyperplanes." 
Proc of the 28th AAAI Conf on Artificial Intelligence. Palo Alto, 
CA: AAAI Press, 2014, 14(2014), pp. 1112 -1119.   
 [14] Lin Yankai, Liu, Zhiyuan, Sun Maosong, et al. "Learning 
Entity and Relation Embeddings for Knowledge Graph 
Completion." Proc of the 29th AAAI Conf on Artificial 
Intelligence. Palo Alto, CA: AAAI Press, 2015, pp. 2181 -2187.  
[15] Ji Guoliang, He Shizhu, Xu Liheng, et al. "Knowledge 
Graph Embedding via Dynamic Mapping Matrix." Proc of the 
53rd Annual Meeting of the Association for Computational 
Linguistics and the 7th Int Joint Conf on Natural Language 
Processing (volume 1: Long Pap ers). Stroudsburg, PA: ACL, 
2015, pp. 687 -696. 
[16] Yang, Fan, Zhilin Yang, and William W. Cohen. 
"Differentiable learning of logical rules for knowledge base 
reasoning." Advances in neural information processing systems 
30 (2017).  
[17] Xiong, Siheng, et al. "TILP: Differentiable Learning of 
Temporal Logical Rules on Knowledge Graphs." The Eleventh 
International Conference on Learning Representations. 2022.  
[18] Feng Jun, Huang Minlie, Yang Yang, et al. "GAKE: Graph 
Aware Knowledge Embedding." Proc of the 26th Int Conf on 
Computational Linguistics (COLING 2016). Stroudsburg, PA: 
ACL, 2016, pp. 641 -651. 
[19] Ristoski P., Paulheim H. "RDF2Vec: RDF Graph 
Embeddings for Data Mining." Proc of the Int Semantic Web 
Conf. Berlin: Springer, 2016, pp. 498 -514. 
[20] Vashishth S., Sanyal S., Nitin V., et al. "Composition -Based 
Multi -Relational Graph Convolutional Networks." Proc of the 
Int Conf on Learning Representations. 2020, pp. 1 -15. [Online]. 
Available: https://www.researchgate.net/publication/337158026  
[21] Schlichtkrull M., Kipf T. N., Bloem P., et al. "Modeling 
Relational Data with Graph Convolutional Networks." Proc of 
the 15th Int Conf on Extended Semantic Web Conf (ESWC 
2018). Berlin: Springer, 2018, pp. 593 -607. 
[22] Shang Chao, Tang Yun, Huang Jing, et al. "End -to-End 
Structure -Aware Convolutional Networks for Knowledge Base 
Completion." Proc of the 33rd AAAI Conf on Artificial 
Intelligence. Palo Alto, CA: AAAI Press, 2019, pp. 3060 -3067.  
[23] Trouillon T., Welbl J., Riedel S., et al. "Complex 
Embeddings for Simple Link Prediction." Proc of the 33rd Int 
Conf on Machine Learning (ICML). New York: ACM, 2016, pp. 
2071 -2080.  
[24] Nickel M., Tresp V., Kriegel H. P. "A Three -Way Model 
for Collective Learning on Multi -Relational Data." Proc of the 
28th Int Conf on Machine Learning. Madison WI, USA: Omni 
Press, 2011, pp. 809 -816. 
[25] Dettmers T., Minervini P., Stenetorp P., et al. 
"Convolutional 2D Knowledge Graph Embeddings." Proc of the 
32nd AAAI Conf on Artificial Intelligence. Palo Alto, CA: 
AAAI Press, 2018, pp. 1811 -1818.  
[26] Devlin J., Chang Mingwei, Lee K., et al. "BERT: Pre -
Training of Deep Bidirectional Transformers for Language 
Understanding." Proc of 2019 Conf of the North American 
Chapter of the Association for Computational Linguistics: 
Human Language Technologies. Stro udsburg, PA: ACL, 2019, 
pp. 4147 -4186.  
[27] Plate T. A. "Holographic Reduced Representations." IEEE 
Transactions on Neural Networks, vol. 6, no. 3, 1995, pp. 623 -
641. [28] Toutanova K., Chen Danqi. "Observed Versus Latent 
Features for Knowledge Base and Text Inference." Proc of the 
3rd Workshop on Continuous Vector Space Models and Their 
Compositionality. Stroudsburg, PA: ACL, 2015, pp. 57 -66. 
[29] Yang Bishan, Yih W. T., He Xiaodong, et al. "Embedding 
Entities and Relations for Learning and Inference in Knowledge 
Bases." Proc of the 3rd Int Conf on Learning Representations 
(ICLR 2015). 2015, pp. 69 -74. [Online]. Available: 
https://www.researchgate.n et/publication/269935407  
[30] Cai Liwei, Wang W. Y. "KBGAN: Adversarial Learning for 
Knowledge Graph Embeddings." Proc of the 2018 Conf of the 
North American Chapter of the Association for Computational 
Linguistics: Human Language Technologies. Stroudsburg, PA: 
ACL, 2018, pp. 1470 -1480 . 
[31] Nguyen D. Q., Nguyen T. D., Nguyen D. Q., et al. "A Novel 
Embedding Model for Knowledge Base Completion Based on 
Convolutional Neural Network." Proc of the 2018 Conf of the 
North American Chapter of the Association for Computational 
Linguistics: Human Lang uage Technologies. Stroudsburg, PA: 
ACL, 2018, pp. 327 -333. 
[32] BalaÅ¾eviÄ‡ I., Allen C., Hospedales T. M. "Hypernetwork 
Knowledge Graph Embeddings." Proc of the Int Conf on 
Artificial Neural Networks. Berlin: Springer, 2019, pp. 553 -565. 
[33] Sun, Zhiqing, et al. "Rotate: Knowledge Graph Embedding 
by Relational Rotation in Complex Space." Proc of the 7th Int 
Conf on Learning Representations (ICLR 2019), 2019, pp. 1 -18, 
www.researchgate.net/publication/331397037_RotatE_Knowle
dge_Graph_Embedding_ by_Relational_Rotation_in_Complex_
Space. Accessed 10 Sept. 2020.  
[34] Jiang, Xiaotian, Wang Quan, and Wang Bin. "Adaptive 
Convolution for Multi -Relational Learning." Proc of the 2019 
Conf of the North American Chapter of the Association for 
Computational Linguistics: Human Language Technologies, 
Stroudsburg, PA, ACL, 2019, p p. 978 -987. 
[35] Ye, Rui, et al. "A Vectorized Relational Graph 
Convolutional Network for Multi -Relational Network 
Alignment." Proc of the 28th Int Joint Conf on Artificial 
Intelligence, San Mateo, CA, Morgan Kaufmann, 2019, pp. 
4135 -4141.  