On the Advantages of Asynchrony in the Unsourced
MAC
Alexander Fengler, Alejandro Lancho, Krishna Narayanan, and Yury Polyanskiy
Abstract ‚ÄîIn this work we demonstrate how a lack of synchro-
nization can in fact be advantageous in the problem of random
access. SpeciÔ¨Åcally, we consider a multiple-access problem over
a frame-asynchronous 2-user binary-input adder channel in the
unsourced setup (2-UBAC). Previous work has shown that under
perfect synchronization the per-user rates achievable with linear
codes over the 2-UBAC are limited by 0.5 bit per channel
use (compared to the capacity of 0.75). In this paper, we Ô¨Årst
demonstrate that arbitrary small (even single-bit) shift between
the user‚Äôs frames enables (random) linear codes to attain full ca-
pacity of 0.75 bit/user. Furthermore, we derive density evolution
equations for irregular LDPC codes, and prove (via concentration
arguments) that they correctly track the asymptotic bit-error rate
of a BP decoder. Optimizing the degree distributions we construct
LDPC codes achieving per-user rates of 0.73 bit per channel use.
Index Terms ‚ÄîMultiple-Access, Low-density parity check
(LDPC), Unsourced, massive machine-type communication
I. I NTRODUCTION
A recent line of work, termed unsourced random access (URA
or UMAC), exploits the idea of same-codebook communi-
cation [1]. This approach allows to separate the different
messages in a multiple-access channel (MAC) based purely on
the structure of the codebook, i.e., the set of allowed messages.
It was shown that good unsourced code designs can approach
the capacity of the additive white Gaussian noise (AWGN)
adder channel without the need for coordination [1], [2].
While many unsourced code constructions have been proposed
[2]‚Äì[8], most of them lack analytic understanding and it is
not well understood what properties make a good unsourced
codebook. Furthermore, many proposed schemes have a high
decoding complexity. Recent works [9], [10] have constructed
LDPC codes speciÔ¨Åcally for two-user communication on the
A. Fengler, A. Lancho, and Y . Polyanskiy are with the Massachusetts
Institute of Technology. (Email: ffengler,lancho,ypg@mit.edu)
Research was sponsored by the United States Air Force Research Lab-
oratory and the United States Air Force ArtiÔ¨Åcial Intelligence Accelerator
and was accomplished under Cooperative Agreement Number FA8750-19-
2-1000. The views and conclusions contained in this document are those
of the authors and should not be interpreted as representing the ofÔ¨Åcial
policies, either expressed or implied, of the United States Air Force or
the U.S. Government. The U.S. Government is authorized to reproduce and
distribute reprints for Government purposes notwithstanding any copyright
notation herein. Alejandro Lancho has received funding from the European
Union‚Äôs Horizon 2020 research and innovation programme under the Marie
Sklodowska-Curie grant agreement No 101024432. Alexander Fengler was
funded by the Deutsche Forschungsgemeinschaft (DFG, German Research
Foundation) ‚Äì Grant 471512611. This work is also supported by the National
Science Foundation (NSF) under Grant No CCF-2131115.
K. Narayanan is with the Texas A&M University. This work is supported
by NSF grant CCF-2131106. (Email: krn@tamu.edu)unsourced binary input adder channel (UBAC). It was found
that linear codes in general suffer a rate loss in the UBAC and
cannot achieve sum rates higher than 1 bit/channel use, which
is still far from the sum-rate capacity of 1.5 bits/channel use.
Another concern for the practical applicability of unsourced
codes is the assumption of perfect synchronization, present
in many works. In low-power low-cost transmitters perfect
synchronization is hard to achieve. Classic results [11] show
that frame-asynchrony does not change the capacity of a
discrete MAC, as long as the allowed delay is smaller than
the blocklength. Recent solutions for uncoordinated multiple-
access schemes that can deal with asynchronism were pro-
posed in [12], [13]. Both of these works present schemes
speciÔ¨Åcally for orthogonal frequency-division multiplexing
(OFDM) modulation with timing offsets within the cyclic
preÔ¨Åx. Such timing offsets can be efÔ¨Åciently handled in the
frequency domain. Nonetheless, OFDM is not necessarily the
best choice for the mMTC scenario since it requires a high
level of frequency synchronization, which is hard to achieve
with low-cost transmitters.
In this work, we Ô¨Årst show that random linear codes
achieve the BAC capacity of 1.5 bits/ch. use as soon as a
frame delay of at least one symbol is introduced. As such,
it enables same-codebook communication with linear codes
and linear decoding complexity that does not suffer from
the rate 1 bottleneck, which limits unsourced linear codes
in the frame-synchronous case. Although the channel model
is idealistic, it is also quite general and does not rely on
any speciÔ¨Åc modulation method. Further, we design LDPC
codes with linear decoding complexity for the two-user frame-
asynchronous UBAC. We Ô¨Ånd codes that achieve sum-rates of
1.46 bits/ch. use. The decoding can be done by two copies
of a conventional single-user belief propagation (BP) decoder
that periodically exchange information. We also show that our
design works if the delay is a random integer with a maximum
value that scales at most sub-linearly with the blocklength.
Randomized LDPC code designs for the two-user multiple-
access channel with AWGN have been presented in [14], [15].
For the code construction presented in [15] it is crucial that the
two code ensembles are optimized independently, resulting in
two different ensembles. If one check node (CN) distribution
is Ô¨Åxed, the CN distribution of the other user can be optimized
by a linear program. In [14], one common code ensemble is
designed, but the two users pick a different random code from
the same ensemble. In addition, to obtain a linear optimization
program, the codes in [14] are constrained such that variable
nodes (VNs) that are connected through the MAC have thearXiv:2305.06985v1  [cs.IT]  11 May 2023same degree. Such a constraint would be hard to enforce in a
model with random delay. In contrast, in this work we design
one LDPC ensemble from which one code is chosen at random
and used by both users. The design of the ensemble relies on
alternating optimization of CN and VN degree distributions.
Surprisingly, we Ô¨Ånd that degree one VNs do not result in error
Ô¨Çoors, in contrast to LDPC codes for the single-user binary-
erasure channel (BEC). A particular difÔ¨Åculty in proving the
density evolution (DE) in the joint graph is that the channel
transition probabilities for one user depends on the transmitted
codeword of the other user. Since the codewords come from
the same codebook the channel outputs may be correlated.
To that end we employ the symmetrization technique of coset
ensembles, cf. [16], although an additional subtlety in our case
is that we need to show that both users can use the same coset.
Thus, our design strictly adheres to the unsourced paradigm
where both users use a common codebook. The symmetriza-
tion allows us to prove that DE describes the asymptotic bit-
error rate (BER) and, furthermore, that it is independent of the
transmitted codewords. This implies that we can assume that
both users transmit the all-zero codeword plus a dither when
analyzing the error probability. We provide a full proof that the
asymptotic error probability is described by the DE and give an
analysis of the probability of short-length stopping sets, which
result in an error Ô¨Çoor. The error Ô¨Çoor analysis shows that we
can expurgate short-length stopping sets created by the MAC
nodes as long as the fraction of degree one VNs is below
a certain threshold. Numerical simulations conÔ¨Årm that DE
accurately predicts the error probability for large blocklengths.
We use the DE to construct codes that approach the capacity
of the two-user BAC. Our work shows that frame-asynchrony
can be exploited to design efÔ¨Åcient linear unsourced codes.
To summarize, our main intellectual contributions in this
paper are:
A random coding argument that shows that linear codes can
achieve the full BAC capacity with a single symbol delay.
The derivation of the DE equations under the same-
codebook constraint and sub-linear frame delays.
A rigorous proof that the BER of a random code from the
ensemble will concentrate around the DE.
The design of a codebook that enables two-user communi-
cation at rates close to the Shannon limit.
These Ô¨Åndings imply that a non-zero frame delay enables two
users to use the same LDPC encoder while still achieving
rates close to the two-user BAC capacity. In addition, decoding
can be done with linear complexity and a simpliÔ¨Åed decoder
architecture that consists of two connected copies of the same
single-user BP decoder.
II. C HANNEL MODEL
We study the frame-asynchronous noiseless BAC:
yi=c1;i+c2;i  (1)
where2[0 :max]andcu;i2f1; 1gforu2f1;2g;i2
[1 :n]andcu;i= 0fori<1ori>n . More speciÔ¨Åcally, eachuser transmits a binary-phase-shift keying (BPSK) modulated
version of a binary codeword cu= 2mu 1;mu2f0;1gn.
We will analyze the case where is random and uniformly
distributed. Furthermore, we will study the asymptotic behav-
ior of code constructions when max2o(n), i.e.,max=n!0
asn!1 . This setting is also known as mild asynchrony in
information theory [17]. Both users transmit a uniform i.i.d.
sequence of nRbits,b1;b2, by picking the respective binary
codewords m1;m2independently, uniformly at random from a
common codebook over the binary Ô¨Åeld C2Fn2nR
2 , wheren
denotes the blocklength and 0<R< 1the per-user rate. The
decoder outputs a list of two messages g(y)and the per-user
error probability is deÔ¨Åned as Pe=1
2(P(b1=2g(y))+P(b2=2
g(y))).
Since the model includes no noise, the channel model
reduces to an erasure channel where a received symbol can be
considered as erased if (c1;i;c2;i )2f(+1; 1);( 1;+1)g.
Remark 1: The coding construction in this paper also works
for the synchronous model if users employ a randomly chosen
cyclic shift of their codeword before transmission. However,
in this case some mechanism needs to be added that allows to
recover the shift of each user, e.g., adding a preamble to each
codeword. For the model (1) this is not necessary since can
be found easily from amplitude information in y.
Remark 2: The BAC model can also be used to model on-
off keying modulation. In that case there is some ambiguity
since there is no dedicated idle symbol. Nonetheless, it is
still possible to detect the start of a frame by introducing a
preamble.
III. R ANDOM LINEAR CODES
We give the following result, which shows that random linear
codes can achieve the two-user BAC capacity if a frame delay
of just one symbol is introduced.
Theorem 1: There exist linear (n;k)codes for the two-user
frame-asynchronous UBAC with = 1 and
Pen 1
22n(2R 1:5)+on(1): (2)

Proof: The proof is given in Appendix A.
Theorem 1 shows that random linear codes can achieve a
vanishing error probability if R< 0:75 for any >0. It
can be shown for both parity check and generator ensembles.
We brieÔ¨Çy describe the intuition behind the proof for parity
check ensembles and why  > 0is strictly necessary to
get rates larger than 0:5. The idea is to treat the channel
as erasure channel, as described in Section II. The erased
symbols can, in principle, be recovered by solving the parity
check equations Hm 1=0andHm 2=0. A key property
of the BAC is that on the erased set the codewords from the
two user have opposed bits, i.e. c1;i= c2;i . This gives
a second collection of parity equations for each codeword.
For= 0 the additional parity check equations would be
linearly dependent, and provide no new information. In thatcase, since the size of the erased set is around n=2, the parity
check matrix needs to have n=2 +linearly independent
rows for correct recovery, resulting in R < 1=2. In contrast,
for= 1 we show in Appendix A that the collection of
parity check equations arising from c1;i= c2;i fori2E
is linearly independent from the set of equations given by
Hm 1=Hm 2=0with high probability. Therefore n=4 +
linearly independent equations for each user, resulting in a
total ofn=2 + 2linearly independent equations for each
codeword, will be enough to ensure correct decoding, allowing
forR< 3=4. In the following we will construct LDPC codes
that approach this limit with linear decoding complexity.
IV. LDPC C ODE DESIGN
A. LDPC Code Ensembles
LDPC codes are deÔ¨Åned by a bipartite graph where the
transmitted bits are represented by VNs which are subject to
local parity checks, represented by CNs. We study random
codes that are drawn uniformly at random from a given
ensemble, deÔ¨Åned by the degree distribution of VNs and CNs.
SpeciÔ¨Åcally, a random graph code from the ensemble is created
by Ô¨Årst assigning degrees to VN and CNs proportional to some
degree distributions. Then the emanating stubs (half-edges)
of VNs and CNs are connected through a uniform random
permutation (multi-edges are not explicitly forbidden). Finally
the VNs are also permuted uniformly at random. We would
like to emphasize that it is important for our construction
that the ensemble deÔ¨Ånition includes a random permutation of
the VNs. For memoryless single-user channels this is usually
not necessary since the error probability is invariant under
permutation of VNs, and some works do not mention it for
this reason, e.g., [18]. However, in the multiple-access case
correlations between VN degrees of neighboring nodes may
introduce unwanted correlations in the joint graph.
LetLidenote the fraction of nodes with degree i,ithe
fraction of edges that connect to degree iVNs, andithe
fraction of edges that connect to degree iCNs. We also deÔ¨Åne
the corresponding power series L(x) :=PLixi;(x) :=Pixi 1, and(x) :=Pixi 1, and we denote the cor-
responding ensemble as LDPC( ;).
B. Message Passing Decoding
We study the bit-error probability under BP decoding on
the joint graph.The values of VNs (v1;i;v2;i)are initialized
with their know values if yi6= 0 and are initialized with the
erased symbol ifyi= 0. BP decoding on the joint graph
can be realized by running two conventional single-user BP
decoders on (y1;:::;yn)and(y1+;:::;yn+)respectively and
exchanging information between them on (y1+;:::;yn). The
information exchange is particularly simple for the BAC since
c1;ifully deÔ¨Ånes c2;i givenyi. We denote the function nodes
that enforce the channel constraint (1) as MAC nodes . An
example of a joint graph is depicted in Fig. 1 where triangles
depict MAC nodes, squares are CNs, and circles are VNs.
The single-user decoder can be run for multiple iterations
Fig. 1: Factor Graph for a UBAC with = 1. Triangles denote MAC nodes,
squares are CNs, circles are VNs.
before information exchange. Nonetheless, in this paper we
only study the case where each iteration of the single-user
decoders is followed by a message exchange through the MAC
nodes. This decoder has O(n)complexity.
C. Coset Codes
To simplify the analysis we consider the ensemble of cosets
of LDPC codes where each code in this ensemble is speciÔ¨Åed
by a graphGand a ‚Äòdither‚Äô vector ~d2f0;1gnwith its BPSK
representation d2f 1gn. The ensemble is then speciÔ¨Åed by a
degree distributions pair ((x);(x))and the dither vector. We
consider the ensemble generated by randomly choosing VN
and CN degrees according to the distribution pair (x);(x)
followed by a random permutation between the left sockets
and right sockets, and by choosing ~duniformly fromf0;1gn.
LetCG;~ddenote the coset code corresponding to a given G
and~d. LetGandHdenote the generator matrix and parity
check matrix of the LDPC code, respectively, with a given G
and~d=0. Then, m2CG;~dif and only if Hm =H~d.
At the encoders, the bit sequences b1andb2are encoded
into codewords m1andm2, respectively, according to
mu=Gbu+~d; u2f1;2g: (3)
Note that both users share the same dither ~d. Since the BPSK
mapping is one-to-one, we can also express the addition of
the dither as multiplication of c1;c2withd, resulting in the
channel output
yi=c1;idi+c2;i di :
Since dis chosen as part of the code design, it is known at
the receiver and its effect can be easily incorporated into the
message passing rules. The analysis in Section V will show
that a randomly chosen dither will be good for any code and
all codeword combinations with probability approaching 1 as
n!1 .
Remark 3: Note that the constructed LDPC codes are not
strictly linear but afÔ¨Åne. Nonetheless, they can be encoded
with a linear encoder followed by a common offset. Besides,
numerical results suggest that the error probabilities stay
unchanged when no dithering is used. As such, the dither is
mainly used as an analytic tool here.
V. D ENSITY EVOLUTION ANALYSIS
We next track the fraction of erased edges through the itera-
tions averaged over the code and dither ensemble as n!1 .Letxlbe the probability that a message from a variable node to
a check node is erased, ylthe probability that a message from
a check node to a variable node is erased, wlthe probability
that a message from a variable node to a MAC node is erased,
andzlthe probability that a message from a MAC node to
a variable node is erased. The subscript lrefers to the l-th
iteration. The passed messages are visualized in Fig. 2.
xl
ylzl‚àí1
wlwl
Fig. 2: Fraction of erased messages between VNs, CNs and MAC nodes.
Assuming that the depth lneighborhood of each node is
a tree, we can derive a recursion for the evolution of the
above parameters as follows. Begin with initial conditions
y0= 1;x0= 1;z0= 1=2
xl+1=zl(yl) (4)
yl+1= 1 (1 xl+1) (5)
wl+1=L(yl+1) (6)
zl+1=1
2wl+1: (7)
These equations are obtained by following the basic message
passing rules. An edge from a degree iVN to a CN is erased
if all incoming edges are erased. The VN has a total of
i 1incoming edges from other CNs which are independently
erased with probability yland one incoming edge from a
MAC node which is erased with probability zl, resulting in
an erasure probability zlyi 1
l. Averaging over all VN degrees
gives the expression for xl+1. The other equations are derived
similarly. The factor 1=2inzl+1arises since the value of
each MAC node is independently erased with probability 1=2.
Note that this is only true because of the symmetrization by
the dither.
By performing some standard substitutions, we end up with
the following scalar recursion:
xl+1=1
2L(1 (1 xl))(1 (1 xl)): (8)
Likewise, we can obtain the following recursion on yl:
yl+1= 1 
1 1
2L(yl)(yl)
: (9)
The probability that a bit remains erased at the end of
iterationl+ 1is given by
pl+1=zlL(yl+1); (10)
where (pl)l=1;2;:::is a deterministic sequence of numbers.
Our main theorem below shows that the BER of a randomly
chosen code with a random dither sequence after ldecoding
iterations concentrates tightly around pl. Let
Pb(d;c;l) :=Pb(c;G;n;l;d;)
=1
2n2nX
i=1E[1fvl
i=gjG;d](11)be the BER (fraction of erased VNs) at blocklength nafterl
iterations for a given code G2 LDPC (;)and codeword pair
c= (c1;c2). Also let Pb(d;l) =1
jCj2P
cPb(d;c;l)denote
the average BER. Then the following holds:
Theorem 2: Asn!1 , for any2[1 :max]
PG;d(jPb(d;l) plj>)!0 (12)
for any>0. 
Proof: The proof is given in Appendix B.
VI. O PTIMIZATION
We can use the DE equations to optimize the degree distribu-
tions. SpeciÔ¨Åcally, deÔ¨Åne
f(y) =y 1 +rmaxX
i=2i
1 1
2L(z(y)(y)i 1
(13)
wherermaxis the maximal CN degree. For Ô¨Åxed , (13) is
linear iniand gives rise to the linear program:
min
X
ii
i
s.t.i0;X
ii= 1;f(y)>8y2(0;1)(14)
where0is a slack variable. For Ô¨Åxed , (8) results in
an optimization problem with linear objective and quadratic
constraints. Details on the quadratic program are given in
Appendix C. Unfortunately, it can be shown that the con-
straints are not positive semideÔ¨Ånite. Therefore, the problem
is not convex in general and a solver is not guaranteed to
converge to the optimal solution. Nonetheless, we Ô¨Ånd that
general purpose quadratic solvers lead to good results and we
are able to empirically Ô¨Ånd degree distributions that achieve
rates close to the BAC capacity by alternating optimization
ofand. To Ô¨Ånd distributions which can be decoded in a
reasonable amount of iterations and are robust to Ô¨Ånite length
Ô¨Çuctuations we follow [19, Sec. VII] and set the slack variable
to=c=pn. The parameter cis set empirically. Higher cwill
result in lower rates but less required decoding iterations.
A. Error-Floor Analysis
In single-user LDPC ensemble constructions, degree one
VNs are usually avoided because they prevent the BER (and
the BLER) from going to zero. Indeed, when two degree
one VNs connect to the same CN, they create a low-weight
stopping set that cannot be recovered, even by an ML decoder.
However, for the two-user frame-asynchronous case, under
certain circumstances, the presence of degree one VNs does
not prevent the BLER from going to zero as n!1 . As we
shall see, this implies that we can increase the rates in the
Ô¨Ånite-blocklength regime without introducing error Ô¨Çoors by
introducing a small fraction of degree one VNs.
In the joint graph, degree one VNs can be recovered through
the MAC nodes, even if they connect to the same CN. In the
following theorem we provide a bound on the probability thata randomly chosen graph with a fraction L1of degree one
VNs has a 4K-sized stopping set, consisting of just degree
one VNs. The case K= 1 is depicted in Fig. 3.
1 2 . . . i i+ 1
1 2 . . . i
Fig. 3: Stopping set of size 4in a joint graph for = 1
Theorem 3: The probability that a random code from the
ensemble LDPC( ;) results in a joint graph that has no
stopping sets of size 4Kcreated by just degree one VNs
for all2[1 :max]can be bounded from below by
1 max
2KX
k=1L2
1
1 Rk1
2k OK
n2
(15)

Proof: See Appendix D.
The above theorem also implies the following result on the
BLER.
Theorem 4: IfL1is sufÔ¨Åciently small compared to max
such that (15) is strictly larger than zero, there exists a constant
fraction of codes in the ensemble with a vanishing BLER. 
Proof: See Appendix D.
Theorem 4 shows that error Ô¨Çoors can be avoided by re-
sampling the code until one is found where the joint graph
contains no 4K-sized stopping sets for a desired range max.
It is necessary that maxis small compared to L2
1=(1 R).1
Note that even if 4K-sized stopping sets of degree one VNs
exist, they only result in bit-errors if all VNs in the set are
erased (i.e., users transmit different symbols), which happens
with probability 2 4K. Therefore it may not be necessary to
expurgate these sets for large K, depending on the desired
BLERs. Besides, Ô¨Åxed length stopping sets result in a number
of bit-errors which does not scale with n. As such, they
could also be corrected by adding an outer code with rate
approaching 1 as n!1 . See also the discussion in [20].
VII. N UMERICAL RESULTS
Table I shows some degree distributions obtained using the
optimization procedure given in Section VI. The slack variable
was adjusted empirically to Ô¨Ånd codes that work with small
blocklength and a reasonable number of required iterations.
The erasure probability for Code 2 in Table I predicted from
DE is shown in Fig. 4 together with some random decoding
realizations with blocklength n= 5104. The empirical
block error rate (BLER) of the codes in Table I is shown
1This can be the case in applications where synchronization is possible but
a small shift is deliberately introduced at the transmitters.Code 1 Code 2 Code 3
L1 0.376 0.560 0.444
L2 0.594 0.371 0.445
L5 0.014
L6 0.016
L7 0.061
L8 0.008 0.111
R4 0.586 0.128 0.323
R5 0.188 0.582 0.489
R10 0.227 0.290
R20 0.188
Design Rate 0.689 0.716 0.733
Mean Iterations 30 30 100
TABLE I: Degree distributions for three codes at different rates.
0 510 15 20 25 30 35 40 45 50 55 6000.10.20.30.40.5
IterationErased Fraction
Fig. 4: Erased fraction of VNs as a function of the number of iterations for
Code 2. The black thick line represents the erasure probability from DE. The
thin lines are sample paths for n= 5104.
in Fig. 5 for a Ô¨Åxed delay = 1. For the code construction
we choose a random sample from the permutation ensemble
and we check if it contains 4K-stopping sets up to K= 3. If
it does, we sample again. The number of required samples is
typically less than 10 for Code 2 and between zero and two
for Codes 1 and 3. We can see in Fig. 5 that the resulting
codes do not show an error Ô¨Çoor. The case with random delay
2[1 :max]is explored in Fig. 6. We choose max= 100
for Code 1 and max= 500 for Codes 2 and 3. The reason
for choosing a smaller maxfor Code 1 is that for n<1000 ,
a delay of several hundred symbols is a signiÔ¨Åcant fraction
of the blocklenght, in which case the number of symbols
where both codewords collide is rather small and hence, the
BER is small, too. This effect also explains the non-monotonic
behavior of the BER for Code 2. Note that both BLER and
BER are limited by 1=maxbecause= 0 will always result
in a block error. As expected from the analysis in Section
VI-A, the codes exhibit an error Ô¨Çoor due to short length
stopping sets caused by degree one VNs and therefore the
corresponding BLERs do not vanish. We can observe in the
simulations that for large enough n, block errors are caused
almost exclusively by 4remaining bit-errors for Code 1 and
3, while Code 2 also occasionally exhibits 8or12remaining
bit-errors. Thus, a high-rate outer code would be sufÔ¨Åcient
to resolve the remaining bit-errors in this case. For example,
a BCH code would sufÔ¨Åce with minimum distance 8or24,
respectively.103104105106 10‚àí310‚àí210‚àí1100
nBLERRate = 0 .688
Rate = 0 .716
Rate = 0 .7326Fig. 5: BLER as a function of nfor= 1.
102103104105106 10‚àí310‚àí2
nBER
Rate = 0 .688
Rate = 0 .716
Rate = 0 .7326
Fig. 6: BER as a function of nfor random2[0;max], withmax= 100
for Code 1, and max= 500 for Code 2 and 3.
REFERENCES
[1] Y . Polyanskiy, ‚ÄúA perspective on massive random-access,‚Äù in 2017
IEEE International Symposium on Information Theory (ISIT) , Jun.
2017, pp. 2523‚Äì2527. DOI: 10.1109/ISIT.2017.8006984.
[2] A. Fengler, P. Jung, and G. Caire, ‚ÄúSPARCs for Unsourced Random
Access,‚Äù IEEE Trans. Inf. Theory , vol. 67, no. 10, pp. 6894‚Äì6915, Oct.
2021. DOI: 10.1109/TIT.2021.3081189.
[3] A. K. Pradhan, V . K. Amalladinne, K. R. Narayanan, and J. Chamber-
land, ‚ÄúPolar Coding and Random Spreading for Unsourced Multiple
Access,‚Äù in ICC 2020 - 2020 IEEE Int. Conf. Commun. ICC , Jun.
2020, pp. 1‚Äì6. DOI: 10.1109/ICC40277.2020.9148687.
[4] E. Marshakov, G. Balitskiy, K. Andreev, and A. Frolov, ‚ÄúA Polar
Code Based Unsourced Random Access for the Gaussian MAC,‚Äù in
2019 IEEE 90th Vehicular Technology Conference (VTC2019-Fall) ,
Sep. 2019, pp. 1‚Äì5. DOI: 10.1109/VTCFall.2019.8891583.
[5] S. S. Kowshik, K. Andreev, A. Frolov, and Y . Polyanskiy, ‚ÄúEnergy
efÔ¨Åcient coded random access for the wireless uplink,‚Äù IEEE Trans.
Commun. , pp. 1‚Äì1, 2020. DOI: 10.1109/TCOMM.2020.3000635.
[6] V . K. Amalladinne, J.-F. Chamberland, and K. R. Narayanan, ‚ÄúA Coded
Compressed Sensing Scheme for Unsourced Multiple Access,‚Äù IEEE
Trans. Inf. Theory , 2020. DOI: 10.1109/TIT.2020.3012948.
[7] D. Truhachev, M. Bashir, A. Karami, and E. Nassaji, ‚ÄúLow-Complexity
Coding and Spreading for Unsourced Random Access,‚Äù IEEE Com-
mun. Lett. , vol. 25, no. 3, pp. 774‚Äì778, Mar. 2021. DOI: 10.1109/
LCOMM.2020.3039436.
[8] A. Fengler, O. Musa, P. Jung, and G. Caire, ‚ÄúPilot-Based Unsourced
Random Access with a Massive MIMO Receiver, Interference Can-
cellation, and Power Control,‚Äù IEEE J. Sel. Areas Commun. , pp. 1‚Äì1,
2022. DOI: 10.1109/JSAC.2022.3144748.
[9] G. Liva and Y . Polyanskiy, ‚ÄúOn Coding Techniques for Unsourced
Multiple-Access,‚Äù in 2021 55th Asilomar Conf. Signals Syst. Comput. ,
Oct. 2021, pp. 1507‚Äì1514. DOI: 10 . 1109 / IEEECONF53345 . 2021 .
9723359.
[10] A. Fengler, G. Liva, and Y . Polyanskiy, ‚ÄúSparse Graph Codes for the
2-User Unsourced MAC,‚Äù in 2022 56th Asilomar Conf. Signals Syst.
Comput. , Nov. 2022.[11] T. Cover, R. McEliece, and E. Posner, ‚ÄúAsynchronous multiple-access
channel capacity,‚Äù IEEE Trans. Inform. Theory , vol. 27, no. 4, pp. 409‚Äì
413, Jul. 1981. DOI: 10.1109/TIT.1981.1056382.
[12] A. Decurninge, P. Ferrand, and M. Guillaud, ‚ÄúMassive Random Access
with Tensor-based Modulation in the Presence of Timing Offsets,‚Äù in
GLOBECOM 2022 - 2022 IEEE Glob. Commun. Conf. , Dec. 2022,
pp. 1061‚Äì1066. DOI: 10.1109/GLOBECOM48099.2022.10001729.
[13] X. Chen, L. Liu, D. Guo, and G. W. Wornell, ‚ÄúAsynchronous Massive
Access and Neighbor Discovery Using OFDMA,‚Äù IEEE Trans. Inf.
Theory , pp. 1‚Äì1, 2022. DOI: 10.1109/TIT.2022.3224951.
[14] A. Roumy and D. Declercq, ‚ÄúCharacterization and Optimization of
LDPC Codes for the 2-User Gaussian Multiple Access Channel,‚Äù J
Wireless Com Network , vol. 2007, no. 1, p. 074 890, Dec. 2007. DOI:
10.1155/2007/74890.
[15] A. Balatsoukas-Stimming, S. Rini, and J. Kliewer, ‚ÄúLDPC Coded
Multiuser Shaping for the Gaussian Multiple Access Channel,‚Äù in 2019
IEEE Int. Symp. Inf. Theory ISIT , Jul. 2019, pp. 2609‚Äì2613. DOI:
10.1109/ISIT.2019.8849785.
[16] R. G. Gallager, Information Theory and Reliable Communication . New
York: Wiley, 1968.
[17] A. E. Gamal and Y .-H. Kim, Network Information Theory . Cambridge
University Press, Dec. 2011.
[18] T. Richardson and R. Urbanke, Modern Coding Theory , Illustrated
edition. Cambridge ; New York: Cambridge University Press, Mar.
2008.
[19] A. Shokrollahi, ‚ÄúRaptor codes,‚Äù IEEE Trans. Inf. Theory , vol. 52, no. 6,
pp. 2551‚Äì2567, Jun. 2006. DOI: 10.1109/TIT.2006.874390.
[20] T. Richardson and R. Urbanke, ‚ÄúThe capacity of low-density parity-
check codes under message-passing decoding,‚Äù IEEE Trans. Inf. The-
ory, vol. 47, no. 2, pp. 599‚Äì618, Feb. 2001. DOI: 10.1109/18.910577.
[21] W. Hoeffding, ‚ÄúProbability Inequalities for Sums of Bounded Random
Variables,‚Äù J. Am. Stat. Assoc. , vol. 58, no. 301, pp. 13‚Äì30, 1963. DOI:
10.2307/2282952.
[22] K. Azuma, ‚ÄúWeighted sums of certain dependent random variables,‚Äù
Tohoku Math. J. (2) , vol. 19, no. 3, Jan. 1967. DOI: 10 . 2748 / tmj /
1178243286.
[23] M. Luby, M. Mitzenmacher, A. Shokrollahi, and D. Spielman, ‚ÄúAnaly-
sis of low density codes and improved designs using irregular graphs,‚Äù
inProc. Thirtieth Annu. ACM Symp. Theory Comput. - STOC 98 ,
Dallas, Texas, United States: ACM Press, 1998, pp. 249‚Äì258. DOI:
10.1145/276698.276756.APPENDIX A
PROOF OF THEOREM 1
Proof: We start by reformulating the decoding problem on
the frame-asynchronous UBAC in terms of the parity check
matrix H2Fn kn
2 of a linear code. Let m1;m2be two
codewords, i.e., Hm 1=Hm 2= 0, and let both codewords
be transmitted through the BAC (1) for some Ô¨Åxed . Let
E=fi:yi= 0gand denote the shifted set by E :=
fi:yi+= 0g. Fori2 E we havem1;i= 1 m2;i .
LetHEdenote the sub-matrix of Hwith column indices in
Eand, analogously, mu;Ebe the restriction of muto the set
E. Note that onE= [n]nEthe entries of m1are known and
similarly onE the entries of m2are known. Therefore,
we can compute the two syndromes:
s1=HEm1;E
s2=HE m2;E (16)
andm1satisÔ¨Åes the two constraints:
HEm1;E=s1
HE m1;E=HE (1 m2;E )
=HE 1 s2=:~s2(17)
We can deÔ¨Åne ~H= [H 0;0H]2F2(n k)(n+)
2 . With this
(17) can be written as ~HEm1;E= [s1;~s2]. This equations can
be solved if the rank of rank (~HE)>jEj.
Now let the entries of the parity check matrix Hbe
Bernoulli(1/2) i.i.d. and deÔ¨Åne r=n k. For some arbitrary
erasure setE[:n]of sizedwe compute the probability
Pdthat a sub-matrix ~HEof~Hof size 2rdhas rankd. Note
that this probability is well deÔ¨Åned since it does only depend
on the size ofEbut not on the actual set. The complications
in the proof, compared to standard techniques, arise from the
fact that ~Hmay contain the same vectors in top and bottom
half, in which case we cannot assume anymore that they are
independent. We can bound Pdas follows:
PddY
k=1
1 2k+1
22r
(18)
To get the bound we compute the smaller probability ~Pdthat
HEhas rankdand the following condition is fullÔ¨Ålled:
i) Non of the top half vector from HEare in the column
span of the bottom half HE .
We compute ~Pdrecursively by adding the indices in Ein
increasing order: Let Ekdenote the sub-set of Ewith only
the Ô¨Årstkindices. Assume the columns of ~HEk 1are linearly
independent and condition i) is satisÔ¨Åed. If one column ~hi:=
[hi;hi ]is added, the resulting set will be linearly dependent
iff~hi2span(~HEk 1 )g:=I1. In addition, condition i)
will be broken if fhi2span(HEk 1 )g:=I2happens.
I1can be further decomposed into the two disjoint events
I1;1=I1\fi 2Ek 1gandI1;2=I1\fi  =2Ek 1g. The
conditional probability of I1;1is zero due to the assumption
that condition i) is fullÔ¨Ålled. On the other hand, if i  =2Ek 1thenhi is independent of ~HEk 1and the probability that
I1;2\I2happens is (1 (2k 1+ 2k)=22r)since there are
2k 1binary vectors in the span of HEk 1and2kvectors in
the span of [HEk 1 ;hi ]. So we can bound ~Pdas
~Pd
1 2k+1
22r
~Pd 1 (19)
which proves (18).
For a Ô¨Åxed parity check matrix H, the probability of de-
coding the Ô¨Årst codeword wrong, averaged over all codeword
pairs, is given by
Pe;H= 1 n X
d=1P(jEj=d)1(rank(~HE) =d) (20)
Letn0:=n anddmax=n0=2 +n0. We can writejEj=Pn0
i=1Xiwhere we deÔ¨Åne Xi:=1(c1;i= c2;i ). It holds
thatE[Xi] = 1=2, Var[Xi] = 1=4,2and theXiarepairwise
independent3. Therefore Var (jEj) =n=4and Chebychev‚Äôs
inequality shows that for any >0
PjEj n
2>n
1
4n: (21)
Since 1(rank(~HE)d)is non-increasing in dwe have
Pe;H1 1(rank(~HE) =dmax)P(jEjdmax)
1 1(rank(~HE) =dmax) +on(1):(22)
Note that the channel is noiseless. Therefore, if one codeword
is correctly recovered the second one can be obtained by
subtracting the Ô¨Årst. Also, it is irrelevant which codeword we
attempt to decode since both users share the same ~HE. For
simplicity we assume that dmax= (n +)=2is an integer.
Averaging (22) over the code ensemble we get
Pe1 ~P(n +)=2+on(1)
=n +
22n(1=2 2(1 R))+on(1)(23)
An alternative proof for the slightly different linear code
ensemble of iid random generator matrices G2Fkn
2 can be
sketched as follows: Let (xi)0=xi fori >  denote the
left-shift of a vector entry by some Ô¨Åxed and let u1;u22Fk
2
be the transmitted bit sequences. Then the channel output reads
as
y= (u1G) + (u2G)0(24)
W.l.o.g. we can choose u1=e1andu2=e2. For arbitrary
u1;u2we can Ô¨Ånd a basis which has u1;u2as Ô¨Årst two basis
vectors and work in the new basis. Since the distribution of G
2This holds for all typical codes, that is those which have a marginal bit
distributions close to Bernoulli(1/2). It can be shown easily that all but an
exponentially small fraction of random parity check codes are typical. So we
can restrict parity check matrices to be typical.
3Again, this is true for all but an exponentially small fraction of parity
check matrices. This can be seen by bringing Hinto systematic form. Then
the Ô¨Årstkdata bits are clearly independent and two of the n kparity check
bits are dependent if and only if they are sums of the exact same set of bits.is invariant under basis change this does not affect the error
probability.
Conditioned on the two rows g1;g2the error probability is
given by
Pe;G=P([
v1;v2f(v1G) + (v2G)0=g1+g0
2gjg1;g2)(25)
We partition the space of possible sequences v1;v2into two
setsAandAcsuch that sequences in Aare zero in the Ô¨Årst
two positions. Within A,v1G;v2Gare independent of g1;g2.
Furthermore, we distinguish two cases. First, that v1andv2
both contain at least one unique bit. In this case we can treat
them as independent vectors and bound the error probability,
averaged over Gn[g1;g2]as
Pe22(k 2)P(b1+b2= 0)jY0jP(b1+b2= 1)jY1j
P(b1+b2= 2)jY2j(26)
whereb1;b2are independent Bernoulli(1/2) distributed bits
andYl=fi:yi=lg. Averaging over g1;g2gives
Pe22(k 2)1
4n=41
2n=21
4n=4
+on(1)
= 2n(2R 1:5)+on(1)(27)
In the second case, where v2is of the form v2=v1ufor
some vector uthat is independent of v1. We get probabilities
of the form P(b1+ (b1b2) =j)forj2f0;1;2g, leading
to (we skip the intermediate steps):
Pe22(k 2)1
4n
+on(1) = 2n(2R 2)+on(1) (28)
It remains to estimate the error probabilities in Ac. First note
that whenever v1;v2both contain at least one unique bit they
can be treated as independent and we get the same bound as
(27). Also, if only one of them contains a random vector, e.g.,
v1=g1;v2=g2u, then there is at most one values of ui
for eachiwhich replicates the channel values. Resulting in
Pe2k 21
2n
+on(1) = 2n(R 1)+on(1) (29)
This leaves only 15possible cases, most of which are trivial
or can be reduced by symmetry to one of the following 4
non-trivial cases:
Case 1: v1=g1u;v2=g2u
We explicitly write down the equations that need to be
satisÔ¨Åed for an error to occur (wlog for = 1):
g1;iui+g2;i 1ui 1=g1;i+g2;i 1 (30)
This can only be satisÔ¨Åed if ui=ui 1which happens
with probability 1=2. Therefore we can bound the error
probability
Pe2k 21
2n
+on(1) = 2n(R 1)+on(1) (31)
Case 2: v1=g1g2u;v2=u
In this case there are some channel values that cannotbe replicated. E.g. g1;i=g2;i= 0 andg2;i 1= 1, then
yi= 1, butg1;ig2;i= 0. So neither values if uican
replicate the channel output. Therefore Pe= 0 +on(1).
Case 3: v1=g1g2u;v2=g1u
Similar to Case 2, giving Pe= 0 +on(1)similar to Case
2.
Case 4: v1=g1u;v2=uIfyi= 1both(ui;ui 1) =
(0;1)and(ui;ui 1) = (1;0)result in the correct channel
output for both g1;i= 0 andg1;i= 1
Pe2k 21
4n=21
2n=2
+on(1) = 2n(R 1:5)+on(1)
(32)
The most restricting constraint is (27), allowing for any R<
3=4.
APPENDIX B
PROOF OF THEOREM 2
The outline of the proof is as follows:
Lemma 1 shows that Pbwith Ô¨Åxed dither concentrates
around the dither average. Corollary 1 shows that Pbfor a
Ô¨Åxed codeword pair concentrates around the average over all
codeword pairs. Lemma 2 establishes that the dither average
is independent of the transmitted codewords. Lemma 3 states
that the computation tree for each VN is with high probability
tree-like for a Ô¨Åxed depth lasn!1 . Finally, we argue that
thatPbfor any Ô¨Åxed random graph concentrates around the
ensemble average, which concludes the proof of Theorem 2.
The proof will make repeated use of Azuma-Hoeffding‚Äôs
inequality [21], [22] applied to so called Doob martingales,
which are conditional expectations of the form
Yi=E[f(X1;:::;Xn)jX1=x1;::;;Xi=xi] (33)
for some function fand a (not necessarily iid) sequence of
RVs(Xi)i=1;:::;n. It holds that Y0=E[f],Yn=f(x1;:::;xn),
and
Theorem 5 (Azuma-Hoeffding for Doob Martingales):
Suppose thatjYk Yk 1jdkfor a sequence (dk)k=1;:::;n
of non-negative reals. Then for >0it holds
P(jYn Y0j>)2 exp
 2
2Pn
k=1d2
k
(34)

The next lemma shows that for two Ô¨Åxed transmitted
codewords any randomly chosen dither sequence, with high
probability, will result in a bit-error rate that is close to the
bit-error rate averaged over all dither sequences.
Lemma 1:
P(jPb(d;c1;c2) E[Pb(d;c1;c2)]j>)exp( Cn)
(35)
for some constant C > 0and any>0.
Proof: DeÔ¨Åne the Doob martingale Yi =
E[Pb(d)jd1;:::;di]. Since any dither value diaffects at
most two VNs and all VNs included in their depth lcomputation graphs, the number of affected VNs is upper
bounded by a constant that does not scale with n. This
constant can be bounded by the maximal VN and CN degrees
in the graph as we will show later as part of the proof of
Lemma 3. Therefore Yihas bounded increments and the
concentration inequality (35) follows from (34).
In fact, also the stronger statement holds, that a randomly
chosen dither can be used for all codeword pairs (c1;c2).
Corollary 1:
P 1
jCj2X
c1;c2Pb(d;c1;c2) E[Pb(d)]>!
exp( C0n)(36)
for some constant C0>0and any>0.
Proof: First, it holds that
Pc0
1;c0
2(jPb(d) Pb(d;c0
1;c0
2)j>)exp( C00n)(37)
for some constant C00>0, any>0and any Ô¨Åxed d. This
can be shown by applying Azuma-Hoeffding‚Äôs inequality to
the martingale that reveals c0
1andc0
2component by compo-
nent. Since each component affects at most a Ô¨Ånite number of
VNs in the depth lneighborhood, the martingale has bounded
increments. Furthermore,
Pd(jPb(d) E[Pb(d)j>)
=Pc0
1;c0
2;d(jPb(d) Pb(d;c0
1;c0
2)
+Pb(d;c0
1;c0
2) E[Pb(d)j>)
Pc0
1;c0
2;d
jPb(d) Pb(d;c0
1;c0
2)j>
2
+Pc0
1;c0
2;d
jPb(d;c0
1;c0
2) E[Pb(d)j>
2
2 exp( C0n)(38)
where the last inequality follows by applying (35) and (37),
integrating, and setting C0= maxfC;C00g=2.
The next lemma will show that the channel output, when
averaged over the distribution of the dither, is iid and does not
depend on the transmitted codewords c1;c2. Therefore, when
evaluating E[Pb(d)], we can assume that both users transmit
the all-ones codeword.
Lemma 2: For any two transmitted codewords c1;c2and
any setS[+ 1 :n], each symbol in the channel output is
erased independently with probability 1=2, i.e.,
Pd(yS=0) =1
2jSj
: (39)

Proof: Sincedi;djare independent if i6=j, we have
p(yi= 0) =p(dic1;i+di c2;i = 0) =1
2sincedic1;i
anddi c2;i are independent and uniform over f 1;1g.
Dependencies may occur only if diis shared in multiple
channel outputs. Note that only yiandyi+includedi. Wecan compute
p(yi= 0;yi+= 0)
=p(yi+= 0jyi= 0)p(yi= 0)
=1
2p(di+c1;i++dic2;i= 0jdic1;i+di c2;i = 0)
=1
2p(di+c1;i+=di c2;i )
=1
4
(40)
where the last inequality follows because di+anddi are
independent. An arbitrary set Scan be handled by using (40)
repeatedly.
User 1
User 1
User 2
User 1T
‚àíœÑ ‚àíœÑ‚àíœÑ‚àíœÑ
T
+œÑ
T
Fig. 7: Computation Graph, T denotes the basic LDPC computation tree
with one VN connected to its adjacent CNs which in turn connected to their
adjacent VNs.
Next, we show that for a random code from LDPC( ;)
the depthlcomputation graph rooted at a VN is a tree
with high probability. Fig. 7 depicts the structure of the
computation graph of an arbitrary VN of user 1. The root
node is connected to one MAC node (triangle) and a variable
number of check nodes, which in turns connect to other
variable nodes, which connect to other check nodes. After this
point, at each additional iteration the structure of parity checks
followed by MAC nodes is recursively repeated ltimes. The
number of leaves of each element, denoted by T, is an iid
random variable whose distribution can be calculated from
the left and right degree distributions. Here, we only need
an upper bound on the number of leaves, which is given by
nmax=lmaxrmax+ 1wherelmaxandrmaxare the maximal VN
and CN degrees. We next show that for a randomly chosencode from the ensemble LDPC( ;) the probability that the
nodes in a computation graph with root VN i,i= 1;:::;2n,
contains only distinct VNs, and is therefore a tree, can be
bound as follows.
Let us represent the VNs as two vectors v1;v22f0;1gn+
with zero padding, i.e. v1;j= 0 forj2[n+ 1 :n+]
andv2;j= 0 forj2[0;]. LetVudenote the set of VNs
for useru,u2f1;2g. Due to the same-codebook constraint,
the neighborhood of v1;iis the same as the neighborhood of
v2;i+. The neighborhood of some Ô¨Åxed VN, without loss of
generality inV1, at depthtcan be recursively expressed as
follows. LetN2t()denote the neighborhood of root VN i
(we drop the index ifor readability) at depth tin the joint
graph with offset . We also drop the dependence on when
immaterial. We split the neighborhood as N2t=N2t
1[N2t
2
whereN2t
1;N2t
2denote the neighbors in V1andV2respec-
tively. LetN0
1=ibe the root. We can describe the evolution
ofN2t
u,u=f1;2g, with increasing depth as follows. DeÔ¨Åne
the shifted setsN:=fi:i=j;j2Ng .
1)N2t+1
1 =N2t
1[Vt;1whereVt;1is the set of nodes in
V1that connect to N2t
1through a CN.
2)N2t+1
2 =N2t+1
1 . The right hand side (rhs) is the
set of nodes inV2that connect to Nt+1through MAC
nodes.
3)N2t+2
2 =N2t+1
2[Vt;2whereVt;2is the set of nodes in
V2that connect to N2t+1
2 through a CN.
4)N2t+2
1 =N2t+2
2 +. The rhs is the set of nodes in V1
that connect to N2t+2
2 through MAC nodes.
Note that for a random code from the ensemble LDPC( ;)
the setsVt;uare random.
Lemma 3:
P(N2T()is not a tree for some 2[1 :max])
n
wheredepends on T;; andmaxbut not onn.
Proof: The proof follows the structure of [20], [23].
Assume that the computation graph at iteration t,t < T , is
a tree.4We need to compute the probability that any of the
four steps in the construction of the neighborhood of a VN
introduces a cycle. Note, that only the sets Vt;uare random
since the MAC connections are Ô¨Åxed. No cycle is introduced
ifVt;1\N2t
1=Vt;2\N2t+1
2 =;. In addition, since we need
to take the same-codebook constraint into account, we also
require that
Vt;u\fN2t
u+g=; 82[1 :max] (41)
foru=f1;2g. Note that (28) is necessary because otherwise
there would be a for whichN2t+1
2 contains a node which is a
mirrored copy of a node in N2t+1
1. This implies that the edges
connected to it are Ô¨Åxed and cannot be considered random
iid anymore. Even though the event (41) does no necessarily
result in a cycle, we treat it as such to get an upper bound
on the probability that a computation graph is cycle-free. This
increases the number of VNs that results in a cycle by a factor
4The Ô¨Årst iteration is special as it has one more connection than the others,
as depicted in Fig. 7. It is apparent that this does not change the proof.(1+max) in each iteration compared to the case without MAC
connections. Intuitively it is clear that this does not change the
basic proof idea of [20] since the size of a neighborhood after
titerations does still not scale with n. Nonetheless, we give a
formal proof for completeness. Let cT
uandvT
u=jN2T
ujdenote
the number of CNs and VNs in the computation graph of user
uafterTiterations inVu. Then, at iteration t+ 1, the number
of newly added CNs is at most
ct+1
u ct
uvt
ulmax (42)
and the number of newly added VNs is at most
vt+1
u vt
uct+1
urmax: (43)
Both of these quantities can be upper-bounded independently
of the index u=f1;2g, so we drop it. Furthermore, vT
vtandcTctforTt. Conditioned on the event that
N2(T 1)()is a tree for all 2[1 :max], going one step
deeper will result in no cycles if the edges from the new VNs,
of which there are vT vT 1, meet two conditions: First,
they connect to distinct, not yet visited, CNs. And second, the
resulting new CNs connect to distinct VNs that are neither in
the set ofcT 1already visited VNs nor in the same set shifted
by some. Both copies of the graph follow the same rules
and have distinct sets of VNs and CNs, so we can bound them
in the same way. The resulting probability is
P(N2T()is a tree8jN2(T 1)()is a tree8)

1 (1 +max)cT
m(1+max)(cT cT 1)

1 (1 +max)vT
n(1+max)(vT vT 1)(44)
So we obtain recursively that
P(N2Tis a tree8)
TY
t=1P(N2tis a tree8jN2(t 1)is a tree8)

1 (1 +max)cT
m(1+max)cT

1 (1 +max)vT
n(1+max)vT
1 ((1 +max)vT)2+((1+max)cT)2
1 R
n(45)
and therefore
P(N2T
iis not a tree )((1 +max)vT)2+((1+max)cT)2
1 R
n(46)
We conclude the proof by giving bounds on cTandvT
cTlmaxT 1X
t=1vtlmax(T 1)vT 1(47)
vTrmaxTcTlmaxrmaxT2vT 1(48)which gives
vT(lmaxrmaxT2)T(49)
cTlmax(T 1)(lmaxrmaxT2)T 1: (50)
We conclude the proof by noting that both upper bounds on
cTandvTare independent of n.
To conclude the proof of Theorem 2 it remains to show
thatEd[Pb(d)]converges to the ensemble average over G2
LDPC(;) asn!1 . We omit a full proof and give only
an outline since it follows, almost without modiÔ¨Åcations, the
proof in [20]. By Lemma 2 assume that the channel output
is iid in the computation of EG;d[Pb(d)]. By Lemma 3 we
can reduce the computation of EG;d[Pb(d)]toEG[1(vl
i==
)jNl
iis a tree ]wherevl
i;i= 1;:::;2n, denotes the value of
thei-th VN after literations. The convergence of the edge
erasure probabilities to the ensemble average can be shown
by constructing an edge exposure martingale. In our case
each revealed edge affects both users‚Äô graphs so the number
of edges affected in the depth lneighborhood doubles. It is
apparent that the martingale still has bounded increments as
the number of edges in the depth lneighborhood of a given
edge does not scale with n. Together with Lemma 1 and
Corollary 1 this concludes the proof.
APPENDIX C
DETAILS ON DEGREE OPTIMIZATION
The optimization of for Ô¨Åxedcan be expressed in standard
form as follows.
g(x) =x 1
2L(z(x))(z(x))
=x 1
2(Pi
i)THx(51)
whereHx;ij=z(x)ij 1
iandz(x) = 1 (1 x). We get the
optimization problem:
max
;
s.t.Xi
i = 0;i0;X
i= 1;
THx 2(x )<08x2(0;1)(52)
APPENDIX D
ERROR FLOOR ANALYSIS
Throughout this section we use the term 4Kstopping set ( 4K-
SS) to denote stopping sets of size 4Kconsisting of just degree
one VNs.
Theorem 6: The probability that a random code from the
ensemble LDPC( ;) results in a joint graph that has no 4-SS
for all2[1 :max]can be bounded as
P(G()has no 4-SS82[1 :max])
1 maxL4
1
2(1 R)2(53)
Proof: There are L1n
2
n2L2
1=2pairs of degree one
VNs. Letnc= (1 R)ndenote the number of CNs. The
probability that a pair of VNs is connected to the same CN is
1=nc. Also let ~pdenote the probability that 4-stopping set
appears that contains a given pair of VNs (v1;v2)in the
joint graph with Ô¨Åxed . It is given by ~p=L2
1=nc, i.e., the
probability that the nodes connected to (v1;v2)through MAC
nodes are both of degree one and connect to the same CN.
The degrees and edges of all maxVNs to the right of (v1;v2)
are independent and therefore the probability that at least one
of the joint graphs with shift contains a 4-SS is given by
1 (1 ~p)max. LetN4denote the number of 4-SSs and Ipthe
event that a 4-SS goes through pair (v1;v2). Then the expected
number of 4-SSs is given by
E[N4] =E2
64(L1n
2)X
p=1Ip3
75
L2
1n2
c
2(1 R)21
nc
1 
1 L2
1
ncmax
maxL4
1
2(1 R)2(54)
The last inequality follows because (1 x)1 x. If
the expected number of 4-SSs is smaller than 1 there must be
graphs in the ensemble that result in zero 4-SSs. Furthermore,
for any non-negative random variable Nit holds that P(N=
0)1 E[N].
Proof of Thm. 3: LetkK. There are L1n
2k

n2kL2k
1=(2k)!k-tuples of degree one VNs. Let nc= (1 R)n
denote the number of CNs. For each 2k-tuple there are
(2k 1)!!ways to partition them in pairs, where (2k 1)!! =
(2k 1)(2k 3):::1denotes the double factorial. The
probability that each pair is connected to the same CN is
n k
c. Let ~p2kdenote the probability that a 4k-SS goes through
a given 2k-tuple in the joint graph with Ô¨Åxed . Note that
the degrees and edges of the neighbor sequence are not
independent if the original tuple of VNs contains a consecutive
sequence of length at least three. We show later that their
contribution to the expected number of 4k-SSs is at most
of orderO(1=n2)and results in the correction term in (15).
For now we consider only 2k-tuples which do not contain
consecutive sequences. For those, the degrees and edges of
the neighbor sequence are independent of the original tuple.
A4k-SS is created if the 2k-tuple connected by MAC nodes
consist of only degree one VNs which connect to kCNs in a
conÔ¨Åguration that does not result in shorter SSs. With respect
to random permutations of VNs and edges this happens with
probability
~p2k(2k 1)!!L2k
1
nkc(55)
Here we have trivially lower bound the conÔ¨Ågurations that
result in SSs smaller than 2kby zero. The probability that at
least one of the joint graphs with shift contains a 2k-SS isgiven by 1 (1 ~p2k)max. LetN4kdenote the number of 4k-
SSs andIp;2kthe event that a 4k-SS goes through the 2k-tuple
p. Then the expected number of 4k-SSs is given by
E[N4k] =E2
64(L1n
2k)X
p=1Ip;2k3
75
(2k 1)!!L2k
1n2k
c
(2k)!(1 R)2k1
nkc(1 (1 ~p2k)max)
+O1
n3
maxL2
1
1 Rk((2k 1)!!)2
(2k)!+O1
n3
maxL2
1
1 Rk1
2k+O1
n2(56)
The second inequality follows because (1 x)1 x.
The expected number of SSs up to length 4KisE[N4K] =PK
k=1E[N4k]. IfE[N4K]is smaller than 1 there must be
graphs in the ensemble that result in zero SSs of size smaller
than 4Kbecause for any non-negative random variable Nit
holds that P(N= 0)1 E[N].
It remains to show that the number of 2k-tuples that contain
consecutive sequences is of order O(1=n2). The number of
length 2l+ 1sequences is at most linear in nwhile it reduces
the probability that the neighbor sequence connects to kCNs
by at most a factor of nl
c. Therefore, the expected number of
4k-SSs that go through at least 2l+ 1 consecutive VNs can
be bound loosely by a O(n=n2k l)term. Since lk 1the
term is maximized for l=k 1andk= 2giving the desired
result.
Proof of Thm. 4: The proof follows by noting that the
probability of having stopping sets with VNs with degree
larger than one connected to the same set of CNs will go
to zero asn! 1 . Indeed, the smallest possible stopping
set containing degree two VNs is the one where two degree
one VNs connect to the same CN, and two degree two VNs
connected to the same pair of CNs. Their expected number
can be upper-bounded by L2n
2
L2
1=n3
c=O(1=n)sincenc
scales withn. Any larger stopping set containing degree two,
or higher, VNs will have an even smaller expected number.
Thus, asn!1 , we can have only stopping sets involving
degree one VNs, which implies that expurgating the randomly
generated graphs that contains these stopping sets guarantees
a vanishing BLER as ngrows.