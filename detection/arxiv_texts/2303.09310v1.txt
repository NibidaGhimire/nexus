GLH-Water: A Large-Scale Dataset for Global Surface Water Detection in
Large-Size Very-High-Resolution Satellite Imagery
Yansheng Li* Bo Dang Wanchun Li Yongjun Zhang
Wuhan University, Wuhan, China
fyansheng.li, bodang, wanchun.li, zhangyj g@whu.edu.cn
Abstract
Global surface water detection in very-high-resolution
(VHR) satellite imagery can directly serve major applica-
tions such as reÔ¨Åned Ô¨Çood mapping and water resource as-
sessment. Although achievements have been made in de-
tecting surface water in small-size satellite images corre-
sponding to local geographic scales, datasets and methods
suitable for mapping and analyzing global surface water
have yet to be explored. To encourage the development of
this task and facilitate the implementation of relevant ap-
plications, we propose the GLH-water dataset that consists
of 250 satellite images and manually labeled surface water
annotations that are distributed globally and contain wa-
ter bodies exhibiting a wide variety of types ( e.g. , rivers,
lakes, and ponds in forests, irrigated Ô¨Åelds, bare areas, and
urban areas). Each image is of the size 12,800 12,800
pixels at 0.3 meter spatial resolution. To build a benchmark
for GLH-water, we perform extensive experiments employ-
ing representative surface water detection models, popu-
lar semantic segmentation models, and ultra-high resolu-
tion segmentation models. Furthermore, we also design
a strong baseline with the novel pyramid consistency loss
(PCL) to initially explore this challenge. Finally, we imple-
ment the cross-dataset and pilot area generalization exper-
iments, and the superior performance illustrates the strong
generalization and practical application of GLH-water.
The dataset is available at https://jack-bo1220.
github.io/project/GLH-water.html .
1. Introduction
As one of the fundamental components of the Earth‚Äôs
natural ecosystem, surface water plays a critical role in
maintaining biodiversity, ecological balance, and the devel-
opment of human societies [47]. Due to its wide spatial
and temporal distribution, using satellite imagery to detect
and map the global surface water is a feasible and conve-
*corresponding author.
Figure 1. Visualization of the GLH-water dataset. We show the
geographical coverage of the samples. Several examples from dif-
ferent continents are selected and their image acquisition times and
scene descriptions are provided.
nient method, leading to promising breakthroughs that are
applied in the Ô¨Çood mapping [33, 52], surface water changes
[13, 38], and other assessments of water resources [51, 17].
Compared to synthetic aperture radar (SAR) im-
agery, very-high-resolution (VHR) optical satellite imagery
(Ground Sampling Distance, GSD <5m) has the advantage
of providing clearer texture and detail information about
water. In contrast, medium- and low-resolution optical im-
ages can only detect large surface water bodies, while small-
scale water bodies and their intricate details can only be
captured by VHR optical satellite imagery.
To our knowledge, no publicly suitable data has been
proposed to effectively facilitate the training and evaluation
of surface water detection methods in global VHR optical
imagery, as highlighted in Table 1, which seriously hinders
the advancement of global VHR surface water body map-
ping tasks. In addition, the size of VHR satellite images of
1arXiv:2303.09310v1  [cs.CV]  16 Mar 2023Dataset DeepWaterMap [21] ESKWB [31] SWED [40]2020 GF
challenge [43]Landcover.ai [1] Agriculture-vision [5] LoveDA [49] FBP [46] DynamicEarthNet [44] OpenEarthMap [54] GLH-water (ours)
Dedicated to surface
water detection tasks4 4 4 4 4
Global sample 4 4 4 4 4 4
VHR 4 4 4 4 4 4 4 4
Large-size imagery 4 4 4
Large-scale dataset 4 4 4
Table 1. Characteristics of GLH-water dataset compared with other public datasets. The analysis demonstrates that the GLH-water
is the Ô¨Årst large-scale dataset for global surface water detection in large-size VHR optical satellite imagery. VHR means GSD <5m.
Large-size imagery means that size of each image is larger than 10,000 10,000 pixels. Large-scale dataset means the
total number of images is equivalent to more than 100,000 tiles of 512 512 pixels in size.
the whole scene is typically large ( e.g. , the standard scene
size of GaoFen-2 satellite images is approximately 6,000
6,000 pixels). Extracting complete and continuous water
bodies from large-size images poses not only a greater chal-
lenge that remains unexplored, but also is closer to practical
applications such as large-scale surface water mapping.
To promote research on this challenging task and to sup-
port applications like higher-resolution global surface wa-
ter mapping, we propose GLH-water , a large-scale dataset
for global surface water detection in large-size VHR optical
satellite imagery. We collect 250 VHR (GSD=0.3m) optical
satellite images of 12,800 12,800 pixels containing vari-
ous water types from the whole world, and create accurate
annotations through manual labeling and expert inspection,
as shown in Figure 1. GLH-water signiÔ¨Åcantly differs from
other existing datasets analyzed in Table 1, with advantages
focusing on the following aspects: (1) large-size images;
(2) a large number of samples; (3) extensive geographical
coverage of the samples; (4) broad temporal span of image
acquisition; (5) inclusion of diverse types of surface water.
These variations and traits give GLH-water its uniqueness
and present new challenges for detecting surface water from
large-size VHR optical satellite imagery.
Furthermore, to evaluate the dataset and explore this
challenging task, we evaluate the performance of repre-
sentative surface water detection models, well-performing
general semantic segmentation models and ultra-high reso-
lution segmentation methods on GLH-water , and combine
their metrics to create a benchmark. Motivated by multi-
layer visual Ô¨Åeld difference of the image pyramid and the
topological continuity of surface water in large-size satel-
lite images, we propose a strong baseline with the new pyra-
mid consistency loss (PCL) to offer a promising pipeline for
this challenge. Finally, we conduct extensive experiments to
demonstrate the strong generalization of GLH-water and its
potential application value. In summary, our contributions
are as follows:
‚Ä¢ We present the Ô¨Årst large-scale dataset for global sur-
face water detection in large-size VHR optical satel-
lite imagery, which offers signiÔ¨Åcant advantages for
tackling the challenge of detecting surface water from
large-size satellite images that remains unexplored.‚Ä¢ We evaluate a variety of semantic segmentation models
onGLH-water , including representative surface water
detection models, advanced segmentation models, and
ultra-high resolution segmentation algorithms, which
can serve as a benchmark for the development of future
methods.
‚Ä¢ We further propose a novel strong baseline with the
PCL, which yields signiÔ¨Åcant improvements and sug-
gests that it will be a competitive pipeline for future
development.
In the future, GLH-water and strong baseline we pro-
posed are also expected to provide reliable training data and
models for manufacturing the global high-resolution sur-
face water map.
2. Related work
2.1. Relevant datasets
Surface water detection datasets. The upper portion of
Table 2 displays existing datasets speciÔ¨Åcally designed for
detecting surface water bodies. The majority of currently
available datasets [19, 21, 31, 40] for surface water de-
tection based on optical satellite imagery exhibit only low
to medium spatial resolution, as seen with Landsat-8 and
Sentinel-2 images. The resolution limitations of the images
result in the blurring and indistinguishability of small rivers
and lakes. To track intricate surface water systems, research
endeavors direct their experimental focus towards commer-
cial satellites that offer high resolution of up to 1m or even
0.3m, such as GeoEye and WorldView [37, 52]. Regret-
tably, owing to the policy constraints of commercial satel-
lites, these datasets will not be made available to the public
community and only be allowed to conduct private exper-
imental validation for their owners. In contrast, our GLH-
water is the Ô¨Årst publicly available large-scale dataset for
surface water detection from global VHR optical satellite
imagery.
Land use and land cover (LULC) datasets. As a funda-
mental application in the Ô¨Åeld of remote sensing, datasets
related to LULC are extensively created and utilized, and
they commonly encompass the class of water. However,
they inadequately fulÔ¨Åll the need of tasks such as reÔ¨Åned
2Dataset # Images # Channels Image size (pixels) GSD (m) # Labeled pixels (billion) Sources Geographic coverage Acquisition
Dedicated surface water detection dataset
DeepWaterMap [21] >140000 6 - 30 - Landsat-8 Globe Public
WSD [19] 16320 3 256√ó256 30 1.07 Landsat-8 - Private
ESKWB [31] 95 6 545 1432√ó6251527 10 0.11 Sentinel-2 Globe Public
SWED [40] 1862 12 256√ó256 10 0.12 Sentinel-2 Globe Public
SWB 2841 3 57 5292√ó576767 10 - Sentinel-2 - Public
2020 GF challenge [43] 1000 3 492 2000√ó4922000 1 to 4 0.24 GaoFen-2 - Public
Moortgat et al. [37] 142 4/8 10000√ó10000 1.2 14.2 GeoEye etc. Arctic Private
Wieland et al. [52] 1120 4 2048√ó2048 0.8 4.69 IKONOS etc. Globe Private
LULC dataset (including water bodies)
DeepGlobe [10] 803 3 2448√ó2448 0.5 4.81 DigitalGlobe - Public
GID [45] 10/150 3/4 7200√ó6800 4 7.34 GaoFen-2 China Public
Landcover.ai [1] 41 39000√ó9500/
4200√ó47000.25/0.5 3.50Public Geodetic
ResourcePoland Public
Agriculture-Vision [5] 94986 4 512√ó512 0.1/0.15/0.2 24.9 UA V camera United States Public
LoveDA [49] 5987 3 1024√ó1024 0.3 6.27 Google Earth China Public
FBP [46] 150 4 7200√ó6800 4 7.34 GaoFen-2 China Public
UrbanWatch [59] 200 4 512√ó512 1 0.05 NAIP United States Public
DynamicEarthNet [44] 54750 4 1024√ó1024 3 57.40 PlanetFusion Globe Public
OpenEarthMap [54] 5000 3 1024√ó1024 0.25-0.5 5.24 - Global 97 regions Public
GLH-water (our) 250 3 12800√ó12800 0.3 40.96 Google Earth Globe Public
Table 2. Comparison among GLH-water and other relevant datasets. All datasets are compared on number of images and channels,
image size, spatial resolution (GSD), data sources, geographic coverage and acquisition.
global surface water detection and mapping. The reason
is that none of them can simultaneously satisfy the trin-
ity of global sampling, VHR, and large-size imagery, as
demonstrated in the lower portion of Table 2. For exam-
ple, FBP [46] originates from the VHR and large-size im-
ages of GaoFen-2 satellite. However, it is conÔ¨Åned to a lim-
ited selection of cities in China, speciÔ¨Åcally Beijing, and
migration of the trained model to other regions presents a
challenge. Similarly, the geographic coverage of the Land-
cover.ai [1] is restricted to Poland, and the trained models
are limited in scale and generalizability. The image size of
DynamicEarthNet [44] is only 1,024√ó1,024 pixels, insuf-
Ô¨Åcient to effectively portray the distribution of water bod-
ies, a characteristic with notable geospatial continuity. In
contrast, our GLH-water offers distinct advantages such as
global sampling, VHR, large-size imagery. These attributes
are essential for executing surface water mapping tasks on
a global scale.
2.2. Relevant methods
Surface water detection methods based on non-deep
learning algorithms. Normalized Difference Water Index
(NDWI) [34], ModiÔ¨Åed Normalized Difference Water In-
dex (MNDWI) [55], High Resolution Water Index (HRWI)
[56], Two-step Urban Water Index (TSUWI) [53], and other
threshold-based water indices are commonly proposed and
implemented in initial studies. However, their reliance on
spectral information result in a lack of consideration for
the spatial information present within the images. Addi-
tionally, shallow classiÔ¨Åers such as Support Vector Machine(SVM) and modiÔ¨Åed Statistical Region Merging (SRM) are
employed and show signiÔ¨Åcant improvements [60, 53, 42].
Surface water detection methods based on deep learn-
ing algorithms. The VHR optical satellite imagery com-
prises of a range of water bodies, including but not limited
to, rivers, lakes, and ponds with diverse sizes and shapes
[26]. Numerous studies [14, 57, 8, 23, 58] aim to enhance
the identiÔ¨Åcation of intricate water bodies by optimizing the
deep learning network, thereby enabling more efÔ¨Åcient uti-
lization of the multiscale characteristic. The meandering
of water body boundaries constitutes a critical hindrance to
the precise segmentation of surface water bodies. Miao et
al. [35] devise a loss function to derive accurate water body
boundaries, taking into account the distribution of bound-
ary weights. EfÔ¨Åcient post-processing algorithms [43, 6]
are also effective approaches.
2.3. Relevant applications
In the broader context of global water resource monitor-
ing and mapping, scholars create a worldwide 250m land
surface water body mask raster data employing MODIS
satellite images, grounded on the already existing global
land surface water body vector data [2]. The European
Commission Joint Research Centre (ECJRC) use Landsat-
5/7/8 satellite imagery to map global 30m water body data
products for the period 1984-2020 [38]. Global land cover
products which incorporate the water body category are
gradually emerging, albeit at a resolution of merely 10m
[22, 3, 24]. In addition, continuous production and appli-
cation of regional mapping products with low to medium
3resolution imagery for water bodies [50, 27, 16] and with
high resolution imagery for LULC [39, 28] is ongoing. The
inevitable trend in cartography is to continuously enhance
the spatial resolution of products, as this demonstrates the
beneÔ¨Åts of more detailed information. However, the pro-
duction of global VHR water cover maps remains a chal-
lenging task, due to the difÔ¨Åculty of acquiring and orga-
nizing VHR satellite data, the absence of publicly available
large-scale surface water detection datasets with manual an-
notation, and the lack of related models that are suitable
for large-size images. Our GLH-water with strong general-
ization and proposed strong baseline will Ô¨Åll the aforemen-
tioned gap.
3. The GLH-water dataset
To Ô¨Åll the lack of pertinent datasets and enhance the gen-
eralizability of segmentation models in detecting global sur-
face water, we Ô¨Årst present the GLH-water dataset that con-
tains 250 VHR (GSD=0.3m) satellite images with the size
of 12,800 √ó 12,800 pixels. These images are collected from
various locations worldwide and manual annotations are in-
cluded, as illustrated in Figure 1. In the remainder of this
section, we provide details on the imagery, annotations, and
advantages of our dataset.
3.1. Images collection and preprocessing
Using the Google Earth platform, we collect a total of
250 satellite images that are evenly distributed across the
globe, each with sizes of 12,800 √ó 12,800 pixels at 0.3m (19
level) spatial resolution, and encompassing approximately
3,686km2in geographic coverage. To guarantee the diver-
sity of the dataset, we handpick the geographic coordinates
and acquisition time of the sample data to ensure an ac-
curate representation of the various attributes of the global
water bodies.
3.2. Annotation method and inspection
The annotation labeling process includes three distinct
stages: Ô¨Åne labeling, Ô¨Åne checking and correction, and ran-
dom checking conducted by experts. To conduct Ô¨Åne la-
beling, we initially employ the ArcGIS software to manu-
ally outline the boundaries of water bodies in the collected
images. In case of ambiguity in certain areas, we refer
to Google Maps of the corresponding areas to aid in the
labeling process. To ensure the accuracy of the annota-
tions, during the second phase, we concentrate on validating
the boundary accuracy, detecting any possible redundancies
and omissions, and rectifying each of the issues that sur-
faced during the inspection. Finally, the annotations accom-
panying each large-size image are cropped into 512 x 512
pixel tiles in order to accurately reÔ¨Çect their quality. A sec-
ond visual inspection is conducted by experts on a randomly
selected 15% of the data.After scrutiny and revision, no apparent erros are found
in the GLH-water dataset, and the standard of annotations is
high, which sufÔ¨Åciently fulÔ¨Ålls the necessities for the forth-
coming algorithmic evaluation. Some annotated samples in
our dataset are shown in Figure 2.
3.3. Advantage analysis
To the best of our knowledge, the GLH-water dataset is
the Ô¨Årst publicly available and largest dedicated datset for
global-scale surface water detection from large-size VHR
satellite imagery that meets the traits of global sampling,
VHR, and large image size. A comparison with other pub-
licly existing datasets is shown in Table 2.
SpeciÔ¨Åcally, our GLH-water dataset has Ô¨Åve remarkable
and important advantages:
‚Ä¢The size of samples is large. The size of each im-
age is up to 12,800 12,800 pixels, which is more in
line with the size of a whole scene image acquired by
satellite. It is also a challenge for existing methods.
‚Ä¢Inclusion of a large number of samples. After non-
overlapping cropping, a total of 156,250 tiles of 512
512 pixels in size and more than 40.96 billion la-
beled pixels are included, which is the largest dataset
for global surface water detection from large-size VHR
satellite imagery.
‚Ä¢The geographical coverage of the samples is ex-
tensive and evenly distributed. Figure 1 illustrates
the detailed geographic distribution, showing that data
points are present on all continents except Antarctica.
The geographic distribution is uniform and reasonable,
and can adequately represent the features of surface
water body worldwide. Therefore, models trained on
our dataset are expected to have stronger generalizabil-
ity in the geographical dimension.
‚Ä¢The temporal span of image acquisition is broad.
The range of acquisition time of data spans from 2011
to 2022, and each year contains a certain amount of
data. Models trained on this dataset exhibit greater
temporal generalization ability.
‚Ä¢Inclusion of a diverse type of surface water land-
scapes , as depicted in Figure 2. These include, but
are not limited to, lakes and rivers in the forest, grass-
land, Ô¨Åeld, shrub, bare area, and urban area ,pools,
glacial lakes, and water in the special scenario . This
wide types of water bodies serves as a representation of
various geographic landscapes, land cover conditions,
water body shapes, and color tone types, thus provid-
ing a comprehensive reÔ¨Çection of the diversity of the
global surface water system.
In summary, the above Ô¨Åve advantages drive GLH-water
dataset to be unique and advanced.
4Figure 2. Visualization of various types of surface water bodies in different scenarios on GLH-water dataset. It can comprehensively
reÔ¨Çect the diversity of the global surface water system.
3.4. Dataset splits
To ensure that the training and test data are roughly
equally distributed, we randomly select 80% of the origi-
nal images as the training set, 10% as the validation set,
and 10% as the test set. We will make all original images
publicly available with annotations. From the geographical
distribution range shown in Figure 1, we can Ô¨Ånd that the
validation and test sets are randomly distributed in various
regions of the world, which can well reÔ¨Çect the actual per-
formance of the model trained by this dataset.
4. Methods on GLH-water dataset
4.1. Baseline models
Many models are developed to consider the characteris-
tics of water bodies in VHR satellite images in the Ô¨Åeld of
remote sensing, as outlined in Section 2.2. We choose three
representative models ( i.e., MECNet [61], MSResNet [9],
and MSCENet [23]) as baseline models. In the realm of
computer vision, numerous sophisticated semantic segmen-
tation models are perpetually created, which can easily be
adapted for satellite images. We use Ô¨Åve advanced models,
namely PSPNet [62], DeepLab v3+ [4], HRNet [48], etc., to
construct the benchmark results. In addition, given the VHR
and the large size of images in GLH-water , we also eval-
Figure 3. An overview of our proposed strong baseline with the
PCL.
uate the state-of-the-art semantic segmentation algorithms
speciÔ¨Åcally designed for ultra-high resolution images ( i.e.,
FCtL [25], MagNet [20], and ISDNet [18]).
4.2. A strong baseline with the PCL
We develop a competitive strong baseline with the new
PCL that is speciÔ¨Åcally designed to explore the detection
performance of surface water bodies in large-size VHR
satellite images. The pyramid consistency encompasses
the intra-layer consistency ( i.e., visual Ô¨Åeld consistency
between pyramidal layers) and the inter-layer consistency
(i.e., spatial consistency within a pyramidal layer), as il-
5lustrated in Figure 3. To construct the image pyramid, we
downsample each original large-size image XHWat vary-
ing ratesfi;i=ng, resulting in a multi-layer represen-
tation. Considering computational cost and efÔ¨Åciency, we
adopt downsampling rates of 1, 1/5, and 1/25, generating
an image pyramid comprising three layers.
Inter-layer consistency. As mentioned in [36], the hu-
man brain may be inÔ¨Çuenced by the varying sizes of the vi-
sual Ô¨Åeld being observed, potentially resulting in divergent
interpretations. The differences in attention maps of tiles
with distinct visual Ô¨Åelds displayed in Figure 4(a) show that
the model is inÔ¨Çuenced by context information associated
with the visual Ô¨Åeld. Motivated by this idea, we propose
the inter-layer consistency loss to calculate the discrimina-
tive variances of the model resulting from dissimilarities
in the visual range of patches. SpeciÔ¨Åcally, we deÔ¨Åne the
small tiles in the original image ( i.e. tiles located in the Ô¨Årst
layer of the pyramid) xhw
1stas the fundamental units and es-
tablish inter-layer tile groups fx1st;x2nd;x3rdghwby up-
wardly mapping the corresponding tiles from various layers.
It is pertinent to note that while the size of each tile within
the tile group remains consistent and same, the visual Ô¨Åeld
they contained is gradually increasing as shown in Figure 3.
The tile groups are trained by the encoder E, decoderD,
and classiÔ¨ÅerCto obtain the corresponding sigmoid nor-
malized conÔ¨Ådence maps fp1st;p2nd;p3rdghw. Minimiz-
ing the differences between same regions in the conÔ¨Ådence
maps, which are caused by differences in the visual Ô¨Åeld,
alleviates the visual Ô¨Åeld bias that arises due to limited con-
textual information.
Intra-layer consistency. Slicing the original image for
processing may lead to the loss of contextual information
and interdependence between adjacent tiles, which poten-
tially disrupts the topological continuity of water bodies in
remote sensing images with a large size. Figure 4(b) im-
plies that the models exhibit differentiated attention for ad-
jacent tiles with overlaps. We argue that enforcing consis-
tency of the overlapping region on tiles with different con-
textual information helps to resume the continuity of water
bodies. Based on this challenge and motivation, we further
develop the intra-layer consistency loss to effectively model
the continuous relationship between neighboring tiles and
compensate for the information gap induced by image slic-
ing. SpeciÔ¨Åcally, we deÔ¨Åne four adjacent and overlapping
tiles as an intra-layer tile group fx1;x2;x3;x4ghw, and
their spatial relationships are depicted in Figure 3. All tile
pairsf(xi;xj);16i<j64gare processed by the en-
coderE, decoderD, and classiÔ¨ÅerCto obtainsigmoid nor-
malized conÔ¨Ådence map pairs (pi;pj). The overlapping part
between them is employed to calculate the intra-layer con-
sistency loss.
Loss function. Inspired by the focal loss [29], we mod-
ify and present a novel consistency loss function to ef-
Figure 4. The motivation of pyramid consistency. Attention
maps of tiles with different visual Ô¨Åelds and overlapping tiles are
distinct in the same areas. Attention maps is obtained by the Grad-
CAM [41], using the ResNet-50 model trained on the GLH-water
dataset.
fectively calculate both inter-layer consistency Linter and
intra-layer consistency Lintra abovementioned. Overall op-
timization objective function can be deÔ¨Åned as follows:
Ltotal=Lseg+interLinter +intraLintra;(1)
whereLsegdenotes the regular semantic segmentation loss
using binary cross entropy loss `bce.inter;intra are
trade-off weights.Linter;Lintra are formulated as
Linter =1
whwhX
(1 p1st)r(1 )y1st`2(p1st;~p2nd)
+pr
1st(1 y1st)`2(p1st;~p2nd)
+1
whwhX
(1 p1st)r(1 )y1st`2(p1st;~p3rd)
+pr
1st(1 y1st)`2(p1st;~p3rd);
(2)
Lintra =1
whwhX X
16i<j64(1 ~pi)r(1 )~yi`2(~pi;~pj)
+~pr
i(1 ~yi)`2(~pi;~pj);
(3)
wherey1stdenotes the tiles and corresponding binary anno-
tations in Ô¨Årst layer. The value of 1 denotes water type in the
given pixel, while the value of 0 indicates non-water type.
p1stdenotes the conÔ¨Ådence map of tiles in Ô¨Årst layer, and
~p2nd;~p3rdrepresent the conÔ¨Ådence maps of the overlapping
regions in the inter-layer tile group of other layers (after up-
sampling).`2(p1st;~p2nd) =kp1st ~p2ndk2
2calculates the
6square of the euclidean distance of p1st;~p2nd. Similarly,
~pi;~pjrepresent the conÔ¨Ådence map of the overlapping re-
gions in the intra-layer tile group. r;are tunable focusing
parameters, which help the model to focus on learning hard-
to-distinguish samples.
5. Benchmark and experiment
5.1. Setup
Implementation details. To ensure the fairness of the eval-
uation, the batchsize of baseline models, except ultra-high
resolution segmentation methods, is set to 8 with a single
NVIDIA TITAN RTX GPU. The initial learning rate adopts
10 4. We crop the original image without overlap to 512
512 pixels and use the SGD optimizer with momentum
0.9, decayed weight 5√ó10 4to train baseline models for
15 epochs under a poly learning rate scheduler. To reduce
training costs and achieve faster convergence, we uniformly
use ImageNet [12] pre-trained backbones. For the imple-
mentation of ultra-high resolution segmentation methods,
we crop the image to 2,560 2,560 pixels and set suitable
parameter and hyperparameter settings refer to the settings
in their paper to ensure that trained models converge.
Due to GPU memory limitations, the batchsize of PCL
is set to 4. The other hyperparameters are the same as those
of baseline methods. The image pyramid is constructed in
three layers, and the default sampling rates are set to 1,
1/5, and 1/25 according to experimental experience. The
tile size of the Ô¨Årst pyramid layer is 512 512 pixels to
calculate the segmentation loss and the PCL. The trade-off
weightsinter andintra in Eq. (1) are both set to 1.0. r;
are set to 2 and 0.2, respectively.
Evaluation metrics. We use the intersection-over-union
(IoU) and F1-score metrics to evaluate the quantitative per-
formance of detecing surface water, following previous re-
lated work. In addition, we also use Frames Per Second
(FPS) and GPU Memory to evaluate the computational efÔ¨Å-
ciency and consumption of different models.
5.2. Evaluation results
As described in Section 4, we evaluate 12 of the pop-
ular methods shown in Table 3. The accuracy of generic
semantic segmentation models is overall higher than that
of models designed speciÔ¨Åcally for surface water body de-
tection. In addition, the state-of-the-art methods perform-
ing on the Cityscapes [7],DeepGlobe [11], and Inria [32]
dataset ( i.e., MagNet [20] and ISDNet [18]) cannot achieve
satisfactory performance on the GLH-water dataset, which
proves that surface water detection in large-size VHR satel-
lite imagery is challenging and still needs further develop-
ment. Furthermore, our proposed PCL outperforms other
methods by leveraging the multi-layer Ô¨Åeld of visual in-
formation present in large-size images and the topologicalMethod Backbone IoU(%) ( ") F1-score(%) (") FPS (") Memory(MB) ( #)
Segmentation methods speciÔ¨Åcally proposed for surface water detection
MECNet [61] - 44.67 61.75 3.44 15749
MSResNet [9] Res-34 69.76 82.18 4.03 5429
MSCENet [23] Res2-50 74.81 85.58 2.60 6347
Generic segmentation methods in Computer Vision
FCN8s [30] VGG-16 73.66 84.83 6.70 8294
PSPNet [62] Res-50 75.19 85.84 5.98 5451
DeepLab v3+ [4] Res-50 79.80 88.76 4.48 4973
HRNet-48 [48] - 78.60 88.01 3.03 8513
STDC-1446 [15] - 75.82 86.25 26.50 2435
Ultra-high Resolution Segmentation methods
MagNet [20] FPN-Res-50 62.77 - 13.33 4796
FCtL [25] FCN8s-VGG16 74.92 85.66 0.112 8192
ISDNet [18] DeepLab v3-Res-18 53.04 - 2.09 13608
Our PCLPSPNet
-Res-5082.26 90.27 1.34 14503
Table 3. Benchmark results of baseline models and our proposed
model on GLH-water test set. FPS and Memory are measured
in training settings with batchsize=2.
continuity of water bodies. Nonetheless, it suffers from
low efÔ¨Åciency and high computational cost, which are com-
mon issues faced by other ultra-high resolution segmenta-
tion methods ( i.e., FCtL [25] and ISDNet [18]). Thus, strik-
ing a balance between accuracy and efÔ¨Åciency should be
considered a crucial research priority in this task.
Table 4 demonstrates the consistent improvement of our
proposed strong baseline compared to the fair baseline ap-
proach across different segmentation model settings. This
indicates that our approach is an effective pipeline and is
driving progress in this task. Detailed visualization results
will be presented in the supplementary material.
Method Seg model IoU (%) F1-score (%)
Baseline
FCN8s-VGG1673.66 84.83
FCtL 74.92 85.66
Our PCL 75.78 (+2.12) 86.23 (+1.4)
BaselinePSPNet-Res-5075.19 85.84
Our PCL 82.26 (+7.07) 90.27 (+4.43)
BaselineDeepLab v3+-Res-5079.80 88.76
Our PCL 81.33 (+1.53) 89.70 (+0.94)
Table 4. Performance of baseline with divergent backbone or the
existing method with the fair backbone and our proposed model
onGLH-water test set. The results show that our model outper-
forms common models when using various segmentation models.
5.3. Ablation study on the strong baseline
Effectiveness of components in PCL. Exps. II and III
in Table 5 show that both key components of PCL ( i.e.,
Linter andLintra ) outperform the baseline by a large mar-
gin (+5.89% and +5.50%), and their combination can fur-
ther improve the performance of the model (Exp. VII).
Effectiveness of loss function of PCL. We conduct an abla-
tion study using the vanilla L2 loss function to measure the
pyramid consistency (Exp. IV), and Ô¨Ånd that the loss func-
7(a)
Yangpu District, Shanghai, China(d)(b)
GLH-waterdataset(IoU:79.80%)
LoveDAdataset(IoU:68.15%)
DeepGlobedataset(IoU:74.43%)Visualization of cross-dataset generalization evalutaion
(c)Pilot area generalization evaluationVisualization of pilot area generalization evaluation
10.2522.9171.7675.99
01020304050607080
DeepGlobe2020 GFchallengeLoveDAGLH-waterIoU  (%)Train setFigure 5. Generalization experiment results on GLH-water dataset. (a) IoU (%) of cross-dataset evaluation. (b) Visualization results of
cross-dataset evaluation. The displayed results in three datasets are all predicted by the model trained on GLH-water . (c) IoU (%) of pilot
area evalution with the HRNet-48 models trained on different datasets. (d) Visualization results of the model trained by our GLH-water on
the pilot area. Red lines represent ground truth, and cyan masks are predictions.
ID ConÔ¨Åguration IoU (%) (%)
I Baseline (Lseg) 75.19 -
II Lseg+Linter 81.08 +5.89
III Lseg+Lintra 80.69 +5.50
IV Vanilla`2 71.46 3.73
V Without the 2rd layers of the image pyramid 80.13 +4.94
VI Without the 3nd layers of the image pyramid 81.37 +6.18
VII Our PCL 82.26 +7.07
Table 5. Ablation study on key components of strong baseline
(seg model: PSPNet-Res-50). Vanilla `2means using vanilla
L2 loss to measure the pyramid loss rather than loss function
(Eqs.(2) and (3)) we designed.
tion we designed (Eqs. (2) and (3)) has superior capacity to
facilitate learning on hard-to-distinguish samples, thereby
resulting in performance improvement.
Impact of the number of image pyramid layers. We ob-
serve that if we only apply two layers of the image pyramid
to participate in training, our PCL will bring a performance
improvement of over 4.9% (Exps. V and VI). When build-
ing three layers of the image pyramid, we can see that there
is a 7.07% improvement (Exp. VII), indicating that more
layers being considered may be more beneÔ¨Åcial.
6. Generalization experiments on GLH-water
6.1. Cross-dataset generalization evaluation
Considering the similar resolution, data source, and large
image size, we choose the LoveDA [49] and DeepGlobe
dataset [11] to implement the cross-dataset generalization
evaluation. Following the data split of [49, 18], we use
DeepLab v3+-Res-50 as the segmentation model to train the
models and evaluate the cross-dataset performance.
As shown in Figure 5(a), there is little difference be-
tween the results of the model trained on GLH-water and
the model trained on LoveDA on the LoveDA test set
(68.15% vs. 69.27%). However, the performance of the
model trained on LoveDA is signiÔ¨Åcantly diminished when
transferred directly to the GLH-water test set (50.13% vs.79.80%). A similar situation occurrs between DeepGlobe
andGLH-water . Results in Figure 5(a) and (b) conÔ¨Årm the
strong generalization of our GLH-water .
6.2. Pilot area generalization evaluation
Providing data support for future VHR global surface
water mapping is one of the motivations for constructing
theGLH-water . We select the Yangpu District of Shanghai,
China, which is independent of the dataset and annotated
by experts, as a pilot area (60.61 km2) to further discuss
the generalization of GLH-water .
Based on the results presented in Figure 5(c) and (d), it
is evident that the model trained on GLH-water exhibits su-
perior performance (75.99%) in the surface water mapping
task in the pilot area, surpassing the models trained on other
datasets. These Ô¨Åndings suggest that GLH-water holds sig-
niÔ¨Åcant potential for global-scale VHR surface water map-
ping, owing to its strong generalization.
7. Qualitative results
Qualitative results on GLH-water test andval sets.
Figures 6 and 7 show the surface water detection visualiza-
tion results of the 12 methods included in the benchmark
on the test set and validation set of GLH-water , re-
spectively. Compared with other results, our PCL can better
preserve more continuous and complete surface water bod-
ies and reduce commission errors, as shown in (n) of Fig-
ure 6. In addition, our PCL can detect small and slim rivers,
as shown in (n) of Figure 7.
Qualitative results about cross-dataset generalization
evaluation. Figures 8 and 9 display the visualization re-
sults on the DeepGlobe [10] and LoveDA [49]test sets
of models trained on different datasets, respectively. As
shown in the quantitative results presented in our paper
(IoU: 74.43% vs. 79.1% and 68.15% vs. 69.27%), thanks to
the strong generalization of GLH-water , the model trained
on the GLH-water train set achieves performance on the
DeepGlobe andLoveDA test sets that is not signiÔ¨Åcantly
8different from the performance of the model trained on their
respective train sets.
Qualitative results on pilot area. Figure 10 shows the
performance of our model trained on GLH-water dataset
for surface water detection in an out-of-sample pilot area
(Yangpu District, Shanghai, China). The model trained on
GLH-water exhibits superior performance (75.99%) in the
surface water mapping task in this pilot area, surpassing
the models trained on DeepGlobe [10], 2020 GF challenge
[43], and LoveDA [49] datasets. Additionally, Figure 10
also demonstrates that our model‚Äôs ability to detect slender
streams in urban scenes and resist the interference of build-
ing shadow is limited. These limitations should be consid-
ered as future research priorities for surface water detection
from large-size VHR satellite imagery.
8. Conclusion
We present a global large-scale dataset for surface wa-
ter detection in large-size VHR satellite imagery which is
Ô¨Årst publicly available dataset in this task. Unlike exisit-
ing datasets, we collect 250 large-size satellite images con-
taining various surface water scenes across the whole earth
and carefully annotate their masks. Considering the advan-
tages of GLH-water over other datasets, we believe that this
dataset is more appropriate for practical applications and
more challenging. Additionally, we build a benchmark to
evaluate advanced segmentation models in the Ô¨Åelds of re-
mote sensing and computer vision. we aslo propose a strong
basline with PCL that is a promising research pipeline to
push this task forward.
In the future, we hope the GLH-water with strong
generalization will not only evaluate the progress of algo-
rithms, but also provide data to support major studies such
as global surface water mapping and even global water
resource conservation and management.
9Figure 6. Qualitative results on the GLH-water test set.(a) Original image. (b) Ground truth. (c)-(e) Results of MECNet, MSResNet,
and MSCENet, respectively. (f)-(j) Results of FCN8s, PSPNet, DeepLab v3+, HRNet-48, and STDC-1446, respectively. (k)-(m) Results
of MagNet, FCtL, and ISDNet, respectively. our PCL can preserve more complete lakes and rivers, with much fewer commission errors
(false positive) and omission errors (false negative), as shown in (n).
10Figure 7. Qualitative results on the GLH-water val set.(a) Original image. (b) Ground truth. (c)-(e) Results of MECNet, MSResNet,
and MSCENet, respectively. (f)-(j) Results of FCN8s, PSPNet, DeepLab v3+, HRNet-48, and STDC-1446, respectively. (k)-(m) Results
of MagNet, FCtL, and ISDNet, respectively. our PCL can preserve more small and slim rivers, with much fewer commission errors (false
positive) and omission errors (false negative), as shown in (n).
11Figure 8. Qualitative results on the DeepGlobe test set. (a) Original image. (b) Ground truth. (c) Results of model trained on
DeepGlobe train set (IoU: 79.1%). (d) Results of model trained on our GLH-water train set (IoU: 74.43%). As in the comparison of
quantitative results, the performance of (d) and (c) is not signiÔ¨Åcantly different, indicating that GLH-water has strong generalization.
12Figure 9. Qualitative results on the LoveDA test set. (a) Original image. (b) Results of model trained on LoveDA train set (IoU:
69.27%). (c) Results of model trained on our GLH-water train set (IoU: 68.15%). (Ground truth is not available and quantitative results are
obtained from the online leaderboard: https://codalab.lisn.upsaclay.fr/competitions/421 .) The detection details of
surface water bodies shown in (c) are better than those in (b), as shown in orange boxes.
13Figure 10. Qualitative results on the pilot area (Yangpu District, Shanghai, China). Cyan masks are predicted by the model trained on
GLH-water train set.
14References
[1] Adrian Boguszewski, Dominik Batorski, Natalia Ziemba-
Jankowska, Tomasz Dziedzic, and Anna Zambrzycka. Land-
cover.ai: Dataset for automatic mapping of buildings, wood-
lands, water and roads from aerial imagery. In Proceed-
ings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR) Workshops , pages 1102‚Äì1110,
June 2021. 2, 3
[2] Mark L Carroll, John R Townshend, Charlene M DiMiceli,
Praveen Noojipady, and Robert A Sohlberg. A new global
raster water mask at 250 m resolution. International Journal
of Digital Earth , 2(4):291‚Äì308, 2009. 3
[3] B Chen, B Xu, Z Zhu, C Yuan, H Ping Suen, J Guo, N Xu,
W Li, Y Zhao, JJSB Yang, et al. Stable classiÔ¨Åcation with
limited sample: Transferring a 30-m resolution sample set
collected in 2015 to mapping 10-m resolution global land
cover in 2017. Sci. Bull , 64:370‚Äì373, 2019. 3
[4] Liang-Chieh Chen, Yukun Zhu, George Papandreou, Florian
Schroff, and Hartwig Adam. Encoder-decoder with atrous
separable convolution for semantic image segmentation. In
Proceedings of the European conference on computer vision
(ECCV) , pages 801‚Äì818, 2018. 5, 7
[5] Mang Tik Chiu, Xingqian Xu, Yunchao Wei, Zilong Huang,
Alexander G. Schwing, Robert Brunner, Hrant Khachatrian,
Hovnatan Karapetyan, Ivan Dozier, Greg Rose, David Wil-
son, Adrian Tudor, Naira Hovakimyan, Thomas S. Huang,
and Honghui Shi. Agriculture-vision: A large aerial image
database for agricultural pattern analysis. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR) , June 2020. 2, 3
[6] Zhengquan Chu, Tian Tian, Ruyi Feng, and Lizhe Wang.
Sea-land segmentation with res-unet and fully connected crf.
InIGARSS 2019-2019 IEEE International Geoscience and
Remote Sensing Symposium , pages 3840‚Äì3843. IEEE, 2019.
3
[7] Marius Cordts, Mohamed Omran, Sebastian Ramos, Timo
Rehfeld, Markus Enzweiler, Rodrigo Benenson, Uwe
Franke, Stefan Roth, and Bernt Schiele. The cityscapes
dataset for semantic urban scene understanding. In Proceed-
ings of the IEEE conference on computer vision and pattern
recognition , pages 3213‚Äì3223, 2016. 7
[8] Binge Cui, Wei Jing, Ling Huang, Zhongrui Li, and Yan Lu.
Sanet: A sea‚Äìland segmentation network via adaptive mul-
tiscale feature learning. IEEE Journal of Selected Topics in
Applied Earth Observations and Remote Sensing , 14:116‚Äì
126, 2020. 3
[9] Bo Dang and Yansheng Li. Msresnet: Multiscale resid-
ual network via self-supervised learning for water-body
detection in remote sensing imagery. Remote Sensing ,
13(16):3122, 2021. 5, 7
[10] Ilke Demir, Krzysztof Koperski, David Lindenbaum, Guan
Pang, Jing Huang, Saikat Basu, Forest Hughes, Devis Tuia,
and Ramesh Raskar. Deepglobe 2018: A challenge to parse
the earth through satellite images. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recog-
nition (CVPR) Workshops , June 2018. 3, 8, 9[11] Ilke Demir, Krzysztof Koperski, David Lindenbaum, Guan
Pang, Jing Huang, Saikat Basu, Forest Hughes, Devis Tuia,
and Ramesh Raskar. Deepglobe 2018: A challenge to parse
the earth through satellite images. In Proceedings of the
IEEE Conference on Computer Vision and Pattern Recog-
nition Workshops , pages 172‚Äì181, 2018. 7, 8
[12] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li,
and Li Fei-Fei. Imagenet: A large-scale hierarchical image
database. In 2009 IEEE conference on computer vision and
pattern recognition , pages 248‚Äì255. Ieee, 2009. 7
[13] Gennadii Donchyts, Fedor Baart, Hessel Winsemius, Noel
Gorelick, Jaap Kwadijk, and Nick Van De Giesen. Earth‚Äôs
surface water change over the past 30 years. Nature Climate
Change , 6(9):810‚Äì813, 2016. 1
[14] Lunhao Duan and Xiangyun Hu. Multiscale reÔ¨Ånement net-
work for water-body segmentation in high-resolution satel-
lite imagery. IEEE Geoscience and Remote Sensing Letters ,
17(4):686‚Äì690, 2019. 3
[15] Mingyuan Fan, Shenqi Lai, Junshi Huang, Xiaoming Wei,
Zhenhua Chai, Junfeng Luo, and Xiaolin Wei. Rethinking
bisenet for real-time semantic segmentation. In Proceedings
of the IEEE/CVF conference on computer vision and pattern
recognition , pages 9716‚Äì9725, 2021. 7
[16] Min Feng, Joseph O Sexton, Saurabh Channan, and John R
Townshend. A global, high-resolution (30-m) inland water
body dataset for 2000: First results of a topographic‚Äìspectral
classiÔ¨Åcation algorithm. International Journal of Digital
Earth , 9(2):113‚Äì133, 2016. 4
[17] G ¬®unther Grill, B Lehner, Michele Thieme, B Geenen, D
Tickner, F Antonelli, S Babu, Pasquale Borrelli, L Cheng, H
Crochetiere, et al. Mapping the world‚Äôs free-Ô¨Çowing rivers.
Nature , 569(7755):215‚Äì221, 2019. 1
[18] Shaohua Guo, Liang Liu, Zhenye Gan, Yabiao Wang, Wuhao
Zhang, Chengjie Wang, Guannan Jiang, Wei Zhang, Ran Yi,
Lizhuang Ma, and Ke Xu. Isdnet: Integrating shallow and
deep networks for efÔ¨Åcient ultra-high resolution segmenta-
tion. In Proceedings of the IEEE/CVF Conference on Com-
puter Vision and Pattern Recognition (CVPR) , pages 4361‚Äì
4370, June 2022. 5, 7, 8
[19] Kai Hu, Meng Li, Min Xia, and Haifeng Lin. Multi-scale
feature aggregation network for water area segmentation. Re-
mote Sensing , 14(1):206, 2022. 2, 3
[20] Chuong Huynh, Anh Tuan Tran, Khoa Luu, and Minh
Hoai. Progressive semantic segmentation. In Proceedings
of the IEEE/CVF Conference on Computer Vision and Pat-
tern Recognition (CVPR) , pages 16755‚Äì16764, June 2021.
5, 7
[21] Leo F Isikdogan, Alan Bovik, and Paola Passalacqua. Seeing
through the clouds with deepwatermap. IEEE Geoscience
and Remote Sensing Letters , 17(10):1662‚Äì1666, 2019. 2, 3
[22] Chen Jun, Yifang Ban, and Songnian Li. Open access to
earth land-cover map. Nature , 514(7523):434‚Äì434, 2014. 3
[23] Jian Kang, Haiyan Guan, Daifeng Peng, and Ziyi Chen.
Multi-scale context extractor network for water-body ex-
traction from high-resolution optical remotely sensed im-
ages. International Journal of Applied Earth Observation
and Geoinformation , 103:102499, 2021. 3, 5, 7
15[24] Krishna Karra, Caitlin Kontgis, Zoe Statman-Weil, Joseph C
Mazzariello, Mark Mathis, and Steven P Brumby. Global
land use/land cover with sentinel 2 and deep learning. In
2021 IEEE international geoscience and remote sensing
symposium IGARSS , pages 4704‚Äì4707. IEEE, 2021. 3
[25] Qi Li, Weixiang Yang, Wenxi Liu, Yuanlong Yu, and
Shengfeng He. From contexts to locality: Ultra-high reso-
lution image segmentation via locality-aware contextual cor-
relation. In Proceedings of the IEEE/CVF International Con-
ference on Computer Vision (ICCV) , pages 7252‚Äì7261, Oc-
tober 2021. 5, 7
[26] Yansheng Li, Bo Dang, Yongjun Zhang, and Zhenhong
Du. Water body classiÔ¨Åcation from high-resolution opti-
cal remote sensing imagery: Achievements and perspec-
tives. ISPRS Journal of Photogrammetry and Remote Sens-
ing, 187:306‚Äì327, 2022. 3
[27] Yang Li and Zhenguo Niu. Systematic method for mapping
Ô¨Åne-resolution water cover types in china based on time se-
ries sentinel-1 and 2 images. International Journal of Ap-
plied Earth Observation and Geoinformation , 106:102656,
2022. 4
[28] Zhuohong Li, Hongyan Zhang, Fangxiao Lu, Ruoyao Xue,
Guangyi Yang, and Liangpei Zhang. Breaking the resolu-
tion barrier: A low-to-high network for large-scale high-
resolution land-cover mapping using low-resolution labels.
ISPRS Journal of Photogrammetry and Remote Sensing ,
192:244‚Äì267, 2022. 4
[29] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and
Piotr Doll ¬¥ar. Focal loss for dense object detection. In Pro-
ceedings of the IEEE international conference on computer
vision , pages 2980‚Äì2988, 2017. 6
[30] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully
convolutional networks for semantic segmentation. In Pro-
ceedings of the IEEE conference on computer vision and pat-
tern recognition , pages 3431‚Äì3440, 2015. 7
[31] Xin Luo, Xiaohua Tong, and Zhongwen Hu. An applicable
and automatic method for earth surface water mapping based
on multispectral images. International Journal of Applied
Earth Observation and Geoinformation , 103:102472, 2021.
2, 3
[32] Emmanuel Maggiori, Yuliya Tarabalka, Guillaume Charpiat,
and Pierre Alliez. Can semantic labeling methods general-
ize to any city? the inria aerial image labeling benchmark.
In2017 IEEE International Geoscience and Remote Sensing
Symposium (IGARSS) , pages 3226‚Äì3229. IEEE, 2017. 7
[33] Gonzalo Mateo-Garcia, Joshua Veitch-Michaelis, Lewis
Smith, Silviu Vlad Oprea, Guy Schumann, Yarin Gal,
Atƒ±lƒ±m G ¬®unes ¬∏ Baydin, and Dietmar Backes. Towards global
Ô¨Çood mapping onboard low cost satellites with machine
learning. ScientiÔ¨Åc reports , 11(1):1‚Äì12, 2021. 1
[34] Stuart K McFeeters. The use of the normalized difference
water index (ndwi) in the delineation of open water features.
International journal of remote sensing , 17(7):1425‚Äì1432,
1996. 3
[35] Ziming Miao, Kun Fu, Hao Sun, Xian Sun, and Meng-
long Yan. Automatic water-body segmentation from high-
resolution satellite images via deep networks. IEEE geo-
science and remote sensing letters , 15(4):602‚Äì606, 2018. 3[36] Juhong Min, Yucheng Zhao, Chong Luo, and Minsu Cho.
Peripheral Vision Transformer. In Advances in Neural Infor-
mation Processing Systems , 2022. 6
[37] Joachim Moortgat, Ziwei Li, Michael Durand, Ian Howat,
Bidhyananda Yadav, and Chunli Dai. Deep learning models
for river classiÔ¨Åcation at sub-meter resolutions from multi-
spectral and panchromatic commercial satellite imagery. Re-
mote Sensing of Environment , 282:113279, 2022. 2, 3
[38] Jean-Franc ¬∏ois Pekel, Andrew Cottam, Noel Gorelick, and
Alan S Belward. High-resolution mapping of global surface
water and its long-term changes. Nature , 540(7633):418‚Äì
422, 2016. 1, 3
[39] Caleb Robinson, Le Hou, Kolya Malkin, Rachel Soobit-
sky, Jacob Czawlytko, Bistra Dilkina, and Nebojsa Jojic.
Large scale high-resolution land cover mapping with multi-
resolution data. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition (CVPR) , June
2019. 4
[40] Catherine Seale, Thomas Redfern, Paul ChatÔ¨Åeld, Chunbo
Luo, and Kari Dempsey. Coastline detection in satellite im-
agery: A deep learning approach on new benchmark data.
Remote Sensing of Environment , 278:113044, 2022. 2, 3
[41] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das,
Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra.
Grad-cam: Visual explanations from deep networks via
gradient-based localization. In Proceedings of the IEEE in-
ternational conference on computer vision , pages 618‚Äì626,
2017. 6
[42] Haigang Sui, Guang Chen, and Li Hua. An automatic in-
tegrated image segmentation, registration and change detec-
tion method for water-body extraction using hsr images and
gis data. Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci ,
7:W2, 2013. 3
[43] Xian Sun, Peijin Wang, Zhiyuan Yan, Wenhui Diao, Xiaonan
Lu, Zhujun Yang, Yidan Zhang, Deliang Xiang, Chen Yan,
Jie Guo, et al. Automated high-resolution earth observation
image interpretation: Outcome of the 2020 gaofen challenge.
IEEE Journal of Selected Topics in Applied Earth Observa-
tions and Remote Sensing , 14:8922‚Äì8940, 2021. 2, 3, 9
[44] Aysim Toker, Lukas Kondmann, Mark Weber, Marvin
Eisenberger, Andr ¬¥es Camero, Jingliang Hu, Ariadna Pregel
Hoderlein, C ¬∏ a Àòglar S ¬∏enaras, Timothy Davis, Daniel Cre-
mers, Giovanni Marchisio, Xiao Xiang Zhu, and Laura
Leal-Taix ¬¥e. Dynamicearthnet: Daily multi-spectral satellite
dataset for semantic change segmentation. In Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern
Recognition (CVPR) , pages 21158‚Äì21167, June 2022. 2, 3
[45] Xin-Yi Tong, Gui-Song Xia, Qikai Lu, Huanfeng Shen,
Shengyang Li, Shucheng You, and Liangpei Zhang. Land-
cover classiÔ¨Åcation with high-resolution remote sensing im-
ages using transferable deep models. Remote Sensing of En-
vironment , 237:111322, 2020. 3
[46] Xin-Yi Tong, Gui-Song Xia, and Xiao Xiang Zhu. Enabling
country-scale land cover mapping with meter-resolution
satellite imagery. ISPRS Journal of Photogrammetry and Re-
mote Sensing , 196:178‚Äì196, 2023. 2, 3
[47] Charles J V ¬®or¬®osmarty, Peter B McIntyre, Mark O Gessner,
David Dudgeon, Alexander Prusevich, Pamela Green, Stan-
16ley Glidden, Stuart E Bunn, Caroline A Sullivan, C Reidy
Liermann, et al. Global threats to human water security and
river biodiversity. nature , 467(7315):555‚Äì561, 2010. 1
[48] Jingdong Wang, Ke Sun, Tianheng Cheng, Borui Jiang,
Chaorui Deng, Yang Zhao, Dong Liu, Yadong Mu, Mingkui
Tan, Xinggang Wang, et al. Deep high-resolution repre-
sentation learning for visual recognition. IEEE transactions
on pattern analysis and machine intelligence , 43(10):3349‚Äì
3364, 2020. 5, 7
[49] Junjue Wang, Zhuo Zheng, Ailong Ma, Xiaoyan Lu, and
Yanfei Zhong. LoveDA: A remote sensing land-cover dataset
for domain adaptive semantic segmentation. In J. Van-
schoren and S. Yeung, editors, Proceedings of the Neural In-
formation Processing Systems Track on Datasets and Bench-
marks , volume 1, 2021. 2, 3, 8, 9
[50] Xinxin Wang, Xiangming Xiao, Yuanwei Qin, Jinwei Dong,
Jihua Wu, and Bo Li. Improved maps of surface water bod-
ies, large dams, reservoirs, and lakes in china. Earth System
Science Data , 14(8):3757‚Äì3771, 2022. 4
[51] Xinxin Wang, Xiangming Xiao, Zhenhua Zou, Jinwei Dong,
Yuanwei Qin, Russell B Doughty, Michael A Menarguez,
Bangqian Chen, Junbang Wang, Hui Ye, et al. Gainers and
losers of surface and terrestrial water resources in china dur-
ing 1989‚Äì2016. Nature communications , 11(1):3471, 2020.
1
[52] Marc Wieland, Sandro Martinis, Ralph KieÔ¨Ç, and Veronika
Gstaiger. Semantic segmentation of water bodies in very
high-resolution satellite and aerial images. Remote Sensing
of Environment , 287:113452, 2023. 1, 2, 3
[53] Wei Wu, Qiangzi Li, Yuan Zhang, Xin Du, and Hongyan
Wang. Two-step urban water index (tsuwi): A new technique
for high-resolution mapping of urban surface water. Remote
sensing , 10(11):1704, 2018. 3
[54] Junshi Xia, Naoto Yokoya, Bruno Adriano, and Clifford
Broni-Bediako. Openearthmap: A benchmark dataset for
global high-resolution land cover mapping. In Proceed-
ings of the IEEE/CVF Winter Conference on Applications of
Computer Vision (WACV) , pages 6254‚Äì6264, January 2023.
2, 3
[55] Hanqiu Xu. ModiÔ¨Åcation of normalised difference water
index (ndwi) to enhance open water features in remotely
sensed imagery. International journal of remote sensing ,
27(14):3025‚Äì3033, 2006. 3
[56] Fangfang Yao, Chao Wang, Di Dong, Jiancheng Luo, Zhan-
feng Shen, and Kehan Yang. High-resolution mapping of ur-
ban surface water using zy-3 multi-spectral imagery. Remote
Sensing , 7(9):12336‚Äì12355, 2015. 3
[57] Yongtao Yu, Yuting Yao, Haiyan Guan, Dilong Li, Zuojun
Liu, Lanfang Wang, Changhui Yu, Shaozhang Xiao, Wen-
hao Wang, and Lv Chang. A self-attention capsule fea-
ture pyramid network for water body extraction from remote
sensing imagery. International Journal of Remote Sensing ,
42(5):1801‚Äì1822, 2021. 3
[58] Kunhao Yuan, Xu Zhuang, Gerald Schaefer, Jianxin Feng,
Lin Guan, and Hui Fang. Deep-learning-based multispec-
tral satellite image segmentation for water body detection.
IEEE Journal of Selected Topics in Applied Earth Observa-
tions and Remote Sensing , 14:7422‚Äì7434, 2021. 3[59] Yindan Zhang, Gang Chen, Soe W Myint, Yuyu Zhou, Geof-
frey J Hay, Jelena Vukomanovic, and Ross K Meentemeyer.
Urbanwatch: A 1-meter resolution land cover and land use
database for 22 major cities in the united states. Remote
Sensing of Environment , 278:113106, 2022. 3
[60] Yongjun Zhang, Xinyi Liu, Yi Zhang, Xiao Ling, and Xu
Huang. Automatic and unsupervised water body extrac-
tion based on spectral-spatial features using gf-1 satellite
imagery. IEEE Geoscience and Remote Sensing Letters ,
16(6):927‚Äì931, 2018. 3
[61] Zhili Zhang, Meng Lu, Shunping Ji, Huafen Yu, and Chen-
hui Nie. Rich cnn features for water-body segmentation from
very high resolution aerial and satellite imagery. Remote
Sensing , 13(10):1912, 2021. 5, 7
[62] Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang
Wang, and Jiaya Jia. Pyramid scene parsing network. In
Proceedings of the IEEE conference on computer vision and
pattern recognition , pages 2881‚Äì2890, 2017. 5, 7
17