Heterogeneous Matrix Factorization: When Features Differ by
Datasets
Naichen Shi naichens@umich.edu
Salar Fattahi fattahi@umich.edu
Raed Al Kontar∗alkontar@umich.edu
Department of Industrial & Operations Engineering
University of Michigan
Ann Arbor, MI 48109, USA
Abstract
In myriad statistical applications, data are collected from related but heterogeneous sources.
These sources share some commonalities while containing idiosyncratic characteristics. One
of the most fundamental challenges in such scenarios is to recover the shared and source-
specific factors. Despite the existence of a few heuristic approaches, a generic algorithm
with theoretical guarantees has yet to be established.
In this paper, we tackle the problem by proposing a method called Heterogeneous
Matrix Factorization to separate the shared and unique factors for a class of problems.
HMF maintains the orthogonality between the shared and unique factors by leveraging an
invariance property in the objective. The algorithm is easy to implement and intrinsically
distributed. On the theoretic side, we show that for the square error loss, HMF will converge
into the optimal solutions, which are close to the ground truth.
HMF can be integrated auto-encoders to learn nonlinear feature mappings. Through a
variety of case studies, we showcase HMF’s benefits and applicability in video segmentation,
time-series feature extraction, and recommender systems.
1 Introduction
In the Internet of Things (IoT), data are frequently gathered at the edge devices such as
mobile phones or sensors, which often operate under different conditions such as temperature,
pressure, or vibration (Kontar et al., 2021).This is an example of data collection from a
diverse range of related sources. Resultingly, data exhibit both shared features, which
represent common knowledge, and unique features, associated with source-specific individual
characteristics.
A central challenge in analyzing the data patterns among heterogeneous sources is to
decouple the shared and unique features from the observations. A natural approach to handle
it is to use mutually orthogonal vectors to model the shared and unique features (Lock
et al., 2013; Yang and Michailidis, 2016; Zhou et al., 2015; Sagonas et al., 2017; Gaynanova
and Li, 2019; Park and Lock, 2020; Liang et al., 2023). Along this line, JIVE (Lock et al.,
2013) uses an alternative minimization algorithm to optimize the joint and individual factors.
While JIVE can find meaningful patterns in some genetic applications, the orthogonality
is not well-respected in the algorithm. Resultingly, the separation is not ideal, and the
∗. Corresponding author
1arXiv:2305.17744v2  [stat.ME]  27 Mar 2024estimates of the shared components have limited fidelities (Zhou et al., 2015). Several works
attempt to improve JIVE by analyzing the singular vectors of observation matrices (Zhou
et al., 2015), considering more complicated structures (Park and Lock, 2020), and many
more. However, many of these algorithms focus on specific statistical problems and employ
heuristic algorithms that do not have a strong convergence guarantee. Distributing these
algorithms is also an arduous task.
Very recently, personalized PCA (perPCA) (Shi and Kontar, 2024) has emerged as
a promising method for distributedly recovering shared and unique features with strong
convergence guarantees. Despite its eminent performance on an array of applications, perPCA
is limited to handling symmetric covariance matrices and cannot be readily extended to
asymmetric and incomplete observation settings, where only a small subset of data is
available.
Hence, there is a need for an extensible algorithm to separate shared and unique factors
with a provable convergence guarantee. In this paper, we propose a framework called
Heterogeneous MatrixFactorization ( HMF) to capture the shared and unique factors under
the orthogonality constraint. Our formulation is based on nonconvex Matrix Factorization
(MF), a widely used technique in data analytics for identifying low-rank structures within high-
dimensional matrices. Such low-rank structures can capture underlying physical processes or
latent features that are highly informative for understanding patterns in high-dimensional
observations (Wright and Ma, 2022), thus are extremely suitable to represent the shared and
unique features among data. Also, the matrix factorization formulation can be extended to
an auto-encoder model, which employs the representation power of neural networks.
More specifically, we consider a group of Nobservation matrices {M(i)}N
i=1from N
related but heterogeneous sources. We model the common information in these matrices
as low-rank components whose columns span the same subspace. Accordingly, the unique
signals are modeled by low-rank components with source-specific column subspaces. The
common and unique subspaces are orthogonal to represent the inductive bias that the shared
and unique features are independent. In nonlinear models, we similarly use shared and
source-specific nonlinear embeddings to model common and unique data patterns.
To learn the shared and unique features, HMFexploits an invariance property of the
objective to handle the constraints by introducing two correction steps. The application of
the invariance property is one of the key distinctions between HMFand previous works, as it
allows HMFto maintain orthogonality between shared and unique factors without changing
the objective. With the correction step, HMFis proved to converge linearly to an optimal
solution under the SE loss with suitable stepsize and initial optimality gap. We also provide
an upper bound on the statistical error between the updates and the ground truths.
We use a wide range of numerical experiments to demonstrate the effectiveness of the
proposed HMF. The case studies on video segmentation, temporal signal analysis, and movie
recommendation showcase the benefits of extracting shared and unique factors.
2 Related Work
Matrix Factorization MF has been applied to a diverse range of fields, including image
processing (Lee and Seung, 1999), time series analysis (Yu et al., 2016), and many others,
making it one of the most popular methods in data analytics. Numerous works analyze
2the theoretical properties of first-order algorithms that solve the (asymmetric) matrix
factorization problem minU,VM−UVT2
For its variants (Li et al., 2018a; Ye and Du,
2021; Sun and Luo, 2016; Park et al., 2017; Tu et al., 2016). Among them, (Sun and Luo,
2016) analyzes the local landscape of the optimization problem and establishes the local linear
convergence of a series of first-order algorithms. (Park et al., 2017; Ge et al., 2017) study
the global geometry of the optimization problem. (Tu et al., 2016) propose the Rectangular
Procrustes Flow algorithm that is proved to converge linearly into the ground truth under
proper initialization and a balancing regularization of the formUTU−VTV2
F. Despite
the abundance of literature on standard matrix factorization and matrix completion, these
works do not consider the case where data contain heterogeneous trends.
Distributed matrix factorization Recent development of edge computation has fueled
a trend to move matrix factorization to the edge. Distributed matrix factorization (DMF)
(Gemulla et al., 2011) exploits the distributed gradient descent to factorize large matrices.
(Chai et al., 2021) proposes a cryptographic framework where multiple clients use their local
data to collaboratively factorize a matrix without leaking private information to the server.
These works use one set of feature matrices UandVto fit data from all clients, and hence,
they do not account for source-by-source feature differences either.
Personalized modeling As discussed, there are a few methods attempting to find the
joint and individual components by heuristic algorithms. Besides the works discussed in the
introduction section, some works leverage additional structural assumptions in data. Among
them, SLIDE (Gaynanova and Li, 2019) analyzes the group sparsity structure. iNMF (Yang
and Michailidis, 2016) adds nonnegativity constraints to the recovered matrices. RJIVE
(Sagonas et al., 2017) aims to cope with the gross noise in the observations. However, to our
best knowledge, none of these algorithms can guarantee that the iterates will converge into
the optimal solutions. Our work improves upon the previous work by providing a flexible
formulation for matrix factorization and proposing a first-order algorithm equipped with a
convergence guarantee. A comprehensive comparison between HMFand exemplary previous
works is outlined in Table 1.
Table 1: Comparison of different methods. dstands for whether a method can be distributed,
ostands for whether the method ensures the orthogonality between the shared and
unique components, cstands for whether it has a convegence guarantee, istands
for whether it can handle incomplete observations.
Algorithm d o c i
DMF (Gemulla et al., 2011) ✓ ✗ ✓ ✗
JIVE (Lock et al., 2013) ✗ ✗ ✗ ✗
COBE (Zhou et al., 2015) ✗ ✗ ✗ ✗
RJIVE (Sagonas et al., 2017) ✗ ✓ ✗ ✗
perPCA (Shi and Kontar, 2024) ✓ ✓ ✓ ✗
perDL (Liang et al., 2023) ✓ ✗ ✓ ✗
HMF(ours) ✓ ✓ ✓ ✓
33 Model
We consider the setting where N∈N+noisy observation matrices M(1),M(2),···,M(N)are
collected from Ndifferent but related sources. These matrices M(i)∈Rn1×n2,(i)are assumed
to have the same number of rows n1.
3.1 Linear model
The natural way to model the commonality and uniqueness among the matrices is assuming
that each matrix is driven by r1shared factors and r2,(i)unique factors and also contaminated
by noise. More specifically, we consider the generation model for matrix M(i)is defined as
M(i)=U⋆gV⋆T
(i),g+U⋆
(i),lV⋆T
(i),l+E⋆
(i) (1)
where U⋆g∈Rn1×r1,V⋆(i),g∈Rn2,(i)×r1,U⋆(i),l∈Rn1×r2,(i),V⋆(i),l∈Rn2,(i)×r2,(i),E⋆(i)∈
Rn1×n2,(i). We use⋆to denote the ground truth. In the above model, r1is the rank of the
global (shared) feature matrices, while r2,(i)is the rank of local (unique) feature matrices from
source i. The matrix U⋆gV⋆T
(i),gmodels the shared low-rank components of the observation
matrix, as the column space is the same across different sources. The matrix U⋆(i),lV⋆T
(i),l
models the unique low-rank part. The rationale of the low-rank matrix factorization is to
use a small number of latent vectors to explain the observations. Thus the ranks r1and
r2,(i)are often much smaller than matrix dimensions. E⋆(i)models the noise from source i.
In matrix factorization problems, the representations U⋆gandU⋆(i),loften correspond to
latent data features. For better interpretability, it is often desirable to have the underlying
features disentangled so that each feature can vary independently of others (Higgins et al.,
2017). Under this rationale, we consider the model where shared and unique factors are
orthogonal,
U⋆T
gU⋆
(i),l= 0,∀i∈[N] (2)
We use [ N] to denote the set {1,2,···, N}. The orthogonality of features implies that the
shared and unique features span different subspaces, thus describing different patterns in
the observation. The orthogonality condition is consistent with literature (Lock et al., 2013;
Zhou et al., 2015).
Under the data generation model (1)and(2), our goal is to find Ug,{V(i),g,U(i),l,V(i),l}
from observations {M(i)}. To achieve this goal, we propose a generic constrained optimization
problem.
min
xNX
i=1˜fi(Ug,V(i),g,U(i),l,V(i),l)
such that UT
gU(i),l= 0,∀i∈[N](3)
where x= 
Ug,{U(i),l,V(i),g,V(i),l}N
i=1
collects the decision variables and ˜fiis a regularized
empirical risk consisting of two parts.
˜fi(Ug,V(i),g,U(i),l,V(i),l)
=ℓ
M(i),UgVT
(i),g+U(i),lVT
(i),l
| {z }
fi+β
2UT
gUg−I2
F+β
2UT
(i),lU(i),l−I2
F| {z }
gi(4)
4We will explain them respectively. Term fiis the empirical risk between the sum of shared
and unique signals and the observation matrix M(i).ℓis a loss metric that can incorporate
a wide range of applications. For example, in matrix factorization, the squared error loss
isℓse
M(i),ˆM(i)
=1
2M(i)−ˆM(i)2
F, i.e., the square error between the observed and
reconstructed matrices. In matrix completion, only a limited number of entries are observed.
We use Ω (i)to denote the set of indices of the observed entries, PΩ(i)(·)to denote the
projection
[PΩ(i)(M)]j,k=(
[M]j,kif entry ( j, k)∈Ω(i)
0 otherwise.
for a general matrix M. Then the projected square error loss ℓpseis defined as
ℓpse
M(i),ˆM(i)
=1
2PΩ(i)
M(i)−ˆM(i)2
F. There are also numerous other loss met-
ricsℓ, such as Huber loss used in robust matrix factorization (Wang and Fan, 2022) or
cross-entropy loss used in community detection (Yang and Leskovec, 2013).
The constraints UT
gU(i),l= 0 reflect our prior belief about the data generation process.
Since we consider the model where the true shared and unique features are orthogonal (2), it
is natural to encode the orthogonality into constraints. Explicitly enforcing the orthogonality
constraints is one of the major differences between our work and the previous works including
JIVE. As we will see in numerical examples, such constraints can encourage shared and
unique features to capture more distinct patterns.
Term giis a regularization term that pushes the Umatrices to be orthonormal. A
well-known theoretical issue in matrix factorization is that objectives like the term fiare
homogeneous with respect to the variables, which in turn leads to the non-smoothness of
the loss function. Regularization terms are added to ensure the smoothness of the loss.
Several works on matrix completion (e.g. (Park et al., 2017; Tu et al., 2016; Fattahi and
Sojoudi, 2020)) consider balancing regularization terms of the formUT
gUg−VT
(i),gV(i),g2
Fto encourage column factors Ugand row factors V(i),gto have similar singular values. Under
a similar rationale, we leverage the regularization terms in gito prevent too radical Ugand
U(i),l’s, as such regularizations are easier to work with in the presence of the constraints
UT
gU(i),l= 0. Here, the parameter βcontrols the strength of the regularization.
Since term fiandgiare both nonconvex, and the feasible set corresponding to the
constraint UT
gU(i),l= 0 is also nonconvex, the problem (3)is nonconvex. In the next section,
we will propose a gradient-based and distributed algorithm to solve the nonconvex problem.
3.2 Extension to auto-encoders
The model (1)is based on linear embeddings of UandV. As a natural extension, we use
auto-encoders (Goodfellow et al., 2016) to find the nonlinear embeddings in data. If some
entries of a matrix Mare missing, we use Mobsto denote the padded matrix Mwhose
unobserved entries are simply replaced with 0. For auto-encoders, the feature matrix Uis
replaced by an encoder network NetU:Rd→Rrthat maps a column of matrix Mobs
(i)into an
embedding vector with dimension r, and the coefficient matrix Vis replaced by a decoder
neural network NetV:Rr→Rdthat maps an embedding vector with dimension rto the
reconstructed observation vector in Rd. We use UandVto denote trainable weights that
5parametrize the neural networks. To accommodate the heterogeneity of features from N
different Mobs
(i), we also introduce a shared encoder NetUgandNunique encoders {NetU(i),l}
to generate the embeddings. All encoders have the same architecture but are parametrized
by different weights. In analogy to (3), we thus propose the following objective for the
nonlinear version of HMF,
min
Ug,{U(i),l},VNX
i=1h
ℓ
M(i),NetV
NetUg
Mobs
(i)
+NetU(i),l
Mobs
(i)
+R 
Ug,U(i),l,Vi
such that, F(NetUg([Mobs
(i)]:,j))TF(NetU(i),l([Mobs
(i)]:,j)) = 0 ,∀j∈[n(i)], i∈[N]
(5)
In(5), we use a compact notation NetUg(Mobs
(i)) to denote the application of NetUgon
each column of Mobs
(i).ℓis still a loss metric. R 
Ug,U(i),l,V
is a regularization term that
prevents the over-fitting of the neural network. In the constraint, F(·)is the folding operator
that folds an r-dimensional vector into kvectors, each with dimension r/k. The constraint
F(NetUg([Mobs
(i)]:,j))TF(NetU(i),l([Mobs
(i)]:,j)) = 0 is a “group orthogonalization condition”
that requires the kfolded vectors generated by the shared encoders to be orthogonal to
kfolded vectors generated by the unique encoders for each column of Mobs
(i). Such group
orthogonalization constraint is a natural extension of the linear constraint in (3), and
encourages NetUgandNetU(i),lto encode different embeddings.
We call this formulation heterogeneous auto-encoders ( HAE).
4 Algorithm
This section will develop the heterogeneous matrix factorization ( HMF) algorithm and its
extenstion to optimize the heterogeneous auto-encoder (5).
4.1 Heterogeneous Matrix Factorization
We use ˜fto denote the summation of ˜fi’s over different sources i,
˜f(Ug,{V(i),g,U(i),l,V(i),l}) =NX
i=1˜fi (6)
The objective ˜fis differentiable. Thus to optimize (3), one can calculate the gradient of ˜fi
with respect to its variables as,


∇Ug˜fi=ℓ′V(i),g+ 2βUg 
UT
gUg−I
∇V(i),g˜fi=ℓ′TUg
∇U(i),l˜fi=ℓ′V(i),l+ 2βU(i),l
UT
(i),lU(i),l−I
∇V(i),l˜fi=ℓ′TU(i),l(7)
where ℓ′denotes the gradient of the empirical loss ℓ,ℓ′=∇ˆM(i)ℓ(M(i),ˆM(i)).
The constraint UT
gU(i),l= 0 poses challenges to the optimization. One naive idea is to
use projected gradient descent to handle this constraint. However, the projection can not be
6easily implemented as the feasible region is nonconvex. A few works also introduce infeasible
updates when the constraint is complicated, including ADMM (Hong and Luo, 2017) or SQP
(Curtis and Overton, 2012). Such approaches often introduce additional tuning parameters
to balance the objective and the constraint.
We take a different route by exploiting a special invariance property in(3). More
specifically, for any R∈Rr1×r2,(i), we can apply the transform φRonUgandU(i),l,
φR: 
Ug,V(i),g,U(i),l,V(i),l
7→ 
Ug,V(i),g+V(i),lRT,U(i),l−UgR,V(i),l
without changing fi:fi(Ug,V(i),g,U(i),l,V(i),l) =fi 
φR 
Ug,V(i),g,U(i),l,V(i),l
.
The invariance property is a result of the special bi-linear structure in (4). One
can use such invariance to ensure the feasibility of the iterations. By choosing R= 
UT
gUg−1UT
gU(i),l, the transform φRautomatically corrects V(i),gandU(i),l, such that
U(i),lis orthogonal to Ug, without changing fi. Based on this fact, we can propose an itera-
tive algorithm. In each epoch, we use φRto correct the variables to ensure feasibility. Then
we use gradient descent on ( Ug,V(i),g,U(i),l,V(i),l) to decrease the regularized objective. A
pseudo-code is shown in Algorithm 1.
Algorithm 1 HMF
1:Input matrices {M(i)}N
i=1, stepsize η
2:Initialize Ug,1,V(i),g,1
2,U(i),l,1
2,V(i),l,1to be small random matrices.
3:forIteration τ= 1, ..., R do
4:fori= 1,···, Ndo
5: Correct U(i),l,τ=U(i),l,τ−1
2−Ug,τ 
UT
g,τUg,τ−1UT
g,τU(i),l,τ−1
2
6: Correct V(i),g,τ=V(i),g,τ−1
2+V(i),l,τUT
(i),l,τ−1
2Ug,τ 
UT
g,τUg,τ−1
7: Update U(i),g,τ+1=Ug,τ−η∇Ug˜fi.
8: Update V(i),g,τ+1
2=V(i),g,τ−η∇V(i),g˜fi.
9: Update U(i),l,τ+1
2=U(i),l,τ−η∇U(i),l˜fi.
10: Update V(i),l,τ+1=V(i),l,τ−η∇V(i),l˜fi.
11: end for
12: Calculates Ug,τ+1=1
NPN
i=1U(i),g,τ+1
13:end for
14:Return Ug,R,{V(i),g,R},{U(i),l,R},{V(i),l,R}.
In Algorithm 1, we use τto denote the iteration index, where a half-integer denotes that
the update of the variable is half complete: it is updated by gradient descent but is not
feasible yet.
One salient feature of algorithm 1 is that it is distributed in nature. Suppose there are
Ncomputation nodes, each holding one observation matrix M(i). Then, Algorithm 1 can be
run on these computation nodes with the help of a central server. In such a scenario, node i
carries out all computation from line 5 to line 10 in Algorithm 1 (colored in teal) and sends
the updated copies of U(i),gto the central server. The server then takes the average in line
12 (colored in brown) and broadcasts the averaged Ugto all nodes.
7The matrix inversion in algorithm 1 takes O(r3
1+r3
2,(i)) operations, all other matrix
productions take O(n1n2(r1+r2,(i))) operations. Therefore if r1andr2,(i)is dominated by
n1andn2, the computational complexity of one single iteration is O(n1n2(r1+r2,(i))).
Algorithm 1 can be readily extended to train the autoencoder in (5). The specifics of
the training algorithm is presented in Appendix A.
5 Convergence Analysis
In spite of its simplicity, Algorithm 1 has provable convergence guarantees. In this section,
we first show that if ℓis the square error (SE), HMFcan converge into the optimal solutions,
which also has a statistical error upper bound. Furthermore, when ℓtakes generic forms,
HMFwill converge into KKT points.
In this section we use B(B1, B2)to denote the set of variables with bounded norms,
B(B1, B2)= (x;∥Ug∥,U(i),l≤B1,V(i),g,V(i),l≤B2). We relegate the proof of all
theorems in this section to the supplementary materials.
5.1 Square Error
The square error, denoted as ℓse(M(i),ˆM(i)) =M(i)−ˆM(i)2
F, measures the sum of the
square of the element-wise difference between M(i)and ˆM(i). Setting ℓtoℓsenaturally
generates the formulation of matrix factorization. Consequently, we thoroughly investigate
the convergence behavior of HMFwith respect to the SE.
Before presenting the convergence results, we briefly review the concept of misalignment
proposed in (Shi and Kontar, 2024). Intuitively speaking, misalignment characterizes the
avarage “minimal difference” among the subspace spanned by a series of vectors. More
formally,
Definition 1 (θ-misalignment) We say {U⋆(i),l}N
i=1areθ-misaligned if there exists a positive
constant θ∈(0,1)such that, λmax
1
NPN
i=1PU⋆(i),l
≤1−θ.
where we define the projection matrix PU∈Rd×dfor a matrix U∈Rd×nasPU=
U 
UTU−1UT.
With the definition of misalignment, we are able to show the following upper bound on
the statistical error.
Theorem 2 (Statistical error) Consider the data generation model (1). Suppose that
(i) the signal part U⋆gV⋆T
(i),g+U⋆(i),lV⋆T
(i),lhasr1+r2nonzero singular values upper
bounded by σmaxand lower bounded by σmin, (ii) unique factors U⋆(i),lareθ-misaligned, (iii)
ˆUg,{ˆV(i),g,ˆU(i),l,ˆV(i),l}N
i=1is one set of optimal solutions to (3)with square error loss ℓse,
then, the following holds
NX
i=1ˆUgˆVT
(i),g−U⋆gV⋆T
(i),g2
F+ˆU(i),lˆVT
(i),l−U⋆
(i),lV⋆T
(i),l2
F
=O1
θNX
i=1E⋆
(i)
F+E⋆
(i)2
F2
+E⋆
(i)
F+E⋆
(i)2
F(8)
8Theorem 2 provides an upper bound on the distance between the optimal solution to (3)
and the ground truth. To the best of our knowledge, we are the first to prove such statistical
error bound in the context of heterogeneous matrix factorization. Interestingly, when the
misalignment parameter θis larger, the statistical error upper bound in (8)is smaller, which
means the features are easier to identify. In the following, we will continue to discuss the
convergence into the optimal solutions.
We use ϕ(i),τto denote the optimality gap at iteration τofHMFfor client i,ϕ(i),τ=
˜fi(Ug,τ,V(i),g,τ,U(i),l,τ,V(i),l,τ)−˜fi(ˆUg,τ,ˆV(i),g,τ,ˆU(i),l,τ,ˆV(i),l,τ). Accordingly, the total
optimality gap is defined as ϕτ=PN
i=1ϕ(i),τ. The following theorem establishes HMF’s linear
convergence.
Theorem 3 (Convergence of HMF) If the assumptions in Theorem 2 are satisfied, and
additionally, the following conditions hold: (i) M(i)=U⋆gV⋆T
(i),g+U⋆(i),lV⋆T
(i),l+E⋆(i),
whereE⋆(i)
F=O(θσmin), (ii) the initial optimality gap satisfies ϕ1=O 
θ1.5σ2
min
, (iii)
the stepsize satisfies η=O
1
σ2max
.
Then, there exists a constant C >0such that the iterations of HMFsatisfy
ϕτ≤(1−Cη)τ−1ϕ1 (9)
The first condition in Theorem 3 imposes an upper bound on the noise matrix so that
the benign optimization landscape is not destroyed by the gross noise. The second condition
in Theorem 3 requires an upper bound on the initial optimality gap. Roughly speaking, this
condition ensures that the iterates do not become trapped at a sub-optimal local solution and
lie within a basin of attraction of the global solution. We note that recent results have relaxed
this condition for other variants of nonconvex matrix factorization by resorting to small,
random, or spectral initialization techniques (Li et al., 2018b; St¨ oger and Soltanolkotabi,
2021; Ma and Fattahi, 2022; Ma et al., 2022; Tu et al., 2016; Ma et al., 2018). We believe
such techniques can be used in HMFto relax the aforementioned initial condition. In fact, in
our simulations, we observed that HMFwith a small Gaussian random initial point converges
to a global solution in almost all instances.
We leave the rigorous analysis of this observation as an enticing challenge for future
research. Finally, the last condition in Theorem 3 imposes an upper bound on the stepsize
of our algorithm to guarantee its convergence.
5.2 General Loss
Under a generic Lipschitz continuous loss function ℓ, less geometric information is known for
the loss landscape. Still, we are able to prove that Algorithm 1 will converge into a KKT
point to problem (3). In this section, we assume r2,(i)=r2, without loss of generality.
Theorem 4 (Convergence of HMFunder general loss) Suppose that the following con-
ditions are satisfied for HMF: (i) there exist constants B1, B2>0that can upper bound the
norm of all iterates 
Ug,{V(i),g,U(i),l,V(i),l}
∈ B(B1, B2), (ii) ℓisL-Lipschitz continuous,
(iii) the stepsize satisfies η=O 1
L2
. Then
min
τ∈{1,T−1}∇˜f(xτ)2
F=O 
T−1
.
9Figure 1: Shared factor error and unique factor error (log-scale) in each iteration.
It is worth noting that at KKT points of problem (3), the gradient norm is zero∇˜f
F= 0.
Hence, Theorem 4 essentially characterizes the rate for Algorithm 1 to converge into
KKT solutions. Such convergence guarantees are not attainable for the previous heuristic
algorithms, including JIVE (Lock et al., 2013), COBE (Zhou et al., 2015), BIDIFAC (Park
and Lock, 2020), and many more, while HMFis guaranteed to converge. The improvement
results from the introduced correction steps in Algorithm 1.
6 Experimental Results
In this section, we present the results of the numerical simulations. We use a synthetic
example and three real-life case studies. Code for all numerical studies is available in the
following repository: https://github.com/UMDataScienceLab/hmf .
6.1 Synthetic Data
We use synthetic data to examine the numerical convergence of HMF. We generate data
according to the model (1), where U⋆g,U⋆(i),l,V⋆(i),g,V⋆(i),lare randomly sampled from
Gaussian distributions. Then we deflate U⋆(i),lto satisfy the requirement U⋆T
gU⋆(i),l= 0.
The noise E⋆(i)is set to 0 to examine the convergence behavior of our algorithm better. We
fixn2= 100 and select n1∈ {30,60,120}to see the effect of different observation matrix sizes.
The ranks of the global and local components are set to r1=r2= 3, and the number of clients
isN= 100. We run HMFon the generated data with the decision variables Ug,U(i),l,V(i),g,
V(i),linitialized as small Gaussian matrices. The errorsPN
i=1Ug,τVT
(i),g,τ−U⋆gV⋆T
(i),g2
F
andPN
i=1U(i),l,τVT
(i),l,τ−U⋆(i),lV⋆T
(i),l2
Fare calculated in each iteration and plotted as
shared feature error and unique feature error in Figure 1. It can be observed that after a few
10Table 2: Subspace error under different ratios of missing entries.
Algorithm 50% 10% 5% 1%
RJIVE 7 .9±0.1 5 .9±0.1 5 .9±0.1 5 .9±0.1
JIVE 0 .52±0.01 (5 .4±0.1)×10−2(2.6±0.1)×10−2(5.2±0.2)×10−3
perPCA 0 .51±0.01 (5 .4±0.1)×10−2(2.6±0.1)×10−2(5.2±0.2)×10−3
HMF (4.5±0.7)×10−2(2.0±0.2)×10−6(7.3±0.4)×10−7(3.4±0.3)×10−8
iterations1, the errors decrease linearly, which is consistent with our theoretical guarantee in
Theorem 3.
We also compare HMFwith three representative baseline algorithms on the synthetic
dataset. To simulate the effects of missing entries, we uniformly randomly remove a subset
of entries in each M(i). Then we run HMFwith ℓpse, JIVE, RJIVE, and perPCA on the
partially observed {M(i)}and calculate the subspace error defined asPUg−PU⋆g2
F+
1
NPN
i=1PU(i),l−PU⋆(i),l2
F. The missing entries are treated as zero in JIVE, RJIVE, and
perPCA. We run the experiments from 3 different random seeds and calculate the mean and
standard deviation of the subspace error. Results are reported in Table. 2. In Table. 2, HMF
has consistently low subspace error, even when the ratio of missing elements is as high as
50%. The result highlights HMF’s superior ability to recover shared and unique features from
incomplete data.
6.2 Case study: video segmentation from incomplete entries
We use an illustrative example in video segmentation to demonstrate the application of HMF.
The video comes from a simulated surveillance dataset (Vacavant et al., 2013). In the video,
multiple vehicles drive through a roundabout. We uniformly randomly remove 40% pixels
to simulate the effects of missing observations. We divide each video frame iinto multiple
7×7 patches and flatten these patches into row vectors to construct observation matrix
M(i). Then, we apply HMFto identify the shared and unique signals from the observation
matrices with r1= 20 and r2,(i)=r2= 30. Naturally, the shared signals will correspond
to the stationary components in the video, and unique signals correspond to the changing
parts. We reconstruct the frames from the shared and unique signals and plot the results in
Figure 2.
The first row of Figure 2 shows 5 sample frames from the video. They are corrupted as
many pixels are missing. The second row plots the reconstructed UgVT
(i),g, one can see that
HMFclearly identifies the fine details on the background. The third row of Figure 2 are the
reconstructed U(i),lVT
(i),l, which also conspicuously show the moving cars.
As comparisons, we also run benchmark algorithms JIVE, RJIVE, and perPCA on the
same dataset with the same data preprocessing procedures. To evaluate the segmentation
performance, we calculate the mean squared error (MSE) and the peak signal-to-noise ratio
(PSNR) for the recovered foreground and backgrounds. Results are shown in Table 3.
A higher level of quality in the reconstructed background and foreground is typically
associated with a lower MSE and a higher PSNR. As indicated in Table 3, it is evident
1.The initial sublinear convergence of the algorithm is due to the fact that our initial point does not satisfy
the condition of Theorem 3. However, once the iterations reach the basin of attraction of the global
solution, the iterations converge linearly.
11Figure 2: Video Segmentation. 5 frames from the video are plotted.
Table 3: Separation performance for different algorithms. BMSE represents MSE for back-
ground reconstruction, FSME represents MSE for foreground reconstruction, similar
for BPSNR and FPSNR.
perPCA JIVE RJIVE HMF
BMSE 0.021 0.024 0.027 0.001
BPSNR 16.7 16.3 15.8 29.8
FMSE 93.7 93.4 94.8 69.4
FPSNR 31.0 31.0 31.0 31.6
that HMFconsistently achieves lower MSE and higher PSNR values for both foreground and
background reconstructions in comparison to benchmark algorithms, thus confirming its
superior performance.
6.3 Case Study: Stocks Market Data
HMFcan also be applied to data from the financial market. As a proof-of-concept, we analyze
the daily stock prices of 214 stocks from January 2, 1990 to November 9, 2017. The goal is
to understand the time-specific patterns in stock prices. These patterns are often related
to abnormal market behaviors and provide insightful information for subsequent trading
decisions.
Similar to (Fattahi and Gomez, 2021), we use a time window of 30 days to group the
stock prices into different batches, and analyze the common and unique features among
these batches. Each batched data matrix M(i)has dimension 214 ×30. The unique features
represent structural differences in the stock prices in each batch, thus signaling sudden
changes in the market. To find the unique features, we apply HMFon the batched data to
extract U(i),l’s and V(i),l’s. To measure the “heterogeneity index” in each batch, we calculate
12Figure 3: The blue curve denotes the heterogeneity index of 214 stock returns from 1998 to
2014. The orange curve is the SP500 closing prices at the corresponding dates.
We label 4 periods where the heterogeneity index has large peaks
the column-wise ℓ1norm of the signal matrix U(i),lVT
(i),lfor each i. The heterogeneity indices
are plotted as the blue curve in Figure 3. To provide better insight, we also plot the SP500
closing prices in the same figure.
From Figure 3, one can observe that almost every significant historical market crash
(shown as sudden drops in the orange curve) corresponds to a peak in the heterogeneity index.
We also identify 4 major periods when the heterogeneity index has several large peaks. By
comparing these periods with the history of the global financial market (Wikipedia, 2023),
one can see that A corresponds to the “dot-com bubble”, B corresponds to the “September
11 attack”, C corresponds to “stock market downturn of 2002”, and D corresponds to the
“2007-2008 financial crisis and the aftermath”.
6.4 Case study: rating prediction on MovieLens
The ability to effectively distinguish between shared and unique features is also beneficial
in recommender systems. This is exemplified in the MovieLens-100k dataset (Harper and
Konstan, 2015). The dataset contains 105ratings (1-5) on 1682 movies from 943 users.
Additionally, each movie is labeled with genre labels, such as action, adventure, or animation.
There are 19 genres in total. Notice that each movie can have more than one genre label.
For example, the movie Titanic belongs to both the romance and drama genre.
To characterize the genre information, we first cluster movies into different groups
according to the genre labels. Different groups represent different sources. More specifically,
for movie m, we use multi-hot encoding to create its genre information vector gm∈R19,
whose j-th element is 1 if movie mbelongs to genre j. Next, we normalize gmand use
K-means clustering to cluster the normalized gms into 10 groups. For each group, we
construct user-movie rating matrices M(i). Each M(i)has 943 rows, and its number of
columns is equal to the number of movies in cluster i. Thus M(i)is highly sparse. Then we
randomly split each Ω (i)into 90% training set Ωtrain
(i)and 10% test set Ωtest
(i)and apply HMF
with ℓpseon the Ωtrain
(i).
13We use two methods to predict the user ratings on unseen movies: (i) collaborative
filtering, which is based on linear model (3), and (ii) auto-encoders, which is based on the
nonlinear model (5).
Collaborative filtering The standard collaborative filtering method pools ratings for
movies from all genres and exploits matrix completion to extract the low-rank movie features
and user features on ∪iΩtrain
(i)(Koren et al., 2009). These features can then be leveraged
for new rating predictions on unseen movies. Though achieving decent performance, the
standard collaborative filtering only finds generic movie features and neglects the genre
information. To incorporate the genre information, we apply HMFto the genre-clustered
ratings M(i)to identify both generic features and genre-specific features. The new predictions
are given as the entries of ˆUgˆV(i),g+ˆU(i),lˆV(i),l.
Auto-encoder As discussed in Section 3.2, auto-encoders are nonlinear extensions to
matrix factorization models and can potentially encode richer information. The auto-encoders
have been employed in the rating prediction tasks and have been shown to outperform
collaborative filtering based on linear features (Muller et al., 2018). The standard auto-
encoder approach for rating prediction minimizes the following reconstruction loss,
min
U,VPΩtrain
M−NetV
NetU
Mobs2
F+R(U,V) (10)
, where Mobsis the observed rating matrix Mpadded with zero in all entries outside the
training set Ω train.R(U,V)is the regularization term dependent on the architecture of the
neural network.
There are numerous works focusing on the architecture of the encoder and decoder
network (Zhang et al., 2017; Darban and Valipour, 2022; Rashed et al., 2019). Among them,
sparsely supported fully connected neural network (SparseFC) (Muller et al., 2018) achieves
decent performance. We briefly introduce the main idea of sparse FC for consistency. A
standard full-connected neural network consists of multiple layers. Layer lwill transform the
input x(l−1)to the output x(l)via a linear mapping W(l)followed by a nonlinear activation
σ(l), i.e., x(l)=σ(l)(W(l)x(l−1)). A sparse kernel layer chooses a different parametrization of
the linear mapping W(l). More specifically, the j-th element out the output x(l)is given by,
x(l)
j=σ(l) X
iα(l)
iK(u(l)
i, u(l)
j)x(l−1)
i!
, where α(l)
i,u(l)
i, and u(l)
jare trainable parameters. Kis a kernel function that can be defined
as Gaussian kernel K(x, y) =exp
−γ∥x−y∥2
. Intuitively, such parametrization would
make the weights K(u(l)
i, u(l)
j) sparse. Sparse FC networks are constructed by sequentially
applying sparse kernel layers. Because of their superior generalization performance, we use
sparse neural networks as the backbones for the encoder and decoder networks NetUand
NetVin(10). We implement the architecture and pool M(i)to build M, then solve (10)
with AdamW (Loshchilov and Hutter, 2019).
As introduced in Section 3.2, we can also employ a heterogeneous version of auto-encoders
HAE. More specifically, we use a shared encoder network NetUgand 10 genre-specific encoders
NetU(i),lto learn both shared and unique nonlinear embeddings of movies. Then, we use a
14decoder NetVto predict user ratings. We still use the sparse FC network as the backbones
of the encoders and decoders.
To visualize the embeddings from standard auto-encoders and heterogeneous auto-
encoders, we show t-SNE plots of different movie embeddings in Figure 4.
Figure 4: t-SNE plots of movie embeddings. Each dot represents a movie. Its color denotes
one genre of the movie. Left: t-SNE of embeddings from HAE.Right : t-SNE of
embeddings from standard auto-encoders
In Figure 4, it is clear that the embeddings from HAEform clusters dependent on the
genre, while the embeddings from standard auto-encoders do not have a clear structure.
These observations are consistent with our intuition that movies with similar genres should
have similar embeddings.
With the fitted models from HMForHAE, we can predict user ratings on unseen movies.
To evaluate the predictive performance, we calculate the predicted ratings on the test set
Ωtest
(i)and compare it with the ground truth. As the movielens 100k dataset is extensively
analyzed in the literature, we also report the RMSE of a few representative benchmark
methods detailed as follows,
•Matrix completion (Koren et al., 2009): We implement the standard matrix completion
on the pooled rating matrix Mto extract linear features.
•AutoSVD++ (Zhang et al., 2017): AutoSVD++ is a hybrid model combining a variant
of biased SVD and a 1-layer fully connected neural network.
•GHRS (Darban and Valipour, 2022): Graph-based Hybrid Recommendation System
builds user similarity graph based on user ratings and side information, including age
15and occupation, then clusters users into different groups and uses group features to
make predictions on the unseen ratings.
•GraphRec (Rashed et al., 2019): GraphRec is a nonlinear model that uses a neural
network to create user and movie embeddings. It also considers the graph-based
features from the user similarity graph.
The root mean square error (RMSE) of the prediction on the test set is shown in Table 4.
For matrix completion, HMF, Sparse FC, and HAE, we run each experiment from 80 different
random seeds and report the mean and standard deviation. For other methods, we report
the performance from the literature.
Table 4: Prediction root mean square error (RMSE) on movielens 100K (10% randomly
selected test set).
Method Source RMSE
Matrix completion (Koren et al., 2009) 0 .981±0.001
HMF Ours 0 .977±0.001
AutoSVD++ (Zhang et al., 2017) 0.901
GHRS (Darban and Valipour, 2022) 0.887
GraphRec (Rashed et al., 2019) 0.883
Sparse FC (Muller et al., 2018) 0 .8838±0.0006
HAE Ours 0.8800±0.0006
In Table 4, it is clear that HAEhas the lowest test error, suggesting that the heterogeneous
features learned by HAEare more accurate in terms of predicting the users’ preferences.
Therefore, the genre features bring useful information to the movie ratings prediction.
7 Conclusion and Discussion of Limitations
This work proposes HMFthat solves a constrained matrix factorization problem to extract
shared and unique features from heterogeneous data, and extends the model to auto-encoders.
One avenue for future research is to consider scenarios where the rank of feature matrices
r1andr2are unknown and must be over-estimated instead (Ma and Fattahi, 2022; St¨ oger
and Soltanolkotabi, 2021). Such a setting (also known as overparameterization) has been
extensively studied for the classical matrix factorization literature. Another promising
direction is to improve the initialization condition for the guaranteed convergence of our
proposed algorithm. Although the theoretical guarantee of our algorithm (Theorem 3) relies
on the availability of a good initial point, we hypothesize that this requirement can be
relaxed, as the algorithm works well in practice with a small and random initialization.
168 Acknowledgments
This research is supported in part by Raed Al Kontar’s NSF CAREER Award 2144147 and
Salar Fattahi’s NSF CAREER Award CCF-2337776.
References
D. P. Bertsekas. Nonlinear programming. Journal of the Operational Research Society , 48
(3):334–334, 1997.
D. Chai, L. Wang, K. Chen, and Q. Yang. Secure federated matrix factorization. IEEE
Intelligent Systems , 36(5):11–20, 2021. doi: 10.1109/MIS.2020.3014880.
J. Chen, D. Liu, and X. Li. Nonconvex rectangular matrix completion via gradient descent
without l2,∞regularization. IEEE Transactions on Information Theory , 66(9):5806–5841,
2020.
F. E. Curtis and M. L. Overton. A sequential quadratic programming algorithm for
nonconvex, nonsmooth constrained optimization. SIAM Journal on Optimization , 22(2):
474–500, 2012.
Z. Z. Darban and M. H. Valipour. Ghrs: Graph-based hybrid recommendation system with
application to movie recommendation. Expert Systems with Applications , 200:116850,
2022.
S. Fattahi and A. Gomez. Scalable inference of sparsely-changing gaussian markov random
fields. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan, editors,
Advances in Neural Information Processing Systems , volume 34, pages 6529–6541. Curran
Associates, Inc., 2021. URL https://proceedings.neurips.cc/paper_files/paper/
2021/file/33853141e0873909be88f5c3e6144cc6-Paper.pdf .
S. Fattahi and S. Sojoudi. Exact guarantees on the absence of spurious local minima for
non-negative rank-1 robust principal component analysis. Journal of machine learning
research , 2020.
I. Gaynanova and G. Li. Structural learning and integrative decomposition of multi-view
data. Biometrics , 75(4):1121–1132, 2019.
R. Ge, C. Jin, and Y. Zheng. No spurious local minima in nonconvex low rank problems:
A unified geometric analysis. In International Conference on Machine Learning , pages
1233–1242. PMLR, 2017.
R. Gemulla, E. Nijkamp, P. J. Haas, and Y. Sismanis. Large-scale matrix factorization
with distributed stochastic gradient descent. In Proceedings of the 17th ACM SIGKDD
international conference on Knowledge discovery and data mining , pages 69–77, 2011.
I. Goodfellow, Y. Bengio, and A. Courville. Deep Learning . MIT Press, 2016. http:
//www.deeplearningbook.org .
17F. M. Harper and J. A. Konstan. The movielens datasets: History and context. Acm
transactions on interactive intelligent systems (tiis) , 5(4):1–19, 2015.
I. Higgins, L. Matthey, A. Pal, C. Burgess, X. Glorot, M. Botvinick, S. Mohamed, and
A. Lerchner. beta-VAE: Learning basic visual concepts with a constrained variational
framework. In International Conference on Learning Representations , 2017. URL https:
//openreview.net/forum?id=Sy2fzU9gl .
M. Hong and Z.-Q. Luo. On the linear convergence of the alternating direction method of
multipliers. Mathematical Programming , 162(1-2):165–199, 2017.
R. Kontar, N. Shi, X. Yue, S. Chung, E. Byon, M. Chowdhury, J. Jin, W. Kontar, N. Masoud,
M. Nouiehed, et al. The internet of federated things (ioft). IEEE Access , 9:156071–156113,
2021.
Y. Koren, R. Bell, and C. Volinsky. Matrix factorization techniques for recommender systems.
Computer , 42(8):30–37, 2009. doi: 10.1109/MC.2009.263.
D. D. Lee and H. S. Seung. Learning the parts of objects by non-negative matrix factorization.
Nature , 401(6755):788–791, 1999.
X. Li, J. Haupt, J. Lu, Z. Wang, R. Arora, H. Liu, and T. Zhao. Symmetry. saddle points,
and global optimization landscape of nonconvex matrix factorization. In 2018 Information
Theory and Applications Workshop (ITA) , pages 1–9, 2018a. doi: 10.1109/ITA.2018.
8503215.
Y. Li, T. Ma, and H. Zhang. Algorithmic regularization in over-parameterized matrix sensing
and neural networks with quadratic activations. In Conference On Learning Theory , pages
2–47. PMLR, 2018b.
G. Liang, N. Shi, R. A. Kontar, and S. Fattahi. Personalized dictionary learning for
heterogeneous datasets. In Thirty-seventh Conference on Neural Information Processing
Systems , 2023. URL https://openreview.net/forum?id=xw6Szwu4xz .
E. F. Lock, K. A. Hoadley, J. S. Marron, and A. B. Nobel. Joint and individual variation
explained (jive) for integrated analysis of multiple data types. The annals of applied
statistics , 7(1):523, 2013.
I. Loshchilov and F. Hutter. Decoupled weight decay regularization. In International
Conference on Learning Representations , 2019. URL https://openreview.net/forum?
id=Bkg6RiCqY7 .
C. Ma, K. Wang, Y. Chi, and Y. Chen. Implicit regularization in nonconvex statistical
estimation: Gradient descent converges linearly for phase retrieval and matrix completion.
InInternational Conference on Machine Learning , pages 3345–3354. PMLR, 2018.
J. Ma and S. Fattahi. Global convergence of sub-gradient method for robust matrix recovery:
Small initialization, noisy measurements, and over-parameterization. arXiv preprint
arXiv:2202.08788 , 2022.
18J. Ma, L. Guo, and S. Fattahi. Behind the scenes of gradient descent: A trajectory analysis
via basis function decomposition. arXiv preprint arXiv:2210.00346 , 2022.
L. Muller, J. Martel, and G. Indiveri. Kernelized synaptic weight matrices. In International
Conference on Machine Learning , pages 3654–3663. PMLR, 2018.
D. Park, A. Kyrillidis, C. Carmanis, and S. Sanghavi. Non-square matrix sensing without
spurious local minima via the Burer-Monteiro approach. In A. Singh and J. Zhu, editors,
Proceedings of the 20th International Conference on Artificial Intelligence and Statistics ,
volume 54 of Proceedings of Machine Learning Research , pages 65–74. PMLR, 20–22 Apr
2017. URL https://proceedings.mlr.press/v54/park17a.html .
J. Y. Park and E. F. Lock. Integrative factorization of bidimensionally linked matrices.
Biometrics , 76(1):61–74, 2020.
A. Rashed, J. Grabocka, and L. Schmidt-Thieme. Attribute-aware non-linear co-embeddings
of graph features. In Proceedings of the 13th ACM conference on recommender systems ,
pages 314–321, 2019.
C. Sagonas, Y. Panagakis, A. Leidinger, and S. Zafeiriou. Robust joint and individual
variance explained. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition , pages 5267–5276, 2017.
N. Shi and R. A. Kontar. Personalized pca: Decoupling shared and unique features. Journal
of machine learning research , 2024.
D. St¨ oger and M. Soltanolkotabi. Small random initialization is akin to spectral learn-
ing: Optimization and generalization guarantees for overparameterized low-rank matrix
reconstruction. Advances in Neural Information Processing Systems , 34:23831–23843,
2021.
R. Sun and Z.-Q. Luo. Guaranteed matrix completion via non-convex factorization. IEEE
Transactions on Information Theory , 62(11):6535–6579, 2016.
S. Tu, R. Boczar, M. Simchowitz, M. Soltanolkotabi, and B. Recht. Low-rank solutions
of linear matrix equations via procrustes flow. In International Conference on Machine
Learning , pages 964–973. PMLR, 2016.
A. Vacavant, T. Chateau, A. Wilhelm, and L. Lequievre. A benchmark dataset for outdoor
foreground/background extraction. In Computer Vision-ACCV 2012 Workshops: ACCV
2012 International Workshops, Daejeon, Korea, November 5-6, 2012, Revised Selected
Papers, Part I 11 , pages 291–300. Springer, 2013.
B. Wang and J. Fan. Robust matrix completion with heavy-tailed noise. arXiv preprint
arXiv:2206.04276 , 2022.
Wikipedia. List of stock market crashes and bear markets, 2023. URL https:
//en.wikipedia.org/wiki/List_of_stock_market_crashes_and_bear_markets . [On-
line; accessed 17-May-2023].
19J. Wright and Y. Ma. High-dimensional data analysis with low-dimensional models: Princi-
ples, computation, and applications . Cambridge University Press, 2022.
J. Yang and J. Leskovec. Overlapping community detection at scale: a nonnegative matrix
factorization approach. In Proceedings of the sixth ACM international conference on Web
search and data mining , pages 587–596, 2013.
Z. Yang and G. Michailidis. A non-negative matrix factorization method for detecting
modules in heterogeneous omics multi-modal data. Bioinformatics , 32(1):1–8, 2016.
T. Ye and S. S. Du. Global convergence of gradient descent for asymmetric low-rank matrix
factorization. Advances in Neural Information Processing Systems , 34:1429–1439, 2021.
H.-F. Yu, N. Rao, and I. S. Dhillon. Temporal regularized matrix factorization for high-
dimensional time series prediction. Advances in neural information processing systems ,
29, 2016.
S. Zhang, L. Yao, and X. Xu. Autosvd++ an efficient hybrid collaborative filtering model
via contractive auto-encoders. In Proceedings of the 40th International ACM SIGIR
conference on Research and Development in Information Retrieval , pages 957–960, 2017.
G. Zhou, A. Cichocki, Y. Zhang, and D. P. Mandic. Group component analysis for multiblock
data: Common and individual feature extraction. IEEE transactions on neural networks
and learning systems , 27(11):2426–2439, 2015.
Appendix A. The algorithm to solve (5)
In this section, we introduce the detailed algorithm to solve (5). The algorithm uses AdamW
(Loshchilov and Hutter, 2019) as the backbone to optimize the regularized reconstruction
loss(5). To enforce the orthogonality constraint between the shared embeddings and the
unique embeddings, we explicitly calculate the projection of the unique embeddings to the
subspace spanned by the shared embeddings and remove such projection from the unique
embeddings. The pseudo-code is presented in Algorithm 2.
In each iteration of Algorithm 2, we calculate the shared and unique embeddings for each
source i. For two tensors A,B ∈Rb×d×c, the projection operator Proj :Rb×d×c×Rb×d×c→
Rb×d×coutputs another tensor. Its i, j, k -th element is defined as,
[Proj ( A,B)]i,j,k= [[A]i 
[A]T
i[A]i−1[A]T
i[B]i]j,k
, where we use [ A]i∈Rd×cto denote the i-th slice of A. Intuitively, the projection operator
projects each slice of Bonto the subspace spanned by the column vectors of Ain the
corresponding slice.
The unfolding operator F−1is the inverse of the folding operator F. It can be easily im-
plemented via the Rearrange function in pytorch. After the projection step, F(Emb (i),l,τ+1)
is orthogonal to F(Emb (i),g,τ+1). Thus, the orthogonality constraint in (5)is strictly satisfied.
The folding, projection, and unfolding operations are fully differentiable. Hence, after
calculating the regularized loss, we can use auto-differentiation packages to take the gradient
20Algorithm 2 HAE
1:Input matrices {Mobs
(i)}N
i=1, regularizations {R(i)}, stepsize η
2:forIteration τ= 1, ..., R do
3:fori= 1,···, Ndo
4: Calculates Emb (i),g,τ+1=NetUg,τ(Mobs
(i))
5: Calculates Emb(i),l,τ+1
2=NetU(i),l,τ(Mobs
(i))
6: Deflates Emb (i),l,τ+1=Emb(i),l,τ+1
2−F−1
Proj
F(Emb (i),g,τ+1),F(Emb(i),l,τ+1
2)
7: Calculates Loss (i),τ+1=PΩ(i)
train
M(i)−NetVτ 
Emb (i),l,τ+1+ Emb (i),g,τ+12
.
8: Updates {U(i),g,τ+1,U(i),l,τ+1,V(i),τ+1}= AdamW 
Loss (i),τ+1,R(i)
.
9:end for
10: Calculates Ug,τ+1=1
NPN
i=1U(i),g,τ+1
11: Calculates Vτ+1=1
NPN
i=1V(i),τ+1
12:end for
13:Return Ug,R,{V(i),g,R},{U(i),l,R},{V(i),l,R}.
of the regularized loss with respect to the parameters of the neural network. The gradients
are then passed to the AdamW optimizer to update the parameters. After updating all the
parameters, the weights for the decoder and for the shared encoder are averaged.
The algorithm repeats for Rrounds.
Appendix B. Proof of Theorem 1
For a matrix A∈Rm×n, we use ∥A∥or∥A∥2to denote A’s operator norm and ∥A∥Fto
denote its Frobenius norm.
The proof mainly consists of a perturbation analysis of the objective (4) in the main
paper. We assume that the loss metric is the square loss ℓsethroughout this section. We
firstly estimate the subspace error ofPˆUg−PU⋆g
FandPˆU(i),l−PU⋆(i),l
F. Then we
estimate the reconstruction errors.
The KKT conditions for the optimal ˆV(i),gandˆV(i),lare,

M(i)−ˆUgˆVT
(i),g−ˆU(i),lˆVT
(i),lTˆUg= 0

M(i)−ˆUgˆVT
(i),g−ˆU(i),lˆVT
(i),lTˆU(i),l= 0
Considering the constraint ˆUT
gˆU(i),l= 0, we can solve ˆV(i),landˆV(i),las,
ˆV(i),g=M(i)ˆUg
ˆUT
gˆUg−1
ˆV(i),l=M(i)ˆU(i),l
ˆUT
(i),lˆU(i),l−1
21Then the objective becomes,
˜fi(ˆUg,{ˆU(i),l}) =1
2M(i)−ˆUg
ˆUT
gˆUg−1ˆUT
gM(i)−ˆU(i),l
ˆUT
(i),lˆU(i),l−1ˆU(i),lM(i)2
F
+β
2ˆUT
gˆUg−I2
F+β
2ˆUT
(i),lˆU(i),l−I2
F
=1
2M(i)−PˆUgM(i)−PˆU(i),lM(i)2
F+β
2ˆUT
gˆUg−I2
F+β
2ˆUT
(i),lˆU(i),l−I2
F
Notice that if ˆUgand{ˆU(i),l}are optimal, we must have ˆUT
gˆUg=IandˆUT
(i),lˆU(i),l=I,
since we can always use Schmidt-Gram procedure to orthonormalize the columns of ˆUg
and{ˆU(i),l}without changing PˆUgand{PˆU(i),l}. Therefore without loss of generality, we
consider the problem
min
ˆUg,{ˆU(i),l}NX
i=1M(i)−PˆUgM(i)−PˆU(i),lM(i)2
F
such that ˆUT
gˆU(i),l= 0,∀i∈[N]
By our assumption on the data generation process, U⋆gand{U⋆(i),l}’s are also feasible.
Thus the objective evaluated at U⋆gand{U⋆(i),l}’s cannot be smaller than the optimal
objective,
NX
i=1M(i)−PˆUgM(i)−PˆU(i),lM(i)2
F≤NX
i=1M(i)−PU⋆gM(i)−PU⋆(i),lM(i)2
F
This is equivalent to
NX
i=1Tr
PˆUg+PˆU(i),l
M(i)MT
(i)
≥NX
i=1Tr
PU⋆g+PU⋆(i),l
M(i)MT
(i)
(11)
On the other hand, we can expand M(i)MT
(i)as
M(i)MT
(i)=
U⋆gV⋆T
(i),g+U⋆
(i),lV⋆T
(i),l
U⋆gV⋆T
(i),g+U⋆
(i),lV⋆T
(i),lT
+
U⋆gV⋆T
(i),g+U⋆
(i),lV⋆T
(i),l
E⋆T
(i)+E⋆
(i)
U⋆gV⋆T
(i),g+U⋆
(i),lV⋆T
(i),lT
+E⋆
(i)E⋆T
(i)
For simplicity, we use F⋆(i)to denote
F⋆
(i)=
U⋆gV⋆T
(i),g+U⋆
(i),lV⋆T
(i),l
E⋆T
(i)+E⋆
(i)
U⋆gV⋆T
(i),g+U⋆
(i),lV⋆T
(i),lT
+E⋆
(i)E⋆T
(i)
22Then the following holds,
Tr
M(i)MT
(i)
PU⋆g+PU⋆(i),l
−
PˆUg+PˆU(i),l
= Tr
U⋆gV⋆T
(i),g+U⋆
(i),lV⋆T
(i),l
U⋆gV⋆T
(i),g+U⋆
(i),lV⋆T
(i),lT
(12)

PU⋆g+PU⋆(i),l
−
PˆUg+PˆU(i),l
+ Tr
F⋆
(i)
PU⋆g+PU⋆(i),l
−
PˆUg+PˆU(i),l
(13)
The first term in (12) is equal to
Tr
U⋆gV⋆T
(i),g+U⋆
(i),lV⋆T
(i),l
U⋆gV⋆T
(i),g+U⋆
(i),lV⋆T
(i),lT
I−
PˆUg+PˆU(i),l
From assumption (i) in Theorem 1, we know

U⋆gV⋆T
(i),g+U⋆
(i),lV⋆T
(i),l
U⋆gV⋆T
(i),g+U⋆
(i),lV⋆T
(i),lT
⪰
PU⋆g+PU⋆(i),l
σ2
min
Since
I−
PˆUg+PˆU(i),l
is symmetric positive semidefinite, we have,
Tr
U⋆gV⋆T
(i),g+U⋆
(i),lV⋆T
(i),l
U⋆gV⋆T
(i),g+U⋆
(i),lV⋆T
(i),lT
I−
PˆUg+PˆU(i),l
≥σ2
minTr
PU⋆g+PU⋆(i),l
I−
PˆUg+PˆU(i),l
By Cauchy-Schwartz inequality, the second term in (12) is lower bounded by,
Tr
F⋆
(i)
PU⋆g+PU⋆(i),l
−
PˆUg+PˆU(i),l
≥ −F⋆
(i)
F
PU⋆g+PU⋆(i),l
−
PˆUg+PˆU(i),l
F
=−√
2F⋆
(i)
Fr
Tr
PU⋆g+PU⋆(i),l
I−
PˆUg+PˆU(i),l
Combing them, we can derive a lower bound on (12) as
Tr
M(i)MT
(i)
PU⋆g+PU⋆(i),l
−
PˆUg+PˆU(i),l
≥σ2
minTr
PU⋆g+PU⋆(i),l
I−
PˆUg+PˆU(i),l
−√
2F⋆
(i)
Fr
Tr
PU⋆g+PU⋆(i),l
I−
PˆUg+PˆU(i),l
Summing up both sides for ifrom 1 to N, and considering (11), we have,
0≥σ2
minNX
i=1Tr
PU⋆g+PU⋆(i),l
I−
PˆUg+PˆU(i),l
23−√
2NX
i=1F⋆
(i)
Fr
Tr
PU⋆g+PU⋆(i),l
I−
PˆUg+PˆU(i),l
≥σ2
minNX
i=1Tr
PU⋆g+PU⋆(i),l
I−
PˆUg+PˆU(i),l
−√
2vuutNX
i=1F⋆(i)2
FvuutNX
i=1Tr
PU⋆g+PU⋆(i),l
I−
PˆUg+PˆU(i),l
where we applied Cauchy-Schwartz inequality in the second inequality.
Therefore, one can deduce,
NX
i=1Tr
PU⋆g+PU⋆(i),l
I−
PˆUg+PˆU(i),l
≤2PN
i=1F⋆(i)2
F
σ4
min
As{U⋆(i),l}areθ-misaligned, from Lemma 2 in (Shi and Kontar, 2024), we have
NX
i=1Tr
PU⋆g+PU⋆(i),l
I−
PˆUg+PˆU(i),l
≥θ
2 
NTr
PU⋆g−PU⋆gPˆUg
+NX
i=1Tr
PU⋆(i),l−PU⋆(i),lPˆU(i),l!
We can thus conclude,
NPU⋆g−PˆUg2
F+NX
i=1PU⋆(i),l−PˆU(i),l2
F≤2PN
i=1F⋆(i)2
F
θσ4
min(14)
Finally, we prove an upper bound on the reconstruction error of the local and global
signals. Notice that
ˆUgˆVT
(i),g−U⋆gV⋆T
(i),g
F=PˆUgM(i)−U⋆gV⋆T
(i),g
F
=PˆUg
U⋆gV⋆T
(i),g+U⋆
(i),lV⋆T
(i),i
+PˆUgE⋆
(i)−U⋆gV⋆T
(i),g
F
≤PˆUg
U⋆gV⋆T
(i),g+U⋆
(i),lV⋆T
(i),i
−U⋆gV⋆T
(i),g
F+PˆUgE⋆
(i)
F
≤PˆUg−PU⋆g
Fσmax+E⋆
(i)
F(15)
We have,
ˆUgˆVT
(i),g−U⋆gV⋆T
(i),g2
F=PˆUgM(i)−U⋆gV⋆T
(i),g2
F
≤2PˆUg−PU⋆g2
Fσ2
max+ 2E⋆
(i)2
F
24Similarly we can prove
ˆU(i),lˆVT
(i),l−U⋆
(i),lV⋆T
(i),l2
F=PˆU(i),lM(i)−U⋆
(i),lV⋆T
(i),l2
F
≤2PˆU(i),l−PU⋆(i),l2
Fσ2
max+ 2E⋆
(i)2
F
Combining the two inequalities with (14) and considering the fact thatF⋆(i)
F≤
2σmaxE⋆(i)
F+E⋆(i)2
F, we can prove (7) in the main paper.
Appendix C. Proof of Theorem 2
In this section we will present the proof of Theorem 2 in the main paper. The proof of
Theorem 2 consists of 2 stages. In the first stage, we show Algorithm 1 converges into
stationary points. In the second stage, we analyze the local geometry of objective ˜fand
show that Algorithm 1 converges into the optimal solutions linearly. The major technical
difficulties lie in the second stage, where the constraints UT
gU(i),l= 0 make the local
geometry analysis complicated.
We will start with a few lemmas and prove Theorem 2 at the end. More specifically,
Lemma 5 connects the assumption on E(i)to a few properties on the optimal solution
ˆUg,{ˆV(i),g,ˆU(i),l,ˆV(i),l}
. Lemma 6 estimates the Lipschitz constant of objective ˜f.
Lemma 7 constructs the so called sufficient descent inequality. Lemmas 9, 10 11, and 12
are related to the geometry analysis. Finally, Lemma 14 shows the PL inequality of the
objective.
Lemma 5 IfM(i)=U⋆gV⋆T
(i),g+U⋆(i),lV⋆T
(i),l+E(i), where
•E(i)’s norm are upper bounded
E(i)
F≤
min

σminθ1.51
6√
2σmin
σmax, σmin2−√
3
2 
2 +6√
θσmax
σmin2!−1
, σminθ1
64√
Nσmin
σmax


•U⋆(i),l’s are θ-misaligned
•the singular values of U⋆gV⋆T
(i),g+U⋆(i),lV⋆T
(i),lare upper bounded by σmaxand lower
bounded by σmin
, we can introduce three new constants ˆσmax= 2σmax,ˆθ=θ
2, and ˆσ2
gap=σ2
min/2such that:
1. The largest singular values of M(i)’s are upper bounded by ˆσmax.
2.There exists constants ˆθ,ˆσ2
gap>0such that1
NPN
i=1PˆU(i),l≤1−ˆθ,
σ2
min
ˆUgˆVT
(i),g+ˆU(i),lˆVT
(i),l
−R(i)2≥ˆσ2
gap, andR(i)≤ˆθˆσ2
gap
8ˆσmaxfor every i.
25Remark If the condition numberσmax
σmin=O(1), the upper bound on the norm of E(i)can
be written asE(i)
F≤O 
σminθ1.5
.
Proof. We first prove Claim 1. By triangle inequality,
M(i)≤U⋆gV⋆T
(i),g+U⋆
(i),lV⋆T
(i),l+E(i)≤σmax+σmax= 2σmax
where we used the conditionE(i)≤E(i)
F≤σminθ1.51
6√
2σmin
σmax≤σmax.
Then we prove the first inequality of Claim 2. Notice that,
1
NNX
i=1PˆU(i),l≤1
NNX
i=1PU⋆(i),l+1
NNX
i=1PˆU(i),l−PU⋆(i),l
≤1−θ+1
NNX
i=1PˆU(i),l−PU⋆(i),l
F
From (14), we know thatPN
i=1PU⋆(i),l−PˆU(i),l2
F≤2PN
i=1∥F⋆(i)∥2
F
θσ4
min. Therefore,
1
NNX
i=1PˆU(i),l−PU⋆(i),l
F≤1√
NvuutNX
i=1PˆU(i),l−PU⋆(i),l2
F
≤vuut2PN
i=1F⋆(i)2
F
θσ4
minN≤θ/2
where the last inequality comes from the fact thatE(i)
F≤σminθ1.51
6√
2σmin
σmaxthusF(i)
F≤
2σmaxE(i)
F+E(i)2
F≤3σmaxE(i)
F≤σ2
minθ1.51
2√
2.
Next we will show a lower bound on σmin
ˆUgˆVT
(i),g+ˆU(i),lˆVT
(i),l
. A fact is that
σmin
ˆUgˆVT
(i),g+ˆU(i),lˆVT
(i),l
≥σmin
U⋆gV⋆T
(i),g+U⋆
(i),lV⋆T
(i),l
−ˆUgˆVT
(i),g−U⋆gV⋆T
(i),g−ˆU(i),lˆVT
(i),l−U⋆
(i),lV⋆T
(i),l
We know from (15) that
ˆUgˆVT
(i),g−U⋆gV⋆T
(i),g
F+ˆU(i),lˆVT
(i),l−U⋆
(i),lV⋆T
(i),l
F
≤PˆUg−PU⋆g
Fσmax+PˆU(i),l−PU⋆(i),l
Fσmax+ 2E⋆
(i)
F
Therefore, by (14), the above is bounded by
σmax√
2rPˆUg−PU⋆g2
F+PˆU(i),l−PU⋆(i),l2
F+ 2E⋆
(i)
F
26≤σmax√
2vuut2PN
i=1F⋆(i)2
F
θσ4
min+ 2E⋆
(i)
F
≤E⋆
(i)
F 
2 +6σ2
max√
θσ2
min!
≤σmin2−√
3
2
where we applied the conditionE⋆(i)
F≤σmin2−√
3
2
2 +6√
θ
σmax
σmin2−1
in the last
inequality. Thus
σmin
ˆUgˆVT
(i),g+ˆU(i),lˆVT
(i),l
≥σmin√
3
2
Also, since R(i)’s correspond to the residuals of the optimal solutions, we have,
R(i)≤R(i)
F≤vuutNX
i=1R(i)2
F≤vuutNX
i=1E⋆(i)2
F≤σmin/2 (16)
where we applied the conditionE⋆(i)
F≤σminθ1
64√
Nσmin
σmaxin the last inequality.
As a result, we have σ2
min
ˆUgˆVT
(i),g+ˆU(i),lˆVT
(i),l
−R(i)2≥ˆσ2
gap.
Finally, we will prove the third condition in Claim 2. We can do so by using the conditionE⋆(i)
F≤σminθ1
64√
Nσmin
σmaxin(16), and considering the fact that ˆσ2
gap=σ2
min/2,ˆθ=θ/2,
and ˆσmax= 2σmax.
This completes our proof. □
In the following, we will always assume Claims 1 and 2 are true and prove our results
under the assumptions of Lemma 5.
The two claims are intuitively understandable. Claim 1 upper bounds the singular values
ofM(i)’s. This is the standard requirement in matrix factorization. Claim 2 implies ˆU(i),l’s
should be ˆθ-misaligned for some nonzero ˆθ. Also, Claim 2 restricts the norm of R(i)’s to be
smaller than a factor of the smallest nonzero singular value of ˆUgˆVT
(i),g+ˆU(i),lˆVT
(i),l. This
requirement is satisfied when the norm of the noise in input M(i)is not too large, i.e., M(i)
is not far from the linear combination of two low-rank matrices.
As introduced in the main paper, we use B(ζ1, ζ2)to denote the set of solutions with
bounded norms:
B(ζ1, ζ2) ={Ug,{U(i),l},{V(i),g},{V(i),l}∥Ug∥,U(i),l≤ζ1,V(i),g,V(i),l≤ζ2}
(17)
The following lemma gives an upper bound on the Lipschitz constant when all iterates
are bounded.
Lemma 6 (Lipschitz continuity) In region B(B1, B2)as defined in (17),giand ˜fiare
Lipschitz continuous:
∇gi(U′
g,U′
(i),l)− ∇gi(Ug,U(i),l)
F
≤LgrU′
g−Ug2
F+U′
(i),l−U(i),l2
F(18)
27and
∇˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇˜fi(Ug,V(i),g,U(i),l,V(i),l)
F
≤LrU′
g−Ug2
F+V′
(i),g−V(i),g2
F+U′
(i),l−U(i),l2
F+V′
(i),l−V(i),l2
F(19)
for{U′
g,{V′
(i),g},{U′
(i),l},{V′
(i),l}},{Ug,{V(i),g},{U(i),l},{V(i),l}} ∈ B (B1, B2), where Lg
andLare constants dependent on B1,B2,ˆσmax, and β,
Lg= 2β(3B2
1+ 1)
and,
L=q
(ˆσmax+ 3B1B2)2+B2
1B2
2+ 2B4
1+B4
2+ (B2
2+ 2β(3B2
1+ 1))2
Proof. We will firstly show the Lipschitz continuity of gi. We know that
∇Uggi(U′
g,U′
(i),l)− ∇Uggi(Ug,U(i),l)
= 2βU′
g
(U′
g)TU′
g−I
−2βUg 
UT
gUg−I
Therefore by some applications of triangle inequalities, we have,
∇Uggi(U′
g,U′
(i),l)− ∇Uggi(Ug,U(i),l)
F≤U′
g−Ug2β(3B2
1+ 1)
This proves inequality (18). The Lipschitz continuity of ˜fican be proved similarly. We will
calculate the gradient of ˜fiover each variable, and bound the norm of the difference of the
gradients.
∇Ug˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇Ug˜fi(Ug,V(i),g,U(i),l,V(i),l)
=
U′
g(V′
(i),g)T+U′
(i),l(V′
(i),l)T−M(i)
V′
(i),g+ 2βU′
g((U′
g)TU′
g−I)
− 
Ug(V(i),g)T+U(i),l(V(i),l)T−M(i)
V(i),g−2βUg(UT
gUg−I)
Also by triangle inequalities, when ( U′
g,V′
(i),g,U′
(i),l,V′
(i),l) and ( Ug,V(i),g,U(i),l,V(i),l) are
inB(B1, B2), we have:
∇Ug˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇Ug˜fi(Ug,V(i),g,U(i),l,V(i),l)
F
≤(B2
2+ 2β(3B2
1+ 1))U′
g−Ug
F+ (ˆσmax+ 3B1B2)V′
(i),g−V(i),g
F
+B2
2U′
(i),l−U(i),l
F+B1B2V′
(i),l−V(i),l
F
Then on the derivative over V(i),g,
∇V(i),g˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇V(i),g˜fi(Ug,V(i),g,U(i),l,V(i),l)
=
U′
g(V′
(i),g)T+U′
(i),l(V′
(i),l)T−M(i)T
U′
g− 
Ug(V(i),g)T+U(i),l(V(i),l)T−M(i)TUg
28Thus by similar calculations, we have,
∇V(i),g˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇V(i),g˜fi(Ug,V(i),g,U(i),l,V(i),l)
F
≤(ˆσmax+ 3B1B2)U′
g−Ug
F+B2
1V′
(i),g−V(i),g
F
+B1B2U′
(i),l−U(i),l
F+B2
1V′
(i),l−V(i),l
F
And,
∇U(i),l˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇U(i),l˜fi(Ug,V(i),g,U(i),l,V(i),l)
F
≤B2
2U′
g−Ug
F+B1B2V′
(i),g−V(i),g
F
+ (B2
2+ 2β(3B2
1+ 1))U′
(i),l−U(i),l
F+ (ˆσmax+ 3B1B2)V′
(i),l−V(i),l
F
Also,
∇V(i),l˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇V(i),l˜fi(Ug,V(i),g,U(i),l,V(i),l)
F
≤B1B2U′
g−Ug
F+B2
1V′
(i),g−V(i),g
F
+ (ˆσmax+ 3B1B2)U′
(i),l−U(i),l
F+B2
1V′
(i),l−V(i),l
F
Combining the 4 inequalities, we have:
∇˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇˜fi(Ug,V(i),g,U(i),l,V(i),l)2
F
=∇Ug˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇Ug˜fi(Ug,V(i),g,U(i),l,V(i),l)2
F
+∇V(i),g˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇V(i),g˜fi(Ug,V(i),g,U(i),l,V(i),l)2
F
+∇U(i),l˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇U(i),l˜fi(Ug,V(i),g,U(i),l,V(i),l)2
F
+∇V(i),l˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇V(i),l˜fi(Ug,V(i),g,U(i),l,V(i),l)2
F
≤L2U′
g−Ug2
F+V′
(i),g−V(i),g2
F+U′
(i),l−U(i),l2
F+V′
(i),l−V(i),l2
F
where Lis a constant defined as,
L=q
(ˆσmax+ 3B1B2)2+B2
1B2
2+ 2B4
1+B4
2+ (B2
2+ 2β(3B2
1+ 1))2
□
The Lipschitz continuity allows us to prove the following sufficient descent lemma.
29Lemma 7 (Sufficient descent inequality) For{Ug,τ,{V(i),g,τ},{U(i),l,τ},{V(i),l,τ}} ∈
B(B1, B2), ifUT
g,τUg,τ−I≤3
4andUT
(i),l,τU(i),l,τ−I
F≤3
4for every i, and the stepsize
ηsmall enough,
η≤minn1
10
2B1B2(2B1B2+ ˆσmax) + 2βB2
1(B2
1+ 1) +
B2(2B1B2+ ˆσmax)
+ 2βB1(B2
1+ 1)2
,1
2 L
2+ 272 βB2
1+ 400 LgB2
1,1o
where LandLgare defined in Lemma 6, then the iterates of algorithm 1 satisfy the following
inequality,
˜f(Ug,τ+1,{V(i),g,τ+1,U(i),l,τ+1,V(i),l,τ+1})−˜f(Ug,τ,{V(i),g,τ,U(i),l,τ,V(i),l,τ})
≤ −η
2 1√
N∇Ug˜f2
F+NX
i=1∇V(i),g˜fi2
F+∇U(i),l˜fi2
F+∇V(i),l˜fi2
F!
Proof. We first look at the correction step. Notice that the function value fibefore and
after correction is the same:
fi(Ug,τ+1,V(i),g,τ+1,U(i),l,τ+1,V(i),l,τ+1)
=M(i)−Ug,τ+1VT
(i),g,τ+1−U(i),l,τ+1VT
(i),l,τ+12
F
=||M(i)−Ug,τ+1
V(i),g,τ+1
2+V(i),l,τ+1UT
(i),l,τ+1
2Ug,τ+1 
UT
g,τ+1Ug,τ+1−1T
−
U(i),l,τ+1
2−Ug,τ+1 
UT
g,τ+1Ug,τ+1−1UT
g,τ+1U(i),l,τ+1
2
VT
(i),l,τ+1||2
F
=M(i),τ+1−Ug,τ+1VT
(i),g,τ+1
2−U(i),l,τ+1
2VT
(i),l,τ+12
F
=fi(Ug,τ+1,V(i),g,τ+1
2,U(i),l,τ+1
2,V(i),l,τ+1)
Forgi, we have:
gi(Ug,τ+1,U(i),l,τ+1)−gi(Ug,τ+1,U(i),l,τ+1
2)
≤D
∇U(i),lgi(Ug,τ+1,U(i),l,τ+1
2),Ug,τ+1 
UT
g,τ+1Ug,τ+1−1UT
g,τ+1U(i),l,τ+1
2E
+Lg
2Ug,τ+1 
UT
g,τ+1Ug,τ+1−1UT
g,τ+1U(i),l,τ+1
22
F
where Lgis the Lipschitz continuity constant of gi. For the first term, we have,
D
∇U(i),lgi(Ug,τ+1,U(i),l,τ+1
2),Ug,τ+1 
UT
g,τ+1Ug,τ+1−1UT
g,τ+1U(i),l,τ+1
2E
= Tr
2βUT
(i),l,τ+1
2(UT
(i),l,τ+1
2U(i),l,τ+1
2−I)UT
(i),l,τ+1
2Ug,τ+1 
UT
g,τ+1Ug,τ+1−1UT
g,τ+1U(i),l,τ+1
2
30SinceUT
(i),l,τU(i),l,τ−I
F≤3
4, we know,
UT
(i),l,τ+1
2U(i),l,τ+1
2−I
F
=UT
(i),l,τ+1
2U(i),l,τ+1
2−I−η∇U(i),l˜fT
iU(i),l−ηUT
(i),l∇U(i),l˜fi+η2∇U(i),l˜fT
i∇U(i),l˜fi
F
≤UT
(i),l,τU(i),l,τ−I+η∇U(i),l˜fiB1+∇U(i),l˜fiB1+η∇U(i),l˜fi2
≤17
20
where in the last inequality, we applied the condition thatUT
(i),l,τU(i),l,τ−I≤3
4andηis
not too large,
η≤1
10
2B1B2(2B1B2+ ˆσmax) + 2βB2
1(B2
1+ 1) + 
B2(2B1B2+ ˆσmax) + 2βB1(B2
1+ 1)2
As,
UT
g,τ+1Ug,τ+1−UT
g,τUg,τ
=ηUT
g,τ∇Ug˜f
N+ (∇Ug˜f
N)TUg,τ+ (∇Ug˜f
N)T∇Ug˜f
N
≤η
2B1B2(2B1B2+ ˆσmax) + 2βB2
1(B2
1+ 1) + η 
B2(2B1B2+ ˆσmax) + 2βB1(B2
1+ 1)2
Since ηis sufficiently small
η≤3
20
2B1B2(2B1B2+ ˆσmax) + 2βB2
1(B2
1+ 1) + 
B2(2B1B2+ ˆσmax) + 2βB1(B2
1+ 1)2
we know thatUT
g,τ+1Ug,τ+1−UT
g,τUg,τ≤3
20. Then, by Lemma 22 we have,
 
UT
g,τ+1Ug,τ+1−1
≤ 
UT
g,τUg,τ−1+ 
UT
g,τUg,τ−12UT
g,τ+1Ug,τ+1−UT
g,τUg,τ
1− 
UTg,τUg,τ−1UT
g,τ+1Ug,τ+1−UTg,τUg,τ
Lemma 19 shows that whenUT
g,τUg,τ−I
F≤3
4, we have 
UT
g,τUg,τ−1≤1 + 3 = 4.
Combining these inequalities, we have 
UT
g,τ+1Ug,τ+1−1≤10.
31Finally, we can look at
UT
g,τ+1U(i),l,τ+1
2
F
=UT
g,τU(i),l,τ−η(∇Ug˜f
N)TU(i),l,τ−ηUT
g,τ∇U(i),l˜fi+η2 
∇Ug˜f
N!T
∇U(i),l˜fi
F
≤η(∇Ug˜f
N)TU(i),l,τ
F+ηUT
g,τ∇U(i),l˜fi
F+η2 
∇Ug˜f
N!T
∇U(i),l˜fi
F
≤η2B1∇Ug˜f
N
F+η2B1∇U(i),l˜fi
F
where we bound the second order terms by first order terms considering the fact that
η∇Ug˜f
N
F,η∇U(i),l˜fi
F≤1.
Combining the three, we have,
D
∇U(i),lgi(Ug,τ+1,U(i),l,τ+1
2),Ug,τ+1 
UT
g,τ+1Ug,τ+1−1UT
g,τ+1U(i),l,τ+1
2E
= Tr
2βUT
(i),l,τ+1
2(UT
(i),l,τ+1
2U(i),l,τ+1
2−I)UT
(i),l,τ+1
2Ug,τ+1 
UT
g,τ+1Ug,τ+1−1UT
g,τ+1U(i),l,τ+1
2
≤2βUT
(i),l,τ+1
2(UT
(i),l,τ+1
2U(i),l,τ+1
2−I)UT
(i),l,τ+1
2Ug,τ+1 
UT
g,τ+1Ug,τ+1−1
F
×UT
g,τ+1U(i),l,τ+1
2
F
≤2βU(i),l,τ+1
2UT
(i),l,τ+1
2U(i),l,τ+1
2−I
F 
UT
g,τ+1Ug,τ+1−1
FUT
g,τ+1U(i),l,τ+1
22
F
≤η2
∇Ug˜f
N2
F+∇U(i),l˜fi2
F
272βB3
1
Similarly,
Lg
2Ug,τ+1 
UT
g,τ+1Ug,τ+1−1UT
g,τ+1U(i),l,τ+1
22
F
≤Lg
2∥Ug,τ+1∥2 
UT
g,τ+1Ug,τ+1−12UT
g,τ+1U(i),l,τ+1
22
F
≤η2
∇Ug˜f
N2
F+∇U(i),l˜fi2
F
400LgB6
1
Therefore,
gi(Ug,τ+1,U(i),l,τ+1)−gi(Ug,τ+1,U(i),l,τ+1
2)
≤η2
∇Ug˜f
N2
F+∇U(i),l˜fi2
F
 
272βB2
1+ 400 LgB6
1
32Also, we know
˜fi(Ug,τ+1,V(i),g,τ+1
2,U(i),l,τ+1
2,V(i),l,τ+1)−˜fi(Ug,τ,V(i),g,τ,U(i),l,τ,V(i),l,τ)
≤D
∇Ug˜fi,Ug,τ+1−Ug,τE
+D
∇V(i),g˜fi,V(i),g,τ+1
2−V(i),g,τE
+D
∇U(i),l˜fi,U(i),l,τ+1
2−U(i),l,τE
+D
∇V(i),l˜fi,V(i),l,τ+1−V(i),l,τE
+L
2
∥Ug,τ+1−Ug,τ∥2
F+V(i),g,τ+1
2−V(i),g,τ2
F+U(i),l,τ+1
2−U(i),l,τ2
F
+V(i),l,τ+1−V(i),l,τ2
F
≤ −η *
∇Ug˜fi,∇Ug˜f
N+
+∇U(i),l˜fi2
F+∇V(i),g˜fi2
F+∇V(i),l˜fi2
F!
+η2L
2
∇Ug˜f
N2
F+∇U(i),l˜fi2
F+∇V(i),g˜fi2
F+∇V(i),l˜fi2
F

Therefore,
˜fi(Ug,τ+1,V(i),g,τ+1,U(i),l,τ+1,V(i),l,τ+1)−˜fi(Ug,τ,V(i),g,τ,U(i),l,τ,V(i),l,τ)
=gi(Ug,τ+1,U(i),l,τ+1)−gi(Ug,τ+1,U(i),l,τ+1
2)
+˜fi(Ug,τ+1,V(i),g,τ+1
2,U(i),l,τ+1
2,V(i),l,τ+1)−˜fi(Ug,τ,V(i),g,τ,U(i),l,τ,V(i),l,τ)
≤ −η *
∇Ug˜fi,∇Ug˜f
N+
+∇U(i),l˜fi2
F+∇V(i),g˜fi2
F+∇V(i),l˜fi2
F!
+η2L
2+ 272 βB2
1+ 400 LgB6
1
∇Ug˜f
N2
F+∇U(i),l˜fi2
F+∇V(i),g˜fi2
F+∇V(i),l˜fi2
F

Summing both side for ifrom 1 to N, we have:
˜f(Ug,τ+1,{V(i),g,τ+1,U(i),l,τ+1,V(i),l,τ+1})−˜f(Ug,τ,{V(i),g,τ,U(i),l,τ,V(i),l,τ})
=NX
i=1˜fi(Ug,τ+1,V(i),g,τ+1,U(i),l,τ+1,V(i),l,τ+1)−˜fi(Ug,τ,V(i),g,τ,U(i),l,τ,V(i),l,τ)
≤ −η 1√
N∇Ug˜f2
F+NX
i=1∇V(i),g˜fi2
F+∇U(i),l˜fi2
F+∇V(i),l˜fi2
F!
+η2L
2+ 272 βB2
1+ 400 LgB6
11√
N∇Ug˜f2
F+NX
i=1∇V(i),g˜fi2
F
+∇U(i),l˜fi2
F+∇V(i),l˜fi2
F
33Therefore, when η≤1
L
2+272 βB2
1+400 LgB6
1, we have:
˜f(Ug,τ+1,{V(i),g,τ+1,U(i),l,τ+1,V(i),l,τ+1})−˜f(Ug,τ,{V(i),g,τ,U(i),l,τ,V(i),l,τ})
≤ −η
2 1√
N∇Ug˜f2
F+NX
i=1∇V(i),g˜fi2
F+∇U(i),l˜fi2
F+∇V(i),l˜fi2
F!
This completes the proof. □
The above analysis suggests that Algorithm 1 will converge to points where the gradients
vanish. In other words, Algorithm 1 converges into stationary points. In the rest of this
section, we will analyze the local geometry around the optimal solutions to (4) and show
that such geometric properties essentially allow Algorithm 1 to converge into the optimal
solutions.
To do so, we will first find one set of optimal solutions that is close to the current iterate.
In particular, given an iterate {Ug,τ,V(i),g,τ,U(i),l,τ,V(i),l,τ}, define:
eUg,τ=PˆUgUg,τ
UT
g,τPˆUgUg,τ−1
2(20a)
eU(i),l,τ=PˆU(i),lU(i),l,τ
UT
(i),l,τPˆU(i),lU(i),l,τ−1
2(20b)
eV(i),g,τ=MT
(i)eU(i),g,τ (20c)
eV(i),l,τ=MT
(i)eU(i),l,τ (20d)
Indeed, the defined solutions are optimal since eUT
g,τeUg,τ=I,eUT
(i),l,τeU(i),l,τ=I, and
eUg,τeVT
(i),g,τ+eU(i),l,τeVT
(i),l,τ=ˆUgˆVT
(i),g+ˆU(i),lˆVT
(i),l. Let the difference between iterates
and these optimal solutions be denoted as


∆Ug,τ=Ug,τ−eUg,τ
∆V(i),g,τ=V(i),g,τ−eV(i),g,τ
∆U(i),l,τ=U(i),l,τ−eU(i),l,τ
∆V(i),l,τ=V(i),l,τ−eV(i),l,τ(21)
Now we introduce the KKT conditions to (4). The KKT condition relies on the regularity
condition that M(i)’s have rank at least r1+r2. This assumption is easily satisfied ifE(i)
is smaller than σmin.
Lemma 8 (KKT conditions for square error) Suppose that {ˆUg,ˆU(i),l,ˆV(i),g,ˆV(i),l}
is the optimal solution to problem (4) in the main paper with square error loss ℓse, and M(i)
has rank at least r1+r2. We have
NX
i=1
ˆUgˆVT
(i),g+ˆU(i),lˆVT
(i),l−M(i)
ˆV(i),g= 0 (22a)

ˆUgˆVT
(i),g+ˆU(i),lˆVT
(i),l−M(i)
ˆV(i),l= 0 (22b)
34
ˆUgˆVT
(i),g+ˆU(i),lˆVT
(i),l−M(i)TˆU(i),l= 0 (22c)

ˆUgˆVT
(i),g+ˆU(i),lˆVT
(i),l−M(i)TˆUg= 0 (22d)
ˆUT
(i),lˆU(i),l=I,ˆUT
gˆUg=I,ˆUT
(i),lˆUg= 0. (22e)
Proof. The proof is presented in two parts.
LICQ of (4). We will first show the linear independence constraint qualification (LICQ) of
the optimal ˆUg,{ˆV(i),g,ˆU(i),l,ˆV(i),l}.
We begin by proving ˆUghas full column rank. Suppose otherwise, ˆUghas rank r′
1< r1.
Since M(i)has rank at least r1+r2, the residual M(i)−ˆUgˆVT
(i),g−ˆU(i),lˆVT
(i),lhas rank at
least 1. Therefore we can find ˆU′
gsuch that ˆU′
gTˆU′
g=Iandfi(ˆU′
g,ˆV(i),g,ˆU(i),l,ˆV(i),l)<
fi(ˆUg,ˆV(i),g,ˆU(i),l,ˆV(i),l). This contradicts the fact that ˆUgis optimal.
Next we will establish the LICQ of constraints. We define hijkas the inner product
between the j-th column of Ugand the k-th column of U(i),l,hijk(x) = [Ug]T
:,j[U(i),l]:,k.
The constraints in (4) can be rewritten as hijk(ˆx) = 0 ,∀i∈[r1],∀j∈[r2],∀k∈[N]. LICQ
requires ∇hijk(ˆx) to be linearly independent for all ijk(Bertsekas, 1997, Proposition 3.1.1).
Suppose we can find constants ψijksuch thatPN
i=1Pr1
j=1Pr2
k=1ψijk∇hijk(ˆx) = 0. We
consider the partial derivative of hijkover the k′-th column of U(i′),l. It is easy to derive,
∂
∂[U(i′),l]:,k′hijk(ˆx) =δii′δkk′[ˆUg]:,j
where δii′is the Kronecker delta function. Then the constants ψijkshould satisfy,
r2X
j=1ψi′jk′[ˆUg]:,j= 0
As the columns of ˆUgare linearly independent, ψi′jk′= 0 for each j. This holds for any i′
andk′. Therefore ψijk= 0 for all i, j, k . This implies ∇hijk’s are linearly independent.
Proof of 8. The Lagrangian of the optimization problem (4) can be written as
L=1
2NX
i=1UgVT
(i),g+U(i),lVT
(i),l−M(i)2
F+β
2UT
gUg−I2
F+β
2UT
(i),lU(i),l−I2
F
+ Tr 
Λ6,(i)UT
gU(i),l
(23)
where Λ6,(i)is the dual variable for the constraint UT
gU(i),l= 0.
Under the LICQ, we know that the optimality of ˆUg,{ˆV(i),g,ˆU(i),l,ˆV(i),l}implies the
KKT condition. Setting the gradient of Lwith respect to V(i),gandV(i),lto zero, we
can prove (22d) and(22c) . Considering the constraint ˆUT
gˆU(i),l= 0, we can solve them as
ˆV(i),g=MT
(i)ˆUg
ˆUT
gˆUg−1
and ˆV(i),l=MT
(i)ˆU(i),l
ˆUT
(i),lˆU(i),l−1
. Then we examine the
gradient of Lwith respect to U(i),l:
∂
∂U(i),lL=
UgVT
(i),g+U(i),lVT
(i),l−M(i)
ˆV(i),l+ 2βU(i),l
UT
(i),lU(i),l−I
+UgΛT
(6),i
35Substituting ˆV(i),g=MT
(i)ˆUg
ˆUT
gˆUg−1
and ˆV(i),l=MT
(i)ˆU(i),l
ˆUT
(i),lˆU(i),l−1
in the
above gradient and setting it to zero, we have

ˆUg
ˆUT
gˆUg−1ˆUT
g+ˆU(i),l
ˆUT
(i),lˆU(i),l−1ˆUT
(i),l−I
M(i)ˆV(i),l
+ 2βˆU(i),l
ˆUT
(i),lˆU(i),l−I
+ˆUgΛT
(6),i= 0
Left multiplying both sides by ˆUT
g, we have Λ6,(i)= 0. Left multiplying
both sides by ˆUT
(i),l, we have ˆUT
(i),lˆU(i),l−I= 0. Therefore we also have
ˆUg
ˆUT
gˆUg−1ˆUT
g+ˆU(i),l
ˆUT
(i),lˆU(i),l−1ˆUT
(i),l−I
M(i)V(i),l= 0. This proves equa-
tion (22b). Now, setting the derivative of Lwith respect to Ugto zero, we have
∂
∂UgL=NX
i=1
ˆUgˆVT
(i),g+ˆU(i),lˆVT
(i),l−M(i)
ˆV(i),g+ 2NβˆUg
ˆUT
gˆUg−I
= 0
Left multiplying both sides by ˆUT
g, we have ˆUT
gˆUg−I= 0. We have thus proven (22a) .
This completes the proof for (22).
□
We note that the KKT conditions provide a set of conditions that must be satisfied
forallstationary points of (4). Since eUg,τ,eV(i),g,τ,eU(i),l,τ, and eV(i),l,τintroduced in
(20a)(20c)(20b)(20d) constitute oneset of optimal solutions, and R(i)=M(i)−U⋆gV⋆T
(i),g−
U⋆(i),lV⋆T
(i),l, we can rewrite the KKT conditions of the optimal solutions from Lemma 8 as,


NX
i=1R(i)eV(i),g= 0
R(i)eV(i),l= 0
RT
(i)eU(i),l= 0,RT
(i)eUg= 0
eUT
(i),leU(i),l=I,eUT
geUg=I,eUT
(i),leUg= 0(24)
From KKT conditions, it is also straightforward to verify that,
PˆUgNX
j=1R(j)=PˆU(i),lR(i)= 0
We will use these KKT conditions when analyzing the convergence of Algorithm 1.
We begin by analyzing the subspace spanned by UgandU(i),l’s. The following lemma
shows that the difference between the subspace spanned by the columns of UgandU(i),l
and by the optimal solution cannot be too large.
Lemma 9 For any set of optimal solutions to (4), ˆUg,ˆV(i),g,ˆU(i),l,ˆV(i),l, andR(i)=M(i)−
ˆUgˆVT
(i),g−ˆU(i),lˆVT
(i),l, if there exists ˆσ2
gap,ˆθ >0, such that (i) σ2
min
ˆUgˆVT
(i),g+ˆU(i),lˆVT
(i),l
−
36R(i)2≥ˆσ2
gap, (ii)R(i)≤ˆθˆσ2
gap
8ˆσmaxfor each i, and (iii) λmax
1
NPN
i=1PˆU(i),l
≤1−ˆθ,
then we have,
NX
i=1
I−PUg,τ−PU(i),l,τ
M(i)2
F−NX
i=1R(i)2
F
≥ˆθˆσ2
gap
8PUg,τ−PˆUg2
F+PU(i),l,τ−PˆU(i),l2
F(25)
Proof. We define M(i),g=ˆUgˆVT
(i),gandM(i),l=ˆU(i),lˆVT
(i),l, then M(i)=M(i),g+M(i),l+
R(i). We have,

I−PUg,τ−PU(i),l,τ
M(i)2
F
= Tr
I−PUg,τ−PU(i),l,τ
M(i)MT
(i)
= Tr
I−PUg,τ−PU(i),l,τ 
M(i),g+M(i),l 
M(i),g+M(i),lT
+ Tr
I−PUg,τ−PU(i),l,τ
R(i)RT
(i)
+ Tr
I−PUg,τ−PU(i),l,τ
M(i),gRT
(i)+R(i)MT
(i),g
where we applied the second equation from (24) that R(i)MT
(i),l=R(i)ˆV(i),lˆUT
(i),l= 0.
Summing index ifrom 1 to N, and considering the KKT conditionPN
i=1M(i),gRT
(i)= 0,
we have,
NX
i=1
I−PUg,τ−PU(i),l,τ
M(i)2
F
=NX
i=1Tr
I−PUg,τ−PU(i),l,τ
M(i)MT
(i)
=NX
i=1Tr
I−PUg,τ−PU(i),l,τ 
M(i),g+M(i),l 
M(i),g+M(i),lT
+NX
i=1Tr
I−PUg,τ−PU(i),l,τ
R(i)RT
(i)
+NX
i=1Tr
−PU(i),l,τ
M(i),gRT
(i)+R(i)MT
(i),g
We use ˆσminto denote the smallest nonzero singular value of M(i),g+M(i),l, then
 
M(i),g+M(i),l 
M(i),g+M(i),lT⪰
PˆUg+PˆU(i),l
ˆσmin2. Hence,
Tr
I−PUg,τ−PU(i),l,τ 
M(i),g+M(i),l 
M(i),g+M(i),lT
≥Tr
I−PUg,τ−PU(i),l,τ
PˆUg+PˆU(i),l
ˆσmin2 
M(i),g+M(i),l
=
r1+r2−D
PUg,τ+PU(i),l,τ,PˆUg+PˆU(i),lE
ˆσmin2 
M(i),g+M(i),l
37Similarly, since R(i)RT
(i)⪯
I−PˆUg−PˆU(i),l
σ2
max 
R(i)
, we have,
Tr
I−PUg,τ−PU(i),l,τ
R(i)RT
(i)
=R(i)2
F−Tr
PUg,τ+PU(i),l,τ
R(i)RT
(i)
≥R(i)2
F−Tr
PUg,τ+PU(i),l,τ
I−PˆUg−PˆU(i),l
σ2
max 
R(i)
As a result,
NX
i=1
I−PUg,τ−PU(i),l,τ
M(i)2
F−R(i)2
F
≥NX
i=1Tr
PUg,τ+PU(i),l,τ
I−PˆUg−PˆU(i),l 
σ2
min 
M(i),g+M(i),l
−σ2
max 
R(i)
+NX
i=1Tr
−PU(i),l,τ
M(i),gRT
(i)+R(i)MT
(i),g
≥NX
i=1D
PUg,τ+PU(i),l,τ,I−PˆUg−PˆU(i),lE
ˆσ2
gap−NX
i=12PU(i),l,τM(i),g
FPU(i),l,τR(i)
F
≥NX
i=1
r1+r2−D
PUg,τ,PˆUgE
−D
PU(i),l,τ,PˆU(i),lEˆθˆσ2
gap
2
−NX
i=12PU(i),l,τ
I−PˆU(i),l2
Fˆσmax∥Ri∥
≥NX
i=1
r1+r2−D
PUg,τ,PˆUgE
−D
PU(i),l,τ,PˆU(i),lEˆθˆσ2
gap
4
where the second inequality comes the definition of ˆσ2
gapand Cauchy-Schwartz inequal-
ity, the third inequality comes from Lemma 2 in (Shi and Kontar, 2024) and Lemma
23. Then, since r1−D
PUg,τ,PˆUgE
=1
2PUg,τ−PˆUg2
Fandr2−D
PU(i),l,τ,PˆU(i),lE
=
1
2PU(i),l,τ−PˆU(i),l2
F, this completes the proof. □
The next lemma shows thatUT
g,τUg,τ−IandUT
(i),l,τU(i),l,τ−I’s are upper bounded
byϕτ.
Lemma 10 Under the same conditions as Lemma 9, we have
NX
i=1UT
g,τUg,τ−I2
F+UT
(i),l,τU(i),l,τ−I2
F
≤2ϕτ
β(26)
38Proof. We decompose ˜fas,
2˜f= 2 
ϕτ+1
2NX
i=1R(i)2
F!
=NX
i=1Ug,τVT
(i),g,τ+U(i),l,τV(i),l−M(i)2
F+βUT
g,τUg,τ−I2
F+UT
(i),l,τU(i),l,τ−I2
F
=NX
i=1
PUg,τ+PU(i),l,τ
Ug,τVT
(i),g,τ+U(i),l,τV(i),l−M(i)
−
I−PUg,τ−PU(i),l,τ
M(i)2
F
+βUT
g,τUg,τ−I2
F+UT
(i),l,τU(i),l,τ−I2
F
=NX
i=1Ug,τVT
(i),g,τ+U(i),l,τV(i),l−
PUg,τ+PU(i),l,τ
M(i)2
F
+
I−PUg,τ−PU(i),l,τ
M(i)2
F+βUT
g,τUg,τ−I2
F+UT
(i),l,τU(i),l,τ−I2
F
(27)
Considering Lemma 9, we know that
2ϕτ
≥NX
i=1ˆθˆσ2
gap
8PUg,τ−PˆUg2
F+PU(i),l,τ−PˆU(i),l2
F
+βUT
g,τUg,τ−I2
F
+βUT
(i),l,τU(i),l,τ−I2
F+Ug,τVT
(i),g,τ+U(i),l,τV(i),l−
PUg,τ+PU(i),l,τ
M(i)2
F
(28)
This completes the proof as all terms on the right hand side are nonnegative. □
Now we can prove that when the objective ˜fis close to the optimal value, the iterates
should also be close to the set of optimal solutions defined in (20a)(20c)(20b)(20d) . We will
first examine the norms of ∆ Ug,τand ∆ U(i),l,τin Lemma 11, then calculate the norms of
∆V(i),g,τand ∆ V(i),l,τin Lemma 12.
Lemma 11 Under the same conditions of Lemma 9, if we further have ϕτ≤
min{9β
128,9ˆθˆσ2
gap
1936}, we have the following,
N∥∆Ug,τ∥2
F+NX
i=1∆U(i),l,τ2
F≤C1ϕτ (29)
where
C1= 
64
9β+ 324
3B2
1+B121
ˆθˆσ2gap!
(30)
39and∆Ug,τand∆U(i),l,τare introduced in (21). Also,
∥Ug,τ∥,U(i),l,τ≤r
11
8,∀i∈ {1,···, N} (31)
Proof. We begin by calculating an upper bound of the norm of ∆ Ug,τ,
∥∆Ug,τ∥F
=Ug,τ−PˆUgUg,τ
UT
g,τPˆUgUg,τ−1
2
F
≤Ug,τ−PˆUgUg,τ
F+PˆUgUg,τ−PˆUgUg,τ
UT
g,τPˆUgUg,τ−1
2
F
≤ ∥Ug,τ∥PUg,τ−PˆUg
F+PˆUgUg,τI−
UT
g,τPˆUgUg,τ−1
2
F
Notice that
I−
UT
g,τPˆUgUg,τ−1
2
F
≤I−
I+ 
UT
g,τUg,τ−I
+UT
g,τ
PˆUg−PUg,τ
Ug,τ−1
2
F
Since ϕτ≤9β
128, we know thatPN
i=1(UT
g,τUg,τ−I2
F+UT
(i),l,τU(i),l,τ−I2
F)≤
9
64from Lemma 10. Therefore,UT
g,τUg,τ−I
F≤3
8. And by triangle inequal-
ity of Frobenius norm, ∥Ug,τ∥ ≤ ∥ Ug,τ∥F≤q
1 +3
8≤q
11
8. Similarly, ϕτ≤
9ˆθˆσ2
gap
1936and Lemma 9 imply thatPˆUg−PUg,τ
F≤3
11. As a result, we know 
UT
g,τUg,τ−I
+UT
g,τ
PˆUg−PUg,τ
Ug,τ
F≤3
4. Thus by Lemma 20, we have,
I−
UT
g,τPˆUgUg,τ−1
2
F
≤4
3 
UT
g,τUg,τ−I
+UT
g,τ
PˆUg−PUg,τ
Ug,τ
F
≤4
3UT
g,τUg,τ−I+B2
1PˆUg−PUg,τ
F
Therefore,
∥∆Ug,τ∥2
F
≤4
3B1UT
g,τUg,τ−I+4
3B2
1+B1PˆUg−PUg,τ
F2
≤32
9UT
g,τUg,τ−I2+ 24
3B2
1+B12PˆUg−PUg,τ2
F
40Similar upper bounds hold for ∆ U(i),l,τ. Summing them up, we have,
NX
i=1∥∆Ug,τ∥2
F+∆U(i),l,τ2
F
≤NX
i=132
9UT
g,τUg,τ−I2+UT
(i),l,τU(i),l,τ−I2
+
24
3B2
1+B12PˆUg−PUg,τ2
F+P⋆
(i)−PU(i),l,τ2
F
≤ 
64
9β+ 324
3B2
1+B121
ˆθˆσ2gap!
ϕτ
We applied Lemma 9, Lemma 10, and (28) in the last inequality. □
We continue to prove the upper bound of the norm of ∆ V(i),g,τand ∆ V(i),l,τintroduced
in (21).
Lemma 12 Under the same conditions of Lemma 11, we have the following,
N∥∆Ug,τ∥2
F+NX
i=1"
∆V(i),g,τ2
F+∆U(i),l,τ2
F+∆V(i),l,τ2
F#
≤C2ϕτ (32)
where
C2= 16 +704ˆσ2
max
β+ 352ˆ σ2
maxC1+C1 (33)
This lemma presents a full perturbation analysis of ˜f. It shows that if the function value is
close to optimal, all iterates must also be close to one set of the optimal solutions.
Proof.
We use the decomposition (27) to derive upper bounds on the norm of ∆ V’s.
By some algebra, we know that,

PUg,τ+PU(i),l,τ
M(i)−Ug,τVT
(i),g,τ−U(i),l,τV(i),l
=Ug,τ∆VT
(i),g,τ+U(i),l,τ∆V(i),l+Ug,τ 
UT
g,τUg,τ−1−I
eVT
(i),g,τ
+Ug,τ 
UT
g,τUg,τ−1∆Ug,τM(i)+U(i),l,τ
UT
(i),l,τU(i),l,τ−1
−I
eVT
(i),l,τ
+U(i),l,τ
UT
(i),l,τU(i),l,τ−1
∆U(i),l,τM(i)
We will bound each term above. By triangle inequality, we have,
Ug,τ 
UT
g,τUg,τ−1−I
eVT
(i),g,τ+Ug,τ 
UT
g,τUg,τ−1∆Ug,τM(i)
F
≤ ∥Ug,τ∥ 
UT
g,τUg,τ−1−I
FeVT
(i),g,τ+∥Ug,τ∥ 
UT
g,τUg,τ−1∥∆Ug,τ∥FM(i)
≤4r
11
8ˆσmaxUT
g,τUg,τ−I
F+ 4r
11
8ˆσmax∥∆Ug,τ∥F
41where we again used Lemma 19 to show that whenUT
(i),l,τU(i),l,τ−I
Fand
UT
g,τUg,τ−I
F≤3
4, we have 
UT
g,τUg,τ−1≤1 + 3 = 4.
A similar bound holds that,
U(i),l,τ
UT
(i),l,τU(i),l,τ−1
−I
eVT
(i),l,τ+U(i),l,τ
UT
(i),l,τU(i),l,τ−1
∆U(i),l,τM(i)
F
≤4r
11
8ˆσmaxUT
(i),l,τU(i),l,τ−I
F+ 4r
11
8ˆσmax∆U(i),l,τ
F
Then by Lemma 21, we have,

PUg,τ+PU(i),l,τ
M(i)−Ug,τVT
(i),g,τ−U(i),l,τV(i),l2
≥1
2Ug,τ∆VT
(i),g,τ+U(i),l,τ∆V(i),l2
F
−
4r
11
8ˆσmax(UT
g,τUg,τ−I
F+UT
(i),l,τU(i),l,τ−I
F)
+ 4r
11
8ˆσmax(∆U(i),l,τ
F+∆U(i),g,τ
F)2
≥1
2Ug,τ∆VT
(i),g,τ2
F+1
2U(i),l,τ∆V(i),l2
F
−44ˆσ2
max(UT
g,τUg,τ−I2
F+UT
(i),l,τU(i),l,τ−I2
F)−44ˆσ2
max(∆U(i),l,τ2
F+∆U(i),g,τ2
F)
≥1
8∆VT
(i),g,τ2
+1
8∆V(i),l2
F
−44ˆσ2
max(UT
g,τUg,τ−I2
F+UT
(i),l,τU(i),l,τ−I2
F)−44ˆσ2
max(∆U(i),l,τ2
F+∆U(i),g,τ2
F)
where we used the conditionUT
g,τUg,τ−I≤3
4andUT
(i),l,τU(i),l,τ−I≤3
4in the third
inequality.
Summing both sides for ifrom 1 to N, and considering Lemma 9, Lemma 11, and
inequality (28), we have,
NX
i=1∆V(i),g,τ2
F+∆V(i),l,τ2
F≤
16 +704ˆσ2
max
β+ 352ˆ σ2
maxC1
ϕτ
We can complete the proof by addingPN
i=1∥∆Ug,τ∥2
F+∆U(i),l,τ2
Fon both sides. □
Now we can look at the following lemma which shows the gradient is aligned with the
direction pointing from current iterate to one set of the optimal solution.
42Lemma 13 (Gradient points to an optimal solution) Under the same conditions as
Lemma 12, if additionally ϕτ≤1
2√
2 max{ˆσ2max,1}+4β2
C3
2, the following inequality would hold,
D
∇Ug˜f,∆Ug,τE
+NX
i=1"D
∇U(i),l˜f,∆U(i),l,τE
+D
∇V(i),g˜f,∆V(i),g,τE
+D
∇V(i),l˜f,∆V(i),lE#
≥ϕτ(34)
This lemma shows that the geometry of the problem is benign.
Proof. Similar to (Sun and Luo, 2016), we define two notations ai,τ,bi,τas,
ai,τ=eUg,τ∆VT
(i),g,τ+ ∆Ug,τeVT
(i),g,τ
+eU(i),l,τ∆VT
(i),l,τ+ ∆U(i),l,τeVT
(i),l,τ(35)
and
bi,τ= ∆Ug,τ∆VT
(i),g,τ+ ∆U(i),l,τ∆VT
(i),l,τ (36)
Then we can calculate the inner product between the derivatives of fiand the difference
between iterates and optimal values,

∇Ugfi,∆Ug,τ
+D
∇V(i),gfi,∆V(i),g,τE
+D
∇U(i),lfi,∆U(i),l,τE
+D
∇V(i),l,τfi,∆V(i),l,τE
=D
Ug,τVT
(i),g,τ+U(i),l,τVT
(i),l,τ−M(i), ai,τ+ 2bi,τE
=
ai,τ+bi,τ+R(i), ai,τ+ 2bi,τ
=∥ai,τ∥2
F+ 2∥bi,τ∥2
F+ 3⟨ai,τ, bi,τ⟩+
R(i), ai,τ
+ 2
R(i), bi,τ
As
2fi−R(i)2
F=Ug,τVT
(i),g,τ+U(i),l,τVT
(i),l,τ−M(i)2
F−R(i)2
F
=ai,τ+bi,τ+R(i)2
F−R(i)2
F
=∥ai,τ∥2
F+∥bi,τ∥2
F+ 2⟨ai,τ, bi,τ⟩+ 2
R(i), ai,τ
+ 2
R(i), bi,τ
We know that,

∇Ugfi,∆Ug,τ
+D
∇V(i),gfi,∆V(i),g,τE
+D
∇U(i),lfi,∆U(i),l,τE
+D
∇V(i),l,τfi,∆V(i),l,τE
= 2fi+∥bi,τ∥2
F+⟨ai,τ, bi,τ⟩+
R(i), ai,τ
−R(i)2
F
Similarly, we can calculate the inner product

∇Uggi,∆Ug,τ
= 2βTr
eUT
g,τ∆Ug,τeUT
g,τ∆Ug,τ+eUT
g,τ∆Ug,τ∆UT
g,τeUg,τ
+ 2βTr
3∆UT
g,τ∆Ug,τeUT
g,τ∆Ug,τ
+ 2βTr 
∆UT
g,τ∆Ug,τ∆UT
g,τ∆Ug,τ
43Since
UT
g,τUg,τ−I2
F
=eUT
g,τ∆Ug,τ+ ∆UT
g,τeUg,τ+ ∆UT
g,τ∆Ug,τ2
F
= 2eUT
g,τ∆Ug,τ2
F+ 2Tr
∆UT
g,τeUg,τ∆UT
g,τeUg,τ
+ 2Tr
eUT
g,τ∆Ug,τ∆UT
g,τ∆Ug,τ
+ 2Tr
∆UT
g,τeUg,τ∆UT
g,τ∆Ug,τ
+∆UT
g,τ∆Ug,τ2
F
We know that

∇Uggi,∆Ug,τ
=βUT
g,τUg,τ−I2
F+ 2βTr
eUT
g,τ∆Ug,τ∆UT
g,τ∆Ug,τ
+β∆UT
g,τ∆Ug,τ2
F
As a result,

∇Uggi,∆Ug,τ
+D
∇U(i),lgi,∆U(i),l,τE
= 2gi+ 2βTr
eUT
g,τ∆Ug,τ∆UT
g,τ∆Ug,τ
+ 2βTr
eUT
(i),l,τ∆U(i),l,τ∆UT
(i),l,τ∆U(i),l,τ
+β∥∆Ug,τ∥4
F+β∆U(i),l,τ4
F
≥2gi−2β∥∆Ug,τ∥3
F−2β∆U(i),l,τ3
F+β∥∆Ug,τ∥4
F+β∆U(i),l,τ4
F
Therefore, we can sum up the two inequalities and derive,
D
∇Ug˜fi,Ug,τ−eUg,τE
+D
∇V(i),g˜fi,V(i),g,τ−eV(i),g,τE
+D
∇U(i),l˜fi,U(i),l,τ−eU(i),l,τE
+D
∇V(i),l,τ˜fi,V(i),l,τ−eV(i),l,τE
≥2˜fi−R(i)2
F
+∥bi,τ∥2
F+⟨ai,τ, bi,τ⟩+
R(i), ai,τ
−2β∥∆Ug,τ∥3
F−2β∆U(i),l,τ3
F+β∥∆Ug,τ∥4
F+β∆U(i),l,τ4
F
We can sum up both sides for ifrom 1 to N, considering the KKT condition thatPN
i=1
R(i), ai,τ
= 0, and the definition of ϕτthatPN
i=12˜fi−R(i)2
F= 2ϕτ, we have,
NX
i=1hD
∇Ug˜fi,Ug,τ−eUg,τE
+D
∇V(i),g˜fi,V(i),g,τ−eV(i),g,τE
+D
∇U(i),l˜fi,U(i),l,τ−eU(i),l,τE
+D
∇V(i),l,τ˜fi,V(i),l,τ−eV(i),l,τEi
≥2ϕτ
+NX
i=1h
∥bi,τ∥2
F+⟨ai,τ, bi,τ⟩ −2β∥∆Ug,τ∥3
F−2β∆U(i),l,τ3
F+β∥∆Ug,τ∥4
F+β∆U(i),l,τ4
Fi
44≥2ϕτ+NX
i=1h
− ∥ai,τ∥F∥bi,τ∥F−2β∥∆Ug,τ∥3
F−2β∆U(i),l,τ3
Fi
(37)
For the higher order terms,
NX
i=1∥ai,τ∥F∥bi,τ∥F
≤vuutNX
i=1∥ai,τ∥2
FvuutNX
i=1∥bi,τ∥2
F
≤vuutNX
i=1
ˆσmax(∥∆Ug,τ∥F+∆U(i),l,τ
F) +∆V(i),g,τ
F+∆V(i),l,τ
F2
vuutNX
i=1
∥∆Ug,τ∥F∆V(i),g,τ
F+∆U(i),l,τ
F∆V(i),l,τ
F2
≤vuut2NX
i=1
ˆσ2max(∥∆Ug,τ∥2
F+∆U(i),l,τ2
F) +∆V(i),g,τ2
F+∆V(i),l,τ2
F
vuut2NX
i=1
∥∆Ug,τ∥2
F∆V(i),g,τ2
F+∆U(i),l,τ2
F∆V(i),l,τ2
F
≤p
2 max{ˆσ2max,1}vuutNX
i=1
∥∆Ug,τ∥2
F+∆U(i),l,τ2
F+∆V(i),g,τ2
F+∆V(i),l,τ2
F
√
2vuut NX
i=1∥∆Ug,τ∥2
F! NX
i=1∆V(i),g,τ2
F!
+ NX
i=1∆U(i),l,τ2
F! NX
i=1∆V(i),l,τ2
F!
≤2p
2 max{ˆσ2max,1}vuutNX
i=1
∥∆Ug,τ∥2
F+∆U(i),l,τ2
F+∆V(i),g,τ2
F+∆V(i),l,τ2
F3
≤2p
2 max{ˆσ2max,1}(ϕτC2)3/2
where we applied Lemma 12 in the last inequality.
And
2βNX
i=1
∥∆Ug,τ∥3
F+∆U(i),l,τ3
F
≤4βvuutNX
i=1
∥∆Ug,τ∥2
F+∆U(i),l,τ2
F+∆V(i),g,τ2
F+∆V(i),l,τ2
F3
≤4β(ϕτC2)3/2
45where we also applied Lemma 12 in the last inequality.
Thus when ϕτ≤1
2√
2 max{ˆσ2max,1}+4β2
C3
2, the higher order O(ϕ3/2
τ) terms in (37)are
dominated by the leading order term 2 ϕτ. As a result, we have,
NX
i=1hD
∇Ug˜fi,Ug,τ−eUg,τE
+D
∇V(i),g˜fi,V(i),g,τ−eV(i),g,τE
+D
∇U(i),l˜fi,U(i),l,τ−eU(i),l,τE
+D
∇V(i),l,τ˜fi,V(i),l,τ−eV(i),l,τEi
≥ϕτ
This completes the proof. □
Finally, we are able to prove the PL inequality,
Lemma 14 (PL inequality) Under the same conditions as Lemma 13, we have the fol-
lowing PL inequality,
1√
N∇Ug˜f2
F+NX
i=1∇V(i),g˜fi2
F+∇U(i),l˜fi2
F+∇V(i),l˜fi2
F≥1
C2ϕτ (38)
Proof. The proof is straightforward. We first combine Lemma 13 with Cauchy-Schwartz
inequality,
vuut1√
N∇Ug˜f2
F+NX
i=1∇V(i),g˜fi2
F+∇U(i),l˜fi2
F+∇V(i),l˜fi2
F
vuutN∥∆Ug,τ∥2
F+NX
i=1∆V(i),g,τ2
F+∆U(i),l,τ2
F+∇V(i),l˜fi2
F
≥1√
N∇Ug˜f
F√
N∆Ug,τ
F+NX
i=1h∇V(i),g˜fi
F∆V(i),g,τ
F
∇U(i),l˜fi
F∆U(i),l,τ
F+∇V(i),l˜fi
F∆V(i),l,τ
Fi
≥NX
i=1hD
∇Ug˜fi,Ug,τ−eUg,τE
+D
∇V(i),g˜fi,V(i),g,τ−eV(i),g,τE
+D
∇U(i),l˜fi,U(i),l,τ−eU(i),l,τE
+D
∇V(i),l,τ˜fi,V(i),l,τ−eV(i),l,τEi
≥ϕτ
Dividing both sides byr
N∥∆Ug,τ∥2
F+PN
i=1∆V(i),g,τ2
F+∆U(i),l,τ2
F+∇V(i),l˜fi2
F
and applying Lemma 12 will give us the desired result. □
Finally, we will combine the derived results and show the linear convergence of Algorithm
1. Theorem 15 is a formal statement of the convergence guarantee.
46Theorem 15 (Formal version of Theorem 2 in the main paper) Under the follow-
ing conditions,
1. The largest singular values of M(i)’s are upper bounded by ˆσmax.
2.There exists constants ˆθ,ˆσ2
gap>0such that1
NPN
i=1PˆU(i),l≤1−ˆθ,
σ2
min
ˆUgˆVT
(i),g+ˆU(i),lˆVT
(i),l
−R(i)2≥ˆσ2
gap, andR(i)≤ˆθˆσ2
gap
8ˆσmaxfor every i.
3.There exist constants B1 > 1and B2 > ˆσmax such that
(Ug,1,{U(i),l,1},{V(i),g,1},{V(i),l,1})∈ B (B1, B2)and the constant stepsize η
is upper bounded by η≤min{1
10
2B1B2(2B1B2+σmax) + 2 βB2
1(B2
1+ 1) +
 
B2(2B1B2+σmax) + 2βB1(B2
1+ 1)2
,1
2(L
2+272 βB2
1+400 LgB2
1),1}.
4.The iterates are initialized properly ϕ1≤min{9β
128,9ˆθˆσ2
gap
1936,1
2√
2 max{σ2max,1}+4β2
C3
2,
(B1−1)2
C1,(B2−σmax)2
C2}.
then all iterates reside in B(B1, B2)and the following holds,
ϕτ≤(1−ηB3)τ−1ϕ1 (39)
where B3is a constant
B3=1
2C2
Notice that by combining Theorem 15 with Lemma 5, we can immediately prove Theorem 2.
We shall emphasize that the conditions in Theorem 15 are more general than that in
Theorem 2, as we do not make assumptions on the input noise structure. Most works on
nonconvex matrix factorization (e.g., (Sun and Luo, 2016; Chen et al., 2020; Ye and Du,
2021)) assume the input data are exactly low-rank, i.e., R(i)= 0. Theorem 15 relaxes such
assumption by allowing R(i)to be small nonzero matrices.
Proof. We will prove that the following claims hold for every τ≥1 by induction.
1.∥Ug,τ∥,U(i),l,τ≤B1andV(i),g,τ,V(i),l,τ≤B2.
2.ϕτ≤(1−η
2C2)τϕ0
Base case At initialization τ= 1, Claim 2 is simply true. Claim 1 is true because we
assume at initialization, the norms of Ug,1,U(i),l,1’s,V(i),g,1’s,V(i),l,1’s are upper bounded.
Induction step Now we assume Claim 1 and 2 are true for τ= 1,···, tand prove that
they still hold for τ=t+ 1.
Since Claim 2 is true for τ=t, we know ϕt= (1−η
2C2)t−1ϕ1≤ϕ1. As ϕ1≤
1
(2√
2 max{ˆσ2max,1}+4β)2C3
3andϕ1≤min{9β
128,9ˆθˆσ2
gap
1936}, we know that the result of Lemma
14 holds.
Also from Lemma 10 and the fact that ϕτ≤9β
128, we knowUT
g,τUg,τ−I
F≤3
4andUT
(i),l,τU(i),l,τ−I
F≤3
4.
47Since Claim 1 is true for τ=t, and the stepsize is upper bounded by η≤
min{1
10
2B1B2(2B1B2+σmax) + 2βB2
1(B2
1+ 1) + 
B2(2B1B2+σmax) + 2βB1(B2
1+ 1)2
,
1
2(L
2+272 βB2
1+400 LgB2
1),1}, all the conditions of Lemma 7 are satisfied. Thus the result of
Lemma 7 holds for τ=t.
Therefore we can combine the results of Lemma 14 and Lemma 7 to derive,
ϕt+1≤ϕt−η
2 1√
N∇Ug˜f2
F+NX
i=1∇V(i),g˜fi2
F+∇U(i),l˜fi2
F+∇V(i),l˜fi2
F!
≤
1−η
21
C2
ϕt
≤(1−η
2C2)t+1ϕ0
. We thus prove Claim 2 for τ=t+ 1.
We then show that Claim 1 is true for t+ 1. As ϕt+1< ϕ 1≤(B1−1)2
C1, by Lemma 11, we
have,
∥∆Ug,t+1∥F≤p
C1ϕt+1≤p
C1ϕ0≤B1−1
Thus by triangle inequality,
∥Ug,t+1∥ ≤eUg,t+1+∥∆Ug,t+1∥ ≤B1
Similar bounds hold for U(i),l,t+1’s. Also, as ϕt+1< ϕ 1≤(B2−ˆσmax)2
C1, by Lemma 11, we
have,∆V(i),g,t+1
F≤p
C2ϕt+1≤p
C2ϕ0≤B2−ˆσmax
Also, by triangle inequality,
V(i),g,t+1≤eV(i),g,t+1+∆U(i),g,t+1≤B2
Similar bounds hold for V(i),l,t+1’s.
This completes the proof. □
Appendix D. Proof of Theorem 3
The procedures to prove Theorem 3 are close to the first stage of the proof of Theorem 2.
We first establish the KKT condition, then derive the sufficient decrease inequality for HMF.
The following lemma presents the KKT conditions to problem (4) in the main paper.
Lemma 16 (KKT conditions for general loss) Suppose that {ˆUg,ˆU(i),l,ˆV(i),g,ˆV(i),l}
is the optimal solution to problem (4) in the main paper with general loss metric ℓ,ˆUgand
ˆU(i),l’s are non-singular, and M(i)has rank at least r1+r2. We have
NX
i=1ℓ′
M(i),ˆUgˆVT
(i),g+ˆU(i),lˆVT
(i),l
ˆV(i),g= 0 (40a)
48ℓ′
M(i),ˆUgˆVT
(i),g+ˆU(i),lˆVT
(i),l
ˆV(i),l= 0 (40b)
ℓ′
M(i),ˆUgˆVT
(i),g+ˆU(i),lˆVT
(i),lTˆU(i),l= 0 (40c)
ℓ′
M(i),ˆUgˆVT
(i),g+ˆU(i),lˆVT
(i),lTˆUg= 0 (40d)
ˆUT
(i),lˆU(i),l=I,ˆUT
gˆUg=I,ˆUT
(i),lˆUg= 0. (40e)
Proof. The proof of the above lemma is very similar to the proof of Lemma 8. The
Lagrangian of the optimization problem (4) in the main paper can be written as
L=NX
i=1ℓ
M(i),UgVT
(i),g+U(i),lVT
(i),l
+β
2UT
gUg−I2
F+β
2UT
(i),lU(i),l−I2
F
+ Tr 
Λ7,(i)UT
gU(i),l(41)
where Λ7,(i)is the dual variable for the constraint UT
gU(i),l= 0.
Similar to Lemma 8, under the LICQ, we know that the optimality of
ˆUg,{ˆV(i),g,ˆU(i),l,ˆV(i),l}implies the KKT condition. Setting the gradient of Lwith re-
spect to V(i),gandV(i),lto zero, we can prove (40d) and(40c) . Then we examine the
gradient of Lwith respect to U(i),l:
∂
∂U(i),lL=ℓ′
M(i),UgVT
(i),g+U(i),lVT
(i),l
ˆV(i),l+ 2βU(i),l
UT
(i),lU(i),l−I
+UgΛT
(7),i
Left multiplying both sides by ˆUT
g, we have Λ7,(i)= 0. Left multiply-
ing both sides by ˆUT
(i),l, we have ˆUT
(i),lˆU(i),l−I= 0. Therefore we have
ℓ′
M(i),UgVT
(i),g+U(i),lVT
(i),l
ˆV(i),l= 0. This proves equation (40b).
Now, setting the derivative of Lwith respect to Ugto zero, we have
∂
∂UgL=NX
i=1ℓ′
M(i),ˆUgˆVT
(i),g+ˆU(i),lˆVT
(i),l
ˆV(i),g+ 2NβˆUg
ˆUT
gˆUg−I
= 0
Left multiplying both sides by ˆUT
g, we have ˆUT
gˆUg−I= 0. We have thus proven (40a) .
This completes the proof for (40). □
The following lemma gives an upper bound on the Lipschitz constant when all the norm
of iterates and gradients are bounded.
Lemma 17 (Lipschitz continuity for general loss metrics) In region
B(B1, B2)as defined in (17), if there exists a constant B4>0such thatℓ′(M(i),UgVT
(i),g+U(i),lVT
(i),l)≤B4, and loss metric ℓisLℓLipschitz continuous
in the region, then the objectives ˜fiwithβ= 0are Lipschitz continuous in the region,
∇˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇˜fi(Ug,V(i),g,U(i),l,V(i),l)
F
≤LgenrU′
g−Ug2
F+V′
(i),g−V(i),g2
F+U′
(i),l−U(i),l2
F+V′
(i),l−V(i),l2
F(42)
49for{U′
g,{V′
(i),g},{U′
(i),l},{V′
(i),l}},{Ug,{V(i),g},{U(i),l},{V(i),l}} ∈ B (B1, B2), where
Lgenis a constant dependent on B1,B2,Lℓ, and B4,
Lgen=q
8 
B2
2+B2
1
L2
ℓmax{B2
1, B2
2}+ 2B2
4
Proof. The proof is similar to the proof of Lemma 6. We will calculate the gradient of ˜fi
over each variable, and bound the norm of the difference of the gradients. For simplicity, we
use ∆ M′
(i)to denote ∆ M′
(i)=U′
g(V′
(i),g)T+U′
(i),l(V′
(i),l)T−UgVT
(i),g−U(i),lVT
(i),l
∇Ug˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇Ug˜fi(Ug,V(i),g,U(i),l,V(i),l)
=ℓ′
M(i),U′
g(V′
(i),g)T+U′
(i),l(V′
(i),l)T
V′
(i),g
−ℓ′ 
M(i),Ug(V(i),g)T+U(i),l(V(i),l)T
V(i),g
Also by triangle inequalities, when ( U′
g,V′
(i),g,U′
(i),l,V′
(i),l) and ( Ug,V(i),g,U(i),l,V(i),l) are
inB(B1, B2), we have:
∇Ug˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇Ug˜fi(Ug,V(i),g,U(i),l,V(i),l)
F
≤LℓB2∆M′
(i)
F+B4V′
(i),g−V(i),g
F
Then on the derivative over V(i),g,
∇V(i),g˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇V(i),g˜fi(Ug,V(i),g,U(i),l,V(i),l)
=ℓ′
M(i),U′
g(V′
(i),g)T+U′
(i),l(V′
(i),l)TT
U′
g−ℓ′ 
M(i),Ug(V(i),g)T+U(i),l(V(i),l)TTUg
Thus by similar calculations, we have,
∇V(i),g˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇V(i),g˜fi(Ug,V(i),g,U(i),l,V(i),l)
F
≤LℓB1∆M′
(i)
F+B4U′
(i),g−U(i),g
F
And,
∇U(i),l˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇U(i),l˜fi(Ug,V(i),g,U(i),l,V(i),l)
F
≤LℓB2∆M′
(i)
F+B4V′
(i),l−V(i),l
F
Also,
∇V(i),l˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇V(i),l˜fi(Ug,V(i),g,U(i),l,V(i),l)
F
≤LℓB1∆M′
(i)
F+B4U′
(i),l−U(i),l
F
50Combining the 4 inequalities and the fact that∆M′
(i)
F≤B2Ug−U′
g
F+
B1V(i),g−V′
(i),g
F+B2U(i),l−U′
(i),l
F+B1V(i),l−V′
(i),l
F, we have:
∇˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇˜fi(Ug,V(i),g,U(i),l,V(i),l)2
F
=∇Ug˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇Ug˜fi(Ug,V(i),g,U(i),l,V(i),l)2
F
+∇V(i),g˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇V(i),g˜fi(Ug,V(i),g,U(i),l,V(i),l)2
F
+∇U(i),l˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇U(i),l˜fi(Ug,V(i),g,U(i),l,V(i),l)2
F
+∇V(i),l˜fi(U′
g,V′
(i),g,U′
(i),l,V′
(i),l)− ∇V(i),l˜fi(Ug,V(i),g,U(i),l,V(i),l)2
F
≤L2
genU′
g−Ug2
F+V′
(i),g−V(i),g2
F+U′
(i),l−U(i),l2
F+V′
(i),l−V(i),l2
F
where Lgenis a constant defined as,
Lgen=q
8 
B2
2+B2
1
L2
ℓmax{B2
1, B2
2}+ 2B2
4=O(Lℓ)
□
With the established Lipschits continuity of the objective, we can prove the convergence
of Algorithm 1. Theorem 18 is a formal statement of such convergence guarantee.
Theorem 18 (Formal version of Theorem 3 in the main paper) Under the follow-
ing conditions,
1.There exists conctants B1, B2, B4>0such that the iterates are bounded,
(Ug{V(i),g,U(i),l,V(i),l} ∈ B (B1, B2)and the gradient norm is alsop upper bounded
ℓ′≤B4.
2.ℓisLℓ-Lipschitz continuous and lower bounded by a constant.
3. The constant stepsize ηis upper bounded by η≤1
Lgen=O(1
Lℓ).
then for Algorithm HMFwithβ= 0, the following holds,
min
τ∈[1,···,T]∇˜f 
Ug,τ,{V(i),g,τ,U(i),l,τ,V(i),l,τ}2
F=O1
T
(43)
Proof. The proof is straightforward given Lemma 17. As β= 0, we have,
˜fi(Ug,τ+1,V(i),g,τ+1,U(i),l,τ+1,V(i),l,τ+1)
=ℓ
M(i),Ug,τ+1VT
(i),g,τ+1+U(i),l,τ+1VT
(i),l,τ+1
=ℓ
M(i),Ug,τ+1
V(i),g,τ+1
2+V(i),l,τ+1UT
(i),l,τ+1
2Ug,τ+1 
UT
g,τ+1Ug,τ+1−1T
+
U(i),l,τ+1
2−Ug,τ+1 
UT
g,τ+1Ug,τ+1−1UT
g,τ+1U(i),l,τ+1
2
VT
(i),l,τ+1
=ℓ
M(i),Ug,τ+1VT
(i),g,τ+1
2+U(i),l,τ+1
2VT
(i),l,τ+1
=˜fi(Ug,τ+1,V(i),g,τ+1
2,U(i),l,τ+1
2,V(i),l,τ+1)
51Combining this and Lemma 17, we have
˜fi(Ug,τ+1,V(i),g,τ+1,U(i),l,τ+1,V(i),l,τ+1)−˜fi(Ug,τ,V(i),g,τ,U(i),l,τ,V(i),l,τ)
=˜fi(Ug,τ+1,V(i),g,τ+1
2,U(i),l,τ+1
2,V(i),l,τ+1)−˜fi(Ug,τ,V(i),g,τ,U(i),l,τ,V(i),l,τ)
≤D
∇Ug˜fi,Ug,τ+1−Ug,τE
+D
∇V(i),g˜fi,V(i),g,τ+1
2−V(i),g,τE
+D
∇U(i),l˜fi,U(i),l,τ+1
2−U(i),l,τE
+D
∇V(i),l˜fi,V(i),l,τ+1−V(i),l,τE
+Lgen
2
∥Ug,τ+1−Ug,τ∥2
F+V(i),g,τ+1
2−V(i),g,τ2
F+U(i),l,τ+1
2−U(i),l,τ2
F
+V(i),l,τ+1−V(i),l,τ2
F
≤ −η *
∇Ug˜fi,∇Ug˜f
N+
+∇U(i),l˜fi2
F+∇V(i),g˜fi2
F+∇V(i),l˜fi2
F!
+η2Lgen
2
∇Ug˜f
N2
F+∇U(i),l˜fi2
F+∇V(i),g˜fi2
F+∇V(i),l˜fi2
F

Summing both side for ifrom 1 to N, we have:
˜f(Ug,τ+1,{V(i),g,τ+1,U(i),l,τ+1,V(i),l,τ+1})−˜f(Ug,τ,{V(i),g,τ,U(i),l,τ,V(i),l,τ})
=NX
i=1˜fi(Ug,τ+1,V(i),g,τ+1,U(i),l,τ+1,V(i),l,τ+1)−˜fi(Ug,τ,V(i),g,τ,U(i),l,τ,V(i),l,τ)
≤ −η 1√
N∇Ug˜f2
F+NX
i=1∇V(i),g˜fi2
F+∇U(i),l˜fi2
F+∇V(i),l˜fi2
F!
+η2Lgen
21√
N∇Ug˜f2
F+NX
i=1∇V(i),g˜fi2
F
+∇U(i),l˜fi2
F+∇V(i),l˜fi2
F
Therefore, when η≤1
Lgen, we have:
˜f(Ug,τ+1,{V(i),g,τ+1,U(i),l,τ+1,V(i),l,τ+1})−˜f(Ug,τ,{V(i),g,τ,U(i),l,τ,V(i),l,τ})
≤ −η
2 1√
N∇Ug˜f2
F+NX
i=1∇V(i),g˜fi2
F+∇U(i),l˜fi2
F+∇V(i),l˜fi2
F!
Summing up both sides for τfrom 1 to T, we have:
TX
τ=1 1√
N∇Ug˜f2
F+NX
i=1∇V(i),g˜fi2
F+∇U(i),l˜fi2
F+∇V(i),l˜fi2
F!
≤2
η
˜f(Ug,1,{V(i),g,1,U(i),l,1,V(i),l,1})−˜f(Ug,T+1,{V(i),g,T+1,U(i),l,T+1,V(i),l,T+1})
52As˜f(Ug,T+1,{V(i),g,T+1,U(i),l,T+1,V(i),l,T+1}) is lower bounded by a constant, the right
hand2
η
˜f(Ug,1,{V(i),g,1,U(i),l,1,V(i),l,1})−˜f(Ug,T+1,{V(i),g,T+1,U(i),l,T+1,V(i),l,T+1})
is upper bounded by a constant. Hence,
min
τ∈{1,···,T} 1√
N∇Ug˜f2
F+NX
i=1∇V(i),g˜fi2
F+∇U(i),l˜fi2
F+∇V(i),l˜fi2
F!
=O1
T
This completes the proof. □
Appendix E. Auxiliary Lemmas
This section discusses some helper lemmas useful for our main proofs. These lemmas are
mostly derived from basic linear algebra.
Lemma 19 For a symmetric matrix A∈Rr×r, if∥A∥F≤3
4, we have,
I−(I+A)−1
F≤4∥A∥F
Proof. We have
I−(I+A)−1
F=(I+A)−1(−A)
F≤(1− ∥A∥F)−1∥A∥F≤4∥A∥F
□
The next lemma presents a similar result.
Lemma 20 For a symmetric matrix A∈Rr×r, if∥A∥F≤3
4, we have,
I−(I+A)−1
2
F≤4∥A∥F
3
Proof. Since∥A∥F≤3
4<1, we can use the series
I−(I+A)−1
2
F=∞X
n=1(2n−1)!!(−1)n
2nn!An
F
≤∞X
n=1(2n−1)!!(−1)n
2nn!∥A∥n
F= (1− ∥A∥F)−1
2−1
≤∥A∥Fp
1− ∥A∥F p
1− ∥A∥F+ 1≤4∥A∥F
3
□
Lemma 21 For two matrices A,B∈Rr×r, we have,
∥A−B∥2
F≥1
2∥A∥2
F− ∥B∥2
F
53Proof. We have
∥A−B∥2
F=∥A∥2
F+∥B∥2
F+ 2⟨A,B⟩
≥ ∥A∥2
F+∥B∥2
F−1
2∥A∥2
F+ 2∥B∥2
F
≥1
2∥A∥2
F− ∥B∥2
F
□
Lemma 22 For two matrices A,B∈Rr×r, ifAis invertable andA−1∥B∥<1, we have,
(A+B)−1≤A−1+A−12∥B∥
1− ∥A−1∥∥B∥
Proof. We have
(A+B)−1−A−1= 
I+BA−1−1−I
A−1≤A−1A−1∥B∥
1− ∥A−1∥∥B∥.
The proof is completed by invoking triangle inequality. □
The following lemma is a well-known result and provides an upper bound on the norm
of product matrices.
Lemma 23 For two matrices A∈Rm×nandB∈Rn×p, we have,
∥AB∥F≤ ∥A∥2∥B∥F
and
∥AB∥2≤ ∥A∥2∥B∥2
Proof.
The proof is straightforward and can be found in (Sun and Luo, 2016). □
54