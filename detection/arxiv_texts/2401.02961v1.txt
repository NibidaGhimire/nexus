1
A Surrogate-Assisted Extended Generative
Adversarial Network for Parameter Optimization in
Free-Form Metasurface Design
Manna Dai, Yang Jiang, Member, IEEE, Feng Yang, Joyjit Chattoraj, Yingzhi Xia, Xinxing Xu, Member, IEEE,
Weijiang Zhao, My Ha Dao, and Yong Liu
Abstract —Metasurfaces have widespread applications in fifth-
generation (5G) microwave communication. Among the meta-
surface family, free-form metasurfaces excel in achieving intri-
cate spectral responses compared to regular-shape counterparts.
However, conventional numerical methods for free-form meta-
surfaces are time-consuming and demand specialized expertise.
Alternatively, recent studies demonstrate that deep learning has
great potential to accelerate and refine metasurface designs.
Here, we present XGAN, an extended generative adversarial
network (GAN) with a surrogate for high-quality free-form
metasurface designs. The proposed surrogate provides a physical
constraint to XGAN so that XGAN can accurately generate
metasurfaces monolithically from input spectral responses. In
comparative experiments involving 20000 free-form metasurface
designs, XGAN achieves 0.9734 average accuracy and is 500 times
faster than the conventional methodology. This method facilitates
the metasurface library building for specific spectral responses
and can be extended to various inverse design problems, including
optical metamaterials, nanophotonic devices, and drug discovery.
Index Terms —Fifth-generation (5G), free-form metasurfaces,
generative adversarial network (GAN), surrogate, inverse design.
I. I NTRODUCTION
THIS Metasurfaces, as the two-dimensional (2D) coun-
terparts of metamaterials, enable the manipulation of
electromagnetic (EM) behaviors, such as phases, amplitudes,
and polarization of reflected/transmitted waves in space [1]–
[3]. With the advent of fifth-generation (5G) wireless commu-
nication, metasurfaces have garnered considerable scientific
and engineering interest due to the advantages of planar
Manuscript received October 12, 2023. This work was financially supported
by the A*STAR AME Programmatic Fund (Grant No. A20H5b0142). (Cor-
responding author: Yong Liu)
Manna Dai, Feng Yang, Joyjit Chattoraj, Yingzhi Xia, Xinxing Xu,
and Yong Liu are with the Computing and Intelligence Department,
Institute of High Performance Computing (IHPC), Agency for Science,
Technology and Research (A*STAR), 1 Fusionopolis Way, #16-16
Connexis, 138632, Republic of Singapore (e-mail: manna dai@ihpc.a-
star.edu.sg; yangf@ihpc.a-star.edu.sg; joyjit chattoraj@ihpc.a-star.edu.sg;
xiayingzhi@ihpc.a-star.edu.sg; xuxinx@ihpc.a-star.edu.sg; liuyong@ihpc.a-
star.edu.sg).
Yang Jiang and Weijiang Zhao are with the Electronics and Photonics
Department, Institute of High Performance Computing (IHPC), Agency for
Science, Technology and Research (A*STAR), 1 Fusionopolis Way, #16-
16 Connexis, 138632, Republic of Singapore (e-mail:jiang yang@ihpc.a-
star.edu.sg; zhaow@ihpc.a-star.edu.sg).
My Ha Dao is with the Fluid Dynamics Department, Institute of High
Performance Computing (IHPC), Agency for Science, Technology and Re-
search (A*STAR), 1 Fusionopolis Way, #16-16 Connexis, 138632, Republic
of Singapore (e-mail:daomh@ihpc.a-star.edu.sg).profile, easy integration, and low loss [4]. The concept of
“digital metamaterials” allowed for the coding of metasurfaces
to achieve different EM responses [5], [6]. The conventional
metasurface design involves three steps: determining metasur-
face patterns by a metamaterial specialist, achieving the EM
responses of patterns with the aid of full-wave EM simulators,
and selecting the metasurface with desired EM responses.
Nevertheless, the pattern design requires the expertise of a
specialist. Moreover, the metasurface selection relies on trial
and error [7], requiring tremendous iterative EM simulations
to achieve a metasurface with a satisfactory spectral response.
Consequently, there is a pressing need to quickly predict the
EM responses of various digital patterns to facilitate rapid
metasurfaces design [8], [9].
Deep learning [10] has replaced a lot of manual work
in metasurface design, such as metasurface coding [11] and
real-time response simulation [12]. The metasurface design
involves forward modeling and inverse design [13], [14].
Forward modeling, also known as surrogate modeling, predicts
EM response without EM simulation by using structural
patterns as input [15], [16]. On the other hand, inverse design
quickly produces structural patterns with the input of EM
response [17], [18]. This on-demand design method overcomes
the limitations of traditional methods, which are generally
time-consuming, inefficient, and experience-dependent. Each
metasurface design exhibits a different degree of freedom
(DOF), comprising input DOF, parameter DOF, and output
DOF [19]. Our study focuses on the parameter DOF, as it aims
to control the geometric parameters of complex metasurface
structures to realize desired EM responses. Liu et al. [20]
introduced deep learning as a substitute to solve the inverse
design problem in photonics and optics, particularly for struc-
ture designs with high parameter DOF that are too intricate
for traditional methods to handle. Deep learning models for
inverse design can be categorized into discriminative models
and generative models. Discriminative models capture the
relationship between structural patterns and optical responses,
but cannot perfectly map an optical response to a unique
set of design parameters due to multiple configurations of
patterns corresponding to the same response. Thus, discrimi-
native models are suitable for low DOF structure designs and
can be implemented with fundamental network architectures
such as fully convolutional networks (FCN) [21], [22] or
convolutional neural networks (CNN) [23], [24]. As DOF
continues growing to thousands and more, generative modelsarXiv:2401.02961v1  [cs.LG]  18 Oct 20232
become useful in reducing the design’s dimensionality and
seeking relationships between structural patterns and optical
responses for optimization. Generative adversarial networks
(GANs) [25], [26] and variational autoencoders (V AEs) [27]
are two commonly used deep generative models that capture
the distribution of high-dimensional data and represent it in a
reduced-dimensional latent space. The generative models can
be jointly leveraged with discriminative models and optimiza-
tion algorithms to accelerate the design process and locate
global optimal solutions.
Some studies have demonstrated the efficacy of using deep
learning for synthesizing metasurfaces with extra parameter
DOF. Liu et al. [28] employed a GAN to produce patterns with
arbitrary topology for desired input responses. They focused
on the basic shapes of binary images, including the classes
of L-shape, circle, arc, square, rectangle, ellipse, and sector.
Ma et al. [29] utilized V AEs to encode metamaterial patterns
and optical responses into a shared latent space, allowing for
the automatic clustering of similar patterns and responses.
Candidate patterns were generated by sampling the latent
space given requirements in the decoding process. Naseri and
Hum [30] used a V AE to encode multilayer EM metasur-
faces into latent vectors, which were searched using particle
swarm optimization (PSO) [31] to find an optimum feature
that closely matched the desired transmission coefficient. The
obtained feature was then decoded by the V AE to obtain
the metasurface design. An et al. [32] presented a GAN that
generated metasurfaces to meet multifunctional design goals,
producing free-form structures in a single design iteration
instead of using iterative optimization. Dai et al. [33] combined
a GAN with a CNN-based forward model, to design free-
form patterns with binary images, which could ensure that the
spectral responses of generated patterns resembled the given
input ones.
Although these deep learning-assisted metasurface design
methods emerge in the past few years, there exist the fol-
lowing limitations to be resolved. Firstly, most networks
tackle some simple typical geometries with limited parameter
DOF, such as square [28], H-shape [29], and circle [34].
These simple geometries impose constraints on the capacity
of metasurfaces to effectively produce desired responses [35].
Therefore, the generation of free-form geometries is necessary
for providing high parameter DOF. Secondly, some networks
produce metasurface designs that are memorized rather than
generating novel solutions by learning the underlying design
principles. Inverse design, as a one-to-many problem, can
result in multiple patterns corresponding to a specific response.
Thirdly, based on research by Yla-Oijala et al. [36], achieving
calculation convergence for the vertex-to-vertex structure in
binary matrices requires a large condition number. However,
existing networks often have insufficient condition parameters,
leading to numerical calculation uncertainty.
To address the above limitations, we conceptually pro-
pose an extended generative adversarial network guided by
a pretrained surrogate, called XGAN. This network leverages
a GAN for automatically designing free-form metasurface
patterns that possess desired spectral responses. We also design
a ternary coding strategy to mitigate the impact of vertex-to-vertex structure on calculation convergence. We treat the sur-
rogate modeling as a 2D image encoding process that produces
1D features. To perform this task, we adopt a modified ResNet
[37] with a multi-head attention model [38], inspired by the
success of contrastive language-image pretraining (CLIP) [39]
for image-to-text mapping. The resulting model is referred to
as forward-ResNet (F-ResNet). We train the F-ResNet along-
side a GAN to generate free-form ternary metasurface patterns
capable of manipulating gigahertz (GHz) waves, which helps
mitigate non-uniqueness issues in metasurface inverse designs.
With GAN’s rapid sampling capability, our XGAN model
is competent to generate a thousand independent patterns
in a second, with an accuracy of 0.9734. In this study, we
developed evaluation metrics to assess XGAN, namely model
fitting metrics. Our comparative analysis shows that XGAN
is exceptionally effective for metasurface inverse designs.
Generating high-quality patterns that match desired responses
is crucial in fields like optics, electronics, and materials
science, especially in the context of 5G millimeter-wave chip
integration regarding frequency-selective performance. XGAN
holds tremendous potential to significantly impact these fields
by delivering high-quality, easy-to-manufactured high-DOF
metasurface variants.
The contributions of this work are summarized as follows.
1) Pioneer the use of image-to-text encoders to create a
surrogate model capable of predicting the 1D spectral
responses of 2D metasurface patterns.
2) Innovatively leverage deep learning techniques to design
ternary metasurface patterns, effectively mitigating the
challenges posed by vertex-to-vertex structures and enhanc-
ing calculation convergence.
3) Design the surrogate model F-ResNet, which outperforms
other CNN-based methods, offering precise response pre-
dictions and maintaining adherence to essential physical
constraints during the tuning of XGAN.
4) Propose the XGAN inverse model, which achieves a re-
markable 500-fold speed improvement over traditional op-
timization methods like simulated annealing (SA). XGAN
produces high-quality metasurface patterns that precisely
match the desired spectral responses, when compared to
alternative deep learning-based inverse models.
5) XGAN can create new solutions based on learned design
principles, overcoming the drawback of tandem networks
that rely on memorized metasurface designs.
We start the rest of this paper by first reviewing the
related work in Section II. Then, the methodology of XGAN
is elaborated in Section III. Comparative experiments and
evaluation results are presented in Section IV.
II. R ELATED WORK
A. Metasurface Inverse Design
The inverse problem of deducing the geometric structure of
a metasurface from a desired spectral response, is not easy to
solve [15]. First, when a designer specifies a particular spectral
response, it may not always be feasible to find metasurface
patterns capable of achieving this response. Second, there is
the one-to-many mapping problem [40], [41], meaning that3
many highly dissimilar geometric structures can yield remark-
ably similar spectral responses. Therefore, for a given set of
desired spectral responses, there isn’t a unique solution, but
rather multiple feasible metasurface designs that can achieve
the same goal. This challenge arises because metasurfaces
with different geometric structures can be designed by various
sets of physical parameters. An ideal solution to this inverse
problem should address two critical aspects: (i) ascertain the
existence of any valid solution and (ii) provide a set of
designs that best approximate the specified response. Naseri
et al. [42] utilized a response prediction tool to serve as a
surrogate models in the analysis and optimization of non-
uniform metasurfaces. The integration of machine learning-
based surrogate models with inverse models offers a promising
solution to the one-to-many inverse design problem [16].
B. Image-to-Text Mapping: CLIP
An image-to-text encoder [43] is a type of neural network
or model that takes an image as input and converts it into a
textual representation or embedding. This technology is often
used in the field of computer vision and natural language
processing to bridge the gap between visual and textual
information. It allows computers to understand and process
images in a way that’s more compatible with natural language
processing. Applications of image-to-text encoders include: 1)
Image Captioning: Generating natural language descriptions
for images [44]. 2) Image Retrieval: Searching for images
using textual queries [45]. 3) Object Recognition: Identifying
objects and their attributes in images [46]. 4) Visual Question
Answering: Answering questions about images with natural
language responses [47]. 5) Scene Understanding: Describing
the scene, context, and relationships in an image using text
[48]. Prominent models that perform image-to-text encoding
include CLIP, where both images and text are processed
in a shared model to understand their relationships. These
models have wide-ranging applications in fields like image
classification, image generation from textual descriptions, rec-
ommendation systems, and more.
Although deep learning methods have been adopted in the
area of metasurface design, to our knowledge, no researchers
have attempted to emply image-to-text transformation in meta-
surface inverse design. As a spectral response can be regarded
as a special language or text to describe a metasurface pattern,
we will demonstrate that image-to-text approach can be used
to automatically realize the response prediction for a given
metasurface pattern.
III. M ETHODOLOGY
A. Overview
There are two components in the metasurface design frame-
work: one is the surrogate model (F-ResNet) that predict
spectral responses from metasurface patterns, and the other
is the inverse model (XGAN) that automatically generates
patterns with desired spectral responses.B. Surrogate Model: F-ResNet
The framework of F-ResNet is depicted in Fig. 1. We
approach the forward processing as a 1D feature extraction
task applied to a 2D image. Taking inspiration from the
impressive performance of CLIP in image-to-text tasks, we
have leveraged its image encoder as the foundation for our
surrogate model. The first step in our model is to employ
ResNet50, a widely used CNN, to extract a feature map
from the input image. This feature map captures high-level
visual information, and then we flatten the feature map via
linear projection. To generate the class embedding vector, we
compute the mean of the flattened feature map. This process
contributes to the improvement in model understanding of the
image content and category. To provide positional information,
we introduce a learnable 1D position embedding vector. This
position embedding is concatenated with the class embedding
as a new feature vector, enabling the model to capture spatial
relationships within the image. Next, we pass the augmented
feature vector through a multi-head attention model with
16 heads. This attention mechanism enhances the model’s
capability to encode complex sequences and capture semantic
representations. Each attention head simultaneously attends to
every part of the feature map, allowing for comprehensive and
fine-grained analysis. Ultimately, the output of the surrogate
model is considered as the extracted image feature, which
serves as the response for the input image. This surrogate
model works as a EM simulator, enabling us to accelerate
the prediction of EM responses. Fig. 1 provides a visual
representation of the architecture of our surrogate model.
During training, the loss function of our F-ResNet employs
L1loss:
Lforward (c, c′) =L1(c, c′) (1)
where candc′represent the desired response and the generated
response.
C. Inverse Model: XGAN
From different types of generative models, we choose GANs
due to their ability to generate high-quality samples and their
fast sampling capabilities. The learning process of a GAN
involves an adversarial game between two neural networks,
a generator, and a discriminator (Fig. 2a). During the training,
the response csampled from the training data is concatenated
with a random noise zsampled from the Gaussian distribution
N(µ, σ). This concatenated vector is fed into the generator and
outputs a pattern xGwhich follows the distribution PG. When
the generator is trained, xGis fed into the discriminator and F-
ResNet, and their outputs are utilized to calculate the Sinkhorn
distance LG
Sinkhorn and response loss L1, respectively. When
we train the discriminator, xGandxrare fed into the discrim-
inator to compute the Sinkhorn distance LD
Sinkhorn . To deal
with the issue of exploding and vanishing gradients, we gain
a sample xpenalty from the distribution Ppenalty to calculate
the gradient penalty Lpenalty [49]. As depicted in Fig. 2b, the
sample xpenalty is calculated by the linear interpolation of xr
andxG.4
Fig. 1. The network of the forward/surrogate model F-ResNet.
Fig. 2. The modeling of XGAN. (a) The training processes of the generator and discriminator of XGAN. (b) The loss functions of XGAN consist of the
discriminator loss LDand the generator loss LG.
1) Generator Network G: The detailed architecture of
Generator is depicted in Fig. 3a. In the construction phase, the
generator follows a specific sequence of layers and operations.
This sequence involves generating patterns from a desired
response vector of size 1×100 and random Gaussian noise
of size 1×10. The construction process includes a linear
layer, a parametric rectified linear unit (PReLU) layer [50] for
introducing nonlinear fitting, and a reshape layer to create a
2D square matrix. To enhance the resolution to a 16×16half-
pattern size, an upscale block is employed, which consists of a
convolutional layer, a batch-normalization layer, a pixel-shuffle
layer [51], and a PReLU. The pixel-shuffle layer is responsiblefor upsampling the input, allowing for higher resolution and
finer details in the synthesized pattern.
To further refine the pattern synthesis, a residual block
is incorporated. This block is composed of a sequence of
layers: a convolutional layer, a batch-normalization layer, a
PReLU layer, another convolutional layer, and another batch-
normalization layer. Notably, this residual block incorporates a
skip connection of ResNet50, connecting the input and output
layers to alleviate the gradient vanishing problem. Following
the residual block, the output passes through a convolutional
layer and a Tanh activation layer, limiting the output values
to the range of [−1,1]. To achieve a symmetric structure, the5
Fig. 3. Proposed XGAN architecture consists of (a) a generator and (b) a discriminator.
output of the Tanh layer is added to its transposed matrix.
The resulting matrix is then multiplied by 0.5 to control
the output matrix values within [−1,1]. Finally, a rounding
function is applied to produce a ternary matrix representation
of the generated image, with values {0,0.5,1}. By following
this specific sequence of layers and operations, the generator
can synthesize high-quality patterns that closely align with the
desired response vector while incorporating random noise for
added variation and diversity.
2) Discriminator Network D: In the discriminator architec-
ture (see Fig. 3b), the ternary pattern is provided as input.
The input pattern is then fed into 2 blocks followed by
a convolutional layer, a flatten layer, and an output layer.
Each block comprises two convolution layers with interleaved
Leaky Rectified Linear Unit (Leaky ReLU) [52] activation
layers. These convolution layers serve a dual purpose by
extracting pattern features and achieving dimensionality reduc-
tion. Meanwhile, the Leaky ReLU activation layers introduce
nonlinear fitting ability and facilitate the retention of relevant
features. The flatten layer is utilized to reshape the input into
the vector format representing the distributions of the input
patterns.
During XGAN training, the generator produces patterns
with symmetric shapes, while the discriminator computes
the distribution distances between real patterns and synthetic
patterns. The pre-trained F-ResNet approximates the spectral
response of the generated pattern. The generator and the
discriminator are trained sequentially: once the discriminatorcompletes training on six batches, the parameter settings are
updated and then fixed. Subsequently, the generator initiates
training on a single batch. This training is guided by the
updated discriminator as well as the pre-trained F-ResNet.
Ultimately, the loss function of the generator is defined as
LG=LG
Sinkhorn +λ∗L1
=LSinkhorn (D(xG),1) +λ∗L1(c, S(xG)),(2)
where G,D, and Sare the generator, the discriminator, and
the pre-trained surrogate model F-ResNet, respectively. xG=
G(c, z)represents the generated pattern xGby the generator
with inputs of the desired response cand the random Gaussian
noise z.LSinkhorn denotes the Sinkhorn distance [53], and λ
is utilized to adjust the weights of losses.
The loss function of the discriminator is computed by
LD=LD
Sinkhorn +γ∗Lpenalty
=LSinkhorn (D(xr),−1) +LSinkhorn (D(xG),1)
+γ∗Lpenalty .(3)
Here, we utilize the gradient penalty Lpenalty [49] to
constrain the Sinkhorn distance, and γis utilized to adjust
the weights of losses.
IV. E XPERIMENT
A. Data Collection
Fig. 4a illustrates the discretization and coding of meta-
surface patterns. The physical dimensions of a metasurface6
Fig. 4. Data collection process. (a) Discretization and coding of the meta-
surface pattern. (b) The process of collecting data based on Python-PEEC
co-simulation. The collected data are utilized for training neural networks
that replace the manual work in forward and inverse processes.
on the 2D plane are both 5.4 mm. These metasurfaces are
uniformly discretized as 32×32matrices, which are 90°
rotation symmetric and exhibit free-form shapes. In order to
alleviate the impact of vertex-to-vertex structure, the coding
sequence of the metasurface pattern equals to a ternary matrix,
where ‘1’ means air, ‘0’ means square metal, and an additional
‘0.5’ represents triangular metal. We use Python-PEEC co-
simulation to prepare the dataset, as illustrated in Fig. 4b.
Python first produces a random symmetric matrix, and the
partial element equivalent circuit (PEEC) method [54] then
calculates the magnitude of the reflection coefficient of this
matrix. We add the matrix and its corresponding response
to our dataset. The magnitude of the reflection coefficient of
the meta-surfaces will be sampled uniformly at 100 points
between 20 and 35 GHz, whose values ranging from -1 to 1.
Our dataset consists of 200,000 samples, of which 180,000
are used for training and 20,000 for testing.
B. Metasurface Design
Fig. 5. A sketch of metasurface design via XGAN.
Fig. 5 depicts the metasurface design created with XGAN.
During inference, we utilize only the generator of XGAN and
remove its discriminator. To generate an initial metasurface
pattern, we feed a random noise following a Gaussian distribu-
tion and a target response into the generator. PEEC is adopted
to calculate the response of this pattern. If the error between
the calculated response and the target response is below a
predetermined threshold, the initial design pattern becomes the
final design.C. Implementation Details
The code was executed on the Ubuntu 20.04.3 LTS oper-
ating system. The deep learning algorithm was implemented
using the Anaconda platform with Python 3.7.11 and PyTorch
1.7.1. These models were trained on a consumer-grade desktop
that was equipped with an NVIDIA GeForce RTX 3090 GPU.
D. Training Parameters
The F-ResNet and XGAN models are optimized using
Adam optimizers [57] with specific hyperparameters. The β1
andβ2values are set to 0.5 and 0.999, respectively, and a fixed
learning rate of 0.0002 is used. Each network is equipped
with its dedicated optimizer, and training is performed with
a batch size of 256. The F-ResNet model is trained for a
total of 1000 epochs, while the XGAN model is subjected to
an extensive training regimen spanning 10000 epochs. During
XGAN training, one epoch of generator training is interleaved
with six epochs of discriminator training. Execution details
used in the all comparative models are listed in Table I. The
training losses of F-ResNet and XGAN are depicted in Fig 6.
E. Model Fitting Metrics
The fitting accuracy of our proposed XGAN is evaluated
by four quantitative accuracy metrics MAE ave,ACC ave,
ACC minandR2
ave. Specially, the calculation of ACC aveand
ACC min follow the equations in the reference [33].
1) Assume that the mean absolute error of each design is
defined as MAE , the average MAE of total mdesigns is
computed by:
MAE ave=1
mmX
i=1MAE (m). (4)
2) The average accuracy of total designs is:
ACC ave= 1−1
2MAE ave. (5)
3) The minimum accuracy of total designs is:
ACC min= 1−1
2max
1≤i≤mMAE (i). (6)
4) Average R2is defined as follows:
R2
ave= 1−mX
i=1MSE (i)
V ar(i), (7)
where the MSE and variance of each design are represented
asMSE andV ar.
F . Experimental Results
1) Prediction Performance for Surrogate Model F-ResNet:
The comparisons are made to evaluate the effectiveness of the
surrogate models in accurately predicting the response values
of the metasurface designs. In this section, we use the CNN-
based surrogate model from our previous work [33] as a con-
trastive benchmark. Density heatmaps (with 20 bins) in Fig.
7 are used to compare the performance of surrogate models
(CNN, F-ResNet) in terms of MAE values. The comparisons7
TABLE I
EXECUTION DETAILS USED IN THE TRAINING OF SURROGATE AND INVERSE MODELS .
CNN [33] F-ResNet WGAN-GP [49] InfoGAN [55] SA [56] XGAN
Software Pytorch Pytorch Pytorch Pytorch Pytorch Pytorch
Hardware GPU GPU GPU GPU GPU GPU
Training set size 180000 180000 180000 180000 NA 180000
Test set size 20000 20000 20000 20000 20000 20000
Optimizer Adam Adam Adam Adam NA Adam
learning rate, β1,β2 2e-4, 0.5, 0.999 2e-4, 0.5, 0.999 2e-4, 0.5, 0.999 2e-4, 0.5, 0.999 NA 2e-4, 0.5, 0.999
Batch size 256 256 256 256 NA 256
Epochs 1000 1000 10000 10000 1000 10000
Surrogate for training NA NA NA NA F-ResNet F-ResNet
Simulator for evaluation NA NA PEEC [54] PEEC [54] PEEC [54] PEEC [54]
Evalustion MetricModel Fitting Model Fitting Model Fitting Model Fitting Model Fitting Model Fitting
Metrics Metrics Metrics Metrics Metrics Metrics
Fig. 6. Training losses of the proposed models, including (a) F-ResNet loss in Eq. 1, (b) XGAN generator loss LGin Eq. 2, and (c) XGAN discriminator
lossLDin Eq. 3.
Fig. 7. Density heatmaps (bins=20) of forward models (CNN, F-ResNet)
comparisons regarding MAE.
are based on 20,000 testing datasets. Specifically, F-ResNet
achieves MAE values generally below 0.05, whereas the CNN
model only achieves this level of accuracy in half of the cases
(see Fig. 7). These results demonstrate the effectiveness of our
proposed F-ResNet model for the given task. Regarding simu-
lation times, Table II reveals that both CNN and F-ResNet,
as deep learning methods, have relatively quick simulation
times for a given case. In contrast, PEEC, a numerical EM
simulator, can only simulate 1 to 3 patterns per minute. In
terms of model fitting metrics , F-ResNet surpasses CNN in
response prediction, as evidenced by superior performance in
ACC ave,ACC min,MAE ave, and R2.
Fig. 8. The polar plots of response accuracies for different network com-
binations (Legend meaning: [Inverse Model+Surrogate Model]+Evaluation
Simulator).
We integrate F-ResNet into various network configurations
to assess its efficacy in predicting responses during XGAN
training, and its performance as a simulation tool for XGAN
evaluation. Our results are evaluated by using the model fitting
metrics . As presented in Fig. 8, incorporating F-ResNet leads
to improved XGAN performance, as opposed to using CNN.
This finding is validated through evaluation, where PEEC or
F-ResNet is used as a simulation tool.
2) XGAN Outperforms Existing Inverse Design Methods:
The experimental approaches for evaluating inverse design8
TABLE II
ACCURACY AND TIME COST FOR DIFFERENT FORWARD AND INVERSE MODELS
Model Type Model Name ACC ave ACC min MAE ave R2Time/Second
Forward/Surrogate ModelCNN [33] 0.9644 0.6576 0.0712 0.8675 0.001
F-ResNet 0.9923 0.7636 0.0154 0.9869 0.001
PEEC [54] NA NA NA NA 20-60
Inverse ModelWGAN-GP [49] 0.8221 0.5338 0.3558 0.7251 0.0015
InfoGAN [55] 0.8321 0.6096 0.3358 0.6401 0.0015
SA [56] 0.8104 0.5335 0.3791 0.7638 0.75
XGAN 0.9734 0.7132 0.0533 0.9228 0.0015
Fig. 9. Density heatmaps (bins=20) of response MAE for inverse models (WGAN-GP, InfoGAN, Simulated Annealing, and XGAN).
Fig. 10. Free-form metasurface design by various inverse models, including WGAN-GP, InfoGAN, Simulated Annealing (SA), and XGAN. (a) Model sample
and original data visualization, when Gaussian noise is N(µ= 0, σ= 1) and input responses are variable. (b) The MAE between the input response and the
PEEC-simulated response of each sample.
in this study include WGAN-GP [49], InfoGAN [55], the
simulated annealing (SA) [56], and XGAN.
Quantitative Comparison: Fig. 9 highlights the superior
performance of XGAN compared to other contrastive methods
regarding MAE. Specifically, the MAE values achieved by
XGAN are generally below 0.1, whereas WGAN-GP and the
SA have the highest MAE value of 1, and InfoGAN has the
highest value of 0.8. Table II provides the running time of
each inverse model. During inference, the proposed XGAN
model takes 0.0015 seconds to generate a solution for a given
response.
Qualitative Comparison: Fig. 10a provides some meta-
surface designs encoded by WGAN-GP, InfoGAN, SA, andXGAN. These models are fed with the target responses,
and the corresponding designed patterns are simulated by
PEEC to obtain the actual responses. Our aim is to determine
which model could generate the highest-quality patterns that
accurately matched the target responses. Specifically, XGAN
generates patterns with response MAEs below 0.1, whereas the
other models fail to achieve the same level of accuracy (see
Fig. 10b). This finding indicates the proficiency of XGAN
in generating patterns with desired responses. This superior
performance can be attributed to the use of interpretable latent
vectors from the XGAN and the response feedback mechanism
from F-ResNet, which allow for condition control and precise
refinement of the generated patterns. To sum up, XGAN show-9
cases the distinctive ability to generate appropriate patterns
based on input responses, setting it apart from other models
that lack this unique capability.
V. C ONCLUSION
In this paper, we present XGAN, a novel approach for the
rapid and accurate realization of free-form metasurfaces. We
combine ResNet50 with a multi-head attention model, named
F-ResNet, to accurately predict the responses of metasurface
patterns. F-ResNet exhibits impressive performance, achieving
a prediction rate of 1000 patterns per second, with ACC ave
of 0.99 and R2of 0.98. This is 20000-60000 times faster than
the conventional simulator PEEC, effectively replacing it as a
surrogate simulation tool. XGAN includes a GAN for inverse
design. To address the limitation of traditional GAN discrim-
inators in capturing response relevance between original and
generated patterns, we integrate F-ResNet into the framework.
F-ResNet acts as a constraint on XGAN training by connecting
it with the generator. During the training, XGAN generates
an initial pattern using input vectors, and iteratively refines
it based on feedback from F-ResNet, ultimately achieving the
desired response. To assess the efficiency of XGAN, we design
model fitting metrics . XGAN achieves ACC aveof 0.97 for
20000 designs in a single run, and produces a metasurface
pattern in 0.0015 seconds, which is 500 times faster than
the conventional optimization method SA. Overall, XGAN
provides a fast and accurate approach for designing free-
form metasurfaces to meet the response requirement. This
makes XGAN suitable for various applications, including light
manipulation and spectral selection.
REFERENCES
[1] Y . Yang, Y . Ge, R. Li, X. Lin, D. Jia, Y .-j. Guan, S.-q. Yuan, H.-x. Sun,
Y . Chong, and B. Zhang, “Demonstration of negative refraction induced
by synthetic gauge fields,” Science Advances , vol. 7, no. 50, p. eabj2062,
2021.
[2] H.-Y . Cheng, M.-J. Ye, W.-R. Chen, C.-Y . Yang, S.-W. Chu, K.-P.
Chen, and K.-H. Lin, “Large optical modulation of dielectric huygens’
metasurface absorber,” Advanced Optical Materials , p. 2300102, 2023.
[3] A. M. Shaltout, V . M. Shalaev, and M. L. Brongersma, “Spatiotemporal
light control with active metasurfaces,” Science , vol. 364, no. 6441, p.
eaat3100, 2019.
[4] Z. N. Chen, T. Li, and W. E. Liu, “Microwave metasurface-based lens
antennas for 5g and beyond,” in 2020 14th European Conference on
Antennas and Propagation (EuCAP) . IEEE, 2020, pp. 1–4.
[5] T. J. Cui, M. Q. Qi, X. Wan, J. Zhao, and Q. Cheng, “Coding
metamaterials, digital metamaterials and programmable metamaterials,”
Light: science & applications , vol. 3, no. 10, pp. e218–e218, 2014.
[6] X. Wan, M. Q. Qi, T. Y . Chen, and T. J. Cui, “Field-programmable
beam reconfiguring based on digitally-controlled coding metasurface,”
Scientific reports , vol. 6, no. 1, p. 20663, 2016.
[7] T. Qiu, X. Shi, J. Wang, Y . Li, S. Qu, Q. Cheng, T. Cui, and S. Sui,
“Deep learning: a rapid and efficient route to automatic metasurface
design,” Advanced Science , vol. 6, no. 12, p. 1900128, 2019.
[8] R. Zhu, T. Qiu, J. Wang, S. Sui, C. Hao, T. Liu, Y . Li, M. Feng,
A. Zhang, C.-W. Qiu et al. , “Phase-to-pattern inverse design paradigm
for fast realization of functional metasurfaces via transfer learning,”
Nature communications , vol. 12, no. 1, p. 2974, 2021.
[9] L. Li, T. Jun Cui, W. Ji, S. Liu, J. Ding, X. Wan, Y . Bo Li, M. Jiang,
C.-W. Qiu, and S. Zhang, “Electromagnetic reprogrammable coding-
metasurface holograms,” Nature communications , vol. 8, no. 1, p. 197,
2017.
[10] Y . Jia, C. Qian, Z. Fan, T. Cai, E.-P. Li, and H. Chen, “A knowledge-
inherited learning for intelligent metasurface design and assembly,”
Light: Science & Applications , vol. 12, no. 1, p. 82, 2023.[11] C. Liu, Q. Ma, Z. J. Luo, Q. R. Hong, Q. Xiao, H. C. Zhang, L. Miao,
W. M. Yu, Q. Cheng, L. Li et al. , “A programmable diffractive deep
neural network based on a digital-coding metasurface array,” Nature
Electronics , vol. 5, no. 2, pp. 113–122, 2022.
[12] Y . Zhu, X. Zang, H. Chi, Y . Zhou, Y . Zhu, and S. Zhuang, “Metasurfaces
designed by a bidirectional deep neural network and iterative algorithm
for generating quantitative field distributions,” Light: Advanced Manu-
facturing , vol. 4, no. 1, pp. 1–11, 2023.
[13] J. Zhang, C. Qian, Z. Fan, J. Chen, E. Li, J. Jin, and H. Chen,
“Heterogeneous transfer-learning-enabled diverse metasurface design,”
Advanced Optical Materials , vol. 10, no. 17, p. 2200748, 2022.
[14] Y . Jia, C. Qian, Z. Fan, Y . Ding, Z. Wang, D. Wang, E.-P. Li, B. Zheng,
T. Cai, and H. Chen, “In situ customized illusion enabled by global
metasurface reconstruction,” Advanced Functional Materials , vol. 32,
no. 19, p. 2109331, 2022.
[15] C. C. Nadell, B. Huang, J. M. Malof, and W. J. Padilla, “Deep learning
for accelerated all-dielectric metasurface design,” Optics express , vol. 27,
no. 20, pp. 27 523–27 535, 2019.
[16] Z. Li, R. Pestourie, Z. Lin, S. G. Johnson, and F. Capasso, “Empowering
metasurfaces with inverse design: principles and applications,” ACS
Photonics , vol. 9, no. 7, pp. 2178–2192, 2022.
[17] I. Tanriover, D. Lee, W. Chen, and K. Aydin, “Deep generative modeling
and inverse design of manufacturable free-form dielectric metasurfaces,”
ACS Photonics , 2022.
[18] J. Wang, R. Xi, T. Cai, H. Lu, R. Zhu, B. Zheng, and H. Chen,
“Deep neural network with data cropping algorithm for absorptive
frequency-selective transmission metasurface,” Advanced Optical Ma-
terials , vol. 10, no. 13, p. 2200178, 2022.
[19] B. Xiong, L. Deng, R. Peng, and Y . Liu, “Controlling the degrees of
freedom in metasurface designs for multi-functional optical devices,”
Nanoscale Advances , vol. 1, no. 10, pp. 3786–3806, 2019.
[20] Z. Liu, D. Zhu, L. Raju, and W. Cai, “Tackling photonic inverse design
with machine learning,” Advanced Science , vol. 8, no. 5, p. 2002923,
2021.
[21] T. Zhang, C. Y . Kee, Y . S. Ang, and L. Ang, “Deep learning-based design
of broadband ghz complex and random metasurfaces,” APL Photonics ,
vol. 6, no. 10, p. 106101, 2021.
[22] J. Yun, S. Kim, S. So, M. Kim, and J. Rho, “Deep learning for
topological photonics,” Advances in Physics: X , vol. 7, no. 1, p. 2046156,
2022.
[23] A. Mall, A. Patil, A. Sethi, and A. Kumar, “A cyclical deep learn-
ing based framework for simultaneous inverse and forward design of
nanophotonic metasurfaces,” Scientific reports , vol. 10, no. 1, pp. 1–12,
2020.
[24] J. A. Hodge, K. V . Mishra, and A. I. Zaghloul, “Multi-discriminator
distributed generative model for multi-layer rf metasurface discovery,”
in2019 IEEE Global Conference on Signal and Information Processing
(GlobalSIP) . IEEE, 2019, pp. 1–5.
[25] A. Creswell, T. White, V . Dumoulin, K. Arulkumaran, B. Sengupta, and
A. A. Bharath, “Generative adversarial networks: An overview,” IEEE
signal processing magazine , vol. 35, no. 1, pp. 53–65, 2018.
[26] Z. Wang, Q. She, and T. E. Ward, “Generative adversarial networks in
computer vision: A survey and taxonomy,” ACM Computing Surveys
(CSUR) , vol. 54, no. 2, pp. 1–38, 2021.
[27] D. P. Kingma and M. Welling, “Stochastic gradient vb and the vari-
ational auto-encoder,” in Second international conference on learning
representations, ICLR , vol. 19, 2014, p. 121.
[28] Z. Liu, D. Zhu, S. P. Rodrigues, K.-T. Lee, and W. Cai, “Generative
model for the inverse design of metasurfaces,” Nano letters , vol. 18,
no. 10, pp. 6570–6576, 2018.
[29] W. Ma, F. Cheng, Y . Xu, Q. Wen, and Y . Liu, “Probabilistic representa-
tion and inverse design of metamaterials based on a deep generative
model with semi-supervised learning strategy,” Advanced Materials ,
vol. 31, no. 35, p. 1901111, 2019.
[30] P. Naseri and S. V . Hum, “A machine learning-based approach to synthe-
size multilayer metasurfaces,” in 2020 IEEE International Symposium on
Antennas and Propagation and North American Radio Science Meeting .
IEEE, 2020, pp. 933–934.
[31] M. Clerc, Particle swarm optimization . John Wiley & Sons, 2010,
vol. 93.
[32] S. An, B. Zheng, H. Tang, M. Y . Shalaginov, L. Zhou, H. Li, M. Kang,
K. A. Richardson, T. Gu, J. Hu et al. , “Multifunctional metasurface
design with a generative adversarial network,” Advanced Optical Mate-
rials, vol. 9, no. 5, p. 2001433, 2021.
[33] M. Dai, Y . Jiang, F. Yang, X. Xu, W. Zhao, M. H. Dao, and Y . Liu,
“Slmgan: Single-layer metasurface design with symmetrical free-form10
patterns using generative adversarial networks,” Applied Soft Computing ,
vol. 130, p. 109646, 2022.
[34] S. An, B. Zheng, M. Y . Shalaginov, H. Tang, H. Li, L. Zhou, J. Ding,
A. M. Agarwal, C. Rivero-Baleine, M. Kang et al. , “Deep learning
modeling approach for metasurfaces with high degrees of freedom,”
Optics Express , vol. 28, no. 21, pp. 31 932–31 942, 2020.
[35] J. Yang, K. Cui, X. Cai, J. Xiong, H. Zhu, S. Rao, S. Xu, Y . Huang,
F. Liu, X. Feng et al. , “Ultraspectral imaging based on metasurfaces
with freeform shaped meta-atoms,” Laser & Photonics Reviews , vol. 16,
no. 7, p. 2100663, 2022.
[36] P. Yla-Oijala and M. Taskinen, “Calculation of cfie impedance matrix
elements with rwg and n/spl times/rwg functions,” IEEE Transactions
on Antennas and Propagation , vol. 51, no. 8, pp. 1837–1846, 2003.
[37] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” arXiv preprint arXiv:1512.03385 , 2015.
[38] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” Advances in
neural information processing systems , vol. 30, 2017.
[39] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal,
G. Sastry, A. Askell, P. Mishkin, J. Clark et al. , “Learning transferable
visual models from natural language supervision,” in International
conference on machine learning . PMLR, 2021, pp. 8748–8763.
[40] G. Jing, P. Wang, H. Wu, J. Ren, Z. Xie, J. Liu, H. Ye, Y . Li, D. Fan,
and S. Chen, “Neural network-based surrogate model for inverse design
of metasurfaces,” Photonics Research , vol. 10, no. 6, pp. 1462–1471,
2022.
[41] I. Tanriover, W. Hadibrata, and K. Aydin, “Physics-based approach for
a neural networks enabled design of all-dielectric metasurfaces,” ACS
Photonics , vol. 7, no. 8, pp. 1957–1964, 2020.
[42] P. Naseri and S. V . Hum, “A generative machine learning-based approach
for inverse design of multilayer metasurfaces,” IEEE Transactions on
Antennas and Propagation , vol. 69, no. 9, pp. 5725–5739, 2021.
[43] M. ˙Zelaszczyk and J. Ma ´ndziuk, “Cross-modal text and visual genera-
tion: A systematic review. part 1—image to text,” Information Fusion ,
2023.
[44] R. Ramos, B. Martins, D. Elliott, and Y . Kementchedjhieva, “Smallcap:
lightweight image captioning prompted with retrieval augmentation,”
inProceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition , 2023, pp. 2840–2849.
[45] G. Couairon, M. Douze, M. Cord, and H. Schwenk, “Embedding
arithmetic of multimodal queries for image retrieval,” in Proceedings of
the IEEE/CVF Conference on Computer Vision and Pattern Recognition ,
2022, pp. 4950–4958.
[46] L. Yao, J. Han, X. Liang, D. Xu, W. Zhang, Z. Li, and H. Xu, “Detclipv2:
Scalable open-vocabulary object detection pre-training via word-region
alignment,” in Proceedings of the IEEE/CVF Conference on Computer
Vision and Pattern Recognition , 2023, pp. 23 497–23 506.
[47] F. Gao, Q. Ping, G. Thattai, A. Reganti, Y . N. Wu, and P. Natara-
jan, “Transform-retrieve-generate: Natural language-centric outside-
knowledge visual question answering,” in Proceedings of the IEEE/CVF
Conference on Computer Vision and Pattern Recognition , 2022, pp.
5067–5077.
[48] J. Kil, S. Changpinyo, X. Chen, H. Hu, S. Goodman, W.-L. Chao,
and R. Soricut, “Prestu: Pre-training for scene-text understanding,” in
Proceedings of the IEEE/CVF International Conference on Computer
Vision , 2023, pp. 15 270–15 280.
[49] I. Gulrajani, F. Ahmed, M. Arjovsky, V . Dumoulin, and A. C. Courville,
“Improved training of wasserstein gans,” Advances in neural information
processing systems , vol. 30, 2017.
[50] K. He, X. Zhang, S. Ren, and J. Sun, “Delving deep into rectifiers:
Surpassing human-level performance on imagenet classification,” in
Proceedings of the IEEE international conference on computer vision ,
2015, pp. 1026–1034.
[51] W. Shi, J. Caballero, F. Husz ´ar, J. Totz, A. P. Aitken, R. Bishop,
D. Rueckert, and Z. Wang, “Real-time single image and video super-
resolution using an efficient sub-pixel convolutional neural network,” in
Proceedings of the IEEE conference on computer vision and pattern
recognition , 2016, pp. 1874–1883.
[52] A. L. Maas, A. Y . Hannun, A. Y . Ng et al. , “Rectifier nonlinearities
improve neural network acoustic models,” in Proc. icml , vol. 30, no. 1.
Atlanta, GA, 2013, p. 3.
[53] M. Cuturi, “Sinkhorn distances: Lightspeed computation of optimal
transport,” Advances in neural information processing systems , vol. 26,
2013.
[54] Y . Jiang, W.-J. Zhao, R. X.-K. Gao, E.-X. Liu, and C. E. Png, “A full-
wave generalized peec model for periodic metallic structure with arbi-trary shape,” IEEE Transactions on Microwave Theory and Techniques ,
vol. 70, no. 9, pp. 4110–4119, 2022.
[55] X. Chen, Y . Duan, R. Houthooft, J. Schulman, I. Sutskever, and
P. Abbeel, “Infogan: Interpretable representation learning by information
maximizing generative adversarial nets,” Advances in neural information
processing systems , vol. 29, 2016.
[56] J. Lee and D. Perkins, “A simulated annealing algorithm with a dual
perturbation method for clustering,” Pattern Recognition , vol. 112, p.
107713, 2021.
[57] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
arXiv preprint arXiv:1412.6980 , 2014.
Manna Dai received her Ph.D. degree in Computer
Science from Faculty of Engineering and Informa-
tion Technology, University of Technology Sydney,
Australia. She was affiliated with Data61, Com-
monwealth Scientific and Industrial ResearchOrga-
nization, Australia. She conducted her postdoctoral
research in the Division of Engineering in Medicine,
Department of Medicine, Brigham and Women’s
Hospital, Harvard Medical School, USA. Currently,
she works as a Scientist in Computing &Intelligence
Department, Institute of High Performance Comput-
ing, Agency for Science, Technology and Research (A*STAR), Singapore. Her
research interests include inverse design, target tracking, machine learning,
deep learning, computer vision, and image-processing.
Yang Jiang (Member, IEEE) was born in Shandong,
China in 1990. He received the B.S. and the Ph.D.
degrees in electronic engineering from the Chinese
University of Hong Kong, Hong Kong, China, in
2013 and 2019. He is currently a Research Scientist
with the Institute of High-Performance Computing
(IHPC), A*STAR, Singapore. His research interests
include partial element equivalent circuit (PEEC)
modeling for cutting-edge technologies, physics-
informed artificial intelligence for inverse design and
inverse scattering problems, and EMC/ESD model-
ing. He received the Highly Recommend Paper Award of APEMC in 2022. He
serves as an Executive Committee Member of IEEE Singapore EMC Chapter.
Feng Yang received his B.Eng. degree in infor-
mation engineering and M.Eng. degree in con-
trol engineering from Xi’an Jiaotong University
(XJTU), Xi’an, China. He then received his Ph.D.
degree in machine learning and bioinformatics from
Nanyang Technological University (NTU), Singa-
pore, in 2012. From June 2011 to March 2012,
he was a Research Associate at NTU. In 2012, he
joined the Institute of High Performance Comput-
ing (IHPC), Agency for Science, Technology, and
Research (A*STAR), Singapore. Currently, he is a
Principal Scientist in the Department of Computing & Intelligence, IHPC. His
research interests include machine learning, knowledge-driven AI, generative
AI for inverse problems, information retrieval, representation learning, data-
based diagnosis and prognosis, and digital twin.11
Joyjit Chattoraj is a senior scientist at Institute of
High Performance Computing (IHPC), Agency for
Science Technology and Research (A*STAR), Sin-
gapore. He received his PhD degree in Physics from
Universit ´e Paris Est, France. His research interests
include Physics-based Artificial Intelligence, Inverse
Modelling, and Artificial Intelligence for Material
Discovery.
Yingzhi Xia received the B.S. degree in Mathe-
matics and Applied Mathematics from Northwest-
ern Polytechnical University, China, and the Ph.D.
degree in Computer Science from the University of
Chinese Academy of Sciences, China, and Shang-
haiTech University, China. He is currently a research
scientist at the Institute of High Performance Com-
puting (IHPC), A*STAR, Singapore. His research
interests include inverse problems, probabilistic ma-
chine learning, and scientific computing.
Xinxing Xu (Member, IEEE) is a senior scientist
and Group Manager of Multimodal AI, Computing
& Intelligence Department at IHPC, A*STAR. He
obtained his Ph.D. in Computer Engineering from
Nanyang Technological University (NTU), Singa-
pore and his bachelor’s degree from the University
of Science and Technology of China (USTC).
His research interests include machine learning,
computer vision, and medical data analysis. He has
published research works in top-tier AI journals and
conferences including IEEE TPAMI, IEEE TNNLS,
IEEE TIP, IEEE JBHI, CVPR, ICCV , IJCAI, ICDM, ECCV , and MICCAI. A
few of his recent research works on deep learning for medical imaging have
also been published in top-tier venues including the New England Journal of
Medicine, Nature Medicine, Nature Aging, Nature Machine Intelligence, and
The Lancet Digital Health. He received Best Paper Winner at OMIA workshop
of MICCAI 2022 and Best Paper Award at BeyondLabeler Workshop at IJCAI
2016. He also won 3rd Place in Glaucoma grAding from Multi-Modality
imAges (GAMMA) Challenge at MICCAI 2021.
Weijiang Zhao received his bachelor degree from
Nankai University in 1989, the M.Eng and the
Ph.D. from Xidian University in 1992 and 1999,
respectively. He was with Xidian University as an
Associate Professor from 1999 to 2001. He then
joined the National University of Singapore as a Re-
search Scientist. He has been with A*STAR Institute
of High Performance Computing, Singapore since
2010, and is currently a Senior Principal Scientist in
the Electronics and Photonics Department. He was
part of the project team responsible for the Integrated
Environmental Modeller software which won the President’s Technology
Award in 2019. Dr Zhao has authored and coauthored more than 60 technical
papers. His research interests include computational electromagnetic, inverse
design of metasurfaces with AI, antennas and propagation, electromagnetic
compatibility and interference, radome analysis, electromagnetic scattering,
wireless communications, traffic noise modeling, GNSS positioning, iono-
spheric scintillation, numerical methods, and optimization techniques.
My Ha Dao received the B.S. degree in Aeronautical
Engineering from the Ho Chi Minh City University
of Technology in 2002, and the M.Eng. degree
in High Performance Computing for Engineered
Systems and the PhD degree in Civil Engineering
from the National University of Singapore in 2004
and 2011, respectively. He work for 7 years at
the Tropical Marine Science Institute and 3 years
at the Singapore-MIT Alliance for Research and
Technology, National University of Singapore. He
is currently a Principal Scientist at the Institute
Of High Performance Computing (IHPC), A*STAR. His research interests
include physics-based, data driven and artificial intelligence models that
complement high fidelity computational numerical models in aerospace,
marine and offshore, additive manufacturing, optics applications.
Yong Liu Deputy Department Director, Computing
& Intelligence Department at Institute of High Per-
formance Computing (IHPC), A*STAR, Singapore.
He is also Adjunct Associate Professor at Duke-
NUS Medical School, NUS and Adjunct Principal
Investigator at Singapore Eye Research Institute
(SERI). Being passionate on the potential of AI
on healthcare, he has led multiple research projects
in multimodal machine learning, medical imaging
analysis, especially AI for digital ophthalmology and
other areas in healthcare. Together with clinicians,
he has been awarded large scale programme and multiple grants as PI in the
area of AI for healthcare. He and his team have been awarded multiple grants
from AI SG, NMRC, IAF-PP, and NHIC. He and his team have also published
top tier papers in New England Journal of Medicine, Lancet Digital Health,
Nature Aging, Ophthalmology, Neurology, Annals of Neurology, and also top-
tier AI papers (AAAI, CVPR, IJCAI, MICCAI). He has won the Nation Award
(Covid-19) Commendation Medal. His papers received Best Paper Award at
REMIA workshop with 2022 MICCAI, Best Paper Award at BeyondLabeler
Workshop on International Joint Conference on Artificial Intelligence (IJCAI)
2016. He and his team has also won the 3rd Place GAMMA Challenge in
MICCAI 2021, the NSCC Outstanding HPC Innovation Award 2017, and the
first prize of Rakuten TV recommendation Challenge 2015.