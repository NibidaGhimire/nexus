arXiv:2305.19731v3  [math.GR]  1 May 2024May 2, 2024
SURJECTIVITY OF POLYNOMIAL MAPS ON MATRICES
SAIKAT PANJA, PRACHI SAINI, AND ANUPAM SINGH
Abstract. Forn≥2, we consider the map on Mn(K) given by evaluation of a
polynomial f(X1,...,X m) over the ﬁeld K. In this article, we explore the image
of the diagonal map given by f=δ1Xk1
1+δ2Xk2
2+···+δmXkmmin terms of
the solution of certain equations over K. In particular, we show that for m≥2,
the diagonal map is surjective when (a) K=C, (b)K=Fqfor large enough q.
Moreover, when K=Randm= 2 it is surjective except when nis odd,k1,k2
are both even, and δ1δ2>0 (in that case the image misses negative scalars), and
the map is surjective for m≥3. We further show that on Mn(H) the diagonal
map is surjective for m≥2, where His the algebra of Hamiltonian quaternions.
1.Introduction
LetAbe an associative algebra over a ﬁeld K. Letf(X1,...,Xm) be a poly-
nomial over Kin non-commuting variables. Such a polynomial deﬁnes a map
ω:Am→ Agiven by evaluation ( x1,x2,...,xm)/ma√sto→f(x1,...,xm). These maps
are called polynomial maps, and a fundamental question is understa nding their
image. In recent years this problem has attracted a lot of attentio n including in
the context of groups, algebras and Lie algebras etc. (e.g. see th e articles [10, 14]
). Several deep results have been proved for word maps on ﬁnite s imple groups
(see the articles [19, 21, 20]). In this article, we look for certain ana logous results
for matrix algebras. Here we deal with a particular map, namely given by diagonal
polynomials.
Given integers k1,k2,...,km≥1, andδ1,...,δm∈Kall non-zero, we consider
the diagonal polynomial
f(X1,...,Xm) =δ1Xk1
1+δ2Xk2
2+···+δmXkm
m (1.1)
2020Mathematics Subject Classiﬁcation. Primary: 16S50,11P05, Secondary: 16K20.
Key words and phrases. Polynomial maps, Diagonal polynomial, Matrix algebra.
The ﬁrst-named author is supported by the HRI PDF-M scholarship . The
second-named author acknowledges the support of CSIR PhD sch olarship number
09/0936(1237)/2021-EMR-I. The third-named author is funded by an NBHM research grant
02011/23/2023/NBHM(RP)/RDII/5955 for this research.
12 PANJA S., SAINI P., AND SINGH A.
inm-variables. We call the corresponding map ωadiagonal map . The main
question here is to understand how big the image is. In particular, we would like
to see if this map is surjective and ﬁnd the smallest mwith this property. When
k1=...=km=kthe Equation 1.1 is a k-form. Such a k-form is said to be
universal onAif the map ωis surjective. Also, the well-known matrix Waring
problem considers δ1=δ2=···=δm= 1 for ak-form and asks for the smallest m
so that the form is universal, i.,e., ωis surjective. The universality of the quadratic
form (k= 2 case) over a ﬁeld is a well-studied problem including the arithmetic
aspects (e.g. in the work of Bhargava [3], [4]). Voloch looked at diagon al forms
over function ﬁelds in [31]. We are interested in looking at this problem w henAis
the matrix algebra Mn(K) and obtain results over certain ﬁelds such as K=C,R
andFq(also over the skew-ﬁeld H). The Waring problem is well-studied for matrix
algebra see Richman [26], Vaserstein [29], Katre [15], [16], Garge [2], [8], Bresar-
Semrl ([5], [6], [7]) etc. More general problems about the images of po lynomial
mapsonalgebrasarebeingconsideredbyKanel-Below, Yavich, Kuny avskii, Rowen
etc. (see [1], [11] ,[12], [13], [22], [24]). For a survey of recent results o ne can look
into [10] and [14].
Motivated by the results obtained for the Waring-like problem in the c ase of
non-abelian ﬁnite simple groups (see [19], [21] and [20]), Larsen asked the question
(see [17]) if every element of Mn(K) can be written as a sum of two k-th powers
for “large enough” K. This question is answered in the aﬃrmative in a series of
two papers [17] and [18] over ﬁnite ﬁelds Fq. In particular, in [18] it is shown that
(see Theorem 1.1) there exists a constant N(k) (which depends only on k) such
that for all q>N(k) the map given by Xk+Ykis surjective on Mn(Fq).
In this article, we obtain more general results about the image of th e diagonal
mapωgiven by the polynomial in Equation 1.1 on Mn(K) such as when invertible
matrices and nilpotent matrices are in the image depending on if we hav e solutions
to certain equations (which are usually k-forms) over the underlying ﬁeld K. These
results are collected in Section 3. With the help of these, we obtain th e following
results in Section 4, and 5 over various ﬁelds:
Theorem 1.1. Letmbea positiveinteger and n≥2. Given integers k1,k2,...,km≥
1, andδ1,...,δm∈Kall non-zero, consider the diagonal map ω:Mn(K)m→
Mn(K)forn≥2given by
ω(x1,...,xm) =δ1xk1
1+δ2xk2
2+···+δmxkm
m.
Then we have the following:SURJECTIVITY OF POLYNOMIAL MAPS ON MATRICES 3
(1) When K=C, the mapωis surjective for all m≥2.
(2) When K=Fqandm≥2, there exists a constant Nwhich depends on
k1,...,kmsuch that for all q >Nthe mapωis surjective.
(3) When K=Randm= 2, the mapωis surjective except when nis odd,
δ1δ2>0andk1,k2are both even (in that case the image misses negative
scalar matrices). It is surjective for m≥3.
(4) OnMn(H)the mapωis surjective for all m≥2.
Since, in general, the power maps need not be surjective, m= 2 is the smallest
possible with the property that ωcould be surjective. This clearly generalises the
known results for the Matrix Waring problem in [18] to a more genera l diagonal
map on one hand, and on the other hand, it generalises the work of R ichman [25,
26]. The result on Hforδi∈Rfollows quite easily by using the canonical form
theory which we mention in Section 6. We further hope to apply our me thod to
some more polynomial maps and obtain similar results. Throughout th e article
I∈Mn(K) will denote the n×nidentity matrix in Mn(K).
2.Preliminaries
Inthissection, we set upamethod thatreduces theproblem ofﬁnd ing asolution
to a matrix equation f(X1,...Xm) =Afor allA∈Mn(K) to that of Jordan
Matrices over extensions of K. Recall that an irreducible separable polynomial is
one which does not have repeated roots over an algebraic closure. We will call a
polynomial to be separable if all of its irreducible factors are separa ble.
2.1.Reduction to Jordan Matrices. LetKbe a ﬁeld and A∈Mn(K). We are
interested in ﬁnding a solution to the equation f(X1,X2,...,Xm) =A. That
is, we want to know if Ais in the image of the map ω:Am→ Agiven by
(x1,x2,...,xm)/ma√sto→f(x1,x2,...,xm). ForP∈GLn(K) we can re-write the equa-
tion as
f(PX1P−1,PX2P−1,...,PX mP−1) =PAP−1,
thus it is enough to consider a canonical form of Aup to similarity. Further,
if we have a block diagonal matrix A= diag(A1,...,Ar), and have a solution
to eachf(X1,X2,...,Xm) =Aifor 1≤i≤r, then we have a solution to
f(X1,X2,...,Xm) =Aby taking solution as the block diagonal matrices with
blocks being the solutions of the earlier equation.4 PANJA S., SAINI P., AND SINGH A.
Further,let Ahasitscharacteristicpolynomialseparableandisgivenby/producttextr
i=1pi(x)si
wherepiare irreducible polynomials then a canonical form of Aisr/circleplustext
i=1ti/circleplustext
j=1Jpi,si(j),
where{si(1),...,si(ti)}isapartitionof si. Thisnotationwillbeabbreviatedinthe
subsequent discussion by omitting the limits when they are clear from the context.
The notation Jp,lrefers to a block matrix with lblocks each of size d=deg(p(x))
and the entries as follows:
Jp,l=
CpI
CpI
......
......
CpI
Cp
whereCp=
0 0 0 ···0−a0
1 0 0 ···0−a1
0 1 0 0 ··· −a2...............
0···0 1 0 −ad−2
0 0 0 ···1−ad−1

isthecompanionmatrixcorresponding to p(x) =xd+ad−1xd−1+···+a1x+a0. The
matrixJp,lis also referred to as a Jordan matrix corresponding to p(x) andl. Let
L=K(α) bea ﬁeld extension that hasa root αofp(x). Then, we consider the map
R:Ml(L)→Mld(K) induced by the left-multiplication map by αonLoverK.
Clearly, this map is a ring homomorphism and maps the matrix Jα,ltoJp,l. Under
the homomorphism Rwe can carry forward a solution of f(X1,X2,...,Xm) =Jα,l
to that off(X1,X2,...,Xm) =Jp,l. This argument can be used to reduce the
problem of ﬁnding the solution to that of Jordan matrices Jα,lfor allαin various
extensions of K. We can summarise this as follows:
Proposition 2.1. LetKbe a ﬁeld and A∈Mn(K)with a separable characteristic
polynomial. Then, the equation f(X1,X2,...,Xm) =AinMn(K)has a solu-
tion iff(X1,X2,...,Xm) =Jα,lhas a solution in Ml(K(α))for allαwhich are
eigenvalues of Aover¯K.
WeusethistoreducetheproblemtosolveEquation1.1tothatforJo rdanmatrices.
We demonstrate this by an example.
Example 2.2. Consider
0−1 1 0
1 0 0 1
0−1
1 0
overRwith characteristic polynomial
(T2+1)2which becomes/parenleftigg
ι1
ι/parenrightigg
overC. We can write this as a sum of squaresSURJECTIVITY OF POLYNOMIAL MAPS ON MATRICES 5
overCas follows:/parenleftigg
ι1
0ι/parenrightigg
=/parenleftigg
ζ8ζ−1
8
0 0/parenrightigg2
+/parenleftigg
0 0
0ζ8/parenrightigg2
whereζ8=e2π
8ι= cos2π
8+ιsin2π
8=c+ιswhich gives us

0−1 1 0
1 0 0 1
0−1
1 0
=
c−s c s
s c−s c
0 0
0 0
2
+
0 0 0 0
0 0 0 0
c−s
s c
2
.
Our goal is to show Theorem 1.1 which solves Equation 1.1. This require s to
understand if the equation δXk1+βYk2=Ahas a solution in Mn(K) for a given
A∈Mn(K). We note that without loss of generality, we may assume δ= 1. Thus,
because of Proposition 2.1 our problem gets reduced to the following :
Proposition 2.3. The equation Xk1+βYk2=Ahas a solution in Mn(K)if
the equation Xk1+βYk2=Jα,lhas a solution in Ml(K(α))for allαwhich are
eigenvalues of Aover¯Kandl≥1.
In view of this, we will explicitly deal with the equation
Xk1+βYk2=A (2.1)
withβ/\⌉}atio\slash= 0 in the following two cases for Aandn≥1:
•the invertible case when A=Jα,nwhereα/\⌉}atio\slash= 0, and
•the nilpotent case when A=J0,n
in theSection 3. Wefurther note that Ais invertible if and only if none of the pi(x)
(appearing in the factorization of the minimal polynomial) are the poly nomialx,
i.e., in the extension ﬁelds we need to deal with Jα,nwithα/\⌉}atio\slash= 0.
3.Diagonal word
In this section, we look at Equation 2.1. Without loss of generality, we may
assumek1≥k2≥2. Note that if one of the ki= 1 then the equation always has
a solution.
3.1.Invertible Elements in the image. We begin with considering A=Jα,n,
i.e, ifXk1+βYk2=Jα,nwithα/\⌉}atio\slash= 0 has a solution in Mn(K). We have the
following:6 PANJA S., SAINI P., AND SINGH A.
Lemma 3.1. Letk1,k2be integers and α∈K∗. Suppose the equation Xk1+βYk2=
αhas two solutions (a,b)and(c,d)satisfyingak1/\⌉}atio\slash=ck1andbk2/\⌉}atio\slash=dk2overK.
Then, the equation Xk1+βYk2=Jα,nhas a solution in Mn(K)swhereMn(K)s
denotes the set of diagonalisable matrices.
Proof.Forn= 1 we are already given the required solution. So, we may assume
n≥2. We have solutions ( a,b),(c,d)∈K×Ksuch thatak1/\⌉}atio\slash=ck1andbk2/\⌉}atio\slash=dk2,
α=ak1+βbk2andα=ck1+βdk2. With this in mind, we consider the following
block diagonal matrices,
(1) whennisevenGn=/circleplustext
n
2/parenleftigg
ak11
0ck1/parenrightigg
andHn= (βbk2)/circleplustext
n−2
2/parenleftigg
βdk21
0βbk2/parenrightigg
/circleplustext(βdk2),
(2) whennisoddGn=/circleplustext
n−1
2/parenleftigg
ak11
0ck1/parenrightigg
/circleplustext(ak1)andHn= (βbk2)/circleplustext
(n−1)
2/parenleftigg
βdk21
0βbk2/parenrightigg
.
Thus, we get Jα,n=Gn+Hn. Sinceak1/\⌉}atio\slash=ck1, andbk2/\⌉}atio\slash=dk2, we get that GnandHn
both are diagonalisable matrices, in fact, similar to diag {ak1,ck1,ak1,ck1,...}and
βdiag{bk2,dk2,bk2,dk2...}respectively. Clearly, Gnis similar to a matrix which is
k1-power of a diagonal matrix, and Hnis similar to βtimesk2-power of a diagonal
matrix. Hence Jα,n=Bk1+βCk2whereB,C∈Mn(K)s. /square
We can use Proposition 2.1 with this Lemma to show when invertible eleme nts are
in the image of the diagonal word map. Suppose A∈Mn(K) with a separable
characteristic polynomial and each eigenvalue of Aover¯Ksatisﬁes the properties
of the Lemma above then Ais in the image.
Remark 3.2. We note that the above proof works for α= 0 too as long as we
have required solutions over K.
Here is an example that the image of ωcould have nilpotent elements.
Example 3.3. Considerω:M2(K)s×M2(K)s→M2(K) given by ω(x1,x2) =
x2
1+x2
2. Supposechar(K)/\⌉}atio\slash= 2, andX2+1 = 0 has a solution in K, sayι, then we
can write/parenleftigg
0 1
0 0/parenrightigg
=/parenleftigg
11
2
0 1/parenrightigg2
+/parenleftigg
ι0
0ι/parenrightigg2
. In the case char(K) = 2 we can write
/parenleftigg
0 1
0 0/parenrightigg
=/parenleftigg
1 0
0 0/parenrightigg2
+/parenleftigg
1 1
0 0/parenrightigg2
.
3.2.Jordan nilpotent elements in the image when n >2k1.Now we are
interested in getting nilpotent elements in the image of Xk1+βYk2. We assumeSURJECTIVITY OF POLYNOMIAL MAPS ON MATRICES 7
k1≥k2. We show that the large-size nilpotents are always in the image. We re call
the notion of the Junction matrix from Section 5 of [18].
Deﬁnition 3.4. Letn≥1 be a positive integer. Let ( n1,n2,...,nk) be partition
ofnwith 1≤n1≤n2≤...≤nk. The Junction matrix associated with the given
partition of n is
J(n1,n2,...,nk):=en1,n1+1+e(n1+n2),(n1+n2+1)+···+e(n1+n2+...+nk−1),(n1+n2+...+nk−1+1)
whereei,jis the matrix with 1 at ijthplace and 0 elsewhere.
We begin with the following:
Lemma 3.5. Supposen≥2k, and(n1,n2,...,nk)be partition of nwith allni≥2.
Then, the junction matrix J(n1,n2,...,nk)=β.Bkfor someB∈Mn(K).
Proof.Let{e1,e2,...,en}be the standard basis of Knand the matrix J(n1,n2,...,nk)
correspondstoalineartransformationgivenbymapping e(n1+n2+···+ni+1)toe(n1+n2+···+ni)
and others to 0. Reordering the basis elements to
{e1,e2,...,eni−1,eni+2,...,en,en1,e(n1+1),e(n1+n2),e(n1+n2+1),...,
e(n1+n2+···+nk−1),e(n1+n2+···+nk−1+1)}
gives a conjugate of the junction matrix J(n1,n2,...,nk), sayC. The matrix
C=
/circleplusdisplay
n−2(k−1)J0,1
/circleplusdisplay/parenleftigg/circleplusdisplay
k−1J0,2/parenrightigg
.
We can also see that Cis conjugate to βCasCis a nilpotent matrix. Hence,
J(n1,n2,...,nk)is conjugate to βC. Now consider B=/parenleftigg
/circleplustext
n−(2k−1)J0,1/parenrightigg
/circleplustextJ0,2k−1and
by Lemma 6.1 of [18], Bkis conjugate to C. Therefore, J(n1,n2,...,nk)is conjugate to
βBk. /square
Theorem 3.6. Letk1≥k2≥2be positive integers. For n≥2k1the Jordan
nilpotent matrix J0,nis in the image of f(X,Y) =Xk1+βYk2.
Proof.We begin with considering Jk1
0,n. Let us denote n′=⌊n
k1⌋andn′′=⌈n
k1⌉.
Sincen≥2k1, we haven′′≥n′≥2. We ﬁnd msuch thatm≡n(modk1)
and 0≤m≤k1. Then, from Miller’s Lemma (Lemma 2 [30]) we get that Jk1
0,nis
conjugate to
JF(Jk1
0,n) =/parenleftigg/circleplusdisplay
k1−mJ0,n′/parenrightigg/circleplusdisplay/parenleftigg/circleplusdisplay
mJ0,n′′/parenrightigg
.8 PANJA S., SAINI P., AND SINGH A.
Now, weconsider J=J0,n−JF(Jk1
0,n). Thematrix Jisajunctionmatrixassociated
to the following partition of n:
n′,...,n′
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
k1−m,n′′,...,n′′
/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
m
. From the Lemma 3.5 it
follows that Jis conjugate to βBk2. This completes the proof. /square
Thus, all nilpotent matrices of index ≥2k1are in the image.
3.3.Nilpotent elements in the image. Now we develop another method to get
nilpotent matrices in the image depending on the existence of solution s of certain
equations over the base ﬁeld. Let us begin with the following n-by-nmatrix for
n≥3 andǫ/\⌉}atio\slash= 0 inK,
M=M(ǫ,x,y,z) =/parenleftigg
ǫJ0,(n−1)tx
yz/parenrightigg
overtheﬁeld Kwherex= (x1,x2,...,xn−1)andy= (y1,y2,...,yn−1)areelements
ofKn−1andtxdenotes the transpose of the vector x. Note that ǫJ0,(n−1)is
conjugate to J0,(n−1). The characteristic polynomial of Mis
χM(T) =Tn−zTn−1−/parenleftiggn−1/summationdisplay
i=1xiyi/parenrightigg
Tn−2−ǫ/parenleftiggn−1/summationdisplay
i=2xiyi−1/parenrightigg
Tn−3−··· (3.1)
−ǫj−2/parenleftiggn−1/summationdisplay
i=j−1xiyi−j+2/parenrightigg
Tn−j−···−ǫn−3(xn−2y1+xn−1y2)T−ǫn−2xn−1y1.
We wish to understand when Mis akpower regular semisimple element (i.e., with
distinct diagonal entries). We recall that the elementary symmetr ic polynomials
are
Ei(X1,...,Xn) =/summationdisplay
1≤j1<j2<···<ji≤nXj1Xj2···Xji
and/producttextn
r=1(T−xr) =Tn−E1(x1,...,xn)Tn−1+···+(−1)nEn(x1,...,xn).
Deﬁnition 3.7. LetKbe a ﬁeld and λ1,...,λnbe a solution of Xk
1+Xk
2+···+
Xk
n=αoverK. We say the solution is regular ifλk
i/\⌉}atio\slash=λk
jfori/\⌉}atio\slash=j. Further, if
none of the λiare 0 we say the solution is non-zero regular.
Note that if 0 appears in a regular solution then it can appear at most once. We
have the following,
Lemma 3.8. Letn≥3, andµ1,...,µnbe a regular solution of Xk
1+Xk
2+···+Xk
n=
zoverK. Then, for a given ywithy1/\⌉}atio\slash= 0(similarly for a given xwithxn−1/\⌉}atio\slash= 0)SURJECTIVITY OF POLYNOMIAL MAPS ON MATRICES 9
there exists x(respectively y) such that the matrix M(ǫ,x,y,z)is conjugate to the
kpower regular semisimple element diag(µk
1,...,µk
n).
Proof.Let us write M=M(ǫ,x,y,z) and we have expression for χM(T) in the
Equation 3.1. We require χM(T) = (T−µk
1)(T−µk
2)···(T−µk
n) which leads to
having a solution to the following system of equations:
z=E1(µk
1,...,µk
n) =/summationdisplay
µk
i
x1y1+···+xn−1yn−1=−E2(µk
1,...,µk
n)
x2y1+x3y2+···+xn−1yn−2=ǫ−1E3(µk
1,...,µk
n)
... =...
xn−2y1+xn−1y2= (−1)nǫ−(n−3)En−1(µk
1,...,µk
n)
xn−1y1= (−1)n+1ǫ−(n−2)En(µk
1,...,µk
n) = (−1)n+1ǫ−(n−2)/productdisplay
µk
i.
Clearly, the ﬁrst equation is satisﬁed. We write the remaining equatio ns in matrix
form as follows:
y1y2···yn−1
0y1···yn−2
.........
0 0···y1

x1
x2
...
xn−1
=
−E2(µk
1,...,µk
n)
...
(−1)n+1ǫ−(n−2)µk
1···µk
n
.
Sincey1/\⌉}atio\slash= 0 the matrix is invertible and we have a solution.
Now, we can also write the above equations taking the bottom one ﬁr st and
thinking of yias variables as follows:

xn−10···0
xn−2xn−1···0
.........
x1x2···xn−1

y1
y2
...
yn−1
=
(−1)n+1ǫ−(n−2)µk
1···µk
n
...
−E2(µk
1,...,µk
n)
.
Sincexn−1/\⌉}atio\slash= 0 we have a solution to this equation. /square
Corollary 3.9. Letn≥3,λ1,...,λnbea regular solution of Xk
1+Xk
2+···+Xk
n= 1
overKandǫ∈K∗withǫ/\⌉}atio\slash=−1. Then, the matrix M(ǫ,(1 +ǫ)en−1,y,1)is a
kpower regular semisimple element where yi=(−1)n−i
(1+ǫ)En−i+1(λk
1,...,λk
n−1)and
en−1= (0,...,0,1).
Corollary 3.10. Letn≥3,µ1,...,µnbe a regular solution of Xk
1+Xk
2+···+Xk
n=
−1
βoverKwithµn= 0. Then, for a given ywithy1/\⌉}atio\slash= 0there exists xwith10 PANJA S., SAINI P., AND SINGH A.
xn−1= 0such that the matrix M(1,x,y,−1)is conjugate to βtimes akpower
regular semisimple element.
Proof.The proof follows along the similar lines as for the Lemma 3.8 by equating
χM(T) to (T−βµk
1)···(T−βµk
n) by noting that the equation xn−1y1= 0 will
ensurexn−1= 0. /square
Theorem 3.11. Letn≥3andKbe a ﬁeld with |K|>2and suppose
(1) the equations Xk1
1+Xk1
2+···+Xk1n= 1has a regular solution, and
(2) in addition, for n≥3,Xk2
1+Xk2
2+···+Xk2
n−1=−1
βhas a non-zero regular
solution.
Then, the nilpotent matrix J0,nis in the image of f(X,Y) =Xk1+βYk2.
Proof.It is enough to show that the Jordan nilpotent matrix J0,nis in the image
off(X,Y) =Xk1+βYk2. Letǫ∈K∗such that 1+ ǫ/\⌉}atio\slash= 0. We write
M(ǫ,(1+ǫ)en−1,y,1)+M(1,x,−y,−1) =/parenleftigg
(1+ǫ)J0,(n−1)(1+ǫ)ten−1+tx
0 0/parenrightigg
whereen−1= (0,...,0,1) andx= (x1,...,xn−2,0). The matrix on the right-
hand side is conjugate to J0,n. The ﬁrst matrix on the left side is k1th power of
a diagonalisable matrix (follows from Corollary 3.9). It also ensures y1/\⌉}atio\slash= 0. The
second matrix is βtimes ak2th power of a diagonalisable matrix (follows from
Corollary 3.10). /square
Theorem 3.12. LetKbe a ﬁeld with |K|>2. Suppose the equation Xk2
1+Xk2
2=
−1
βhas a regular solution. Then, the nilpotent matrix J0,2is in the image of
f(X,Y) =Xk1+βYk2.
Proof.Let (λ1,λ2) be a regular solution of Xk1
1+Xk1
2=−1
β. We write
/parenleftigg
0 1
0 0/parenrightigg
=/parenleftigg
0 0
y1/parenrightigg
+β/parenleftigg
01
β
−y
β−1
β/parenrightigg
.
Now, the ﬁrst matrix on the right is an idempotent and hence is k1-th power of
itself. For the second matrix to conjugateto diag( λk2
1,λk2
2), we needλk2
1+λk2
2=−1
β
andλk2
1λk2
2=y
β. Determining ygives us the desired result. /square
4.Image of diagonal polynomial over CandFq
We use the results obtained in the previous section to obtain some su rjectivity
results over particular ﬁelds for the diagonal word map.SURJECTIVITY OF POLYNOMIAL MAPS ON MATRICES 11
4.1.Diagonal polynomial over C.Wedemonstrate anapplicationofourearlier
results. Note that this result will still hold for any algebraically closed ﬁeld of
characteristic 0, but we choose to state it for C.
Theorem 4.1. LetK=Candk1,k2≥1be integers and βbe a non-zero element
inC. Then, the map ω:Mn(C)s×Mn(C)s→Mn(C)given byω(x1,x2) =xk1
1+
βxk2
2, whereMn(C)sis the set of semisimple matrices, is surjective.
Proof.LetAbe inMn(C). Then, the Jordan canonical form of Ais the direct
sum of the Jordan matrices Jα,lwhereα∈C. Now, we look at the equation
Xk1+βYk2=αoverC. Take any a,c∈Csuch thatak1/\⌉}atio\slash=ck1and consider
the equations βYk2=α−ak1andβYk2=α−ck1. We can easily ﬁnd solutions
required in the Lemma 3.1, thus Jα,lis in the image. The same argument works
for Jordan nilpotent matrices in the view of remark 3.2 (or alternativ ely we can
use Theorem 3.11, 3.12 for α= 0 case). This proves the required result. /square
Corollary 4.2. Letm≥2, andω:Mn(C)m→Mn(C)givenbyω(x1,x2,...,xm) =
δ1xk1
1+δ2xk2
2+···+δmxkmm. Then,ω(Mn(C)s) =Mn(C). Thus,ωis surjective.
4.2.Over ﬁnite ﬁeld. The result in this section is a generalisation of that in [18].
The proof is along similar lines too thus we keep it short.
The proof relies on having enough solutions of the equation Xk1+βYk2=cover
the ﬁeld Fq, for large enough q. The solution of polynomial equations over ﬁnite
ﬁelds has a long history with some fundamental results such as the C hevalley-
Warning theorem and Lang-Weil bound etc. We begin with some of the se results
regarding the number of solutions which will be used in the main proof. We recall
a version of Lang-Weil theorem [28, Theorem 5A].
Theorem 4.3. Consider the polynomial equation δ1Xk1
1+···+δmXkmm= 1where
δi∈F∗
qandki>0for alli. Then the number of solutions Sof this equation in
Fm
qsatisﬁes
|S−qm−1| ≤k1k2···kmqm−1
2/parenleftbigg
1−1
q/parenrightbigg−m/2
.
The next lemma is along a similar line as Proposition A.3 [18].
Lemma 4.4. Fork1≥k2≥2andα,β∈F×
q, consider the polynomial
F(X1,X2) =Xk1
1+βXk2
2−α.
Then, forq > k4
1k4
2, there exists solutions (a,b)and(c,d)toF(X1,X2) = 0such
thatak1/\⌉}atio\slash=ck1andbk2/\⌉}atio\slash=dk2.12 PANJA S., SAINI P., AND SINGH A.
Proof.By Theorem 4.3, we have the following inequality about the number of
solutionsSof the equation F(X1,X2) = 0 andm= 2,
|S−q| ≤k1k2√q/parenleftbiggq
q−1/parenrightbigg
.
Observe thatq
q−1≤2≤k1. Therefore, we have |S−q| ≤k2
1k2√q. Suppose ( a,b)
and (c,d) are solutions of F(X1,X2) = 0. Ifak1=ck1, thenF(X1,X2) = 0 has at
mostk2
2solutions as ( a,ζk2b) and (c,ζk2d), whereζk2refers to a root of unity if it
exists, are also the possibility for solutions. Similarly, for bk2=dk2, there are at
mostk2
1solutions possible. So, we need to have
S≥q−k2
1k2√q≥k2
1+k2
2+1
i.e., we want√q(√q−k2
1k2)≥k2
1+k2
2+1. For this to besatisﬁed, it suﬃces to have√q>k2
1k2
2. In that case, we get√q(√q−k2
1k2)>√q >k2
1k2
2≥4k2
1≥k2
1+k2
2+1
ask2≥2. /square
Corollary 4.5. Letk1,k2≥1be integers and α∈F∗
q. Then, there exist a constant
N1(depending on k1andk2only) such that for all q >N1, the matrix Jα,n∈
Mn(Fq)can be written as Bk1+βCk2for someB,C∈Mn(Fq)both diagonalisable.
Proof.Using Lemma 4.4, there exists a constant N1(depending on k1,k2only)
such that for q >N1, andα∈F×
q, there exist solutions ( a,b),(c,d)∈F2
qsuch that
ak1/\⌉}atio\slash=ck1andbk2/\⌉}atio\slash=dk2,α=ak1+βbk2andα=ck1+βdk2forq >N1. Now we
can simply use the Lemma 3.1 to get the required solution. /square
Now, we recall Proposition 2.3 from [17] and Proposition A.2 from [18] w hich
guarantees regular solutions to certain equations over Fq.
Lemma 4.6. Letγ∈F∗
qandn≥2be an integer. Then, there exists a constant N2,
depending on kandn, such that for all q>N2the equation Xk
1+Xk
2+···+Xk
n=γ
has a regular solution over Fq. In fact, it always has a non-zero regular solution
whenn≥3.
Proposition 4.7. Let|K|>2. For every integer k1≥k2≥1, andβ∈F∗
qthere
exists a constant N3, depending on k1,k2andnonly, such that for all q>N3the
Jordan nilpotent matrix J0,nis in the image of Xk1+βYk2.
Proof.In view of Lemma above the required hypothesis of Theorem 3.12 and 3.11
are satisﬁed if q >N3. Note that N3is the maximum of the constants required
in the hypothesis of the referred Theorems for various choices of k1andk2for
diﬀerentn. Thus, we have the required result. /squareSURJECTIVITY OF POLYNOMIAL MAPS ON MATRICES 13
Now we are ready to prove the main result of this section,
Theorem 4.8. Letk1,k2≥1andn≥2be integers and βbe a non-zero element
in the ﬁnite ﬁeld Fq. Consider the map ω:Mn(Fq)×Mn(Fq)→Mn(Fq)given by
ω(x1,x2) =xk1
1+βxk2
2. Then, there exists a constant N(k1,k2)(which depends
only onk1andk2) such that for all q >N(k1,k2), the mapωis surjective.
Proof.In the view of Proposition 2.1 the problem is reduced to dealing with Jα,l
for all extensions of Fqwherel≤n. The case of α/\⌉}atio\slash= 0 is covered by Corollary 4.5
for allq>N1whereN1depends on k1andk2only. The case of J0,lforl>2k1is
covered by Theorem 3.6 which works for any q. For the case of J0,lwithl≤2k1
we use Proposition 4.7 which works for q >N2depending on k1,k2andlas well.
Thus, if we take q>NwhereNis the maximum of N1and various N2forl<2k1
(which are ﬁnitely many) we get the result. Note that Ndepends on k1andk2
only. /square
Corollary 4.9. Form≥2, there exists a constant Ndepending only on k1,...,km
such thatfor all q >Nthe mapω:Mn(Fq)m→Mn(Fq)givenbyω(x1,x2,...,xm)/ma√sto→
δ1xk1
1+δ2xk2
2+···+δmxkmmis surjective.
5.Image of diagonal word over R
In this section, we consider the diagonal polynomials with coeﬃcients inRand
look at its image over Mn(R). Our main theorems in this section are as follows:
Theorem 5.1. LetK=R,k1≥k2≥k3≥1be integers and β,γbe non-zero
elements in R. Then, the map ω:Mn(R)3→Mn(R)given byω(x1,x2,x3) =
xk1
1+βxk2
2+γxk3
3is surjective.
Theorem 5.2. LetK=R,k1≥k2≥1be integers and β >0inR. Then, the
mapω:Mn(R)×Mn(R)→Mn(R)given byω(x1,x2) =xk1
1+βxk2
2is surjective if
and only if one of the following holds
(i)nis even,
(ii)nis odd and one of the k1ork2is odd.
Further, when nis odd andk1,k2both are even the image is Mn(R)\{λIn|λ<0}.
We may assume that all of the coeﬃcients of the diagonal polynomial are positive.
That is, we are dealing with δ1xk1
1+δ2xk2
2+···+δmxkmmwhereδi>0 real for all
i. Because for xk1
1+βxk2
2withβ <0, following a similar argument as for Cin
Section 4.1, the equations required in the Theorem 3.11, 3.12 have so lutions over14 PANJA S., SAINI P., AND SINGH A.
R, hence the map given by xk1
1+βxk2
2would be surjective. In fact, without loss
of generality, we may assume that δi= 1 asδi>0 has aki-th root. Thus in what
follows, we will be dealing with the map given by xk1
1+xk2
2+···+xkmm. The rest
of the section is devoted to the proof of these statements.
We begin by recalling a result from Richman (see Theorem 6 [25]) which a lso
uses the work of Griﬃn and Krusemeyer from [9]:
Theorem 5.3 (Richman, Griﬃn-Krusemeyer) .Letkbe a ﬁeld with characteristic
not equal to 2andnbe odd. Then, a scalar matrix cIn∈Mn(K)is a sum of two
squares if and only if cis a sum of two squares in K.
Thus in view of this, we have,
Corollary 5.4. Letnbe odd andk1,k2both even. Suppose β >0is a real number.
Then, a scalar matrix λIn∈Mn(R)forλ <0can not be written as Ak1+βBk2
whereA,B∈Mn(R).
Proof.If we can write λIn∈Mn(R) asAk1+βBk2thenλIn∈Mn(R) is also a
sum of two squares in Mn(R), and then by the above Theorem of Richman λis a
sum of two squares. This is not possible for λ<0. /square
The rest of the proof is devoted to essentially showing that these a re the only
exceptions. The proof will be divided into three cases:
Case 1: When one of the k1ork2is odd.
Case 2: Both k1andk2are even and nis even.
Case 3: Both k1andk2are even and nis odd.
5.1.Case 1 when one of the k1ork2is odd:The proof when k1ork2is odd is
simpler. Let A∈Mn(R). Then,Ais conjugate to the direct sum of Jordan blocks
(1)Jα,lwhereα≥0 inR,
(2)Jα,lwhereα<0 inR, and
(3)Jp(x),lwherep(x) is degree 2 irreducible polynomial over R.
Using Proposition 2.1 we can realise Jp(x),lof the kind Jλ,lfor someλ∈Cwhere
we can use Theorem 4.1 to prove the result. Thus, we need to deal w ithJα,lwhere
α∈R. We may assume k2is odd. Note that when α/\⌉}atio\slash= 0, we are done using
Lemma 3.1 as the equation Xk1+Yk2=αhas required solutions (in the view of
k2being odd).
Whenα= 0 we can use Theorem 3.11 and 3.12 to get the result as we have
solutions of required kind over R(once again in view of k2being odd).SURJECTIVITY OF POLYNOMIAL MAPS ON MATRICES 15
5.2.Case 2 when nis even and k1,k2both even: Inthiscase, wewish to show
that the equation p(x1,x2) =xk1
1+xk2
2=AwhereAis inMn(R) andnis even,
always has a solution in Mn(R). Since the equation is closed under conjugation we
may consider Ain its canonical form. The blocks appearing in the canonical form
ofAwill be as follows:
(1)Jα,2mwhereα∈Randm≥1.
(2)Jα1,2m1−1⊕Jα2,2m2−1forα1,α2∈Randm1,m2≥1 (because nis even).
(3)Jf(x),mwherefis an irreducible polynomial of degree 2 over R, and the
particular case m= 1 refers to the 2 ×2 companion matrix Cf.
Denoteτm= (τ⊕τ⊕···⊕τ)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright
m−timeswhereτ=/parenleftigg
cosπ
k1−sinπ
k1
sinπ
k1cosπ
k1/parenrightigg
thenτk1m=−I2m.
Thus, for a real number ξ >0,/parenleftig
ξ1
k1τm/parenrightigk1
=−ξI2m. Also, we note that for ξ >0
andη=ξ1
k2, the Jordan matrix Jη,shas the property that ( Jη,s)k2is conjugate to
Jξ,s.
In view of the discussion above we need to deal with the three kinds o f blocks.
In each of these cases, we show that the matrix is in the image of ω(x1,x2).
(1) Whenα >0, we know Jα,2mhask1-th root, so we are done. When α≤0
pickψ>0 such that ψ+α>0, we write
Jα,2m=−ψI2m+J(α+ψ),2m=/parenleftig
ψ1
k1Tm/parenrightigk1+J(α+ψ),2m.
Now,notethat Jα+ψ,2misak2-thpowerasitisaconjugateof/parenleftig
Jk2√
(α+ψ),2m/parenrightigk2.
(2) In the case of Jα1,2m1−1⊕Jα2,2m2−1if bothα1,α2are positive it has k1-th
root. Else, we pick ψ>0 such that ψ+α1>0 andψ+α2>0 and write
Jα1,2m1−1⊕Jα2,2m2−1=−ψI2(m1+m2−1)+(Jα1+ψ,2m1−1⊕Jα2+ψ,2m2−1).
Now,−ψI2(m1+m2−1)is ak1-th root and Jα1+ψ,2m1−1⊕Jα2+ψ,2m2−1is ak2-th
root.
(3) In this case we can use Lemma 3.1 and go over the extension Cwhere we
can ﬁnd the solution and realise it over R.
5.3.Case 3 when nis odd and k1,k2both even: In this case, we wish to
show that the equation p(x1,x2) =xk1
1+xk2
2=AwhereAis inMn(R) andnis
odd, has a solution in Mn(R) except when Ais a negative scalar matrix. The fact
that negative scalars are not in the image follows from Corollary 5.4. S ince the16 PANJA S., SAINI P., AND SINGH A.
equation is closed under conjugation we can work with the canonical form ofA.
The canonical form of Ais a direct sum of the following:
(1)Jα1,l1⊕Jα2,l2⊕···⊕Jαr,lrwhereαi∈Randlieven.
(2)Jα1,l1⊕Jα2,l2⊕···⊕Jαs,lswhereαi∈Randliodd (smust be odd as nis
odd).
(3)⊕Jfi(x),mwherefiis an irreducible polynomial of degree 2 over R. The
particular case i= 1,m= 1 refers to the 2 ×2 companion matrix Cf.
We ﬁrst prove some Lemma.
Lemma 5.5. Letm≥3. Letd1,d2,...,dmbe non-negative reals. Consider the
matrix
M=
−d11
−d21
−d31
......
−dm−11
−a1−a2··· ··· − am−1−(dm+1)
∈Mm(R).
Then,ajs can be chosen in such a way that the matrix Misk-th power of some
diagonalizable matrix in Mm(R).
Proof.The characteristic polynomial of Mis given by χM(T)
=Tm+Tm−1/parenleftigg
1+/summationdisplay
1≤i≤mdi/parenrightigg
+Tm−2/parenleftigg/summationdisplay
1≤i1<i2≤mdi1di2+/summationdisplay
1≤i≤m−1di+am−1/parenrightigg
+
Tm−3/parenleftigg/summationdisplay
1≤i1<i2<i3≤mdi1di2di3+/summationdisplay
1≤i1<i2≤m−1di1di2+am−1/parenleftigg/summationdisplay
1≤i≤m−2di/parenrightigg
+am−2/parenrightigg
+
···+T
/summationdisplay
1≤i1<i2<i3<...<i m−1≤mdi1di2...dim−1+···+a3(d1+d2)+a2
+
(d1d2...dm−1(dm+1)+d1d2...dm−2am−1+...+d1a2+a1).
We claim that we can choose λ1,...,λm−2positive reals and λm−1,λm, a pair
of non-real complex conjugates such that χM(T) = (T−λ1)···(T−λm−2)(T−
λm−1)(T−λm) andλi/\⌉}atio\slash=λjfor alli/\⌉}atio\slash=j. This will help us ensure that Mis
conjugate to a regular semisimple element which is k-th power. For this, we needSURJECTIVITY OF POLYNOMIAL MAPS ON MATRICES 17
to solve the following system of equations,
/summationdisplay
1≤i≤mdi+1 =−E1(λ1,λ2...,λm),
/summationdisplay
1≤i1<i2≤mdi1di2+/summationdisplay
1≤I≤m−1di+am−1= (−1)2E2(λ1,...,λm−1,λm),
/summationdisplay
1≤i1<i2<i3≤mdi1di2di3+/summationdisplay
1≤i1<i2≤m−1di1di2+am−1/parenleftigg/summationdisplay
1≤i≤m−2di/parenrightigg
+am−2
= (−1)3E3(λ1,...,λm−1,λm),
...
/summationdisplay
1≤i1<i2<i3<...<i m−1≤mdi1di2...dim−1+...+a3(d1+d2)+a2
= (−1)m−1Em−1(λ1,...,λm−1,λm),
d1d2...dm+d1d2...dm−1+...+a2d1+a1= (−1)mE(λ1,...,λm−1,λm).
Now, we simply pick λ1,...,λm−2positive reals and λm−1,λma pair of non-real
complex conjugate such that
−/summationdisplay
1≤i≤mdi−1 =E1(λ1,...,λm−2,λm−1,λm) =m−2/summationdisplay
i=1λi+λm−1+λm
andλi/\⌉}atio\slash=λjfor alli/\⌉}atio\slash=j. This ensures each λifor 1≤i≤m−2 has a real k-th
root. Further note that when kis even the real part of λmhas to be negative and
we will see that the requirement of k-th root forces a pair of complex conjugates.
Wenotethatsince λm−1andλmareapairofcomplexconjugatethe Ej(λ1,...,λm)
are inR. Thus, the above equations determine the value of ajwhich are real num-
bers. This proves that we can choose ajin such a way that Mis conjugate to
˜M=diag(λ1,...,λm−2)⊕Cfwhereλiare positive reals and Cfis companion
matrix of the real polynomial T2−(λm−1+λm)T+λm−1λm. Clearly, ˜Mhas ak-th
root inMm(R) because scalars on the diagonal are positive and the 2 ×2 block
can be thought of as an element in C. HenceMis ak-th power. /square
Next we have the following,18 PANJA S., SAINI P., AND SINGH A.
Lemma 5.6. Letn≥3andd1,...,dnbe non-negative reals. Consider the matrix
T∈Mn(R)as follows:
T=
−d11
−d21
......
......
−dn−11
−dn
.
Then, there exist matrices BandCinMn(R)such thatT=Bk1+Ck2.
Proof.Let us consider a matrix B=
0 0··· 0
0 0··· 0
a1a2···an−11
and observe that
Bk1=B. Now, from Lemma 5.5 we can choose a1,...,an−1such that the matrix
T−B, which is in the required form, is k2-th power, say Ck2. ThusT=Bk1+
Ck2. /square
Proposition 5.7. Letnbe odd and A∈Mn(R). Suppose the odd-size Jordan
blocks appearing in the canonical form of Aare all of the size ≥3. Then,Ais in
the image of xk1
1+xk2
2.
Proof.The Jordan blocks of the kind Jα,2landJf(x),lcan be taken care of as in the
Subsection 5.2 as they are of even size. For the Jordan blocks of th e kindJα,2l−1
we can use Lemma 5.6 as they are of size ≥3. /square
Lemma 5.8. All diagonal matrices in Mm(R), whenmis even, and the diagonal
matrices with at least 2distinct diagonals, when mis odd, are in the image of
xk1
1+xk2
2.
Proof.Whenmis even the diagonal matrices belonging to the image are covered
in Section 5.2. Now for modd, we are done if even one of the diagonal entries
is positive. So, we may assume all of the diagonal entries are negativ e. We need
to deal with diag( λ1,λ2,λ3,...) whereλi<0 for alliandλ1/\⌉}atio\slash=λ2. Note that
diag(λ1,λ2,λ3,...) is similar to
λ11
λ2
λ3
...
(becauseλ1/\⌉}atio\slash=λ2).SURJECTIVITY OF POLYNOMIAL MAPS ON MATRICES 19
Now, we consider the matrix L=/parenleftigg
0 0
a1a0/parenrightigg
and note that
M:=/parenleftigg
λ11
λ2/parenrightigg
−Lk1=/parenleftigg
λ1 1
−a1ak1−1
0λ2−ak1
0/parenrightigg
.
We claim that we can choose a0anda1such that the characteristic polynomial of
the above matrix MisχM(T) = (T+λ1)(T−µ) withµ/\⌉}atio\slash=−λ1. For this we need
to have−λ1+µ=λ1+λ2−ak1
0and−λ1µ=λ1(λ2−ak1
0) +a1ak1−1
0. The ﬁrst
equation would require ak1
0= 2λ1+λ2−µwhich can be solved by choosing µso
that 2λ1+λ2−µ>0 (this means µ<2λ1+λ2<0≤ −λ1). The second equation
givesa1. Thus, we can make Msimilar to diag( −λ1,µ) withµ/\⌉}atio\slash=−λ1. Hence,
˜M:=
λ11
λ2
λ3
...
−
L
0
...
k1
is similar to diag( −λ1,µ,λ3,...) where−λ1>0. Now, ˜Mhas one of the diagonal
entries positive (and remaining part is even size) so it is a k2-th power by the
earlier argument. This completes the proof. /square
Lemma 5.9. Letl >1andα,ξ∈R. The matrices Jα,2l⊕(ξ)andJf,l⊕(ξ)are
in the image of xk1
1+xk2
2.
Proof.First we deal with Jα,2l⊕(ξ). From the argument in Section 5.2 we know
thatJα,2lis in the image of xk1
1+xk2
2and hence if ξ >0 (it has roots) we are done.
Thus, we may assume ξ <0.
Writem= 2lfor simplicity and consider w1,w2,...,wm∈Rsuch thatw1/\⌉}atio\slash=
0. TakeLto be a matrix with ﬁrst m−1 rows 0 and the last row to be
(wm,wm−1,...,w 1). Then,
Jα,m−Lk1=
α 1 0 ···0
0 α 1···0
...............
... ··· ··· α1
−wmwk1−1
1−wm−1wk1−1
1··· ···α−wk1
1
.
We claim that we can choose w1,w2,...,wmin such a way that the characteristic
polynomial of Jα,m−Lk1is (X+ξ)m−1(X−λ) withλ/\⌉}atio\slash=−ξ. Following a similar20 PANJA S., SAINI P., AND SINGH A.
calculation as in the proof of Lemma 5.5, we need to ensure tr(Jα,m−Lk1) =
−(m−1)ξ+λ, that is,mα−wk1
1=−(m−1)ξ+λ. Thus, we need to have a
solution for wk1
1=mα+(m−1)ξ−λwhich can be insured by choosing λ<0, in
fact takeλ<ξ <0. This allows us that Jα,m−Lk1is conjugate to M1⊕(λ) where
only eigen values of M1is−ξwhich is positive. Thus, M1=Mk2for someM.
Now, let us write uk1=ξ−λ>0 andλ=−vk1. Then,/parenleftigg
Jα,m
ξ/parenrightigg
−/parenleftigg
L
u/parenrightiggk1
=
/parenleftigg
Jα,m−Lk1
ξ−uk1/parenrightigg
is conjugate to
Mk2
λ
λ
. Now all we need to show
is thatλI2is ak2-th power where λ <0. Equivalently, enough to show −I2is a
k2-th power. This can be done using −I=/parenleftigg
cosπ
k2−sinπ
k2
sinπ
k2cosπ
k2/parenrightiggk2
.
Now, let us deal with Jf,l⊕(ξ). Once again, from the argument in Section 5.2
we know that Jf,lis in the image of xk1
1+xk2
2and hence if ξ >0 we are done. We
need to deal with the case when ξ <0.
First, we consider the case of l= 1 withf(x) =x2+b0x+b1andCf:=/parenleftigg
0−b1
1−b0/parenrightigg
∈M2(R). Letw1,w2be two real numbers with w1non-zero. Consider
the matrix L=/parenleftigg
0 0
w2w1/parenrightigg
. Then,
/parenleftigg
Cf
ξ/parenrightigg
−/parenleftigg
L
u/parenrightiggk1
=
0 −b1 0
1−w2wk1−1
1−b0−wk1
10
0 0 ξ−uk1

and we claim that with a choice of w1,w2anduwe can make this a k2-th power.
Note that the characteristic polynomial of Cf−Lk1isT2+(b0+wk1
1)T+b1(1−
w2wk1−1
1). To make Cf−Lk1conjugate to a diagonal matrix diag( −ξ,λ) with
λ/\⌉}atio\slash=−ξwe need to equate trace and determinant, i.e, −ξ+λ=−b0−wk1
1and
−ξλ=b1(1−w2wk1−1
1). We ﬁx,λ<0 such that ξ−λ>0 and−b0+ξ−λ>0,
which ensures, solution for uk1=ξ−λ>0 (to getu) andwk1
1=−b0+uk1. The
second equation gives w2and with this choice of u,w1andw2we get:
/parenleftigg
Cf
ξ/parenrightigg
−/parenleftigg
L
u/parenrightiggk1
=
−ξ
λ
λ
=:M2.SURJECTIVITY OF POLYNOMIAL MAPS ON MATRICES 21
Now,−ξ >0 which has k2-th root and λ<0 we can use the earlier trick on 2 ×2
block by using k2-th root of −Ito get the job done.
Now forl>1, letLbe a size 2 matrix as above for some w1andw2. Consider
Q:=
CfI
CfI
......
CfI
Cf
ξ
−
0 0 0...0 0
0 0 0...0 0
0 0 0...0 0
..................
0 0 0... L0
0 0 0...0u
k1
.
Then, the characteristic polynomial of Qisf(T)l−1(T+ξ)(T−λ)2equal to the
minimal polynomial and hence Qis similar to Jf,l−1⊕M2. SinceJf,m−1isk2−th
power andM2isk2-th power so is Q. This completes the proof. /square
5.4.Proof of the Theorem.
Proof of Theorem 5.2. Whennis even the proof follows from the argument in
Section 5.1 and 5.2. Now, suppose n≥3 is odd and k1,k2is both even. The
negative real scalar matrices are not in the image, as follows from Co rollary 5.4.
It remains to show that every matrix in Mn(R) is in the image of xk1
1+xk2
2unless
it is of the form −λInwhereλis a positive real.
LetA∈Mn(R). From Proposition 5.7 if all odd-size Jordan blocks appearing
in the canonical form of Aare of size ≥3 then we are done. So, we may assume
that the odd-size Jordan blocks are of size 1. Since nis odd there has to be at
least one block of size 1. Now we claim that if Ahas at least 1 even size Jordan
block then Ais in the image. For this we can combine one even-size block with a
size 1 block and use Lemma 5.9 and the remaining parts will be even-size blocks.
Thus, we are left with the case when Ahas no blocks of even size (and no blocks
of odd size ≥3). That is, Ais a diagonal matrix. Once again if Ahas at least 2
distinct entries on the diagonal we are done with Lemma 5.8. Thus, Amust be a
scalar matrix of the form λIn.
/square
Proof of Theorem 5.1. From the proof above all we need to show that λIn
whenλ <0 andnodd is of the form xk1
1+xk2
2+xk3
3. For this we write λIn=
diag(λ,...,λ, 0) + diag(0 ,...,0,λ). Here, the ﬁrst one is k1-th power using τn−1
222 PANJA S., SAINI P., AND SINGH A.
from Section 5.2. For the second one again we use the argument fro m Section 5.2
on/parenleftigg
0
λ/parenrightigg
and write it as a sum of k2andk3powers. /square
6.Images of diagonal polynomial over real quaternions
In this section, we look at the diagonal polynomial over Mn(H) where His
Hamilton’s real quaternion division algebra. We show that the map ω(x1,x2) =
xk1
1+βxk2
2is surjective when β/\⌉}atio\slash= 0. This easily implies the surjectivity of the
diagonal map for all m≥2. The result here is surprisingly easy to obtain due
to the canonical form theory for matrices in Mn(H). We begin with the following
result due to Wiegmann and Liping (See [32, Theorem 1], also [23, Lemma 3]).
Lemma 6.1. Everyn×nmatrix with real quaternion elements is similar under
a matrix transformation with real quaternion elements to a m atrix in (complex)
Jordan normal form with diagonal elements of the form a+bi,b≥0. That is to
say ifA∈Mn(H), thenAis similar to a matrix of the form
J(A) :=Jλ1,n1⊕Jλ2,n2⊕...⊕Jλk,nk,
withλk=ak+ibk∈Cbeing right eigenvalues of A. Furthermore, bk∈Rcan
be chosen to be non-negative. In this decomposition J(A)is uniquely determined
byAup to the order of Jordan blocks Jλk,nk, andJ(A)is said to be the Jordan
canonical form of Acorresponding to maximal subﬁeld CofH.
This Lemma reduces the problem to look for A∈Mn(H) as an image of diagonal
polynomial to that of A∈Mn(C).We call a matrix A∈Mn(H) to be invertible
if there exists B∈Mn(H) such that AB=BA=I. Note that any matrix
A∈Mn(H) has ﬁnitely many conjugacy classes of left eigenvalues (i.e. α∈Hsuch
thatA·v=α·vfor somev∈Hn). Since the number of conjugacy classes in H
are inﬁnite, given any matrix A∈Mn(H), there exists λ∈Hsuch thatλis not a
left eigenvalue of A, and consequently A−λ·Iis invertible (see [27, Proposition
5.3.4]). Now we are ready to state and prove the ﬁnal result of this a rticle.
Theorem 6.2. Let0/\⌉}atio\slash=β∈H. Then the map ω(x1,x2) =xk1
1+βxk2
2is surjective
onMn(H). In particular, any matrix in Mn(H)can be written as a sum of two
k-th powers.
Proof.IfA∈Mn(H) is invertible it can be written as Xk1for some matrix Xin
Mn(H), since it is so in Mn(C). HenceAis in the image of ω, by setting x2to beREFERENCES 23
the zero matrix. Next, assume A∈Mn(H) is not invertible. Choose λ∈Hsuch
thatλk2does not belong to the set of left eigenvalues of A. Fixη∈Hsuch that
ηk2=β. This can be done as ηcan be conjugated to a complex number, thanks to
Lemma 6.1. Then for x2= (λ/η)·I, the matrix A−βxk2is an invertible matrix
(since 0 is not a left eigenvalue of A−βxk2) and hence the map is surjective by
the previous argument. /square
References
[1] T. Bandman et al. “Equations in simple Lie algebras”. In: J. Algebra 355
(2012),pp.67–79. issn:0021-8693. doi:10.1016/j.jalgebra.2012.01.012 .
[2] R. Barai and A. S. Garge. “Trace and discriminant criteria for a m atrix to be
a sum of sixth and eighth powers of matrices”. In: Integers 22 (2022), Paper
No. A25, 14.
[3] M. Bhargava. “On the Conway-Schneeberger ﬁfteen theorem ”. In:Quadratic
forms and their applications (Dublin, 1999) .Vol.272.Contemp. Math. Amer.
Math.Soc.,Providence, RI,2000,pp.27–37. doi:10.1090/conm/272/04395 .
[4] M. Bhargava et al. “What is the probability that a random integral quadratic
form innvariables has an integral zero?” In: Int. Math. Res. Not. IMRN 12
(2016), pp. 3828–3848. issn: 1073-7928. doi:10.1093/imrn/rnv251 .
[5] M. Breˇ sar. “Commutators and images of noncommutative polyn omials”. In:
Adv. Math. 374(2020),pp.107346,21. issn:0001-8708. doi:10.1016/j.aim.2020.107346 .
[6] M. Breˇ sar and P. ˇSemrl. “The Waring problem for matrix algebras”. In:
Israel J. Math. 253.1 (2023), pp. 381–405. issn: 0021-2172,1565-8511. doi:
10.1007/s11856-022-2366-7 .
[7] M. Breˇ sar and P. ˇSemrl. “The Waring problem for matrix algebras, II”. In:
Bull. Lond. Math. Soc. 55.4 (2023), pp. 1880–1889. issn: 0024-6093,1469-
2120.
[8] A. S. Garge. “Matrices over commutative rings as sums of ﬁfth a nd seventh
powers of matrices”. In: Linear Multilinear Algebra 69.12 (2021), pp. 2220–
2227.issn: 0308-1087. doi:10.1080/03081087.2019.1664386 .
[9] M. Griﬃn and M. Krusemeyer. “Matrices as sums of squares”. In :Linear and
Multilinear Algebra 5.1 (1977/78/1978), pp. 33–44.
[10] A. Kanel-Belov, B. Kunyavskii, and E. Plotkin. “Word equations in simple
groups and polynomial equations in simple algebras”. In: Vestnik St. Peters-
burg Univ. Math. 46.1 (2013), pp. 3–13. issn: 1063-4541.24 REFERENCES
[11] A. Kanel-Belov, S. Malev, and L. Rowen. “The images of Lie polyno mials
evaluated on matrices”. In: Comm. Algebra 45.11 (2017), pp. 4801–4808.
issn: 0092-7872. doi:10.1080/00927872.2017.1282959 .
[12] A. Kanel-Belov, S. Malev, and L. Rowen. “The images of multilinear polyno-
mials evaluated on 3 ×3 matrices”. In: Proc. Amer. Math. Soc. 144.1 (2016),
pp. 7–19. issn: 0002-9939. doi:10.1090/proc/12478 .
[13] A. Kanel-Belov, S. Malev, and L. Rowen. “The images of non-com mutative
polynomials evaluated on 2 ×2 matrices”. In: Proc. Amer. Math. Soc. 140.2
(2012),pp.465–478. issn:0002-9939. doi:10.1090/S0002-9939-2011-10963-8 .
[14] A. Kanel-Belov et al. “Evaluations of noncommutative polynomials on al-
gebras: methods and problems, and the L’vov-Kaplansky conject ure”. In:
SIGMA Symmetry Integrability Geom. Methods Appl. 16 (2020), Paper No.
071, 61.doi:10.3842/SIGMA.2020.071 .
[15] S. A. Katre and D. Krishnamurthi. “Matrices over non-commut ative rings
as sums of powers”. In: Linear Multilinear Algebra 70.5 (2022), pp. 824–829.
issn: 0308-1087. doi:10.1080/03081087.2020.1748856 .
[16] S. A. Katre and K. Wadikar. “Matrices over noncommutative rin gs as sums
ofkth powers”. In: Linear Multilinear Algebra 69.11 (2021), pp. 2050–2058.
issn: 0308-1087. doi:10.1080/03081087.2019.1659219 .
[17] K. Kishore. “Matrix Waring problem”. In: Linear Algebra Appl. 646 (2022),
pp. 84–94. issn: 0024-3795. doi:10.1016/j.laa.2022.03.022 .
[18] K. Kishore and A. Singh. “Matrix Waring Problem – II”. In: Israel Journal
of Mathematics accepted (2023).
[19] M. Larsen and A. Shalev. “Word maps and Waring type problems” . In:J.
Amer.Math. Soc. 22.2(2009),pp.437–466. issn:0894-0347. doi:10.1090/S0894-0347-08-00615 
[20] M. Larsen, A. Shalev, and P. H. Tiep. “Probabilistic Waring proble ms for
ﬁnite simple groups”. In: Ann. of Math. (2) 190.2 (2019), pp. 561–608. issn:
0003-486X. doi:10.4007/annals.2019.190.2.3 .
[21] M. Larsen, A. Shalev, and P. H. Tiep. “The Waring problem for ﬁn ite simple
groups”. In: Ann. of Math. (2) 174.3 (2011), pp. 1885–1950. issn: 0003-486X.
doi:10.4007/annals.2011.174.3.10 .
[22] J.Lee.“Integralmatricesasdiagonalquadraticforms”.In :Linear Multilinear
Algebra66.4(2018),pp.742–747. issn:0308-1087. doi:10.1080/03081087.2017.1320965 .
[23] H. Liping. “Consimilarity of quaternion matrices and complex matr ices”.
In:Linear Algebra Appl. 331.1-3 (2001), pp. 21–30. issn: 0024-3795. doi:
10.1016/S0024-3795(01)00266-X .REFERENCES 25
[24] S.PanjaandS.Prasad.“TheimageofpolynomialsandWaringtyp eproblems
on upper triangular matrix algebras”. In: J. Algebra 631 (2023), pp. 148–193.
issn: 0021-8693,1090-266X. doi:10.1016/j.jalgebra.2023.04.027 .
[25] D. R. Richman. “Matrices as sums of squares: a conjecture of Griﬃn and
Krusemeyer”. In: Linear and Multilinear Algebra 17.3-4 (1985), pp. 289–294.
[26] D. R. Richman. “The Waring problem for matrices”. In: Linear and Multilin-
earAlgebra 22.2(1987),pp.171–192. issn:0308-1087. doi:10.1080/03081088708817831 .
[27] L. Rodman. Topics in quaternion linear algebra . Princeton Series in Applied
Mathematics. Princeton University Press, Princeton, NJ, 2014, p p. xii+363.
isbn: 978-0-691-16185-3. doi:10.1515/9781400852741 .
[28] W. Schmidt. Equations over ﬁnite ﬁelds: an elementary approach . Second.
Kendrick Press, Heber City, UT, 2004, pp. x+333. isbn: 0-9740427-1-4.
[29] L.N.Vaserstein. “Onthesumofpowersofmatrices”. In: Linear and Multilin-
earAlgebra 21.3(1987),pp.261–270. issn:0308-1087. doi:10.1080/03081088708817800 .
[30] S. M. Victor. “Counting matrices that are squares”. In: arXiv:1606.09299
(2016).
[31] J. F. Voloch. “Diagonal equations over function ﬁelds”. In: Bol. Soc. Brasil.
Mat.16.2 (1985), pp. 29–39. issn: 0100-3569. doi:10.1007/BF02584799 .
[32] N. A. Wiegmann. “Some theorems on matrices with real quatern ion ele-
ments”. In: Canadian J. Math. 7 (1955), pp. 191–201. issn: 0008-414X. doi:
10.4153/CJM-1955-024-x .
Harish-Chandra Research Institute Prayagraj (Allahabad) , Uttar Pradesh
211019, India
Email address :panjasaikat300@gmail.com
IISER Pune, Dr. Homi Bhabha Road, Pashan, Pune 411 008, India
Email address :prachi2608saini@gmail.com
IISER Pune, Dr. Homi Bhabha Road, Pashan, Pune 411 008, India
Email address :anupamk18@gmail.com