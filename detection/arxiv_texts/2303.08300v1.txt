1
Learning From High-Dimensional Cyber-Physical
Data Streams for Diagnosing Faults in Smart Grids
Hossein Hassani, Graduate Student Member, IEEE , Ehsan Hallaji, Graduate Student Member, IEEE ,
Roozbeh Razavi-Far, Senior Member, IEEE , Mehrdad Saif, Senior Member, IEEE ,
Abstract —The performance of fault diagnosis systems are
highly affected by data quality in cyber-physical power systems.
These systems generate massive amounts of data that overburden
the system with excessive computational costs. Another issue
is the presence of noise in recorded measurements, which
prevents building a precise decision model. Furthermore, the
diagnostic model is often provided with a mixture of redundant
measurements that may deviate it from learning normal and fault
distributions. This paper presents the effect of feature engineering
on mitigating the aforementioned challenges in cyber-physical
systems. Feature selection and dimensionality reduction methods
are combined with decision models to simulate data-driven fault
diagnosis in a 118-bus power system. A comparative study is
enabled accordingly to compare several advanced techniques in
both domains. Dimensionality reduction and feature selection
methods are compared both jointly and separately. Finally,
experiments are concluded, and a setting is suggested that
enhances data quality for fault diagnosis.
Index Terms —Feature selection, dimensionality reduction, clas-
siﬁcation, fault diagnosis, cyber-physical power systems.
I. I NTRODUCTION
FAULT diagnosis system (FDS) is a critical component of
cyber-physical power systems that is crucial for detecting
malfunctions, identifying their cause, and pinpointing their
location in the grid [1]. Nevertheless, designing a traditional
model-based FDS model becomes more challenging as the grid
grows in scale and complexity. The integration of intelligent
models with power systems results in a cyber-physical system
that bypasses the aforementioned problem [2]. Making use of
data-driven approaches for diagnostic purposes provides the
model with a better generalization. Furthermore, intelligent
models facilitate the decision-making process in control sys-
tems by reducing human-machine interaction [3].
Data-driven FDS is primarily carried out using classiﬁcation
algorithms [4], [5], [6]. Having a set of sampled records
corresponding to different system states, one can build a
statistical model that maps incoming signal patterns to certain
conditions such as different events of faults in the systems [7].
In a fault detection setting, the FDS model can be formulated
as an anomaly detector that reveals any signal pattern mis-
matches those of the normal or healthy system state. The past
Hossein Hassani, Ehsan Hallaji, and Mehrdad Saif are with the Department
of Electrical and Computer Engineering, University of Windsor, Windsor,
ON N9B 3P4, Canada (e-mail: hassa12t@uwindsor.ca, hallaji@uwindsor.ca,
msaif@uwindsor.ca).
Roozbeh Razavi-Far is with the Faculty of Computer Science and Canadian
Institute for Cybersecurity, University of New Brunswick, Fredericton, NB
E3B 5A3, Canada, and also with the Department of Electrical and Computer
Engineering, University of Windsor, Windsor, ON N9B 3P4, Canada (e-mail:
roozbeh.razavi-far@unb.ca).decade has witnessed numerous advancements in intelligent
FDS models that resort to sensory data for monitoring power
systems [8], [9]. Nevertheless, the computational efﬁciency of
intelligent models and their dependency on data quality limit
the feasibility of such methods for FDS in power systems.
Data-driven methods only perform well if supplied with
high-quality data. These methods try to capture the character-
istics of a data distribution based on the existing relationships
in the input space and form a mapping from distribution
samples to a set of states in the system [10]. However, if
the input distribution at hand is not a good representative of
the system, the statistical model cannot capture the system
characteristics accordingly. In power systems, this situation
happens due to a number of reasons. Firstly, the captured
signal through sensors often contains noise, which makes it
harder for machine learning models to capture the intrinsic
relationships within data. Furthermore, the abundance of the
set of measurements and the number of sensors (e.g., phasor
measurement units) result in high-dimensional data [11]. The
higher the dimensionality size of the data, the more samples
are needed for obtaining an accurate statistical model. This
phenomenon is also referred to as the curse of dimensionality
in the literature. In turn, processing high-dimensional data
signiﬁcantly increases the computational burden of the FDS. In
addition, the utilized measurements in the power system most
likely result in some invariant and duplicate features that feed
the FDS model with irrelevant information that deteriorates
the precision of the constructed model.
Feature selection (FS) and dimensionality reduction (DR)
techniques are two main approaches that are commonly used
in tackling the curse of dimensionality and improving the data
quality to ensure optimal performance of the diagnostic model.
FS is referred to the process of ﬁltering or ranking different
features (i.e., dimensions of the feature space) to remove non-
informative features and select only a limited set of features
that lead to the optimal performance of decision-making
models [12], [13], [14]. On the other hand, DR methods
transform the whole feature space into a smaller space [15],
[16], [17]. Under a supervised setting, DR may additionally
improve distribution by making classes more distinguishable
in the transformed space [18], [19].
In this paper, an experimental review is performed on state-
of-the-art FS and DR methods for diagnosing faults in cyber-
physical power systems. Both mentioned harsh conditions,
namely noisy signals (with different levels and frequencies)
and high-dimensional data are taken into account throughout
the experiments. This comparative study is enabled by ana-arXiv:2303.08300v1  [cs.LG]  15 Mar 20232
Fig. 1. The single-line diagram of the IEEE 118-bus system [20].
lyzing FS and DR methods in three study groups: 1) FS, 2)
DR, and 3) FS and DR. Finally, we suggest the best methods
that will most likely beneﬁt FDS in real-world power systems,
where similar conditions are expected.
The remainder of this paper is organized as follows. Sec-
tion II presents the employed case-study and data. Section
III explains the proposed methodology. Section IV contains
the experimental results and analysis. Finally, the paper is
concluded in Section V.
II. C ASE-STUDY : CYBER -PHYSICAL POWER SYSTEMS
In the present study, the IEEE 118-bus system has been
employed in order to check for the effectiveness of the
proposed diagnostic methodology. The single-line diagram of
this system has been illustrated in Fig. 1. This system contains,
as the name stands, 118 buses, 91 loads and 19 generation
units. The system is simulated using PowerFactory, and data
measurements are collected using a sampling rate of 10KHz
for faulty and normal scenarios.
Three types of faults are simulated. These faults are named
load-loss (LL), generator outage (GO), and generator ground
(GG) faults. To simulate an LL or GO fault, a breaker has been
placed between the load or generator and the corresponding
bus. The breaker is initially closed, and, then, it is triggered
for 25 ms to disconnect the load or generator from the bus. As
for the GG faults, three-phase short-circuit faults are simulated
between the generation units and the ground. In either fault
case, data measurements are collected from the moment the
fault appears in the system until the moment the fault has been
cleared. This period of time has been set to be 25 ms and witha sampling rate of 10KHz, therefore, a total number of 250
samples are collected for each scenario.
The list of simulated faults is represented in Table I. As
it can be observed from this table, there exist 31 LL fault
scenarios, 19 GO, and 19 GG, in addition to the normal
operational state of the system, leading to a total number of
70 simulated scenarios, where each one could be thought of
as a class of data to be classiﬁed. Therefore, we are dealing
with a multi-class classiﬁcation problem with 70 classes. It
is worth noting that as there are 19 generation units, the GO
and GG faults are simulated on all of the buses connected to
a generation unit. However, for the LL faults, only 31 out of
91 possible locations are considered in the construction of the
fault scenarios. The selected buses to simulate the LL faults
are tried to be from different zones of the grid as shown in
Fig. 1, in order to consider the impact of the fault location on
the performance of the proposed methodology.
In general, six datasets are constructed following the
aforementioned fault scenarios. These datasets are shown by
fD1; : : : ;D6gand the characteristics of each one is summa-
rized in Table II. We aim to investigate the effect of the signal-
to-noise-ratio (SNR) and fault resistance (FR) values on the
performance of the proposed diagnostic, too. In this regard,
three different SNR values including f10 dB ;30 dB ;70 dBg
are considered to model the deep noisy measurements as well
as data measurements with a slight noise. Following this, the
FR value has also been set to be either 1
or10
. Therefore,
with three SNR and two FR values, there could be a total of
six combinations to construct the set of data, as described in
Table II.3
TABLE I
SUMMARY OF THE SIMULATED FAULT SCENARIOS .
Fault Type # Scenarios
LL 31
GO 19
GG 19
Normal 1
Total 70
TABLE II
SUMMARY OF THE CHARACTERISTICS OF THE CONSTRUCTED DATASETS .
Dataset SNR (dB) FR ( 
) # Samples # Features
D1 10 1 17,500 354
D2 10 10 17,500 354
D3 30 1 17,500 354
D4 30 10 17,500 354
D5 70 1 17,500 354
D6 70 10 17,500 354
In terms of the set of features, as given in Table II, there
are a total number of 354 features. Firstly, three types of
measurements are collected from each bus of the system fol-
lowing a simulated scenario. These measurements are voltage,
frequency, and phase angle. Due to the fact that the system has
118 buses, and three types of features are collected from each
bus, therefore, the constructed datasets contain 354 features.
Table III summarizes the set of features.
III. M ETHODOLOGY
In line with what was previously mentioned in Section I,
the general framework of the proposed diagnostic model, as
shown in Fig. 2, is to perform FS and DR techniques on
the constructed datasets described in Table II, and, then, fed
the set of selected or extracted features to three classiﬁcation
models including k Nearest Neighbours (kNN), Support Vector
Machine (SVM) and Random Forest (RF) for the sake of
fault diagnosis. Within this general framework, we discuss
the implementation procedure and evaluation metrics in this
section.
A. Implementation Procedure
The ﬁrst step in the implementation procedure is to stan-
dardize the given datasets. This is of paramount importance
because the feature sets (i.e., voltage, frequency, and phase an-
gle) take different values from different domains. For instance,
the values of voltage measurements are per unit and are close
to 1, while the frequency measurements ﬂuctuate around 50
Hz. Therefore, there is a need to standardize the given datasets
for the sake of eliminating the impact of scale variation from
one feature to another. In this regard, given dataset D, we
TABLE III
COLLECTED FEATURES TO CONSTRUCT DATASETS .
Measurements Feature
voltage 1 to 118
frequency 119 to 236
phase angle 236 to 354
Fig. 2. General framework of the proposed methodology.
do normalize the dataset column-wise through the following
equation:
Dj
n=Dj Dj
min
Dj
max Dj
min; (1)
whereDj
nis the jth column of the normalized dataset with j=
1; : : : ; 354,Dj
max is the maximum value of a given column,
andDj
min shows the minimum value of the corresponding
column.
The normalized dataset will then be fed into the FS and
DR modules in order to select or extract the set of most infor-
mative features. As for the FS techniques, we resort to seven
techniques including Inﬁnite Feature Selection (InfFS) [14],
relief [21], Least Absolute Shrinkage and Selection Operator
(LASSO) [13], Unsupervised Feature Selection with Ordinal
Locality (UFSOL) [22], and Concrete Feature selection based
on Mutual Information (CFMI) [13]. These techniques are
selected to serve two purposes. First, the selected FS methods
are categorized into ﬁlters, wrappers, and embedded. To this
end, we aim to check which category of FS methods could
improve diagnostic performance through a comparative study
between different categories. Second, we aim to look for
providing a ranking for the best FS-classiﬁer combination
for the sake of diagnosis. In the same vein, the selected
DR techniques are from two broad categories namely linear
and nonlinear, depending on the type of transformation. The
employed DR techniques are Principal Component Analysis
(PCA) [15], Linear Discriminant Analysis (LDA) [19], Multi-
dimensional Scaling (MDS) [17], Locally Linear Embedding
(LLE) [16] and Constrained Adversarial Dimensionality Re-
duction (CADR) [18]. The aforementioned two purposes are
also considered in the implementation of DR techniques.
Features of the selected FS and DR techniques are summarized
in Table IV.
Each FS or DR technique is then combined with a classiﬁca-
tion model (kNN, SVM and RF). In this regard, the selected set
of features is fed into the aforementioned classiﬁcation models
and the classiﬁcation results are then represented in terms of
the accuracy and f-measure. However, the number of selected
or extracted features by means of the FS and DR techniques
needs to be adjusted carefully. To this end, in all experiments,
we start with one feature and increase the number of features
to the value, for which the performance of the classiﬁcation
model does not improve signiﬁcantly.4
TABLE IV
CHARACTERISTICS OF THE SELECTED FSAND DR TECHNIQUES .
Technique FS/DR Type Class
InfFS FS Filter Unsupervised
relief FS Filter Supervised
UFSOL FS Wrapper Unsupervised
LASSO FS Embedded Supervised
CFMI FS Embedded Unsupervised
PCA DR Linear Unsupervised
LDA DR Linear Supervised
MDS DR Nonlinear Unsupervised
LLE DR Nonlinear Unsupervised
CADR DR Nonlinear Supervised
B. Evaluation Metrics
To measure the performance of the FS/DR-classiﬁer com-
binations, we resort to the classiﬁcation accuracy Aand f-
measureF1values. In this regard, the constructed combina-
tions are validated through a 10-fold cross-validation manner
and the attained results are collected in terms of accuracy and
f-measure. It is evident that for binary classiﬁcation with only
positive and negative classes, the accuracy index captures the
ratio of the correct decisions made by the classiﬁcation model.
As for the f-measure, it could be thought of as the harmonic
mean of the precision Pand recallR, where the precision is
a measure of the ratio of positive samples that are correctly
classiﬁed into a positive category, while the recall measures
the performance of the classiﬁcation model in classifying the
positive data samples. Following this, one case deﬁnes f-
measure as given below:
F1=2PR
P+R: (2)
In terms of the multi-class classiﬁcation, however, a confusion
matrix of the following form could be constructed:
C=2
664cm11: : : cm 1l
.........
cml1...cmll3
775; (3)
With lbeing the total number of classes. Following this
structure, the precision and recall can then be deﬁned as
follows:
P=1
llX
k=1cmkkPl
i=1cki; (4)
R=1
llX
k=1cmkkPl
i=1cik: (5)
HavingPandRcalculated, the f-measure can then be
obtained based on the Eq. 2 for a multi-class classiﬁcation
problem.
IV. S IMULATION RESULTS AND COMPARATIVE STUDY
In this section, a comprehensive comparative study is pro-
vided to compare the performance of FS/DR-classiﬁer com-
binations. In this regard, the ultimate goal is to identify what
combinations perform better for the sake of fault diagnosis inTABLE V
THE ATTAINED ACCURACY AND F -MEASURE VALUES BY MEANS OF THE
BASELINE MODELS .
Dataset kNN SVM RF
A F 1 A F 1 A F 1
D1 0.4288 0.4413 0.3559 0.3717 0.4012 0.4014
D2 0.4257 0.4424 0.3480 0.3651 0.1793 0.1797
D3 0.5716 0.5807 0.3514 0.3676 0.3417 0.3452
D4 0.5786 0.5858 0.5531 0.5692 0.3403 0.3429
D5 0.6778 0.6848 0.7748 0.7887 0.5037 0.5053
D6 0.6804 0.6869 0.7211 0.7370 0.5150 0.5176
Avg. 0.5604 0.5703 0.5174 0.5332 0.3802 0.3820
cyber-physical power systems. In terms of the FS and DR tech-
niques, we initially investigate that what category of methods
could deal better with the constructed datasets. In particular,
FS techniques are selected from three categories including
ﬁlters, wrappers, and embedded methods, and the selected DR
techniques are either linear or nonlinear. Therefore, the goal
is to investigate which category of FS and DR methods is
superior in comparison with other categories. Furthermore, by
resorting to the overall performance of FS and DR techniques,
we aim to investigate whether FS techniques are preferred over
DR techniques or vice versa.
A. Baseline
The baseline models refer to the case, in which no data
reduction technique is employed. In this regard, the original
datasets are only normalized and, then, fed into the classiﬁca-
tion models. Following this setup, the classiﬁcation results are
collected in terms of accuracy and f-measure through a 10-
fold cross-validation scheme. To this end, the attained average
accuracy and f-measure values by means of the baseline
models are represented in Table V. The collected results in
Table V denote that kNN outperforms the SVM and RF in
terms of average accuracy and f-measure. Furthermore, it is
evident that moving from dataset D1toD6the attained values
are increased because of the fact that the level of noise is
decreased from 10 dB to 70 dB.
B. FS-classiﬁer Combinations
In this section, the performance of the FS techniques along
with their combinations with the given classiﬁcation models
is presented in terms of the accuracy and f-measure. The aim
is to ﬁrst compare the performance of the FS techniques to
see which technique is superior, which is then followed by a
discussion on the superiority of FS-classiﬁer combinations to
see which combination could be the best for the sake of fault
diagnosis in power systems.
We begin with a comprehensive study on the performance
of the given FS-classiﬁer combinations, where the attained
results are collected in Table VI in terms of accuracy and f-
measure. We initially study the effects of the SNR values on
the performance of combinations. From the presented results
in Table VI, it could be concluded that the average values of
accuracy and f-measure increases from 0.61, 0.71, 0.77 and
0.58, 0.72, 0.78, respectively, by moving from SNR values of
10 dB to 30 dB and 70 dB. Obviously, the lower the level5
TABLE VI
THE ATTAINED AVERAGE VALUES OF THE ACCURACY AND F -MEASURE FOR FS- CLASSIFIER COMBINATIONS .
DatasetInfFS relief LASSO UFSOL CFMI
kNN SVM RF kNN SVM RF kNN SVM RF kNN SVM RF kNN SVM RF
D1 0.54 0.51 0.60 0.58 0.56 0.51 0.58 0.59 0.65 0.67 0.60 0.57 0.58 0.54 0.66 0.64 0.60 0.55 0.56 0.42 0.62 0.55 0.58 0.58 0.59 0.58 0.73 0.74 0.56 0.56
D2 0.57 0.56 0.64 0.64 0.60 0.56 0.61 0.56 0.68 0.65 0.63 0.56 0.61 0.56 0.67 0.64 0.62 0.56 0.57 0.47 0.64 0.57 0.60 0.60 0.59 0.57 0.73 0.73 0.56 0.55
D3 0.64 0.68 0.69 0.73 0.64 0.67 0.74 0.77 0.79 0.82 0.74 0.76 0.70 0.73 0.75 0.78 0.71 0.72 0.66 0.60 0.70 0.65 0.66 0.59 0.71 0.71 0.78 0.79 0.62 0.61
D4 0.71 0.74 0.76 0.79 0.71 0.73 0.73 0.75 0.78 0.81 0.73 0.75 0.72 0.74 0.77 0.79 0.73 0.74 0.66 0.61 0.71 0.66 0.67 0.61 0.73 0.73 0.79 0.79 0.64 0.63
D5 0.80 0.83 0.83 0.86 0.79 0.82 0.74 0.79 0.78 0.82 0.75 0.79 0.76 0.75 0.80 0.79 0.78 0.77 0.75 0.73 0.78 0.77 0.74 0.71 0.82 0.81 0.82 0.83 0.71 0.70
D6 0.75 0.79 0.79 0.82 0.75 0.78 0.77 0.81 0.81 0.84 0.78 0.82 0.70 0.75 0.73 0.77 0.72 0.76 0.77 0.74 0.80 0.77 0.76 0.70 0.82 0.82 0.83 0.84 0.76 0.75
Avg. 0.67 0.69 0.72 0.74 0.68 0.68 0.70 0.71 0.75 0.77 0.71 0.71 0.68 0.68 0.73 0.73 0.70 0.68 0.66 0.60 0.71 0.66 0.67 0.63 0.71 0.70 0.78 0.79 0.64 0.63
TABLE VII
COMPARISON BETWEEN VARIOUS FSTECHNIQUES IN TERMS OF THE
AVERAGE ACCURACY AND F -MEASURE FOR THE GIVEN DATASETS .
FS InfFS relief LASSO UFSOL CFMI
A 0.69 0.71 0.70 0.68 0.72
F1 0.70 0.72 0.70 0.63 0.71
TABLE VIII
THE ATTAINED AVERAGE VALUES OF THE ACCURACY AND F -MEASURE BY
MEANS OF THE CLASSIFICATION MODELS IN COMBINATION WITH THE
GIVEN FSTECHNIQUES .
Model kNN SVM RF
A 0.68 0.74 0.68
F1 0.67 0.73 0.67
of noise, the better the performance of the combinations. In
order to check for the performance of the given combinations
in dealing with different fault resistance values, by resorting
to the collected results in Table VI it could be concluded that
the average values of the accuracy and f-measure are 0.69,
0.69 and 0.70, 0.70, when the fault resistance values are 10 
and 1 
, respectively. Therefore, the attained results denote
that the value of the fault resistance has slightly impacted the
performance of the given combinations, where it shows that
a higher value of the fault resistance could negatively impact
the performance.
In terms of the comparison between the given FS tech-
niques, the average values of the accuracy and f-measure w.r.t.
to datasetsD1toD6are summarized in Table VII. Firstly,
it could be observed that CFMI outperforms the other FS
techniques in terms of accuracy, which is then followed by
relief, LASSO, InfFS, and UFSOL. However, in terms of the
f-measure, the collected results denote that the relief technique
outperforms the rest of the techniques, which is followed
by CFMI, LASSO, InfFS, and UFSOL. Secondly, by taking
into account the average values of the accuracy for the ﬁlter,
wrapper, and embedded techniques, the attained results denote
that all categories have almost the same performance, however,
in terms of the f-measure, the ﬁlter category of methods
outperforms the other two categories by 1%.
In terms of the classiﬁcation models, i.e., kNN, SVM, and
RF, the average values of the accuracy and f-measure w.r.t.
all combinations are summarized in Table VIII. The collected
results denote that SVM outperforms the other classiﬁcation
models, while kNN and RF have shown the same performance
in dealing with the given datasets and in accordance withTABLE IX
RANKING OF THE DR- CLASSIFIER COMBINATIONS BASED ON THE
ACCURACY AND F -MEASURE .
Rank Combination Combination
Accuracy f-measure
1 CFMI-SVM CFMI-SVM
2 relief-SVM relief-SVM
3 LASSO-SVM InfFS-SVM
4 InfFS-SVM LASSO-SVM
5 CFMI-kNN relief-kNN
6 UFSOL-SVM relief-RF
7 relief-RF CFMI-kNN
8 relief-kNN InfFS-kNN
9 LASSO-RF InfFS-RF
10 LASSO-kNN LASSO-kNN
11 InfFS-RF LASSO-RF
12 InfFS-kNN UFSOL-SVM
13 UFSOL-RF CFMI-RF
14 UFSOL-kNN UFSOL-RF
15 CFMI-RF UFSOL-kNN
the constructed combinations. Further to this, by comparing
the results of Table VIII with those presented in Table V, it
is evident that FS techniques have considerably helped with
improving the performance of the given classiﬁcation models.
Turning into details, it could be observed that the performance
of the kNN is improved from 0.56 to 0.68, that is from 0.51 to
0.74 and from 0.38 to 0.68 for the SVM and RF, respectively,
and in terms of the average accuracy values. In the same vein
and in terms of the average f-measure values, the presented
results show that the performance of the kNN is improved
from 0.57 to 0.67, that is from 0.53 to 0.73 and from 0.38 to
0.67 for the SVM and RF, respectively.
Finally, we analyze the performance of the constructed
combinations in order to rank them based on the accuracy or
f-measure. In this regard, the ranked combinations are listed
in Table IX w.r.t. accuracy and f-measure. Firstly, the given
ranking in terms of the accuracy and f-measure denotes that
CFMI-SVM is the best combination in order to deal with the
constructed datasets D1toD6. Secondly, it could be observed
that in four out of the ﬁve ﬁrst combinations, the FS techniques
are combined with the SVM, showing that SVM could be of
a better performance in combination with FS techniques for
the sake of fault diagnosis.
C. DR-classiﬁer Combinations
In this section, we present the attained results by means of
the DR-classiﬁer combinations. In this regard, we ﬁrst com-
pare DR techniques in dealing with the given datasets in terms6
TABLE X
THE ATTAINED AVERAGE VALUES OF THE ACCURACY AND F -MEASURE FOR DR- CLASSIFIER COMBINATIONS .
DatasetPCA MDS LDA LLE CADR
kNN SVM RF kNN SVM RF kNN SVM RF kNN SVM RF kNN SVM RF
D1 0.49 0.50 0.63 0.64 0.58 0.58 0.50 0.50 0.62 0.63 0.58 0.57 0.40 0.50 0.43 0.51 0.42 0.50 0.41 0.42 0.58 0.65 0.46 0.46 0.73 0.74 0.81 0.81 0.72 0.72
D2 0.48 0.48 0.64 0.64 0.57 0.57 0.48 0.48 0.62 0.62 0.57 0.57 0.39 0.50 0.42 0.50 0.42 0.50 0.43 0.43 0.54 0.45 0.46 0.46 0.73 0.73 0.80 0.80 0.70 0.70
D3 0.60 0.61 0.71 0.71 0.67 0.67 0.60 0.60 0.71 0.71 0.67 0.67 0.39 0.50 0.43 0.51 0.42 0.50 0.51 0.52 0.70 0.75 0.56 0.56 0.76 0.77 0.85 0.86 0.74 0.74
D4 0.59 0.59 0.70 0.71 0.66 0.66 0.59 0.59 0.70 0.71 0.66 0.66 0.40 0.51 0.43 0.51 0.42 0.50 0.50 0.51 0.67 0.73 0.55 0.56 0.77 0.77 0.86 0.87 0.74 0.75
D5 0.68 0.68 0.78 0.78 0.74 0.74 0.68 0.68 0.78 0.79 0.74 0.74 0.39 0.50 0.43 0.50 0.42 0.50 0.56 0.56 0.87 0.67 0.62 0.62 0.82 0.82 0.90 0.91 0.79 0.79
D6 0.67 0.67 0.77 0.78 0.73 0.73 0.67 0.67 0.77 0.78 0.73 0.73 0.39 0.50 0.43 0.50 0.43 0.51 0.57 0.57 0.83 0.85 0.62 0.62 0.83 0.83 0.90 0.91 0.80 0.80
Avg. 0.59 0.59 0.71 0.71 0.66 0.66 0.59 0.59 0.70 0.71 0.66 0.66 0.39 0.50 0.43 0.51 0.42 0.50 0.50 0.50 0.69 0.68 0.55 0.55 0.77 0.78 0.85 0.86 0.75 0.75
TABLE XI
COMPARISON BETWEEN VARIOUS DR TECHNIQUES IN TERMS OF THE
AVERAGE ACCURACY AND F -MEASURE FOR THE GIVEN DATASETS .
DR PCA MDS LDA LLE CADR
A 0.65 0.65 0.41 0.58 0.79
F1 0.65 0.65 0.50 0.58 0.80
of accuracy and f-measure, and, then, all the possible DR-
classiﬁer combinations are ranked based on their performance.
Same as what was presented in Section IV-B for the FS-
classiﬁer combinations, Table X summarizes the attained av-
erage values of the accuracy and f-measure of all DR-classiﬁer
combinations w.r.t. datasets D1toD6. We start with the impact
of the SNR on the performance of the given DR techniques. In
this regard, we resort to the attained accuracy and f-measure
values collected in Table X and calculate the average accuracy
and f-measure for all combinations w.r.t. different SNR values.
To this end, the attained average accuracy and f-measures are
0.55, 0.62, 0.68, 0.57, 0.64, and 0.69, respectively, for datasets
with the SNR value of 10 dB, 30 dB, and 70 dB. As it was
expected, the lower the value of the SNR, the lower the value
of accuracy and f-measure values, denoting that noisy mea-
surements could degrade the performance of DR techniques.
Other than the SNR, the value of the fault resistance could
also play an important role in the performance of the given
DR techniques. By resorting to the results presented in Table
X, the average values of the accuracy and f-measure w.r.t.
fault resistance values of 1 
and 10 
are 0.62, 0.61, and 0.64,
0.63, respectively, denoting that both the index measures are
degraded by 1% when the fault resistance value is increased
from 1 
to 10 
. This is due to the fact that a higher fault
resistance value could decrease the signature of the faults on
the collected data measurements from the grid.
In terms of the comparison between the given DR tech-
niques, Table XI summarizes the performance of all the
given techniques in terms of the average accuracy and f-
measure w.r.t. datasets D1toD6. Following the presented
results in Table XI, it could be observed that ﬁrstly, CADR
outperforms other DR techniques in terms of accuracy and
f-measure. Secondly, for the linear DR techniques, i.e., PCA
and LDA, the average accuracy and f-measure values are 0.53
and 0.58, respectively, while for the nonlinear techniques, i.e.,
MDS, LLE, and CADR, the average accuracy, and f-measure
values are 0.67 and 0.67, respectively. Therefore, the attained
results denote that nonlinear DR techniques could in general
outperform linear ones for the sake of fault diagnosis.TABLE XII
THE ATTAINED AVERAGE VALUES OF THE ACCURACY AND F -MEASURE BY
MEANS OF THE CLASSIFICATION MODELS IN COMBINATION WITH THE
GIVEN DR TECHNIQUES .
Model kNN SVM RF
A 0.57 0.68 0.61
F1 0.59 0.69 0.62
In terms of the classiﬁcation models combined with the
given DR techniques, the average accuracy and f-measure
values are summarized in Table XII. Firstly, it is evident that
SVM results in the best classiﬁcation performance ( A= 0:68,
F1= 0:69), which is followed by the RF ( A= 0:61,
F1= 0:62) and kNN (A= 0:57,F1= 0:59). Secondly,
compared with the results presented in Table V for the
baseline models, it could be concluded that the constructed
DR-classiﬁer combinations have improved the performance
of the diagnostic system, verifying the importance of feature
extraction in dealing with the curse of dimensionality.
Finally, all the possible DR-classiﬁer combinations are
ranked based on their performance in terms of accuracy and
f-measure, where the ranked combinations are collected in
Table XIII. The ranked combinations in terms of accuracy, in
line with what was discussed previously, denote that CADR
in combination with any of the given classiﬁcation models
outperforms the rest of the DR techniques. In addition, three
out of the ﬁrst ﬁve combinations are cases in which SVM is
combined with a DR technique, verifying the superiority of the
SVM classiﬁcation model over the kNN and RF. Furthermore,
seven out of the ﬁrst 10 combinations include a nonlinear DR
technique that denotes these techniques are superior to their
linear counterparts. The provided rankings based upon the f-
measure index, there is no change in the ﬁrst 10 combinations,
and, therefore, the same concluding remarks could be made.
D. Discussion
In Section IV-B and Section IV-C, we analyzed the perfor-
mance of the FS/DR-classiﬁer combinations. In this section,
we aim to discuss and compare the performance of FS
techniques in comparison with the DR techniques in order
to ﬁnd out which type of data reduction could help more with
improving the performance of fault diagnosis for the given
case-study.
In this regard, we resort to the average values of the
accuracy and f-measure attained by means of FS techniques
in combination with all the given classiﬁcation models and7
TABLE XIII
RANKING OF THE DR- CLASSIFIER COMBINATIONS BASED ON THE
ACCURACY AND F -MEASURE .
Rank Combination Combination
Accuracy f-measure
1 CADR-SVM CADR-SVM
2 CADR-kNN CADR-kNN
3 CADR-RF CADR-RF
4 PCA-SVM PCA-SVM
5 MDS-SVM MDS-SVM
6 LLE-SVM LLE-SVM
7 PCA-RF PCA-RF
8 MDS-RF MDS-RF
9 PCA-kNN PCA-kNN
10 MDS-kNN MDS-kNN
11 LLE-RF LLE-RF
12 LLE-kNN LDA-SVM
13 LDA-SVM LDA-kNN
14 LDA-RF LLE-kNN
15 LDA-kNN LDA-RF
compare them with those of DR techniques. The attained
results denote that the average accuracy and f-measure values
for the FS techniques are 0.70 and 0.70, respectively, and
those are 0.62 and 0.64 for the DR techniques. Therefore, the
attained results denote that for this case-study, the combination
of FS techniques with classiﬁcation models could deal better
with the classiﬁcation task compared with the combinations
of the DR techniques with classiﬁcation models.
V. C ONCLUDING REMARKS
In this paper, we studied the fault diagnosis problem of
cyber-physical power systems by resorting to a data-driven
technique. This proposal suggested the combination of data
reduction techniques including feature selection and dimen-
sionality reduction and their combinations with classiﬁcation
models in order to identify four types of faults including
generator outage, generator ground, and load loss. It was
proposed to make use of different types of feature selec-
tion and dimensionality reduction techniques to investigate
the impact of different models on diagnostic performance.
The attained results ﬁrst denoted that in terms of feature
selection and their combinations with classiﬁcation models,
all the categories performed more or less the same to deal
with the classiﬁcation task. However, for the dimensionality
reduction techniques, it was observed that nonlinear models
could improve the classiﬁcation performance in comparison
with the linear counterpart. Furthermore, the results of the
given experiments denoted that in general, feature selection
techniques could be of a better performance in comparison
with dimensionality reduction methods for the sake of fault
diagnosis. In addition to this, we studied the impact of noisy
measurements and fault resistance values, where the results
showed that when the level of noise and the value of the
fault resistance decreases, the performance of the constructed
combinations could be improved. Due to the high volume of
available data that could be collected from large-scale power
systems, this study could be further extended to the use of
deep learning algorithms for the sake of classiﬁcation due to
their ability in dealing with large-size datasets.REFERENCES
[1] Z. Gao, C. Cecati, and S. X. Ding, “A survey of fault diagnosis and
fault-tolerant techniques—part i: Fault diagnosis with model-based and
signal-based approaches,” IEEE Trans. Ind. Electron. , vol. 62, no. 6, pp.
3757–3767, 2015.
[2] Y . Zhang, X. Shi, H. Zhang, Y . Cao, and V . Terzija, “Review on deep
learning applications in frequency analysis and control of modern power
system,” Int. J. Electr. Power Energy Syst. , vol. 136, p. 107744, 2022.
[3] H. Hassani, R. Razavi-Far, M. Saif, J. Zarei, and F. Blaabjerg, “Intelli-
gent decision support and fusion models for fault detection and location
in power grids,” IEEE Trans. Emerg. Top. Comput. Intell. , vol. 6, no. 3,
pp. 530–543, 2022.
[4] Y . Wang, X. Wang, Y . Wu, and Y . Guo, “Power system fault classiﬁca-
tion and prediction based on a three-layer data mining structure,” IEEE
Access , vol. 8, pp. 200 897–200 914, 2020.
[5] S. Zhang, Y . Wang, M. Liu, and Z. Bao, “Data-based line trip fault
prediction in power systems using lstm networks and svm,” IEEE Access ,
vol. 6, pp. 7675–7686, 2018.
[6] H.-L. Dang, J. Kim, S. Kwak, and S. Choi, “Series dc arc fault detection
using machine learning algorithms,” IEEE Access , vol. 9, pp. 133 346–
133 364, 2021.
[7] H. Hassani, R. Razavi-Far, M. Saif, and V . Palade, “Generative adversar-
ial network-based scheme for diagnosing faults in cyber-physical power
systems,” Sensors , vol. 21, no. 15, p. 5173, 2021.
[8] H. R. Baghaee, D. Mlaki ´c, S. Nikolovski, and T. Dragicevi ´c, “Support
vector machine-based islanding and grid fault detection in active dis-
tribution networks,” IEEE J. Emerg. Sel. Top. Power Electron. , vol. 8,
no. 3, pp. 2385–2403, 2020.
[9] V . Le, X. Yao, C. Miller, and B.-H. Tsao, “Series dc arc fault detection
based on ensemble machine learning,” IEEE Trans. Power Electron. ,
vol. 35, no. 8, pp. 7826–7839, 2020.
[10] E. Hallaji, R. Razavi-Far, M. Wang, M. Saif, and B. Fardanesh, “A
stream learning approach for real-time identiﬁcation of false data injec-
tion attacks in cyber-physical power systems,” IEEE Trans. Inf. Forensics
Secur. , vol. 17, pp. 3934–3945, 2022.
[11] H. Hassani, M. Farajzadeh-Zanjani, R. Razavi-Far, M. Saif, and
V . Palade, “Design of a cost-effective deep convolutional neural net-
work–based scheme for diagnosing faults in smart grids,” in IEEE Int.
Conf. Mach. Learn. Appl. (ICMLA) , 2019, pp. 1420–1425.
[12] “Unsupervised concrete feature selection based on mutual information
for diagnosing faults and cyber-attacks in power systems,” Eng. Appl.
Artif. Intell. , vol. 100, p. 104150, 2021.
[13] R. Muthukrishnan and R. Rohini, “Lasso: A feature selection technique
in predictive modeling for machine learning,” in IEEE Int. Conf. Adv.
Comput. Appl. (ICACA) , 2016, pp. 18–20.
[14] G. Roffo, S. Melzi, and M. Cristani, “Inﬁnite feature selection,” in IEEE
Int. Conf. Comput. Vision (ICCV) , 2015, pp. 4202–4210.
[15] I. Jolliffe, Principal Component Analysis . Berlin, Heidelberg: Springer
Berlin Heidelberg, 2011, pp. 1094–1096.
[16] R. Salakhutdinov and G. Hinton, “Learning a nonlinear embedding by
preserving class neighbourhood structure,” in Proc. Eleventh Inte. Conf.
Artiﬁ. Intell. Statistics , ser. Proceedings of Machine Learning Research,
vol. 2. San Juan, Puerto Rico: PMLR, 21–24 Mar 2007, pp. 412–419.
[17] N. Saeed, H. Nam, M. I. U. Haq, and D. B. Muhammad Saqib, “A survey
on multidimensional scaling,” ACM Comput. Surv. , vol. 51, no. 3, may
2018.
[18] E. Hallaji, M. Farajzadeh-Zanjani, R. Razavi-Far, V . Palade, and M. Saif,
“Constrained generative adversarial learning for dimensionality reduc-
tion,” IEEE Trans. Knowl. Data Eng. , pp. 1–1, 2021.
[19] R. A. Fisher, “The use of multiple measurements in taxonomic prob-
lems,” Annals Eugen. , vol. 7, pp. 179–188, 1936.
[20] C. Li, J. Yun, T. Ding, F. Liu, Y . Ju, and S. Yuan, “Robust co-
optimization to energy and reserve joint dispatch considering wind
power generation and zonal reserve constraints in real-time electricity
markets,” Appl. Sci. , vol. 7, no. 7, p. 680, 2017.
[21] M. Robnik- ˇSikonja and I. Kononenko, “Theoretical and empirical anal-
ysis of relieff and rrelieff,” Machine Learning , vol. 53, no. 1, pp. 23–69,
2003.
[22] J. Guo, Y . Guo, X. Kong, and R. He, “Unsupervised feature selection
with ordinal locality,” in IEEE Int. Conf. Multimed. Expo (ICME) , 2017,
pp. 1213–1218.