arXiv:2305.11898v1  [cs.CV]  15 May 2023NEURAL INFORMATION CODING FOR EFFICIENT SPIKE-BASED IMAGE DENOISING
Andrea Castagnetti, Alain Pegatoquet, Beno ˆıt Miramond
Universit´ e Cˆ ote d’Azur, CNRS, LEAT
ﬁrstname.lastname@univ-cotedazur.fr
ABSTRACT
In recent years, Deep Convolutional Neural Networks (DC-
NNs) have outreached the performance of classical algo-
rithms for image restoration tasks. However most of these
methods are not suited for computational efﬁciency and are
therefore too expensive to be executed on embedded and
mobile devices. In this work we investigate Spiking Neural
Networks (SNNs) for Gaussian denoising, with the goal of
approaching the performance of conventional DCNN while
reducing the computational load. We propose a formal anal-
ysis of the information conversion processing carried out b y
the Leaky Integrate and Fire (LIF) neurons and we compare
its performance with the classical rate-coding mechanism.
The neural coding schemes are then evaluated through exper-
iments in terms of denoising performance and computation
efﬁciency for a state-of-the-art deep convolutional neura l net-
work. Our results show that SNNs with LIF neurons can
provide competitive denoising performance but at a reduced
computational cost.
Index Terms —Image denoising, Spiking Neural Net-
works, Neural information coding, Neuromorphic computing .
1. INTRODUCTION AND RELATED WORK
Smartphone cameras, because of their reduced size and high
pixel count, are intrinsically more susceptible to noise th an
conventional digital cameras. Image denoising algorithms are
therefore intensively used in smartphones to recover image
quality by reducing the amount of noise of the raw image. Im-
age denoising performance have increased during the last fe w
years and recent methods based on Deep Convolutional Neu-
ral Networks (DCNNs) have provided very high scores [ 1]
to the point of outreaching classical spatial and patch-bas ed
algorithms [ 2]. However, deploying AI-based algorithms on
embedded devices poses many problems. The limited amount
of memory available, power consumption and thermal dissi-
pation are indeed critical for embedded battery powered
platforms. The ﬁeld of neuromorphic engineering, especial ly
SNNs, is emerging as a new paradigm for the design of low-
power and real-time information processing hardware [ 3].
This work has been supported by the French governement throu gh 3IA
Cˆ ote d’Azur institute, reference ANR-19-P3IA-0002The spike information coding used by SNNs enables sparse
and event-based computation through the network. The com-
bination of these properties may lead to more energy efﬁcien t
hardware implementations of neural networks, allowing sta te-
of-the-art AI algorithms to be executed on mobile platforms
with a reduced power budget [ 4]. However, to achieve these
energy gains while simultaneously reaching the level of per -
formance of DCNNs, SNNs must be able to encode analog
data with high precision using very compact codes, i.e. spik e
trains. In recent years, several training and conversion me th-
ods have been proposed to improve the accuracy of SNNs
on large-scale machine learning tasks. To take advantage of
better performance provided by supervised learning, sever al
methods have been developed to convert ANNs, trained using
standard schemes like backpropagation, into SNNs for event -
driven inference [ 5] [6]. The ANN-SNN conversion is based
on the idea that ﬁring rates of spiking neurons should match
the activations of analog neurons. Rate-based conversion
methods have achieved signiﬁcant results over the last few
years, thus reducing the accuracy gap with ANNs [ 7]. How-
ever, rate-based conversion methods have a major drawback
since they require a large amount of timesteps to precisely
match the activations of analog neurons. A new approach,
called surrogate gradient learning, has been proposed to tr ain
SNNs directly in the spike domain using standard supervised
learning algorithms [ 8]. Recent studies reported competitive
performance on a series of static and dynamic datasets using
surrogate gradient training [ 9]. In this paper, we will extend
these previous works and study the trade off between accu-
racy and efﬁciency of SNNs for the speciﬁc and uncovered
case of image denoising. This task is challenging for two
reasons. First, as denoising is a regression task, the netwo rk
has to predict a continuous value (i.e. the noise amplitude) for
each pixel of the image. Moreover, state of the art results ha ve
been obtained with very deep networks (17 layers or more).
In Section 2we study two spike coding approaches and we
formalize the trade-off between performance and activatio n
sparsity in SNN. In Section 3we propose, for the ﬁrst time, an
image denoising solution based on SNN. The network trained
directly in the spike domain provides a level of performance
close to the state of the art CNN based solution. In the last
section, we conclude the paper and we discuss future work.2. NEURAL CODING
Neural coding schemes convert input pixels into spikes that
are transmitted to spiking neurons for information process ing.
Speciﬁcally, we are interested in the two complementary neu -
ral coding procedures called encoding anddecoding that map
analog values into train of spikes and its inverse. Two types of
encoding and decoding schemes are studied: the coding with
information conversion and the rate-coding. The following
section presents an analysis of the neural conversion with L IF
neurons. The comparison between the two coding scheme
will be discussed in Sec. 2.2
2.1. Neural coding with LIF neurons
In this ﬁrst coding scheme, that we call Neural information
conversion , a LIF neuron, located in the ﬁrst layer (encod-
ing) of the network is fed with a constant input xthroughT
timesteps. We are interested in ﬁnding the encoding functio n
that deﬁnes the relation between xandz(t), the spiking out-
put. Let us ﬁrst recall the equations that govern the dynamic
of a LIF neuron in the discrete case [ 10]:
V[n] =V[n−1]+1
τ(−(V[n−1]−Vreset)+x[n])(1)
Whenever V[n]≥Vth, whereVthis the threshold voltage, the
neuron emits a binary spike. The spike train representation of
the analog input x, is thus encoded in the following function:
z(t) =T/summationdisplay
j=1δ(t−tj) (2)
Whereδ(t)is the Dirac delta function and tjare the spike-
times indexed by j.
In the following we also consider that the membrane
potential is completely discharged after a spike emission,
Vreset= 0. Let us ﬁnd the value of xthat makes the neuron
ﬁres at each timestep, thus producing a constant ﬁring rate o f
1. The conditions that produce this ﬁring pattern are shown
below: 

V[n−1] = 0
V[n]≥Vth
x[n] =x,∀n(3)
Since a spike has to be generated at the current timestep n,
the membrane potential is greater or equal to Vth. Moreover,
with a ﬁring rate of 1, the neuron resets its membrane poten-
tial at each timestep, after the spike emission. Therefore t he
membrane potential at the previous timestep, V[n−1], equals
0. Replacing conditions 3into Eq. 1we obtain:
x≥Vth.τ (4)
When the input xis greater than or equal to Vth.τ, the LIF
neuron ﬁres a spike at each timestep. Following the sameTimesteps frk
0 1 2 3 4 5 6 7
1 1 1 1 1 1 1 1 1.0 0
0 1 0 1 0 1 0 1 0.5 1
0 0 1 0 0 1 0 0 0.25 2
0 0 0 1 0 0 0 1 0.25 3
0 0 0 0 1 0 0 0 0.125 4
0 0 0 0 0 1 0 0 0.125 5
0 0 0 0 0 0 1 0 0.125 6
0 0 0 0 0 0 0 1 0.125 7
0 0 0 0 0 0 0 0 0 8
Table 1 : Output codes of a LIF neuron stimulated with a
constant value. Trepresents the number of timesteps (here
T= 8).fris the ﬁring rate and kis the number of timesteps
used for the charge phase before the ﬁrst spike. The value 1
means that a spike has been generated on the corresponding
timestep.
reasoning, let us ﬁnd the values of xthat produce a ﬁring
rate of 0.5. In such a case, the neuron periodically alternat es
between two states: [charge, ﬁre&reset, charge, ﬁre&reset ,
. . . ]. The conditions that lead to this behaviour are shown
below: 

V[n−1] =x/τ
V[n]≥Vth
x[n] =x,∀n(5)
Replacing conditions 5into Eq. 1we obtain:
V[n] =Vth=x/τ+1
τ(x−x/τ) (6)
The values of xthat produces a ﬁring rate of 0.5 are deﬁned
by:
Vth
2/τ−1/τ2≤x≤Vth.τ (7)
The same approach can be used to determine the produc-
tion conditions of the other ﬁring rates of a LIF model as de-
picted in ﬁgure 1.
Before proceeding in the analysis, it is now interesting to f o-
cus on the spike patterns generated by a LIF neuron in more
details. We may wonder, for example, if all spiking patterns
of a LIF neuron are allowed, as well as the number of differ-
ent ﬁring rates. Let us start with a simple example where the
neuron codes information over T= 8 timesteps. Note that
a sequence that leads to a generation of a spike (in the case
of a constant input) must have the following format: [charge ]
duringktimesteps, followed by [ﬁre&reset]. Table 1, shows
the spiking pattern generated by a LIF neuron, when simu-
lated forT= 8 timesteps. We can observe that the number
of output codes does not depend on the input xbut only on
the value of T(simulation timesteps). In fact, only T+1out-
put codes can be generated by a LIF neuron, when stimulatedwith a constant input. We have so far characterized the en-
coding function, the relation between the analog input xand
the spike pattern, z(t), generated at the output of the neuron.
The inverse process called decoding aims at mapping the in-
verse function, that is the reconstruction of the analog val ue
(ˆx) from a spiking input. To do so, we use the ﬁring-rate of
the neuron as the information carrying variable and express
the decoded analog output as follows, where frdenotes the
ﬁring rate:
ˆx=fr=1
TT/summationdisplay
z(t) (8)
The output codes obtained by simulating a LIF neuron
are plotted in Fig. 1as a function of the input value x. As it
1.0 1 .2 1 .4 1 .6 1 .8 2 .0 2 .2 2 .4
x0.00.20.40.60.81.0frVthτ= 2.0
Vth
2/τ−1/τ2= 1.33
Vth
4/τ−6/τ2+4/τ3−1/τ4= 1.07
Fig. 1 : Firing-rate as a function of the input xforT= 8
(Vth= 1.0,τ= 2.0). The thresholds for fr= 1.0andfr=
0.5andfr= 0.25are also shown.
can be observed, the conversion operated by a LIF neuron is
highly non-uniform as it provides more quantization steps a t
amplitudes near Vththan at higher amplitudes. However, the
quantization step sizes decrease while approaching Vth. At
the opposite, codes that carry a high fr, have large quantiza-
tion step sizes. As an example and as shown in Fig. 1, afrof
0.5 will be generated by the neuron when x∈[1.33,2.0].
2.2. Comparison between neural conversion and rate
coding
To assess the performance of the neural conversion scheme,
we use a set of 12 natural images [ 11] (Set12), to measure
the accuracy of the quantizer. The Peak-Signal-to-Noise ra -
tio (PSNR) is used as quality criterion. The pixel intensiti esof the test images are normalized in the interval [1.0,2.0]to
match the conversion range of the LIF neuron shown in Fig.
1. The normalized pixel intensities are fed (without noise)
into a LIF neuron membrane for Ttimesteps. The spikes
generated by each neuron are then collected and an estimate
of each pixel value is computed using equation 8. We com-
pare the neural coding of LIF neurons with the rate coding, a
well known scheme that has been extensively used in the SNN
community for coding dense information in the spike domain
[12] [13] [14]. In the rate coding scheme we assume that spike
trains are independent realizations of Poisson processes w ith
ratesri, where the pixel intensity xiis the ﬁring probability,
normalized between [0,1], at each timestep. Eq. 8is also used
to decode the spiking output. The average PSNR on Set12 is
shown on the left side of Fig. 2. As we can observe, the PSNR
0 5 10
Timesteps510152025PSNR [dB]Neural conversion (LIF)
Rate coding
0 5 10
Timesteps0246810θNeural conversion (LIF)
Rate coding
Fig. 2 : PSNR (left) and θ(right) as a function of the number
of timesteps for the LIF neural conversion and rate coding
schemes on the Set12 dataset. Each point of the curves rep-
resents an average over the number of pixels of all the datase t
images. Here Vth= 1andτ= 2for the LIF neurons.
increases quickly for the LIF coding scheme and saturates at
T∼10. Adding more timesteps to the conversion does not
improve the image reconstruction. From the previous analy-
sis, presented in Sec. 2.1, we know that increasing Tadds
more quantization intervals and therefore also increases t he
number of output codes that can be generated by a LIF neu-
ron. However, as it can be observed from Fig. 1, the sizes
of newly added quantized intervals decrease fast and vanish
whenxapproaches Vth. As a result, the non-uniform quan-
tization scheme that emerges from the LIF neuron does not
allow decreasing the distortion between the original and th e
quantized signals by adding more quantization bits, i.e. in -
creasingT. On the other hand, the rate conversion scheme
does not set any limits on the accuracy since the PSNR in-
creases with a logarithmic shape as a function of T. Let us
now study a property of great interest for a neural informa-
tion coding scheme: the activity of the spiking neurons. Thi s
property is key for reducing computation costs, thus the en-ergy consumption in networks of spiking neurons. The activ-
ity of a neural network is deﬁned as the average number of
spikes generated by each neuron during Ttimesteps. Refer-
ring to the previous image quantization example, the activi ty
is deﬁned as follows:
θ=n/summationdisplay
i=0m/summationdisplay
j=0zi,j(t)
n×m(9)
Where(n,m)is the size of the input image. Summing over
z, which is a T×n×mbinary matrix, results in the total
number of spikes generated by all the LIF neurons. The ac-
tivity,θ, of the rate coding and LIF conversion scheme can be
seen on the right side of Fig. 2. This ﬁgure shows that, like in
each rate conversion scheme, the number of spikes increases
almost linearly with T. However, as we can observe from the
PSNR curve shown in Fig. 2, the amount of information car-
ried by each new spike in the neural conversion scheme satu-
rates above T∼10. The process of coding dense information
into stream of spikes is key for SNN and has been pointed out
as one of the main reasons for the current performance gap
between SNN and ANN. In the next section we investigate
how these rules and properties show up in larger and complex
networks of spiking neurons.
3. IMAGE DENOISING WITH SPIKING NEURONS
Our study of image denoising with spiking neurons is based
on the DnCNN network proposed in [ 1]. We focus the study
on Gaussian denoising with a certain noise level. The consid -
ered network is composed of 17 convolutional layers. Activa -
tion functions are replaced with LIF neurons ( Vth= 1,τ=
2). The input of the network is a noisy observation y=x+v
wherevis additive white Gaussian noise with zero mean and
standard deviation σ. As proposed in [ 1] we follow a residual
learning formulation, to train a mapping R(y)∼vand re-
cover the clean image from x=y−R(y). The averaged mean
square error between the desired and the estimated residual s
is used as the loss function. Training data for gaussian gray
image denoising are generated using the same method pro-
posed in [ 1]. A dataset composed of 12 images (not included
in the train set) is used for testing. The surrogate gradient [8]
learning is used to train the SNN networks. Denoising result s
and neuron activity are shown in Fig. 3. As we can observe
the network performance (PSNR) follows the same trend ob-
served for information coding shown in Fig. 2. The LIF
conversion scheme can provide competitive denoising perfo r-
mance with few timesteps, but PSNR saturates when T >10.
Rate coding could theoretically achieve the same PSNR as
DnCNN but at the cost of hundreds of timesteps. Fig. 4illus-
trates the visual results of the coding methods on the C.man
image. As it can be seen with only 7 timesteps, the LIF con-
version method provides better images compared with rate0.0 2.5 5.0 7.5 10.0
Timesteps2224262830PSNR [dB]Neural conversion (LIF)
Rate coding
DnCNN
0.0 2.5 5.0 7.5 10.0
Timesteps0123456θNeural conversion (LIF)
Rate coding
Fig. 3 : Denoising PSNR (left) and θ(right) as a function of
the number of conversion timesteps for the LIF neural con-
version scheme and the rate coding. The dotted line represen t
the performance of DnCNN for a noise level σ= 25 .
coding. The latter scheme would require a large amount of
timesteps to encode analog values with the precision needed
for the denoising task.
(a) Clean image
 (b) Noisy image (20.18 dB)
(c) LIF (28.35 dB)
 (d) Rate coding (21.59 dB)
Fig. 4 : Denoising results of the image “C.man” with noise
level 25. Denoised images are shown in Fig. c and d for LIF
conversion and rate coding, both with T= 7.
4. CONCLUSION
In this paper we have presented an analysis, based on informa -
tion coding, for SNNs and its application for image denoisin g.
Our analysis showed that information coding at the neuron
level can explain the performance at the network level. As fu -
ture work, we aim at using our approach to guide the design
of spiking neural models. Our objective is to encode infor-
mation with both low latency and high precision for further
hardware neuromorphic implementation.5. REFERENCES
[1] Kai Zhang, Wangmeng Zuo, Yunjin Chen, Deyu Meng,
and Lei Zhang, “Beyond a Gaussian Denoiser: Residual
Learning of Deep CNN for Image Denoising,” IEEE
Transactions on Image Processing , vol. 26, no. 7, pp.
3142–3155, July 2017, arXiv: 1608.03981.
[2] Shuhang Gu, Lei Zhang, Wangmeng Zuo, and Xiangchu
Feng, “Weighted Nuclear Norm Minimization with Ap-
plication to Image Denoising,” in 2014 IEEE Con-
ference on Computer Vision and Pattern Recognition ,
Columbus, OH, USA, June 2014, pp. 2862–2869, IEEE.
[3] Nassim Abderrahmane, Edgar Lemaire, and Benoˆ ıt Mi-
ramond, “Design space exploration of hardware spiking
neurons for embedded artiﬁcial intelligence,” Neural
Networks , vol. 121, pp. 366–386, 2020.
[4] Javier Mendez, Kay Bierzynski, MP Cu´ ellar, and
Diego P Morales, “Edge intelligence: Concepts, ar-
chitectures, applications and future directions,” ACM
Transactions on Embedded Computing Systems (TECS) ,
2022.
[5] Peter U. Diehl, Daniel Neil, Jonathan Binas, Matthew
Cook, Shih-Chii Liu, and Michael Pfeiffer, “Fast-
classifying, high-accuracy spiking deep networks
through weight and threshold balancing,” in 2015 Inter-
national Joint Conference on Neural Networks (IJCNN) ,
July 2015, pp. 1–8, ISSN: 2161-4407.
[6] Bodo Rueckauer, Iulia-Alexandra Lungu, Yuhuang Hu,
Michael Pfeiffer, and Shih-Chii Liu, “Conversion of
Continuous-Valued Deep Networks to Efﬁcient Event-
Driven Networks for Image Classiﬁcation,” Frontiers in
Neuroscience , vol. 11, pp. 682, 2017.
[7] Abhronil Sengupta, Yuting Ye, Robert Wang, Chiao Liu,
and Kaushik Roy, “Going Deeper in Spiking Neural
Networks: VGG and Residual Architectures,” Frontiers
in Neuroscience , vol. 13, pp. 95, 2019.
[8] Emre O. Neftci, Hesham Mostafa, and Friedemann
Zenke, “Surrogate Gradient Learning in Spiking Neural
Networks: Bringing the Power of Gradient-Based Op-
timization to Spiking Neural Networks,” IEEE Signal
Processing Magazine , vol. 36, no. 6, pp. 51–63, Nov.
2019.
[9] Stanisław Wo´ zniak, Angeliki Pantazi, Thomas Bohnst-
ingl, and Evangelos Eleftheriou, “Deep learning incor-
porating biologically inspired neural dynamics and in-
memory computing,” Nature Machine Intelligence , vol.
2, no. 6, pp. 325–336, June 2020.[10] Effrosyni Doutsi, Lionel Fillatre, Marc Antonini, and
Panagiotis Tsakalides, “Dynamic Image Quantization
Using Leaky Integrate-and-Fire Neurons,” IEEE Trans-
actions on Image Processing , vol. 30, pp. 4305–4315,
2021.
[11] S. Roth and M.J. Black, “Fields of Experts: a frame-
work for learning image priors,” in 2005 IEEE Com-
puter Society Conference on Computer Vision and Pat-
tern Recognition (CVPR’05) , June 2005, vol. 2, pp.
860–867 vol. 2, ISSN: 1063-6919.
[12] Wenzhe Guo, Mohammed E. Fouda, Ahmed M. Eltawil,
and Khaled Nabil Salama, “Neural Coding in Spik-
ing Neural Networks: A Comparative Study for Robust
Neuromorphic Systems,” Frontiers in Neuroscience ,
vol. 15, pp. 638474, Mar. 2021.
[13] Nassim Abderrahmane and Benoit Miramond, “Neural
coding: adapting spike generation for embedded hard-
ware classiﬁcation,” in 2020 International Joint Con-
ference on Neural Networks (IJCNN) , Glasgow, United
Kingdom, July 2020, pp. 1–8, IEEE.
[14] Romain Brette, “Philosophy of the Spike: Rate-Based
vs. Spike-Based Theories of the Brain,” Frontiers in
Systems Neuroscience , vol. 9, pp. 151, 2015.