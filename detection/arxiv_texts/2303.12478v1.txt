arXiv:2303.12478v1  [math.PR]  22 Mar 2023NO EIGENV ALUES OUTSIDE THE SUPPORT OF THE LIMITING
SPECTRAL DISTRIBUTION OF LARGE DIMENSIONAL NONCENTRAL
SAMPLE COV ARIANCE MATRICES
BYZHIDONG BAI1,aJIANG HU1,bJACK W. S ILVERSTEIN2,dHUANCHAO ZHOU1,c
1KLASMOE and School of Mathematics and Statistics, Northeas t Normal University, China ,abaizd@nenu.edu.cn ;
bhuj156@nenu.edu.cn ;czhouhc782@nenu.edu.cn
2Department of Mathematics, North Carolina State Universit y, USA ,djack@ncsu.edu
LetBn=1
n(Rn+T1/2
nXn)(Rn+T1/2
nXn)∗, whereXnis ap×n
matrix with independent standardized random variables, Rnis ap×nnon-
random matrix and Tnis ap×pnon-random, nonnegative deﬁnite Hermitian
matrix. The matrix Bnis referred to as the information-plus-noise type ma-
trix, where Rncontains the information and T1/2
nXnis the noise matrix
with the covariance matrix Tn. It is known that, as n→∞ , ifp/nconverges
to a positive number, the empirical spectral distribution o fBnconverges al-
most surely to a nonrandom limit, under some mild conditions . In this paper,
we prove that, under certain conditions on the eigenvalues o fRnandTn, for
any closed interval outside the support of the limit spectra l distribution, with
probability one there will be no eigenvalues falling in this interval for all n
sufﬁciently large.
1. Introduction. LetXn= (xij)be ap×nmatrix of independent and standardized
random variables (Exij=0,E|xij|2=1) ,Rnbe ap×nnon-random matrix and Tnbe a
p×pnon-random nonnegative deﬁnite Hermitian matrix. The matr ix
Bn=1
n(Rn+T1/2
nXn)(Rn+T1/2
nXn)∗,
is referred to as the information-plus-noise type matrix, w here the information is contained
in the matrix RnR∗
n/nand the matrix T1/2
nXnis the additive noise. The limiting spectral
distribution (LSD) of Bnhas been studied in [ 8], and the result is expressed in terms of the
empirical spectral distribution (ESD) function FBn. More speciﬁcally, assume that uiand
tiare the paired eigenvalues of RnR∗
n/nandTnin their simultaneous spectral decomposi-
tion. it is shown in [ 8] that if the formation RnR∗
n/ncommutes with the noise covariance
Tn, and asmin{p,n}→∞ ,yn=p/n→y>0, the two-dimensional distribution function
Hn(u,t)=p−1/summationtextp
i=1I(ui≤u,ti≤t)converges weakly to a nonrandom limit distribution
H(u,t), then with probability one, FBnconverges in distribution to F,a nonrandom proba-
bility distribution function, whose Stieltjes transform s=sF(z)satisﬁes the equation system
(1.1)

s=/integraldisplaydH(u,t)
u
1+yg−(1+yst)z+t(1−y),
g=/integraldisplaytdH(u,t)
u
1+yg−(1+yst)z+t(1−y).
MSC2020 subject classiﬁcations :Primary 60E99, 26A46; secondary 62H99.
Keywords and phrases: Random matrix, LSD, Stieltjes transform, Information-plu s-noise matrix.
12
Moreover, for each z∈C+,(s,g)is the unique solution to ( 1.1) inC+. Here and in the
sequel, the Stieltjes transform of Fis deﬁned as
sF(z)=/integraldisplay1
λ−zdF(λ), z∈C+≡{z∈C:ℑz>0},
andFcan be obtained by the inversion formula
F(b)−F(a)=1
πlim
v→0+/integraldisplayb
aℑsF(x+iv)dx, (1.2)
wherea,bare continuity points of F.
The analytic properties of the Stieltjes transform of the LS D ofBnare studied in [ 9]. Let
Bn=1
n(Rn+T1
2nXn)∗(Rn+T1
2nXn). The eigenvalues of the matrix Bnare the same as
those of the matrix Bnexcept|n−p|zero eigenvalues. Therefore, their ESDs and Stieltjes
transforms have the following relations
FBn=/parenleftig
1−p
n/parenrightig
I[0,∞]+p
nFBn,
s(z)=−1−y
z+ys(z)andg(z)=−1
z(1+yg(z)),
wheres(z)is the Stieltjes transform of the LSD FBnandsn(z)=sFBn(z)andg(z)is the
limit ofgn=1
ptrTn(Bn−zI)−1. Then the equations in ( 1.1) become
(1.3)

z=−1−y
s−y
s/integraldisplaydH(t,u)
1+ug(z)+ts(z),
z=−1
g+y/integraldisplaytdH(t,u)
1+ug(z)+ts(z).
It is shown that for all x∈R+,limz∈C+→xsF(z)≡s(x)exists. And continuous dependence
ofFonyandHis readily apparent from the inversion formula ( 1.2) and ( 1.3). Moreover,
away from zero, Falso has a continuous density. Moreover, the support of a dis tribution
functionFis the set of all points xsatisfyingF(x+ε)−F(x−ε)>0for allε>0.Let
SFandSHdenote the support of FandH, respectively. Clearly, by deﬁnition of FandH,
we haveSF⊂[0,∞)andSH⊂[0,∞). Then, on intervals outside the support of probability
distribution function F,sF(x)exists and is increasing.
The focus of this paper is on intervals of R+≡R−{0}lying outside the support of F.
We will prove that when nis large, with probability one, there are no sample eigenval ues of
Bnfalling into the limiting spectral gaps. If T=σ2I, [3] proved that for any closed interval
contained in an open interval in R+outside the supports of the limiting distribution Fyn,Hn,
then, almost surely, no eigenvalues of Bnwill appear in this interval for all nlarge. And [ 4]
proved the exact separation theorem.
In this paper, we prove that, under certain conditions on the eigenvalues of RnandTn,
for any closed interval outside the support of the limit spec tral distribution, with probability
one there will be no eigenvalues falling in this interval for allnsufﬁciently large. Our main
result of this paper is as follows.
THEOREM 1.1. Assume that
(a)[a,b]⊂(c,d)⊂Sc
Fyn,Hn, withc>0for all large n;3
(b)The matrix Xnis thep×nupper-left conner of the double array of random variables xij
having means zero, variances one, second moments zero if com plex and there is a random
variableXwith ﬁnite fourth moment such that for a constant Kand for allx>0
1
pp/summationdisplay
i=1P(|xij|>x)≤KP(|X|)>x),
and
1
nn/summationdisplay
j=1P(|xij|>x)≤KP(|X|)>x);
(c)There exists a positive function ψ(x)↑∞ asx→∞ , andM>0such that
max
ijE|x2
ij|ψ(|xij|)≤M;
(d)n=n(p)withyn=p/n→y>0asn→∞ ;
(e)Forn=1,2,...,Rnis ap×nnonrandom matrix with1√nRnuniformly bounded in
special norm for all n;
(f)The matrix Tnis uniformly bounded in spectral norm and λ−1≤Kfor some constant K,
and is also commutative with (1/n)RnR∗
nand their joint spectral distribution Hn(u,t)
tends to a proper distribution H(u,t), whereλ−1=/integraltext
t−1dH(u,t).
Then, we have that
P(no eigenvalues of Bnappear in [a,b]for all large n)=1. (1.4)
REMARK 1.1. As mentioned in [ 1,3,5], assumptions (b)-(c) allow for the xijto depart
from merely being i.i.d.. After suitable truncation, centr alization, and scaling of the xij’s one
can assume these variables to be uniformly bounded.
The rest of this paper is organized as follows. Some prelimin ary results of proving the
theorem are introduced in Section 2. The proof of Theorem 1.1is split into the proofs of the
convergence of the random part and the convergence of the non -random part Sections 3 and
4, respectively. We complete the proof of Theorem 1.1in Section 5. Some technical lemmas
are given in Section 6.
2. Preliminary Results. In this section, we give some preliminary results for the pro of
of Theorem 1.1. Before the truncation and centralization steps, we give a l emma below that
can simplify the assumptions on the matrix of Xn.
LEMMA 2.1. Assume that the entries of {xij}are a double array of independent com-
plex random variables with mean zero, variance σ2, and satisfy the assumptions (b) – (e) of
Theorem 1.1. LetXn=(xij;i≤p,j≤n)be thep×nmatrix of the upper-left corner of the
double array. Then, with probability one, we have
−2√yσ2≤liminfn→∞λmin(Sn−σ2(1+y)In)
≤liminfn→∞λmax(Sn−σ2(1+y)In)≤2√yσ2,
whereSn=n−1XnX∗
n.4
PROOF . The proof of Lemma 2.1is exactly the same as that of Theorem 5.10 of [ 2] after
the truncation and centralization. Therefore, we only pres ent the truncation and centralization
here, and the detailed proof of the lemma is omitted.
Without loss of generality, we assume σ= 1. We ﬁrst truncate the x-variables. Since
E|X|4<∞, we can select a sequence of slowly decreasing constants δn→0such that√nδn
is increasing, δ−2
nn2P(|X|>δn√n)→0and
(2.5)/summationdisplay
kδ−2
2k22kP(|X|≥2k/2δ2k)<∞.
Deﬁnexijn=xijI(|xij|≤δn√n)and construct a matrix /hatwideSnwith the same structure of Sn
by replacing xijwithxijn. Then, we have
P/parenleftig
/hatwideSn/ne}ationslash=Sn,i.o./parenrightig
≤lim
M→∞∞/summationdisplay
k=MP
/uniondisplay
2k<n≤2k+1/uniondisplay
i≤p,j≤n(xijn/ne}ationslash=xij)

≤lim
M→∞∞/summationdisplay
k=MP
/uniondisplay
2k<n≤2k+1/uniondisplay
i,j≤2k+1(|xij|≥δ2k2k/2)

= lim
M→∞∞/summationdisplay
k=MP
/uniondisplay
i,j≤2k+1(|xij|≥δ2k2k/2)

≤lim
M→∞K∞/summationdisplay
k=M22k+2P/parenleftig
|X|≥δ2k2k/2/parenrightig
=0.
This shows that the truncation doesn’t affect the limits of e xtreme eigenvalues of Sn. Next,
let/tildewideSnbe the matrix constructed as Snwithxijreplaced by ˜xij=xijn−Exijn. By Theorem
A.46 of [ 2], we have
max
1≤i≤p|λi(/hatwideSn)−λi(/tildewideSn)|2≤/vextenddouble/vextenddouble/vextenddouble/vextenddouble1√n(Exijn)/vextenddouble/vextenddouble/vextenddouble/vextenddouble2
≤sup
|c1|2+···+|c2
p|=11
np/summationdisplay
i=1n/summationdisplay
j=1/parenleftiggp/summationdisplay
i=1|ci|E|xijI(|xij|>δn√n)/parenrightigg2
≤1
np/summationdisplay
i=1n/summationdisplay
j=1/parenleftbigg/integraldisplay∞
δn√nP(|xij|>x)dx/parenrightbigg2
≤δ−1
nn1/2/parenleftbigg
K/integraldisplay∞
δn√nP(|X|>x)dx/parenrightbigg
=Kδ−3
nn−1/2→0,
where we have used the fact that/integraldisplay∞
δn√nP(|xij|>x)dx≤δ−1
nn−1/2/integraldisplay∞
0xP(|xij|≥x)dx≤δ−1
nn−1/2.
This shows that the centralization doesn’t affect the limit s of extreme eigenvalues of Sn.5
Therefore, when prove Lemma 2.1, we may assume that
(1)E(xij)=0,E(|xij|2)≤1,and E(|xij|2)→1. (2.6)
(2)/summationdisplay
i(or)jE(|xij|ℓ)≤/braceleftigg
bn(δn√n)ℓ−3for allℓ≥3
porn forℓ=1,2.
Here, the third conclusion of assertion (1) in ( 2.6) follows from
1−E|x2
ijn|=E|x2
ij|I(|xij|≥δn√n)≤ψ−1(δn√n)E|x2
ij|ψ(|xij|)→0.
As for conclusion (2) in ( 2.6), it needs assumption (b) of Theorem 1.1,
p/summationdisplay
i=1E(|xij|ℓ)=p/summationdisplay
i=1ℓ/integraldisplayδn√n
0xℓ−1P(|xij|>x)dx≤Kpℓ/integraldisplayδn√n
0xℓ−1P(|X|>x)dx
=KpE|X|ℓ(|X|≤δn√n),
and the routine approach. Similar to the other assertion. Th en Lemma 2.1can be proved by
the same lines as those of Theorem 5.10 of [ 2], with noticing the sufﬁciency of Lemma B.25
of [2] in the latter remaining hold after truncation and centrali zation.
Now, we turn to the preliminary for the proof of Theorem 1.1. First, we deﬁne ˆxij=
xijI(|xij|<C)−ExijI(|xij|<C)andˆyij=xijI(|xij|≥C)−ExijI(|xij|≥C)for some
constantCand deﬁne ˆX=(ˆxij)p×n,Y=X−ˆXand
ˆBn=1
n(Rn+T1/2
nˆX)(Rn+T1/2
nˆX)∗.
By Lemma 2.1and Lemma 6.7, we have
max
i≤p|λi(Bn)−λi(ˆBn)|≤1√n/bardblT1/2
nY/bardbl≤/radicalbig
/bardblTn/bardbl(1+√y)/radicalbig
E|X2|I(|X|≥C),
which can be arbitrarily small when Cis large.
Choosing [a′,b′]and(c′,d′)such thatc<c′<a′<a<b<b′<d′<d. SelectClarge
enough such that/radicalbig
/bardblTn/bardbl(1 +√y)/radicalbig
E|X2|I(|X|≥C)is smaller than the smallest gap
amongc<c′<a′<a<b<b′<d′<d. The intervals [a′,b′]and(c′,d′)satisfy the con-
ditions of Theorem 1.1for the matrix ˆBn. If we proved that no eigenvalues of ˆBnare falling
into the interval [a′,b′], then there will be no eigenvalues of Bnfalling in [a,b]. Therefore,
we may prove the Theorem 1.1under the additional assumption that the random variables
are uniformly bounded.
Similar to [ 3], we need to establish an estimate like Theorem 1.2 in [ 3]. Then we will be
devoted to proving the following.
THEOREM 2.2. Letz=x+ivnwithvn=n−δ, whereδ>0. Then for some small but
constantδ>0,
sup
x∈[a,b]nvn|sn(x+ivn)−s0
n(x+ivn)|a.s.−→0, (2.7)
wheres0
n(z)is the solution to (1.1)with(y,H)replaced by (yn,Hn).6
As shown in [ 1,3], Theorem 2.2can prove Theorem 1.1. Let[a′,b′]⊂(c,d)for which
a′<a,b′>b. Then from Theorem 2.2, it is straightforward to argue (more details will be
presented in Section 5)
sup
x∈[a,b]/vextendsingle/vextendsingle/vextendsingle/vextendsingle/integraldisplayI([a′,b′]c)d(FBn(λ)−Fyn,Hn(λ))
((x−λ)2+v2n)((x−λ)2+2v2n)···((x−λ)2+kv2n)
+/summationdisplay
λj∈[a′,b′]v2k
n
((x−λ)2+v2n)((x−λ)2+2v2n)···((x−λ)2+kv2n)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle=o(1),a.s.
where theλjare the eigenvalues of Bn. Since the integral converges a.s. to zero, one can
argue, by contradiction that there can be no eigenvalues of Bnin[a,b]for allnlarge.
We will prove Theorem 2.2in Sections 3-5. Before the proof, some lemmas needed in the
proof are listed next, and Section 6 contains the mathematic al tools in the previous sections.
LEMMA 2.3. Under the conditions of Theorem 2.1 in [ 8], wheny≤1, the real part of
1+yg(z)is always positive.
PROOF . Writes(z)=s1+is2andg=g1+ig2, wheres1,s2,g1andg2are both real.
Whenx≤0andz=x+ivwithv≥0,ℜgn(z)≥0, as a limit,g1(z)≥0, hence1+yg1>0.
Therefore, we only need to show the lemma for ℜz>0. Whenx=ℜz→∞ andv=ℑz≥0
ﬁxed, one can easily show that g(z)→0and hence 1 +yg1(z)→1>0for all large x.
Therefore, there exists a constant µ>0such that when x>µ ,1+yg1(z)>0. Sinceg1(z)is
a continuous function of x, if the lemma is untrue, then there exists a x>0and av≤0such
that1+yg1(z)=0 . We will show the lemma by deriving a contradiction to this as sumption.
Comparing the real parts of two sides of the two equations of ( 1.1), we obtain
s1=−B0x−yB1(xs1−vs2)+B1(1−y),
−1
y=−B1x−yB2(xs1−vs2)+B2(1−y),
where
Bj=/integraldisplaytjdH(u,t)/vextendsingle/vextendsingle/vextendsingle/vextendsingleu
1+yg(z)−(1+ys(z)t)z+t(1−y)/vextendsingle/vextendsingle/vextendsingle/vextendsingle2,j=0,1,2.
From the two equations, we obtain
s2=(1
y−xB1+B2(1−y))(1+xyB1)−xyB2(−xB0+B1(1−y))
−vyB2(1+xyB1)+vxy2B1B2
=−(1
y+B2(1−y))+x2yB2
1−x2yB2B0
vyB2.
We get a contradictory by Cauchy-Schwarz inequality B2
1≤B0B1and−(1
y+B2(1−y))<
0. The proof of the lemma is complete.
LEMMA 2.4. Under the conditions of Theorem 2.1 in [ 8], for each large n, the density of
Fyn,Hn
0 , is bounded by Kx−1/2for some constant K. Hence,Fyn,Hn
0 satisﬁes the Lipschitz
condition with index1
2.7
PROOF . By the inversion formula ( 1.2), the density of Fyn,Hn
0 equalsπ−1ℑs0
n(x). There-
fore, the ﬁrst assertion follows by estimating the bound of s0
n(x). Whenℑs0
n(x) = 0 , the
density is 0, it is surely bounded. We only need to consider the case where its imaginary part
is positive. Note that s0
nsatisﬁes the ﬁrst equation in ( 1.1), taking its imaginary part we obtain
ℑs0
n(x)=/integraldisplay uℑ(g0
n(x))
|1+yng0
n|2dHn(u,t)
/vextendsingle/vextendsingle/vextendsingle/vextendsingleu
1+yng0n−(1+ynst)x+t(1−yn)/vextendsingle/vextendsingle/vextendsingle/vextendsingle2
+/integraldisplayynxtℑ(s0
n(x))dHn(u,t)/vextendsingle/vextendsingle/vextendsingle/vextendsingleu
1+yng0n−(1+ynst)x+t(1−yn)/vextendsingle/vextendsingle/vextendsingle/vextendsingle2.
Dropping the non-negative ﬁrst term and then eliminating ℑ(s0
n(x)), we obtain
1>/integraldisplayynxtdHn(u,t)/vextendsingle/vextendsingle/vextendsingle/vextendsingleu
1+yg0n−(1+ynst)x+t(1−yn)/vextendsingle/vextendsingle/vextendsingle/vextendsingle2. (2.8)
On the other hand, by the ﬁrst equation of ( 1.1) and the Cauchy-Schwarz inequality, we
obtain
|s0
n(x)|≤
/integraldisplay1
tdHn(u,t)/integraldisplaytdHn(u,t)/vextendsingle/vextendsingle/vextendsingle/vextendsingleu
1+yg0n−(1+ynst)x+t(1−yn)/vextendsingle/vextendsingle/vextendsingle/vextendsingle2
1/2
≤λ−11√ynx.
Hence, the ﬁrst assertion of the lemma is proved. The second a ssertion is a natural conse-
quence of the ﬁrst. In fact, for any 0≤a<b<∞, we have
Fyn,Hn
0(b)−Fyn,Hn
0(a)=/integraldisplayb
afyn,Hn
0(t)dt≤K/integraldisplayb
at−1/2dt
≤2K(√
b−√a)=2Kb−a√
b+√a≤2K|b−a|1/2.
The proof is complete.
LEMMA 2.5. Supposez=x+ivnandvn≥n−1/10,
sup
x∈[−A,A]|sn(z)−s0
n(z)|≤√vn,
whereA=v−2
n. Then
Fyn,Hn
0([a,b])≤√vn, (2.9)
for all large n.
PROOF . We shall use Lemma 6.1to prove this lemma. Choose B=v−1.5
n. Then, with
probability one, for all large n,
Fn([−B,B]c)≤B−11
ptrBn≤KB−1(2.10)8
for some absolute constant K. Similarly, we can prove
Fyn,Hn
0([−B,B]c)≤KB−1(2.11)
sinceFnD−→Fy,H
0andFyn,Hn
0D−→Fy,H
0.
By the selection of AandB, the parameter κsatisﬁes ( 6.50). Applying Lemma 6.1, the
lemma follows.
LEMMA 2.6. Under the conditions of Theorem 1.1, the spectral norm of (K−zI)−1is
bounded for all x∈[a,b]andz=x+ivn, where
K=n−1RnR∗
n
1+ynEgn(z)−zEsn(z)Tn.
PROOF . Since[a,b]is a subinterval of (c,d)⊂SFnfor all largen, there exists 0<ε1<ε2
such that [a′′,b′′]=[a−ε2,b+ε2]⊂(c,d). Write(s0(x),g0(x))be the extended solution,
i.e., limits of regular solutions for z∈C+, to (1.3). By part (b) of Theorem 4 in [ 9], for each
x∈[a′′,b′′], we have
inf{|ug0(x)+ts0(x)+1|:(u,t)∈SH}>0
and consequently
inf
x∈[a′′,b′′]{|ug0(x)+ts0(x)+1|:(u,t)∈SH}>0.
Since(yn,Hn)→(y,H), forn→∞ , there exist s0
nandg0
nwhich are extended solutions
to the equation ( 1.3) with(y,H)replaced by (yn,Hn)and
δn:= inf
x∈[a′,b′]min
i≤p{|uig0
n(x)+tis0
n(x)+1|:(ui,ti)∈SHn}>0, (2.12)
where[a′,b′]=[a−ε1,b−ε1].
We claim that there is a positive lower bound for δn≥δ >0for all large n. Convert
(s0
n,g0
n)to(s0
n,g0
n)which satisﬁes ( 1.1). Since the integrands of the two integrals are uni-
formly bounded, by DCT, we conclude that s0
n(z)→s0(z)andg0
n(z)→g0(z)for allz∈C+.
Thus,Fyn,Hn→Fweakly. Therefore, {Fyn,Hn}is tight and so is {Fyn,Hn}. Thus, there is
a constantBsuch thatFyn,Hn([B,∞))<1/3. Consequently, for x∈[a′′,b′′]
(s0
n)′(x)=/integraldisplaydFyn,Hn(λ)
(λ−x)2≥/integraldisplayB
0dFyn,Hn(λ)
(λ−x)2≥2
3B2≥m>0. (2.13)
It is proved in Theorem 4 of [ 9] thatg′=(1+s′cB2)/(g−2−cA2), so we have g′
n(x)≥m
for some constant m>0.
By Theorem 4 in [ 9], for each n= 0 or large and every supporting point (ui,ti)of
Hn, the function uign(x) +tisn(x)is increasing and continuous. Therefore, the inﬁ-
mum of|uign(x) +tisn(x) + 1|forx∈[a′′,b′′]reaches atx=a′′orb′′, say ata′′and
uign(x)+tisn(x)+1>0. Then, for any x∈[a′,b′], we have
uign(x)+tisn(x)+1≥uign(a′)+tisn(a′)+1 (2.14)
≥uign(a′′)+tisn(a′′)+1+/integraldisplaya′′
a′(uig′
n(x)+tis′
n(x))
≥0+(a′−a′′)m∆=(ε2−ε1)m∆:=δ>0.9
If the inﬁmum reaches are b′′, thenuign(x)+tisn(x)+1<0. One can similarly prove
(2.14), namely,
uign(x)+tisn(x)+1≤−δ<0.
The assertion is proved.
For anyz=x+ivn,x∈[a′,b′],we have
|Esn(z)−s0(x)|≤|Esn(z)−s0
n(x)|+|s0
n(z)−s0(x)|→0,
|Egn(z)−g0(x)|≤|Egn(z)−g0
n(x)|+|g0
n(z)−g0(x)|→0.
So, we will have
min
i≤pinf
x∈[a′,b′]|uign(x)+tisn(x)+1|>δ+o(1).
Hence, we have
/bardbl(K−zI)−1/bardbl≤K. (2.15)
LEMMA 2.7. Under the conditions of Theorem 1.1, for any bounded non-random vector
u,
sup
x∈[a,b]|u∗(Bn−zI)−1u−u∗(K−zI)−1u|→0, a.s.
and hence when x∈[a,b],u∗(Bn−zI)−1uare uniformly bounded with probability one.
Especially, the conclusion is true for u=1√nrk,k=1,2,...,p.
PROOF . The proof of the limit can be done by multiplying u∗from left and ufrom right
to the equation (K−zI)−1−(Bn−zI)−1and following similar lines as proving the approx-
imation of the Stieltjes transform. The uniformly boundedn ess ofu∗(Bn−zI)−1ufollows
from Lemma 2.6and the fact that uis bounded.
DEFINITION 2.8. Random variables xnandynare said to be similar in moment denoted
asxnm≃ynif for any integer ℓ≥1,E|xn−yn|2ℓ≤Kℓn−2ℓv−6ℓ
n. Ifynis non-random and
bounded, we say that xnis bounded in moment, and denoted as xnm<∞. Ifxn−yncan be
written as a sum of a non-negative constant and a random varia ble which is similar in moment
with 0, then we say xnis larger than or equal to ynin moment, denoted as xnm
≥yn.
REMARK 2.1. If a random variable is bounded in moment, then it can be b asically treated
as bounded when computing the expectation of the product of i t with a nonnegative random
variablewwhich is bounded by v−ν
nfor some constant ν, in fact, for any ε>0, its expectation
of the product is less than (µn+ε)Ew+v−ν
nP(|ιn|>ε) = (µn+ε)Ew+o(1), ifvn≥
n−1/10andℓis chosen large enough.
LEMMA 2.9. Under the conditions of Theorem 1.1, for allzwithx∈[a,b], the quantities
1/βk,1/˘βkare uniformly bounded in moment.10
PROOF . By Theorem 1 in [ 9], there is a constant δ>0such that for all z∈C+with
x∈[a,b],gis bounded from above and hence |1+yg(z)|>δ>0. SinceFyn,Hn→Fy,H, we
haveg0
n(z)→g(z)uniformly on C+and thus when nis large|1+yng0
n(z)|>δ>0, where
δis an absolute constant, may take different value at differe nt appearances. Consequently, by
Lemma 6.2,|1+yng0
nk(z)|>δ>0.
At ﬁrst, we point out that these bounds will be used for provin g the“b”bounds and hence
we may assume that the “a”bounds are true and thus
E|sn(z)−s0
n(z)|2ℓ≤Kℓn−2ℓv−2ℓ
n, (2.16)
E|gn(z)−g0
n(z)|2ℓ≤Kℓn−2ℓv−2ℓ
n,
ifz=x+ivnwithvn≥n−1/8and choosing ℓ≥4. Here, the convergence is true uniformly
for allx∈[e,f]. Using the notation given in Deﬁnition 2.8, we may say that (1+ygnk(z))−1
is uniformly bounded in moment.
If the angle between the complex numbers n−1r∗
k(Bnk−zI)−1rkand1+yngnk(z)is
less than or equal to 90◦, then
|˘βk|=|1+yngnk(z)+n−1r∗
k(Bnk−zI)−1rk|≥|1+yngnk(z)|≥δ
and thus1/˘βk(x)is bounded from above.
Now, assume that the angle between n−1r∗
k(Bnk−zI)−1rkand1+yngnk(z)is larger
than90◦. If|n−1r∗
k(Bnk−zI)−1rk|<δ/2, then˘βk≥1/2δand thus 1/˘βkis bounded by
2/δfrom above. Now, we assume |n−1r∗
k(Bnk−zI)−1rk|≥δ/2. By the formula
n−1r∗
k(Bn−zI)−1rk (2.17)
=n−1r∗
k(Bnk−zI)−1rk−n−2r∗
k(Bnk−zI)−1αα∗(Bnk−zI)−1rk
βk
m=n−1r∗
k(Bnk−zI)−1rk−n−2r∗
k(Bnk−zI)−1rkr∗
k(Bnk−zI)−1rk
˘βk
m=n−1r∗
k(Bnk−zI)−1rk(1+n−1x∗
kT1/2
n(Bnk−zI)−1T1/2
nxk)
˘βk
m=n−1r∗
k(Bnk−zI)−1rk(1+yng0
n(z))
˘βk,
where we have used Lemma 6.2for
n−1x∗
kT1/2
n(Bnk−zI)−1T1/2
nxkm=n−1trTn(Bnk−zI)−1
m=yngn(z)m=yg0
n(z).
From Lemma 2.7,n−1r∗
k(Bn−zI)−1rkis bounded from above, consequently, 1/˘βkis
bounded from above.
Sinceβkm=˘βk,1/βkis bounded in moment from above.
Similar to ( 2.17), one may establish the following lemma.
LEMMA 2.10. For any random vector vwhich is of bounded norm and independent of
rk, for anyx∈[a,b]we have
v∗D−1
nkrk
˘βkm=v∗D−1
nrk
1+yg0(z)11
LEMMA 2.11. Under the conditions of Theorem 1.1, for any integer ℓ≥1and non-
random vector α=(a1,...,ap)′
E|α∗xk|2ℓ≤Kℓ

p/summationdisplay
j=1|a2
j|
ℓ
+p/summationdisplay
j=1|a2ℓ
j|

PROOF . This is a consequence of Burkholder inequality, Lemma 6.4and the facts that
E|x2
kj|≤1and|xkj|≤C, after the truncation.
LEMMA 2.12. Under the conditions of Theorem 1.1, for any integer ℓ≥1and non-
random Hermitian matrix M=(mij)
E/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglex∗
kMxk−p/summationdisplay
j=1mjjE|x2
kj|/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle2ℓ
≤≤Kℓ[(trMM∗)ℓ+tr(MM∗)ℓ].
PROOF . Write
x∗
kMxk−p/summationdisplay
j=1mjjE|x2
kj|=p/summationdisplay
j=1mjj(|x2
kj|−E|x2
kj|)+2p/summationdisplay
j1=2j1−1/summationdisplay
j2=1ℜ(mj1j2xkj1xkj2).
Applying Burkholder inequality to the ﬁrst term, we obtain
E
p/summationdisplay
j=1mjj(|x2
kj|−E|x2
kj|)
2ℓ
≤Kℓ

p/summationdisplay
j=1|mjj|2
ℓ
+p/summationdisplay
j=1|mjj|2ℓ
≤Kℓ(trMM∗)ℓ.
Applying Burkholder inequality to the second term, we obtai n
E
2p/summationdisplay
j1=2j1−1/summationdisplay
j2=1ℜ(mj1j2xkj1xkj2)
2ℓ
≤Kℓ

p/summationdisplay
j1=2E/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglej1−1/summationdisplay
j2=1mj1j2xkj2/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle2
ℓ
+p/summationdisplay
j1=2E/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglej1−1/summationdisplay
j2=1mj1j2xkj2/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle2ℓ
.
By independence and Jensen inequality, the ﬁrst term above i s less than or equal to
Kℓ
p/summationdisplay
j1=1E/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglep/summationdisplay
j2=1mj1j2xkj2/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle2
ℓ
≤KℓE
p/summationdisplay
j1=1/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglep/summationdisplay
j2=1mj1j2xkj2/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle2
ℓ
=KℓE(x∗
kMM∗xk)ℓ≤Kℓ[(trMM∗)ℓ+tr(MM∗)ℓ],
where the last inequality follows by induction. Again, by Bu rkholder inequality to the second
term, we have
p/summationdisplay
j1=1E/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglep/summationdisplay
j2=1mj1j2xkj2/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle2ℓ
≤Kℓp/summationdisplay
j1=1

p/summationdisplay
j2=1|mj1j2|2
ℓ
+p/summationdisplay
j2=1|mj1j2|2ℓ

≤Kℓ[(trMM∗)ℓ+tr(MM∗)ℓ].
Collect the inequalities above, the proof of the lemma is com plete.12
3. Convergence of the Random Part. Constants appearing in inequalities are desig-
nated byK, sometimes subscripted. They are nonrandom and may differ f rom one appear-
ance to the next.
We ﬁrst introduce some notation to simplify the writing. Den oteDn=Bn−zI,Dnk=
Bnk−zI=Dn−αkα∗
k,Q=K−zI, where
Bnk=Bn−αkα∗
k, αk=1√n(rk+T1/2xk),
K=1
nRnR∗
n
1+yEgn(z)−zEsn(z)Tnandsn=−1−yn
z+ynsn(z).
Also, let E0(·)be the expectation and Ek(·)be the conditional expectation with respect
to theσ-ﬁeld generated by the random variables {xij,i,j>k}. We employ the martingale
technique to decompose the random part sn−Esnas a sum of martingale differences
sn−Esn=n/summationdisplay
k=1(Ek−Ek−1)sn=n/summationdisplay
k=1(Ek−Ek−1)(sn−snk) (3.18)
=1
pn/summationdisplay
k=1(Ek−Ek−1)α∗
kD−2
nkαkβ−1
k
m=1
pn/summationdisplay
k=1(Ek−Ek−1)(σnk˘β−1
k−σnk˘β−1
kβ−1
kεk),
where
βk=1+n−1α∗
kD−1
nkαk,
˘βk=1+n−1r∗
kT1/2D−1
nkrk+n−1trTD−1
nk,
εk=β−1
k−˘β−1
k
σnk=n−1r∗
kD−2
nkrk+n−1trTD−2
nk,
σnk=n−1(α∗
kD−2
nkαk)−σnk.
In the following, we will show for vn=κn−1/m,msuitable large, and any ℓ≥1
E|sn(z)−Esn(z)|2ℓ≤/braceleftbigg
Kℓv−6ℓ
nn−2ℓ(a)
Kℓn−2ℓ,(b)(3.19)
and by a similar procedure
E|gn(z)−Egn(z)|2ℓ≤/braceleftbigg
Kℓv−6ℓ
nn−2ℓ(a)
Kℓn−2ℓ,(b)(3.20)
wheregn(z)=p−1trTD−1
n. And for any bounded nonrandom vector u
E|u∗D−1
nu−Eu∗D−1
nu|2ℓ≤Kℓn−ℓv−4ℓ. (3.21)
The“a”bound holds uniformly for all x∈[e,f], it contributes to a preliminary estimate
for the convergence of sn(x+ivn)−s0
n(x+ivn). Based on the preliminary estimation, we
will establish a convergence rate of the ESD /bardblFn−Fyn,Hn
0/bardbl=O(√vn). The“b”bound holds
uniformly for all x∈[a,b], it is considered as a reﬁnement of the estimate of the conver gence13
ofsn(x+i/tildewidevn)−Esn(x+i/tildewidevn). The reﬁned convergence rate will be proved under an addi-
tional condition that Fyn,Hn
0([a′,b′])=O(/tildewidev4
n)which is established based on the “a”bound,
where/tildewidevn=8√vnand[a′,b′]=[a−ε,b+ε]⊂(c,d)⊂SFyn,Hn
0,ε>0. Notice these bounds
hold for allℓ≥1once they are shown to be true for sufﬁciently large ℓ. For brevity, we use
an abused notation that simpliﬁes /tildewidevnasvn. That means, the vn’s in“b”bounds stands for
8√vnas those in “a”bounds. Namely in the proofs of “b”bounds will be proceeded under
the additional condition that Fyn,Hn
0([a,b])=O(v4
n).
Before proceeding, we introduce some lemmas for the next pro ofs. We ﬁrst establish
(3.19)(a). Splitting the interval [e,f]intonequal parts and write the set of splitting points as
Sn. So,/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglesup
x∈[e,f]|sn(z)−Esn(z)|−max
x∈Sn|sn(z)−Esn(z)|/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
≤max
x∈Snsup
|x1−x2|≤(f−e)/2n[|sn(z1)−sn(z2)|+|Esn(z1)−Esn(z2)|]
≤(f−e)n−1v−2
n.
So, we have
sup
x∈[e,f]E|sn(z)−Esn(z)|2ℓ
≤max
x∈SnE|sn(z)−Esn(z)|2ℓ+Kℓn−2ℓv−4ℓ
n.
Note that ℑ(˘βk)=vn(n−1/bardbl(D−1
nkrk/bardbl2+n−1tr[D−1
nkD−1
nk])≥vn|σnk|and hence |σnk˘β−1
k|≤
1/vn, whereDdenotes the conjugate transpose of D. Furthermore, it is already known that
|σnk|≤Kv−2
nand|β−1
k|≤|z|v−1
n. Then, by Burkholder inequality, i.e. Lemma 6.4, and the
decomposition ( 3.18), forx∈Sn, we have for vn=n−δwithδ<1/(6ℓ+1),
E|sn(z)−Esn(z)|2ℓ(3.22)
≤Kℓp−2ℓ/parenleftiggn/summationdisplay
k=1E|σnk˘β−1
k−σnk˘β−1
kβ−1
kεk|2/parenrightiggℓ
+Kℓp−2ℓn/summationdisplay
k=1E|σnk˘β−1
k−σnk˘β−1
kβ−1
kεk|2ℓ
≤Kℓp−2ℓ/parenleftiggn/summationdisplay
k=1v−2
nE|σnk|2+v−4
nE|εk|2/parenrightiggℓ
+Kℓp−2ℓn/summationdisplay
k=1[v2ℓ
nE|σnk|2ℓ+v−4ℓ
nE|εk|2ℓ].
Furthermore, we have
E|σ2
nk|≤2n−2[4E|r∗
kD−2
nkT1/2xk|2+E|x∗
kT1/2D−2
nkT1/2xk−trTD−1
nk|2] (3.23)
≤2n−2[KEr∗
kD−2
nkTnD−2
nkrk+EtrTD−2
nkTnD−2
nk]≤Kn−1v−4
n,
and
E|ε2
k|≤2n−2[KE|r∗
kD−1
nkT1/2xk|2+E|x∗
kT1/2D−1
nkT1/2xk−trTD−1
nk|2] (3.24)
≤2n−2[KEr∗
kD−1
nkTnD−1
nkrk+EtrTD−1
nkTnD−1
nk]≤Kn−1v−2
n,14
and by Lemmas 6.5,2.11 and2.12.
E|σ2ℓ
nk|≤2ℓn−2ℓ[2E|r∗
kD−2
nkT1/2xk|2ℓ+E|x∗
kT1/2D−2
nkT1/2xk−trTD−2
nk|2ℓ] (3.25)
≤22ℓn−2ℓ[22ℓE/bardblr∗
kD−2
nkT1/2
n/bardbl2ℓ+Etr(T2D−2
nkTnD−2
nk)ℓ]
≤o(n−ℓv−4ℓ
n)=o(n−1v2ℓ
n)
and
E|ε2ℓ
k|≤Kℓn−2ℓ+1v−ℓ
n=o(n−1v4ℓ
n). (3.26)
Substituting these into ( 3.22), we obtain ( 3.19)(a). The proof of ( 3.19)(a)is done.
The proofs of ( 3.20)(a)and ( 3.21) are similar to that ( 3.19)(a)and hence omitted.
Now, let us consider the reﬁnement ( 3.19)(b)under the additional condition that
F([a′,b′])=o(v4
n). Review the proof of ( 3.19)(a)we only need to reﬁne the estimates ( 3.23)
and ( 3.24).
Write the spectral decomposition of Bnk=/summationtextn
j=1λnkjvkjv∗
kj, then we have
1
nEtrTD−1
nkTnD−1
nk=1
nn/summationdisplay
j=1(v∗
kjTnvkj)2|λnkj−z|−2
=1
n/summationdisplay
λnkj/∈[a′,b′](v∗
kjTnvkj)2|λnkj−z|−2+1
n/summationdisplay
λnkj∈[a′,b′](v∗
kjTnvkj)2|λnkj−z|−2
≤1
nν−2/summationdisplay
λnkj/∈[a′,b′](v∗
kjTnvkj)2+Kv−2
n(Fn([a′,b′])+O(p−1))
≤K
ν2n/summationdisplay
λnkj/∈[a′,b′]+O(p−1)=Kν−2EFn([a′,b′])+O(p−1)
≤Kν−2v4
n+o(1),
whereν= min(a−a′,b′−b)and the last step follows from the facts that v∗
kjTnvkjis
bounded since Tnis bounded in spectral norm and that the difference of the num bers of
eigenvalues of Bnkfalling in the interval [a′,b′]from that of Bnis at most 1by the Lemma
6.6. Consequently, we obtain
1
nEtrTnD−1
nkTnD−1
nk=o(1). (3.27)
Similarly, we can prove
1
nEtrTnD−2
nkTnD−2
nk=o(1). (3.28)
Next, we shall estimate n−1r∗
kD−1
nkTnD−1
nkrk≤Kn−1r∗
kD−1
nkD−1
nkrk. We use the size reduc-
ing formula D−1
n=D−1
nk−D−1
nkαkα∗
kD−1
nk
βkand by similar steps to ( 2.17), we get
n−1r∗
kD−1
nD−1
nrk
=n−1r∗
kD−1
nkD−1
nkrk−n−1r∗
kD−1
nkαkα∗
kD−1
nkD−1
nkrk
βk
−n−1r∗
kD−1
nkD−1
nkαkα∗
kD−1
nkrk
βk+n−1r∗
kD−1
nkαkα∗
kD−1
nkD−1
nkαkα∗
kD−1
nkrk
βkβk15
m=n−1r∗
kD−1
nkD−1
nkrk−n−1r∗
kD−1
nkrkr∗
kD−1
nkD−1
nkrk
βk
−n−1r∗
kD−1
nkD−1
nkrkr∗
kD−1
nkrk
βk+n−1r∗
kD−1
nkrkr∗
kD−1
nkD−1
nkrkr∗
kD−1
nkrk
βkβk
m=n−1r∗
kD−1
nkD−1
nkrk×/parenleftigg
1−n−1r∗
kD−1
nkrk
1+n−1α∗
kD−1
nkαk+ynEgn/parenrightigg
×/parenleftigg
1−n−1r∗
kD−1
nkrk
1+n−1α∗
kD−1
nkαk+Egn/parenrightigg
=n−1r∗
kD−1
nkD−1
nkrk|1+ynEgn|2
|˘βk|2.
The last step follows by Lemma 2.9. Therefore, we obtain
n−1r∗
kD−1
nkD−1
nkrk
|˘βk|2m=n−1r∗
kD−1
nD−1
nrk
|1+ynEgn|2. (3.29)
Note that
|βk|2m=|˘βk|2,and1+ynEgn→1+yg0.
Hence, by the spectral decomposition of Bn=/summationtextn
j=1λnjvjv∗
j, we have
n/summationdisplay
k=1n−2r∗
kD−1
nkD−1
nkrk
|˘βk|2≤Kn/summationdisplay
k=1n−2r∗
kD−1
nD−1
nrk
|1+yg0|2≤Kn−2trRnR∗
nD−1
nD−1
n(3.30)
=Kn−1p/summationdisplay
j=1v∗
j(RnR∗
n/n)vj|λj−z|−2
=Kn−1/summationdisplay
λj/∈[a′,b′]v∗
j(RnR∗
n/n)vj|λj−z|−2+Kn−1/summationdisplay
λj∈[a′,b′]v∗
j(RnR∗
n/n)vj|λj−z|−2
≤Kn−1/summationdisplay
λj/∈[a′,b′]v∗
j(RnR∗
n/n)+Kv−2
nFn([a′,b′])
≤oa.s(1),
where the second inequality follows by |1+yg0|≥δ>0due to Theorem 1 in [ 9], the last
step follows since v∗
j(RnR∗
n/n)vjis bounded and Fn([a′,b′])=oa.s(v4
n).
Finally, similarly applying the size reducing formula to th e ﬁrstD−1and the last D−1, we
obtain
n−1r∗
kD−2
nD−2
nrk
m=n−1r∗
kD−1
nkD−1
nD−1
nD−1
nkrk−n−1r∗
kD−1
nkrk
βkn−1r∗
kD−1
nkD−1
nD−1
nD−1
nkrk
−n−1r∗
kD−1
nkD−1
nD−1
nD−1
nkrkn−1r∗
kD−1
nkrk
βk+n−1r∗
kD−1
nkD−1
nD−1
nD−1
nkrk|n−1r∗
kD−1
nkrk|2
|βk|216
m=n−1r∗
kD−1
nkD−1
nD−1
nD−1
nkrk/parenleftigg
1−n−1r∗
kD−1
nkrk
βk/parenrightigg/parenleftigg
1−n−1r∗
kD−1
nkrk
βk/parenrightigg
m=n−1r∗
kD−1
nkD−1
nD−1
nD−1
nkrk|1+yEgn|2
|˘βk|2.
Furthermore,
r∗
kD−1
nkD−1
nD−1
nD−1
nkrk
m=r∗
kD−2
nkD−2
nkrk−2ℜ/parenleftigg
r∗
kD−2
nkD−1
nkrk
βkr∗
kD−1
nkD−1
nkrk/parenrightigg
+1
|βk|2(r∗
kD−1
nkD−1
nkrk)3.
And similarly
r∗
kD−2
nD−1
nrkm=r∗
kD−1
nkD−1
nD−1
nkrk|1+yEgn|2
|βk|2
m=r∗
kD−2
nkD−1
nkrk|1+yEgn|2
|βk|2−2ℜ(r∗
kD−2
nkrk)r∗
kD−1
nkD−1
nrk|1+yEgn|2
β|βk|2.
Consequently, we obtain
n−1r∗
kD−2
nkD−2
nkrk
|˘βk|2
m=n−1r∗
kD−1
nkD−1
nD−1
nD−1
nkrk
|˘βk|2+2ℜ/parenleftigg
r∗
kD−2
nkD−1
nkrk
βk|βk|2r∗
kD−1
nkD−1
nkrk/parenrightigg
−1
|βk|4(r∗
kD−1
nkD−1
nkrk)3
m=n−1r∗
kD−2
nD−2
nrk
|1+yEgn|2+2ℜ/parenleftigg
r∗
kD−2
nD−1
nrk
βk|1+yEgn|2r∗
kD−1
nkD−1
nkrk/parenrightigg
+4ℜ/parenleftigg
r∗
kD−2
nrk
˘β2
k|˘βk|2(r∗
kD−1
nkD−1
nkrk)2/parenrightigg
−1
|βk|4(r∗
kD−1
nkD−1
nkrk)3
Therefore, we may similarly prove that
En/summationdisplay
k=1n−2r∗
kD−2
nkD−2
nkrk
|˘βk|2m
≤En/summationdisplay
k=1n−2r∗
kD−2
nD−2
nrk
|1+yEgn|2≤Kn−2tr(RnR∗
nD−2D−2)≤o(1).
Substituting these two estimate to ( 3.22)−(3.24), the proof of ( 3.19)(b)will be complete.
The assertions ( 3.20)(a)and ( 3.20)(b)can be similarly proved.
4. Convergence of the Nonrandom Part. Our next goal is to establish the convergence
rate of the nonrandom part, i.e., we shall prove that
sup
x∈[a,b]|Esn(x+ivn)−s0
n(x+ivn)|=O(n−1). (4.31)
This result is not only a necessary step for the proof of ( 2.7), it is also helpful to the proof of
the random part.
In this section, We ﬁrst prove that
Esn(z)−1
ptrQ−1=ωn1(z)=O(n−1), (4.32)
Egn(z)−1
ptrTnQ−1=ωn2(z)=O(n−1),17
whereQ=K−zIand
K=n−1RnR∗
n
1+ynEgn(z)−zEsn(z)Tn.
In the process of obtaining the LSD of Bn, we proved that
1
ptrTl
nQ−1−1
pEtrTl
n(Bn−zI)−1→0,forℓ=0,1. (4.33)
We only need to reﬁne the order of ( 4.33). For the reﬁnement, one needs only examine step
by step for all error terms to have the order O(n−1)whenx∈[a,b].
Recall the proof of ( 4.33), we have
1
ptrTℓ
nQ−1−1
pEtrTℓ
n(Bn−zI)−1(4.34)
=1
pn/summationdisplay
k=1Eα∗
kD−1
nkTℓ
nQ−1αk
βk−1
pEtrTℓ
n(Bn−zI)−1KQ−1
=1
pn/summationdisplay
k=1Eα∗
kD−1
nkTℓ
nQ−1αk
˘βk−1
pEtrTℓ
n(Bn−zI)−1KQ−1+o(1)
=1
pn/summationdisplay
k=1Er∗
kQ−1Tℓ
nD−1
nkrk+tr[TnQ−1Tℓ
nD−1
nk]
˘βk−1
pEtrTℓ
n(Bn−zI)−1KQ−1+o(1)
Using
(Bn−zI)−1=(Bnk−zI)−1−1
n(Bnk−zI)−1αkα∗
k(Bnk−zI)−1
βk,
we have
1
npn/summationdisplay
k=1Er∗
kQ−1Tℓ
nD−1
nkrk
˘βk(4.35)
=1
npn/summationdisplay
k=1/bracketleftigg
Er∗
kQ−1Tℓ
nD−1
nrk
˘βk+Er∗
kQ−1Tℓ
nD−1
nkαkα∗
kD−1
nkrk
n˘βkβk/bracketrightigg
=1
npn/summationdisplay
k=1/bracketleftigg
Er∗
kQ−1Tℓ
nD−1
nrk
˘βk+Er∗
kQ−1Tℓ
nD−1
nkαkα∗
kD−1
nkrk
n˘β2
k/bracketrightigg
+o(1)
=1
npn/summationdisplay
k=1/bracketleftigg
Er∗
kQ−1Tℓ
nD−1
nrk
˘βk+Er∗
kQ−1Tℓ
nD−1
nk(rkr∗
k+Tn)D−1
nkrk
n˘β2
k/bracketrightigg
+o(1)
=1
npn/summationdisplay
k=1/bracketleftigg
Er∗
kQ−1Tℓ
nD−1
nrk
˘βk+Er∗
kQ−1Tℓ
nD−1
nkrkr∗
kD−1
nkrk
n˘β2
k/bracketrightigg
+o(1)
Moving the second term to the left hand side, by noticing
1−Er∗
kD−1
nkrk
˘βk=E1+1
ntrTnD−1
nk
˘βk=E1+1
ntrTnD−1
n
n˘βk+O(n−1)
=1+yEgn(z)
n˘βk+O(n−1),18
we obtain
1
npn/summationdisplay
k=1Er∗
kQ−1Tℓ
nD−1
nkrk
˘βk=1
npn/summationdisplay
k=1Er∗
kQ−1TℓD−1
nrk
1+yEgn(z)+o(1) (4.36)
=1
npEtrRnR∗
nQ−1Tℓ
nD−1
n
1+yEgn(z)+o(1).
Similarly, we have
1
npn/summationdisplay
k=1Etr[TnQ−1Tℓ
nD−1
nk]
˘βk=1
npn/summationdisplay
k=1Etr[TnQ−1Tℓ
nD−1
nk]
βk+O(n−1) (4.37)
=−1
pEztr[TnQ−1Tℓ
nD−1
n]Esn(z)+O(n−1)
Substituting ( 4.36) and ( 4.37) into ( 4.34), we obtain
1
ptrTℓ
nQ−1−1
pEtrTℓ
nD−1
n
=1
nptrRnR∗
nQ−1Tℓ
nD−1
n
1+yEgn(z)+1
pEztr[TnQ−1Tℓ
nD−1
n]Esn(z)+o(1)−1
pED−1
nKQ−1.
Therefore, we will have
1
ptrTl
nQ−1−1
pEtrTl
n(Bn−zI)−1→0,forℓ=0,1.
Examining the above proof, we ﬁnd there are the following err ors yield in the transforma-
tions:
(1) In ( 4.34) due to the change βk→˘βk,
e1=1
pp/summationdisplay
k=1Eα∗
kQ−1TℓD−1
nkαk/parenleftbigg1
βk−1
˘βk/parenrightbigg
; (4.38)
(2) In ( 4.35) again due to the change βk→˘βk,
e2=1
pp/summationdisplay
k=1Er∗
kQ−1TℓD−1
nkαkα∗
kD−1
nkrk
n˘βk/parenleftbigg1
βk−1
˘βk/parenrightbigg
; (4.39)
(3) And removing the term involved T
e3=1
npp/summationdisplay
k=1Er∗
kQ−1TℓD−1
nkTD−1
nkrk
n˘βk; (4.40)
(4) In ( 4.36) changinggn(z)→Egn(z)in the denominator
e4=1
npp/summationdisplay
k=1Er∗
kQ−1TℓD−1
nkTD−1
nkrk
1+ynEgnyn(Egn−gn)
1+yngn; (4.41)
(5) In ( 4.37) changing ˘βkback toβk
e5=1
npn/summationdisplay
k=1EtrTnQ−1Tℓ
n(D−1
nk−D−1
n)
˘βk; (4.42)
e6=1
npn/summationdisplay
k=1Etr[TnQ−1Tℓ
nD−1
n]/parenleftbigg1
˘βk−1
βk/parenrightbigg
;19
Before estimating the six errors, we point out that E|εk|2=O(n−1)whenz=x+ivn
withx∈[a,b], whose proof is the same as that for ( 3.19)(b). And the order O(n−1)in the
reﬁned estimate is independent of vn, butxshould be restricted in [a, b]. And the estimates/vextendsingle/vextendsingle/vextendsingle/vextendsingle1
βk/vextendsingle/vextendsingle/vextendsingle/vextendsingleand/vextendsingle/vextendsingle/vextendsingle/vextendsingle1
˘βk/vextendsingle/vextendsingle/vextendsingle/vextendsingleare improved to be bounded in moment in Lemma 2.9.
In Lemma 2.6, it is proved that Q−1is bounded when x∈[a,b]. We can get that Q−1is
also bounded x∈[a′,b′]. The estimate E|α∗
kQ−1Tℓ
nD−1
nkαk|2=O(1)remains unchanged as
x∈[a,b]which can be proved by similar approach as showing ( 3.19)(b).
Using the identity
1
βk−1
˘βk=−εk
˘β2
k+ε2
k
˘β2
kβk. (4.43)
The error term e1in (4.38) is split into two terms:
e11=−1
pp/summationdisplay
k=1Eεkα∗
kQ−1Tℓ
nD−1
nkαk
˘β2
k, (4.44)
and
e12=1
pp/summationdisplay
k=1Eε2
kα∗
kQ−1Tℓ
nD−1
nkαk
˘β2
kβk, (4.45)
LetE(k)denote the conditional expectation given all random vector s exceptxk. Then by
Cauchy-Schwarz and Lemma 2.9, whenx∈[a,b], we obtain
|e11|≤1
pp/summationdisplay
k=1/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleEεk(α∗
kQ−1Tℓ
nD−1
nkαk−E(k)α∗
kQ−1Tℓ
nD−1
nkαk)
˘β2
k/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
≤K
pp/summationdisplay
k=1E|εk(α∗
kQ−1Tℓ
nD−1
nkαk−E(k)α∗
kQ−1Tℓ
nD−1
nkαk)|
≤K
p/parenleftiggp/summationdisplay
k=1E|εk|2p/summationdisplay
k=1E|α∗
kQ−1Tℓ
nD−1
nkαk−E(k)α∗
kQ−1Tℓ
nD−1
nkαk|2/parenrightigg1/2
=O(n−1),
where the proof of the last step is similar to that of ( 3.19)(b). At the same time,
|e12|≤1
p/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglep/summationdisplay
k=1Eε2
kα∗
kQ−1Tℓ
nD−1
nkTnD−1
nkαk
˘β2
kβk/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
≤C
pp/summationdisplay
k=1E|ε2
kα∗
kQ−1Tℓ
nD−1
nkTnD−1
nkαk|
≤C
pp/summationdisplay
k=1(E|ε2
kE(k)α∗
kQ−1Tℓ
nD−1
nkTnD−1
nkαk|
+E|ε2
k(α∗
kQ−1Tℓ
nD−1
nkTnD−1
nkαk−E(k)α∗
kQ−1Tℓ
nD−1
nkTnD−1
nkαk)|)
=O(n−1)+o(n−1),20
where the estimates in the last step, the ﬁrst term is similar to that of ( 3.19)(b)and the second
term follows by Cauchy-Schwarz and
E|α∗
kQ−1Tℓ
nD−1
nkTnD−1
nkαk−E(k)α∗
kQ−1Tℓ
nD−1
nkTnD−1
nkαk|2≤Cn−1v−2
n,
and
E|ε4
k|≤Cn−2v−4
n,
providedvn=n−δwithδ<1/3.
To evaluatee2, notice that
E(k)αkα∗
k=1
n(rkr∗
k+T1/2
nD−1
nkT1/2
n),
and consequently we have
|e2|≤|e21|+|e22|+|e23|,
where
|e21|=1
p/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglep/summationdisplay
k=1Er∗
kQ−1Tℓ
nD−1
nk(αkα∗
k−E(k)αkα∗
k)D−1
nkrk
n˘βk/parenleftbigg1
βk−1
˘βk/parenrightbigg/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
≤C
np/parenleftiggp/summationdisplay
k=1E|r∗
kQ−1Tℓ
nD−1
nk(αkα∗
k−E(k)αkα∗
k)D−1
nkrk|2
˘β4
kp/summationdisplay
k=1E|εk|2/parenrightigg1/2
≤C
n2p/parenleftiggp/summationdisplay
k=1E˘β−4
k/parenleftig
|r∗
kQ−1TℓD−1
nkrk|2/bardblT1/2
nD−1
nkrk/bardbl2
+E/bardblr∗
kQ−1TℓD−1
nkT1/2
n/bardbl2|r∗
kD−1
nkrk|2+E/bardblr∗
kQ−1Tℓ
nD−1
nkT1/2
n/bardbl2/bardblr∗
kD−1
nkT1/2
n/bardbl2
+E|r∗
kQ−1Tℓ
nD−1
nkTnD−1
nkrk|2/parenrightig/parenrightig1/2
where we have used the fact that
sup
x∈[a,b]p/summationdisplay
k=1E|εk|2=O(1).
By Lemma 2.10, we have
p/summationdisplay
k=1E˘β−4
k|r∗
kQ−1TℓD−1
nkrk|2/bardblT1/2
nD−1
nkrk/bardbl2≤Cnp/summationdisplay
k=1E˘β−4
k(r∗
kD−1
nkD−1
nkrk)2
m=Cnp/summationdisplay
k=1E(1+yg0(z))−4(r∗
kD−1
nD−1
nrk)2≤Cn2p/summationdisplay
k=1Er∗
kD−2
nD−2
nrk
=Cn2trRR∗D−1
nD−1
n=O(n4),
where the ﬁrst inequality follows by Cauchy-Schwarz with /bardblr∗
kQ−1Tℓ
n/bardbl2=O(n)andQ−1,
Tnare bounded in spectral norm; the second inequality employs the Cauchy-Schwarz again
and/bardblrk/bardbl2=O(n); and the last estimation follows by assumption F([a,b])=o(v4
n).21
To estimate the second term, let vk=Tℓ
nQ−1rk. We have
r∗
kD−1
nD−1
nvk
=r∗
kD−1
nkD−1
nkvk−r∗
kD−1
nkαkα∗
kD−1
nkD−1
nkvk
βk−r∗
kD−1
nkD−1
nkαkα∗
kD−1
nkvk
βk
+r∗
kD−1
nkαkα∗
kD−1
nkD−1
nkαkα∗
kD−1
nkvk
|βk|2
m=r∗
kD−1
nkD−1
nkvk−r∗
kD−1
nk(rkr∗
k+Tn)D−1
nkD−1
nkvk
n˘βk−r∗
kD−1
nkD−1
nk(rkr∗
k+Tn)D−1
nkvk
n˘βk
+r∗
kD−1
nk(rkr∗
k+Tn)D−1
nk(rkr∗
k+Tn)D−1
nkD−1
nkvk
n2|˘βk|2
m=r∗
kD−1
nkD−1
nkvk−r∗
kD−1
nkrkr∗
kD−1
nkD−1
nkvk
n˘βk−r∗
kD−1
nkD−1
nkrkr∗
kD−1
nkvk
n˘βk
+r∗
kD−1
nkrkr∗
kD−1
nkD−1
nkrkr∗
kD−1
nkvk
n2|˘βk|2+O(v−4
n)
m=/parenleftigg
1+yg0(z)
˘βkr∗
kD−1
nkD−1
nkvk−r∗
kD−1
nD−1
nrkr∗
kD−1
nvk|˘βk|2
n|1+yg0(z)|2(1+yg0(z))
+r∗
kD−1
nrkr∗
kD−1
nD−1
nrkr∗
kD−1
nvk|˘βk|2
n2|1+yg0(z)|4+O(v−4
n)/parenrightigg
Smilarly, we have
v∗
kD−1
nD−1
nvkm=v∗
kD−1
nkD−1
nkvk−v∗
kD−1
nrkr∗
kD−1
nkD−1
nkvk
n(1+yg0(z))
−v∗
kD−1
nkD−1
nkrkr∗
kD−1
nvk
n(1+yg0(z))+v∗
kD−1
nrkr∗
kD−1
nD−1
nrkr∗
kD−1
nvk|˘βk|2
n2|1+yg0(z)|4.
Therefore,
v∗
kD−1
nkD−1
nkvk(4.46)
=v∗
kD−1
nD−1
nvk+2ℜ/parenleftigg
v∗
kD−1
nrkr∗
kD−1
nD−1
nkvk˘βk
n(1+yg0(z))2+r∗
kD−1
nD−1
nrk|r∗
kD−1
nvk|2|˘βk|2˘βk
n|1+yg0(z)|4
+r∗
kD−1
nrkr∗
kD−1
nD−1
nrkr∗
kD−1
nvk|˘βk|2˘βk
n2|1+yg0(z)|4(1+yg0(z))/parenrightigg
−|v∗
kD−1
nrk|2r∗
kD−1
nD−1
nrk|˘βk|2
n2|1+yg0(z)|4
Therefore, the second term in e21is dominated by
1
n2p/parenleftiggp/summationdisplay
k=1E|˘βk|−4v∗
kD−1
nkD−1
nkvk|r∗
kD−1
nkrk|2/parenrightigg1/2
=O(n−1)22
which can be derived by substituting ( 4.46) and applying Lemma 2.10.
|e22|=1
np/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglep/summationdisplay
k=1Er∗
kQ−1TℓD−1
nkTD−1
nkrk
n˘βk/parenleftbigg1
βk−1
˘βk/parenrightbigg/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
≤C
npv2np/summationdisplay
k=1E|εk|=O(n−3/2v−4
n)=O(n−1).
|e23|=1
np/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglep/summationdisplay
k=1Er∗
kQ−1TℓD−1
nkrkr∗
kD−1
nkrk
n˘βk/parenleftbigg1
βk−1
˘βk/parenrightbigg/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
=1
n2p/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglep/summationdisplay
k=1Er∗
kQ−1TℓD−1
nkrkr∗
kD−1
nkrk
˘βk/parenleftigg
ε2
k
˘β3
k−ε3
k
˘β3
kβk/parenrightigg/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
≤1
n2pp/summationdisplay
k=1r∗
kQ−1TℓD−1
nkrkr∗
kD−1
nkrk
|˘βk|4E|εk|3+O(n−3/2)v−5
n
≤C
n4pp/summationdisplay
k=1Er∗
kQ−1TℓD−1
nrkr∗
kD−1
nrk
|˘βk|2|1+ygn(z)|2/parenleftig
r∗
kD−1
nk˘β−1
nkrk+trT2
n/parenrightig
+O(n−1)
=O(n−1).
The estimation of e3ande4are as follows,
|e3|≤1
n2p/parenleftiggp/summationdisplay
k=1Ev∗
kD−1
nkD−1
nkvk
|˘βk|2p/summationdisplay
k=1r∗
kD−1
nkD−1
nkrk
|˘βk|2/parenrightigg1/2
=O(n−1).
and
|e4|=1
np/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglep/summationdisplay
k=1Er∗
kQ−1TℓD−1
nrk−Er∗
kQ−1TℓD−1
nrk
1+ynEgnyn(Egn−gn)
1+yngn/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
≤C
np/parenleftig
E|trRnR∗
nQ−1TℓD−1
n−EtrRnR∗
nQ−1TℓD−1
n|2E(gn(z)−Egn(z))2/parenrightig1/2
=O(n−1).
In the proof for the last step, we have used conclusions E|gn−Egn|2=O(n−1)which is
(3.20)(b)withℓ=1and
E|1
ptr(RnR∗
n)/nQ−1TℓD−1
n−Etr(RnR∗
n)/nQ−1TℓD−1
n|2=O(n−1)
which is the same as ( 3.20)(b)when the matrix Tnintr(TnD−1
n)is replaced by
(RnR∗
n)/nQ−1Tℓ.
The errore5can be estimated as
|e5|=1
np/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglep/summationdisplay
k=1Etr[TnQ−1Tℓ
n{D−1
nkαkα∗
kD−1
nk}]
˘βkβk/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
m=1
n2p/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglep/summationdisplay
k=1Etr[TnQ−1Tℓ
n{D−1
nk(rkr∗
k+Tn)D−1
nk}]
˘β2
k/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle23
≤1
n2pp/summationdisplay
k=1/vextendsingle/vextendsingle/vextendsingle(r∗
kD−1
nkD−1
nkrk+tr(D−1
nkD−1
nk))/vextendsingle/vextendsingle/vextendsingle=O(n−1).
As for the last error e6, we have
|e6|=1
np/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglep/summationdisplay
k=1Etr[TnQ−1Tℓ
nD−1
n]/parenleftigg
εk
˘β2
k−ε2
k
˘β2
kβk/parenrightigg/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
≤C
npp/summationdisplay
k=1/bracketleftigg/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleEtr[TnQ−1Tℓ
n(D−1
n−ED−1
n)]εk
˘β2
k/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle+E|tr[TnQ−1Tℓ
nD−1
n]||εk|2
|˘βk|2/bracketrightigg
≤O(n−1),
where the ﬁrst term was estimated in e4and the second term can be estimated rountinely.
Now, lets0
nandg0
nbe the solutions to the system of equations
s0
n=/integraldisplaydHn(u,t)
u
1+yng0n−(1+tyns0n)z+t(1−yn),
g0
n=/integraldisplaytdHn(u,t)
u
1+yng0n−(1+tyns0n)z+t(1−yn).
From these and ( 4.32), we have
|Esn−s0
n|=/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/integraldisplaydHn(u,t)
u
1+ynEgn−(1+tynEsn)z+t(1−yn)
−/integraldisplaydHn(u,t)
u
1+yng0n−(1+tyns0n)z+t(1−yn)+O(n−1)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
≤yn/tildewideA1|Egn−g0
n|+yn/tildewideB1|Esn−s0
n|+O(n−1),
|Egn−g0
n|=/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/integraldisplaytdHn(u,t)
u
1+ynEgn−(1+tynEsn)z+t(1−yn)
−/integraldisplaytdHn(u,t)
u
1+yng0n−(1+tyns0n)z+t(1−yn)+O(n−1)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
≤yn/tildewideA2|Egn−g0
n|+yn/tildewideB2|Esn−s0
n|+O(n−1),
where
/tildewideAj=/integraldisplay utj−1
|1+ynEgn||1+yng0
n|dHn(u,t)
/vextendsingle/vextendsingle/vextendsingle/vextendsingleu
1+ynEgn−(1+ynEsn)z+t(1−yn)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleu
1+yng0n−(1+yns0n)z+t(1−yn)/vextendsingle/vextendsingle/vextendsingle/vextendsingle24
→/tildewideAj0=/integraldisplay utj−1
|1+yng0|2dHn(u,t)
/vextendsingle/vextendsingle/vextendsingle/vextendsingleu
1+yg0−(1+ys0)z+t(1−y)/vextendsingle/vextendsingle/vextendsingle/vextendsingle2,j=1,2,
/tildewideBj=/integraldisplaytjdHn(u,t)/vextendsingle/vextendsingle/vextendsingle/vextendsingleu
1+ynEgn−(1+ynEsn)z+t(1−yn)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleu
1+yng0n−(1+yns0n)z+t(1−yn)/vextendsingle/vextendsingle/vextendsingle/vextendsingle
→/tildewideBj0=/integraldisplaytjdHn(u,t)/vextendsingle/vextendsingle/vextendsingle/vextendsingleu
1+yg0−(1+ys0)z+t(1−y)/vextendsingle/vextendsingle/vextendsingle/vextendsingle2,j=1,2.
From these, one can easily derive that
|Esn−s0
n|≤(1−yn/tildewideB1−y2
n/tildewideA1/tildewideB2(1−yn/tildewideA2)−1)−1O(n−1)=O(n−1).
In the above, the convergence of /tildewideAj(/tildewideBj)to/tildewideAj0(/tildewideBj0)follows by DCT and (1−yn/tildewideB1−
y2
n/tildewideA1/tildewideB2(1−yn/tildewideA2)−1)−1has an upper bound follows from the convergence and y/tildewideB10−
y2/tildewideA10/tildewideB20(1−y/tildewideA20)−1<1which can be showing by comparing the imaginary part of ( 1.1).
Therefore, we can get for all nsufﬁciently large,
sup
x∈[a,b]|Esn(x+ivn)−s0
n(x+ivn)|=O(n−1).
which is ( 4.31).
5. Completing the proof. From the last two sections, combining ( 3.19) (b) and ( 4.31),
for anyδ∈(0,1/64),vn=n−δandx∈[a,b],we get
sup
x∈[a,b](nvn)|sn(x+ivn)−s0
n(x+ivn)|=o(1) a.s.. (5.47)
It is clear that ( 5.47) is true when the imaginary part of zis replaced by a constant multiple
ofvn. So we have
sup
x∈[a,b]|sn(x+i√
kvn)−s0
n(x+i√
kvn)|=o(1/(nvn)) a.s..
Taking the imaginary part and taking differences, we get
sup
x∈[a,b]/vextendsingle/vextendsingle/vextendsingle/vextendsingle/integraldisplayd(FBn(λ)−Fyn,Hn(λ))
((x−λ)2+v2n)((x−λ)2+2v2n)···((x−λ)2+pv2n)/vextendsingle/vextendsingle/vextendsingle/vextendsingle=o(1),a.s.
We split up the integral and get
sup
x∈[a,b]/vextendsingle/vextendsingle/vextendsingle/vextendsingle/integraldisplayI([a′,b′]c)d(FBn(λ)−Fyn,Hn(λ))
((x−λ)2+v2n)((x−λ)2+2v2n)···((x−λ)2+pv2n)(5.48)
+/summationdisplay
λj∈[a′,b′]v2p
n
((x−λ)2+v2n)((x−λ)2+2v2n)···((x−λ)2+pv2n)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle=o(1),a.s.
Now if for each term in a subsequence satisfying ( 5.48), there is at least one eigenvalue
contained in [a,b], then the sum in ( 5.48) will be uniformly bounded away from 0. Thus, the
integral in ( 5.48) must also stay uniformly bounded away from 0. But the integral converges
to 0 a.s. since the integrand is bounded and, with probabilit y one, both FBnandFyn,Hn
converge weakly to the same limit having no mass on [a′,b′]. Thus, with probability one, no
eigenvalues of Bnwill appear in [a,b]for allnsufﬁciently large. This completes the proof
of Theorem 1.1.25
6. Mathematical tools.
LEMMA 6.1. (Theorem B.14 of [ 2]) LetFbe a distribution function and let Gbe a func-
tion of bounded variation satisfying/integraltext
|F(x)−G(x)|dx<∞. Denote their Stieltjes trans-
forms byf(z)andg(z), respectively. Then, we have
/bardblF−G/bardbl≤1
π(1−κ)(2γ−1)/bracketleftigg/integraldisplayA
−A|f(z)−g(z)|du+2πv−1/integraldisplay
|x|>B|F(x)−G(x)|dx(6.49)
+v−1sup
x/integraldisplay
|y|≤2va|G(x+y)−G(x)|dy/bracketrightigg
,
whereAandBare positive constants such that A>B and
κ=4B
π(A−B)(2γ−1)<1. (6.50)
LEMMA 6.2. ( Lemma 3.3 of [ 6]) Letz∈C+withv=ℑz,AandBn×nwithB
Hermitian, and r∈Cn. Then
|tr((B−zI)−1−(B+rr∗−zI)−1)A|=/vextendsingle/vextendsingle/vextendsingle/vextendsingler∗(B−zI)−1A(B−zI)−1r
1+r∗(B−zI)−1r/vextendsingle/vextendsingle/vextendsingle/vextendsingle≤/bardblA/bardbl
v.
LEMMA 6.3. (Lemma 2.12 of [ 2]) Let{Xk}be a complex martingale difference se-
quence with respect to the increasing σ−fieldFk. Then, forp>1,
E|Xk|p≤KpE/parenleftig/summationdisplay
|Xk|2/parenrightigp/2
.
LEMMA 6.4. (Lemma 2.13 of [ 2]) Let{Xk}be a complex martingale difference se-
quence with respect to the increasing σ−fieldFk, and letEkdenote conditional expecta-
tionw.r.t.Fk.Then, forp≥2,
E|Xk|p≤Kp/parenleftbigg
E/parenleftig/summationdisplay
Ek−1|Xk|2/parenrightigp/2
+E/summationdisplay
|Xk|p/parenrightbigg
LEMMA 6.5. (Lemma B.26 of [ 2]) LetA=(aij)be ann×nnonrandom matrix and
X=(x1,...,xn)′be a random vector of independent entries. Assume that Exi=0,E|xi|2=
1,andE|xj|ℓ≤νℓ. Then, for any p≥1,
E|X∗AX−trA|p≤Cp/parenleftig
(ν4tr(AA∗))p/2+ν2ptr(AA∗)p/2/parenrightig
,
whereCpis a constant depending on ponly.
LEMMA 6.6. (Interlacing theorem) If Cis an(n−1)×(n−1)major sub-matrix of
then×nHermitian matrix A, thenλ1(A)≥λ1(C)≥λ2(A)≥···≥λn−1(C)≥λn(A),
whereλi(A)denotes thei-th largest eigenvalues of the Hermitian matrix A.
LEMMA 6.7. (Corollary 7.3.8 of [ 7]) Forn×pmatrices AandBwith respec-
tive singular values s1(A)≥s2(A)≥ ··· ≥sq(A),s1(B)≥s2(B)≥ ··· ≥sq(B), where
q=min(n,p), for allk=1,2,···,q, we have
|sk(A)−sk(B)|≤/bardblA−B/bardbl.26
Acknowledgments. Z. D. Bai was partially supported by NSFC Grant 12171198 and
Team Project of Jilin Provincial Department of Science and T echnology (No.20210101147JC).
J. Hu was supported by NSFC (Nos. 12171078, 11971097).
REFERENCES
[1] B AI, Z. D. and S ILVERSTEIN , J. W. (1998). No eigenvalues outside the support of the limi ting spectral
distribution of large-dimensional sample covariance matr ices. The Annals of Probability 26316–345.
[2] B AI, Z. and S ILVERSTEIN , J. W. (2010). Spectral analysis of large dimensional random matrices 20.
Springer.
[3] B AI, Z. D. and S ILVERSTEIN , J. W. (2012). No eigenvalues outside the support of the limi ting spectral distri-
bution of information-plus-noise type matrices. Random Matrices: Theory and Applications 11150004.
[4] C APITAINE , M. (2014). Exact separation phenomenon for the eigenvalue s of large information-plus-noise
type matrices, and an application to spiked models. Indiana University Mathematics Journal 1875–
1910.
[5] C OUILLET , R., D EBBAH , M. and S ILVERSTEIN , J. W. (2011). A deterministic equivalent for the analysis o f
correlated MIMO multiple access channels. IEEE Transactions on Information Theory 573493–3514.
[6] D OZIER , R. B. and S ILVERSTEIN , J. W. (2007). On the empirical distribution of eigenvalues of large di-
mensional information-plus-noise-type matrices. Journal of Multivariate Analysis 98678–694.
[7] H OM, R. A. and J OHNSON , C. R. (1985). Matrix analysis. Cambridge University Express 455.
[8] Z HOU , H., B AI, Z. and H U, J. (2022). The Limiting Spectral Distribution of Large-Di mensional General
Information-Plus-Noise-Type Matrices. Journal of Theoretical Probability . forthcoming.
[9] Z HOU , H., H U, J., B AI, Z. and S ILVERSTEIN , J. W. (2023). Analysis of the limiting spectral distributi on of
large dimensional General information-plus-noise type ma trices. arXiv preprint arXiv:2302.01711 .