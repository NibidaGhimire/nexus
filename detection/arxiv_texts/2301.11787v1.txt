Workshop on Multi-scale, Multi-physic and Coupled Problems on Highly Parallel Systems
HPC Asia 2023, 27 February - 2 March 2023, Singapore
Accelerating Domain-aware Deep Learning Models with
Distributed Training
Aishwarya Sarkar, Chaoqun Lu and Ali Jannesari
Iowa State University, USA
fasarkar1, clu, jannesar g@iastate.edu
Keywords :domain-knowledge, model parallelism, distributed training, knowledge-guided
neural network
1 Abstract and Motivation
Recent advances in data-generating techniques led to an explosive growth of geo-
spatiotemporal data. In domains such as hydrology, ecology, and transportation, in-
terpreting the complex underlying patterns of spatiotemporal interactions with the help
of deep learning techniques hence becomes the need of the hour. However, applying deep
learning techniques without domain-specic knowledge tends to provide sub-optimal pre-
diction performance. Secondly, training such models on large-scale data requires extensive
computational resources. To eliminate these challenges, we present a novel distributed
domain-aware spatiotemporal network that utilizes domain-specic knowledge with im-
proved model performance. Our network consists of a pixel-contribution block, a dis-
tributed multiheaded multichannel convolutional (CNN) spatial block, and a recurrent
temporal block. We choose ood prediction in hydrology as a use case to test our pro-
posed method. From our analysis, the network eectively predicts high peaks in discharge
measurements at watershed outlets with up to 4.1x speedup and increased prediction per-
formance of up to 93%. Our approach achieved a 12.6x overall speedup and increased the
mean prediction performance by 16%. We perform extensive experiments on a dataset of
23 watersheds in a northern state of the U.S. and present our ndings.
Domain-aware deep learning (DL) models do not solely rely on data in hand. Having
some insight about the targetted domain is what makes them stand out. Without explicit
constraints, DL models are prone to make erroneous predictions. Research shows that
these models outperform their data-driven counterparts in various applications such as
human pose estimation [1], studying animal models [2], breast cancer diagnosis [3], and
seismic inversion [4] among others. To make a DL model domain-aware, researchers have
tried to closely integrate them with their domain-specic counterparts [5]. Despite these
advances, the bottleneck of eciently training, testing, and deploying these models still
remains a challenge. The recent breakthrough in high-performance computing systems
shows immense potential to make domain-aware DL models overcome bottlenecks by
making them scalable, and cost-eective [6, 7].
Global oods and extreme rainfall events have surged by more than 50% this decade and
are now occurring at a rate four times higher than in 1980. Increasing evidence shows
the huge potential of predicting and mitigating ood occurrences in reducing yield loss,arXiv:2301.11787v1  [cs.LG]  25 Jan 20232
Figure 1: The overall workow of the proposed distributed spatiotemporal network Dom-
ST with (a) pixel-contribution (Pix-Con) block, (b) spatial block with parallel convolution
heads, and a recurrent (c) temporal block. The blue boxes represent data, and the
orange boxes represent various modules of Dom-ST. The arrows show the data ow during
inference.
improving disaster risk management, and beneting the environment [8, 9, 10]. This work
tackles the challenges in DL-based pixellated spatiotemporal ood prediction models by
introducing a novel approach to somewhat eliminate its black box-like nature. It exploits
domain knowledge that comes from pixelated inputs by learning their pixel-specic spa-
tiotemporal contributions. We further propose a novel distributed training approach to
accelerate and optimize the training time of a pixellated domain-aware spatiotemporal
network. In summary, our contributions are:
1. A domain-aware distributed spatiotemporal network (Dom-ST) with a novel pixel-
contribution block (Pix-Con) to compute pixel-specic weights that transforms spa-
tiotemporal inputs based on their local contribution to the water discharge (Figure
1).
2. A partitioning module in the Pix-Con block that partitions spatiotemporal pixels
dynamically and distributes them to multiple devices (Figure 1).
3. A novel domain-guided distributed training approach to accelerate training (Figure
2).
4. An approach to utilize domain-signicant temporal input measurements (the target
day) to increase domain awareness in Dom-ST.
5. Competitive results in improving ood prediction by upto 93% and an overall
speedup of 12.6x with domain-guided distributed training,
2 Distribution Strategy
Since the climate and other environmental factors of a region, such as soil, land cover,
temperature, and human impact, vary from one location to another, one global hydro-
logical model, if trained, will either give suboptimal results or will be computationally
extensive. Model performance can be improved further from the knowledge gained by
modeling targetted regions. Besides, data scarcity in remote areas is a challenge of its
own which can be tackled to some extent by transfer learning approaches [11]. Due to the
huge amount of complex multi-dimensional spatiotemporal data, training a hydrological
model based on deep learning approaches on a single device requires more resources in3
Figure 2: (a) The input pipeline distributes chunks of data (watersheds) and creates
Dom-ST replicas on multiple nodes (Left). (b) Each node runs distributed Dom-ST using
the host (CPU) and multiple devices (GPU) (Right).
terms of time and memory. Our distributed training approach tackles this challenge (Fig-
ure 2). Firstly, the training data of the targetted site is split into 23 regions or watersheds
in the input pipeline (I.P.), which then distributes the set of watersheds to multiple nodes
(Figure 2.a.), where each node is responsible for a single watershed. The I.P. also creates
model replicas and distributes them for each watershed to corresponding nodes. Secondly,
in each watershed node, we partition the model and ooad it to multiple GPUs by ex-
ploiting the parallel architecture of our spatial block (Figure 2.b.). Each head of the CNN
is separated and trained on a single separate GPU making the heads train parallelly, thus
optimizing the training time. Once the forward passes of the spatial blocks are completed,
the outputs are transferred to the next GPU, which has the temporal block containing
the stacked LSTM layers and the following nal layers of the model. The temporal GPU
also receives the second input of the model directly.
We use pixellated daily precipitation from the Climate Research Unit and distances of
each pixel from the nearest water source as inputs and U.S. Geological Survey's daily
discharge measurements [12] as labels. We selected Nash-Sutclie eciency (NSE) as our
model evaluation metric [13]. Our baseline model consists of only the spatial and temporal
blocks. The spatial block consists of singlehead one-dimensional multichannel 1D-CNN
without any Pix-Con block, which implies that the baseline is purely data-driven with no
domain knowledge. We refer to this as Singlehead . The baseline runs on a single GPU. We
explore how having an additional input of the target day's precipitation outperforms the
baseline's performance. Figure 3 shows that in almost all the watersheds (91%), feeding
the target day's precipitation in the nal layers of the model ( Singlehead (+P)) improves
the performance. The target day's precipitation, the primary contributing factor of ash
oods, provides temporally ne-grained data to Dom-ST as a domain-specic cue to im-
prove the prediction. Next, we evaluate our proposed Dom-ST, which has a Pix-Con block,
a distributed multihead spatial block, and a temporal block that receives the target day's
inputs. For comparison, we refer to it as Distributed-Multihead(+P) in Figure 3. From
our results, Distributed-Multihead(+P) outperforms both Singlehead andSinglehead (+P)
in almost all the watersheds. This supports that Dom-ST is more domain-aware than its
counterparts. To evaluate the input pipeline strategy, we compare the computation time
ofSinglehead+ PandDistributed-Multihead(+P) , each running sequentially (S) and then
parallelly (IP-D). Table 1 shows the total training time of 23 watersheds in each case.4
123456789101112131415161718192021222300.10.20.30.40.50.60.70.80.911.1
0.57
0.52
0.35
0.71
0.27
0.88
0.87
0.84
0.81
0.89
0.74
0.92
0.59
0.4
0.59
0.67
0.61
0.52
0.69
0.87
0.66
0.68
0.73
Watershed no.NSESinglehead Singlehead(+ P) Distributed-Multihead(+ P)
Figure 3: Comparison of prediction performance in terms of NSE [14] between 3 ap-
proaches - singlehead, singlehead with extra precipitation inputs (Singlehead(+ P)), and
distributed-multihead with extra precipitation inputs (Distributed-Multihead(+ P)).
Table 1: Evaluation of the input pipeline strategy (IP-D).
Approach Time (S) Time (IP-D) Speedup
Singlehead(+ P) 9.96 hours 1.18 hours 8.5x
Distributed-Multihead(+ P)5.49 hours 0.44 hours 12.6x
3 Conclusion
We propose a novel distributed training approach to accelerate a domain-aware spatiotem-
poral network. Through rigorous experiments and ablation studies, we further explore
how domain knowledge drives a model's prediction and can also be utilized in nding an
approach for distributed training by exploiting pixellated spatiotemporal data to infuse
pixel-level contribution. Our ndings indicate that the use of Dom-ST leads to an av-
erage speedup of 2 :02x across all the analyzed watersheds. The pixel-contribution block
in Dom-ST utilizes domain-knowledge and improves the model's prediction performance.
Our experiments achieved the highest individual watershed speedup of up to 4 :11x and
an overall speedup of 12 :6x with the highest increase in individual NSE by 93%.
REFERENCES
[1] Guanghan Ning, Zhi Zhang, and Zhiquan He. Knowledge-guided deep fractal neural
networks for human pose estimation. IEEE Transactions on Multimedia , 20(5):1246{
1259, 2018.
[2] Tao Zhong, Fenqiang Zhao, Yuchen Pei, Zhenyuan Ning, Lufan Liao, Zhengwang Wu,
Yuyu Niu, Li Wang, Dinggang Shen, Yu Zhang, et al. Dika-nets: Domain-invariant5
knowledge-guided attention networks for brain skull stripping of early developing
macaques. NeuroImage , 227:117649, 2021.
[3] Chen Chen, Yong Wang, Jianwei Niu, Xuefeng Liu, Qingfeng Li, and Xuantong
Gong. Domain knowledge powered deep learning for breast cancer diagnosis based
on contrast-enhanced ultrasound videos. IEEE Transactions on Medical Imaging ,
40(9):2439{2451, 2021.
[4] Jian Sun, Kristopher A Innanen, and Chao Huang. Physics-guided deep learning
for seismic inversion with hybrid training and uncertainty analysis. Geophysics ,
86(3):R303{R317, 2021.
[5] Aishwarya Sarkar, Jien Zhang, Chaoqun Lu, and Ali Jannesari. Hydrodeep{a knowl-
edge guided deep neural network for geo-spatiotemporal data analysis. arXiv preprint
arXiv:2010.04328 , 2020.
[6] Sixing Yu, Murali Emani, Chunhua Liao, Pei-Hung Lin, Tristan Vanderbruggen,
Xipeng Shen, and Ali Jannesari. Towards seamless management of ai models in
high-performance computing. arXiv preprint arXiv:2212.06352 , 2022.
[7] Sixing Yu, Phuong Nguyen, Waqwoya Abebe, Wei Qian, Ali Anwar, and Ali Jan-
nesari. Spatl: salient parameter aggregation and transfer learning for heterogeneous
federated learning. In 2022 SC22: International Conference for High Performance
Computing, Networking, Storage and Analysis (SC) , pages 495{508. IEEE Computer
Society, 2022.
[8] P. E. O'Connell, J. Ewen, G. O'Donnell, and P. Quinn. Is there a link between agri-
cultural land-use management and ooding? Hydrology and Earth System Sciences ,
11(1):96{107, 2007.
[9] Roger Moussa, Marc Voltz, and Patrick Andrieux. Eects of the spatial organization
of agricultural management on the hydrological behaviour of a farmed catchment
during ood events. Hydrological Processes , 16(2):393{412, 2002.
[10] Howard Wheater and Edward Evans. Land use, water management and future ood
risk. Land Use Policy , 26:S251{S264, 2009. Land Use Futures.
[11] Aishwarya Sarkar, Jien Zhang, Chaoqun Lu, and Ali Jannesari. Transfer learning ap-
proaches for knowledge discovery in grid-based geo-spatiotemporal data. In NeurIPS
2021 AI for Science Workshop , 2021.
[12] Christopher S Jones, Jacob K Nielsen, Keith E Schilling, and Larry J Weber. Iowa
stream nitrate and the gulf of mexico. PloS one , 13(4):e0195930, 2018.
[13] Daniel N Moriasi, Jerey G Arnold, Michael W Van Liew, Ronald L Bingner, R Daren
Harmel, and Tamie L Veith. Model evaluation guidelines for systematic quantication
of accuracy in watershed simulations. Transactions of the ASABE , 50(3):885{900,
2007.
[14] J Eamonn Nash and Jonh V Sutclie. River ow forecasting through conceptual
models part i|a discussion of principles. Journal of hydrology , 10(3):282{290, 1970.