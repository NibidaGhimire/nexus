LAVA: Granular Neuron-Level Explainable AI for
Alzheimer‚Äôs Disease Assessment from Fundus Images
Nooshin Yousefzadeh1, Charlie Tran2, Adolfo Ramirez-Zamora3, Jinghua Chen4,
Ruogu Fang2,5,6,*and My T. Thai1,*
1Department of Computer & Information Science & Engineering, University of Florida, Gainesville, Florida, USA
2Department of Electrical and Computer Engineering, University of Florida, Gainesville, Florida, USA
3Department of Neurology, University of Florida, Gainesville, Florida, USA
4Department of Ophthalmology, University of Florida, Gainesville, Florida, USA
5J. Crayton Pruitt Family Department of Biomedical Engineering, University of Florida, Gainesville, Florida, USA
6Center for Cognitive Aging and Memory, University of Florida, Gainesville, Florida, USA
Abstract
Alzheimer‚Äôs Disease (AD) is a progressive neurodegenerative disease and the leading cause of dementia.
Early diagnosis is critical for patients to benefit from potential intervention and treatment. The retina
has been hypothesized as a diagnostic site for AD detection owing to its anatomical connection with the
brain. Developed AI models for this purpose have yet to provide a rational explanation about the decision
and neither to infer the stage of the disease‚Äôs progression. Along this direction, we propose a novel model-
agnostic explainable-AI framework, called Granu lar Neuron-le vel Expl ainer (LAVA), an interpretation
prototype that probes into intermediate layers of the Convolutional Neural Network (CNN) models to
assess the AD continuum directly from the retinal imaging without longitudinal or clinical evaluation.
This method is applied to validate the retinal vasculature as a biomarker and diagnostic modality for
Alzheimer‚Äôs Disease (AD) evaluation. UK Biobank cognitive tests and vascular morphological features
suggest LAVA shows strong promise and effectiveness in identifying AD stages across the progression
continuum.
Alzheimer‚Äôs disease is the leading cause of dementia. The number of people aged 65 and
older with AD in the United States is estimated to be around 6.5 million, which is expected
to grow to 13.8 million by 2050 [ 1]. AD is a progressive disease that can be broadly characterized
into preclinical, prodromal mild cognitive impairment (MCI due to AD), mild AD, moderate
AD, and severe AD based on the presence of clinical biomarkers and cognitive symptoms [ 2,3].
Early screening and diagnosis of AD are essential to alter the disease trajectory.
Pathological changes to the retina have been associated with early-stage neurodegenerative
diseases [ 4,5,6]. Retinal screening presents a non-invasive, feasible, and economical solution
to early AD diagnosis which has been hindered by the lack of consistent clinical symptoms
and the absence of clinically accessible neuroimaging and biological markers [ 7]. Among
the retinal features, weakening and alterations of the retinal vasculature as an AD biomarker
have recently emerged [ 8]. Clinical studies have focused on the time-consuming manual
segmentation of the vasculature, propagating subjective error into the quantitative analysis. To
counteract this problem, AI-based models have been introduced as more objective, repetitive,
*Corresponding author.
/envelope-opennooshinyousefzad@ufl.edu (N. Yousefzadeh); charlietran@ufl.edu (C. Tran); aramirezzamora@ufl.edu
(A. Ramirez-Zamora); jinghuachen@ufl.edu (J. Chen); ruogu.fang@bme.ufl.edu (R. Fang); mythai@cise.ufl.edu
(M. T. Thai)arXiv:2302.03008v2  [cs.LG]  16 Mar 2023precise, and automated systems to aid the vasculature segmentation and the decision-making
of ophthalmologists. Only few AI-based models have investigated AD through the retina
[9,10,11] and no work has yet studied the retinal biomarkers for AD across the disease
spectrum. Furthermore, these AI-based models have been used as black-box models without a
clear understanding of why the model made such predictions.
Recent advances in Explainable-AI (XAI) have shed interpretability into AI models. Notable
explainers are feature attributions (e.g., saliency maps [ 12], SHAP [ 13], LIME, [ 14], and integrated
gradients [ 15]). In particular, these explainers are effective at the macro-level (e.g., input-wise or
layer-wise) highlighting the features that are most effective in decision-making. However, these
explainers lack information attained at the micro-level of artificial neurons which influences
different mechanisms of decision-making. We look to invoke this ideology into the perspective
of AD, that is, a medical XAI framework to identify sub-types and progression stages of the
disease.
We propose our XAI framework called Granu lar Neuron-le vel Expl ainer (LAVA) for explain-
able diagnosis and assessment of the AD continuum. The intuition behind this approach is
that analyzing the behavior of neurons generates rich information reflecting not only the cor-
relation between biomarkers but also the interaction among biomarkers, thanks to inductive
learning of deep neural network architectures. We thereby introduce latent representations of
raw pixels reflected in the activation behavior of neurons as a resource to discover and reveal
hierarchical taxonomies of potential biomarkers. LAVA is a systematic approach that probes
into intermediate layers of the CNN model, inspects and leverages the activation patterns of
neurons as auxiliary information to improve model Explainability and Diagnostic power jointly.
Subsequently, we show how this new source of information during the learning process is used
to predict coarse-to-fine class in a downstream classification task where only coarse-level target
labels are available; such discovered knowledge can be linked to the domain of knowledge to
gain new insights from experts in the application domain.
There are two core modules so-called Neuron Probing andGranularity Explanation that
constitute the LAVA architecture, as shown in Fig. 1. The former identifies critical neurons
and inspects their activation patterns. The latter clusters input sample images into distinctive
groups emulated by activation of critical neurons as independent random variables. LAVA is
input size invariant, model-agnostic in the sense that it can adapt to a broad class of CNN
models1, and adjustable to the granularity level of data in the application domain.
In this article, we present the development of a novel XAI framework, Granular Neuron-
level Explainer (LAVA) to evaluate fundus images as a diagnostic modality of AD continuum
assessment. We verify the effectiveness of LAVA through consistency checks using clinical
measures of cognitive function and vascular integrity in the UK Biobank [ 16]. We employ
feature attribution and pixel reconstruction methods to highlight regions of interest in the
diagnosis of AD. The proposed framework supports the automation of an XAI diagnostic system
which may be used for clinical intervention and advance the field‚Äôs mechanistic understanding
of AD.
1The activation of neurons are extracted during the test phase, hence CNN models that do not contain any dropout
layers in their architectures are preferable in this framework in order to avoid randomized and non-reproducible
results.ClassificationQuality Selection
Preprocess Segmentation Vessel Map
Intermediate
Activation
MapsHierarcharial
ClusteringCritical Neuron
Identification
via SVRNeuron Probing
Healthy Granularity ExplanationAD/NC
AD Continuum AssessmentUKB
(Age)  
(Gender)AD NC
(Age)  
(Gender)
Biomarker Localization  
Ensemble Critical
Neurons from K-
Fold V alidation
ModelsDendrogram  
Granularity  
ConfigurationData Acquisition
 Neuron-Level-XAI 
... ... Mixed Mild AD  Moderate AD  Severe AD
Critical Neurons
Activation  
Values  SamplesAll Critical Neurons
All SamplesLayers
Figure 1.: Overall architecture of LAVA framework. End-to-end learning process in LAVA frame-
work is constituted by four main phases: (1) Data Acquisition where fundus images from the UK
Biobank are collected along with quality selection and AutoMorph preprocessing to obtain retinal
vasculature maps and morphological features, (2) Classification where a VGG-16 model is utilized
for binary classification between AD and NC images supplemented with a feature attribution map,
(3)Neuron-level XAI that consists of two modules of Neuron Probing to identify and extract critical
neurons across the VGG-16 network and Granularity Explanation to identify sub-classes of labels hidden
in data, and (4) AD Continuum Assessment where the diagnostic result of LAVA for an individual
subject is summarized.
Results
Study design and participants. LAVA is developed to assess AD classification and infer
the disease continuum utilizing fundus images acquired from the UK Biobank [ 16]. The UK
Biobank contains nearly 170,000 fundus images from over 500,000 participants. Quality control
is performed to exclude fundus images with artifacts and clarity issues using a pretrained CNN
module on the EyePacs-Q dataset. AD subjects with other additional sub-types of dementia (e.g.,frontotemporal dementia (FTD) are excluded. We identify a total of 100 images from 61 unique
AD subjects. To avoid potential confounding factors, we construct our binary-labeled dataset
by matching each AD image with 80 unique age and gender-matched normal controls (NC)
leading to a total number of 200 fundus images. The AutoMorph deep learning pipeline [ 17] is
used for preprocessing, vessel segmentation, and morphological vascular feature quantification.
Training and inference. A VGG-16 [ 18] binary classifier model is trained and evaluated under
five-fold stratified cross-validation setting on the segmented vessel maps. This procedure is
repeated with five repetitions with an optimal 5-fold accuracy of 75% and average accuracy of
71.4% (SD = 0.03). The best-performing cross-validation model is utilized for post-hoc analysis.
Neuron Probing. We probe into intermediate layers of the network at the neuron level to
assess the AD continuum (see Fig. 1). In our setting, we chose Max-Pooling layers and the first
two fully connected layers of the VGG-16 for critical neuron selection. Although our approach
supports critical neuron extraction from early layers, we find our LAVA framework works
effectively using a combination of Max-Pooling Layers. Owing to the Maximum Likelihood
Estimation (MLE) algorithm to approximate the joint Mutual Information (MI) objective in the
selection of critical neurons, the LAVA framework is reproducible, model agnostic, and input
size invariant. We use Epsilon-support vector regression ( ùúñ-SVR) [ 19] with a linear kernel as
a core algorithm to estimate the contribution coefficient of every single neuron at selected
layers and wrap the output by Recursive Feature Elimination (RFE) to collectively realize our
MLE-based critical feature selection objective.
We set two hyperparameters for the number of selected critical neurons at each layer to be 20
and the number of neurons pruned at each iteration to be 1000. This MLE-based feature selection
procedure repeats to ensemble five sets of selected neurons at each layer by each of five cross-
validation models into approximately 700 critical neurons, 100 from each layer, concatenated
(with repetition) across the network. Supplementary Fig. 7 shows the Jaccard similarity index
computed to compare overlapping between sets of neurons selected by five cross-validation
models. Higher similarities suggest similar activation behavior at the certain layers which can
be interpreted as similar Region Of Interest (ROIs) used for the feature extraction.
Granularity Explanation. Using the results obtained in neuron probing, we can distill the
activation values of critical neurons across the network over all input samples as a new dataset
that will be used for our knowledge discovery. Under a semi-supervised setting, LAVA employs
the Adjacency-constrained Hierarchical Agglomerative Clustering (HAC) algorithm [ 20] where
an early constructed ùëònearest-neighbor graph ( ùëò‚àíNNG) imposes connectivity constraints in
the form of a 97.5% ( ùëò= 5, ùëÅ= 200 ) sparse connectivity matrix of shape ùëÅ√óùëÅthat links
each input sample to its five nearest neighbors. This algorithm first creates a distance matrix
for sample instances using the Euclidean metric and then reduces a chunk of distances to the
ùëò-nearest neighbors for each sample where the array of distances for that sample is partitioned
by the element index ùëò‚àí1in the stable sorted order. ùëòis a hyperparameter chosen based on
experience and the number of target labels; ùëò= 3andùëò= 5are common choices in the LAVA
framework. The results show this approach is highly effective in using fundus biomarkers to
identify latent sub-classes of predicted label interpreted as AD continuum.
Fig. 2 (a)(Supplementary Fig. 8) visualizes UMAP (Uniform Manifold Approximation and
Projection for Dimensionality Reduction) [ 21] embedding of input fundus images in terms of
their activation of critical neurons projected in three dimensions. Unlike t-SNE, UMAP doesnot completely preserve density of data and thus provides a more effective preprocessing tool
for our clustering. In this study, we make use of UMAP visualization and the dendrogram
diagram (Fig. 2 (b)and Supplementary Fig. 9) for two purposes: (1) Initial evaluation of the
hardness of the clustering task, and (2) Decision on the appropriate number of clusters. The
number of clusters is a hyperparameter in LAVA framework normally chosen based on the
granularity level of the data and the nature of the problem under study, which is set to 7 in
this experiment. We used intrinsic metrics e.g., Calinski-Harabasz (CH) index (also known as
the Variance Ratio Criterion) [ 22] and Adjusted Mutual Information (AMI) [ 23] to choose the
appropriate clustering method by comparing their performances. The result of this clustering is
summarized in Supplementary Table 1 including 3 purely AD groups, 3 purely NC groups and 1
Mixed group of coarsely AD or NC labeled subjects.
We further analyzed the behavior of critical neurons of the trained network independent
from the input data. First, we use t-SNE [ 24] to project high-dimensional space of critical
neurons‚Äô activation values at a certain layer down to two dimensions. Second, we apply Kernel
Density Estimation (KDE) [ 25] method on top of t-SNE to estimate the probability density curve
associated with each dimension of t-SNE embedding as shown in Fig. 3 and Supplementary Fig.
10. Blue and orange curves at each layer can be interpreted as the distinctive behavior of the
model in the prediction of coarse class labels (AD/NC), while the presence of multiple peaks at
each curve reveals a mixture of multiple probability distributions corresponding to the different
mechanisms of prediction or different activation patterns used in the prediction of each class of
label. Our intuition is that each peak can potentially correspond to one distinctive sub-cluster
of examined samples. This observation is an analogy to previous UMAP and dendrogram
visualization of latent clustering structure within 200 input samples suggested by activation
values of critical neurons in the network.
The choice of hierarchical clustering over other semi-supervised clustering methods e.g.,
KMeans [ 26], Mean Shift Clustering [ 27], Affinity Propagation [ 19], etc. is made based on the
behavior of critical neurons and how well each clustering algorithm can scale on our dataset.
We use various statistical methods e.g., Variance Ratio Criterion, Adjusted Mutual Information,
Rand index, V-measure, homogeneity score, and completeness score to evaluate and compare
the performance of different clustering algorithms. We observe medical assessments reported
on UK Biobank cognitive tests [ 28] efficiently scale over a hierarchy and not a flat set of clusters.
The primary results encourage our further investigation into finding appropriate clustering
algorithm in order to gain more insights on learning the connection between AD-related
biomarkers in eye fundus images and activation pattern of critical neurons in the network.
Continuum assessment. Next, we showcase our LAVA-based hierarchical clustering is re-
flective of the AD continuum. Seeing that the UKB lacks detailed assessment of activities of
daily living, cognitive profile or functional scores (e.g., the clinical dementia rating and the
mini-mental state examination) and neither brain imaging data in our cohort, we use cognitive
test measures from the UKB as proxy measures of cognitive ability [ 29]. These tests include
two-levels of memory from the UKB, the pairs matching and prospective memory, and an intel-
lectual problem-solving measure, the fluid intelligence. We note that the clusters are extracted
from retinal vasculature images, and thus, we hypothesize that image-level features should
coincide with our continuum. Naturally, such image-level features live in an abstract space.
To resolve this issue, we evaluate quantifiable morphological features, specifically, the fractalSub-cluster
AD-3
AD-2
AD-1
Mixed
CN-3
CN-2
CN-1
a
b
Indices of 200 I nput Sample I magesEuclidean D istanceFigure 2.: Neuron-level probing results. (a) 3D visualization of UMAP embedding for high-
dimensional data sample points. Samples with similar embeddings (close to each other or similar
in the behaviour of critical neurons) have similar sub-cluster label predicted by HAC algorithm that
effectively reveals the clustering structure within data. (b)Dendrogram of agglomerative connectivity
constraint clustering with Ward‚Äôs Linkage represents the similarity relationship among sub-clusters
of AD subjects in terms of the behaviour of critical neurons. Imaginary horizontal line traversing
dendrogram determines the correspondent detail level of latent sub-clusters that characterizes subjects
within the continuum of disease.
dimension and vessel density, that are representative of the image-level features and relate
these to the cognitive ability of a subject.
We employ our analysis at the group-level (AD/NC) and the sub-group level. First, we verify
that the cognitive measures are significantly different across groups, as shown in Supplementary
Fig. 11. Next, as each metric is on a different scale, all of the scores are normalized on [0,1] for
comparison. A normalized comparison across groups is illustrated in Fig. 4 (a)through a visual
radar plot. We demonstrate that such metrics form an increasing sequence of measures across
clusters, supporting the idea that such latent clusters are indicative of the AD continuum. From
this observation, we term our sub-groups in order ranging from the healthiest states of cognitive
normal (CN) to the severity of AD [CN-1, CN-2, CN-3, Mixed, AD-1, AD-2, AD-3]. Notably, the
Mixed Group contains a sub-cohort of AD and NC subjects suggesting similarities of AD subjects
and potentially at risk NC subjects. Furthermore, the reduction in morphological vascular
features coincides with decline in cognitive ability, thus supporting the retinal vasculature
as indicative of the AD continuum, as shown in Fig. 4 (b). Last, taking from the observation
the sequence of our clusters, we look to assign a simplistic AD score of the continuum as60
 40
 20
 020 40 60
Activation of Critical Neurons0.0000.0050.0100.0150.0200.025Probability DensityMaxPool_9
60
 40
 20
 020 40 60
Activation of Critical Neurons0.0000.0050.0100.0150.0200.025Probability DensityMaxPool_16
60
40
20
0204060
Activation of Critical Neurons0.0000.0050.0100.0150.020Probability DensityMaxPool_23
80
60
40
20
0204060
Activation of Critical Neurons0.0000.0030.0050.0070.0100.0130.0150.0180.020Probability DensityMaxPool_30
60
40
20
020406080
Activation of Critical Neurons0.0000.0050.0100.0150.0200.025Probability Densityfc_0
60
40
20
0204060
Activation of Critical Neurons0.0000.0050.0100.0150.0200.025Probability Densityfc_3Figure 3.: Exploring activation pattern of critical neurons. KDE applied on top of two-dimensional
t-SNE embedding of critical neurons‚Äô activation values unveils multiple activation patterns for the same
set of critical neurons at each layer. It suggests evaluated fundus images belong to different sub-cluster
of patients within AD continuum associated with AD or NC target class (blue and orange curves) of the
disease.
illustrated in the gauge plot, Fig. 4 (c). To accomplish this, we average together the normalized
cognitive metrics (pairs matching, prospective memory, and fluid intelligence). In this manner,
the healthiest subject has a score of 0 and a severe subject has an upper bound score of 1.
Therefore, for any new subject, we may apply our LAVA framework and assign a subject‚Äôs vessel
map a position in the AD continuum as a manner for assigning their risk and potential clinical
intervention.
Visual model interpretation for clinical evaluation. We investigate the learning process
by use of the guided backpropagation method, wherein we mask crucial input features and
examine how the essential ROIs effective in the discovery of the AD continuum develop. With
some modifications to the pruning objective, we use the method introduced in [ 30] to reconstruct
critical fragments effective in the prediction of each latent sub-class using a sparse pathways
limited to some percentile of critical neurons identified and scored in Neuron-level XAI phase.
In this technique, the Integrated Gradients method [ 15] is combined with Lucent objective [ 31],
and as shown in Fig. 5, biomarkers can be decoded at different levels of criticality to highlight
the most determinant regions in the AD continuum prediction prioritized from the most specific
to the most general.
Furthermore, we apply the prior technique in conjunction (and in comparison with) traditional
attribution maps achieved by guided backpropagation [ 32], to develop an effective method
for searching relevant biomarkers at different scales. The guided backpropagation is repeated
using the Noise Tunnel Algorithm [ 33] averaged 10 times for robustness of relevance. To
mimic a clinician‚Äôs diagnostic decision-making, we zoom into a 70√ó70crop of the image ofcb
 a
Figure 4.: LAVA evaluation with clinical measures. The cognitive and vascular features are normal-
ized onto [0,1] for scalable weighting. (a)The UK Biobank cognitive test measures and vascular features
between AD and NC groups. (b)The cognitive and vascular feature comparison in the continuum
identified by the LAVA framework. (c)The AD-score defined by averaging the normalized cognitive
features. Each sub-group block is not drawn to scale.
highest feature attribution (see Fig. 6). Nevertheless, while the GBP visualization reveals where
to place attention for clinical observers, a true understanding of visual biomarkers remains
unclear and requires future research collaborated with domain experts in neuro-ophthalmology.
For this reason, we hope that a combination of visual model interpretation and quantifiable
morphological features can be used together for informed judgement.
Sanity Check of the Explanation. We evaluate the faithfulness of the LAVA in providing
a true explanation of the model‚Äôs behaviors. We feed LAVA with a VGG-16 binary classifier
where the parameters are randomized and examine how much the set of critical neurons in this
model differs from that of original model. We observe a significant change in the set of critical
neurons identified by LAVA at each layer of the model after the weights of the network are
replaced by random weights (Jaccard similarity index computed as at fc-3 layer is 0.008 and
zero at every other layers). This suggests LAVA truly extracts neurons critical to the output of
the model i.e., extracted neurons are correctly explaining the behavior of the network.
Discussion
We develop Granular Neuron-Level Explainer (LAVA), a novel explainability framework for AD
classification from fundus imaging. Specifically, we equip a traditional VGG-16 CNN with a five-
fold cross validation binary classification accuracy of 75% with a neuron-level XAI framework
to support the retinal vasculature as an efficient AD screening modality. Our explanations are
generated through a two-phase-procedure: (1) neuron probing and (2) granularity explanation.
Notably, the utilization of a neuron-level-XAI model is valid, as the contribution of neurons is a
better representation of the human imperceptible input features than the contribution of the
raw input image pixels themselves [ 30]. The reason behind this argument is that the hidden
(latent) variables constructed during the learning process by convolutional deep neural networksOriginal Segmented70th
Percentile95th
Percentile97th
Percentile98th
Percentile
AD-3   
(AD:18, CN:0)
AD-2   
(AD:30, CN:0)
AD-1   
(AD:21, CN:0)
Mixed   
(AD:31, CN:31)
CN-3   
(AD:0, CN:15)
CN-2  
(AD:0, CN:39)
CN-1   
(AD:0, CN:15)Figure 5.: Gaining insights into determinative biomarkers. The original CNN network is masked
to include only a percentile of important neurons identified by LAVA, while Integrated Gradients com-
putes the gradient of the model‚Äôs prediction output with respect to its input features. The reconstructed
pixels reflects the layout of biomarkers highly associated with the prediction of AD continuum progres-
sion. As the subnetwork becomes sparser for the most critical neurons, the reconstructed pixels reveal
the most critical biomarkers effective in the diagnosis of each sub-cluster of the prediction.
play a significant but underrated role in characterizing and fully describing the undergoing
phenomenon in medical image processing.
Few prior studies using AI models have been approached using retinal fundus images [ 9,10,
11]. However, these models do not consider the different stages of AD progression and thus
do not offer a comprehensive evaluation of the risk severity. One of the primary contributions
of this work is the projected inference of binary class labels (AD/NC) into latent sub-classes,
which we claim to be indicative of the AD continuum. We support this argument through a
number of approaches through comparisons of cognitive tests, morphological vascular features,
and several visualizations modules. The value of our findings is applicable in many biomedicalFundus Attribution Patch Zoom
AD-3   
(AD=18, CN=0)
AD-2   
(AD=30, CN=0)
AD-1   
(AD=21, CN=0)
Mixed  
(AD=31, CN=31)
CN-3   
(AD=0, CN=15)
CN-2  
(AD=0, CN=39)
CN-1
(AD=0, CN=15)Figure 6.: Visualization of input features identified relevant to the prediction . The guided back-
propagation method is employed to identify the region of interest. A sliding window is used to identify
a crop of the image with the highest feature attribution. The reference fundus image (column 1) and the
zoomed-crop (column 4) are shown for diagnostic visualiation that may help to explain the vascular
biomarkers across the predicted continuum of AD progression.
applications to enhance the interpretation of classifier models, allowing enhanced diagnostic
judgement and understanding of the underlying biological phenomena.
To demonstrate our claim of continuum assessment and allow various levels of enhanced
interpretability, we compare the differences across cognitive level features (e.g., the pairs
matching test, prospective memory, and fluid intelligence), morphological feature (fractal
dimension and vessel density), and visualization models. All designated cognitive and vascular
measures are demonstrated to be reduced in the AD group compared to the normal controlsat statistical significance ( ùëù < 0.01). We extend these differences from a group-level to a
latent-sub-group level via visual gauge and radar plots to demonstrate a sequence of clusters,
ranging from healthiest to strongest severity of AD. In particular, we are capable of arranging
the latent-sub-groups identified by our LAVA framework into a seven-level continuum, and
design a simplistic manner for assigning an AD-score to a subject. Guided backpropagation maps
and critical neuron reconstruction techniques are used to determine diagnostic biomarkers,
regions of interest, and differences amongst subgroups as deemed important by the model.
Although our study presents the ability to assess the AD continuum, the framework carries
limitations. First, the amount of data is lacking, with only 100 images from 61 AD participants
total, which hinders our model training and generalization to the real-world setting. Further-
more, we do not consider the effects of other confounding factors (demographics, genetics,
etc.) or similarities in retinal biomarkers amongst other neurodegenerative diseases. While
our work supports the reduction in cognitive performance and vessel structures [ 6,34] in the
retina, large individual variations between subjects could hinder the retina as a diagnostic site
and need further validation. We also acknowledge the limitations of current cognitive variables
and limited data assessing cognitive domains affected early and late in the disease like episodic
memory and language. On the other hand, our XAI work supports clinical studies associating
retinal degeneration to be linked to Alzheimer‚Äôs Disease, rather than normal aging, as well as
connections with cerebral small vascular disease.
Overall, our study demonstrates an explainable and systematic framework to map subjects
into the progression continuum of Alzheimer‚Äôs Disease using retinal vasculature from fundus
images. Our method is effective in enhancing biological and diagnostic understanding, and
automating healthcare streamlining and preclinical screening. This study will be helpful in
examining how retinal pathology is connected to cognitive impairment neurodegeneration,
with not only applications to AD, but other types of dementia and neurological/retinal diseases.
Methods
LAVA is a systematic method that leverages neuron-level explanation as auxiliary information
during the learning process to predict coarse-to-fine class in a downstream classification task
where only coarse-level target labels are available. In this section, the details of our proposed
XAI framework are provided.
Neuron Probing. In the first phase of LAVA framework, we look to find a subset of critical
neurons at each layer of the CNN model containing the most information concerning the
prediction of class labels.
Let consider any CNNs classification model Œ¶with a sequential structure consisting of ùêø
layers, where each layer ùëôhasùêæùëôneurons and ùëô={1, .., ùêø}. Once any input sample ùë•‚ààRùëõ
is fed into the model Œ¶through the forwarding function ùë¶=ùëì(ùë•)where ùë¶‚ààRùëöis a logit,
the activation of neurons at layer ùëôdenoted as ùëçùëôis a random variable and also a function of
the input ùëçùëô=ùëìùëô(ùë•)where ùëìùëô:Rùëõ‚ÜíRùëòùëô. The forwarding structure of the neural networks
suggests the activation of neurons at each layer depends only on the activation of the neurons
at the previous layer i.e., ùëçùëô‚ä• ‚ä•ùëçùëñ|ùëçùëô‚àí1,‚àÄùëñ= 0, ..., ùëô‚àí2, where‚ä• ‚ä•denotes the independent
relationship.Our goal is to find a subset of critical neurons at each layer ùëôcontaining the most information
on the prediction of interest. Recently, the notion of criticality in neuron-level extraction and
the objective of critical neurons identification subsequently is formulated with joint mutual-
information (MI) function [ 35] from probability and information theories [ 36] to measure the
mutual dependence between two variables.
Let(ùëçùëô, ùëçùëô+1)be two discrete random variables over the space ùíµùëô√óùíµùëô+1to indicate activation
of neurons for a pair of adjacent layers in CNN model. If ùëÉ(ùëçùëô,ùëçùëô+1)denotes the joint distribution
andùëÉùëçùëôandùëÉùëçùëô+1denote marginals, then the amount of information shared between those
two adjacent layers can be measured by an MI objective that searches for the set of critical
neurons at each layer on the set of critical neurons solved in the next layer [35].
ùëÄùêº(ùëçùëô;ùëçùëô+1) =‚àëÔ∏Å
ùëçùëô‚ààùíµùëô‚àëÔ∏Å
ùëçùëô+1‚ààùíµùëô+1ùëÉ(ùëçùëô,ùëçùëô+1)logùëÉ(ùëçùëô,ùëçùëô+1)
ùëÉùëçùëôùëÉùëçùëô+1(1)
Thus, a sequence of MI objectives, starting from the last layer, can be optimized at any layer
with respect to its preceding layer to identify the most critical neurons from each layer ùëÄùëô
through the network. This sparse sub-network of critical neurons conveys the most important
information all the way from input to output of the model.
ùëÄùëô= argmax
ùëÄùëô‚äÜùêæùëôùëÄùêº(ùëçùëÄùëô
ùëô;ùëçùëÄùëô+1
ùëô+1) (2)
Directly solving Equation (2) at each pair of adjacent layers in this sequential optimization
formulation is in NP-hard [ 37], because as proved in [ 35], MIN-FEATURES [ 38] problem can
be reduced to this problem in polynomial time. On the other hand, the state of Markov chain
ofùêølayers ( ùëç0‚Üíùëç1‚Üí...‚Üíùëçùêø) [39] suggests ùëçùëÄùëô
ùëôcan determine ùëå, and consequently,
ùëÄùëôthat contains ùëÄùëô(ùëå). As a consequence, to overcome the the curse of dimensionality, an
approximation solution can solve MI objective at each pair of a layer with the output (ùëçùëÄùëô
ùëô;ùëå)
instead of solving that at each pair of adjacent layers (ùëçùëÄùëô
ùëô;ùëçùëÄùëô+1
ùëô+1)as follows:
ùëÄùëô‚âàargmax
ùëÄùëô‚äÜùêæùëôùëÄùêº(ùëçùëÄùëô
ùëô;ùëå) (3)
The entropic (informational) correlation between a feature and class label in high-dimensional
scheme is a useful statistic measurement for feature selection. As the mutual information
enlarges, the feature becomes more significant and distinguishable. Let ùëß‚ààùëçùëôdenote a feature
(single neuron at layer ùëô) andùë¶‚ààùëådenote a class of label, then the mutual information between
them can be defined as follows:
ùëÄùêº(ùëçùëô;ùëå) =ùëÄ‚àëÔ∏Å
ùëó=1ùëÅ‚àëÔ∏Å
ùëñ=1ùëù(ùë¶ùëó, ùëßùëñ) log2ùëù(ùë¶ùëó, ùëßùëñ)
ùëù(ùë¶ùëó)ùëù(ùëßùëñ)(4)
where ùëõ={1, ..., ùëÅ}andùëö={0, ..., ùëÄ}are the number of different values for ùëßandùë¶
respectively, ùëù(ùëßùëñ)andùëù(ùë¶ùëó)are marginals, and ùëù(ùëßùëñ, ùë¶ùëó)is the joint probability.
NeuCEPT [ 35] uses Model-X Knockoffs as a statistical tool with false discovery rate control
to approximate Markov Blanket [ 40] as the smallest subset of neurons at each layer maximizingthe MI; however, it imposes some limitations in our application: (1) The subtle differences
among fundus images result in low variance in distribution of neurons‚Äô activation which
makes it difficult for any neurons to be selected. (2) Selection of critical neurons from large-
sized intermediate layers of our network is difficult due to the complexity of matrix inversion
operation involved. In order to overcome aforementioned limitations, MI can be alternatively
approximated using density estimates [ 41] based on the Kernel Density Estimator (KDE) [ 25] and
thus Model-X Knockoffs can be replaced with any Maximum Likelihood Estimation (MLE)-based
feature selection technique as an estimation of MI.
We adopt the same method used in [ 42] for gene selection from expansive patterns of gene
expression data in genetic diagnosis (or drug discovery) in LAVA to capture a very small and
compact (non-redundant) multiset2of the most critical neurons at each selected layer through
the network while evaluating the binary target labels (AD/NC) by cross-validation models in the
different subsets of input images. This approach combines Epsilon Support Vector Regression
with Recursive Feature Elimination algorithm ( ùúñ-SVR+RFE) to satisfy the MLE objective in
selection of the critical neurons across all ùêølayers each of ùêæùëô-dimensionality. Following the
same objective of Joint Mutual Information (MI) function, ùúñ-SVR [ 43] maximizes likelihood
estimation to identify critical neurons with respect to the output of the model. More specifically,
this feature scoring method constructs a coefficient vector with a logit link function and a
regularized maximum likelihood score. Thus, as shown in [ 44], this compact feature selection
technique employed in LAVA assures that the neuron whose MI is larger is more likely to be
selected as critical. In this technique, RFE is a wrapper-type statistical method that uses ùúñ-SVR
algorithm in the core. It eliminates the least important features iteratively until the desired
number of features is reached.
Epsilon-supported Support Vector Regression ( ùúñ-SVR) attributes coefficients of contribution to
each neuron under acceptable maximum error ùúñ(epsilon). First the activation value of ùëÄcritical
neurons at a selected layer for ùëÅsample inputs{ùëç}ùëÅ√óùëÄmaps in feature space ùëà=ùúë(ùëç), and
then a hyperplane is constructed using a kernel function ùëì(ùëç, ùëä ) =ùëäùëáùëç+ùëèthat minimize
its deviation from training data by minimizing L2 norm of the coefficient vector ||ùëä||. The
setting of hyperparameters for ùúñ-SVR includes a kernel parameter (e.g, linear, sigmoid, radial
basis function, and polynomial) and a regularization parameter. The latter is used to make a
tradeoff between the complexity of the model and the accuracy of the training. The objective
function of ùúñ-SVR is as follows:
min1
2||ùëä||2+ùê∂ùëõ‚àëÔ∏Å
ùëñ=1|ùúâùëñ| (5)
constrained by|ùë¶ùëñ‚àí‚àëÔ∏ÄùëÄ
ùëó=1ùë§ùëó(ùëßùëñ,ùëó)|‚â§ùúñ+|ùúâùëñ|.
Here ùë§ùëóis the coefficient of the support vector in the decision function assigned to the
ùëó-th critical neuron and ùúñdenotes a margin for absolute distance value between actual and
predicted values in the training loss function for which no penalty is associated. Penalties can
be regularized by ùê∂as a measure of tolerance for the output of the ùëñ-th input sample to fall
outside ùúâùëñdeviation from true output variable ùë¶ùëñand still is acceptable within error margin ùúñ.
The implementation of ùúñ-SVR is from LIBSVM library [45].
2An ensemble bag with repeated elements (multiplicity is allowed.)The results obtained by ùúñ-SVR+RFE feature selection technique at the Neuron Probing phase
of LAVA framework can be adjusted to desired detail level that characterizes subpopulations
within the target continnum. The pseudocode of this algorithm is provided in Supplementary
Algorithm 1.
Granularity Explanation. In the second phase of the LAVA framework, we search to answer
this question ‚ÄúTo what extent similarity between input samples in terms of the pattern of activation
is consistent with that in terms of true labels in the multi-granularity deep local structure of target
domain?‚Äù To discern the division of AD subjects, our choice of agglomerative connectivity
constraint clustering with ward‚Äôs linkage (also known as Minimum Variance) is rational to the
intrinsic granularity of diagnostic biomarkers associated with the continnum of progressive
nature of Alzheimer‚Äôs disease. Our hypothesis is that hierarchical representation levels hidden
in the input image dataset can interpret biomedical features associated with progressive disease
in this study. Although such artifacted dynamics biomarkers mapped to different levels of
abstraction representation made by a convolutional deep neural model might not be visually
descriptive and explicitly perceptible by humans.
We employ the Hierarchical Agglomerative Clustering (HAC) method with connectivity
constraints ( ùëò-NNG graph) [ 20] to partition entire eye fundus image samples into subgroups of
data based on similar activation patterns of critical neurons during evaluation of the image by
the CNN model. The description and pseudocode of this algorithm is provided in Supplementary
Algorithm 2 and Supplementary Method A.
The appropriate number of clusters can be visualized and heuristically determined on a
hierarchical ward‚Äôs tree of the clustering learning process so-called dendrogram. The height of
rectangles fit between different levels of hierarchy in dendrogram represents the distinctiveness
among clusters at that specific level. The number of vertical lines cut by an imaginary horizontal
line traversing dendrogram determines the correspondent number of clusters as a configurable
parameter in HAC learning algorithm.
Study Population and Baseline Characteristics This study is conducted on the UK Biobank.
At the time of acquisition (Jun 2019) of our UKB basket, there are a total of 1,005 AD subjects
from approximately 500,000 total subjects. In particular, we investigate the incidence of AD,
which is defined as subjects who are diagnosed with Alzheimer‚Äôs Disease after the baseline visit,
in contrast to prevalent AD, which consists of subjects with a record of AD diagnosis before the
baseline visit (as according to the UK public health records, ICD9 and ICD10 codes). From the
1005 AD subjects in the UKB, there are 111 AD subjects with fundus images. Next, we manually
select an overall number of 100 images from 61 unique AD subjects images upon the following
criteria: (1) the incidence of AD, (2) sufficient visibility of the retinal vasculature in terms of the
level of artifacts and clarity of the image, and (3) no record of other neurodegenerative diseases,
excluding subjects with mixed dementia and/or forms of Parkinsonism. To prevent external bias
in our analysis, we perform age and gender matching for each AD subject with a normal control
(NC). We note that a normal control subject is taken with the understanding of no current label
of dementia, regardless of whether a subject may be at risk, or develop dementia in the future.
We identify 100 images from a total of 80 unique NC subjects, wherein an additional NC subject
is substituted when the image quality for certain fundus image pairs for a matched AD subject
is insufficient.
Supplementary Table 2 showcases the summary statistics of the study population includingdemographics (age, gender, and ethnicity), ophthalmic features, and covariates. The ophthalmic
features include eye problems (e.g., glaucoma, cataratcs, etc.) and visual acuity (LogMAR). The
covariates include townsend indices, obesity-diabetes status, smoking status, alcohol status, and
history of stroke. Obesity-diabetes is defined as a BMI greater than 30 or diagnosis of diabetes.
All baseline characteristics were selected on the basis of explored risk factors in AD-studies
[46, 47].
Data-Preprocessing. A manual image quality selection is employed to ensure that each fundus
image has sufficient retinal vascular visibility. We employ the AutoMorph pipeline for image pre-
processing. In particular, the image undergoes thresh-holding, morphological image operations,
and cropping to effectively remove the background of the fundus images. The images are passed
into a Segan [ 48] network for vessel segmentation pretrained on a collection of labeled retinal
vasculature datasets. The details of pre-training can be found in [ 17]. During the model training
and evaluation of our classifiers, the vessel maps are resized to 224√ó224in accordance with
ImageNet. The vascular morphological features are computed using the original image size.
Data Partitioning, Tuning, and Evaluation. In the binary classification task, we apply
nested stratified five-fold cross validation. To avoid potential bias, each fold is split such that
eyes from the same subject are contained in the same fold and each fold is equivalent in number
(n = 20 images). To maximize the limited data, we tune the hyper-parameters during training
with a four-fold cross validation loop and re-train the model over all training data with the best
hyper-parameters. Our experiments suggest optimization over a small learning rate grid of
[1e-4, 1e-5] and a maximal number of 50 epochs is sufficient. We use a cross-entropy loss, Adam
optimizer [ 49], and data augmentations (flipping and rotations) for fine-tuning an ImageNet pre-
trained VGG-16 classifier [ 18]. The model is then re-trained over the optimal hyper-parameters
using all of the training data and tested on the outer cross-validation fold.
Vascular Morphological Feature Measurements. The AutoMorph pipeline is used to extract
the vessel density and fractal dimension [ 50] from the retinal vasculature. These measures are
chosen on the basis of hypothesized mechanisms concerning the reduction of vessel structures
(e.g., small vessel disease) and structural complexity [ 51,52,6]. The vessel density is defined as
the proportion of vessel pixels to the number of pixels in the image. The fractal dimension is
defined here as the Minkowski-Bouligand dimension, also known as the box-counting dimension.
Letùëãdenote a (square) image, that is, the input vessel map. The Minkowski-Bouligand
dimension is thus defined as follows:
FDùëèùëúùë•(ùëã) = lim
ùúñ‚Üí0log(ùëÅ/ùúÄ)
log(1/ùúÄ)(6)
Discretely, ùëÅis the input size of the image where ùúñis taken such that the window size of the
box is reduced by a factor of 2until the window attains a box of chosen size, 16√ó16.
Cognitive Tests. The UKB administers several cognitive tests for a subset of the UKB cohort
[28]. The Pairs Matching Test (Field 399; Number of Incorrect Matches) contains a three card
and six card variant. We select the six card variant for analysis for simplicity, larger variance,
as well as being used in other studies [ 53]. Moreover, we extract the prospective memory (Field
20018: Prospective Memory Result), and fluid intelligence (Field 20016: Fluid Intelligence Scores).
Overall, these tests are chosen on the basis of natural associations of reduction in AD subjects
(symptomatic of the loss of memory and problem-solving) which have been investigated inprior clinical studies [ 54,55]. For the few subjects who do not have cognitive test measures,
their values are interpolated using the average over their diagnostic class.
Acknowledgments
This material is based upon work supported by the National Science Foundation under Grant
No. (NSF 2123809).
Data Availability Statement
This research has been conducted using the UK Biobank Resource under application number
48388. The datasets are available to researchers through an open application via https://www.
ukbiobank.ac.uk/register-apply/.References
[1] Issue information, Alzheimers. Dement. 18 (2022) 545‚Äì550.
[2]P. S. Aisen, J. Cummings, C. R. Jack, J. C. Morris, R. Sperling, L. Fr√∂lich, R. W. Jones,
S. A. Dowsett, B. R. Matthews, J. Raskin, et al., On the path to 2025: understanding the
alzheimer‚Äôs disease continuum, Alzheimer‚Äôs research & therapy 9 (2017) 1‚Äì10.
[3]M. T√°buas-Pereira, I. Baldeiras, D. Duro, B. Santiago, M. H. Ribeiro, M. J. Leit√£o, C. Oliveira,
I. Santana, Prognosis of early-onset vs. late-onset mild cognitive impairment: Comparison
of conversion rates and its predictors, Geriatrics 1 (2016). URL: https://www.mdpi.com/
2308-3417/1/2/11. doi: 10.3390/geriatrics1020011 .
[4]H. Shi, Y. Koronyo, A. Rentsendorj, D.-T. Fuchs, J. Sheyn, K. L. Black, N. Mirzaei, M. Koronyo-
Hamaoui, Retinal vasculopathy in alzheimer‚Äôs disease, Frontiers in Neuroscience (2021)
1211.
[5]M. Koronyo-Hamaoui, H. Shi, A. Rentsendorj, D.-T. Fuchs, J. Sheyn, G. C. Regis,
K. Wawrowsky, A. A. Kramerov, A. V. Ljubimov, S. Lahiri, et al., Retinal vascular ab-
normalities and blood-retinal barrier breakdown in alzheimer‚Äôs disease, Alzheimer‚Äôs &
Dementia 17 (2021) e056603.
[6]Y.-T. Ong, S. Hilal, C. Y.-l. Cheung, X. Xu, C. Chen, N. Venketasubramanian, T. Y. Wong,
M. K. Ikram, Retinal vascular fractals and cognitive impairment, Dementia and geriatric
cognitive disorders extra 4 (2014) 305‚Äì313.
[7]S. Langella, M. U. Sadiq, P. J. Mucha, K. S. Giovanello, E. Dayan, Lower functional
hippocampal redundancy in mild cognitive impairment, Translational Psychiatry 11
(2021).
[8]Y. Zhang, Y. Wang, C. Shi, M. Shen, F. Lu, Advances in retina imaging as potential
biomarkers for early diagnosis of alzheimer‚Äôs disease, Translational Neurodegeneration
10 (2021) 1‚Äì9.
[9]C. E. Wisely, D. Wang, R. Henao, D. S. Grewal, A. C. Thompson, C. B. Robbins, S. P.
Yoon, S. Soundararajan, B. W. Polascik, J. R. Burke, et al., Convolutional neural network
to identify symptomatic alzheimer‚Äôs disease using multimodal retinal imaging, British
Journal of Ophthalmology 106 (2022) 388‚Äì395.
[10] J. Tian, G. Smith, H. Guo, B. Liu, Z. Pan, Z. Wang, S. Xiong, R. Fang, Modular machine
learning for alzheimer‚Äôs disease classification from retinal vasculature, Nature Scientific
Reports 11 (2021) 238. doi: https://doi.org/10.1038/s41598-020-80312-2 .
[11] Q. Zhang, J. Li, M. Bian, Q. He, Y. Shen, Y. Lan, D. Huang, Retinal imaging techniques based
on machine learning models in recognition and prediction of mild cognitive impairment,
Neuropsychiatr. Dis. Treat. 17 (2021) 3267‚Äì3281.
[12] K. Simonyan, A. Vedaldi, A. Zisserman, Deep inside convolutional networks: Visualising
image classification models and saliency maps. arxiv 2013, arXiv preprint arXiv:1312.6034
(2019).
[13] S. M. Lundberg, S.-I. Lee, A unified approach to interpreting model predictions, Advances
in neural information processing systems 30 (2017).
[14] M. T. Ribeiro, S. Singh, C. Guestrin, ‚Äúwhy should i trust you?‚Äù: Explaining the predictions
of any classifier, in: NAACL 2016, 2016.
[15] M. Sundararajan, A. Taly, Q. Yan, Axiomatic attribution for deep networks, in: Internationalconference on machine learning, PMLR, 2017, pp. 3319‚Äì3328.
[16] C. Sudlow, J. Gallacher, N. Allen, V. Beral, P. Burton, J. Danesh, P. Downey, P. Elliott,
J. Green, M. Landray, et al., Uk biobank: an open access resource for identifying the
causes of a wide range of complex diseases of middle and old age, PLoS medicine 12 (2015)
e1001779.
[17] Y. Zhou, S. K. Wagner, M. A. Chia, A. Zhao, M. Xu, R. Struyven, D. C. Alexander, P. A.
Keane, et al., Automorph: Automated retinal vascular morphology quantification via a
deep learning pipeline, Translational vision science & technology 11 (2022) 12‚Äì12.
[18] K. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale image
recognition, arXiv preprint arXiv:1409.1556 (2014).
[19] B. J. Frey, D. Dueck, Clustering by passing messages between data points, Science 315
(2007) 972 ‚Äì 976.
[20] C. Ambroise, A. Dehman, P. Neuvial, G. Rigaill, N. Vialaneix, Adjacency-constrained
hierarchical clustering of a band similarity matrix with application to genomics, Algorithms
for Molecular Biology : AMB 14 (2019).
[21] L. McInnes, J. Healy, Umap: Uniform manifold approximation and projection for dimension
reduction, ArXiv abs/1802.03426 (2018).
[22] T. Cali≈Ñski, J. Harabasz, A dendrite method for cluster analysis, Communications in
Statistics-theory and Methods 3 (1974) 1‚Äì27.
[23] X. V. Nguyen, J. Epps, J. Bailey, Information theoretic measures for clusterings comparison:
is a correction for chance necessary?, in: ICML ‚Äô09, 2009.
[24] L. Van der Maaten, G. Hinton, Visualizing data using t-sne., Journal of machine learning
research 9 (2008).
[25] Y.-C. Chen, A tutorial on kernel density estimation and recent advances, Biostatistics &
Epidemiology 1 (2017) 161‚Äì187.
[26] D. Arthur, S. Vassilvitskii, k-means++: the advantages of careful seeding, in: SODA ‚Äô07,
2007.
[27] D. Comaniciu, P. Meer, Mean shift: A robust approach toward feature space analysis, IEEE
Trans. Pattern Anal. Mach. Intell. 24 (2002) 603‚Äì619.
[28] C. Fawns-Ritchie, I. J. Deary, Reliability and validity of the uk biobank cognitive tests, The
American journal of managed care 15 (2020). doi: 10.1371/journal.pone.0231627 .
[29] L. Sp√≠ndola, S. M. D. Brucki, Prospective memory in alzheimer‚Äôs disease and mild cognitive
impairment, Dementia & Neuropsychologia 5 (2011) 64‚Äì68.
[30] A. Khakzar, S. Baselizadeh, S. Khanduja, C. Rupprecht, S. T. Kim, N. Navab, Neural
response interpretation through the lens of critical pathways, 2021 IEEE/CVF Conference
on Computer Vision and Pattern Recognition (CVPR) (2021) 13523‚Äì13533.
[31] Lucent, ???? URL: https://pypi.org/project/torch-lucent/.
[32] R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, D. Batra, Grad-cam: Visual
explanations from deep networks via gradient-based localization, in: Proceedings of the
IEEE international conference on computer vision, 2017, pp. 618‚Äì626.
[33] D. Smilkov, N. Thorat, B. Kim, F. B. Vi√©gas, M. Wattenberg, Smoothgrad: removing
noise by adding noise, CoRR abs/1706.03825 (2017). URL: http://arxiv.org/abs/1706.03825.
arXiv:1706.03825 .
[34] R. Luben, S. Wagner, R. Struyven, M. Cortina-Borja, A. Petzold, E. Trucco, M. R. K. Mookiah,J. Rahi, A. K. Denniston, P. A. Keane, Retinal fractal dimension in prevalent dementia: The
alzeye study, Investigative Ophthalmology & Visual Science 63 (2022) 244440‚ÄìF0119.
[35] M. N. Vu, T. D. Nguyen, M. T. Thai, Neucept: Locally discover neural networks‚Äô mechanism
via critical neurons identification with precision guarantee, arXiv preprint arXiv:2209.08448
(2022).
[36] T. M. Cover, J. A. Thomas, Elements of Information Theory (Wiley Series in Telecommuni-
cations and Signal Processing), Wiley-Interscience, USA, 2006.
[37] S. Davies, S. J. Russell, Np-completeness of searches for smallest possible feature sets,
1994.
[38] S. Davies, S. Russell, Np-completeness of searches for smallest possible feature sets, in:
AAAI Symposium on Intelligent Relevance, AAAI Press Menlo Park, 1994, pp. 37‚Äì39.
[39] J. Pearl, A. Paz, Confounding equivalence in causal inference, Journal of Causal Inference
2 (2014) 75‚Äì93.
[40] D. Koller, N. Friedman, Probabilistic Graphical Models: Principles and Techniques - Adap-
tive Computation and Machine Learning, The MIT Press, 2009.
[41] T. Suzuki, M. Sugiyama, J. Sese, T. Kanamori, Approximating mutual information by
maximum likelihood density ratio estimation, in: FSDM, 2008.
[42] I. Guyon, J. Weston, S. D. Barnhill, V. N. Vapnik, Gene selection for cancer classification
using support vector machines, Machine Learning 46 (2004) 389‚Äì422.
[43] J. Platt, N. Karampatziakis, Probabilistic outputs for svms and comparisons to regularized
likelihood methods, 2007.
[44] X. Lin, F. Yang, L. Zhou, P. Yin, H. Kong, W. Xing, X. Lu, L. Jia, Q. Wang, G. Xu, A
support vector machine-recursive feature elimination feature selection method based on
artificial contrast variables and mutual information, Journal of chromatography B 910
(2012) 149‚Äì155.
[45] C.-C. Chang, C.-J. Lin, Libsvm: A library for support vector machines, ACM Trans. Intell.
Syst. Technol. 2 (2011) 27:1‚Äì27:27.
[46] J. Gong, K. Harris, S. A. E. Peters, M. Woodward, Sex differences in the association between
major cardiovascular risk factors in midlife and dementia: a cohort study using data from
the UK biobank, BMC Medicine 19 (2021). URL: https://doi.org/10.1186/s12916-021-01980-z.
doi:10.1186/s12916-021-01980-z .
[47] A. L. Lumsden, A. Mulugeta, A. Zhou, E. Hypp√∂nen, Apolipoprotein e (APOE) genotype-
associated disease risks: a phenome-wide, registry-based, case-control study utilising the
UK biobank, eBioMedicine 59 (2020) 102954. URL: https://doi.org/10.1016/j.ebiom.2020.
102954. doi: 10.1016/j.ebiom.2020.102954 .
[48] Y. Xue, T. Xu, H. Zhang, L. R. Long, X. Huang, Segan: adversarial network with multi-scale
l1 loss for medical image segmentation, Neuroinformatics 16 (2018) 383‚Äì392.
[49] D. P. Kingma, J. Ba, Adam: A method for stochastic optimization, arXiv preprint
arXiv:1412.6980 (2014).
[50] K. J. Falconer, Cambridge tracts in mathematics: The geometry of fractal sets series number
85, Cambridge University Press, Cambridge, England, 2010.
[51] Y. S. Zhang, N. Zhou, B. M. Knoll, S. Samra, M. R. Ward, S. Weintraub, A. A. Fawzi,
Parafoveal vessel loss and correlation between peripapillary vessel density and cognitive
performance in amnestic mild cognitive impairment and early alzheimer‚Äôs disease onoptical coherence tomography angiography, PloS one 14 (2019). doi: https://doi.org/
10.1371/journal.pone.0214685 .
[52] J. M. Wardlaw, P. A. Sandercock, M. S. Dennis, J. Starr, Is breakdown of the blood-brain
barrier responsible for lacunar stroke, leukoaraiosis, and dementia?, Stroke 24 (2014)
806‚Äì812. doi: https://doi.org/10.1161/01.STR.0000058480.77236.B3 .
[53] D. M. Lyall, B. Cullen, M. Allerhand, D. J. Smith, D. Mackay, J. Evans, J. Anderson, C. Fawns-
Ritchie, A. M. McIntosh, I. J. Deary, et al., Cognitive test scores in uk biobank: data reduction
in 480,416 participants and longitudinal stability in 20,346 participants, PloS one 11 (2016)
e0154222.
[54] L. Sp√≠ndola, S. M. D. Brucki, Prospective memory in alzheimer‚Äôs disease and mild cognitive
impairment, Dementia & Neuropsychologia 5 (2011) 64‚Äì68.
[55] N. Raz, U. Lindenberger, P. Ghisletta, K. M. Rodrigue, K. M. Kennedy, J. D. Acker, Neu-
roanatomical correlates of fluid intelligence in healthy adults and persons with vascular
risk factors, Cerebral cortex 18 (2008) 718‚Äì726.Supplementary Information
A. Supplementary Methods
Adjacency-constrained Hierarchical Agglomerative Clustering. Hierarchical clustering
can be generated either top-down called divisive clustering similar to ùëò-means (where a data set
is divided into more number of smaller clusters gradually) or bottom-up called agglomerative
clustering (where initially every data point is considered as an individual cluster and then
gradually merged into less number of bigger clusters). Divisive clustering can be linear in the
number of clusters if the number of top levels is fixed, despite that the number of clusters
in LAVA formulation is not pre-defined and depends on the application and the granularity
nature of the data structure. We use Hierarchical Agglomerative Clustering (HAC) with ward‚Äôs
linkage. The time complexity of naive agglomerative clustering is ùëÇ(ùëõ3)and can be reduced
toùëÇ(ùëõ2ùëôùëúùëîùëõ)when priority queue data structure is used and can be reduced to ùëÇ(ùëõ2)with
some further optimization. In HAC algorithm, the between-cluster agglomerative distance can
be recursively computed, while aggregated distance between clusters can be updated without
need to compute all the pair of objects contained in the clusters. In this setting, we use ward‚Äôs
linkage to update aggregated distance between clusters. This approach attempts to merge two
clusters for which the change in total variation is minimized. The total variation of a clustering
result is the sum of squared-error ùê∏ùëÜùëÜ (ùê∂)(so-called inertia of cluster C [20]) between every
object and the centroid of the cluster containing that object. Thus, Ward‚Äôs linkage criterion ùõø
can be formulated as follows when two clusters ùê∂andùê∂‚Ä≤are merged where ùê∂¬Øis the the mean
vector (centroid) of the clusters.
ùõø(ùê∂, ùê∂‚Ä≤) =ùê∏ùëÜùëÜ (ùê∂‚à™ùê∂‚Ä≤)‚àíùê∏ùëÜùëÜ (ùê∂)‚àíùê∏ùëÜùëÜ (ùê∂‚Ä≤) (A.1)
ùê∏ùëÜùëÜ (ùê∂) :=1
|ùê∂|‚àëÔ∏Å
ùëñ‚ààùê∂||ùë•ùëñ‚àíùê∂¬Ø||2(A.2)
Suppose we have two clusters ùê∂andùê∂‚Ä≤that are merged into a new cluster ùê∂*, and let ùê∂‚Ä≤‚Ä≤be
any other cluster. Let the size of cluster ùê∂,ùê∂‚Ä≤,ùê∂‚Ä≤‚Ä≤beùëõùëê,ùëõ‚Ä≤
ùëê,ùëõ‚Ä≤‚Ä≤
ùëêcorrespondingly. Algorithm
updates distance ùê∑(ùê∂*, ùê∂‚Ä≤‚Ä≤)from ùê∑(ùê∂, ùê∂‚Ä≤‚Ä≤)andùê∑(ùê∂‚Ä≤, ùê∂‚Ä≤‚Ä≤)through a systematic pairwise
distance ùê∑(ùë•ùëñ, ùë•ùëó)for every ùëñÃ∏=ùëóis given as follows.
ùê∑(ùê∂*, ùê∂‚Ä≤‚Ä≤) =ùëõùëê+ùëõ‚Ä≤‚Ä≤
ùëê
ùëõùëê+ùëõ‚Ä≤ùëê+ùëõ‚Ä≤‚Ä≤ùëêùê∑(ùê∂, ùê∂‚Ä≤‚Ä≤)+
ùëõ‚Ä≤
ùëê+ùëõ‚Ä≤‚Ä≤
ùëê
ùëõùëê+ùëõ‚Ä≤ùëê+ùëõ‚Ä≤‚Ä≤ùëêùê∑(ùê∂‚Ä≤, ùê∂‚Ä≤‚Ä≤)‚àíùëõ‚Ä≤‚Ä≤
ùëê
ùëõùëê+ùëõ‚Ä≤ùëê+ùëõ‚Ä≤‚Ä≤ùëêùê∑(ùê∂, ùê∂‚Ä≤)(A.3)
In our experiment, we use the entire set of input images for which the array of features
(critical neurons‚Äô activation) serves as raw training data so-called activation dataset in the
constrained version of clustering algorithm in semi-supervised setting.
Given ùëòdifferent parameterization of a classifier model Œ¶through nested ùëò-fold cross-
validation learning paradigm, with ùêø‚Ä≤selected layers where ùëô‚Ä≤={1, .., ùêø‚Ä≤}, andùëÅ={1, ..., ùëÅ}total number of input samples ùëã={ùë•1, ..., ùë• ùëõ}. let{ùëçùëò
ùëô‚Ä≤}ùëÅ
ùëñ=1denotes the activation of critical
neurons at selected layer ùëô‚Ä≤ofùëò-th model for ùëñ-th input instance. To aggregate activation values,
first we stack activation values across all cross-validating models {ùëçùëô‚Ä≤}ùëÅ
ùëñ=1. Second we stack
them across all selected layers {ùëç}ùëÅ
ùëñ=1(where ùëñis an index of input sample instance) to construct
a two-dimensional array of the activation values of critical neurons across entire networks over
all input samples.
Letùëå={ùë¶1, ...ùë¶ ùëõ}denotes the array of ground-truth labels for all input images. We
construct the connectivity graph ‚Ñé={0,1}ùëÅ√óùëÅout of the ùëò-nearest neighbor graph (K-NNG)
as constraints in semi-supervised learning algorithm. In this graph, if the distance between
two nodes ùëùandùëûis among the ùëòùë°‚Ñésmallest distance from node ùëùto any other nodes, ùëùand
ùëûare connected. In this setting, standard Euclidean metric measures the difference of ground
truth labels assigned to each sample point. The output of this algorithm is a sparse CSR-format
connectivity matrix A of shape ùëÅ√óùëÅwhere only ùëò√óùëÅnumber of entries (self-included)
are one and the rests are zero. This algorithm reduces a chunk of distances to the ùëò-nearest
neighbors where elements are partitioned by element index ùëò‚àí1in the stable sorted array of
distances for each sample instance.
Connectivity constraints make the clustering algorithm performs differently in the con-
strained version of HAC in two aspects:
1.After each step of merging, a graph ‚Ñé(ùëù)will be created (recursively) to record the
connectivity constraints between clusters at any iteration ùëùwhere current clusters are
treated as nodes in the graph.
2.Two clusters can be merged only if they are connected according to the connectivity
constraint graph at the current iteration ‚Ñé(ùëù).
The pseudocode of this clustering method is provided in Supplementary Algorithm 2
B. Supplementary Algorithms
Algorithm 1. LAVA - Neuron-level Probing
1:Input:
2:A binary vector ùëå^= (ùë¶^1, ..ùë¶^ùëõ)of predicted labels for ùëõinput samples ùëã= (ùë•1, ..ùë•ùëõ).
3:A set of all neurons at ùêølayers denoted as{ùëÜùëô}ùêø
ùëô=1and their activation values for all input samples, denoted as {ùëçùëô}ùêø
ùëô=1.
4:A positive integer ùëÉnumber of critical neurons to extract from selected layer.
5:A Kernel type.
6:An equal or greater than 1 integer for regularization parameter ùê∂.
7:
8:Output:
9:Set of critical neurons at each layer {ùëÜ^ùëô}ùêø
ùëô=1and their activation values {ùëç‚Ä≤
ùëô}ùêæ
ùëô=1.
10:
11:forùëô= 1 toùêødo ‚óÅat each selected layer
12: ùë†ùëêùëúùëüùëíùë†‚áêcoefficient of contribution of neurons to the output of the model ùëå^estimated by ùúñ-SVR on{ùëçùëô}ùêø
ùëô=1.
13: ùëÜ^ùëô‚áêrecursively eliminate the least important neurons based on the ùë†ùëêùëúùëüùëíùë† untilùëÉis reached by RFE.
14: ùëç‚Ä≤
ùëô‚áêfilter activation values for only critical neurons at each layer.
15:return ùëÜ^andùëç‚Ä≤.Algorithm 2. LAVA - Granularity Explanation
1:Input:
2:An array ùëç‚Ä≤of activation values of critical neurons at ùêølayers for all samples (obtained from Algorithm 1)
3:A positive integer ùêænumber of nearest neighbors.
4:A binary vector ùëå= (ùë¶1, ..ùë¶ùëõ)of target labels for ùëõinput samples ùëã= (ùë•1, ..ùë•ùëõ).
5:Ward‚Äôs linkage criterion ùõø.
6:A pairwise distance metric ùúÅ.
7:A positive integer ùëÖnumber of clusters.
8: 9:Output :
10:A ward tree representation ùëàof input samples.
11:A vector of cluster labels ùëäfor input samples.
12:
13:# Linkage matrix construction
14: ‚Ñé={0,1}ùëõ√óùëõ‚áêconstruct sparse connectivity matrix with ùëåandùêæ
15:# Semi-supervised learning
16: Construct distance matrix ùëÄonùëç‚Ä≤withùúÅ.
17: (ùê∂0) = (ùê∂0
ùëñ)1‚â§ùëñ‚â§ùëÅwithùê∂0
ùëñ={ùë•ùëñ} ‚óÅinitializing clusters
18: Initialize ‚Ñé(0)graph on clusters ùê∂0
ùëñas vertices.
19: forùëñ= 1 toùëõ‚àí1
20: if(ùê∂(ùëñ‚àí1)
ùë¢ , ùê∂(ùëñ‚àí1)
ùë¢+1)‚àà‚Ñé(ùëñ‚àí1)‚óÅfind best merging candidate
21: ùëëùë°=ùëéùëüùëîùëöùëñùëõ ùëë‚àà{1,...,ùëÅ‚àíùëñ}ùõø(ùê∂ùëñ‚àí1
ùë¢, ùê∂ùëñ‚àí1
ùë¢+1)
22: Update graph ‚Ñé(ùëñ)on new clusters.
23: Update matrix ùëÄby removing row and column of merged clusters.
24: forùëë= 1 toùëõ‚àíùëñ‚àí1 ‚óÅupdate ùê∂ùëñwithùê∂ùëñ‚àí1
25: ifùëë < ùëë ùëñthenùê∂ùëñ
ùë¢=ùê∂ùëñ‚àí1
ùë¢
26: else if ùëë=ùëëùëñthenùê∂ùëñ
ùë¢=ùê∂ùëñ‚àí1
ùë¢‚à™ùê∂ùëñ‚àí1
ùë¢+1
27: else if ùëë > ùëë ùëñthenùê∂ùëñ
ùë¢=ùê∂ùëñ‚àí1
ùë¢+128: end if
29: end For
30: end for
31: ùëî‚áêconstructed hierarchical ward tree
32: Fitùëîonùëç‚Ä≤for R clusters.
33: ùëà‚áêtransformation of ùëç‚Ä≤by ward tree ùëî
34: ùëä‚áêpredict sub-class labels on ùëç‚Ä≤by ward tree ùëî
35:return ùëàandùëä.
C. Supplementary FiguresMaxPool_4 MaxPool_9MaxPool_16 MaxPool_23 MaxPool_30fc_0 fc_3
Layer0.000.050.100.150.200.250.300.35Jaccard SimilarityFigure 7.: Critical neurons identification. Overlapping between sets of critical neurons at different
layers of the network identified repetitively by different parameterizations of the model obtained from
K-fold cross-validation is measured by Jaccard similarity.
Sub-cluster
AD-3
AD-2
AD-1
Mix ed
CN-3
CN-2
CN-1
Figure 8.: UMAP embedding of input image samples. UMAP embedding reveals potential sub-
clusters within each target class of label learned from eye fundus images at LAVA‚Äôs neuron-level probing
phase.Indices of 200 I nput Sample I magesEuclidean D istanceFigure 9.: The results of the neuron-level hierarchical clustering. Dendrogram of agglomerative
connectivity constraint clustering with ward‚Äôs linkage represents the relationships of similarity among
a clade of AD subjects.
60
 40
 20
 020 40 60
Activation of Critical Neurons0.0000.0050.0100.0150.0200.025Probability DensityMaxPool_9
60
 40
 20
 020 40 60
Activation of Critical Neurons0.0000.0050.0100.0150.0200.025Probability DensityMaxPool_16
60
40
20
0204060
Activation of Critical Neurons0.0000.0050.0100.0150.020Probability DensityMaxPool_23
80
60
40
20
0204060
Activation of Critical Neurons0.0000.0030.0050.0070.0100.0130.0150.0180.020Probability DensityMaxPool_30
60
40
20
020406080
Activation of Critical Neurons0.0000.0050.0100.0150.0200.025Probability Densityfc_0
60
40
20
0204060
Activation of Critical Neurons0.0000.0050.0100.0150.0200.025Probability Densityfc_3
Figure 10.: Exploring activation pattern of critical neurons. Kernel density estimate (KDE) applied
on top of two-dimensional embedded space (lower-dimensional representation of the critical neurons‚Äô
activation at different hidden layers) obtained by t-distributed stochastic neighbor embedding (t-SNE)
and unveils multiple Gaussian distributions embedded in the activation pattern of critical neurons
corresponding to distinctive sub-cluster(s) associated with AD or NC target class (blue and orange
curves) of the disease.a b c
e f
Figure 11.: Box-plot comparisons between AD and NC groups of cognitive and vascular fea-
tures. (*) indicates statistical significance ( ùëù <0.01) by two-tailed significance tests.
D. Supplementary Tables
CN-1 CN-2 CN-3 Mixed AD-1 AD-2 AD-3 Total
AD 0 0 0 31 21 30 18 100
CN 15 39 15 31 0 0 0 100
Table 1.
Results of partitioning data samples by LAVA. In this study, the granularity level is configured to
diagnose 7 subgroups of subjects corresponding to different stages of AD progression. In total 3 AD
groups, 3 CN group and 1 Mixed group are identified by the LAVA framework.Baseline Characteristics AD Group HC Group pvalue
N 61 80 ‚Äì
Age, mean (SD), years 64.5 (3.6) 63.9 (4.1) 0.35
Gender, No. (%) 0.94
Male 27 (44) 34 (45)
Female 34 (56) 44 (55)
Ethnicity, No. (%) 0.74
White 56 (91.8) 78 (97.5)
Others 5 (8.2) 2 (2.5)
Eye Problems (%) 0.98
Yes 10 (16.4) 13 (16.3)
No 51 (83.6) 67 (83.8)
Visual Acuity, mean (SD), LogMAR 0.11 (0.20) 0.06 (0.20) 0.16
Townsend Indices, mean (SD) -1.43 (3.30) -1.55 (2.61) 0.81
Diabetes-Obesity, No. (%) 0.19
Yes 18 (29.5) 16 (20)
No 43 (70.49) 64 (80)
Smoking Status, No. (%) 0.13
Yes 33 (54.1) 33 (41.3)
No 28 (45.9) 47 (58.8)
Alcohol Status, No. (%) 0.18
Yes 60 (98.4) 75 (93.8)
No 1 (1.6) 5 (6.3)
History of Stroke, No. (%) 0.01*
Yes 8 (13.1) 2 (2.5)
No 53 (86.9) 78 (97.5)
Table 2.
Baseline characteristics of the study populations . P-values conducted on continuous data are
computed by the Student‚Äôs t-test. Categorical variables are computed by Pearson‚Äôs Chi-squared test. *
indicates statistically significant ( ùëù <0.05).