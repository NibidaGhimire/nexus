Making the cut: two methods for breaking down a quantum algorithm
Miguel Mur¸ ca,1, 2, 3, ∗Duarte Magano,1, 4,∗and Yasser Omar1, 2, 3
1Instituto Superior T´ ecnico, Universidade de Lisboa, Portugal
2Centro de F´ ısica e Engenharia de Materiais Avan¸ cados (CeFEMA),
Physics of Information and Quantum Technologies Group, Portugal
3PQI – Portuguese Quantum Institute, Portugal
4Instituto de Telecomunica¸ c˜ oes, Lisboa, Portugal
(Dated: May 29, 2023)
Despite the promise that fault-tolerant quantum computers can efficiently solve classically in-
tractable problems, it remains a major challenge to find quantum algorithms that may reach
computational advantage in the present era of noisy, small-scale quantum hardware. Thus, there is
substantial ongoing effort to create new quantum algorithms (or adapt existing ones) to accommodate
depth and space restrictions. By adopting a hybrid query perspective, we identify and characterize
two methods of “breaking down” quantum algorithms into rounds of lower (query) depth, designating
these approaches as “parallelization” and “interpolation”. To the best of our knowledge, these had
not been explicitly identified and compared side-by-side, although one can find instances of them
in the literature. We apply them to two problems with known quantum speedup: calculating the
k-threshold function and computing a NAND tree. We show that for the first problem parallelization
offers the best performance, while for the second interpolation is the better choice. This illustrates
that no approach is strictly better than the other, and so that there is more than one good way to
break down a quantum algorithm into a hybrid quantum-classical algorithm.
I. INTRODUCTION
Algorithms that combine classical processing with lim-
ited quantum computational resources hold an attractive
promise: to provide computational advantage over com-
pletely classical computation, while remaining compatible
with the technological landscape of quantum computing.
The appeal of this kind of algorithm is well reflected in
some of the key modern proposals for quantum advantage,
usually based on variational principles [ 1]. Prominent ex-
amples include the Quantum Approximate Optimization
Algorithm [ 2], the Variational Quantum Eigensolver [ 3–6],
and some versions of Quantum Machine Learning [ 7–11].
All of these attempt to exploit circuits of limited coherence
to obtain computational advantage. However, variational
approaches often cannot offer theoretical performance
guarantees, as discussed in refs. [12, 13].
Consider instead a setting where we are given a quan-
tum algorithm with guaranteed advantage for a certain
computational problem, but the available hardware is too
noisy to execute the algorithm with a reasonable fidelity.
We would need to limit the circuit depths to values much
shorter than the ones prescribed by the original algorithm
to prevent errors from dominating the calculations. Is
it still possible to guarantee some quantum advantage?
We may phrase this question more precisely. Say we are
faced with a computational problem fthat can be solved
by a classical computer in time C(f), and we know a
quantum algorithm that solves fwith complexity Q(f)
(Q(f)< C(f)) by running quantum circuits of depth D;
what is the best we can do if we are only permitted to run
∗These authors contributed equally to this work; corresponding
author address: miguel.murca@tecnico.ulisboa.ptquantum circuits up to a depth D′smaller than D? The
expectation is that best strategy yields an algorithm with
a complexity between C(f) and Q(f). We believe that
understanding this question may contribute to finding
practical but provable advantage in near-term quantum
computers.
For oracular problems, the notion of limited coherence
is captured by the hybrid query (or decision tree) complex-
ityQ(f;D), introduced by Sun and Zheng [ 14]. In this
setting, only the input accesses (or queries) contribute to
the complexity count, while the intermediate computa-
tions are free. Q(f;D) is defined as the minimum number
of queries required to solve fwhen limited to running
quantum circuits of depth D. That is, we can only per-
form Dqueries before being forced to measure the state
of the circuit and restart it.
It is known that quantum decision trees are strictly
more powerful than hybrid decision trees, which are
strictly more powerful than classical decision trees. Con-
cretely, there is a problem ffor which C(f) and Q(f,O(1))
are (super-)exponentially separated [ 15], and similarly
there is a problem ffor which Q(f,O(1)) and Q(f) are
exponentially separated [ 14]. There are also problems f
that exhibit a continuous trade-off between speedup and
circuit depth [ 16], i.e., Q(f;D)< Q(f;D+ 1) for every
Dbetween 1 and Q(f).
Despite these landmark results, it is not always obvious
how to optimally “break up” an algorithm into circuits
of smaller sizes. For example, when given a quantum
circuit that is too deep, P´ erez-Salinas et al. [17] propose
a heuristic algorithm where one performs intermediate
measurements in a parametrized basis, as given by a
shallow variational circuit, optimized to minimize the
effect of measuring and restarting the quantum operation.
But, the expressiveness of the shallow circuit determiningarXiv:2305.10485v2  [quant-ph]  26 May 20232
Figure 1. Diagrammatic representation of the procedures of parallelization (procedure 1) and interpolation (procedure 2), as
defined and exemplified in this paper. For both procedures, the overall goal is to carry out a quantum algorithm (as described
by some unitary U) for some input Xto calculate a property fofX, as shown in the box to the left. However, this unitary may
require a prohibitive depth (modelled by us as a prohibitive amount of coherent quantum queries). In the case of parallelization
(procedure 1), this is dealt with by identifying independent, smaller instances of the same problem that can be dealt with within
the query constraints; in other words, by partitioning the input appropriately into sub-problems. Interpolation (procedure
2) involves, instead, considering multiple repetitions of some unitary (or sequence of unitaries) that require, individually, less
coherent queries, but that collectively yield the same information as a single run of U. For both of these approaches, “breaking
up” the original algorithm may come at a cost of more overall queries – indeed, we expect that this will be the case for most
algorithms. We show that no method is strictly better than the other, and that the best choice depends on the problem at hand.
the measurement basis and the difficulty of minimizing
the cost function may limit the success of this approach.
In this paper, we identify and discuss two general strate-
gies with theoretical guarantees to limit the depth of an
algorithm to some specified value D. We refer to them as
“parallelization” and “interpolation”. Parallelization ap-
plies when a problem can be broken down into a number
of smaller, independent sub-problems, such that the algo-
rithm that solves these sub-problems fits the permitted
circuit depth. In contrast, with interpolation the entire
problem is tackled at each circuit run. It applies whenever
there is a trade-off between the information content of the
measurement and the depth of the corresponding circuit.
In these cases, we may compensate the information loss
caused by shortening the circuit depth with repeated runs
of the shorter circuit. Intuitively, we can say that inter-
polation methods “break up the unitary” that solves the
problem instead of breaking up the problem itself. See
Figure 1 for an illustration of these notions. To the best
of our knowledge, neither of these methods had been ex-
plicitly identified and compared side-by-side, even though
several works that fit into these labels can be found in the
literature. For example, parallelization approaches are
present in refs. [ 18–20], while refs. [ 16,21–23] describe
interpolation methods.
We argue that Quantum Singular Value Transforma-
tions (QSVTs) [ 24] provide a natural framework for think-
ing about interpolation. In a seminal work, Gily´ en et
al.[24] have shown that it is possible to perform poly-nomial transformations on the singular values of large
matrices with circuits whose degree is proportional to
the degree of the corresponding polynomial, and that
many important quantum algorithms can be described
this way. Taking this perspective, limiting the circuit
depth means implementing a rougher approximation to
the target function. As a consequence, each measurement
provides less accurate information about the quantity that
we are trying to estimate. Sometimes, this effect can be
compensated with statistical sampling. That is, we can
trade-off circuit depth and number of circuit runs.
We illustrate these methods with two well-known prob-
lems: the k-threshold function and perfectly balanced
NAND trees. These problems are known to exhibit quan-
tum speed-ups ([ 25] and [ 2,26,27]), but, to the best of
our knowledge, neither has been discussed in the context
of a limited-depth computing model. Both problems are
amenable to both parallelization and interpolation. We
show that for the k-threshold function parallelization of-
fers the best performance, while for evaluating perfectly
balanced NAND trees the interpolation method is the
most efficient. This reinforces the relevance of the dis-
tinction between parallelization and interpolation, and
demonstrates that no technique is a priori better than
the other, as the best option depends on the problem at
hand.3
II. PRELIMINARIES
A. Hybrid Query Model
We will be working mostly within the query model of
quantum computing. Here we quickly review the main
concepts, referring to Ambainis [ 28] for a more in-depth
discussion.
The quantum query complexity model, a generalization
of decision tree complexity [ 29], is widely used to study
the power of quantum computers. On one hand, it cap-
tures the important features of most quantum algorithms,
including search [ 30], period-finding [ 31], and element
distinctness [ 32]. On the other hand, it is simple enough
to make the proof of lower bounds attainable [25, 33].
In the query model, the goal is to compute a Boolean
function f(x1, . . . , x N) of variables xi∈ {0,1}. The func-
tion can be total (defined on {0,1}N) or partial (defined
on a subset of {0,1}N). We only get information about
the input variables by querying a black-box quantum
operator Oacting as
O|i⟩|b⟩=|i⟩|b⊕xi⟩ (1)
for every b∈ {0,1}andi∈ {0,1}N. A quantum query al-
gorithm is specified by a set of input-independent unitaries
U0, U1, . . . , U T. The algorithm consists in performing the
transformation
UTO UT−1. . . U 2O U1O U0|0⟩ (2)
and measuring the result, which is then converted into
the answer of the problem according to a predefined rule.
In the query model, the algorithm’s complexity increases
with each query, while the intermediate computations are
free. That is, the complexity of the algorithm correspond-
ing to transformation (2)isT, independently of how the
unitaries Uiare chosen.
We say that a quantum algorithm computes fwith
bounded error if, for all x∈ {0,1}N, the answer of the
algorithm agrees with f(x) with probability at least 2 /3,
where the probability is over the randomness of the al-
gorithm’s measuring process. The minimum query com-
plexity of any bounded-error algorithm computing fis
the quantum (bounded-error) complexity of f, denoted
asQ(f).
The hybrid query model introduced by Sun and Zheng
[14] captures the idea of restricted-depth computation
in an oracular setting. Hybrid algorithms are in direct
correspondence with hybrid decision trees. A hybrid
decision tree is similar to a (classical) decision tree, but
the decision at each node is determined by the output of a
quantum algorithm with query complexity no more than
a value D, which we refer to as the depth of the hybrid
algorithm. The hybrid algorithm’s answer is the output
of the algorithm at the leaf node. More plainly, a hybrid
algorithm works by running and measuring sequences
of circuits like (2)with T≤D, using the intermediatemeasurements to decide what quantum circuit to run
next.
A hybrid algorithm computes fwith bounded error if,
for all x∈ {0,1}N, the answer of the algorithm agrees with
f(x) with probability at least 2 /3, where the probability
is over the randomness of the internal measurements.
The complexity of a path in a hybrid tree is the sum
of the complexities of the algorithms associated to each
node in the path. The complexity of a hybrid algorithm
that computes a function fis the maximal complexity
of any path that connects the root and a leaf, that is, it
is the total number of queries needed to evaluate fin
the worst case. The minimum query complexity of any
bounded-error hybrid algorithm computing fis the hybrid
(bounded-error) complexity of f, denoted as Q(f;D).
B. Quantum Singular Value Transformations
In this paper we make extensive use of Quantum Sin-
gular Value Transformations (QSVTs) [ 24,34,35]. As a
generalization of the work on Quantum Signal Processing
[36], QSVTs have provided a unifying description of sev-
eral algorithms, including amplitude estimation, quantum
simulation, and quantum methods for linear systems. Re-
cently, Magano and Mur¸ ca [ 23] have shown that QSVTs
also constitute a natural framework for reasoning about
interpolation methods.
By the singular value decomposition theorem, an arbi-
trary matrix Aof rank rcan be written as
A=rX
i=1σi|wk⟩⟨vk|, (3)
where {wk}kand{vk}kare orthogonal sets (known as
the left and right singular values of A, respectively) and
{σk}kare positive real numbers (known as the singular
values of A). For functions P:R→C, we call
P(SV)(A) :=rX
i=1P(σi)|wk⟩⟨vk| (4)
a singular value transformation of A.
When considering performing such transformations on
arbitrary matrices with quantum computers, we are im-
mediately faced with the difficulty that quantum states
evolve according to unitary transformations. The in-
troduction of block-encodings overcomes this apparent
limitation [ 37]. Let Π and ˜Πbe orthogonal projectors
andUbe a unitary; we say that Π, ˜Π, and Uform a
block-encoding of the operator Aif
A=˜ΠUΠ. (5)
Based on this concept, the main theorem of QSVTs
can be phrase as follows.
Theorem 1 (QSVTs [ 24]).LetΠ,˜Π, and Ube a block-
encoding of a matrix A, and let P: [−1,1]→[−1,1]be a4
polynomial of degree d. Then, we can implement a unitary
UPsuch that Π,˜Π, and UPform a block-encoding of
P(SV)(A)usingO(d)calls to U,U†andΠ/˜Π-controlled-
NOT operations.[38]
A transformation that will be particularly useful for us
is the step (or Heaviside) function,
σ7→(
1,ifσ≥µ
0,ifσ < µ, (6)
for some µ∈[−1,1]. Refs. [ 24,39] show that we can
approximate this transformation up to arbitrary accuracy
by a polynomial approximation of the error function,
defined as
(x) :=2√πZx
0e−t2dt . (7)
The result is stated below.
Theorem 2 (Polynomial approximation of step function
[24]).There is a polynomial Pδ,η,µ(λ) : [−1,1]→[−1,1]
of degree
O1
δlog1
η
(8)
satisfying
|Pδ,η,µ(σ)| ≤η,for all σ∈[−1, µ−δ] (9)
Pδ,η,µ(σ)≥1−η,for all σ∈[µ+δ,1]. (10)
We will also be interested in performing a step transfor-
mation on the modulus of the singular values (also known
as a window function due to the shape of its plot),
σ→(
1,if|σ| ≤µ
0,if|σ|> µ. (11)
Noting that Pδ,η,−µ−Pδ,η,µis a polynomial with the same
degree as Pδ,η,µ, we immediately derive the following.
Corollary 1 (Polynomial approximation of window func-
tion).There is a polynomial P′
δ,η,µ(λ) : [−1,1]→[−1,1]
of degree
O1
δlog1
η
(12)
satisfying
|P′
δ,η,µ(σ)| ≤η,for all σ∈[−1,−µ−δ]∪[µ+δ,1]
(13)
P′
δ,η,µ(σ)≥1−η,for all σ∈[−µ+δ, µ−δ]. (14)
Combining Theorems 1 and 2 we find a method to
distinguish the singular values of a block-encoded matrix
that are above or below a given threshold. Similarly,
from Theorem 1 and Corollary 1 we can distinguish the
singular values of a block-encoded matrix whose modulus
are above or below a given threshold.III. TWO APPROACHES TO
RESTRICTED-DEPTH COMPUTATION
A. Parallelization
In many cases the problem at hand can be broken down
into a number of smaller, independent sub-problems. As
an example, consider the problem of computing the OR
function on Nbits. We can partition the domain into p
subdomains of size approximately N/p. If for any of those
subdomains there is an index ifor which xi= 1, then we
return 1; otherwise the answer is 0. In other words, the
problem is reduced to evaluating pOR function on N/p
bits. With Grover’s algorithm [ 30] we can evaluate each
subdomain with O(p
N/p) queries. In total, this strategy
has a query complexity of
Op
pN
. (15)
If we are limited to circuits of depth D, we set p=
O(N/D2), finding that
Q(OR; D) =ON
D+√
N
. (16)
By Corollary 1.5 of Sun and Zheng [14], this is optimal.
We say that the algorithms that employ this kind of
strategy – breaking the problem into smaller problems
that fit the permitted depth – fall into the category of
parallelization methods. Note that this procedure does
not require multiple quantum processors operating at the
same time, even though it is amenable to it. The impor-
tant point is that the different sub-problems considered
are independent and may be treated as such. This should
be contrasted with the notion of parallel quantum algo-
rithms as defined by Jeffery et al. [20], where a number
of queries are realized at the same time (in parallel), but
by a number of quantum registers that may, for example,
be entangled with each other.
Arguably, parallelization as described above is the most
natural approach to “breaking up” a quantum algorithm
into circuits of lower quantum depth. Examples of paral-
lelization include Zalka [18], containing the OR function
discussed above, Grover and Radhakrishnan [ 19], search-
ing for marked elements over many copies of a database,
and Jeffery et al. [20], with the problems of element
distinctness and k-sum. Although these references were
originally motivated by the idea of quantum processors
acting in parallel, they easily translate to the discussion
of restricted-depth setting, and fit into the description of
the procedure of parallelization we have made above.
B. Interpolation
Contrary to parallelization, interpolation methods do
not distribute the problem into different sub-problems.
Instead, at each run the entire problem is tackled – only5
over several quantum circuit runs. Since the circuit depth
is limited, each circuit measurement can only yield partial
information about the answer to problem; the definitive
answer is recovered by repeating the computation multiple
times.
We illustrate this approach with an information-
theoretic argument (similar to that of Wang et al. [21]).
Say that we have a quantum routine Athat prepares the
state
|0n⟩A− →p
1−p|ψ0⟩+√p|ψ1⟩ (17)
for some unknown p∈[0,1], and assume that we can
efficiently distinguish between |ψ0⟩and|ψ1⟩. The goal
is to estimate p, noting that many query problems can
be reduced to estimating an amplitude. With Grover’s
iterator [30], we can prepare the state
cos 
(1 + 2 k)θ
|ψ0⟩+ sin 
(1 + 2 k)θ
|ψ1⟩,(18)
where θ=arcsin √p
, with O(k) calls to A. Now sup-
pose that we prepare and measure the state (18)in the
{|ψ0⟩,|ψ1⟩}basis ltimes, recording the outcomes. The
Fisher information associated with this experiment is
I(π) :=lX
i=0,11
P[|ψi⟩|π]∂
∂πP[|ψi⟩|π]2
=l(1 + 2 k)2
π(1−π), (19)
where P[|ψi⟩|π] is the probability of observing outcome
|ψi⟩in a single trial assuming that p=π. Expression
(19) reveals that the measurement is more informative
the larger the value of k(in particular, that it grows
quadratically with k, justifying the quadratic speedup of
Grover’s algorithm).
Refs. [ 16,22,23] have suggested different schemes to
harness the enhanced information of deeper circuits. Here
we adopt the perspective put forward by Magano and
Mur¸ ca [ 23], according to which QSVTs constitute a natu-
ral framework for interpolation methods. The idea is to
trade off the quality of the polynomial approximation to
the target function by statistical sampling. That is, we
can compensate using polynomials of lower degree (corre-
sponding to lower circuit depths) by running the quantum
circuits more times. The result is a continuous trade-off
between circuit depth and quantum speed-up, without
ever needing to identify independent sub-problems.
In the subsequent sections we demonstrate how QSVTs
can be used to interpolate specific problems.
IV. SOMETIMES PARALLELIZATION IS
BETTER: THRESHOLD FUNCTION
Consider the k-threshold function, a total symmetric
boolean function defined as follows:Threshold k(x1, . . . , x N) =(
0 ifPN
i=1xi≤k
1 otherwise.(20)
This function admits a quantum query speed-up:
whereas in the classical case Θ( N) queries are required
(easily concluded by an adversarial argument), the quan-
tum query complexity is Θ(p
Nmin(k, N−k)) (as fol-
lows from Beals et al. [25]), resulting in the aforemen-
tioned quadratic speed-up when min(k, N−k) =O(1),
and no speed-up when min(k, N−k) = Ω( N). For sim-
plicity, we assume from now on that k≤N/2.
We approach the problem from the perspective of
QSVTs. This is a departure from the original proof
of Beals et al. [25], where the problem of evaluating any
totally symmetric Boolean function is reduced to quan-
tum counting. Arguably, QSVTs permit tackling the
k-threshold problem more directly, while also offering a
more natural route towards interpolation. We show in
Appendix B that our approach can also be generalized
to any totally symmetric Boolean function, although in
that case the proof resembles more closely that of Beals
et al. [25].
We start by making the (trivial) observation that k-
threshold function can be written as a function of the
Hamming weight of the input, which we denote by |x|.
The first step of our algorithm will be to block-encodep
|x|/N(or, more technically, to block-encode the 1 ×
1 matrix whose only entry isp
|x|/N). Then, we will
perform a QSVT on this value to prepare the desired
function of |x|.
Consider the unitary transformation
U=n/H⊗n
OX , (21)
where n=log2(N) – assuming, without loss of generality,
that Nis exactly a power of two – and Ois our query
operator (defined in Section II A). We have that
U|0n+1⟩=r
1
N X
i:xi=0|i⟩|0⟩+X
i:xi=1|i⟩|1⟩!
=r
1−|X|
N|ϕ0⟩|0⟩+r
|X|
N|ϕ1⟩|1⟩,(22)
where |ϕ0⟩and|ϕ1⟩are normalized states. Choosing
Π =|0n+1⟩⟨0n+1|and ˜Π = I 2n⊗|1⟩⟨1| (23)
we find that
˜ΠUΠ =r
|x|
N. (24)
That is, ˜Π, Π, and Uform a block-encoding ofp
|x|/N.
We would like to distinguish between cases wherep
|x|/Nis smaller or equal top
k/N and those where6
it is larger thanp
k/N. From the results on QSVTs
(Theorems 1 and 2) we can perform the transformation
|0n+1⟩ →Pδ,η,µ r
|x|
N!
|ϕ1⟩|1⟩+|⊥1⟩,(25)
where |⊥1⟩is such that ˜Π|⊥1⟩= 0, using
O((1/δ)log(1/η)) calls to U. As Uonly calls the
query operator Oonce, the operation (25)only involves
O((1/δ) log(1 /η)) queries. We choose the parameters as
η= 1/8, (26)
δ=1
2p
(k+ 1)/N−p
k/N
=O1√
kN
,(27)
µ=1
2p
(k+ 1)/N+p
k/N
, (28)
in which case the operation (25) consumes O(√
kN)
queries. The final step is simply to measure the last
qubit of the resulting state, outputting 0 if we measure
|0⟩and outputting 1 if we measure |1⟩. To verify that
this yields the desired answer, consider the two possible
scenarios:
•Threshold k(x1, . . . , x N) = 0. Then,p
|x|/N≤p
|k|/N, which means that Pδ,η,µ(p
|x|/N)≤η=
1/8. So, the probability of measuring the last qubit
in state |1⟩is less than 1 /3.
•Threshold k(x1, . . . , x N) = 1. Then,p
|x|/N >p
|k|/N, which means that Pδ,η,µ(p
|x|/N)≥1−
η= 7/8. So, the probability of measuring the last
qubit in state |1⟩is greater than 2 /3.
If instead k > N/ 2, the algorithm does not
change significantly: denote the logical negation of x
byx, and note that Threshold k(x1, . . . , x N) = 1 −
Threshold k(x1, . . . , xN). It follows that we just need to
evaluate the threshold function on x, whose Hamming
weight is |x|=N−|x|. Looking at expression (22), we see
thatUalready provides a block-encoding of thep
|x|/N:
we just need to replace ˜ΠbyI2n⊗|0⟩⟨0|. Everything else
follows as before.
a. Interpolation. The algorithm that we have just
presented can be interpolated using the same strategy
as in Magano and Mur¸ ca [ 23]. Recall from the theory
of QSVTs (Section II B) that with deeper circuits we
can prepare polynomial transformations of higher degree.
Conversely, by limiting the circuit depths we are forced
to implement a rougher approximation to the target func-
tion (in this case, the step function). The idea is to
compensate this effect by performing a larger number of
measurements.
Concretely, the trade-off between circuit depth and rep-
etitions of the circuit can be controlled by the parameter
η, which we had previously fixed to be O(1) (cf.(26)).
Now we choose
η=O 
2−δD
(29)in such a way that the circuit depth associated with the
transformation by Pδ,η,µis upper bounded by D. If we
measure the last qubit of state (25), the probability that
we see |1⟩is
≤η2,if Threshold k(x) = 0 ,or (30)
≥(1−η)2,if Threshold k(x) = 1 . (31)
So, the problem is reduced to distinguishing the bias
of a Bernoulli distribution with precision 1 −2η. It is
well-known that Θ(1 /(1−η)2) samples are sufficient (and
necessary) to achieve such a precision with bounded-error
probability. That is, we prepare and measure state (25)
O1
(1−η)2
=O1
δD
(32)
times. The total number of queries to Ois
O1
(1−η)2×1
δlog1
η
=O1
δ2D
.(33)
Replacing in the definition of δ(27), we conclude that
Q(Threshold k;D) =OkN
D+√
kN
. (34)
b. Parallelization. The approach of [ 23] was origi-
nally developed in the context phase estimation. In phase
estimation the parameter ϕto be estimated is accessed via
a black-box oracle that changes the phase of a particular
state by an angle proportional to ϕ. In that case, the
interpolation is likely optimal. However, the threshold
problem has more structure than phase estimation. In-
deed, we can choose to query only a subset of the input
variables, in which case the block-encoding holds informa-
tion about the Hamming weight of that subset of input
variables, whereas we cannot choose to query a “fractional
phase”.
It is the parallelization approach that yields the opti-
mal algorithm for evaluating the threshold function in a
restricted-depth setting. To show this, we follow a pro-
cedure similar to that of Grover and Radhakrishnan [ 19].
First, we partition the set {1,2, . . . , N }intopdisjoint sub-
setsV1, . . . , V pof size N/p(to simplify the notation, we
assume that N/p is an integer). Then, for each subset Vi,
we prepare the uniform superpositionp
p/NP
j∈Vi|j⟩|0⟩
and apply to it the query operator O. The resulting state
is
r
p|x/ /V i|
N|ϕ′
1⟩|1⟩+r
1−p|x/ /V i|
N|ϕ′
0⟩|0⟩(35)
where |ϕ′
0⟩,|ϕ′
1⟩are normalized states and |x/ / V i|:=
|{xj∈x:j∈Vi}|. If we run the amplitude estimation
algorithm of Brassard et al. [40] for Dsteps we get an
estimate of the amplitudep
p|x/ /V i|/Nup to precision
O 
1
Dr
p|x/ /V i|
N!
(36)7
with a constant probability. To lower the probability
that the algorithm fails to 1 /p, we repeat the amplitude
amplification routine O(logp) times; this guarantees a
bounded probability that all the amplitude estimations
succeed in returning a precision as in (36). We set
D=

Oq
Nlogp
p
ifk≤plogp
O√
Nk
p
ifk≥plogp.(37)
Then, for every subset Vi, we are estimating |x/ /V i|
with precision
ϵi=

Oq
|x/ /V i|
logp
ifk≤plogp
Oq
|x/ /V i|
k/p
ifk≥plogp.(38)
We estimate |x|as the sum of our estimates for |x/ /V i|.
If it exceeds k, we output 1, and otherwise we output 0.
The actual behaviour of the algorithm depends on how
the 1-input variables are distributed among the subsets
V1, . . . , V p. In the worst-case scenario, all the ones are
concentrated in a single bin. However, this scenario is
extremely unlikely. Raab and Steger’s “balls into bins”
theorem [ 41] states that, with probability greater than
2/3,
max
i|x/ /V i|=(
O(logp) if|x| ≤plogp
O
|x|
p
if|x| ≥plogp.(39)
Using this result, we show in Appendix A that there is a
choice for the constant factors in (37)that guarantees that
our estimate for |x|is larger than kifThreshold k(x) = 1
and smaller or equal than kif Threshold k(x) = 0.
Putting everything together, we conclude that
Q(Threshold k;D) =ON
Dlog2N
D
+√
Nklogk
.
(40)
Comparing with the upper bound that we derived with
the interpolation method (equation (34)), we see that
parallelization offers the best performance. Indeed, for
short circuit depths the complexity of the parallelization
method is smaller by a factor of k(up to logarithmic
factors).
V. SOMETIMES INTERPOLATION IS BETTER:
NAND TREES
We now apply the interpolation and parallelization tech-
niques for the problem of evaluating a balanced binary
NAND formula. This problem has been widely studied in
the literature: Farhi et al. [42] proposed a quantum walk
algorithm that runs in O 
N1/2
time with an unconven-
tional, continuous-time query model. Later, Childs et al.
[26] understood that this algorithm could be translated
into the discrete query model (as presented in Section II A)with just an O 
No(1)
overhead. Finally, Ambainis et al.
[27] presented an optimal O 
N1/2
-time algorithm on the
conventional query model. We adapt their approach to a
restricted-depth setting.
Let Φ be a Boolean function on Ninputs x1, . . . , x N
expressed with NAND gates. We treat each occurrence
of a variable separately, in that Nis counting with the
variables’ multiplicity. Equivalently, we could be con-
sidering a formula expressed in terms of the gate set
{AND ,OR,NOT}. The input is accessed via the conven-
tional query operator Oas defined in Section II A.
The formula Φ can be represented by a tree, where the
internal nodes are NAND gates acting on their children
and the leafs hold the input variables. Here we restrict
our attention to formulas that are represented by perfectly
balanced binary trees. We note that Ambainis et al. ’s
algorithm can be applied to general formulas after a proper
rebalancing of the corresponding tree [ 43,44]. Similarly,
our arguments could also be extended to the general case.
Ambainis et al. [27] prove that (after efficient classical
pre-processing) Φ( x) can be evaluated with bounded-error
probability using√
Nqueries to O. The main idea is to
build a weighted graph, whose adjacency matrix, denoted
asH, has spectrum that relates to the value of Φ( x).
Then, one simulates a discrete-time quantum walk on this
graph. By applying a phase estimation on this process
for a special starting state, one is able to infer the value
of Φ( x).
Starting on the graph construction of Ambainis et al.
[27], we present a different, QSVT-based approach to
infer the value of Φ( x), circumventing the quantum walk
and phase estimation steps. With the aforementioned
principle of trading off lower degree polynomial approxi-
mations by longer statistical sampling, we immediately
derive an interpolating algorithm for evaluating general
NAND trees.
We present a succinct definition of H, referring the
reader to the original paper [ 27] for a more detailed expla-
nation. We construct a symmetric weighted graph from
the formula’s tree, attaching to the root node (call it r)
a tail of two nodes, r′andr′′. For each node v, let sv
be the number of variables of the subformula rooted at
v. The weights on the graph are defined in the following
manner. If pis the parent of a node v, then
⟨v|H|p⟩:=sv
sp1/4
, (41)
with two exceptions:
1.ifvis a leaf reading 1, then ⟨v|H|p⟩:= 0 (effectively
removing the edge ( v, p) from the graph);
2.⟨r′|H|r′′⟩:= 1/(√
2N1/4).
The spectrum of Hhas the following properties [ 27,
Theorem 2]:
1.if Φ(x) = 0, then there is a zero-eigenvalue eigen-
state|g⟩ofH|⟨r′′|g⟩| ≥ 1/√
2;8
2.if Φ(x) = 1, then every eigenstate with support on
|r′′⟩has eigenvalue at least 1 /(18√
2N) in absolute
value.
That is, we can evaluate Φ by determining whether
|r′′⟩has a large zero-eigenvalue component. We propose
doing this within the QSVT framework.
a. Interpolation. The first step in our interpolation
approach to evaluating NAND trees is to construct a
block-encoding of H. As Hhas bounded degree and the
weights of its edges are upper bounded by 1, we can use
standard block-encoding techniques for sparse matrices
[35, 37]. Namely, for projectors
Π,˜Π =|0m⟩⟨0m|, (42)
with m=O(logN), there is a unitary UHthat block-
encodes H/3 with O(1) calls to O. By definition, the
unitary UHis such that, for an arbitrary state |ψ⟩
UH|0m⟩|ψ⟩=|0m⟩H
3|ψ⟩
+|⊥⟩, (43)
where |⊥⟩is orthogonal to |0m⟩.
We would like to distinguish between the eigenstates
ofH/3 whose eigenvalue is close to zero and those whose
eigenvalue is larger than
1
3×1
18√
2N=:δ (44)
in absolute value. We treat this as a QSVT problem,
as discussed in Section II B. Indeed, let {λi,|vi⟩}ibe an
eigenvalue decomposition of H/3 and |ψ⟩=P
iαi|vi⟩be
an arbitrary state. From Theorem 1 and Corollary 1, we
can perform the transformation
|0m⟩|ψ⟩=|0m⟩ X
iαi|vi⟩!
→|0m⟩ X
iP′
δ,η,µ(λi)αi|vi⟩!
+|⊥⟩,(45)
where P′
δ,η,µis an approximation to the window function
(as defined in Corollary 1), with O((1/δ)log(1/η)) queries
toO.
We now have all the necessary tools to solve the problem.
We start by preparing the state |r′′⟩(this does not involve
any oracle queries). We then transform |r′′⟩as in (45).
We measure the mfirst qubits (i.e., the block-encoding
register) of the resulting state, assigning an outcome “yes”
if we observe |0m⟩and an outcome “no” otherwise. From
the spectral properties of Hwe known that
P[“yes”](
≥(1−η)2
2,if Φ(x) = 0
≤η2,if Φ(x) = 1. (46)
So, we need to determine the bias of a Bernoulli dis-
tribution with precision no larger than (1 −η)/4. It iswell-known that O(1/(1−η)2) samples are sufficient (and
necessary) to achieve such a precision with bounded-error
probability. In summary, we can evaluate Φ( x) with
bounded-error probability by running O((1/δ)log(1/η))-
deep circuits O(1/(1−η)2) times, amounting to a total
of
O1
(1−η)2×1
δlog1
η
(47)
queries to O.
We have purposely left ηas a free parameter in our
algorithm. We get the best possible complexity by choos-
ingη= 1−Ω(1), in which case the algorithm’s query
complexity is (using definition (44))
O1
δ
=O√
N
, (48)
recovering the scaling of Ambainis et al. [27]. But this
choice of ηrequires running circuits of depth also in
O(√
N). Suppose now that we want to limit the circuit
depth to some maximum value D. We can run the same
algorithm, setting this time ηto be
η=O 
2−δD
. (49)
Replacing into expression (47), we find that
Q(Φ;D) =ON
D+√
N
. (50)
b. Parallelization. The problem of evaluating NAND
trees is also amenable to parallelization. The key obser-
vation is that, if for any given level of the tree we know
the logical value of all the nodes at that level, then we
can infer Φ( x) without performing any more queries to
the input. Therefore, we solve the problem if, for every
node vat that level, we run the quantum algorithm for
evaluating the NAND tree rooted at v.
Say that we want to limit our circuit depths to D.
We partition the input variables into O(N/D2) subsets
ofO(D2) variables each. To each subset of variables
corresponds a subtree of the total tree. For each such
subtree, we evaluate the logical value of the root node
with an error probability bounded by D2/N, which we
can do with O(√
D2log 
N/D2
) queries to O. Since we
repeat this for all subtrees, the hybrid query complexity
becomes
Q(Φ;D) =ON
DlogN
D
+√
N
. (51)
We find that both the interpolation and parallelization
methods can be applied for evaluating balanced binary
NAND trees. Although the resulting complexities are
close, the parallelization approach comes with an extra
log(N/D )factor. This problem illustrates that there are
also situations where interpolation is advantageous over
parallelization.9
VI. CONCLUSIONS
In this paper, we suggest two distinct approaches for
adapting a quantum algorithm to a restricted-depth set-
ting: parallelization and interpolation. An algorithm is
said to be “parallelizable” whenever we can split its action
into smaller, independent sub-problems; and “interpolat-
able” if the loss of information caused by shortening the
circuit depth can be compensated by repeated runs of the
shorter circuit. Therefore, informally, these two methods
can be understood as either “breaking up the input” (for
parallelization) or “breaking up the unitary procedure”
(for interpolation).
We argue that Quantum Singular Value Transforma-
tions (QSVT) closely relate to the notion of interpolation,
rather than parallelization. For QSVTs, a smaller cir-
cuit depth corresponds to a polynomial approximation
to a target function of lower degree, which needs to be
compensated by longer statistical sampling.
We apply these approaches to two problems with known
quantum speed-ups: the k-threshold function and per-
fectly balanced NAND trees. To the best of our knowledge,
neither of these problems had been studied in a hybrid,
restricted-depth setting. For the k-threshold function,
we show that parallelization offers the best performance
by a factor of ˜O(k) (in terms of query complexity). In
contrast, for evaluating perfectly balanced NAND trees
the interpolation method is the most efficient, differing by
a factor of O(log(N/D )). This way, we demonstrate that
no technique (parallelization or interpolation) is strictly
better than the other – each one may be the best option
depending on the problem at hand.
This shows that, when designing a quantum-classical
hybrid algorithm obeying certain (query) depth limita-
tions, both of the proposed techniques can be explored as
a strategy for maintaining some of the speedup (over a
fully classical approach) of a quantum unrestricted-depth
counterpart. Furthermore, given the close connection be-
tween (depth unrestricted) algorithms formulated in terms
of QSVTs and the interpolation method, this implies that,
when searching for hybrid quantum-classical algorithms
for a particular problem, it may be a good option to startby formulating a (depth unrestricted) QSVT algorithm
for the problem, and then seeking to interpolate it.
We note that we only offered an example of a problem
(perfectly balanced NAND trees) where the interpolation
beats parallelization by a logarithmic factor. It would be
interesting to find a problem for which the interpolation
procedure is polynomially more efficient than the corre-
sponding parallelization, to rule out the possibility that
parallelization, whenever applicable, is always optimal up
to logarithmic factors. We leave the existence of such a
problem as an open question.
The definitions we have provided for the terms “paral-
lelization” and “interpolation” are not strictly rigorous;
they should be seen as general strategies for restricted-
depth computing, rather than formal notions. This does
not preclude that in some situations the two strategies
may be simultaneously at play, or that these classifica-
tions may not apply. As such, we expect there is room
for discussion on what other classes of methods may exist
besides the ones discussed here, and for other systematic
approaches to hybridization.
ACKNOWLEDGMENTS
We thank R. de Wolf for his comments on quan-
tum query lower bounds for the problem of quantum
counting, in the context of calculating the threshold func-
tion, and N. Stamatopoulos for his comments regarding
the proof of the parallelization method for the thresh-
old function. We also thank the support from FCT
– Funda¸ c˜ ao para a Ciˆ encia e a Tecnologia (Portugal),
namely through project UIDB/04540/2020, as well as
from projects QuantHEP and HQCC supported by the
EU QuantERA ERA-NET Cofund in Quantum Tech-
nologies and by FCT (QuantERA/0001/2019 and Quan-
tERA/004/2021, respectively), and from the EU Horizon
Europe Quantum Flagship project EuRyQa (101070144).
DM and MM acknowledge the support from FCT through
scholarships 2020.04677.BD and 2021.05528.BD, respec-
tively.
[1]K. Bharti, A. Cervera-Lierta, T. H. Kyaw, T. Haug,
S. Alperin-Lea, A. Anand, M. Degroote, H. Heimonen,
J. S. Kottmann, T. Menke, W.-K. Mok, S. Sim, L.-C.
Kwek, and A. Aspuru-Guzik, Noisy intermediate-scale
quantum algorithms, Reviews of Modern Physics 94,
10.1103/revmodphys.94.015004 (2022).
[2]E. Farhi, J. Goldstone, and S. Gutmann, A quantum
approximate optimization algorithm, arXiv:1411.4028
[quant-ph] (2014).
[3]A. Peruzzo, J. McClean, P. Shadbolt, M. H. Yung,
X. Q. Zhou, P. J. Love, A. Aspuru-Guzik, and J. L.
O’Brien, A variational eigenvalue solver on a photonic
quantum processor, Nature Communications 2014 5:1 5,10.1038/ncomms5213 (2014).
[4]J. R. McClean, J. Romero, R. Babbush, and A. Aspuru-
Guzik, The theory of variational hybrid quantum-classical
algorithms, New Journal of Physics 18, 023023 (2016).
[5]D. Wecker, M. B. Hastings, and M. Troyer, Progress
towards practical quantum variational algorithms, Phys.
Rev. A 92, 042303 (2015).
[6]A. Kandala, A. Mezzacapo, K. Temme, M. Takita,
M. Brink, J. M. Chow, and J. M. Gambetta, Hardware-
efficient variational quantum eigensolver for small
molecules and quantum magnets, Nature 549, 242 (2017).
[7]E. Farhi and H. Neven, Classification with quantum neu-
ral networks on near term processors, arXiv:1802.0600210
[quant-ph] (2018).
[8]M. Benedetti, E. Lloyd, S. Sack, and M. Fiorentini, Pa-
rameterized quantum circuits as machine learning models,
Quantum Science and Technology 4, 043001 (2019).
[9]S. Y.-C. Chen, C.-H. H. Yang, J. Qi, P.-Y. Chen, X. Ma,
and H.-S. Goan, Variational quantum circuits for deep
reinforcement learning, IEEE Access 8, 141007 (2020).
[10]L. Banchi, Robust quantum classifiers via NISQ adversar-
ial learning, Nature Computational Science 2, 699 (2022).
[11]L. Buffoni and F. Caruso, New trends in quantum machine
learning, Europhysics Letters 132, 60004 (2020).
[12]J. R. McClean, S. Boixo, V. N. Smelyanskiy, R. Bab-
bush, and H. Neven, Barren plateaus in quantum neural
network training landscapes, Nature Communications 9,
10.1038/s41467-018-07090-4 (2018).
[13]E. R. Anschuetz and B. T. Kiani, Quantum variational
algorithms are swamped with traps, Nature Communica-
tions 13, 10.1038/s41467-022-35364-5 (2022).
[14]X. Sun and Y. Zheng, Hybrid decision trees: Longer
quantum time is strictly more powerful, arXiv:1911.13091
[cs.CC] (2019).
[15]S. Aaronson and A. Ambainis, Forrelation: A problem
that optimally separates quantum from classical comput-
ing, SIAM Journal on Computing 47, 982 (2018).
[16]D. Wang, O. Higgott, and S. Brierley, Accelerated varia-
tional quantum eigensolver, Physical Review Letters 122,
10.1103/physrevlett.122.140504 (2019).
[17]A. P´ erez-Salinas, R. Draˇ ski´ c, J. Tura, and V. Dun-
jko, Reduce&chop: Shallow circuits for deeper problems,
arXiv:2212.11862 [quant-ph] (2022).
[18]C. Zalka, Grover’s quantum searching algorithm is opti-
mal, Physical Review A 60, 2746 (1999).
[19]L. K. Grover and J. Radhakrishnan, Quantum search
for multiple items using parallel queries, arXiv:0407217
[quant-ph] (2004).
[20]S. Jeffery, F. Magniez, and R. Wolf, Optimal parallel
quantum query algorithms, Algorithmica 79, 509 (2017).
[21]G. Wang, D. E. Koh, P. D. Johnson, and Y. Cao, Mini-
mizing estimation runtime on noisy quantum computers,
PRX Quantum 2, 10.1103/prxquantum.2.010346 (2021).
[22]T. Giurgica-Tiron, I. Kerenidis, F. Labib, A. Prakash, and
W. Zeng, Low depth algorithms for quantum amplitude
estimation, Quantum 6, 745 (2022).
[23]D. Magano and M. Mur¸ ca, Simplifying a classical-
quantum algorithm interpolation with quantum sin-
gular value transformations, Physical Review A 106,
10.1103/physreva.106.062419 (2022).
[24]A. Gily´ en, Y. Su, G. H. Low, and N. Wiebe, Quantum
singular value transformation and beyond: exponential
improvements for quantum matrix arithmetics, in Pro-
ceedings of the 51st Annual ACM SIGACT Symposium
on Theory of Computing (ACM, 2019).
[25]R. Beals, H. Buhrman, R. Cleve, M. Mosca, and
R. de Wolf, Quantum lower bounds by polynomials, Jour-
nal of the ACM 48, 778 (2001).
[26]A. M. Childs, R. Cleve, S. P. Jordan, and D. Yonge-Mallo,
Discrete-query quantum algorithm for nand trees, Theory
of Computing 5, 119 (2009).
[27]A. Ambainis, A. M. Childs, B. W. Reichardt, R. ˇSpalek,
and S. Zhang, Any AND-OR formula of size N can be
evaluated in time N1/2+o(1)on a quantum computer,
SIAM Journal on Computing 39, 2513 (2010).
[28]A. Ambainis, Understanding algorithms via query com-
plexity, in Proceedings of the International Congress ofMathematicians (ICM 2018) (World Scientific, 2019) pp.
3265–3285, available as arXiv:1712.06349 [quant-ph].
[29]H. Buhrman and R. de Wolf, Complexity measures and
decision tree complexity: a survey, Theoretical Computer
Science 288, 21 (2002), complexity and Logic.
[30]L. Grover, Quantum mechanics helps in searching for a
needle in a haystack, Phys. Rev. Lett. 79, 325 (1997).
[31]P. Shor, Algorithms for quantum computation: discrete
logarithms and factoring, in Proceedings 35th Annual
Symposium on Foundations of Computer Science (IEEE
Comput. Soc. Press, 1994).
[32]A. Ambainis, Quantum walk algorithm for element dis-
tinctness, SIAM Journal on Computing 37, 210 (2007).
[33]A. Ambainis, Quantum lower bounds by quantum argu-
ments, Journal of Computer and System Sciences 64, 750
(2002).
[34]J. M. Martyn, Z. M. Rossi, A. K. Tan, and I. L. Chuang,
Grand unification of quantum algorithms, PRX Quantum
2, 10.1103/prxquantum.2.040203 (2021).
[35]L. Lin, Lecture notes on quantum algorithms for scientific
computation, arXiv:2201.08309 [quant-ph] (2022).
[36]G. H. Low and I. L. Chuang, Hamiltonian simulation by
qubitization, Quantum 3, 163 (2019).
[37]S. Chakraborty, A. Gily´ en, and S. Jeffery, The power of
block-encoded matrix powers: improved regression tech-
niques via faster hamiltonian simulation, in International
Colloquium on Automata, Languages and Programming
(2018).
[38]By Π-controlled-NOT we mean an operation that acts
as a NOT gate controlled on a given state being in the
image of Π /˜Π.
[39]G. H. Low, Quantum signal processing by single-qubit
dynamics , Ph.D. thesis, Massachusetts Institute of Tech-
nology (2017).
[40]G. Brassard, P. Høyer, M. Mosca, and A. Tapp, Quan-
tum amplitude amplification and estimation, Quantum
Computation and Information 305, 53 (2002).
[41]M. Raab and A. Steger, “balls into bins” — a simple and
tight analysis, in Randomization and Approximation Tech-
niques in Computer Science , edited by M. Luby, J. D. P.
Rolim, and M. Serna (Springer Berlin Heidelberg, Berlin,
Heidelberg, 1998) pp. 159–170.
[42]E. Farhi, J. Goldstone, and S. Gutmann, A quantum algo-
rithm for the hamiltonian nand tree, Theory of Computing
4, 169 (2008).
[43]N. H. Bshouty, R. Cleve, and W. Eberly, Size-depth trade-
offs for algebraic formulas, SIAM Journal on Computing
24, 682 (1995).
[44]M. L. Bonet and S. R. Buss, Size-depth tradeoffs for
boolean formulae, Information Processing Letters 49, 151
(1994).
[45]G. H. Low and I. L. Chuang, Hamiltonian simulation by
uniform spectral amplification, arXiv:1707.05391 [quant-
ph] (2017).11
Appendix A: Threshold function – proof of
parallelization method
From Brassard et al. [40], there is a constant csuch
that the error for our estimate of |x/ /V i|is bounded as
ϵi< cp
N|x/ /V i|/p
D. (A1)
We analyse separately the cases where Threshold k(x) =
0 and Threshold k(x) = 1.
IfThreshold k(x) = 0, the following possible relations
between p,k, and|x|need to be considered.
1.plogp≤ |x| ≤k. From the result of Raab and Ste-
ger (equation (39)), we know that |x/ /V i|=O(|x|/p)
for all i. So, by our expression for the error (38),
we see that ϵi=O(p
|x|/k) =O(1).
2.|x| ≤plogp≤k. Now we know that |x/ /V i|=
O(logp). So, for all i,ϵi=O(p
plogp/k) =O(1).
3.|x| ≤ k≤plogp. Equation (39) ensures that
|x/ /V i|=O(logp). From the expression for the
error, we see that ϵi=O(p
logp/logp) =O(1).
That is, there is a choice of constants that guarantees
thatϵi<1/2 for all iwith bounded probability. In that
case, we estimate each |x/ /V i|exactly, and so we exactly
infer|x|and consequently the value of Threshold k(x).
IfThreshold k(x) = 1, the proof is slightly different.
Again, we consider three scenarios.
1.plogp≤k≤ |x|. Equation (39) tells us that
|x/ /V i|=O(|x|/p). Combining with (38) we see
that there is a (controllable) constant Cfor which
ϵi< Cr
|x|
k(A2)
for all |x|, k. Unlike before, we cannot guarantee
that ϵiis kept below 1 /2 for all |x|. But we can
make sure that our estimate for the Hamming weight
is always greater than k. Let Xjbe the random
variables corresponding to the estimations of each
|x/ /V j|, and σ2
jthe corresponding variances. From
the Chebyshev bound,
PrX
jXj− |x|>|x| −k
<P
jσj
|x| −k2
<
<C′pp
|x|/k
|x| −k2
(A3)
for some constant C′. Thus we can attain with
constant probability an estimation of |x|with error
within |x|−kif there exists a constant C′such that
there exists a value |x|∗satisfying:•If|x|<|x|∗, the error in the estimation of each
|x/ /V j|is less than 1 /2, such that the estimate
of|x|is exact,
•If|x|>|x|∗, then C′p
|x|/k < (|x| −k)/p,
bounding the error probability to be constant.
Choosing |x|∗=k+plogp, one can check that
C= 1/4(C′) satisfies the conditions above.
2.k≤plogp≤ |x|. Again, for all i,|x/ /V i|=O(|x|/p).
Combining this with the expression for the error
(38), we get ϵi=O(|x|/plogp). The proof follows
the same steps as the “ plogp≤k≤ |x|” case.
3.k≤ |x| ≤plogp. From equation (39) we known
that|x/ /V i|=O(logp) for all i. Then, ϵi=
O(p
logp/logp) =O(1). So, in this case we can
also ensure that we estimateP
i|x/ /V i|exactly.
Appendix B: Total Non-Constant Symmetric Boolean
Functions
We have shown, before, how to interpolate the k-
threshold function based on Quantum Singular Value
Transformations. A similar interpolation scheme to the
one we have shown can actually be applied to the cal-
culation of any symmetric boolean function, as we now
show. Furthermore, we show that a similar difference
exists between the scaling for this interpolation and the
scaling for a parallelization procedure.
We start by reviewing an intermediate claim of Beals
et al. [25]:
Lemma 1. (Part of Theorem 4.10 of Beals et al. [ 25])
For a symmetric boolean function f, if given an algorithm
that outputs |X|if|X|<(N−Γ(f))/2or outputs “in”
otherwise, with Qqueries to the oracle, immediately there
is an algorithm that computes fwith Qqueries to the
oracle.
Proof. LetAbe an algorithm as outlined in the lemma,
requiring Qqueries to the oracle. By definition of Γ( f),
fis constant for Xsuch that |X| ∈[(N−Γ(f))/2,(N+
Γ(f))/2]. Therefore, let A′be an algorithm that runs A,
and then:
•IfAoutputs “in”, A′outputs f((N−Γ(f))/2),
•IfAoutputs |X|,A′outputs f(|X|).
A′requires only as many queries as A.
Now, departing from Beals et al. ’s proof, we rephrase
the construction of an algorithm matching the descrip-
tion of lemma 1 in terms of Quantum Singular Value
Transformations.
We start with the following lemma of Low and Chuang
[45]:12
Lemma 2. [45] For a given k∈R,δ∈[−1,1]and
ϵ∈(0,O(1)), there exists a real polynomial p(x)satisfying
|p(x)| ≤1, x∈[−1,1],and
|p(x)−(k(x−δ))| ≤ϵ , x∈[−1,1].
with polynomial degree
deg(p) =O s
log1
ϵ
k2+ log1
ϵ!
.(B1)
From this lemma follows the already mentioned con-
struction for a polynomial approximation to the threshold
function, which we restate:
Corollary 2. [45] For a given δ∈[−1,1],ϵ∈(0,O(1)),
η∈(0,1/4), there exists a real polynomial psatisfying
|p(x)| ≤1, x∈[−1,1]
|p(x)−1| ≤η , x∈[−1, δ−ϵ],
|p(x)| ≤η , x∈[δ+ϵ,1],
and with polynomial degree
deg(p) =O1
ϵlog1
η
.
To make use of these polynomial transformations, we
also recall the block encoding of the quantities of interest,
which are the same as for the k-threshold case; for unitary
U=n/H⊗
OX
X
and Π = |0n+1⟩⟨0n+1|, we have that ( I2n⊗|1⟩⟨1|)UΠ is
a block encoding ofp
|X|/N, and ( I2n⊗|0⟩⟨0|)UΠ is a
block encoding ofp
(N− |X|)/N.
Now we first determine if the Hamming weight of the
input should produce output “in” or not, which is, essen-
tially, the task of calculating the k-threshold function with
k= (N−Γ(f))/2 and with k′= (N+ Γ(f))/2. As stated
in the body text, the case of threshold k′can be reduced
to the case of threshold kcalculated for the complement of
the Hamming weight N−|X|, and so we conclude that this
step requires O(2p
N(N−Γ(f))) =O(p
N(N−Γ(f)))
applications of the oracle.
In the event that we find |X|to be smaller than ( N−
Γ(f))/2, or larger than ( N+Γ(f))/2, it remains to output
the Hamming weight of X, or of X, respectively. We
consider henceforth the case of |X|<(N−Γ(f))/2, from
which generalization is easy.
Note first that performing bisections on |X|for|X| ∈
[0,(N−Γ(f))/2] corresponds to performing successive
threshold operations for thresholds k′<(N−Γ(f))/2,
so, by binary search, we have that we may find |X|with
O[p
N(N−Γ(f)) log2(N−Γ(f))] applications of the or-
acle, where one of the logfactors is due to the binary
search, and the other to error probability bounding. How-
ever, by making direct use of lemma 2, the logfactors can
be significantly lowered. Consider the following lemma:Lemma 3. Given the block encoding of a value z∈
[a, b]⊆[−1,1], it is possible to determine [a′, b′]⊆[a, b]
such that z∈[a′, b′], and (b′−a′)≤(b−a)/2, with
Dround =O1
b−a
(B2)
coherent applications of the oracle, and
Tround =O1
b−alog1
E
(B3)
total applications of the oracle, with probability of error
at most E.
Proof. Fixη∈O(1), for example, η= 1/8. Using QSVT,
create a block encoding of P(z), where Pis the polynomial
approximating ( k(x−δ)) up to absolute error ϵ(to be
determined), with k=2
b−aerf-1(1−2η) and µ= (b−a)/2.
For a choice of σ, after O(log(1/E)/σ2) samples of this
encoding, one obtains an estimate for ( k(z−µ))2up to
precision σ+ϵ2with error probability E; denote this
estimate ˜p. This estimate implies a new window [ a′, b′]
forzsatisfying
b′−a′≤1
k 
erf-1(2p
˜p−1 + 2( σ+ϵ))−
erf-1(2p
˜p−1−2(σ+ϵ))
(B4)
which in turn satisfies, with our choice of k,
b′−a′
b−a≤2
erf-1(1−2η)(σ+ϵ)×
×max
y∈[−2,2](erf-1)′(2p
˜p−1 +y(σ+ϵ)).(B5)
Demanding that
σ+ϵ!
≤η/4, (B6)
we have
b′−a′
b−a≤η
4√π
erf-1(1−2η)e(erf-1(1−η))2(B7)
which, for η= 1/8, has a right-hand side of less than one
half.
Since η∈ O(1), we may choose σ∈ O(1) and ϵ∈ O(1)
satisfying the constraint (B6), and thus follows that this
procedure requires
Mround =O1
σ2log1
E
=O
log1
E
(B8)
measurements of a circuit encoding a polynomial trans-
formation of degree (cf. equation (B1))
Dround =O(k) =O1
b−a
(B9)13
or, equivalently, the same number of coherent queries.
The total number of queries is therefore
Tround =Dround·Mround =OlogE−1
b−a
(B10)
as claimed.
By repeating the procedure given in the lemma above,
we may reduce the window forp
|X|/Nuntil this value
is unambiguous. This requires a final window of size
∆ =1
2(p
N−Γ(f)−p
N−Γ(f)−1), which in turn
requires log(p
N−Γ(f)/∆) = O[log{√
N(N−Γ(f))}]
rounds of application of the lemma.
Since we wish any of these rounds to fail with probabil-
ity at most 1 /3, this requires that each round fails with
probability at most 1 /(3 log[√
N(N−Γ(f))]).
Therefore, overall, this procedure requires
D=Op
N(N−Γ(f))
(B11)
maximum coherent oracle calls, and a total number of
oracle calls
T=Op
N−Γ(f) log log[√
N(N−Γ(f))]
.(B12)
Performing the interpolation now is straightforward:
instead of demanding the procedure from lemma 3 be
repeated until the window is so small that the Hamming
weight of Xis unambiguous, we instead choose a final
window size ∆′that respects the given coherent query
limit. After this limit has been reached, we “switch” to
statistical sampling until the final window size for the
value ofp
|X|/Nis ∆. This procedure therefore is split
into two steps; following an analysis analogous to the one
for the unbound case, we conclude that for some choice
of ∆′, the first phase requires maximum coherent querydepth
Dfirst=O1
∆′
(B13)
and total query count
Tfirst=OlogE−1
∆′
. (B14)
Using the fact that ( erf-1)′(x)≥√π/2, one may then
conclude that and the second phase requires corresponding
Dsecond =O 
1
∆′s
log
C∆′
∆!
(B15)
Tsecond =O 
∆′
∆2s
log
C∆′
∆
logE−1!
(B16)
where, again, Eis the error probability, and Cis a con-
stant in O(1).
Choosing this intermediate window size ∆′to be ∆1−α,
forα∈[0,1], we recover complexities analogous to those
verified for α-Quantum Phase Estimation [22, 23]:
D(α) =Dfirst+Dsecond =
=O
∆α−1p
log(C∆−α)
(B17)
T(α) =Tfirst+Tsecond =
=O
∆−(1+α)p
log(C∆−α) logE−1
(B18)
Using again the fact that ∆−1=O(p
N(N−Γ(f))),
and with considerations as to the error probability identi-
cal to before, we finally have
D(α) =˜O
[N(N−Γ(f))](1−α)/2
(B19)
T(α) =˜O
[N(N−Γ(f))](1+α)/2
. (B20)