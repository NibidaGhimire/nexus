Revealing the Hidden Effects of Phishing Emails:
An Analysis of Eye and Mouse Movements in Email Sorting Tasks
Yasmeen Abdrabou,1,2, Felix Dietz2, Ahmed Shams3, Pascal Knierim4,
Yomna Abdelrahman5, Ken Pfeuffer6, Mariam Hassib2,7, Florian Alt2
1Lancaster University, United Kingdom, y.abdrabou@lancaster.ac.uk
2University of the Bundeswehr, Germany
3Fatura LLC, Egypt,4University of Innsbruck, Austria,
5European Universities in Egypt,6Aahrus University, Denmark
7fortiss, Research Institute of the Free State of Bavaria, Germany
Abstract
Users are the last line of defense as phishing emails pass filter
mechanisms. At the same time, phishing emails are designed
so that they are challenging to identify by users. To this end,
attackers employ techniques, such as eliciting stress, target-
ing helpfulness, or exercising authority, due to which users
often miss being manipulated out of malicious intent. This
work builds on the assumption that manipulation techniques,
even if going unnoticed by users, still lead to changes in their
behavior. In this work, we present the outcomes of an online
study in which we collected gaze and mouse movement data
during an email sorting task. Our findings show that phishing
emails lead to significant differences across behavioral fea-
tures but depend on the nature of the email. We discuss how
our findings can be leveraged to build security mechanisms
protecting users and companies from phishing.
1 Introduction
Emails are still one of the most popular communication media,
and the number of emails is constantly increasing1. At the
same time, also the number of phishing emails is increasing,
reaching an annual rate of 65% of all emails sent in 2019. In
the same year, 76% of companies reported already having
been victims of phishing attacks2, making phishing emails
one of the most popular attack vectors of cyber attacks [57].
Phishing is a form of social engineering where impostors
manipulate users with the ultimate goal of getting access to
an account, network (identity theft), or payment information
(online fraud), as well as for extorting money from victims
(e.g., ransomware) [17, 49]. The aforementioned goals are
usually achieved by making users perform actions, such as
opening malicious attachments, providing sensitive informa-
tion (e.g., credentials) on a fake website linked from within
the email, or directly responding with sensitive information.
1https://www.statista.com/statistics/456500/
daily-number-of-e-mails-worldwide/
2Phishing Statistics: https://retruster.com/blog/
2019-phishing-and-email-fraud-statistics.html
Figure 1: We observe and analyze users’ eye and mouse move-
ment behavior during an online email sorting task. Our results
show differences in behavior as users are exposed to phishing
emails as opposed to benign emails.
To mitigate such attacks, organizations spend billions of
dollars per year on employing technical defenses (for exam-
ple, email filters) and on training users not to fall for such
attacks3. However, both approaches do not provide sustain-
able protection, as awareness raised through training wears
off over time [45] and attackers constantly develop new at-
tacks. In this work, we investigate how humans can serve as a
proxy to detect phishing emails. Typically, phishing emails
employ techniques well-known from psychology, for exam-
ple, eliciting fear or stress [3]. Hereby, the attacker triggers
state changes in the victim through their pretext. For example,
a victim might be threatened to lose access to their online
banking account if they do not change their password within a
few hours, thus creating a state of stress. Our idea is to assess
users’ behavior indicative of this state change. For example,
as the stress level of a user increases while working on emails,
this is likely to cause measurable changes in mouse move-
3Global Spending on Security: https://www.linkedin.com/pulse/
global-spending-security-awareness-training-employees-steve-morgan/
1arXiv:2305.17044v1  [cs.HC]  26 May 2023ments, keystroke dynamics, and eye movements, allowing an
attack to be identified instantly. The sketched approach be-
comes possible through the increasing prevalence of wearable
devices and personal computers capable of capturing user
behavior and physiological data.
We demonstrate that exposure to phishing emails leads to
measurable changes in user behavior. We focus on email sort-
ing, that is reading, and moving emails to appropriate folders,
as a use case. This task allows us to assess user behavior
from mouse and eye movements. To capture users’ unbiased,
unconscious behaviors, we developed a remote role-playing
study ( N=39), mimicking a typical email sorting task while
recording users’ mouse and eye movements. We then ana-
lyzed users’ mouse and eye behavior, looking for features that
indicate whether users fall for phishing emails.
Our results show that users’ mouse and gaze behavior can
be indicative of the type of email they are reading. However,
the nature of the email plays a vital role. For example, impor-
tant emails lead to more noticeable changes in mouse behav-
ior, whereas emails considered neutral or advertisements lead
to changes in gaze behavior. We discuss how future research
can use our findings to enhance email security.
Contribution Statement. We make the following contribu-
tions: (1) designing and implementing an email client capable
of collecting behavioral data (gaze/mouse movements); (2)
conducting a remote role-playing study in which we collected
behavioral data based on mouse activity and gaze movements
while reading different types of emails on our developed web
client; (3) an analysis of the data, identifying gaze and mouse
movement features influenced during the exposure to phishing
emails; and (4) a discussion on how future security concepts
can leverage behavioral data to mitigate phishing attacks.
2 Background and Related Work
We review prior work on (1) phishing attacks, user suscep-
tibility, and mitigation strategies, and (2) users’ interaction
behavior (gaze/mouse) while using computing systems.
2.1 Phishing Attacks
Phishing is a particular form of a social engineering attack.
Most commonly, adversaries use phishing emails to lure vic-
tims into clicking on malicious links in emails, to visit web
pages asking for personal, sensitive information, or into open-
ing attachments as a result of which malicious software is
executed on users’ computers [37].
Attackers use various strategies, such as conveying urgency
or pressure [55], target greed, and leverage users’ helpful-
ness [18]. Phishing attacks are so popular because they can
be conducted at low costs, and attackers are rarely discov-
ered [10]. As a result, individuals, organizations, and even
governments incur substantial financial loss.Generally, there are two different angles from which phish-
ing attacks have been investigated: a user-centric perspective
with the goal of better understanding why and who falls for
phishing attacks, and a more technology-centric perspective
to design means of protection against phishing attacks [15].
2.1.1 Understanding Phishing Attacks
Security experts analyzed and identified factors making users
vulnerable to phishing [5, 16, 50]. From a users’ perspective ,
researchers looked at the different traits and demographics of
users who fall for phishing [35,41,50]. Sheng et al. found that
age, demographics, and education are indicators of phishing
susceptibility [50]. More recently, Lin et al. focused on the
susceptibility of Internet users to spear phishing , which is
phishing targeted at particular users. They found that besides
age and gender, email content also increased the probability
that users fall for a phishing attempt [37]. Personality traits,
such as risk-taking, also increase users’ susceptibility to phish-
ing attacks [50]. Albakry et al. conducted an online survey
on user understanding of URLs from hovered links in emails.
They found that participants who reported higher technology
affinity are only marginally more aware of phishing links than
others [2]. One reason may be that psychological tools of
influence that work in real life often also work in phishing.
Caldini has listed seven of these influencing principles: Au-
thority (strength conveys trust), Consistency (familiar email
interfaces suggest normality), Unity (same interests foster em-
pathy), Reciprocity (user acts as desired via click or download
and receives a promised reward in the form of information),
Scarcity (unavailability or difficult accessibility encourages
desire), Consensus (others already having done something
entices users to do the same), and Like (wanting to please,
disregards caution) [12].
2.1.2 Mitigating Phishing Attacks
From a technology perspective , researchers looked into how
phishing attacks can be mitigated through automatic filtering
of emails / malicious content, which are successful but not
foolproof and often produce false positives [4, 43].
Regarding interventions , researchers investigated the effec-
tiveness of security bars in web browsers to reduce the number
of successful phishing attacks [56]. Researchers also studied
the effectiveness of phishing warnings in web browsers [19]
and tried to enhance them through browser add-ons [22] and
highlighting the domain name in the address bar [36]. More-
over, a recent study proposed simplifying expert tools and
providing non-expert users with a form of a report, judg-
ing the safety of URLs based on information professionals
use [6]. Other work tried three warning mechanisms to alert
the users: (1) putting the warning close to the phishing link,
(2) displaying a warning while hovering over a link, and (3)
directing attention to the warning by deactivating the original
2link and embedding it in the warning [43]. Deactivating the
link worked best, followed by putting the warning nearby the
link and displaying the alert while hovering. In 2015, Mar-
forio et al. showed that using personalized security indicators,
participants chose themselves significantly enhanced users’
ability to detect phishing attacks [39].
Researchers also looked into enhancing training effective-
ness to support users in recognizing suspicious content [33].
One approach that received considerable attention is gamifi-
cation. For example, Sheng et al. created Anti-Phishing Phil ,
a game teaching employees in an organization to avoid phish-
ing [51]. Kumaraguru et al. created PhishGuru , an in-situ
training system for identifying email phishing [34]. More
recently, Wen et al. created What.Hack. , a role-playing game
aimed at teaching users phishing concepts, showed its success
more than traditional training [55]. However, user training
also suffers from drawbacks. In a recent study, Lain et al.
found that employees’ resilience to phishing attacks did not
increase when they took part in embedded training after sim-
ulated phishing attacks [35]. In addition, the effect of user
training has been shown to wear off over time [9].
2.1.3 Summary
The challenge of mitigating phishing attacks has been ap-
proached from differing perspectives. Yet, the need for new
solutions is undisputed. The most successful techniques are
personalized solutions to combat phishing (e.g. [17, 39]). It is
necessary to know users’ behavior and personal characteris-
tics. Just as attackers leverage psychological patterns to influ-
ence users, knowledge can similarly be used to defend against
or detect attacks. The more we understand users’ behaviors
and personality traits that make them susceptible to phishing,
the better we can help create successful solutions [41, 50].
2.2 Mouse and Eye Movement Behavior
The concept we investigate in this work is based on the hypoth-
esis that phishing attacks lead to unconscious changes in user
behavior. Eye gaze behaviors and mouse movements while
reading emails are particularly interesting in this context. Eye
tracking will become widely available in the following years
as an increasing number of laptops and monitors are equipped
with eye trackers or gaze estimation methods that rely on a
webcam [29]. These are also becoming robust enough to ob-
tain high-quality gaze data. As a result, the following section
provides an overview of work examining what can be learned
from mouse and eye movement behavior.
Prior studies looked into the relationship of eye gaze and
mouse movements during particular tasks [46]. Rodden et
al. [46] and Chen et al. [11] both showed that mouse move-
ments and gaze correlate while browsing websites. The mouse
may follow the eye gaze vertically or horizontally [46]. Other
research showed eye-mouse movements to indicate visual at-tention [40]. Research conducted by Huang et al. showed that
mouse position is 700 ms delayed after gaze movements [24].
They also analyzed diversity of mouse movement patterns
unique to reading tasks where the mouse follows the fixated
text, inactive states, actions such as clicking and scrolling with
high gaze/mouse correlation, and examining web content.
Eye movement behavior is especially promising in cyber-
security [23, 29]. In addition, Majaranta and Bulling showed
that it is possible to identify user activity from gaze move-
ments [38]. Moreover, users’ eye gaze behavior can reveal
their current task [26]. Iqbal and Bailey demonstrated that
it is possible to differentiate between reading, mathematical
reasoning, searching, and object manipulation by organizing
an email inbox. Clark et al. [13] showed that it is possible to
differentiate between email genres by tracking users’ gaze
behavior. They also highlighted that text format and layout are
essential in human text categorization. Finally, Rayner shows
that users’ eye movements vary during cognitive tasks such
as reading music notes, typing, visual search, and scene per-
ception [44]. From this, we learn that different, unconscious
users’ behavior is reflected in their eye gaze, such as cognitive
workload, task, and user activity. In addition, it is promising
in the field of cybersecurity.
Mouse movements have been used as an indicator of cogni-
tive load [48]. Hehman et al. provide several different ways of
using mouse movements to measure cognitive processes [21].
Koop et al. showed that mouse movements could also be
used to understand users’ on-screen decisions and peripheral
choice [32]. Moreover, several papers showed that mouse
movement analysis is an excellent indicator of understanding
users’ risky online behavior. For example, Kelley and Berten-
thal [30] analyzed participants’ mouse trajectories to assess
participants’ decisions of logging in or backing out of some
websites. They showed that mouse trajectories differed if the
domain names were correct or spoofed. Iuga et al. compared
using mouse and eye movements heat maps as indicators to
explore if users will fall for phishing websites, identifying
65% of cases. Moreover, they report that the lack of mouse
and eye data on the areas of interest can indicate falling for
phishing [27]. In addition to the previous study, a recent study
by Yu et al. provided empirical evidence that slower mouse
behavior when reading phishing emails can be a valid indi-
cator for phishing awareness [57]. Finally, a recent study by
Abdrabou et al. [1] showed the possibility of detecting ex-
posure to fake news on Facebook by analyzing users’ gaze
and mouse movements. The authors asked participants to go
through their home page on an imitated Facebook website
and tracked their eye gaze and mouse.
From previous research and the rising prevalence and ubiq-
uity of personal sensing techniques, it is clear that mouse
movements and eye gaze present an opportunity to assess be-
havior during online tasks. We utilize these two sensing tech-
niques to obtain information about users’ behavior and phys-
iological state as a security awareness indicator. We chose
3to analyze users’ eye gaze and mouse movement behavior
during sorting emails, as emails have clear and defined areas
of interest and remain the largest source of phishing attacks
today. Users’ behavior while exposed to phishing emails is
likely different from exposure to legitimate emails.
3 Research Approach
3.1 Research Question
Our work is guided by the following research question: How
does exposure to a phishing email influence users’ mouse
movement and gaze behavior during an email sorting task?
Several aspects of this question are of interest to our work.
First, prior work showed a close relationship between users’
eye movements and what they do with their hands (eye-hand
coordination) [28, 40, 46]. Thus, we consider investigating
the interplay in an email sorting task interesting. Second, we
assume that users’ behavior might concurrently be influenced
by the techniques employed by phishing emails (e.g., eliciting
stress) and the actual task (e.g., leading to an increase in
cognitive load). To understand this mutual influence, we will
investigate behavior changes for different types of email.
3.2 Study Design Considerations
Our work was guided by a number of design considerations,
which we briefly reflect upon.
3.2.1 Use Case: Email Sorting
We are particularly interested in so-called sorting tasks ; peo-
ple read their emails to identify those needing immediate at-
tention and those less important. This task is often performed
at the beginning of a working day or week. Opposed to this
are situations where people work on emails in a focused man-
ner, including writing responses to emails and/or working
on tasks that relate to the email. Such situations are much
more heterogeneous and, thus, much more difficult to assess.
Hence, we decided to leave them for future research.
3.2.2 Scenario and Tasks
One objective was not to make users aware that the study was
about phishing emails, as prior research showed such prim-
ing to improve participant performance [42]. To address this,
previous work suggested using role playing [17] or deception-
based scenarios [43]. We opted for the former approach. In
particular, participants were asked to play the role of a per-
sonal assistant, responsible for pre-classifying emails in the
inbox of their boss. Similar role-playing scenarios were suc-
cessfully used in prior phishing studies [17]. In the following,
we will refer to this task as the sorting task ortask 1 .
Users were shown the following scenario:You are working as a personal assistant in a start-up
called Global-Connect . Your task is to go through
your boss’s custom emails as your first task in the
morning. Your boss is out-of-office on holiday for
the week. Please go through all the emails in the
inbox and move them to the correct folder.
To verify whether participants identified emails as phishing,
they were asked to look at all emails again and classify them
asphishing ornon-phishing . We will refer to this task as the
validation task ortask 2 .
3.2.3 Types of Emails
As previously mentioned, we were interested in how the type
of email influences people’s behavior. To this end, we in-
cluded three types of emails in the study: urgent emails, neu-
tral emails, and advertising videos. Each of these types of
emails could either be legitimate or phishing.
For the purpose of the study, we asked participants to sort
emails into one of four folders:
Important Folder for emails that should be responded to
later on with high priority.
Normal Folder for less important emails that should be dealt
with once having taken care of the important emails.
Spam Many companies provide a dedicated spam folder.
Emails moved to this folder are used to enhance filters.
Bin Folder for non-important emails.
3.2.4 Online Study
We chose to conduct the study online, that is people could
participate remotely from their own desktop or laptop. This
allowed a more diverse sample to be reached and users to
perform the task in a less artificial setting than a lab. The
only requirements were to have a desktop or laptop equipped
with a webcam and the Firefox or Google Chrome browser
installed as well as a stable Internet connection.
3.3 Limitations
We opted for a remote role-playing experiment to increase
ecological validity and study user behavior in a natural con-
dition. However, this came with challenges as we did not
control whether participants were interrupted by others dur-
ing the study or provided entirely correct information on their
demographics. These challenges do come with any real-world
research. Yet, we believe the benefits of conducting a remote
study in our case outweigh these challenges.
44 Apparatus
4.1 Email Client
We implemented an email web client resembling a regular
email client (cf. Figure 2) allowing the user interface and data
collection to be customized to our needs. The client consists of
the inbox and four folders, named Important ,Neutral ,Spam ,
andBin, following the common naming in email clients.
Users can perform three actions on the emails in the inbox:
move to one of the folders (important, neutral, spam, bin), go
to the previous email, and go to the following email. As per
our role-playing scenarios, the emails were personalized with
receiver’s name and email. The list of all emails is visible on
the left side, previewing sender’s name, date, and subject.
We used Javascript and Node.Js for the implementation
and a PostgreSQL database. Figure 2 depicts the email client,
including different functionalities and areas of interest (AOIs):
Folders ,Email List ,Actions ,Email Header ,Email Body .
4.2 Data Collection
In our study, we collect two types of behavioral data:
Eye Movement Using the API GazeRecorder4we collect
time-stamped, raw eye position data ( x,y) based on
appearance-based gaze estimation from an RGB camera.
Mouse Movement We collect time-stamped mouse coordi-
nates, mouse events ( right click ,hover ).
We also collected the height of the browser window and the
browser anchor position on the screen. In addition, we utilize
three main areas of interest (AOIs) from the five described in
Figure 2 (email header, emaial body, inbox).
5 Study Design
We designed a within-subjects online study where users had
the task of classifying 36 emails from an inbox into four
folders. During our study, we had three independent variables:
1) eye movement data, 2) mouse movement data, and 3) email
labeling time. In addition, we had one dependent variable,
that was email type ( phishing, non-phishing).
5.1 Task
When it comes now to classifying emails, people usually
label emails or move them to a certain folder, to later more
easily retrieve, for example, important emails. In our work,
we decided to use folders, as commonly used in email clients,
such as Apple Mail, Thunderbird, or Outlook.
For this our study had the following two tasks:
4GazeRecorder: https://gazerecorder.com/•Task 1: Sorting Sort emails into the four folders Impor-
tant,Neutral ,Spam , and Bin.
•Task 2: Validation Classify emails as (Non) Phishing .
Task 1 results will reflect on how users deal with and ar-
range their inboxes and their behavior towards phishing emails
if they notice it. Task 2 will reflect if they found any phishing
emails or not. This has been added to see the awareness level
of our pool of participants.
5.2 Email Data Set
We created 36 emails5: 12 advertising emails, 12 neutral
emails, and 12 urgent emails. In each category, 9 emails are
legitimate and 3 are phishing. This ratio was chosen based
on prior work6, showing that approximately 25% of emails
received today are phishing.
Advertising Emails We created advertisement emails based
on samples from companies, such as Nivea, UNIDAYS,
and Zalando, containing newsletters, mailing list sub-
scriptions, and offers.
Neutral Emails We created the regular emails by mimicking
valid emails with the proposed scenario in mind, such as:
following up on previous emails, password reset requests,
links for a shared document, or updating a payment plan.
Urgent Emails We used time-sensitive topics such as over-
due sick leave notices or notification deadlines for a
project for important emails.
Phishing Emails We used a broad range of topics for phish-
ing emails. The 3 phishing emails in the neutral emails
category had the following topics 1) a document was
shared, 2) new office regulation, and 3) a password reset
was required. The phishing emails in the important email
category applied pressure and added a deadline for the
tasks, for example, 1) fill in the evaluation form within a
short time period, 2) fill out an urgent employee survey,
and 3) validate your drive account asap. The phishing
emails in the advertisements emails followed the presen-
tation often found among phishing emails impersonating
companies, such as different colors, logos, and grammar
mistakes. We used the following topics: 1) lottery, 2)
party invitation, and 3) extending a software license.
The phishing links pointed to domains we previously reg-
istered. Similar to [43], we mimicked websites of popu-
lar companies (Dropbox, Apple, Microsoft, and Skype)
and published them on our web server to which the regis-
tered domains pointed. The nine phishing emails covered
5Dataset: https://osf.io/7ae5z/?view_only=
0f39aaeda81d479abaca3b362a0c17d1
6https://www.darkreading.com/cloud/
25-of-phishing-emails-sneak-into-office-365-report
5Figure 2: Email Client Interface for the sorting task: On the top left, participants are greeted with their usernames. The top pane
shows three folders for Group 1 ( Important ,Neutral , and Bin) or four folders for Group 2 ( Important ,Neutral ,Spam , and Bin).
The left pane shows the emails and the right pane contains the user actions, email header, and body.
categories such as links for shared documents, raffles for
Apple iPhones, or a new IP login warning. Furthermore,
we added emails specifically targeted towards our role-
playing scenario company Global-Connect employees.
5.3 Participants and Recruiting
Participants were recruited from Prolific7and received a
3.13 GBP compensation for their participation. We recruited
39 participants (20 female, age M=25, SD=6.6). Participants
were students, salespeople, researchers, lawyers, and archi-
tects. On a 5-Point Likert scale (1=no experience, 5=expert),
participants rated their experience with IT security ( M=2.5)
and eye-tracking technology ( M=2.6) as moderate.
5.4 Procedure
Figure 3 shows the study procedure. First, participants were
provided with a description of the study and requirements.
They were asked to confirm that they were conducting the
study from a PC or laptop with a webcam, using Firefox or
Google Chrome, and to give consent. They were then pre-
7Prolific: https://prolific.co/sented with the role-playing scenario and task. Participants
had to enter a username and an email for use in the study.
Afterward, participants were directed to the eye gaze cali-
bration page. They were asked to sit in a well-lit room without
direct backlight, look into the webcam, try to minimize exten-
sive head movements, and, if possible, take their glasses off.
They then performed a 9-point calibration of the eye track-
ing software, followed by a head movement calibration. The
duration of the calibration process was around 2 minutes.
Afterwards, the mail client interface was loaded. Figure 2
shows the mail client interface with the 36 randomly ordered
emails. Participants can click on an email in the left panel,
read it, and decide which of the four folders to move it into.
Participants can freely switch between the four folders and the
inbox. When finished with the task, participants were directed
to an open-ended question, asking how they sorted the emails.
Afterward, participants were directed to the second task.
We informed them that parts of the emails they were asked
to sort into folders were phishing. We then asked them to
go through all the emails they had sorted again and indicate
whether they had identified them as phishing emails. At the
end of the second task, a 9-point accuracy test was presented
to check the eye tracker calibration quality.
6Finally, the post-study questionnaire was displayed, in
which demographic information about the participants’ age,
gender, background, and prior knowledge about security and
phishing was collected. Furthermore, we asked them if they
faced any difficulties during the study and asked some ques-
tions about the screen size and devices they used for the study.
In addition, participants were asked to answer a set of ques-
tions, including how they classified the emails in the study,
how they dealt with phishing emails daily, and whether they
used the same strategy to classify the emails in the study as
in real life. The study lasted approximately 30 minutes.
6 Data Analysis
In this section, we explain how data was cleaned, pre-
processed, and analyzed the collected data.
6.1 Data Cleaning and Pre-Processing
To clean our collected dataset, we identified and removed
outliers. Based on the standard deviation for completing the
classification for each email, we considered cases as outliers in
which participants required very long (more than 30 seconds)
or very short (less than 1 second) to label the data.
6.2 Feature Extraction
We extracted a feature set, describing mouse movement and
gaze behavior from the collected data. We extracted the fol-
lowing three groups of features based on prior work: 1) re-
sponse time, 2) mouse features (12 features), and 3) gaze
features (8 features).
6.2.1 Task Response Time
We calculate the response time Tsrequired by each user in task
1 to sort each email into a folder and in task 2 for classifying
each email as phishing / no phishing.
6.2.2 Mouse Features
We collected mouse movement behavior at a rate of 33 ms
and extracted a set of 12 features, as suggested by prior
work [57]. Regarding the AOIs (cf. Figure 2), we divide the
Email Header AOI into sub-AOIs (i.e. from,to,date,subject ),
allowing the mouse movements in this area to be more pre-
cisely analyzed. We also include mouse hovers over AOIs, as
prior work showed this to indicate reading / reflecting over the
content in the AOI [13,25] as well as mouse clicks and mouse
speed [57]. Below, we provide an overview of the features:
Mouse Hover on Subject Total number of mouse hovers
on the Subject header in an email.Mouse Hover on From Total number of mouse hovers on
theFrom header in an email.
Mouse Hover on Embedded Link Total number of
mouse hovers on any linkin an email.
Mouse Hover Frequency Total number of hover events
during an email sorting task.
Mouse Click on Link Total number of clicks on links in
the email during an email sorting task.
Mouse Hover Frequency for Mouse Movements Speeds
We first identified four speeds of movement within
each email: the distance moved between position Nand
N+1 for a 250 ms snippet is calculated first. Then we
continued by calculating the speed in pixels/second for
the change in position and interpreted it as follows:
•Idle: Speed at 0 px/s
•Slow : Speed at speed < 100 px/s
•Regular : 100 px/s<speed <500px/s
•Fast :>500px/s.
In this way, we obtained a frequency of movement state
for each email.
Slow Mouse Movement Time per Email We calculated
the total time spent with the mouse moving in the Slow
state ( speed <100px/s)
Mouse Movement Distance per Email Total mouse dis-
tance during email sorting.
Slow Mouse Movement Ratio Duration of slow mouse
movements divided by time for email sorting.
6.2.3 Gaze Features
Using the GazeRecorder API, we collected gaze data from
users’ webcam. From the collected raw gaze data (x and
y position), we calculated a set of 8 gaze features. In our
case, all participants provided data at 30 Hz. Both gaze and
mouse movement data were synced using a Unix timestamp.
From the raw data, we removed the outliers and calculated the
fixations using the Dispersion-Threshold Identification algo-
rithm [47]. This method produces accurate results in real-time
using only two parameters (dispersion and duration threshold),
which we set to 25 ms and 100 ms, respectively. We chose
the most frequent gaze features used in the literature [15, 53].
Below is the list of the different gaze features:
Fixation Count Total number of gaze fixations.
Avg Fixation Count Average number of fixations per AOI.
Fixation Duration Total fixation duration per AOI.
Avg Fixation Duration Average duration for all fixations
per AOI.
7GazeRecorder 
calibration Study 
details & 
Consent Email sorting 
taskGaze 
accuracy 
TestDemographics 
& post 
questionnaire 
1-2 mins 10-15 mins 1 min Spam vs not 
spam 
classification 
5-7 mins SPAM How did you 
classify the 
emails? 
?Figure 3: The study procedure consisted of four main steps. The study duration was approx. 30 minutes.
Saccadic Duration Duration between every consecutive
fixations.
Avg Saccadic Duration Average duration taken between
each two fixations.
Saccadic Length Distance between every two fixations.
Avg Saccadic Length Average dist. between two fixations.
7 Results
Throughout this section, we will be reporting non-parametric
tests as the collected data distribution was shown to be non-
normaly distributed as proven by a Shapiro-Wilk test .
7.1 Data Overview
In total, we collected users’ responses for 1404 emails and
176.19 minutes of behavioral data (gaze and mouse move-
ment). After data pre-processing, we had an average of 14.451
samples for both gaze and mouse movements per participant
during sorting all emails. This results in a mean of 563K
samples for all users during sorting all emails.
7.2 Task1: Email Sorting
Table 1 shows how participants sorted the emails into the
4 folders. We found that most of the Phishing emails were
sorted into Important (49%) and Neutral (36.8%). The rest
was sorted into the BinandSpam folders (6% and 8.2% respec-
tively). The urgent emails were mainly sorted into important
(67%). The neutral emails where were mainly sorted into
the neutral folder (66.1%). For the advertisement emails, we
found that more than half of them were sorted into the spam
folder (53.8%) while 38.2% were sorted into the bin.
7.3 Task 2: Phishing Validation Task
Table 2 shows how participants classified emails as phishing
and non-phishing. The majority of emails was labeled as non-
phishing: phishing emails (97.3%), important emails (99.7%),
neutral emails (97,4%), advertisement emails (88.7%).Table 1: Task 1 (email sorting) results based on the target
folder chosen by participants.
Email Type/
Sorted IntoPhishing Important Neutral Ads
Bin 6% 12.5% 6.6% 38.2%
Important 49% 67.8% 25.6% 7.7%
Neutral 36.8% 19.4% 66.1% 0.3%
Spam 8.2% 0.3% 1.7% 53.8%
Table 2: Task 2 (email classification) results, based on classi-
fication as phishing / no phishing.
Phishing No Phishing
Phishing 2.7% 97.3%
Important 0.3% 99.7%
Neutral 2.6% 97.4%
Ads 88.7% 11.3%
Summary. From this we learn that our study setting worked
as intended, i.e. a considerable number of participants indeed
did not recognize phishing emails.
7.4 Labeling Response Time
Literature showed that task response time can be used as a
metric of cognitive load when participants are engaged in a
primary task [8,20]. We analyze the response time in seconds
taken to sort the emails in each email folder. The figure shows
that participants required equally long to sort the emails into
the different folders. We found that sorting important emails
required slightly longer ( M=10.93s), followed by phishing
emails ( M=10.89s), advertisements ( M=10.79s), and fi-
nally neutral emails ( M=10.46s). Wilcoxon Signed-Rank
tests did not show a statistically significant effect of the email
category on the labeling duration, p> .05.
We analyzed the response time taken to sort the phishing
and non-phishing emails in each category (Figure 4). Partici-
pants took slightly longer for sorting phishing ( M=9.62sec-
onds) compared to non-phishing ( M=9.34seconds) emails
in each category. However, Wilcoxon Signed-Rank test did
not show a statistically significant effect of the email type on
the labeling duration, p> .05.
8Figure 4: Phishing and non-phishing emails in each category,
and the overall average.
7.5 Mouse Movements
We present the results from a Wilcoxon signed-rank test, con-
ducted to study the effect of reading and sorting phishing
and non-phishing emails into different folders on the differ-
ent mouse movement features in Table 3. We highlight the
significant results in bold.
Across the different email types, we found significant dif-
ferences in users’ mouse behavior while reading and sorting
phishing and non-phishing emails. Seven mouse movement
features show significant differences highlighted in bold in Ta-
ble 3. Reading phishing emails leads to participants’ hovering
more frequently over text, more often clicking links, and per-
forming more idle, slow, fast and regular mouse movements
as well as also longer slow mouse movements.
In line with prior work [57], slow mouse movements were
a good indicator for detecting reading phishing emails. We
found that participants covered longer mouse distances while
reading phishing emails. Also this aligns with prior literature,
showing that longer mouse movements can indicate higher
cognitive load [20]. In addition, the mean values showed
that participants clicked significantly more often on links in
phishing emails compared to links in non-phishing email.
When looking at different types of emails, an interesting
aspect is that differences in mouse movement occur for more
features (8) when the emails are important as opposed to
advertisements (3) and neutral emails (1).
7.6 Gaze Movements
Table 4 shows the Wilcoxon test results for the gaze features
with significant values in bold for phishing and non-phishing
emails across the different email categories. Overall, saccadic
length, average saccadic duration, and fixation count are the
most significant features for reading and sorting phishing
emails across the different categories. More specifically, sort-ing phishing emails leads to shorter average fixation duration,
shorter average saccadic duration, more fixations, and longer
saccades. This can be explained by prior work showing those
features to serve as an indicator for added cognitive load [14].
This seems to confirm our assumption that phishing emails
can increase cognitive load, leading to observable behavior.
An interesting finding was that none of the gaze features
showed statistically significant differences when looking at
important emails. While we cannot draw strong conclusions
here, an explanation for this could be that important/urgent
emails may trigger similar gaze behavior like phishing emails
(for example, both might increase cognitive load or stress).
However, this needs further investigation.
7.7 Questionnaire Results
At the end of the study, participants were asked to fill out a
short questionnaire about their experience. On a 5-point Lik-
ert scale (1=strongly disagree, 5=strongly agree), participants
found that the information in the interface helped them cate-
gorize the emails ( M=4.08,SD=0.87). When asked about
the particular folders, participants found it slightly easier to
sort emails as Important (M=4.08,SD=0.62) and Spam
(M=3.74,SD=1.01) than Bin(M=3.33,SD=1.02) and
Neutral (M=3.44,SD=1.10). Thirty seven participants re-
ported that they used the same strategy in the study to classify
emails as in real life. Only two participants reported using a
different strategy.
After giving a general definition of phishing to our partici-
pants, we asked how they usually act when receiving a phish-
ing email. The majority of our participants (29 participants)
mentioned they would delete or report it, while 4 participants
said they would do nothing with the email. Seventeen partici-
pants would look for technical details that can conclusively
identify the email as phishing, and 10 participants would try
to make sense of the email and understand how it relates to
other things in their lives. After email classification, partici-
pants were asked four open-ended questions where they could
enter free text, namely: what aspects of the email made them
categorize emails as Important ,Neutral ,Bin, and Spam .
To analyze this data, we conducted a thematic analysis
where two researchers analyzed the data independently then
compared their results and combined them to produce a set of
themes for each email category and conflicts were resolved
in the discussions.
Participants considered an email Important when they re-
quired some urgent reply or action (18 participants) and based
on if the mail was related to work (17 participants). They also
considered it Important based on specific senders, such as
emails from their boss (2 participants). Participants labeled
emails as Neutral when they were non-important company
emails (24 participants) or when they contained party invi-
tations (2 participants). Participants labeled emails mainly
asBinwhen they contained advertisements (12 participants),
9Table 3: Wilcoxon Signed-rank Test for The Mouse Features for Phishing and non-phishing emails across different email
categories (Significant results ( P< .05) in bold).
Mouse FeaturesWilcoxon
Overall Phishing/non phishing Imp
Phishing/
non phishingAds
Phishing/
non phishingNeutral
Phishing/
non phishingMean
PhishingMean Non
PhishingWilcoxon
"Subject" Header Hover Freq. .020 .025 Z=-.80, P=.42 Z=-1.89, P=.05 Z=-.26, P=.79 Z=-.46, P=.63
"From" Header Hover Freq. .021 .018 Z=-.22, P=.82 Z=-1.25, P=.21 Z=-.45, P=.64 Z=-1.87, P=.06
Email Link Hover Freq. .025 .028 Z=-.55, P=.58 Z=-.76, P=.44 Z=-1.06, P=.28 Z=-1.96, P=.04
Overall Hover Freq. 315.47 228.49 Z=-4.76, P<.001 Z=-2.78, P=.005 Z=-4.37, P<.001 Z=-1.16, P=.24
Click on the Email Link 2.05 .24 Z=2.48, P=.013 Z=-2.02, P=.04 Z=-2.20, P=.028 Z=-.44, P=.65
Idle Mouse Movements Freq. 120.03 86.79 Z=-4.71, P<.001 Z=-2.28, P=.02 Z=-4.06, P<.001 Z=-.30, P=.75
Slow Mouse Movements Freq. 21.63 16.47 Z=-2.55, P=.011 Z=-2.30, P=.02 Z=-1.60, P=.10 Z=-.18, P=.85
Fast Mouse Movements Freq. 5.42 4.76 Z=-2.52, P=.012 Z=-2.39, P=.01 Z=-.50, P=.61 Z=-.60, P=.54
Regular Mouse Movements Freq. 8.88 7.34 Z=-2.16, P=.031 Z=-1.61, P=.10 Z=-.95, P=.33 Z=-.37, P=.71
Mouse Distance per Email 2208.96 1972.48 Z=-1.92, P=.054 Z=-1.99, P=.04 Z=-.96, P=.33 Z=-.29, P=.76
Slow Mouse Movements Time 1.35 1.02 Z=-2.55, P=.011 Z=-2.30, P=.02 Z=-1.60, P=.10 Z=-.18, P=.85
Slow Mouse Movements Ratio .00 .00 Z=-1.64, P=.100 Z=-2.64, P=.008 Z=-.89, P=.36 Z=-.89, P=.37
Table 4: Wilcoxon test results for eye gaze movement analysis over the email categories (Significant results in bold, P< .05).
Gaze FeaturesWilcoxon
Overall Phishing/non phishing Imp
Phishing/
non-phishingAds
Phishing/
non-phishingNeutral
Phishing/
non-phishingMean non
PhishingMean
PhishingWilcoxon
Fixation Duration 52608.12 57109.3 Z=-.54, P=.58 Z=-1.32, P=.18 Z=-1.19, P=.23 Z=-1.09, P=.27
Avg Fixation Duration 10595.06 8610.93 Z=-2.37, P=.018 Z=-1.69, P=.09 Z=-1.08, P=.28 Z=-1.10, P=.26
Saccade Duration 30881.52 20409.46 Z=-1.88, P=.06 Z=-.62, P=.53 Z=-.45, P=.64 Z=-2.40, P=.016
Avg Saccade Duration 7715.25 2753.63 Z=-2.33, P=.02 Z=-1.12, P=.26 Z=-3.22, P=.001 Z=-2.81, P=.005
Fixation Count 134.58 189.12 Z=-4.34, P<.001 Z=-1.84, P=.06 Z=-4.372 P<.001 Z=-.59, P=.55
Avg Fixation Count .49 .49 Z=-.25, P=.80 Z=-.00, P=.99 Z=-.13, P=.89 Z=-.58, P=.56
Saccade Length 119.2 157.2 Z=-4.18, P<.001 Z=-1.71, P=.08 Z=-4.43, P<.001 Z=-.53, P=.59
Avg Saccade Length .51 .51 Z=.25, P=.80 Z=-.00, P=.99 Z=-.13, P=.89 Z=-.58, P=.56
and when they contained non-relevant information (8 partici-
pants). Emails were considered as Spam when they contained
advertisements (27 participants). Two participants mentioned
they marked it as Spam whenever an email did not contain any
personal details. Furthermore, 1 participant mentioned they
marked it as Spam when emails contained false information.
8 Discussion
8.1 Behavioral Indicators for Phishing
We statistically analyzed response times, mouse movement,
and eye gaze throughout our study. We found similarities to
prior work and interesting features for use in further analyses.
Users seem to spend more time examining and labeling
phishing emails than non-phishing emails. However, similar
to prior work [57], we did not find statistically significant
differences when looking at the overall time.
We looked more closely into how the elapsed time was
spent. We found significant differences between mouse hover
frequencies in different AOIs of an email. In particular, mousehovers on the subject or the embedded links can indicate that
users dedicate more attention to this particular element. This
suggest that a fine-grained analysis is required when trying to
use time as a predictor for exposure to emails.
Our findings also illustrate that an important feature is the
speed of the mouse movement within an email, correlating
with the distance covered. Whereas slower movements were
studied in prior work [57], we found that an increase in fast,
idle, and slow movements reflects users‘ behavior towards dif-
ferent types of emails in general and reading phishing emails
in particular. Also prior research on intrusion detection us-
ing mouse movement found significant differences in behav-
ior such as mouse movement speed and distance covered on
screens during fraudulent versus legitimate logins to a PC [7].
Gaze data shows that users’ fixation counts, average fixa-
tion duration, saccadic length, and average saccadic length
are different for reading phishing than non-phishing emails.
Prior work had shown that more thorough reading reflects
in eye gaze behavior, showing longer fixation duration [54],
which is the case when participants read phishing emails.
108.2 Effect of Email Type on User Behavior
Users often seem to carefully read phishing emails (reflected
in participants’ gaze and mouse movements). However, they
still labeled them as non-phishing, cf. Tables 1 and 2. Our
findings suggest that particular features may only accurately
predict phishing emails when considering its particular type.
We noticed that most mouse movement features were sig-
nificantly different for important emails compared to almost
no significant differences for the gaze data. This might be due
to users’ perception of important emails that guide them to
read them carefully. This seems reasonable, especially in the
context of role-playing where the participants know that they
can receive emails from other colleagues, making it harder to
identify the differences between phishing and non-phishing
emails in such a scenario. However, for the advertisements
and neutral emails, participants’ mouse and gaze movement
behavior differed when reading phishing and non-phishing
emails. This highlights the potential of considering different
types of behavior, showing that for most emails, users’ behav-
ior could reveal their exposure to phishing emails even if they
still label them as non-phishing.
8.3 Suspicious Content Indicators
Although phishing emails are a significant problem for indi-
viduals and institutions, other channels for social engineering
attacks are becoming an imminent threat (e.g., Facebook, Twit-
ter, instant messaging). Recent work on detecting fake news
on social media has shown that users who spend more time
looking at post headings were more successful in detecting
fake news [52]. Past work has also looked into users’ success
in identifying the legitimacy of websites based on how much
users look at different parts of the browser [5]. Our findings
may be valuable for other researchers attempting to mitigate
other forms of social engineering attacks. For instance, fea-
tures such as slow mouse movements or high fixation counts
in certain AOIs when looking at tweets or TikTok videos
could be used for detection.
9 Practical Implications
Our findings yield some practical implications. We focus on
how existing tools (email clients, filters) can benefit from our
approach, which requirements for sensing exist, and how the
selection of features can be enhanced by existing tools.
9.1 Integration with Email Clients and Filters
Enhancing Email Clients Based on Behavioral Data. Our
approach could be implemented in different forms. For in-
stance, it can be integrated into email clients or be used as
a provider-independent solution by implementing a browser
plugin that accesses the camera and assesses users’ gaze dataas they read their emails. Finally, our approach could run on
smart glasses/AR glasses, active when users read their emails.
A prediction system can provide interventions to nudge and
protect the user. For example, it can show pop-ups to warn
the user from clicking on the phishing link, it can auto-label
and move the email to the spam folder, or apply any of the
different interventions presented in the literature [43].
Enhancing Spam Filters based on Behavioral Data. One
use case can be enhancing existing spam filters by adding user
behavior (such as mouse movement, gaze tracking, or both) as
a second line of defense. This could be done on an individual
basis or systems could "crowd-source" the response of users
towards emails so as to offer protection for other users.
9.2 Requirements for Sensing
Sensing Technology for Behavior-Aware Phishing Protec-
tion Mechanisms Eye tracking is about to become ubiqui-
tous. Already today there are computers with integrated eye
trackers and this trend may continue in the future. Also, eye
tracking is already being integrated into smartphones, such
as the iPhoneX as well as in most Mixed Reality headsets
(which are likely to become unobtrusive smart glasses in the
future). Beyond those examples, advances in computer vision
will make it possible in the future to offer high quality gaze
estimation in many more different devices, simply by means
of a high-quality RGB camera camera [31].
Use of Fine-Grained Gaze Data. A main finding of our
work is that changes to behavior while reading emails may be
subtle. For example, we found that the amount of fixations and
their duration is a significant feature to differentiate between
phishing and non phishing emails. These features require
sensors that yield data of sufficient quality. We used a webcam-
based approach employing appearance-based gaze estimation
showing the general feasibility of the approach, that is, it is
possible to integrate the approach on consumer PCs with
a webcam only. At the same time, the availability of high-
quality gaze data (e.g., from commercial eye trackers based on
infrared) might allow more subtle differences to be revealed.
9.3 Enhancing Features Selection
Label Important Emails to Select Best features. We
found that the importance of an email may cause changes
to gaze features triggered by phishing to be superimposed,
as both the importance and nature of the phishing email may
cause increased workload or stress. At the same time, mouse
movements still serve as a good predictor of phishing emails.
Hence, the challenge is to decide which features to look at.
Emails can generally be flagged as important. This informa-
tion could be used by an email client that offers protection
11mechanisms to select the optimal gaze features to make a pre-
diction. As a result, research might look into approaches that
either educate users when it makes sense to flag an email as
important or look at whether the importance of emails can be
assessed on the sender side and emails be labeled accordingly.
Consider Type of Email. We found that the type of email
affects users’ behavior, consequently, how well the prediction
works. For example, we found many gaze features that serve
as a good predictor for phishing in neutral and advertising
emails. Current email clients like Gmail are already very good
at, for example, labeling emails as advertising or social media.
Such knowledge could be leveraged by a phishing protection
mechanism to select the best features for analysis.
9.4 Personalizing Protection User Interfaces
We found differences in user behavior when it comes to click-
ing on links, that is, some participants are just more likely to
click on links (independent of whether or not they are phish-
ing). This is in line with prior work showing that this has
to do with their risk-taking behavior. Such individual differ-
ences need to be considered in the design of user interfaces
that use our approach to identify phishing. For example, for
some users, nudges may be sufficient whereas other should
be actively prevented from clicking links.
10 Conclusion and Future Work
In this work, we demonstrated the feasibility and potential of
collecting and assessing users’ eye gaze and mouse behavior
during the exposure to phishing emails. We investigated such
behavior through a remote role-playing study of email sorting
with 39 users, using a self-developed, web-based email client.
We collected behavioral data, namely eye gaze, mouse move-
ment data, and actions performed while sorting emails into
different folders. Our findings indicate significant differences
between specific mouse movements and eye gaze features
when interacting with phishing and non-phishing emails.
We see our work as a first step toward designing and im-
plementing approaches in which user behavior is assessed
while working on emails in real-time and where interventions
becomes possible based on the probability of falling for phish-
ing – as opposed to approaches that warn users every time
they perform an action that is a potential security risk (e.g.,
clicking on a link or opening an attachment).
Our work opens up many possibilities for future work by
the usable security community. Researchers could look into
how machine learning / deep learning could be used to build
predictive models and optimize their accuracy for phishing
email identification. Furthermore, researchers could extend
the approach by employing additional behavioral data (e.g.,
keystroke dynamics or touches on smart phones) as well aseven physiological data (heart rate, skin conductance). And
finally, future work can look into how effective interventions
can be built that consider the user’s context, individual behav-
ior and habits, and likeliness of an attack.
References
[1]Yasmeen Abdrabou, Elisaveta Karypidou, Florian Alt,
and Mariam Hassib. Investigating user behaviour to-
wards fake news on social media using gaze and mouse
movements. In Proceedings of the Usable Security Mini
Conference 2023 , USEC’23, San Diego, CA, USA, 2023.
Internet Society.
[2]Sara Albakry, Kami Vaniea, and Maria K. Wolters. What
is this url’s destination? empirical evaluation of users’
url reading. In Proceedings of the 2020 CHI Confer-
ence on Human Factors in Computing Systems , CHI ’20,
page 1–12, New York, NY , USA, 2020. Association for
Computing Machinery.
[3]Zainab Alkhalil, Chaminda Hewage, Liqaa Nawaf, and
Imtiaz Khan. Phishing attacks: A recent comprehen-
sive study and a new anatomy. Frontiers in Computer
Science , 3(5):6, 2021.
[4]Ammar Almomani, Brij B Gupta, Samer Atawneh, An-
drew Meulenberg, and Eman Almomani. A survey of
phishing email filtering techniques. IEEE communica-
tions surveys & tutorials , 15(4):2070–2090, 2013.
[5]Mohamed Alsharnouby, Furkan Alaca, and Sonia Chi-
asson. Why phishing still works: User strategies for
combating phishing attacks. International Journal of
Human-Computer Studies , 82:69 – 82, 2015.
[6]Kholoud Althobaiti, Nicole Meng, and Kami Vaniea.
I don’t need an expert! making url phishing features
human comprehensible. In Proceedings of the 2021 CHI
Conference on Human Factors in Computing Systems ,
CHI ’21, New York, NY , USA, 2021. Association for
Computing Machinery.
[7]M. Antal and E. Egyed-Zsigmond. Intrusion detection
using mouse dynamics. IET Biometrics , 8(5):285–294,
2019.
[8]Roland Brunken, Jan L Plass, and Detlev Leutner. Direct
measurement of cognitive load in multimedia learning.
Educational psychologist , 38(1):53–61, 2003.
[9]Deanna D Caputo, Shari Lawrence Pfleeger, Jesse D
Freeman, and M Eric Johnson. Going spear phishing:
Exploring embedded training and awareness. IEEE
Security & Privacy , 12(1):28–38, 2013.
12[10] Jeffrey Carr. Inside cyber warfare: Mapping the cyber
underworld . O’Reilly Media, Inc., 2012.
[11] Mon Chu Chen, John R. Anderson, and Myeong Ho
Sohn. What can a mouse cursor tell us more? correlation
of eye/mouse movements on web browsing. In CHI ’01
Extended Abstracts on Human Factors in Computing
Systems , CHI EA ’01, page 281–282, New York, NY ,
USA, 2001. Association for Computing Machinery.
[12] Robert B. Cialdini. Influence . Harlow, Pearson Educa-
tion, 2013.
[13] Malcolm Clark, Ian Ruthven, Patrik O’Brian Holt,
Dawei Song, and Stuart Watt. You have e-mail, what
happens next? tracking the eyes for genre. Information
processing & management , 50(1):175–198, 2014.
[14] Malcolm Clark, Ian Ruthven, Patrik O’Brian Holt,
Dawei Song, and Stuart Watt. You have e-mail, what
happens next? tracking the eyes for genre. Information
Processing & Management , 50(1):175–198, 2014.
[15] A. Darwish and E. Bataineh. Eye tracking analysis of
browser security indicators. In 2012 International Con-
ference on Computer Systems and Industrial Informatics ,
pages 1–6, 2012.
[16] Rachna Dhamija, J. D. Tygar, and Marti Hearst. Why
phishing works. In Proceedings of the SIGCHI Confer-
ence on Human Factors in Computing Systems , CHI ’06,
page 581–590, New York, NY , USA, 2006. Association
for Computing Machinery.
[17] Julie S. Downs, Mandy Holbrook, and Lorrie Faith Cra-
nor. Behavioral response to phishing risk. In Proceed-
ings of the Anti-Phishing Working Groups 2nd Annual
ECrime Researchers Summit , eCrime ’07, page 37–44,
New York, NY , USA, 2007. Association for Computing
Machinery.
[18] Christine E Drake, Jonathan J Oliver, and Eugene J
Koontz. Anatomy of a phishing email. In CEAS . Cite-
seer, 2004.
[19] Serge Egelman, Lorrie Faith Cranor, and Jason Hong.
You’ve been warned: An empirical study of the effective-
ness of web browser phishing warnings. In Proceedings
of the SIGCHI Conference on Human Factors in Com-
puting Systems , CHI ’08, page 1065–1074, New York,
NY , USA, 2008. Association for Computing Machinery.
[20] G. Mark Grimes and Joseph S. Valacich. Mind over
mouse: The effect of cognitive load on mouse movement
behavior. In Traci A. Carte, Armin Heinzl, and CathyUrquhart, editors, Proceedings of the International Con-
ference on Information Systems - Exploring the Informa-
tion Frontier, ICIS 2015, Fort Worth, Texas, USA, Decem-
ber 13-16, 2015 . Association for Information Systems,
2015.
[21] Eric Hehman, Ryan M Stolier, and Jonathan B Free-
man. Advanced mouse-tracking analytic techniques for
enhancing psychological science. Group Processes &
Intergroup Relations , 18(3):384–401, 2015.
[22] Amir Herzberg and Ahmad Gbara. Trustbar: Protect-
ing (even naive) web users from spoofing and phishing
attacks. Technical report, Cryptology ePrint Archive,
Report 2004/155. http://eprint. iacr. org/2004/155, 2004.
[23] Corey Holland and Oleg V . Komogortsev. Biomet-
ric identification via eye movement scanpaths in read-
ing. 2011 International Joint Conference on Biometrics
(IJCB) , pages 1–8, 2011.
[24] Jeff Huang, Ryen White, and Georg Buscher. User see,
user point: Gaze and cursor alignment in web search. In
Proceedings of the SIGCHI Conference on Human Fac-
tors in Computing Systems , CHI ’12, page 1341–1350,
New York, NY , USA, 2012. Association for Computing
Machinery.
[25] Jeff Huang, Ryen W. White, and Susan Dumais. No
clicks, no problem: Using cursor movements to under-
stand and improve search. In Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems ,
CHI ’11, page 1225–1234, New York, NY , USA, 2011.
Association for Computing Machinery.
[26] Shamsi T Iqbal and Brian P Bailey. Using eye gaze
patterns to identify user tasks. In The Grace Hopper
Celebration of Women in Computing , volume 1, 2004.
[27] Cristian Iuga, Jason RC Nurse, and Arnau Erola. Baiting
the hook: factors impacting susceptibility to phishing
attacks. Human-centric Computing and Information
Sciences , 6(1):1–20, 2016.
[28] Roland S Johansson, Göran Westling, Anders Bäck-
ström, and J Randall Flanagan. Eye–hand coordina-
tion in object manipulation. Journal of neuroscience ,
21(17):6917–6932, 2001.
[29] Christina Katsini, Yasmeen Abdrabou, George E. Raptis,
Mohamed Khamis, and Florian Alt. The Role of Eye
Gaze in Security and Privacy Applications: Survey and
Future HCI Research Directions , page 1–21. Associa-
tion for Computing Machinery, New York, NY , USA,
2020.
13[30] Timothy Kelley and Bennett I Bertenthal. Attention and
past behavior, not security knowledge, modulate users’
decisions to login to insecure websites. Information &
Computer Security , 2016.
[31] Mohamed Khamis, Florian Alt, and Andreas Bulling.
The past, present, and future of gaze-enabled handheld
mobile devices: Survey and lessons learned. In Proceed-
ings of the 20th International Conference on Human-
Computer Interaction with Mobile Devices and Services ,
MobileHCI ’18, New York, NY , USA, 2018. Association
for Computing Machinery.
[32] Gregory J. Koop and Joseph G. Johnson. The response
dynamics of preferential choice. Cognitive Psychology ,
67(4):151–185, 2013.
[33] Ponnurangam Kumaraguru, Yong Rhee, Alessandro Ac-
quisti, Lorrie Faith Cranor, Jason Hong, and Elizabeth
Nunge. Protecting people from phishing: The design
and evaluation of an embedded training email system.
InProceedings of the SIGCHI Conference on Human
Factors in Computing Systems , CHI ’07, page 905–914,
New York, NY , USA, 2007. Association for Computing
Machinery.
[34] Ponnurangam Kumaraguru, Steve Sheng, Alessandro
Acquisti, Lorrie Faith Cranor, and Jason Hong. Teach-
ing johnny not to fall for phish. ACM Trans. Internet
Technol. , 10(2), June 2010.
[35] Daniele Lain, Kari Kostiainen, and Srdjan ˇCapkun.
Phishing in organizations: Findings from a large-scale
and long-term study. In 2022 IEEE Symposium on Se-
curity and Privacy (SP) , pages 842–859, 2022.
[36] Eric Lin, Saul Greenberg, Eileah Trotter, David Ma, and
John Aycock. Does domain highlighting help people
identify phishing sites? In Proceedings of the SIGCHI
Conference on Human Factors in Computing Systems ,
CHI ’11, page 2075–2084, New York, NY , USA, 2011.
Association for Computing Machinery.
[37] Tian Lin, Daniel E Capecci, Donovan M Ellis, Harold A
Rocha, Sandeep Dommaraju, Daniela S Oliveira, and
Natalie C Ebner. Susceptibility to spear-phishing emails:
Effects of internet user demographics and email con-
tent. ACM Transactions on Computer-Human Interac-
tion (TOCHI) , 26(5):1–28, 2019.
[38] Päivi Majaranta and Andreas Bulling. Eye Tracking and
Eye-Based Human-Computer Interaction , pages 39–65.
Springer Publishing London, 2014.
[39] Claudio Marforio, Ramya Jayaram Masti, Claudio Sori-
ente, Kari Kostiainen, and Srdjan Capkun. Personalized
security indicators to detect application phishing attacksin mobile platforms. arXiv preprint arXiv:1502.06824 ,
2015.
[40] Vidhya Navalpakkam, LaDawn Jentzsch, Rory Sayres,
Sujith Ravi, Amr Ahmed, and Alex Smola. Measure-
ment and modeling of eye-mouse behavior in the pres-
ence of nonlinear page layouts. In Proceedings of
the 22nd international conference on World Wide Web ,
pages 953–964, 2013.
[41] Daniela Oliveira, Harold Rocha, Huizi Yang, Donovan
Ellis, Sandeep Dommaraju, Melis Muradoglu, Devon
Weir, Adam Soliman, Tian Lin, and Natalie Ebner. Dis-
secting spear phishing emails for older vs young adults:
On the interplay of weapons of influence and life do-
mains in predicting susceptibility to phishing. In Pro-
ceedings of the 2017 CHI Conference on Human Factors
in Computing Systems , CHI ’17, page 6412–6424, New
York, NY , USA, 2017. Association for Computing Ma-
chinery.
[42] Kathryn Parsons, Agata McCormac, Malcolm Pattin-
son, Marcus Butavicius, and Cate Jerram. Phishing for
the truth: A scenario-based experiment of users’ be-
havioural response to emails. In Lech J. Janczewski,
Henry B. Wolfe, and Sujeet Shenoi, editors, Security
and Privacy Protection in Information Processing Sys-
tems, pages 366–378, Berlin, Heidelberg, 2013. Springer
Berlin Heidelberg.
[43] Justin Petelka, Yixin Zou, and Florian Schaub. Put your
warning where your link is: Improving and evaluating
email phishing warnings. In Proceedings of the 2019
CHI Conference on Human Factors in Computing Sys-
tems, CHI ’19, page 1–15, New York, NY , USA, 2019.
Association for Computing Machinery.
[44] Keith Rayner. Eye movements in reading and informa-
tion processing: 20 years of research. Psychological
bulletin , 124(3):372, 1998.
[45] Benjamin Reinheimer, Lukas Aldag, Peter Mayer, Mat-
tia Mossano, Reyhan Duezguen, Bettina Lofthouse, Ta-
tiana von Landesberger, and Melanie V olkamer. An
investigation of phishing awareness and education over
time: When and how to best remind users. In Sixteenth
Symposium on Usable Privacy and Security (SOUPS
2020) , pages 259–284. USENIX Association, August
2020.
[46] Kerry Rodden, Xin Fu, Anne Aula, and Ian Spiro. Eye-
mouse coordination patterns on web search results pages.
InCHI ’08 Extended Abstracts on Human Factors in
Computing Systems , CHI EA ’08, page 2997–3002, New
York, NY , USA, 2008. Association for Computing Ma-
chinery.
14[47] Dario D. Salvucci and Joseph H. Goldberg. Identify-
ing fixations and saccades in eye-tracking protocols. In
Proceedings of the 2000 Symposium on Eye Tracking
Research & Applications , ETRA ’00, page 71–78, New
York, NY , USA, 2000. Association for Computing Ma-
chinery.
[48] Stefan Scherbaum and Maja Dshemuchadse. Psycho-
metrics of the continuous mind: Measuring cognitive
sub-processes via mouse tracking. Memory & Cogni-
tion, 48(3):436–454, 2020.
[49] Bruce Schneier. Semantic attacks: The third wave of
network attacks. Crypto-Gram Newsletter , 14, 2000.
[50] Steve Sheng, Mandy Holbrook, Ponnurangam Ku-
maraguru, Lorrie Faith Cranor, and Julie Downs. Who
falls for phish? a demographic analysis of phishing sus-
ceptibility and effectiveness of interventions. In Pro-
ceedings of the SIGCHI Conference on Human Factors
in Computing Systems , CHI ’10, page 373–382, New
York, NY , USA, 2010. Association for Computing Ma-
chinery.
[51] Steve Sheng, Bryant Magnien, Ponnurangam Ku-
maraguru, Alessandro Acquisti, Lorrie Faith Cranor, Ja-
son Hong, and Elizabeth Nunge. Anti-phishing phil:
The design and evaluation of a game that teaches people
not to fall for phish. In Proceedings of the 3rd Sym-
posium on Usable Privacy and Security , SOUPS ’07,
page 88–99, New York, NY , USA, 2007. Association
for Computing Machinery.
[52] Jakub Simko, Martina Hanakova, Patrik Racsko, Matus
Tomlein, Robert Moro, and Maria Bielikova. Fake news
reading on social media: an eye-tracking study. In Pro-
ceedings of the 30th ACM Conference on Hypertext and
Social Media , pages 221–230, 2019.[53] Tommy Strandvall. Eye tracking in human-computer in-
teraction and usability research. In Tom Gross, Jan Gul-
liksen, Paula Kotzé, Lars Oestreicher, Philippe Palanque,
Raquel Oliveira Prates, and Marco Winckler, editors,
Human-Computer Interaction – INTERACT 2009 , pages
936–937, Berlin, Heidelberg, 2009. Springer Berlin Hei-
delberg.
[54] Matteo Valsecchi, Karl R Gegenfurtner, and Alexan-
der C Schütz. Saccadic and smooth-pursuit eye move-
ments during reading of drifting texts. Journal of vision ,
13(10):8–8, 2013.
[55] Zikai Alex Wen, Zhiqiu Lin, Rowena Chen, and Erik
Andersen. What.hack: Engaging anti-phishing training
through a role-playing phishing simulation game. In
Proceedings of the 2019 CHI Conference on Human
Factors in Computing Systems , CHI ’19, page 1–12,
New York, NY , USA, 2019. Association for Computing
Machinery.
[56] Min Wu, Robert C. Miller, and Simson L. Garfinkel.
Do security toolbars actually prevent phishing attacks?
InProceedings of the SIGCHI Conference on Human
Factors in Computing Systems , CHI ’06, page 601–610,
New York, NY , USA, 2006. Association for Computing
Machinery.
[57] Kun Yu, Ronnie Taib, Marcus A. Butavicius, Kathryn
Parsons, and Fang Chen. Mouse behavior as an in-
dex of phishing awareness. In David Lamas, Fernando
Loizides, Lennart Nacke, Helen Petrie, Marco Winck-
ler, and Panayiotis Zaphiris, editors, Human-Computer
Interaction – INTERACT 2019 , pages 539–548, Cham,
2019. Springer International Publishing.
15