Atomic Cluster Expansion without Self-Interaction
Cheuk Hin Ho∗, Timon S. Gutleb∗, Christoph Ortner∗
Abstract
TheAtomic Cluster Expansion (ACE) (Drautz, Phys. Rev. B 99, 2019) has been widely
applied in high energy physics, quantum mechanics and atomistic modeling to construct
many-body interaction models respecting physical symmetries. Computational efficiency is
achieved by allowing non-physical self-interaction terms in the model. We propose and ana-
lyze an efficient method to evaluate and parameterize an orthogonal, or, non-self-interacting
cluster expansion model. We present numerical experiments demonstrating improved con-
ditioning and more robust approximation properties than the original expansion in regres-
sion tasks both in simplified toy problems and in applications in the machine learning of
interatomic potentials.
1 Introduction
Most physical systems of interest in applications exhibit numerous symmetries. When using
machine learning to model such systems, preserving those symmetries is an important consid-
eration for model architecture design. Permutation invariance, that is invariance of the model
under permutation of input particles, is a typical property of molecular dynamics, computer
vision and quantum mechanics applications [32, 31, 23]. Equivariance with respect to a reduc-
tive Lie group Gsuch as the Lorentz group, orthogonal groups or the Euclidean group are also
frequently encountered. One common approach in equivariant machine learning is to generate
a complete basis that exhibits permutation and G-equivariance which spans the target func-
tion space. Concretely, we will consider the construction, efficient evaluation and numerical
properties of equivariant bases of polynomials.
An important application of equivariant machine learning models is the parameterization of
potential energy surfaces [13, 27]. An early proposal for the parameterization of permutation
invariant potential energy surfaces with polynomials can be found in [9]. Another approach
called aPIPs (atomic body-ordered permutation-invariant polynomials) [34] generalized this idea
to much higher order body interactions. In practice, invariant theory and symbolic computation
allow for the use of invariant polynomial bases of up to around body order 5. In 2019 Drautz
[14] introduced a framework called the Atomic Cluster Expansion (ACE), which falls under this
family of methods but allows for the efficient parameterization of much higher body orders than
aPIPs. A key computational ingredient of ACE is that the canonical many body expansion is
transformed into the self-interacting expansion by interchanging a summation and a product
operation, resulting in symmetric tensor product basis functions which are more efficient to
evaluate at the cost of introducing physically undesired terms. The construction also allows
explicit symmetrization with respect to the orthogonal group with a sparse linear operator.
Aside from applications in the parameterization of potential energy surfaces and activate
learning for molecular dynamics [35], ACE has also been used for the parameterization of wave
∗Department of Mathematics, University of British Columbia, Vancouver, V6T1Z2, BC, Canada
1arXiv:2401.01550v2  [math.NA]  5 Jan 2024functions for the Schr¨ odinger equation [15, 42] and Lorentz group invariant polynomials for jet
tagging [26]. In [6], a message passing neural network was introduced to attain state-of-the-art
accuracy based on the systematic and theoretically sound model architecture motivated from
ACE. More recently, [5] extended these ideas to a general reductive Lie group G. The success
of the ACE approach motivated the discussion of its theoretical properties from a numerical
analysis point of view in [16, 3] as well as our present investigation of the ACE basis and
potential improvements to its approximation properties in this paper.
The canonical many body expansion which underpins the derivation and motivation of the
self-interacting ACE expansion is generally not considered in practice since the cost of naive eval-
uation of the corresponding basis functions scales combinatorially with the input dimension and
thus results in computationally intractable algorithms. This paper’s primary focus is to show
that under mild conditions one canefficiently evaluate of the canonical cluster expansion and
that this is in fact equivalent to a special regularization choice in the widely used self-interacting
expansion. Since the canonical expansion has been considered computationally intractable prior
to this work (with the exception of a brief comment in [16]) despite being chemically and phys-
ically better motivated, the in-practice differences between the two expansions have remained
under-explored. Thus, as far as we are aware, our current work also presents the first in-depth
exploration of the canonical expansion.
After describing in detail how to efficiently evaluate the canonical expansion in Section 2
we conduct a practical review of its spanning space compared to the self-interacting expansion,
supplementing the results of previous work such as [5, 16]. Importantly, we demonstrate that
our framework respects symmetric sparsification for the Euclidean group, which is of major
interest in applications. We present numerical experiments for simplified academic examples
in Section 3 and applications in the machine learning of interatomic potentials in Section 4,
showing that the canonical cluster expansion produces models with better physical properties
for applications such as molecular dynamics simulations. Additionally, we observe that the
canonical expansion appears less sensitive to the regularization parameter in regression tasks
which favours hyper-parameter tuning. While we demonstrate several noteworthy qualitative
advantages of the canonical basis, we also observe that the two expansions do not appear to
show dramatic differences in the sense of the prediction error in regression tasks as demonstrated
in Section 3 in a practical but relatively simple point cloud setting. We view this as additional
evidence that the efficient self-interacting expansion in previous works is well suited to the
problems it is used for. On the other hand, when regressing symmetric functions with fixed
dimensionality, the canonical basis is clearly superior in all our tests.
2 Theory
2.1 Two cluster expansions of point clouds
Let Ω be a configuration domain for particles denoted by xj. A particle is a point in Rd
decorated with additional properties such as chemical species, spin, or charge. For example, an
atom in a molecular dynamics simulation could be described by position and chemical species,
i.e.xj“ prj, Zjq PR3ˆZ. An electron in a variational Monte-Carlo simulation would be
described by position and spin, xj“prj, σjqPR3ˆtÒ,Óu. A particle configuration (commonly
also called a point cloud ) is a multi-set on Ω, denoted by X“ttxjuuJ
j“1, where each xjPΩ and
JPN. We denote the set of all multi-sets on Ω by MS pΩq.
Many applications [32, 23, 24, 31, 37] are concerned with approximating a multi-set function
V: MSpΩqÑF, (1)
2where FPtR,Cu. The restriction to scalar-valued functions is only for the sake of notational
simplicity; we explain in Section 2.4.1 how to extend all our results to tensor-valued functions.
Symmetric functions with fixed dimensionality (as oppposed to multi-set functions) are implicitly
included in our framework and will be discussed in Section 2.3.
The argument Xbeing a multi-set implicitly entails that Vis invariant under a permutation
(or, relabelling) of particles xj. In addition, one often requires also invariance under a Lie-group
action, isometry-invariance being the prototypical example. Let Gbe such a Lie group acting
on Ω, e.g. G“Opdq. We say that VisG-invariant if
V˝g“V@gPG; (2)
see [32, 8, 20] and references therein. The current work focuses on the atomic cluster expansion
(ACE) framework which, in its simplest form, produces a complete linear model for G-invariant
functions defined on multi-sets. A similar construction can be used if VisG-equivariant instead.
We now review this framework in more detail, following [5, 14, 16, 38].
2.1.1 Canonical cluster expansion
The first step of the ACE framework is to perform a many-body expansion,
VpXq«VNpXq“Nÿ
N“0ÿ
j1ă¨¨¨ă jNvNpxj1,¨¨¨,xjNq, (3)
where NPN0:“NYt0uis the maximum correlation order , and the expansion components
vN: ΩNÑFare permutation invariant on the fixed dimension subspace ΩNof MSpΩq.VNis
an approximation to Vdue to both the truncation in correlation order and the parameterization
of the functions vN.
The term v0pqwithout argument is simply a constant. Each vNis now expanded using a
tensor product basis. To that end, let tϕkukPIbe a countable family of linearly independent
one-particle basis functions, i.e., ϕk: ΩÑF. Note that kdoes not necessarily have to be an
integer but could be a multi-index. We assign to each ϕka degree degpϕkq PRě0and write
degpϕkq“degpkqwhen there is no confusion. Throughout this work we assume that there is a
natural total ordering of ϕkthat is consistent with deg pϕkq.
One can then parameterize each vNwith finitely many k,
vNpx1,¨¨¨,xNq“ÿ
k“pk1,¨¨¨,kNqckNź
t“1ϕktpxtq. (4)
Permutation-invariance of vNis guaranteed if and only if ck“cσkfor all σPSN. Note that
v0pq“cpqPF. Combining the above, we obtain newparameters ck1,¨¨¨,kNsuch that
VNpXq“Nÿ
N“0ÿ
k“pk1,¨¨¨,kNq
korderedckAkpXq, (5)
where “ordered” means lexicographic ordering, and the Akbasis is defined by
Ak“Ak1,¨¨¨,kNpXq:“ÿ
j1‰¨¨¨‰ jNNź
t“1ϕktpxjtq. (6)
3We call (5) the canonical cluster expansion . This is to contrast it with the self-interacting
formulation that was introduced in [14] to overcome the prohibitive combinatorial scaling of the
computational cost of evaluating (5) and which we discuss in the next section. After having
introduced the self-interacting version, we will return to the canonical formulation in Section 2.2
to show how to make it equally computationally tractable.
While (5) highlights the many-body expansion aspect, it is usually more convenient to employ
the more compact expression
VNpXq“ÿ
kPKckAkpXq, (7)
where Kis a finite set of ordered tuples pk1, . . . , k Nqwith 0ďNďN. We also say that Akis
of order N, denoted by ord pkq, ifk“pk1,¨¨¨, kNqis of length N.
2.1.2 Self-interacting cluster expansion
The computational cost of evaluating the basis Akscales as`J
N˘
due to the naive summation over
all unique clusters of Nparticles chosen from Jparticles. To obtain a computationally efficient
formulation, Drautz [14] proposed allowing self-interaction terms in the many-body expansion,
UNpXq“Nÿ
N“0ÿ
j1,¨¨¨,jNuNpxj1,¨¨¨,xjNq. (8)
In contrast with (3) the summationř
j1,...,jNis taken over repeated clusters as well as spurious
clusters where one or more particles may be repeated. We therefore call (8) the self-interacting
cluster expansion. It is sometimes suggested [14, 16] that this is equivalent to the canonical
formulation (3) but we will show in Theorem 2.1 that after discretization this is only true under
specific conditions on the basis.
The tensor product structure in the N-dimensional sums in (8) can be utilized to obtain a
computationally efficient parameterization. Proceeding as above by expanding the uNterms in
a tensor product basis and then interchanging summation we obtain
UNpXq“Nÿ
N“0ÿ
k“pk1,¨¨¨,kNq
korderedckAkpXq, where (9)
Ak1,...,k NpXq:“ÿ
j1,¨¨¨,jNNź
t“1ϕktpxjtq“Nź
t“1Jÿ
j“1ϕktpxjq. (10)
Substituting
AkpXq“Jÿ
j“1ϕkpxjq, AkpXq“ź
tAktpXq, (11)
we observe that the evaluation is comprised of two stages: (i) a pooling operation at an OpJq
cost per feature Akand (ii) the N-correlations OpNqcost per feature Ak. As a matter of fact,
in most scenarios the latter can be reduced to Op1qcost per feature as explained in [28].
2.2 Efficient Evaluation of the Canonical Cluster Expansion
We now discuss our main theoretical results: exposing and analyzing an efficient evaluation
algorithm for the canonical cluster expansion. The overarching idea is to construct a “purifi-
cation operator” which transforms the self-interaction expansion to the canonical expansion.
4The potential for such an algorithm was hinted at in [16], but no details or detailed analysis of
the purification operator were given. We also note that much of the construction which follows
could be directly applied without the symmetrization step to generate a permutation invariant
function on MS pΩq, or a subspace of MS pΩqcontaining only a fixed number of particles, which
will be discussed further in Section 2.3.
For illustrative purposes, we first demonstrate the procedure for a two-correlation. Notice
thatAk1k2can be rewritten as
Ak1k2“ÿ
j1‰j2ϕk1pxj1qϕk2pxj2q`ÿ
jϕk1pxjqϕk2pxjq“Ak1k2`ÿ
jϕk1pxjqϕk2pxjq,
or, conversely,
Ak1k2“Ak1k2´ÿ
jϕk1pxjqϕk2pxjq.
A key assumption of our following construction is that the pointwise product ϕk1pxjqϕk2pxjq
can be re-expanded, or linearized as this operation is commonly called, in a finite sum,
ϕk1pxjqϕk2pxjq“ÿ
κPk1k2
κϕκpxjq, (12)
with linearization coefficients Pk1k2κ. This assumption is natural for polynomials, including
trigonometric polynomials and spherical harmonics; cf. Section 2.4. Using (12) we immediately
obtain
Ak1k2“Ak1k2´ÿ
jÿ
κPk1k2
κϕκpxjq“Ak1k2´ÿ
κPk1k2
κAκ. (13)
We note here that for a finite index set Kin (7) and k1, k2PK, the summation over κhas to
be closed in Kso that the purification (13) can be done while only evaluating basis functions
corresponding to indices in K. Expanding on this idea one can obtain the following result.
Theorem 2.1. LetKbe a finite ordered index set. Suppose that any pointwise product of
ϕk1pxqϕk2pxqcan be linearized exactly in terms of a finite sum of ϕκpxq(12). Then there exists
aK1ĄKsuch that spanptAk1uk1PK1qĄspanptAkukPKq.
The proof is given in Appendix A, where we also derive a recursion (Eq. (43)) analogous
to (13) which allows the explicit construction of K1. Building on the above theorem we obtain
the following corollary declaring the existence of the desired purification operator. Its practical
implementation is discussed in Section 2.2.1.
Corollary 2.2. Under the conditions in Proposition 2.1, for each kPK,Akcan be expressed
uniquely as a linear combination of the tAk1uk1PK1basis. That is, there exists a unique linear
operator P“pPk
k1qkPK,k1PK1, such that
Ak“ÿ
k1PK1Pk
k1Ak1. (14)
For brevity, we may simply write A“PA, where A“tAk1uk1PK1andA“tAkukPK.
Remark 2.3. As stated in [14] and [16], following their construction, with the decomposition
AkptrjuJ
j“1q“Akprj1,¨¨¨,rjNq`WN´1ptrjuJ
j“1q, (15)
WN´1is then of correlation order N´1and can be absorbed by basis terms of order less than
or equal to N´1. However, in many cases Kis not rich enough for such an absorption;
5we give explicit examples in Section 4 and Table 2. To obtain the canonical expansion via
a linear purification, one has to extend Kas discussed in Theorem 2.1. In those situations,
spanptAkukPKq‰spanptAkukPKq. In the setting of a complete (infinite basis) basis, they are
formally always equivalent.
Two natural questions regarding the efficiency of applying the purification operator Parise:
(1) how does K1depend on Kin (14), e.g. how much larger is it; and (2) how sparse is the
purification matrix, i.e., how many of the entries Pk
k1will be non-zero in (14)? The following
two propositions (see Appendix B for proofs) provide partial answers and illustrate that the
purification can be performed efficiently.
The next proposition illustrates the fact that the purification of Akpreserves properties of
the linearization of products of ϕk. Extending the definition of degree on AkandAknaturally
as degpAkq“degpAkq“degpkq“ř
tdegpktq, fork“pktqt, one obtains the following result.
Proposition 2.4. Suppose that the linearization is total-degree preserving,
ϕk1ϕk2Pspan␣
ϕκ|degpκqďdegpk1q`degpk2q(
@k1, k2. (16)
Then, the purification (14) is also total-degree preserving; that is,
Pk
k1“0 whenever degpk1qądegpkq. (17)
Note that a polynomial basis equipped with the usual definition of polynomial degree satisfies
(16). Importantly, this idea is readily transferable to also show the sparsity of the purification
operator in symmetry-based sparsification in Section 2.4. Via Proposition 2.4, one can see that
Pis a triangular matrix with non-zero diagonal entries (cf. Figure 1b) K1if ordered according
the deg in (16), hence deriving a strong version of the result in Theorem 2.1.
Corollary 2.5. LetKbe a finite ordered index set. Suppose that any pointwise product of
ϕk1pxqϕk2pxqcan be linearized exactly in terms of a finite sum of ϕκpxq(12) and is total-degree
preserving (16). Then there exists a K1ĄKsuch that spanptAk1uk1PK1q“spanptAkukPK1q. In
addition, we have
K1Ă␣
k1ˇˇdegpk1qďmax
kPKdegpkq(
. (18)
Corollary 2.5 follows directly from the fact that a triangular matrix with strictly non-zero
diagonal entries is invertible and Proposition 2.4. The statement (18) follows from (17). Next
we show a general estimate on the sparsity of the transformation.
Proposition 2.6. LetKě1be a uniform bound on the number of terms in the linearization
of all ϕkiϕkj. For each kPK, letMNbe the number of non-zero Pk
k1(14), where N“ordpkq.
Then MNďN´1ś
t“1pKt`1qďKNN!.
The bound Kin Proposition 2.6 is basis dependent. For example, if particles are one-
dimensional and ϕkare Chebyshev polynomials, then K“2. For complex trigonometric poly-
nomials, K“1. For spherical harmonics, Kgrows with the maximum degree. In practice
the purification operator Pis actually sparser than the pessimistic bound in Proposition 2.6;
see Figure 1b. The sub-asymptotic behavior of the non-zero coupling coefficients (cf. Figure
1a) is attributable to the fact that overlapping non-zero terms combine in the purification (14),
which is not taken into account in the derivation of the general upper bound approximation in
Proposition 2.6; see also our discussion of Example B.1 below.
6(a)
 (b)
Figure 1: (a) Bound of non-zero terms in k1summation in (14) when using a Chebyshev basis
for embedding one-dimensional particles xjPr´1,1s; The higher the correlation order and the
lower the degree, the more the bound is overestimated. (b) Sparsity pattern of Pfor correlation
order three and total degree = 20. Black pixels indicate non-zeros; sparsity «1.48%. Pis
triangular since the Chebyshev basis is total-degree preserving 16.
2.2.1 Implementation remarks
We now provide some information how the purification framework can be implemented in prac-
tice. Populating the matrix Pcan be an expensive operation, but it needs to be done only once
in a preprocessing step, and is highly parallelizable. A prototype implementation is provided in
[1].
The first step is to evaluate the linearization coefficients Pkikjκofϕkiϕkj. For some classes of
polynomials, including the general family of Jacobi polynomials [17] and spherical harmonics [10,
39], they can be computed from known formulas. This is straightforward to generalize to
products of polynomials. However, in practice, we found it most straightforward to obtain the
Pkikjκcoefficients by solving a least squares problem,
min
Pkikj
κÿ
xPXˇˇˇÿ
κPkikj
κϕκpxq´ϕkipxqϕkjpxqˇˇˇ2
, (19)
where Xis taken as random samples from a suitable distribution that makes this problem well
posed [12]. Note that all instances of (19) for different pki, kjqpairs utilize the same design
matrix, and hence one requires only a single QR factorization. If the tϕkukPIare, to name one
important example, a set of orthogonal polynomials, then (19) can be solved in a numerically
stable and efficient manner.
As the second step we can now populate the matrix Pwhich represents the purification
operator (cf. Corollary 2.2). The first step already gives us all the entries Pk1k2
k. For Ną2
we can proceed recursively. For each order N“2,3,¨¨¨,N, we update the list of non-zero
indices in Pusing the recursion relation Equation (43). We note that these update are highly
parallelizable due to the following result, the proof of which is given in Appendix B.
Proposition 2.7. For every kof order Ně2, the purification operator entries Pk
k1, where k1
has order N1, can be non-zero only if k1“kor if N1ăN.
72.3 Orthogonal Symmetric Basis
In this section we discuss how the construction of the foregoing sections can be used to con-
struct an orthogonal basis for symmetric functions, in particular highlighting the connection
between purification and orthogonality. We now consider the simpler setting of approximating
asymmetric function f: ΩNÑF, i.e., it is invariant under permutations of its arguments,
fpx1, . . . , x Nq“fpxσ1, . . . , x σNq @ σPSN;
orf˝σ“fin short. It is straightforward to see that, if tϕkukPIis a basis for one-particle
functions, then
ApNq:“␣
Akˇˇk“pk1, . . . , k Nqordered(
,
is a basis of symmetric functions on ΩN; see [3] for a detailed discussion. The purification
operation A“PAyields an efficient evaluation scheme for this basis.
Likewise, it is easy to show [3] that the set
ApNq:“␣
Akˇˇk“pk1, . . . , k Nqordered(
forms a basis of symmetric functions on ΩNif 1Pspanpϕkq. The “self-interactions” can be
absorbed in this case, implying span pApNqq“spanpApNqq.
Suppose now that ϕkare orthonormal with respect to the L2
µpΩq-inner product,
xϕk, ϕk1yL2µpΩq“ż
L2pΩqϕkϕk1dµ“δkk1. (20)
Although ApNqandApNqhave the same spanning space provided 1 Pspanpϕkq, only ApNq
inherits the orthogonality (20): it is orthogonal (though not orthonormal) with respect the
induced L2
µbNpΩNq-inner product. For notational simplicity we demonstrate this for the special
case of N“2: ifk“pk1, k2qandk1“pk1
1, k1
2qthen
@
Ak,Ak1D
L2
µb2pΩ2q
“@
ϕk1px1qϕk2px2q`ϕk1px2qϕk2px1q, ϕk1
1px1qϕk1
2px2q`ϕk1
1px2qϕk1
2px1qD
L2
µb2pΩ2q
“2δk1k1
1δk2k1
2`2δk1k1
2δk2k1
1,(21)
which equals 0, 2 or 4 depending on the values of kandk1. Indeed, following a similar argument
in (5) and the above calculation of xAk,Ak1yL2
µb2pΩ2q(21) one can show that a series expansion of
symmetric function with ApNqis equivalent to a multivariate symmetric orthogonal polynomial
series with orthogonality L2
µbNpΩNq. In contrast ApNqis clearly not orthogonal in the L2sense,
a fact which we explore numerically in more detail in Section 3.1.
2.3.1 Regularization of cluster expansions for multisets
Our observations about orthogonality for parameterizing symmetric functions in the previous
section naturally lead to a discussion of regularization choices for atomic cluster expansion mod-
els for multi-sets. We now explore the relationship between the canonical and self-interacting ex-
pansions from the point of view of regularization, leading to the observation that one may equiv-
alently think of the purification operator in (14) as a special regularizer on the self-interacting
expansion. In what follows we consider classical Tikhonov regularizations of the form
min
c}Ψc´y}2
2`}Γc}2
2, (22)
8where Ψ is the design matrix corresponding to AorArespectively, Γ is the regularizer and
care the coefficients in the corresponding expansions. Consider an inner product for the ϕk
defined by (20). Given a maximum correlation order None can define the following natural
inner product for the canonical expansion (3) by considering each vNas an independent function
on ΩN:
xVN, V1Ny“Nÿ
N“0xvN, v1
NyL2
µbNpΩNq. (23)
We remind ourselves here that one straightforwardly finds that the canonical Akbasis is or-
thogonal with respect to the inner product in the sense of (21). We can thus assume without
loss of generality that Akis orthonormal with respect to this inner product, as we can always
rescale the basis. With Akassumed orthonormal the Tikhonov regularization term with Γ “I
is found to simply be
}c}2
2“ÿ
kc2
k`ÿ
k1,k2c2
k1,k2`¨¨¨ÿ
k1,¨¨¨,kNc2
k1,¨¨¨,kN
“}v1}2
L2µpΩq`¨¨¨`} vN}2
L2
µbNpΩNq,
which is consistent with the inner product in (23). An analogous definition for the self-interacting
expansion yields an inner product
xUN, U1Ny“ż
L2pΩqu1¯u1
1pxq`u2¯u1
2px, xq`¨¨¨` uN¯u1
Npx,¨¨¨, xqdµ
`ż
L2
µb2pΩ2qu2¯u1
2px1, x2q`¨¨¨`ż
L2
µbNpΩNquN¯u1
NdµbN.
However, applying Γ “ITikhonov regularization for the self-interacting basis one also obtains
a Tikhonov term of the form
}c}2
2“}u1}2
L2µpΩq`¨¨¨`} uN}2
L2
µbNpΩNq, (24)
where the self-interacting terms in xUN, U1Nyare completely absent. This discussion motivates
an alternative view of the linear purification operator PwithA“PAin (14) as a regularizer
in the Tikhonov sense: To regularize UNin the sense of inner products of VN, we may set
Γ“P´Jsuch that all self-interacting terms are accounted for. We explore the improved
behavior resulting from this alternative regularization choice in the self-interacting basis in
the numerical experiments in Sections 3 and 4, where among other results we show that the
purification regularizer Γ “P´Japplied to the self-interacting expansion produces equivalently
improved results as using the canonical expansion.
As a final remark, we note that while we used Γ “Ifor the above observation for simplicity,
it is straightforwardly generalized to the case where Γ is any invertible diagonal matrix which
notably includes the important case of the smoothness prior which we discuss in more detail in
the numerical experiments in Section 3.
2.4 Purification and G-Symmetrization
The discussion up to this point suggests that the canonical cluster expansion basis Akcan
be evaluated efficiently in a way that overcomes the naive Op`J
N˘
qcost. However, in practice
one usually applies a further transformation of the Akbasis to impose a Lie group symmetry
[16]. This typically results in a structural sparsification of A. In the following paragraphs,
9we demonstrate that the purification operator preserves many aspects of this symmetry-based
sparsification, analogous to Proposition 2.4. We will focus on the orthogonal group Opnqwith
nď3 (the most common cases for applications) and consider an index set KD
N, where Dis a
given bound on the total degree deg pkqandNis the maximum correlation order.
2.4.1 Review of G-symmetrization
Suppose that a target function we wish to approximate satisfies the G-invariance (2), then it
would be preferrable in many scenarios if the approximation scheme can exactly preserve this
invariance. We therefore review how to extend the ACE construction to an invariant basis.
In the abstract we assume that ϕkis chosen such that we have a representation ρ“pρkk1q
of the group action,
ϕk˝g“ÿ
k1ρkk1pgqϕk, (25)
where gPGand for each kthe sum over k1is a finite sum. For all classical Lie groups, such
representations are known. Then Ak1andAk1can be symmetrized to obtain the invariant Bα
orBαbases (i.e., Bα˝g“BαandBα˝g“Bα),
Bα:“ÿ
k1Cα
k1Ak1, and Bα:“ÿ
k1Cα
k1Ak1, (26)
where Cα
k1are sometimes called generalized Clebsch–Gordan coefficients and the indices αare
simply indexing all possible invariant basis functions that can be generated by symmetrizing
Ak1orAk1. We refer to [16, 5, 7] for the details of this construction.
This construction forms the basis of a number of highly successful machine learning archi-
tectures thanks to its flexibility which allows a vast design space, from linear models [16, 22]
and a straightforward extension to non-linear forms [14, 30] to models using message passing
neural networks [6, 4]. This leads to a wide range of applications of ACE including featurization
for jet-tagging [26], parameterization of wave functions [15, 42], learning Hamiltonian operators
[41] and modeling molecular dynamics for materials and molecules [6, 25, 21].
A convenient feature of our proposed purification framework is that the symmetrization and
the purification operations are both represented as sparse matrix multiplications and hence can
be merged into a single sparse matrix operation. More precisely, we can pre-compute sparse
matrices C,PandCp“C¨P, such that
B“CPA“:CpA, (27)
where A“tAk1uk1PK1andB“tBαuα.
2.4.2 Effect of symmetrization for G“Op1q
A function is Op1qinvariant if it is invariant under reflection through the origin. We consider
this simple case before moving on to the more challenging Op2qandOp3qcases. We assume that
particles belong to the closed interval Ω “r´ 1,1sand use the set of monomials as one particle
basis, i.e.,
ϕkpxq“xk. (28)
The group Op1qconsists of only two elements: the identity g1x“xand the reflection g´1x“´x.
We have the representation ϕk˝gσ“σkϕk. From this observation it can be readily seen that
the symmetrization becomes simply a filtering operation, i.e., we can identify the invariant basis
10indices αwith all those tuples α“ksuch thatřk:“ř
kPkkis even. An Op1q-invariant
parameterization can now be simply written as
VNpx1,¨¨¨,xJq“ÿ
řk“evenckAkpx1,¨¨¨,xJq. (29)
Therefore, the index set of interest in the many-body expansion is reduced to
K:“KD
NX␣
kˇˇřk“even(
. (30)
Observe that the linearization of ϕkϕk1contains only a single term ϕk`k1with k`k1PKD
N. We
also note that the condition (16) in Lemma 2.4 is satisfied and the result applies. In this case
we have
ϕk1ϕk2Pspantϕκ|degpκq“degpk1q`degpk2qu. (31)
Following the proof of Proposition 2.4 one can similarly observe that the linearization (14)
with monomials is exactly total-degree preserving. In other words (14) can be performed with
indices k1such that deg pk1q “ degpkq. Importantly, the number of non-zero entries of the
transformation Phits exactly the lower bound of the proven estimation in Proposition 2.6 (i.e.
K“1), attaining the best possible sparsity.
2.4.3 Effect of symmetrization for G“SOp2q
We now consider another academic example, taking G“SOp2qand Ω the unit circle. This
setting can equivalently be understood as the translation group on the torus. Thus, we take
Ω“T“p´ π, πs,
supplied with periodic boundary conditions. The translation group Gcan be identified with T
itself. To emphasize the connection with the unit circle and the rotation group we write x“θ.
We then define the one-particle basis
ϕkpθq“eikθ, (32)
where kPZ. For any gθ0PGwe have the representation
ϕk˝gθ0“eikθ0ϕkpθq.
To satisfy invariance, the symmetrization once again becomes a simple filtering operation. To
see this more clearly, we have:
Nź
t“1ϕktpθt`θ0q“Nź
t“1eiktθ0ϕkt“eipřkqθ0Nź
t“1ϕktpθtq.
Hence, the invariant basis indices αare tuples ksuch thatřk“0. Consequently, multi-set
functions VNwhich are permutation and SOp2qinvariant can be parameterized by
VNpθ1,¨¨¨, θJq“ÿ
řk“0ckAkpθ1,¨¨¨, θJq. (33)
Analogous to monomials in the Op1qcase, the linearization of ϕkϕk1contains only a single term
ϕk`k1with k`k1PKD
N(i.e. it is exactly total degree preserving). By a similar observation as
in Section 2.4.2, following the proof of Proposition 2.4, one can show that every non-zero term
Pk
k1in the purification satisfiesřk1“0. This entails that the purification can be performed
with only basis elements from the index set of interest K:“KD
NX␣
k|řk“0(
and again
the number of non-zero entries of the transformation Pattains the lower bound of the proven
estimate in Proposition 2.6.
112.4.4 Effect of symmetrization for G“Op3q
Finally, we turn to the case of isometry invariance in three dimensions, i.e. G“Op3q, which is
the most relevant for applications.
Following [14, 16], we use the one particle functions ϕnlm: ΩÑCdefined by
ϕnlmprq“RnprqYm
lpˆ rq, (34)
where Ω“ r0, rcutsˆS2ĂR3with rcutą0. Here r“ |r|,r“rˆ randk“ pn, l, mqis a
multi-index. In (34) tRnunPN0is a basis of linearly independent polynomials on r0, rcutsandYm
l
are standard complex spherical harmonics [32, 18]. It is possible to generalize the construction
to allow radial bases Rnl(e.g., three-dimensional Zernike polynomials), but we omit this as it
introduces additional notational complexity.
From the representation of spherical harmonics, following [16], any permutation and Op3q
invariant multi-set functions VNcan then be parameterized by
VNpr1,¨¨¨,rJq“ÿ
nřl“evencnliÿ
řm“0Cnli
mAnlmpr1,¨¨¨,rJq
“:ÿ
n,l,i:řl“evencnliBnlipr1,¨¨¨,rJq,
where ienumerates all possible symmetric couplings of the generalized Clebsch–Gordan co-
efficients [16] and Cnli
mare constructed from the representation of the spherical harmonics
[14, 16, 28]. The constraintřl“even andřm“0 are, respectively, due to the reflec-
tion symmetry and rotation symmetry. This corresponds to α“pnliqin (26), which entails the
index set of interest,
K:“KD
NX␣
pn,l,mqˇˇřm“0,řl“even(
, (35)
where degpkq“degpnlmqis defined as the sum n`land degpkqcan be naturally extended asř
tnt`lt. In this setting, since |m|ďl, it is common to not include min the definition of total
degree. This also ensures that the basis is closed under the symmetrization operator.
As in Sections 2.4.2 and 2.4.3, the key to showing that no additional basis functions are
needed for purification lies in the properties of the linearization of ϕn1l1m1ϕn2l2m2.
The following proposition is a special case of Corollary 2.2 when K“K1.
Proposition 2.8. With definition of ϕnlmandKin(34) and(35), for each kPK,Akcan be
expressed uniquely as a linear combination of the tAk1uk1PKbasis. That is, there exists a unique
(invertible) linear operator P“pPk
k1qkPK,k1PK, such that
Ak“ÿ
k1PKPk
k1Ak1. (36)
Proof. We first show that any product of ϕn1l1m1prqϕn2l2m2prqcan be linearized exactly in
terms of a finite sum of ϕκprq(12) with κPK. Let ϕn1l1m1“Rn1Ym1
l1andϕn2l2m2“Rn2Ym2
l2.
SincetRnunPNis a basis of polynomials, there exist finitely many Pn1n2ν such that Rn1Rn2“ř
νPn1n2νRν. Then the linearization coefficients can be obtained by expanding Pn1n2ν and the
Clebsch-Gordon coefficients CLM
l1l2m1m2from the contraction rule of spherical harmonics [10, 39].
Therefore, Corollary 2.2 applies. It remains to show that K“K1. The total degree preserving
property follows from the fact that the expansion over radial basis and spherical harmonics
preserves the total degree. Conservation ofřm“0 follows from the fact that CLM
l1l2m1m2is
12non-zero only if m1`m2`M“0, with similar deduction as in Section 2.4.3. Forřl“even, we
first notice that CLM
l1l2m1m2is non-zero only if l1`l2`L“0. This entails that the linearization
of any ϕk1ϕk2preserves parity over the lindex, precisely:
ϕn1l1m1ϕn2l2m2Pspantϕnκlκmκ|l1`l2”lκmod 2u. (37)
By a similar argument as in Proposition 2.4, one can see that the purification (14) can be
performed with indices preserving the original parity. Therefore, no basis outside Kare needed
for the transformation.
3 Numerical Experiments: Academic Examples
In this section we present numerical experiments comparing basic properties of the canonical
and self-interacting atomic cluster expansions including conditioning, effect of regularization
choices and coefficient decay in the simplified regression context. We defer comparisons in the
context of machine learning interatomic potentials, the primary application of the atomic cluster
expansion framework, to Section 4.
3.1 Conditioning of the gram matrix
In this section we explore the conditioning of the gram matrix for the canonical and self-
interacting bases when G“Op3q(cf. Section 2.4.4), the most interesting case for applications.
Following the discussion in Section 2.3.1 and using the fact that Bnliis simply an orthogonal
transformation of Anlmthe condition number of the gram matrix of the Bnlibasis with re-
spect to the standard L2inner product should be 1 (up to diagonal scaling) when N“J. We
present a numerical comparison of the obtained condition numbers for the gram matrices of
the respective bases in Table 1. Each sample X“ttxjuuJ
j“1is drawn independently from µbJ
where µis chosen such that xϕnlm, ϕn1l1m1yL2µpΩq“δnn1δll1δmm1, where Ω“r0, rcutsˆS2as in
Section 2.4.4. For each total degree, p70ˆbasis sizeqdata samples are used to form the full
design matrix. The submatrices corresponding to each order Nare then extracted to compute
the gram matrix, followed by a scaling with respect to the diagonal of each submatrix. We
observe that the condition numbers of the Bnlibasis are all close to 1 and the improvement in
conditioning is substantial when compared with the self-interacting Bnlibasis. Similar behavior
is observed for JąNbut the significance of the effect decreases as Jincreases with fixed N, as
seen in Figure 2. The critical point observed in the condition number corresponding to the gram
matrix of the self-interacting expansion in Figure 2 is observed to be present even without the
diagonal rescaling of the Gram matrix. We have no satisfactory explanation for this observed
phenomenon.
3.2 Coefficient decay
In the context of function approximation, the coefficient decay of a polynomial approximation is
widely used as a proxy for error estimation, especially in the absence of other metrics. A note-
worthy feature of orthogonal polynomial expansions is their predictable exponential coefficient
decay for sufficiently well-behaved functions, which we investigate numerically for the canonical
and self-interacting atomic cluster expansions. We define the following difficult to approximate
test functions with aą0 and xPr´1,1sJ(though we take J“Nin the initial tests):
fapxq“1
1`a}x}2, (38)
13Total degree 10 12 14 16
N“2 Canonical 1 .3ˆ1001.3ˆ1001.3ˆ1001.2ˆ100
Self-interacting 1 .8ˆ1023.8ˆ1027.8ˆ1021.2ˆ103
N“3 Canonical 1 .6ˆ1001.4ˆ1001.6ˆ1001.5ˆ100
Self-interacting 1 .3ˆ1035.7ˆ1031.6ˆ1044.8ˆ104
N“4 Canonical 1 .6ˆ1001.6ˆ1002.1ˆ1002.2ˆ100
Self-interacting 1 .0ˆ1031.2ˆ1047.1ˆ1043.6ˆ105
N“5 Canonical 1 .9ˆ1002.2ˆ1002.2ˆ1002.9ˆ100
Self-interacting 4 .8ˆ1024.6ˆ1036.3ˆ1044.7ˆ105
N“6 Canonical 1 .7ˆ1002.0ˆ1002.6ˆ1003.8ˆ100
Self-interacting 6 .5ˆ1012.6ˆ1031.9ˆ1042.0ˆ105
Table 1: Condition numbers for gram matrices of the self-interacting and canonical bases with
indicated total degree and basis sizes using the default parameters in ACE1x.jl ,N“6 and
p70ˆbasis sizeqdata samples to form the design matrix and extract the corresponding order
N. A diagonal scaling is applied s.t. the expected canonical condition numbers are 1.
(a)N“2
 (b)N“3
 (c)N“4
Figure 2: Change of gram matrix condition numbers of the canonical and self-interacting bases
with total degree 14 for the indicated basis orders. A diagonal scaling is applied to the gram
matrices consistent with Table 1.
fais a multi-variate generalization of the Runge function, a famously ill-conditioned function
to approximate with polynomials. Notice that fais permutation invariant and analytic on the
N-dimensional hypercube r´1,1sNand increasingly difficult to approximate with increasing a,
making them good test cases for the discussed ACE bases.
It was shown in [33] that the natural notion of degree for problems of this kind is not the
total degree but the Euclidean degree , defined by
euclpkq:“`ř
kPkk2˘1{2.
that is, the coefficients decay as Opρ´euclpkqq, for some ρą1.
In Figure 3 we show representative examples of the observed coefficient decay. Comparing
the two bases in this way, we observe that the slowest decaying coefficients corresponding to the
product terms in the self-interacting basis are resolved with improved decay in the canonical
expansion. Furthermore, while both bases notably show exponential coefficient decay, as seen
by the linear behavior on the semi-logarithmic plots, the canonical basis agrees better with the
decay behavior expected from quasi-optimal N-dimensional Chebyshev polynomial expansions
[33] indicated in Figure 3 by a dashed line.
14This can potentially be exploited in effectiveness of sparsification and of regularization via
a smoothness prior, as we demonstrate in the next section.
(a)N“J“2
 (b)N“J“3
Figure 3: Coefficient decay in the canonical and self-interacting bases for f25as defined in
(38). All data was sampled independently from a tensor product of distributions with density
1?
1´x2overr´1,1sNand regressed against an N–dimensional ACE basis. The coefficient decay
estimate was obtained following [33] and is the same in (a) and (b).
3.3 Regularization, smoothness priors and the Runge effect
Priors and regularization are of critical importance for applications involving linear models
[34, 38]. In this section we explore the effects of regularization on the two discussed ACE bases
and observe that smoothness priors in particular produce better results with the canonical basis.
To observe the effects of regularization numerically we again use the difficult to resolve functions
defined in (38). We use classical Tikhonov regularization throughout this section, that is we
minimize systems of the form
min
c}Ψc´y}2`λ}Γc}2, (39)
where Ψ is the design matrix, ythe target values, Γ is a regularizer, care the desired coefficients
or model parameters and λis a hyperparameter over which we optimize in the range p10´15,103q
using a logarithmic grid search. The regularization choices we consider in this section are the
identity prior Γ “Iand a diagonal regularizer of the form
Γkk“γpkq. (40)
Taking γincreasing with increasing frequency (e.g., polynomial degree) of the basis, such a reg-
ularizer encourages smoothness of the fitted target function and is therefore called a smoothness
prior . The chosen growth in the smoothness prior parameter γenforces a corresponding asymp-
totic coefficient decay incas readily seen by inspecting the Tikhonov term in (39), see also the
discussion of coefficient decay in the previous section. A common alternative motivation for the
smoothness prior relates it to the gradients ∇pϕk[34].
In Section 2.3.1 we discussed the relationship of these two regularization choices with the
canonical and self-interacting basis respectively and showed that they can be rigorously moti-
vated for the canonical basis only, leading to the natural conjecture that they would perform
better in that context. In the experiments below we use Chebyshev and Legendre polynomials,
15i.e.ϕkpxq “Tkpxq, where Tkare Chebyshev or Legendre polynomials of degree k, to con-
struct the self-interacting and canonical expansions along with smoothness priors as in (40)
with γpkq“ř
tp1`ktq2. This choice is made in order to avoid assuming prior knowledge on the
coefficient decay of the target function but in practice other more aggressive regularizers may
be used.
Figure 4 shows some representative examples of the RMSE for approximations of the func-
tions in (38) obtained via a Tikhonov regression when N“J“4, while Figure 5 shows
examples for the maximum error under identical setting. Several interesting observations can
be made from Figures 4 and 5 which appear to hold with some generality. First, analogous
to classical approximation theory results we find that Chebyshev distributed sampling leads
to improved errors in both the canonical and self-interacting basis compared to uniformly dis-
tributed data. While neither Chebyshev nor uniformly distributed data are very likely to be
encountered in a practical application setting, a uniform distribution more closely corresponds
to the expected generic approximation theoretic behavior of real data as opposed to the very
special case of Chebyshev nodes. As such, the improved behavior observed for the canonical
basis in the uniformly distributed cases is noteworthy.
Figure 5 also includes the different regularization of the self-interacting basis suggested by the
discussion in Section 2.3.1, demonstrating that instead of a change of basis one can equivalently
make a special choice of regularization based on the purification transform to obtain the observed
improvements. As seen in Section 2.3.1, this equivalence is general and not limited to the
numerical experiments discussed in this section. Depending on implementation details this may
in fact be the more attractive option in many scenarios as a change of regularizer is usually a
trivial drop-in replacement compared to a change of basis.
We observe in Figure 6 that the smoothness prior outperforms the identity prior and the
canonical basis outperforms the self-interacting basis when smoothness priors are applied to
both. Similar observations were made for a simple extension of the JąNRunge function in
Figure 6c and 6f.
To further examine the performance of the canonical and self-interacting expansions in terms
of the RMSE in regression tasks we consider the following test function Fa,ϵ:RJÑRdefined
by
Fa,ϵpxq“ÿ
xĂxfapxq`ϵJź
i“1xi, (41)
where fa:RNÑRis defined as in (38) andř
xĂxdenotes the sum over all unique “sub-clusters”
txj1, . . . , x jNuof length N. For ϵą0 this test function has qualitative similarities to the form
of site energies in the context of interatomic potentials with a higher-body-order terms that the
model cannot resolve.
Figure 7 shows the learning curves (RMSE) for approximating example functions of the form
(41) for J“8 and N“4 with uniformly distributed data over a range of values for aandϵ,
using Tikhonov regression. We observe that the two described bases perform similarly in all
tested cases. The reason for the marked difference to the observed behavior in Figures 6c and
6f is that, while approximating faof fixed dimension Jusing a basis with JąNcan be viewed
as a truncation of an approximation of order J, no notable Runge phenomenon seems to occur
forFa,ϵ. This suggests that the self-interacting expansion has similar performance in terms
of regression task errors for multi-set functions. This observation is also consistent with the
condition number tests of Section 3.1.
16(a)f5, distribution with density 1 {?
1´x2
 (b)f5, uniform distribution
Figure 4: RMSE when approximating the functions f5in (38) with the indicated basis functions
of total degree 30 and differently distributed data.
(a)f5, distribution with density 1 {?
1´x2
 (b)f5, uniform distribution
Figure 5: Maximum error when approximating the functions f5in (38) with the indicated basis
functions of total degree 30 using the uniform distribution with identical setting as in Figure 4.
17(a)f5with N“J“4
and smoothness prior
(b)f5with N“J“4
and identity prior
(c)f1with N“4,J“5
and smoothness prior
(d)f5with N“J“4
and smoothness prior
(e)f5with N“J“4
and identity prior
(f)f1with N“4,J“5
and smoothness prior
Figure 6: Radial plots comparing approximations in the canonical and self-interacting bases
with the approximated function and its gradient in different settings. Comparison shows the
superior effect of the smoothness prior for the canonical basis as well as better performance of
the smoothness prior compared to a simpler Γ “Iidentity prior. We use f1in (c) and (f)
instead of f5to reduce the difficulty of the regression and obtain a meaningfully accurate fit.
(a)F1,0
 (b)F5,0
 (c)F25,0
(d)F1,0.1
 (e)F5,0.1
 (f)F25,0.1
Figure 7: RMSE when approximating the function Fa,ϵin (41) with indicated aandεusing the
uniform distribution with the indicated basis functions of total degree 30.
184 Application to machine learning interatomic potentials
The original and still primary application of the (self-interacting) atomic cluster expansion has
been the parameterization of machine learning interatomic potentials (MLIPs) [38, 14, 36, 16].
In this section we demonstrate the advantages of replacing the standard self-interacting ACE
formulation with the canonical cluster expansion in this application.
4.1 Review of ACE for MLIPs
The task is the parameterization of the potential energy Epttri, ZiuuNat
i“1qof an atomic structure
ttri, ZiuuNat
i“1ĂR3ˆZ, where riandZiare, respectively, the position and atomic number of
atom i. For the sake of simplicity, we will only consider elemental systems, hence we ignore
the atomic number; an atomic structure then becomes simply a point cloud ttriuuNat
i“1ĂR3.
Furthermore, we will ignore periodic boundary conditions which are commonly employed in
this setting. (Although they do appear in the datasets we use below, they are unimportant to
explain the model parameterization via ACE.)
Within the ACE framework the potential energy surface is not parameterized directly but
it is first decomposed into site energies,
E`
triuNat
i“1˘
“Natÿ
i“1ε`␣ ␣
rij( (
j„i˘
where εis called the site energy potential ,rij“rj´riandj„iif|rij| ărcut. The cutoff
radius rcutą0 is a model hyperparameter which we take as fixed. The spatial decomposition
into site energies can be thought of as a physical constraint, or prior [11, 29]. The reason to
parameterize εinstead of Edirectly is size-extensivity of the model. We can guarantee Ep3q
invariance (Euclidean group) of Eby enforcing Op3qinvariance of ε.
Since the distance between atoms changes during a simulation, the atomic environment
ttrijuuj„iof an atom iis a multi-set. Setting Ω ĂR3to be a ball with radius rcutandxj:“rij
brings us into the general abstract context of the foregoing sections to parameterize εvia the
canonical or self-interacting Op3q-invariant cluster expansion. To specify the parameterization
ofεwe will closely (but not exactly) follow the construction in Section 2.4.4.
There is a small change in the construction of the one-particle basis due to the presence of
the cutoff radius renv. Following [16, 38], to guarantee smoothness of εas atoms enter and exit
the atomic neighbourhood, we introduce an envelope function fcut. The radial basis Rnin (34)
is thus replaced by
Rnprijq“fenvpyprijqqPnpyprijqq, (42)
where yis a coordinate transform, Pnis an orthogonal basis in y-coordinate with weight
fenvpyprijqqandfenvpyprijqqis a polynomial that vanishes smoothly outside r0, rcuts. By choosing
fenvto be a polynomial (normally at most quartic) allows exact linearization of ϕn1l1m1ϕl2m2l2,
which is required for the construction of the purification operator. Further details of the radial
basis construction are given in Appendix C.1 and in [38], which also gives a more in-depth
explanation for the choice of radial basis.
After constructing the one particle basis, the general ACE framework outlined in the pre-
vious sections can be used to construct the Op3q-invariant basis Bpttrijuuj„iqand the resulting
parameterization of the site energy potential,
ε`
c;ttrijuuj„i˘
“c¨Bpttrijuuj„iq, or, ε`
c;ttrijuuj„i˘
“c¨Bpttrijuuj„iq.
19A key point to note here is that, due to the addition of an envelope function, the expansion
on the radial part is not total degree preserving (cf. Proposition 2.4), and hence two models
(canonical and self-interacting) may be no longer equivalent. We refer to Appendix C.2 for a
discussion of the effect of the envelope function on the spanning space of the two expansions.
From εwe can evaluate total energies E, and hence also forces and potentially other obser-
vations. Training datasets are notprovided in the form of atomic environment and site energy
pairs, but in the form of a list of atomic structures, and corresponding target total energies and
forces obtained from ab-initio level calculations (Kohn-Sham density function theory in all our
examples). The parameters care estimated by minimizing a mean square cost function match-
ing all available observations. Since energies and forces are linear functions of the parameters
c, this results in a linear regression problem. There are many different methods to solve such
a linear least squares problem. We will not use the very general Tikhonov formulation in (22)
and instead rescale the design matrix Ψ by Γ´1to enforce an asymptotic coefficient decay to
obtain:
min
b››ΨΓ´1b´y››2,
which we solve for given relative tolerances via a truncated SVD approach, after which we revert
the scaling via c“Γ´1b. All the experiments are performed using the ACEpotentials.jl
code [38]. We refer again to [38, 16] for further details and further discussion of the parameter
estimation.
The canonical parameterization c¨Bpttrijuuj„iqhas the potential advantage over the self-
interacting parameterization that the energy contribution from every order is separated as clearly
seen in (3). However, since the two expansions span the same or nearly the same space, it is
unclear whether this chemically intuitive property translates into actual benefits in accuracy
or qualitative properties of the fitted site energy potential ε. Our experiments in the following
section are a preliminary investigation of this question. We perform this analysis on two data
sets: the “Zou et al (2020) data set” taken from an established MLIPs benchmark [43] and a
more recent and more challenging “iron data set” published in [40].
4.2 Zuo et al (2020) data set
The Zou et al (2020) data set [43] contains data sets for six elements, Li, Mo, Ni, Cu, Si and Ge,
spanning various crystal structures (bcc, fcc, and diamond) and bonding types (metallic and
covalent). It is a relatively large dataset but with limited diversities in terms of its coverage of
the configuration space for each of these materials. Test and training data splits are provided
explicitly and are not generated randomly. In previous tests [38], we found the Mo dataset to
be the most challenging, hence we use this for our tests, but similar observations were made
on the other materials. A self-interacting and canonical model using approximately 1200 basis
functions is used (See D.1 for details) to construct the design matrix.
In our first test, we explore the data efficiency of the two parameterizations. To that end, we
plot the learning curves for both total energy and forces in Figure 8, for different regularization
parameters. The canonical model achieves only slightly better force errors and similar energy
errors as the self-interacting model. However, the canonical model is more robust in this test in
two important ways: first, it is capable of achieving the best accuracy simultaneously for energy
and forces; and secondly, its convergence is more stable under changes in the regularization
parameter.
The second part of our exploration concerns qualitative properties. A common test [25,
38] is to visually inspect the regularity of the dimer curve, since it is a one-dimensional but
chemically important quantity. Empirically, the regularity and qualitatively convex-concave
20(a) Predicted energy error
 (b) Predicted force error
Figure 8: Lerning curves for canonical and self-interacting ACE models for the Mo data set of
Zuo et al [43]. We use MAE instead of RMSE for consistency with [43].
shape of the dimer curve has been found to be directly related to the stability of molecular
dynamics simulations. In Figure 9 we plot the dimer curves (and their derivatives) for the
canonical and self-interacting ACE models, both in a low-data and large-data regime, and for
different choices of regularization parameters. With minimal regularization, even though both
models have acceptable energy and force errors on the test set, their dimer shapes are highly
oscillatory which is unacceptable in simulations [25, 38]. With sufficient regularization, both
models provide qualitatively acceptable dimer curves. However the canonical model shows
markedly smoother results (most clearly visible in subfigures c, d) and in the high-data regime
the dimer energy minimum is an accurate representation of the ground state bondlength.
4.3 Fe data set
Another example we consider is a Fe data set constructed via active learning with the Gaussian
Approximation Potential (GAP) [40]. The purpose of the GAP model was to simulate the
deformation mechanisms of the crack-tip to demonstrate the semi-brittle nature of bcc iron.
Such predictions involves a broad range of material behavior, hence the Fe dataset is very
diverse and therefore challenging to fit. In the following experiment, we follow a similar set
up as in the Zuo (2020) data set but using larger model sizes. We label a sequence of ACE
models via levels 1 through 5; higher levels correspond to larger basis sizes.; see Appendix D.2
for details. A weighted least squares system is set up using weights on individual observations
exactly as described in [40].
Since the dataset is very diverse, but there are limited structures within each subgroup, it is
more interesting to explore the convergence of the model accuracy as we increase the basis size
rather than the number of observations. This is shown in Figure 10 for a range of regularization
parameters. We observe that for all regularization parameters, the canonical model has signif-
icantly better accuracy, and the accuracy gap is particularly large for stronger regularization.
This is a very promising result since it suggests that the canonical cluster expansion parameter-
ization can be more strongly regularized (hence leading to better generalization) without losing
too much accuracy.
Secondly, we consider again the “physicality” of the fit by exploring whether the canonical
and self-interacting models are able to recover a realistic dimer curve shape. In this test, both
the canonical and self-interacting dimer curves are very smooth (likely due to the significantly
21(a) Number of observations: 6379 (20%)
 (b) Number of observations: 30455 (full)
(c) Number of observations: 6379 (20%)
 (d) Number of observations: 30455 (full)
Figure 9: Plots of the dimer and dimer derivative of Mo for the indicated number of observations.
The red vertical line indicates the nearest neighbour distance of Mo; A key observation is that
the dimer of the canonical model is smooth, repulsive and attains its minimum close to the
nearest neighbour distance, while the self-interacting model is more oscillatory.
(a) Predicted energy error
 (b) Predicted force error
Figure 10: Convergence plots of the RMSE with respect to model levels for total energy (a) and
forces (b) for the Fe data set with the indicated relative tolerances in the truncated SVD.
22more diverse dataset). Both models appear to converge stably to a chemically intuitive dimer
curve shape as the regularization parameter increases. However, similarly as for the Zuo (2020)
dataset, the canonical model still captures the potential energy minimum accurately while the
self-interacting model does not.
(a) Relative tolerance: 10´8
(b) Relative tolerance: 5 ˆ10´8
(c) Relative tolerance: 10´7
Figure 11: Dimer curves for the Fe data set with the indicated relative tolerances in the truncated
SVD. The red vertical line indicates the nearest neighbour distance of the Fe ground state crystal.
5 Conclusion
We developed a framework to transform the computationally efficient self-interacting cluster
expansion into the physically motivated canonical cluster expansion . We provided details how
to generate the transform in practice as well as an in-depth analysis of the cost of applying
the transform and of the benefits of using the canonical cluster expansion instead of the self-
interacting cluster expansion in a range of academic and realistic examples.
Our numerical evidence suggests that typical smoothness priors perform better when ap-
plied to the canonical cluster expansion and it is also less sensitive to changes in the regular-
ization parameter, allowing more efficient hyper parameter tuning. For regression of certain
ill-conditioned symmetric functions , we observe notable improvements in prediction accuracy
over the self-interacting expansion. For regression of multi-set functions the accuracy improve-
ments are relatively minor or even negligible. This is explained by the condition number tests
in Section 3.1. These observations empirically support the considerable success of the existing
ACE framework, which employs the self-interacting cluster expansion and which is normally
applied to the regression of set functions.
On the other hand, we did observe that the canonical cluster expansion can lead to improved
qualitative properties of the regressed target function. Our overall conclusion is therefore, that
the canonical cluster expansion is a worthwhile drop-in replacement for the self-interacting clus-
ter expansion in a wide variety of modeling tasks. Our results suggest that it will generally lead
to improved numerical robustness and sometimes also improved prediction accuracy. Further
insight beyond the scope of this paper can be gained by more stringent and rigorous testing
in specific application domains, in particular analyzing the effect of different regularization and
regression techniques.
Acknowledgements
This work was supported by NSERC Discovery Grant GR019381 and NFRF Exploration Grant
GR022937. TSG was also supported by a PIMS-Simons postdoctoral fellowship, jointly funded
by the Pacific Institute for the Mathematical Sciences (PIMS) and the Simons Foundation.
23Appendix
A The purification operator and conservative properties
Lemma A.1. LettϕkukPIbe a countable family of linearly independent one-particle basis func-
tions i.e., ϕk: ΩÑF. Suppose that any pointwise product of ϕk1pxqϕk2pxqcan be linearized
exactly in terms of a finite sum of ϕκpxq(12). Let AkandAkbe defined as in (6)and(10).
Then for every k“pk1, k2, . . . , k NqandkN`1, there exist coefficients PkβkN`1
κ such that
Apk,kN`1q“AkAkN`1´Nÿ
β“1ÿ
κPkβkN`1
κ Akrβ,κs, (43)
where krβ, κs:“pk1
1, k1
2, . . . , k1
Nqwith:
k1
α“#
kα, α‰β
κ, α“β.
In particular, PkβkN`1
κ are the linearization coefficients appearing in the linearization of products
of the form ϕkβϕkN`1.
Proof. By assumption, for each β“1,¨¨¨, N, there exist finitely many PkβkN`1
κ such that
ÿ
κPkβkN`1
κ ϕκpxq“ϕkβpxqϕkN`1pxq, (44)
for all xPΩ. We first notice that Apk,kN`1q´AkAkN`1is exactly the sum of all self-interacting
terms between ϕkN`1andϕkβforβ“1, . . . , N . More precisely, the self-interacting term between
ϕkN`1andϕkβreads
ÿ
j1‰¨¨¨‰ jNϕk1pxj1q. . . ϕ kβpxjβq. . . ϕ kNpxjNqϕkN`1pxjβq
for each pair pkβ, kN`1q. Now for each β, we have
ÿ
κPkβkN`1
κ Akrβ,κs“ÿ
κPkβkN`1
κÿ
j1‰¨¨¨‰ jNϕk1pxj1q. . . ϕ κpxjβq. . . ϕ kNpxjNq
“ÿ
j1‰¨¨¨‰ jNϕk1pxj1q. . .`ÿ
κPkβkN`1
κ ϕκpxjβq˘
. . . ϕ kNpxjNq
“ÿ
j1‰¨¨¨‰ jNϕk1pxj1q. . . ϕ kβpxjβq. . . ϕ kNpxjNqϕkN`1pxjβq.rbyp44qs
From the above calculation we can see thatř
κPkβkN`1
κ Akrβ,κsis exactly the self-interaction
corresponding to bases ϕkβandϕkN`1which is left from Apk,kN`1q´AkAkN`1. Therefore, by
summing over βfor each β“1,2, . . . .N , we have:
Apk,kN`1q“AkAkN`1´Nÿ
β“1ÿ
κPkβkN`1
κ Akrβ,κs,
which completes the proof.
Following from the above lemma, we now prove Theorem 2.1.
Proof of Theorem 2.1. For each kPK, by recursively expanding (43), one can readily observe
that each Akcan be expressed as linear combination of the A-basis (14). The result follows
from collecting all non-zero indices from the recursive expansion to form K1.
24B Computational efficiency of the purification transform
Proof of Proposition 2.4. The proof proceeds by induction, with the N“2 case being obtained
via (13). Assume the statement holds for order N, i.e. that for each kof order Nthe expansion
Ak“ÿ
k1Pk
k1A
is total-degree preserving. Then, for order N`1, we have
Apk,kN`1q“AkAkN`1´Nÿ
β“1ÿ
κPkβkN`1
κ Akrβ,κs
“ÿ
k1Pk1Ak1AkN`1´Nÿ
β“1ÿ
κPkβkN`1
κ Akrβ,κs
“ÿ
k1Pk1Apk1,kN`1q´Nÿ
β“1ÿ
κPkβkN`1
κ Akrβ,κs.
In the above, the indices of every term in the first summations sums up to degree ďřk`kN`1
by the induction hypothesis. The second term is a sum of the Abasis with indicesřkrβ, κs,
satisfying assumption (16) and the induction hypothesis.
Proof of Proposition 2.6. It is straightforward to observe that MNďMN´1`KpN´1qMN´1“
pKpN´1q`1qMN´1from (43). The result follows from applying this recursively.
Example B.1. To observe additional cancellations in the coefficients, we use an Ak1k2k3formed
from Chebyshev polynomials as an example. Recall that the product of Chebyshev polynomials
TmandTncan be written as a weighted sum of Tm`nandTm´n[19]. Directly applying (43)
gives
Ak1k2k3“Ak1k2Ak3´ÿ
κPk1k3
κAκk2´ÿ
κPk2k3
κAk1κ
“pAk1k2´Pk1k2
k1`k2Ak1`k2´Pk1k2
k2´k1Ak2´k1qAk3´ÿ
κPk1k3
κAκk2´ÿ
κPk2k3
κAk1κ
The part without κ-summation contributes the following non-zero indices to C:pk1, k2, k3q,pk1`
k2, k3q,pk2´k1, k3q. The remaining two summations each contribute six terms:
#
pk1`k3, k2q,pk1`k2`k3q,pk1`k3´k2q
pk3´k1, k2q,pk3´k1`k2q,p|k3´k1´k2|q#
pk2`k3, k1q,pk1`k2`k3q,pk2`k3´k1q
pk3´k2, k1q,pk3´k2`k1q,p|k3´k2´k1|q
Notice that there are duplications in indices and there are thus only at most 11 non-zero elements
(which happens when ki‰kjfor all i‰j) in total for the purification of an order 3 basis using
Chebyshev polynomials. This explains the sub-asymptotic behavior in Figure 1a.
Proof of Proposition 2.7. For clarity we write the index as pk, kN`1qand show that purification
25of an order N`1 basis only depends on Ak1basis functions of order N. By (43)
Apk,kN`1q“AkAkN`1´Nÿ
β“1ÿ
κPkβkN`1
κ Akrβ,κs
“˜
Ak´1AkN´N´1ÿ
β“1ÿ
κPkβkN
κAk´1rβ,κs¸
AkN`1´Nÿ
β“1ÿ
κPkβkN`1
κ Akrβ,κs
“Ak´1AkNkN`1´N´1ÿ
β“1ÿ
κPkβkN
κAk´1rβ,κsAkN`1´Nÿ
β“1ÿ
κPkβkN`1
κ Akrβ,κs
l jh n
ďorder N
“Ak1¨¨¨kN`1´L.O.T .
where L.O.T denotes terms of order ďNand the last line follows from recursively expanding
allAterms as in the second equality.
C The ACE model for MLIPs
C.1 Model construction
The ACE model applied throughout our experiments in Section 4 slightly differs from simply
theOp3qinvariant basis in Section 2.4.4 with an additional pair potential and is implemented as
acemodel inACEpotentials.jl [38]. More precisely, acemodel is a sum of a pair (order “1)
and many-body BorB-basis of maximum order N, where Ncorresponding to the maximum
correlation order of the potential terms, determined by the user, as in (3) and throughout the
paper. A cutoff rcutą0 is specified to enforce decay of pair as rÑrcutand of many body
terms as rÑ0 and rÑrcut. The default choice for the many-body basis is
fenvprijq“y2py´ycutq2(45)
where ycut“yprcutqandyis a coordinate transformation as in (42). The default choice of
envelope for the paired basis is a modified Coulomb potential to ensure a smooth cut off as
rÑrcutand repulsive behavior as rÑ0,
fenvprijq“´rij
r0¯´1
´´rcut
r0¯´1
`´rcut
r0¯´2´rij
r0´rcut
r0¯
.
Here, r0is an estimate of the equilibrium bond-length, which is system-dependent. We also note
here that the choice of coordinate transformation yis independent of the purification framework
and beyond the focus of this work. We refer to [38] and the documentation of ACEpotentials.jl
[2] for more details.
C.2 The effect of envelope functions
The incorporation of envelope functions results in the basis being no longer total degree deserv-
ing. Table 2 shows an example on the number of extra basis elements required for the different
sparsifications. For flexibility, an additional type sparsification, which generalize the idea of to-
tal degree, is commonly applied. One specifies a tuple of total degree D“pD1,¨¨¨, DNq, which
means that all the basis elements of correlation order Nhas a total degree ďDNfor 1ďNďN.
26For clarity, the table contains an extra column for the total degree in ACEpotentials.jl , de-
noted by DACEpot, which starts with 1 instead of 0. The actual total degree of order N(regard-
less of envelope function) in another column of the table is calculated by DN“DACEpot
N´N.
An envelope function of degree = 4 (as in (45)) is used and the actual total degree with envelope
function Denvis also computed in a separate column.
We make three key observations from Table 2:
(i) The analysis of the two conditions:řm“0 andřl“even on the angular part (i.e.
spherical harmonics) of the basis in Section 2.4.4 is not affected by the radial envelope
function;
(ii) With the introduction of the envelope function, Proposition 2.4 cannot be applied di-
rectly with basis sparsification as in Section 2.4.4 and extra basis elements supplementing
insufficiency in linearization of the radial part of ϕn1l1m1ϕn2l2m2have to be evaluated;
(iii) In some cases, if the difference in total degree for each order is large enough, the two
bases nevertheless have the same span since the lower order term is already sufficient for
removing the self-interacting terms without extra basis. This corresponds to the cases
where number of extra Akbasis is zero in Table 2.
DACEpotD Denv# ofAk
basis# of extra
Akbasis# ofBα
andBα
basisEquivalent?
22, 18, 14, 10 21, 16, 11, 6 25, 24, 23, 22 1709 0 539 Yes
24, 20, 16, 12 23, 18, 13, 8 27, 26, 25, 24 3704 0 929 Yes
26, 22, 18, 14 25, 20, 15, 10 29, 28, 27, 26 8034 0 1608 Yes
18, 15, 12, 9 17, 13, 9, 5 21, 21, 21, 21 736 0 299 Yes
20, 17, 14, 11 19, 15, 11, 7 23, 23, 23, 23 1669 0 538 Yes
22, 19, 16, 13 21, 17, 13, 9 25, 25, 25, 25 3842 0 969 Yes
18, 16, 14, 12 17, 14, 11, 8 21, 22, 23, 24 1718 362 559 No
20, 18, 16, 14 19, 16, 13, 10 23, 24, 25, 26 4226 886 1056 No
22, 20, 18, 16 21, 18, 15, 12 25, 26, 27, 28 10363 1771 1969 No
17, 16, 15, 14 16, 14, 12, 10 20, 22, 24, 26 3168 1383 862 No
19, 18, 17, 16 18, 16, 14, 12 22, 24, 26, 28 8245 2907 1677 No
21, 20, 19, 18 20, 18, 16, 14 24, 26, 28, 30 20845 5855 3197 No
Table 2: In the table, DACEpotis the degree used in ACEpotentials.jl [38], Dis calculated
byDN“DACEpot
N´NandDenvis calculated by Denv
N“DN`4N, where 4 is the polynomial
degree of the envelope function fenvin (42). The equivalence of the two bases sets is verified by
checking numerically whether every Bnlibasis is in span ptBnliunliq, and vice versa.
D Hyperparameters for our numerical experiments
D.1 Zuo data set
acemodel with total degree = (25, 21, 17, 13) (See C.2 for the definition of specifying total
degree as a tuple) and default weights for the least squares system in ACEpotentials.jl [38] is
applied. Only energy and force observations are used to estimate the parameters. An algebraic
smoothness prior with p“5 is used. All other hyper parameters are kept as default.
27Levels Total degree Basis size
1 18, 14, 10, 6 183
2 20, 16, 12, 8 314
3 22, 18, 14, 10 539
4 24, 20, 16, 12 929
5 26, 22, 18, 14 1609
Table 3: Model levels in Section 4.3 and corresponding total degree in ACEpotentials.jl [38].
See C.2 for the definition of specifying total degree as a tuple.
D.2 Fe data set
acemodel with total degree as specified in Table 2 and rcut“6.5˚A is applied. The energy of
the one-body term is set to be Eref “ ´3455.6995339 following the GAP model in [40]. We
specify the weights of the least squares system depending on the configuration type following
[40]. All energy, force and viral observations are used to estimate the parameters. A algebraic
smoothness prior of p“5 is used. All other hyper parameters are kept as default.
28References
[1]ACE1x.jl . Experimental features for ACEpotentials.jl .github.com/ACEsuit/ACE1x.jl .
[2]ACEpotentials.jl . Documentation and user interface for Julia-language development of
ACE potentials. github.com/ACEsuit/ACEpotentials.jl .
[3] Markus Bachmayr, Genevieve Dusson, Christoph Ortner, and Jack Thomas. Polynomial
approximation of symmetric functions. arXiv:2109.14771 , 2023. to appear in Math. Com-
put.
[4] Ilyes Batatia, Simon Batzner, D´ avid P´ eter Kov´ acs, Albert Musaelian, Gregor NC Simm,
Ralf Drautz, Christoph Ortner, Boris Kozinsky, and G´ abor Cs´ anyi. The design space of
E(3)-equivariant atom-centered interatomic potentials. arXiv:2205.06643 , 2022. to appear
in Nature Machine Intelligence.
[5] Ilyes Batatia, Mario Geiger, Jose Munoz, Tess Smidt, Lior Silberman, and Christoph
Ortner. A general framework for equivariant neural networks on reductive Lie groups.
arXiv:2306.00091 , 2023. to appear in Advances in Neural Information Processing Systems.
[6] Ilyes Batatia, David P Kovacs, Gregor Simm, Christoph Ortner, and Gabor Cs´ anyi. Mace:
Higher order equivariant message passing neural networks for fast and accurate force fields.
In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Adv.
Neural Inf. Process. Syst. , volume 35, pages 11423–11436. Curran Associates, Inc., 2022.
[7] Ilyes Batatia, Lars L Schaaf, Huajie Chen, G´ abor Cs´ anyi, Christoph Ortner, and Felix A
Faber. Equivariant matrix function neural networks. arXiv:2310.10434 , 2023.
[8] Ben Blum-Smith and Soledad Villar. Machine learning and invariant theory.
arXiv:2209.14991 , 2023.
[9] Bastiaan J Braams and Joel M Bowman. Permutationally invariant potential energy sur-
faces in high dimensionality. Int. Rev. Phys. Chem. , 28(4):577–606, 2009.
[10] William Elwood Byerly. An elemenatary treatise on Fourier’s series, and spherical, cylin-
drical, and ellipsoidal harmonics, with applications to problems in mathematical physics .
Dover Publications, 1893.
[11] Huajie Chen and Christoph Ortner. Qm/mm methods for crystalline defects. part 1: Lo-
cality of the tight binding model. Multiscale Model. Sim. , 14(1):232–264, 2016.
[12] Albert Cohen, Mark A Davenport, and Dany Leviatan. On the stability and accuracy of
least squares approximations. Found. Comput. Math. , 13:819–834, 2013.
[13] Volker L Deringer, Miguel A Caro, and G´ abor Cs´ anyi. Machine learning interatomic po-
tentials as emerging tools for materials science. Advanced Materials , 31(46):1902765, 2019.
[14] Ralf Drautz. Atomic cluster expansion for accurate and transferable interatomic potentials.
Phys. Rev. B , 99:014104, Jan 2019.
[15] Ralf Drautz and Christoph Ortner. Atomic cluster expansion and wave function represen-
tations. arXiv:2206.11375 , 2022.
[16] Genevi` eve Dusson, Markus Bachmayr, G´ abor Cs´ anyi, Ralf Drautz, Simon Etter, Cas
van der Oord, and Christoph Ortner. Atomic cluster expansion: Completeness, efficiency
and stability. J. Comput. Phys. , 454:110946, 2022.
29[17] George Gasper. Linearization of the product of Jacobi polynomials. I. Canadian J. Math. ,
22(1):171–175, 1970.
[18] Jan E Gerken, Jimmy Aronsson, Oscar Carlsson, Hampus Linander, Fredrik Ohlsson,
Christoffer Petersson, and Daniel Persson. Geometric deep learning and equivariant neural
networks. Artif. Intell. Rev. , pages 1–58, 2023.
[19] Pascal Giorgi. On polynomial multiplication in Chebyshev basis. IEEE Trans. Comput. ,
61(6):780–789, 2011.
[20] Michael J Hutchinson, Charline Le Lan, Sheheryar Zaidi, Emilien Dupont, Yee Whye Teh,
and Hyunjik Kim. Lietransformer: Equivariant self-attention for Lie groups. In Interna-
tional Conference on Machine Learning , pages 4533–4543. PMLR, 2021.
[21] D´ avid P´ eter Kov´ acs, Ilyes Batatia, Eszter Sara Arany, and Gabor Csanyi. Evaluation of
the MACE force field architecture: from medicinal chemistry to materials science. J. Chem.
Phys. , 159(4), jul 2023.
[22] D´ avid P´ eter Kov´ acs, Cas van der Oord, Jiri Kucera, Alice EA Allen, Daniel J Cole,
Christoph Ortner, and G´ abor Cs´ anyi. Linear atomic cluster expansion force fields for
organic molecules: beyond rmse. J. Chem. Theory Comput. , 17(12):7696–7711, 2021.
[23] Juho Lee, Yoonho Lee, Jungtaek Kim, Adam Kosiorek, Seungjin Choi, and Yee Whye Teh.
Set transformer: A framework for attention-based permutation-invariant neural networks.
InInternational Conference on Machine Learning , pages 3744–3753. PMLR, 2019.
[24] He Li, Zun Wang, Nianlong Zou, Meng Ye, Runzhang Xu, Xiaoxun Gong, Wenhui Duan,
and Yong Xu. Deep-learning density functional theory hamiltonian for efficient ab initio
electronic-structure calculation. Nat. Comput. Sci. , 2(6):367–377, 2022.
[25] Yury Lysogorskiy, Cas van der Oord, Anton Bochkarev, Sarath Menon, Matteo Rinaldi,
Thomas Hammerschmidt, Matous Mrovec, Aidan Thompson, G´ abor Cs´ anyi, Christoph
Ortner, et al. Performant implementation of the atomic cluster expansion (PACE) and
application to copper and silicon. npj Comput. Mater. , 7(1):97, 2021.
[26] Jose M Munoz, Ilyes Batatia, and Christoph Ortner. Boost invariant polynomials for
efficient jet tagging. Mach. Learn.: Sci. Technol. , 3(4):04LT05, 2022.
[27] Felix Musil, Andrea Grisafi, Albert P Bart´ ok, Christoph Ortner, G´ abor Cs´ anyi, and Michele
Ceriotti. Physics-inspired structural representations for molecules and materials. Chemical
Reviews , 121(16):9759–9815, 2021.
[28] Jigyasa Nigam, Sergey Pozdnyakov, and Michele Ceriotti. Recursive evaluation and iterative
contraction of n-body equivariant features. J. Chem. Phys. , 153(12), 2020.
[29] Christoph Ortner, Jack Thomas, and Huajie Chen. Locality of interatomic forces in tight
binding models for insulators. ESAIM: Mathematical Modelling and Numerical Analysis ,
54(6):2295–2318, 2020.
[30] Minaam Qamar, Matous Mrovec, Yury Lysogorskiy, Anton Bochkarev, and Ralf Drautz.
Atomic cluster expansion for quantum-accurate large-scale simulations of carbon. J. Chem.
Theory Comput. , 19(15):5151–5167, 2023.
30[31] Charles Ruizhongtai Qi, Li Yi, Hao Su, and Leonidas J Guibas. Pointnet++: Deep hier-
archical feature learning on point sets in a metric space. In I. Guyon, U. Von Luxburg,
S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, editors, Adv. Neural
Inf. Process. Syst. , volume 30. Curran Associates, Inc., 2017.
[32] Nathaniel Thomas, Tess Smidt, Steven Kearnes, Lusann Yang, Li Li, Kai Kohlhoff, and
Patrick Riley. Tensor field networks: Rotation-and translation-equivariant neural networks
for 3d point clouds. arXiv:1802.08219 , 2018.
[33] Lloyd N. Trefethen. Multivariate polynomial approximation in the hypercube. Proc. Amer.
Math. Soc. , 145(11):4837–4844, 2017.
[34] Cas van Der Oord, Genevi` eve Dusson, G´ abor Cs´ anyi, and Christoph Ortner. Regularised
atomic body-ordered permutation-invariant polynomials for the construction of interatomic
potentials. Mach. Learn.: Sci. Technol. , 1(1):015004, 2020.
[35] Cas van der Oord, Matthias Sachs, D´ avid P´ eter Kov´ acs, Christoph Ortner, and G´ abor
Cs´ anyi. Hyperactive learning for data-driven interatomic potentials. npj Computational
Materials , 9(1):168, 2023.
[36] Jonathan Vandermause, Steven B Torrisi, Simon Batzner, Yu Xie, Lixin Sun, Alexie M
Kolpak, and Boris Kozinsky. On-the-fly active learning of interpretable Bayesian force
fields for atomistic rare events. npj Comput. Mater. , 6(1):20, 2020.
[37] Yangshuai Wang, Shashwat Patel, and Christoph Ortner. A theoretical case study of the
generalisation of machine-learned potentials. arXiv:2311.01664 , 2023.
[38] William C Witt, Cas van der Oord, Elena Gelˇ zinyt˙ e, Teemu J¨ arvinen, Andres Ross, James P
Darby, Cheuk Hin Ho, William J Baldwin, Matthias Sachs, James Kermode, et al. Ace-
potentials. jl: A julia implementation of the atomic cluster expansion. J. Chem. Phys. ,
159(16), 2023.
[39] Adolfas P Yutsis, Ioshua Beniaminovich Levinson, and Vladislavas Vladovich Vanagas.
Mathematical apparatus of the theory of angular momentum. Academy of Sciences of the
Lithuanian S.S.R. , 1962.
[40] Lei Zhang, G´ abor Cs´ anyi, Erik van der Giessen, and Francesco Maresca. Atomistic fracture
in bcc iron revealed by active learning of gaussian approximation potential. npj Computa-
tional Materials , 9(1):217, Dec 2023.
[41] Liwei Zhang, Berk Onat, Genevi` eve Dusson, Adam McSloy, Gautam Anand, Reinhard J
Maurer, Christoph Ortner, and James R Kermode. Equivariant analytical mapping of first
principles Hamiltonians to accurate and transferable materials models. npj Comput. Mater. ,
8(1):158, 2022.
[42] Dexuan Zhou, Huajie Chen, Cheuk Hin Ho, and Christoph Ortner. A multilevel
method for many-electron Schr¨ odinger equations based on the atomic cluster expansion.
arXiv:2304.04260 , 2023. to appear in SIAM J. Sci. Comput.
[43] Yunxing Zuo, Chi Chen, Xiangguo Li, Zhi Deng, Yiming Chen, J¨ org Behler, G´ abor Cs´ anyi,
Alexander V. Shapeev, Aidan P. Thompson, Mitchell A. Wood, and Shyue Ping Ong.
Performance and cost assessment of machine learning interatomic potentials. J. Phys.
Chem. A , 124(4):731–745, 2020. PMID: 31916773.
31