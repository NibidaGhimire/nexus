Distributed Inexact Newton Method with Adaptive
Step Sizes
DuË‡ san JakovetiÂ´ câˆ—, NataË‡ sa KrejiÂ´ câˆ—, Greta Malaspinaâ€ 
Abstract
We consider two formulations for distributed optimization wherein
Nnodes in a generic connected network solve a problem of common
interest: distributed personalized optimization and consensus opti-
mization. A new method termed DINAS (Distributed Inexact Newton
method with Adaptive step size) is proposed. DINAS employs large
adaptively computed step sizes, requires a reduced global parameters
knowledge with respect to existing alternatives, and can operate with-
out any local Hessian inverse calculations nor Hessian communications.
When solving personalized distributed learning formulations, DINAS
achieves quadratic convergence with respect to computational cost and
linear convergence with respect to communication cost, the latter rate
being independent of the local functions condition numbers or of the
network topology. When solving consensus optimization problems, DI-
NAS is shown to converge to the global solution. Extensive numerical
experiments demonstrate significant improvements of DINAS over ex-
isting alternatives. As a result of independent interest, we provide for
the first time convergence analysis of the Newton method with the
adaptive Polyakâ€™s step size when the Newton direction is computed
inexactly in centralized environment.
âˆ—Department of Mathematics and Informatics, Faculty of Sciences, University
of Novi Sad, Trg Dositeja ObradoviÂ´ ca 4, 21000 Novi Sad, Serbia, Email: du-
san.jakovetic@dmi.uns.ac.rs, natasak@uns.ac.rs, The work of D. JakovetiÂ´ c and N. KrejiÂ´ c
was supported by the Science Fund of the Republic of Serbia, Grant no. 7359, Project
LASCADO.
â€ Dipartimento di Ingegneria Industriale, Universit` a degli studi di Firenze, Viale G.B.
Morgagni 40, 50134 Firenze, Italy. Member of the INdAM Research Group GNCS. Email:
greta.malaspina@unifi.it. This work is partially supported by the BIGMATH project
which has received funding by the European Unionâ€™s Horizon 2020 research and innovation
programme under the Marie Sk lodowska-Curie Grant Agreement no. 812912, and by
Partenariato esteso FAIR â€œFuture Artificial Intelligence Researchâ€ SPOKE 1 Human-
Centered AI. Obiettivo 4, Project â€œMathematical and Physical approaches to innovative
Machine Learning technologies (MaPLe)â€.
1arXiv:2305.13985v2  [math.OC]  14 Jan 20251 Introduction
We consider distributed optimization problems where a network of Ncom-
putational nodes, interconnected by a generic undirected connected network,
collaborate in order to solve a problem of common interest. Specifically, we
consider the following two widely used problem formulations:
minNX
i=1fi(xi) +1
2Î²X
{i,j}âˆˆEwijâˆ¥xiâˆ’xjâˆ¥2(1)
minf(y) =NX
i=1fi(y). (2)
Here,âˆ¥ Â· âˆ¥denotes the Euclidean norm; fi:Rnâ†’Ris a local cost function
available to node i;xiâˆˆRn,i= 1, ..., n , and yâˆˆRnare optimization
variables; i= 1, ..., N ;Edenotes the set of undirected edges; Î² > 0 is a
parameter; and wij>0,{i, j} âˆˆE, are positive constants. Formulation (1)
arises, e.g., in personalized decentralized machine learning, e.g., [1, 7, 20,
25, 38]; see also [9] for a related formulation in federated learning settings.
Therein, each node iwants to find its personalized local model xiby fitting
it against its local data-based loss function fi. In typical scenarios, the data
available to other nodes jÌ¸=iare also useful to node i. One way to enable
node ilearn from node jâ€™s local data is hence to impose a similarity between
the different nodesâ€™ models. This is done in (1) by adding a quadratic penalty
term, where parameter wij>0 encodes the â€œstrengthâ€ of the similarity
between node iâ€™s and node jâ€™s models.1The quantities wijâ€™s also respect
the sparsity pattern of the underlying network, i.e., they are non-zero only
for the node pairs i, jthat can communicate directly, i.e., for those pairs i, j
such that {i, j} âˆˆE.Throughout the paper, we refer to formulation (1) as
distributed personalized optimization, or penalty formulation.
Formulation (2) has also been extensively studied, e.g., [31, 10, 11, 15,
16, 21, 29, 35, 36, 43]. It is related with (1) but, unlike (1), there is a global
model (optimization variable) yâˆˆRncommon to all nodes, i.e., the nodes
want to reach a consensus (agreement) on the model. Formulation (1) may
be seen as an inexact penalty variant of (2), with the increasing approxi-
mation accuracy as Î²becomes smaller. This connection between the two
formulations has also been exploited in prior works, e.g., [27], in order to de-
velop new methods for solving (2). In other words, once a distributed solver
1In order to simplify the presentation, we let the wijâ€™s satisfyP
jÌ¸=iwij<1 and also
introduce an arbitrary common multiplicative constant Î² >0.
2for (1) is available, one can also solve (2) approximately by taking a small
Î², or exactly by solving a sequence of problems (2) with an appropriately
tuned decreasing sequence of Î²â€™s. We refer to formulation (2) as distributed
consensus optimization, or simply consensus optimization.
In this paper, we also follow this path and first devise a method for
solving (1) with a fixed Î²; we then capitalize on the latter to derive solvers
for (2).
There is a vast literature for solving problems of type (2) and (1). We
first discuss formulation (2). In general one can distinguish between several
classes of methods. To start, a distributed gradient (DG) method has been
considered in [31]. Given that the gradient method with fixed step size
cannot achieve exact convergence, a number of methods, belonging to the
class of gradient tracking methods which assume that additional information
is shared among nodes, are proposed and analysed, [10, 11, 15, 16, 21, 29,
35, 36, 43]. In these methods the objective function is assumed to be convex
with Lipschitz-continuos gradient, the gradient tracking scheme is employed
with a fixed steps size, and the exact convergence to is reached. The step
size required in order to ensure convergence needs to be smaller than a
threshold that depends on global constants such as strong convexity and
gradientâ€™s Lipschitz constant; the constant also needs to be known by all
nodes beforehand.
In [30, 43, 41, 42, 46], the case of uncoordinated time-invariant step sizes
is considered.
In [12], a modification of the gradient tracking method, with step sizes
varying both across nodes and across iterations is proposed. Time varying
networks are considered in [29, 33]. Again, the step sizes in all of these meth-
ods depend on some global constants (like strong convexity and Lipschitz).
The actual implementation is subject to estimation of these constants and
very often leads to costly hand-tuning of step size parameters.
If the optimization problem of interest is ill-conditioned, first order meth-
ods might be very slow, and second order methods appear as an attractive
alternative. When considering second order methods in a distributed and
large-scale framework, there are a few issues that need to be addressed.
First, as in the classical (centralized) optimization framework, Hessian-based
methods are typically quite expensive: while in the distributed framework
the work of computing the Hessian is shared by the nodes and therefore may
not represent a major issue, solving the linear system typically required at
each iteration to compute the Newton-like direction may be prohibitively ex-
pensive for problems of very large sizes. Secondly, while we normally assume
that nodes can share the local vector of variables and the local gradients (or
3some other vectors of magnitudes comparable to the variable dimension n),
sharing the Hessian cause communication costs quadratic in n. Finally, one
would like to have superlinear or quadratic convergence for a second order
method. However, in a distributed framework when solving (2) or (1), there
are two main obstacles: reaching consensus, and the choice of the step size.
These issues are addressed in the literature in several ways so far.
We first discuss second order methods that solve (1). In [27] the au-
thors propose a distributed version of the classical Newton method, dubbed
Network Newton â€“ NN, that relies on a truncated Taylor expansion of the
inverse Hessian matrix. NN solves exactly (1) and yields an inexact solution
of (2). The approximation of the inverse Hessian with NN involves inver-
sion of local (possibly dense) Hessians of the fiâ€™s. Linear convergence of the
method to the solution of (1) is proved if standard assumptions for the New-
ton method hold, for a suitable choice of the step size. In [39] a modification
of NN method is proposed, that employs a reinforcement strategy.
Several second order methods are proposed that solve (2). In [28] the
direction is computed using the same approximation strategy as in NN,
but within primal-dual strategy. The method proposed in [14] relies on
primal-dual framework as well but computes the direction inexactly. Thus,
the method avoids any kind of matrix inversion and relies on a fixed point
iterative method for computing the search direction. This leads to favorable
performance for problems with a relatively large n.In [47] the gradient-
tracking strategy is extended to the case of the Newton method.
Current second order methods that solve (1) such as [27] and [25] con-
verge at best linearly to the solution of (1).2Moreover, the step size by
which a Newton-like step is taken depends on several global constants and
is usually very small, leading to slow convergence in applications. The choice
of the step size is of fundamental importance for a method to achieve both
global convergence and fast local convergence. Classical line-search strate-
gies, which effectively solve this issue in the centralized framework, are not
applicable in the distributed setting as they require knowledge of the value
of the global function at all nodes and may require several evaluation at
each iteration, which would yield prohibitively large communication traffic.
In [48] the authors propose a method termed DAN, [48] proposes a method
for solving (2), but it may be generalized to solving (1) such that similar
convergence rate guarantees hold order-wise. The method employs a finite-
2It has been shown that the methods in [27] and [25] exhibit an error decay of a
quadratic order only for a bounded number of iterations, while the actual convergence
rate is linear.
4time communication strategy to share the local hessians through the whole
network and makes use of the step size proposed in [32] for the Newton
method in the centralized case, which ensures both global convergence and
fast local convergence. Given that sharing all local hessians among nodes
might be too expensive for problems of even moderate size, a version of
DAN that employs and shares through the whole network rank one approx-
imations of the local hessians is proposed. The step size is again defined by
the global constants such as strong convexity and Lipschitz constants. In [4]
the authors propose a distributed Newton method with cubic regularization
for solving empirical risk minimization problems. In [3] the authors propose
a Distributed Newton method for the solution of quadratic problems that
requires the nodes to share both vectors and matrices, and prove that the
convergence on the method depends only on the logarithm of the condition
number of the problem. In particular they prove that sharing second or-
der information can improve the performance of distributed methods when
the condition number of the problem is large. In [22] the authors combine
the idea of sharing compressed Hessian information with that of performing
several rounds of consensus at each iteration of the method, then show that
the method they propose achieves asymptotically superlinear convergence
when the number of consensus rounds at every iterations tends to infinity.
In summary, current second order methods for solving (1) suffer from
at least one of the following drawbacks. Only linear convergence rate is
achieved, both with respect to the number of local functions fiâ€™s gradient
and Hessian evaluations, and with respect to the number of inter-node com-
munication rounds. The methods require knowledge of global constants
beforehand in order for step size to be set, usually leading to small step size
choices and slow convergence. If a superlinear or quadratic convergence is
reached, this comes at a O(n2) cost of local Hessiansâ€™ communication.
Contributions . We propose a new method termed DINAS (Distributed
Inexact Newton method with Adaptive step size) that can solve both (1)
and (2) formulations. When solving (1), DINAS achieves linear, superlinear
or quadratic convergence to the solution in terms of the number of outer it-
erations. In more detail, the method achieves, in a best scenario, a quadratic
convergence with respect to the number of local gradient and local Hessian
evaluations, and a linear convergence with respect to the number of com-
munication rounds. Moreover, the communication-wise linear convergence
rate is independent of local functionsâ€™ condition numbers or of the underlying
network topology, and it is hence significantly improved over the linear rates
5achieved in the literature so far. DINAS uses an adaptive step size that can
be computed at each iteration with a reduced knowledge of global constants
required when compared with existing alternatives. It computes the search
direction by using a suitable linear solver, i.e., an approximate solution of
the Newton linear system is computed in a distributed way at each iteration
via an iterative solver. To make the presentation easier to follow we specify
here the method with Jacobi Overrelaxation, JOR, as the linear solver of
choice, but any other linear solver that is implementable in the distributed
environment can be applied. After computation of the approximate Newton
direction of suitable level of inexactness, the step size is computed based
on the progress in gradient decrease, and the new iteration is computed.
The step size computation is an adaptation to the distributed framework of
the step size presented in [32] for the classical Newton method. This way
we achieve global convergence of the method. Furthermore, adaptive step
size allows us to maintain fast local convergence. The rate of convergence
is controlled by the forcing terms as in the classical Inexact Newton meth-
ods, [5], depending on the quality of approximation of the Newton direction
obtained by JOR method. Thus one can balance the cost and convergence
rate depending on the desired precision and adjust the forcing term during
the iterative process. The fact that we do not need any matrix inversion and
solve the linear system only approximately reduces the computational cost
in practice by several orders of magnitude, in particular if the dimension n
is relatively large.
For formulation (2), we employ DINAS by solving a sequence of problems
(1) with an appropriately chosen decreasing sequence of penalty parameters
Î², and show that the overall scheme converges to the solution of (2). While
we do not have theoretical convergence rate guarantees for solving (2), ex-
tensive numerical experiments demonstrate significant improvements over
state-of-the-art distributed second order solvers of (2). The results also
confirm that DINAS is particularly efficient for large dimensional (large n)
settings.
Finally, an important byproduct of the convergence theory for the dis-
tributed case developed here is the convergence of the classical (centralized)
Newton method with the Polyak adaptive step size when the Newton direc-
tions are computed inexactly. To the best of our knowledge, only the exact
Newton method with the Polyak step size has been analyzed to date.
This paper is organized as follows. In Section 2 we describe the dis-
tributed optimization framework that we consider and formulate the as-
sumptions. The DINAS algorithm is presented and discussed in Section 3.
The analysis of DINAS for formulation (1) is given in Section 4. The analy-
6sis of the centralized Newton method with the Polyak step size and inexact
Newton-like updates is given in Section 5, while the analysis for formulation
(2) is presented in Section 6. Numerical results are provided in Section 7.
We offer some conclusions in Section 8.
2 Model and preliminaries
Assume that a network G= (V,E) of computational nodes is such that node
iholds the function fiand can communicate directly with all its neighbors in
G. Moreover, assume that each node hold a local vector of variables xiâˆˆRn.
The properties of the communication network are stated in the assumption
below.
Assumption A1. The network G= (V,E)is undirected, simple and con-
nected, and it has self-loops at every node, i.e., (i, i)âˆˆEfor every i=
1, . . . , N .
We associate the communication matrix Wto the graph Gas follows.
Assumption A2. The matrix W= [wij]âˆˆRNÃ—Nis symmetric and doubly
stochastic such that if (i, j)/âˆˆEthen wij= 0, wijÌ¸= 0,(i, j)âˆˆEandwiiÌ¸=
0, i= 1, . . . , N.
Double stochastic matrix means that all elements of the matrix are non-
negative and they sum up to 1 by columns and rows, i.e.Pn
i=1wij=
1,Pn
j=1wij= 1.Hence wijâˆˆ[0,1].Given the communication matrix W
that satisfies Assumption A2 we can associate each node iwith its neigh-
borsjâˆˆOi.Clearly wijÌ¸= 0 if jâˆˆOi, wiiÌ¸= 0 andP
jâˆˆOiwij+wii= 1.The
communication matrix is also called consensus matrix.
The method we propose here is a Newton-type method, hence we assume
the standard properties of the objective function. We use the symbol â‰ºto
denote the following matrix property: Aâ‰ºBmeans that Aâˆ’Bis a positive
definite matrix.
Assumption A3. Let each fi, i= 1, . . . , N be a two times continuously
differentiable, strongly convex function such that for some 0< Âµ < M there
holds
ÂµIâ‰º âˆ‡2fi(y)â‰ºMI. (3)
The Hessian is Lipschitz continuous and for some L >0and all y, zâˆˆRn
we have
âˆ¥âˆ‡2fi(y)âˆ’ âˆ‡2fi(z)âˆ¥âˆâ‰¤Lâˆ¥yâˆ’zâˆ¥âˆ. (4)
7We are also interested in (1). It can be expressed as follows. Let
F(x) =NX
i=1fi(xi),
where x= (x1, . . . ,xN)âˆˆRnN,xiâˆˆRn.Then (2) is equivalent to the
following constrained problem
min
xâˆˆRnNF(x) s.t. xi=xj, i, jâˆˆ {1, . . . , N }.
Notice that Assumption A3 implies that Fis strongly convex and its Hessian
is Lipschitz continuous with the same constants Âµ, M andL.
Assuming that Wis a consensus matrix associated with the network G,
we define W=WâŠ—Inwith Inbeing the identity matrix in RnandâŠ—the
Kronecker product. Since Wis a doubly stochastic matrix, we have that
Wx=xif and only if xi=xjfor every i, j= 1, . . . , N, [27] and therefore,
problem (2) is equivalent to the following problem
min
xâˆˆRnNF(x),s.t. (Iâˆ’W)1/2x= 0. (5)
Clearly, one can state the constraint in (5) in different ways, for example
(Iâˆ’W)x= 0, but the formulation in (5) is the most common one as it
allows us to consider the quadratic penalty as stated in (6) below. Given
Î² >0, we consider the following problem, equivalent to (1):
min
xâˆˆRnNÎ¦Î²(x) with Î¦ Î²(x) =F(x) +1
2Î²xâŠ¤(Iâˆ’W)x. (6)
The relationship between (6) and (2) is analysed in [45]. In particular, it is
known that the penalty problem (6) yields an approximate solution of (2)
such that âˆ¥xâˆ—
iâˆ’yâˆ—âˆ¥=O(Î²/(1âˆ’Î»2)) where xâˆ—= (xâˆ—
1, . . . ,xâˆ—
N) is the solution
of (6), yâˆ—is the solution of (2) and Î»2is the second largest eigenvalue of
W.First we will be concerned with the solution of (6). Later in Section
6 we deal with a sequence of penalty problems, with decreasing values of
the penalty parameter Î²that allow us to reach the solution of (2) with
an arbitrary precision. This approach in some sense mimics the penalty
decomposition methods in the classical computational framework, where
one deals with a sequence of penalty problems, defined in different ways, to
solve the original problems. The decomposition is usually defined splitting
the set of constraints into sets of easy and difficult constraints, and then a
sequence of problems is solved, possibly inexactly, using different optimality
conditions, for example see [18].
83 Algorithm DINAS: Personalized distributed op-
timization
The classical Inexact Newton iteration for (6), given the current iteration
xkand the forcing parameter Î·k,is defined as
xk+1=xk+Î±kdk,
where Î±k>0 is the step size, dkis computed from
âˆ‡2Î¦Î²(xk)dk=âˆ‡Î¦Î²(xk) +rk(7)
andrkis the residual vector that satisfies
âˆ¥rkâˆ¥âˆâ‰¤Î·kâˆ¥âˆ‡Î¦Î²(xk)âˆ¥âˆ. (8)
The forcing term Î·kis bounded from above, Î·kâ‰¤Î· <1 while the step size
Î±kis determined by line search or some other globalization strategy, [6]. If
Î·k= 0 the method is in fact the Newtonâ€™s method and the step size can
be determined as in [32]. Notice that we are using the norm âˆ¥ Â· âˆ¥âˆin the
above expressions as that norm is suitable for the distributed case we are
interested in.
In the context of the setting presented in (7)â€“(8), we can distinguish our
theoretical and numerical contributions. Our theoretical contributions are
grounded on 1) novel analysis of inexact Newton methods when the residual
error satisfies condition (8); and 2) showing that a wide class of iterative
distributed solvers can be designed such that it satisfies condition (8). Our
numerical contributions are to develop, test and validate efficient iterative
solvers that solve (7) up to accuracy (8).
To apply an Inexact Newton method in distributed framework we need
to compute the direction dksuch that (8) holds and to determine the step
size. Note that directly solving (7) would require the inversion of matrix
âˆ‡2Î¦Î²(xk). This is however not amenable in distributed setting. Namely,
while the matrix âˆ‡2Î¦Î²(xk) has a block-sparsity structure that respects the
sparsity pattern of the network, its inverse may not have this property,
and hence a direct solution of (7) by the matrix inversion is not possible.
However, as the matrix âˆ‡2Î¦Î²(xk) is block-sparse according to the network
structure, we can apply carefully designed iterative fixed point solvers in
order to solve (7) up to the accuracy defined by (8). For this purpose, a
number of methods for solving linear systems in distributed framework may
be used, [24, 23, 17]. It turns out that a class of fixed point methods may be
9used without any changes, [13, 14]. The application of Jacobi Overrelaxation
(JOR) method to the system (7) is specified here but the theoretical analysis
holds for any solver assuming that (8) is valid.
For the sake of clarity let us briefly state the JOR method for solving
(7), while further details can be seen in [13, 14]. First of all notice that the
system matrix âˆ‡2Î¦Î²(xk) =âˆ‡2F(xk) +1
Î²(Iâˆ’W) is symmetric and positive
definite due to strong convexity of F,positive Î²and the fact that ( Iâˆ’W) is
positive semidefinite matrix. Given the current approximation dk,â„“âˆˆRnN,
where â„“denotes the inner iteration counter â„“= 0,1. . . ,for solving the linear
system, we can describe the next iteration of JOR method for solving (7) as
follows. Denoting the Hessian Hk= [Hk
ij] =âˆ‡2Î¦Î²(xk)âˆˆRnNÃ—nN, Hk
ii=
âˆ‡2fi(xk
i) +1
Î²(1âˆ’wii)In, Hk
ij=âˆ’1
Î²wijIn, iÌ¸=j,with the diagonal part of
each Hk
iidenoted by Dk
ii,the gradient gk= (gk
1, . . . ,gk
N),gk
i=âˆ‡fi(xk
i) +
1
Î²((1âˆ’wii)xk
iâˆ’P
jâˆˆOIwijxk
j), i= 1, . . . , N and with the relaxation parameter
Ï‰âˆˆR, that will be defined later on, the next iteration of JOR method for
solving (7) is given by
dk,â„“+1
i =dk,â„“
i+Ï‰(Dk
ii)âˆ’1ï£«
ï£­gk
iâˆ’NX
j=1Hk
ijdk,â„“
jï£¶
ï£¸. (9)
Performing enough iterations of (9) we can get dk=dk,â„“such that (8)
holds. It is easy to see that (9) is distributed as each node iholds the
blocks Hk
ii, Hk
ij, jâˆˆOi,i.e., each node holds the corresponding row Hk
iof
the Hessian Hk,the local gradient component gk
iand the nodes need to
share their approximate solutions dk,â„“
ionly among neighbours. The method
is converging for a suitable value of 0 < Ï‰ < 2Î²(1âˆ’Â¯w)/(M+ 2Î²),with
Â¯w= max 1â‰¤iâ‰¤Nwii,see [13] for details. From now on we will assume that
Ï‰is chosen such that JOR method converges, with further implementation
details postponed to Section 7.
Notice that, in order for parameter Ï‰to be properly set, nodes need to
know beforehand the global constants Â¯ wandM. These two constants that
corresponds to maxima of certain local nodesâ€™ quantities across the network
can be precomputed by running beforehand two independent algorithms for
the maximum computation such as [34]. In addition, DINAS can alleviate
the requirement for such knowledge if JOR is replaced by the following
iterative method:
dk,â„“+1
i =h
âˆ‡2fi(xk
i) + (1 /Î²)Iiâˆ’1ï£«
ï£­X
jâˆˆOiwij(1/Î²)dk,â„“
j+gk
iï£¶
ï£¸, (10)
10fori= 1, ..., N in parallel. The iterative method (10) does not require any
beforehand knowledge of global parameters, at the cost of the requirement
for local Hessian inverse calculations. It is easy to see that (10) converges
linearly, and there holds:
âˆ¥dk,â„“+1âˆ’dk,â‹†âˆ¥ â‰¤1/Î²
1/Î²+Âµâˆ¥dk,â„“âˆ’dk,â‹†âˆ¥,
where dk,â‹†=
âˆ‡2Î¦Î²(xk)âˆ’1âˆ‡Î¦Î²(xk) is the exact solution of (7).
Having a distributed algorithm for solving the system of linear equations,
let us explain the adaptive step size strategy employed here. The basic
assumption is that the global constants ÂµandLare not available. Classical
line search method, without the global constants, is not applicable in the
distributed settings as it requires the value of the global function at each
node, which would be very costly in terms of communications. Furthermore,
several values of global function value might be needed in each iteration to
compute the line search step size. Thus we employ the procedure that is
governed by a sequence of parameters {Î³k}that are used to generate the
step sizes, adopting the reasoning for the Newton method from [32] to the
case of distributed and inexact method. In each iteration we try the step
size based on the current value of Î³kand check if such step size generates
enough decrease in the gradient. If the decrease is large enough the step
size is accepted and we proceed to a new iteration. If not, the step size is
rejected, the value of Î³kis reduced and a new step size is tried with the
same direction. Thus the checking procedure is cheap as the direction stays
the same and we will show that it eventually ends up with a step size that
generates enough decrease.
The step size computation includes the infinity norm of the gradient
in the previous iteration and all nodes need this value. Therefore we use
the algorithm from [48] for exchange of information around the network.
Recall that in [48] the nodes exchange either local Hessians or their rank one
approximations, while in DINAS they exchange only scalars. The algorithm
is included here for the sake of completeness. The distributed maximum
computation can be performed exactly in a finite number of communication
rounds, at most equal to the network diameter [34]. However we used the
algorithm from [48] as this does not make an important difference for DINAS
and makes numerical comparison presented in Section 7 easier to follow.
Algorithm 3.1 (DSF) .
Input: Each node i:{Si}iâˆˆNscalar messages
1:SetI0
i={Si}
112:fork= 0, . . . , N âˆ’1do
3:forjâˆˆOido
4: take SâˆˆIkâˆ’1
0such that Swas not received from node jand not
sent to node jat the previous iterations
5: send Sto node j
6:end for
7: update Ik
iadding the messages received by the neighbors
8:end for
Once the step is accepted the nodes run DSF algorithm exchanging the
infinity norms of local gradients to get the infinity norm of the aggregate
gradient and proceed to the new iteration. The algorithm is stated in a node-
wise fashion, to facilitate the understanding of the distributed flow although
a condensed formulation will be used later on, for theoretical considerations.
Algorithm 3.2 (DINAS) .
Iteration k, each node iholds: Î·k,xk
i,gk
i, Hk
i, Î³k>0,âˆ¥gkâˆ¥âˆ, qâˆˆ
(0,1)
1:All nodes run distributed JOR iterations (9) to compute {dk
i}N
i=1such
that
âˆ¥Hk
idk
iâˆ’gk
iâˆ¥âˆâ‰¤Î·kâˆ¥gkâˆ¥âˆ,âˆ€i= 1, . . . , N (11)
2:All nodes compute the step size
Î±k= min
1,1âˆ’Î·k
(1 +Î·k)2Î³k1
âˆ¥gkâˆ¥âˆ
3:Each node icomputes Ë†xi=xk
iâˆ’Î±kdk
i
4:All nodes share Ë†xiwith the neighbors in Oi
5:Each node icomputes Ë†gi=âˆ‡fi(Ë†xi) +1
Î²
Ë†xiâˆ’P
jwijË†xj
6:All nodes run DSF (Algorithm 3.1) with message at node igiven by
Si=âˆ¥Ë†giâˆ¥âˆ
7:Each node icomputes âˆ¥Ë†gâˆ¥âˆ= max j=1:NSj
8:Each node iperforms the following check and conditional updates
9:if
Î±k<1andâˆ¥Ë†gâˆ¥âˆâ‰¤ âˆ¥gkâˆ¥âˆâˆ’1
2(1âˆ’Î·k)2
(1 +Î·k)2Î³k (12)
or
Î±k= 1andâˆ¥Ë†gâˆ¥âˆâ‰¤Î·kâˆ¥gkâˆ¥âˆ+1
2Î³k(1 +Î·k)2âˆ¥gkâˆ¥2
âˆ (13)
then
1210: setÎ³k+1=Î³k
11: setxk+1
i=Ë†xi,gk+1
i=Ë†gi,âˆ¥gk+1âˆ¥âˆ=âˆ¥Ë†gâˆ¥âˆ
12: define Hk+1
i=
Hk+1
i1, . . . , Hk+1
iN
âˆˆRnÃ—nNwith
Hk+1
ii=âˆ‡2fi(xk+1
i) +1
Î²(1âˆ’wii)In, Hk+1
ij=âˆ’1
Î²wijIn, jÌ¸=i
13:else
14: setÎ³k=qÎ³kand return to line 2
15:end if
Let us briefly comment the computational and computational costs of
DINAS here, with further details postponed to Section 7. Application of
JOR method for solving (7) implies that in each inner (JOR) iteration all
nodes share their current approximations dk,â„“
iwith neighbours. Each itera-
tion of JOR method includes only the inversion of local diagonal matrix and
is hence rather cheap. Depending on the value of Î·kthe number of inner
iterations can vary but the right hand side of (8) ensures that initially we
solve (7) rather loosely, with relative large residual and small computational
effort while the accuracy requirements increase as the gradients gets smaller
and we approach the solution. Therefore we completely avoid inversion of
(possibly very dense) local Hessians that is needed in NN method [27] and
in one version of DAN, [48]. Thus DINAS should be particularly effective
if the dimension of (2) is relatively large as the cost of JOR approximate
solution should be significantly smaller than the cost of exact solution (local
Hessian inversion) in each iteration of Network Newton method.
The condition (11) does not need to be verified online if a pre-defined
number of iterations is used and we will estimate that number later on.
Otherwise, if online verification is used, the nodes would need to run another
distributed maximum procedure to see that each node satisfies the condition
but such addition appears unnecessary. Communication costs of exchanges
needed to compute âˆ¥g(xk)âˆ¥âˆandâˆ¥Ë†gâˆ¥âˆare not large as the nodes exchange
only scalar values - the infinity norm of local gradient components.
The step size computation at line 2 is performed by each node but they
all compute the same value so that step is well defined. The check and
update defined at line 9 is again performed by all nodes using the same
values and hence the result will be the same at each node. Therefore, all
nodes go back to line 2 or all nodes update the approximate solution xk
iand
the if loop at line 9 is well defined. In the next section we will prove that
the if loop has finite termination.
13Regarding the global knowledge requirements of system constants, to
implement Step 6 (DSF or [34]), all nodes need to know beforehand an
upper bound on the number of nodes N, or on network diameter. Next, one
can utilize (10) with a single inner iteration and Î·= 1/(1 +Î²Âµ), and global
convergence of DINAS is ensured; see Theorem 4.1 ahead. Hence, for global
convergence, nodes only need to know beforehand an upper bound on Nand
a lower bound on Âµ. Notice that Âµcan be calculated beforehand by running
a distributed minimum algorithm computation [34] with the initialization at
node igiven by its local costâ€™s strong convexity constant. When compared
with alternative second order solvers such as NN [27] and [25], this is a
significantly reduced prior knowledge requirement as these methods require
the Lipschitz constans of Hessian and the gradient. When DINAS employs
additional tuning and knowledge of global constants, as it is assumed by
Theorems 4.2â€“4.4, then stronger results in terms of convergence rates are
ensured.
DINAS requires the scalar maximum-compute in Step 6 and synchro-
nized activities of all nodes in Steps 6â€“14. It is interesting to compare
DINAS with [48] that requires a similar procedure. While [48] utilizes such
procedure over local Hessians ( O(n2)-sized local messages), DINAS requires
Step 6 only for a scalar quantity. It is also worth noting that, in view of
Steps 6â€“14, DINAS is not easily generalizable to asynchronous settings as
done in [25], or to unreliable link/nodes settings although direction might be
computed by asynchronous JOR method [8]. However, for reliable and syn-
chronized networks, we emphasize that DINAS incurs drastic improvements
both theoretically (quadratic convergence) and in experiments, exhibiting
orders of magnitude faster rates when compared with existing alternatives.
4 Convergence analysis of DINAS for personalized
distributed optimization
Let us start the analysis proving that DINAS is well defined , i.e. proving
that the loop defined at line 9 has finite termination.
Lemma 4.1. Let Assumptions A1 - A3 hold. Then the following statements
hold:
i) if Î³kâ‰¤Âµ2/Lthen one of the condition at line 9 is satisfied;
ii) the number of times Î³kis reduced is bounded from above by log1/q 
Î³0L/Âµ2
;
iii) for every kâˆˆN0we have Â¯Î³ < Î³ kâ‰¤Î³0, with Â¯Î³=qÂµ2
L;
14iv) there exists Â¯m1âˆˆN0such that Î³k=Î³Â¯m1for every kâ‰¥Â¯m1.
Proof. Since fis two times continuously differentiable we have that for any
Î±âˆˆR
g(xkâˆ’Î±dk) =g(xk)âˆ’Î±Hkdkâˆ’Z1
0Î±
H(xkâˆ’sÎ±dk)âˆ’Hk
dkds
and therefore, by Assumption A3, (7) and (8)
âˆ¥g(xkâˆ’Î±dk)âˆ¥âˆâ‰¤ âˆ¥gkâˆ’Î±(gk+rk)âˆ¥âˆ+Î±Z1
0âˆ¥H(xkâˆ’sÎ±dk)âˆ’Hkâˆ¥âˆâˆ¥dkâˆ¥âˆds
â‰¤ |1âˆ’Î±|âˆ¥gkâˆ¥âˆ+Î±âˆ¥rkâˆ¥âˆ+Î±2LZ1
0sâˆ¥dkâˆ¥2
âˆds
â‰¤ |1âˆ’Î±|âˆ¥gkâˆ¥âˆ+Î±Î·kâˆ¥gkâˆ¥âˆ+Î±2L
2âˆ¥(Hk)âˆ’1(gk+rk)âˆ¥2
âˆ,
and we get
âˆ¥g(xkâˆ’Î±dk)âˆ¥âˆâ‰¤(|1âˆ’Î±|+Î·kÎ±)âˆ¥gkâˆ¥âˆ+1
2L
Âµ2(1 +Î·k)2Î±2âˆ¥gkâˆ¥2
âˆ.(14)
To prove the first statement we have to show that if Î³kâ‰¤Âµ2/Lthen either
(12) or (13) hold. From (14), if Î±k= 1 we have
âˆ¥Ë†gâˆ¥âˆâ‰¤Î·kâˆ¥gkâˆ¥âˆ+1
2L
Âµ2(1 +Î·k)2âˆ¥gkâˆ¥2
âˆ.
Otherwise, for Î±k<1, we get
âˆ¥Ë†gâˆ¥âˆâ‰¤
1âˆ’Î³k(1âˆ’Î·k)2
âˆ¥gkâˆ¥âˆ(1 +Î·k)2
âˆ¥gkâˆ¥âˆ+L
2Âµ2(1 +Î·k)2Î³k(1âˆ’Î·k)
(1 +Î·k)2âˆ¥gkâˆ¥âˆ2
âˆ¥gkâˆ¥2
âˆ
â‰¤ âˆ¥gkâˆ¥âˆ+Î³k(1âˆ’Î·k)2
(1 +Î·k)2L
2Âµ2Î³kâˆ’1
.
Given that Î³kâ‰¤Âµ2/Lthe desired inequalities follow in both cases and we
geti).
By definition of Î³k+1(lines 10 and 13 in Algorithm DINAS), the sequence
{Î³k}is non increasing, the value of Î³kis reduced only when neither (12) nor
(13) are satisfied and in that case we decrease Î³kby a fixed qâˆˆ(0,1).This,
together with i) implies ii) and iii).Since we proved that {Î³k}is bounded
from below, iv) follows. â–¡
15Lemma 4.1 implies in particular that for klarge enough Î³kbecomes
constant. While by iii) we know that Î³Â¯m1â‰¥qÂµ2/L, the Lemma does not
state that Î³kwill eventually reach qÂµ2/L.
Notice that the iteration of DINAS can be written in a compact form as
follows. Given xkanddksuch that (8) holds, we have xk+1=xkâˆ’Î±kdk
where
Î±k= min
1,1âˆ’Î·k
(1 +Î·k)2Î³k1
âˆ¥gkâˆ¥âˆ
. (15)
In the next theorem we prove convergence to the unique solution of (6).
Theorem 4.1. Assume that A1 - A3 hold, {Î·k}is a nonincreasing sequence
such that 0â‰¤Î·kâ‰¤Â¯Î· <1andÎ³0>0.Let{xk}be an arbitrary sequence
generated by DINAS. Then
i) there exists Â¯m2âˆˆN0such that Î±k= 1for every kâ‰¥Â¯m1+ Â¯m2, and
Â¯m2â‰¤1
C
âˆ¥gÂ¯m1âˆ¥âˆâˆ’Â¯Î³1âˆ’Â¯Î·
(1 + Â¯Î·)2
+ 1
, C=qÂµ2
L(1âˆ’Â¯Î·)2
(1 + Â¯Î·)2; (16)
ii)limkâ†’âˆâˆ¥gkâˆ¥âˆ= 0;
iii)limkâ†’âˆxk=xâˆ—, where xâˆ—is the unique solution of (6).
Proof. Let us first assume that at iteration kwe have step size
Î±k=1âˆ’Î·k
(1 +Î·k)2Î³k1
âˆ¥gkâˆ¥âˆ<1. (17)
Then (12) implies
âˆ¥gk+1âˆ¥âˆâ‰¤ âˆ¥gkâˆ¥âˆâˆ’1
2Î³k(1âˆ’Î·k)2
(1 +Î·k)2. (18)
By Lemma 4.1 we have Î³kâ‰¥qÂµ2/L. Moreover, since(1âˆ’Î·)2
(1+Î·)2is a decreasing
function of Î·forÎ·âˆˆ(0,1) and Î·kâ‰¤Â¯Î· <1 we have that, for every k
(1âˆ’Î·k)2
(1 +Î·k)2â‰¥(1âˆ’Â¯Î·)2
(1 + Â¯Î·)2>0,andÎ³k(1âˆ’Î·k)2
(1 +Î·k)2â‰¥qÂµ2
L(1âˆ’Â¯Î·)2
(1 + Â¯Î·)2=:C >0
Replacing the last inequality in (18) we get
âˆ¥gk+1âˆ¥âˆâ‰¤ âˆ¥gkâˆ¥âˆâˆ’C/2 (19)
16for every iteration index ksuch that Î±k<1.
Let us now consider the case where Î±k= 1.The by definition of Î±kthere
follows
âˆ¥gkâˆ¥âˆâ‰¤Î³k1âˆ’Î·k
(1 +Î·k)2. (20)
From this inequality and (13) we have
âˆ¥gk+1âˆ¥âˆâ‰¤Î·kâˆ¥gkâˆ¥âˆ+1
2Î³k(1 +Î·k)2âˆ¥gkâˆ¥2
âˆ
â‰¤Î·kâˆ¥gkâˆ¥âˆ+1
2(1âˆ’Î·k)âˆ¥gkâˆ¥âˆ=1
2(1 +Î·k)âˆ¥gkâˆ¥âˆ.(21)
Since Î·kâ‰¤Â¯Î· <1, for every ksuch that Î±k= 1 we have, with Ï=1
2(1 + Â¯Î·),
âˆ¥gk+1âˆ¥âˆâ‰¤Ïâˆ¥gkâˆ¥âˆ. (22)
Letk > Â¯m1. IfÎ±k= 1, by (20), (21), Î·k+1â‰¤Î·k, and Î³k=Î³Â¯m1=Î³k+1
we have
âˆ¥gk+1âˆ¥âˆâ‰¤Ïâˆ¥gkâˆ¥âˆâ‰¤ÏÎ³k(1âˆ’Î·k)
(1âˆ’Î·k)2â‰¤ÏÎ³k+1(1âˆ’Î·k+1)
(1âˆ’Î·k+1)2,
which implies Î±k+1= 1.Denote with Â¯ m2the smallest positive integer such
thatÎ±Â¯m1+ Â¯m2= 1. This, together with (17) which holds for k= Â¯m1+ Â¯m2âˆ’1
and (18) implies
Î³Â¯m1+ Â¯m2âˆ’11âˆ’Î·Â¯m1+ Â¯m2âˆ’1
(1 +Î·Â¯m1+ Â¯m2âˆ’1)2<âˆ¥gÂ¯m1+ Â¯m2âˆ’1âˆ¥âˆâ‰¤ âˆ¥gÂ¯m1+ Â¯m2âˆ’2âˆ¥âˆâˆ’C
â‰¤ âˆ¥gÂ¯m1âˆ¥âˆâˆ’( Â¯m2âˆ’1)C,
and thus
Â¯m2<1
C
âˆ¥gÂ¯m1âˆ¥âˆâˆ’Î³Â¯m1+ Â¯m2âˆ’11âˆ’Î·Â¯m1+ Â¯m2âˆ’1
(1 +Î·Â¯m1+ Â¯m2âˆ’1)2
+ 1
â‰¤1
C
âˆ¥gÂ¯m1âˆ¥âˆâˆ’Â¯Î³1âˆ’Â¯Î·
(1 + Â¯Î·)2
+ 1.
Since we already proved that Î±k= 1 implies Î±k+1= 1 for every kâ‰¥Â¯m2,
i) holds. Inequalities (19) and (22), together with i), imply part ii) of the
statement.
It remains to prove that the sequence of iterates {xk}converges to the unique
17solution of (6). For every jâˆˆNwe have, by (7), (8), (22) and the bound on
Î·k
âˆ¥dÂ¯m1+ Â¯m2+jâˆ¥âˆâ‰¤ âˆ¥ 
HÂ¯m1+ Â¯m2+jâˆ’1(gÂ¯m1+ Â¯m2+j+rÂ¯m1+ Â¯m2+j)âˆ¥âˆ
â‰¤1
Âµ(1 + Â¯Î·)âˆ¥gÂ¯m1+ Â¯m2+jâˆ¥âˆâ‰¤1
Âµ(1 + Â¯Î·)Ïâˆ¥gÂ¯m1+ Â¯m2+jâˆ’1âˆ¥âˆâ‰¤1
Âµ(1 + Â¯Î·)Ïjâˆ¥gÂ¯m1+ Â¯m2âˆ¥âˆ.
Thus, for every sâ‰¥lâ‰¥0
âˆ¥xÂ¯m1+ Â¯m2+sâˆ’xÂ¯m1+ Â¯m2+lâˆ¥âˆâ‰¤sâˆ’1X
j=lâˆ¥dÂ¯m1+ Â¯m2+jâˆ¥âˆ
â‰¤1
Âµ(1 + Â¯Î·)âˆ¥gÂ¯m1+ Â¯m2âˆ¥âˆsâˆ’1X
j=lÏj=1
Âµ(1 + Â¯Î·)âˆ¥gÂ¯m1+ Â¯m2âˆ¥âˆÏsâˆ’Ïl
1âˆ’Ï.
So,{xk}is a Cauchy sequence and therefore there exists Â¯x= lim kâ†’+âˆxk.
Since we already proved that lim kâ†’+âˆâˆ¥gkâˆ¥âˆ= 0, we have that Â¯x=xâˆ—.â–¡
Remark 4.1. Theorem 4.1 shows that, like line search in the classical frame-
work, the adaptive strategy employed by Algorithm 3.2 ensures convergence
to the solution for any initial guess (i.e. global convergence), and also that
the full step Î±k= 1is accepted whenever âˆ¥gkâˆ¥âˆis small enough.
Remark 4.2. The method is convergent whenever Î·kâ‰¤Â¯Î· <1.For suitable
choices of the relaxation parameter the spectral radius of the iterative matrix
of the JOR method is bounded away from 1, [44]. Therefore Theorem 4.1
hold if at each iteration of Algorithm 3.2 the nodes perform only one itera-
tion of JOR method and we have global convergence. The number of JOR
iterations needed for (11) is discussed later.
The forcing sequence {Î·k}determines the rate of convergence as in the
centralized optimization, [5]. We obtain linear, superlinear or quadratic
convergence with a suitable choice of Î·kas stated below.
Theorem 4.2. Assume that A1 - A3 hold, Î³0>0and let {xk}be a sequence
generated by DINAS algorithm. If {Î·k}is a nonincreasing sequence such that
Î·kâ‰¤Â¯Î·forÂ¯Î·small enough then {xk}converges linearly in norm âˆ¥ Â· âˆ¥âˆ. If
Î·kâ‰¤Î·âˆ¥gkâˆ¥Î´
âˆfor some Î·â‰¥0andklarge enough, then the convergence is
superlinear for Î´âˆˆ(0,1)and quadratic for Î´= 1.
Proof. We already proved in Theorem 4.1 that âˆ¥gkâˆ¥âˆandxkconverge to
0 and xâˆ—respectively. In the following, we always assume that kâ‰¥Â¯m=
18Â¯m1+ Â¯m2, and hence Î±k= 1 and Î³k=Î³Â¯m.ForÎ´= 0, linear convergence
ofâˆ¥gkâˆ¥âˆfollows directly from (22). Let us consider the case Î´ >0. For k
large enough, from (21) we have
âˆ¥gk+1âˆ¥âˆâ‰¤Î·kâˆ¥gkâˆ¥âˆ+1
2Î³k(1 +Î·k)2âˆ¥gkâˆ¥2
âˆ
â‰¤Î·âˆ¥gkâˆ¥1+Î´
âˆ+1
Î³kâˆ¥gkâˆ¥2
âˆâ‰¤Î·âˆ¥gkâˆ¥1+Î´
âˆ+1
Î³Â¯mâˆ¥gkâˆ¥2
âˆ.
IfÎ´= 1 then
lim
kâ†’+âˆâˆ¥gk+1âˆ¥âˆ
âˆ¥gkâˆ¥2âˆâ‰¤lim
kâ†’+âˆÎ·âˆ¥gkâˆ¥2
âˆ+1
Î³Â¯mâˆ¥gkâˆ¥2
âˆ
âˆ¥gkâˆ¥2âˆ=Î·+1
Î³Â¯m,
which ensures quadratic convergence. If Î´âˆˆ(0,1), then lim kâ†’âˆâˆ¥gkâˆ¥= 0
implies
lim
kâ†’+âˆâˆ¥gk+1âˆ¥âˆ
âˆ¥gkâˆ¥âˆâ‰¤lim
kâ†’+âˆÎ·âˆ¥gkâˆ¥1+Î´
âˆ+1
Î³Â¯mâˆ¥gkâˆ¥2
âˆ
âˆ¥gkâˆ¥âˆ= 0
Let us now consider the sequence xk.For every jâˆˆNwe have
âˆ¥xÂ¯m+j+1âˆ’xâˆ—âˆ¥âˆ=âˆ¥xÂ¯m+jâˆ’xâˆ—âˆ’dÂ¯m+jâˆ¥âˆ
=âˆ¥xÂ¯m+jâˆ’xâˆ—âˆ’(HÂ¯m+j)âˆ’1(gÂ¯m+j+rÂ¯m+j)âˆ¥âˆ
=âˆ¥(HÂ¯m+j)âˆ’1âˆ¥âˆâˆ¥HÂ¯m+j(xÂ¯m+jâˆ’xâˆ—)âˆ’(gÂ¯m+j+rÂ¯m+j)âˆ¥âˆ
â‰¤1
Âµâˆ¥HÂ¯m+j(xÂ¯m+jâˆ’xâˆ—)âˆ’(gÂ¯m+jâˆ’gâˆ—)âˆ¥âˆ+1
Âµâˆ¥rÂ¯m+jâˆ¥âˆ.
(23)
Since the objective function is twice continuously differentiable, we have
âˆ¥HÂ¯m+j(xÂ¯m+jâˆ’xâˆ—)âˆ’(gÂ¯m+jâˆ’gâˆ—)âˆ¥âˆ
=Z1
0(HÂ¯m+jâˆ’H(xÂ¯m+j+s(xÂ¯m+jâˆ’xâˆ—))(xÂ¯m+jâˆ’xâˆ—)ds
âˆ
â‰¤Z1
0sLâˆ¥xÂ¯m+jâˆ’xâˆ—)âˆ¥2
âˆdsâ‰¤L
2âˆ¥xÂ¯m+jâˆ’xâˆ—)âˆ¥2
âˆ.
Replacing this term in (23) and using the bound on âˆ¥rkâˆ¥âˆwe get
âˆ¥xÂ¯m+j+1âˆ’xâˆ—âˆ¥âˆâ‰¤1
ÂµL
2âˆ¥xÂ¯m+jâˆ’xâˆ—âˆ¥2
âˆ+1
ÂµÎ·Â¯m+jâˆ¥gÂ¯m+jâˆ¥âˆ. (24)
19By Assumption A3 we have
âˆ¥gkâˆ¥âˆ=âˆ¥gkâˆ’gâˆ—âˆ¥âˆâ‰¤Mâˆ¥xkâˆ’xâˆ—âˆ¥âˆ.
Let us consider the case Î´ >0 and let us notice that, since xkconverges
toxâˆ—, we can assume jis large enough so that âˆ¥xÂ¯m+jâˆ’xâˆ—âˆ¥âˆ<1. So, by
definition of Î·k
âˆ¥xÂ¯m+j+1âˆ’xâˆ—âˆ¥âˆâ‰¤1
ÂµL
2âˆ¥xÂ¯m+jâˆ’xâˆ—âˆ¥2
âˆ+1
ÂµÎ·âˆ¥gÂ¯m+jâˆ¥1+Î´
âˆ
â‰¤1
ÂµL
2+MÎ·
âˆ¥xÂ¯m+jâˆ’xâˆ—âˆ¥1+Î´
âˆ
which proves superlinear and quadratic convergence for Î´âˆˆ(0,1) and Î´= 1,
respectively. For Î´= 0 and âˆ¥xÂ¯m+jâˆ’xâˆ—âˆ¥âˆâ‰¤Îµwe have (24) and Î·kâ‰¤Â¯Î·,
and
âˆ¥xÂ¯m+j+1âˆ’xâˆ—âˆ¥âˆâ‰¤1
ÂµL
2Îµ+MÂ¯Î·
âˆ¥xÂ¯m+jâˆ’xâˆ—âˆ¥âˆ
ForÎµ,Â¯Î·small enough we have that1
Âµ L
2Îµ+MÂ¯Î·
<1,which ensures linear
convergence and concludes the proof. â–¡
The next statement gives the complexity result, i.e. we estimate the
number of iterations needed to achieve âˆ¥gkâˆ¥âˆâ‰¤Îµ.
Theorem 4.3. Assume that A1 - A3 hold, {Î·k}is a nonincreasing sequence
of forcing parameters such that 0â‰¤Î·kâ‰¤Â¯Î· <1andÎ³0>0.Let{xk}be an
arbitrary sequence generated by DINAS. The number of iterations necessary
to reach âˆ¥gkâˆ¥âˆâ‰¤Îµfor a given Îµ >0is bounded from above by
kÎµ=&
log 
Îµâˆ’1âˆ¥g0âˆ¥âˆ
log(Ë†Ïâˆ’1)+ 1'
with
Ë†Ï= max(1 + Â¯Î·)
2,1âˆ’qÂµ2
L(1âˆ’Â¯Î·)2
(1 + Â¯Î·)21
âˆ¥g0âˆ¥âˆ
<1.
Proof. Let us consider inequalities (18) and (22) derived in the proof of
Theorem 4.1. For every index kwe have that if Î±k= 1 then âˆ¥gk+1âˆ¥âˆâ‰¤
Ïâˆ¥gkâˆ¥âˆwith Ï= (1 + Â¯ Î·)/2. If Î±k<1 and C=qÂµ2
L(1âˆ’Â¯Î·)2
(1+Â¯Î·)2,then
âˆ¥gk+1âˆ¥âˆâ‰¤ âˆ¥gkâˆ¥âˆâˆ’C/2â‰¤ âˆ¥gkâˆ¥âˆ
1âˆ’C
2âˆ¥g0âˆ¥âˆ
=:Ï2âˆ¥gkâˆ¥âˆ.
20Since Î±k<1, the definition of Î±kand inequalities Î³kâ‰¥qÂµ2/LandÎ·kâ‰¤Â¯Î· <
1 imply
âˆ¥gkâˆ¥âˆ> Î³k1âˆ’Â¯Î·k
(1 + Â¯Î·k)2â‰¥qÂµ2
L1âˆ’Â¯Î·
(1 + Â¯Î·)2> C
and thus Ï2âˆˆ(0,1).That is, denoting with Ë† Ï= max {Ï, Ï2}<1, we have
âˆ¥gk+1âˆ¥âˆâ‰¤Ë†Ïâˆ¥gkâˆ¥âˆ.
Let us denote with kÎµthe first iteration such that âˆ¥gkÎµâˆ¥âˆâ‰¤Îµ.From the
inequality above, we have
Îµ <âˆ¥gkÎµâˆ’1âˆ¥âˆâ‰¤Ë†Ïâˆ¥gkÎµâˆ’2âˆ¥âˆâ‰¤Ë†ÏkÎµâˆ’1âˆ¥g0âˆ¥âˆ,
which implies
Ë†ÏkÎµâˆ’1>Îµ
âˆ¥g0âˆ¥âˆ
and thus
kÎµâˆ’1<log1/Ë†Ï 
Îµâˆ’1âˆ¥g0âˆ¥âˆ
=log 
Îµâˆ’1âˆ¥g0âˆ¥âˆ
log(Ë†Ïâˆ’1),
which concludes the proof. â–¡
To complement the above result we give here an estimated number of
inner (JOR) iterations needed to satisfy (11).
Lemma 4.2. Assume that at every outer iteration kthe nodes run JOR
method starting at dk,0
i= 0for every i= 1, . . . , N, and let us denote with
Mk(Ï‰k)the iterative matrix of JOR method. Then the number of JOR
iteration performed by the nodes to satisfy the termination condition (11)is
bounded from above by:
Â¯â„“k=ln (Î·k)
ln (âˆ¥Mk(Ï‰k)âˆ¥âˆ)
.
Proof. For every â„“âˆˆN, we have
âˆ¥Hkdk,â„“âˆ’gkâˆ¥âˆ=âˆ¥Hkdk,â„“âˆ’1+Ï‰kHkDâˆ’1
k(gkâˆ’Hkdk,â„“âˆ’1)âˆ’gkâˆ¥âˆ
=âˆ¥(Iâˆ’Ï‰kHkDâˆ’1
k)(Hkdk,â„“âˆ’1âˆ’gk)âˆ¥âˆâ‰¤ âˆ¥Mk(Ï‰k)âˆ¥âˆâˆ¥Hdk,â„“âˆ’1âˆ’gkâˆ¥âˆ.
Recursively applying this inequality and using the fact that dk,0= 0, we get
the following bound for the residual at the â„“-th iteration of JOR method:
âˆ¥Hkdk,â„“âˆ’gkâˆ¥âˆâ‰¤ âˆ¥Mk(Ï‰k)âˆ¥â„“
âˆâˆ¥Hdk,0âˆ’gkâˆ¥âˆ=âˆ¥Mk(Ï‰k)âˆ¥â„“
âˆâˆ¥gkâˆ¥âˆ.
Ifâ„“â‰¥l
ln(Î·k)
ln(âˆ¥Mk(Ï‰k)âˆ¥âˆ)m
thenâˆ¥Hkdk,â„“âˆ’gkâˆ¥âˆâ‰¤Î·kâˆ¥gkâˆ¥âˆand therefore the
statement is proved. â–¡
21Assume that for every iteration kthe forcing term Î·kis given by Î·k=
Î·âˆ¥gkâˆ¥Î´. Theorem 4.2 then ensures local linear, superlinear or quadratic
convergence depending on the value of Î´and at each iteration the following
inequality holds
âˆ¥gk+1âˆ¥âˆâ‰¤Î·kâˆ¥gkâˆ¥âˆ+1
Î³Â¯mâˆ¥gkâˆ¥2
âˆ=Î½kâˆ¥gkâˆ¥âˆ,
where
Î½k=
Î·k+1
Î³Â¯mâˆ¥gkâˆ¥âˆ
. (25)
Therefore we can estimate the rate of convergence with respect to the com-
munication rounds. Given that the step size Î±k= 1 is eventually accepted
forklarge enough, the total number of communications rounds per outer
iteration is â„“kcommunications for the JOR method, plus the sharing of
the local Newtonian directions, i.e. the total number of communications
is governed by â„“k.The following statement claims that the rate of conver-
gence with respect to the communication rounds is always linear, with the
convergence factor depending on Î·k,i.e., on Î´.
To be more precise, we introduce the following quantity:
ÏÎ´:= lim
kâ†’âˆÎ½1/Â¯â„“k
k<1.
The above limit exists as shown ahead. Quantity ÏÎ´may be seen as an
asymptotic convergence factor with respect to the number of communica-
tion rounds. Indeed, given that, at the outer iteration k, the number of
communication rounds is governed by â„“k, it follows that the multiplicative
factor of the error decay per a single inner iteration (communication round)
at iteration kequals Î½1/Â¯â„“k
k. Hence, taking the limit of the latter quantity as
kâ†’ âˆ gives the asymptotic (geometricâ€“multiplicative) convergence factor
with respect to the number of communication rounds.
Theorem 4.4. LetÎ´âˆˆ[0,1]andÎ·k=Î·âˆ¥gkâˆ¥Î´
âˆforÎ· >0small enough and
assume that at each iteration the JOR parameter Ï‰kis chosen in such a way
thatâˆ¥Mk(Ï‰k)âˆ¥âˆâ‰¤Ïƒ <1. Then the rate of convergence with respect to the
communications rounds of DINAS method is linear, i.e. ÏÎ´<1.
Proof. We will distinguish two cases, depending on the value of Î´.Let us
first consider Î´= 0. Since in this case Î·k=Î·for every k, by Lemma 4.2 we
have that the number of inner iterations is bounded from above by
Â¯â„“k=ln (Î·)
ln (âˆ¥Mk(Ï‰k)âˆ¥âˆ)
â‰¤ln (Î·)
ln(Ïƒ)
=:Â¯â„“.
22From (22) we have Î½k=Ïfor every iteration index kand
Ï0= lim
kâ†’âˆÎ½1/Â¯â„“k
kâ‰¤Ïln(Ïƒ)
ln(Î·)<1,
which proves the thesis for Î´= 0.
Let us now consider the case Î´âˆˆ(0,1].From (25), the definition of Î·k, and
the fact that {âˆ¥gkâˆ¥}is a decreasing sequence that tends to 0, we have that
forklarge enough
Î½kâ‰¤
Î·+1
Î³Â¯m
âˆ¥gkâˆ¥Î´
âˆ.
Therefore
ÏÎ´= lim
kâ†’âˆÎ½1/Â¯â„“k
k= lim
kâ†’âˆ
Î·+1
Î³Â¯m
âˆ¥gkâˆ¥Î´
âˆ ln(Ïƒ)
ln(Î·âˆ¥gkâˆ¥Î´âˆ)
= lim
kâ†’âˆexpï£«
ï£­ln(Ïƒ)ln
Î·+1
Î³Â¯m
âˆ¥gkâˆ¥Î´
âˆ
ln (Î·âˆ¥gkâˆ¥âˆ)ï£¶
ï£¸=eln(Ïƒ)=Ïƒ.
Since Ïƒâˆˆ(0,1) this implies ÏÎ´=Ïƒ <1, and the proof is complete. â–¡
Remark 4.3. Theorem 4.4, jointly with Theorem 4.2, establish a quadratic
(respectively, superlinear) convergence rate for Î´= 1(respectively, Î´âˆˆ(0,1))
with respect to outer iterations (number of local gradient and local Hessian
evaluations) and a linear convergence rate with respect to the number of
communication rounds. This is a strict improvement with respect to ex-
isting results like, e.g., [26], that only establish a linear rate with respect
to the number of local gradient and Hessian evaluations and the number of
communication rounds. More precisely, [26] provides a bounded range of
iterations during which the â€œconvergence rateâ€ corresponds to a â€œquadraticâ€
regime. In contrast, we establish here the quadratic or superlinear rate in
the asymptotic sense.
Remark 4.4. ForÎ´ > 0, the asymptotic linear rate with respect to the
number of communication rounds equals Ïƒ, i.e., it matches the rate of the
inner iteration JOR method. In other words, the rate is the same as if the
JOR method was run independently for solving (7)withrk= 0. Intuitively,
forÎ´ >0, the outer iteration process exhibits at least a superlinear rate, and
therefore the outer iteration process has no effect (asymptotically) on the
communication-wise convergence rate.
23Remark 4.5. The convergence factor Ïƒfor the communication-wise linear
convergence rate established here (the Î´ >0case) is significantly improved
over the existing results like [26]. The rate here is improved as it corre-
sponds to the inner JOR process and is not constrained (deteriorated) by the
requirement on the sufficiently small Newton direction step size, as it is the
case in [26]. To further illustrate this, when (10) inner solver is used, the
final linear convergence factor communication-wise equals 1/(1 +Î²Âµ), and
it is hence independent of the local functionsâ€™ condition numbers, network
topology, or local Hessian Lipschitz constants.
5 Analysis of inexact centralized Newton method
with Polyakâ€™s adaptive step size
The adaptive step size we use in DINAS can be traced back to the adaptive
step sizes proposed in [32] for the Newton method. The convergence results
we obtain are in fact derived generalizing the reasoning presented there,
taking into account both the distributed computational framework and ap-
proximate Newton search direction. Assuming that N= 1,i.e., considering
the classical problem of solving (2) on a single computational node we can
state the adaptive step size method for Inexact method with the same anal-
ysis as already presented. Thus if we consider the method stated for (2) in
the centralized computation framework we get the algorithm bellow. Here
âˆ¥ Â· âˆ¥is an arbitrary norm.
Algorithm 5.1 (DINASC) .
Iteration k:Î·k, yk, Î³k>0, qâˆˆ(0,1)
1:Compute dksuch that
âˆ¥âˆ‡2f(yk)dkâˆ’ âˆ‡f(yk)âˆ¥ â‰¤Î·kâˆ¥âˆ‡f(yk)âˆ¥ (26)
2:Compute the step size
Î±k= min
1,1âˆ’Î·k
(1 +Î·k)2Î³k1
âˆ¥âˆ‡f(yk)âˆ¥
(27)
3:Compute the trial point Ë†y=ykâˆ’Î±kâˆ‡f(yk)
4:if
Î±k<1andâˆ¥âˆ‡f(Ë†y)âˆ¥ â‰¤ âˆ¥âˆ‡ (f(yk)âˆ¥ âˆ’1
2(1âˆ’Î·k)2
(1 +Î·k)2Î³k (28)
24or
Î±k= 1andâˆ¥âˆ‡f(Ë†y)âˆ¥ â‰¤Î·kâˆ¥âˆ‡f(yk)âˆ¥+1
2Î³k(1 +Î·k)2âˆ¥ âˆ‡f(yk)âˆ¥2(29)
then
5: setÎ³k+1=Î³kandyk+1= Ë†y
6:else
7: setÎ³k=qÎ³kand return to line 2
8:end if
The statements already proved for the distributed case clearly imply the
global convergence of the sequence {yk}as stated below.
Theorem 5.1. Assume that A1 - A3 hold and that the iterative sequence
{yk}is generated by Algorithm DINASC. Then limkyk=yâˆ—and the rate of
convergence is governed by the forcing sequence {Î·k}as in Theorem 4.2.
Assuming that the constants ÂµandLare available we get the following
statement for Inexact Newton methods with arbitrary linear solver.
Corollary 5.1. Assume that A1 - A3 hold and that the iterative sequence
{yk}is generated as yk+1=ykâˆ’Ë†Î±kdk,where dksatisfies (26), and
Ë†Î±k= min
1,1âˆ’Î·k
(1 +Î·k)2Âµ2
L1
âˆ¥âˆ‡f(yk)âˆ¥
. (30)
Then limkyk=yâˆ—and the rate of convergence depends on the forcing se-
quence {Î·k}as in Theorem 4.2.
Proof. The step size employed in DINASC algorithm reduces to Ë† Î±kwhenever
Î³k=Âµ2/L, while from part i) of Lemma 4.1 we have that for this choice of Î³k
either condition (28) or (29) is always satisfied. That is, for the considered
sequence, we have
âˆ¥âˆ‡f(yk+1)âˆ¥ â‰¤ âˆ¥âˆ‡ f(yk)âˆ¥ âˆ’1
2Âµ2
L(1âˆ’Î·k)2
(1 +Î·k)2
for every ksuch that Ë† Î±k<1, and
âˆ¥âˆ‡f(yk+1)âˆ¥ â‰¤Î·kâˆ¥âˆ‡f(yk)âˆ¥+1
2L
Âµ2(1 +Î·k)2âˆ¥âˆ‡f(yk)âˆ¥2
for every ksuch that Ë† Î±k= 1. The thesis follows directly from the analysis
of DINAS. â–¡
25Remark 5.1. The previous corollary provides a choice of the step size that
is accepted at all iterations. However, compared to Ë†Î±k, the adaptive step
size(27), i.e. (15) in DINAS, presents several advantages. First of all,
the definition of Ë†Î±kinvolves the regularity constants LandÂµ, which are
generally not known. Moreover, even when the constants are known, Ë†Î±k
could be very small, especially if in the initial iterations the gradient is large.
The numerical experience so far implies that for a reasonable value of Î³0
we have a rather small number of rejections in Step 4 (Step 9 of DINAS)
and the step size is mostly accepted although Î³k> Âµ2/L. Notice that when
Î³k> Âµ2/L, the right hand sides of inequalities (28) and(29) are smaller
than their equivalent for Î³k=Âµ2/L.That is, the adaptive step size generates
the decrease in the gradient is larger than the decrease induced by Ë†Î±k.
6 Convergence analysis for DINAS: Consensus op-
timization
Let us finally address the issue of convergence towards solutions of (2) and
(6). As already explained the solution of (6) is an approximate solution of
(2), and each local component xâˆ—
iof the penalty problem solution xâˆ—is in
theÎ²- neighbourhood of yâˆ—- the solution of (2). So, one might naturally
consider a sequence of penalty problem
min Î¦ Î²s=F(x) +1
2Î²sxT(Iâˆ’W)x (31)
with a decreasing sequence Î²sto reach the solution of (2) with arbitrary
precision and mimic the so-called exact methods discussed in Introduction.
Thus we can solve each penalty method determined by Î²sby DINAS up to
a certain precision and use a warm start strategy (taking the solution of the
problem with Î²sas the starting point for the problem with Î²s+1) to generate
the solution of (2). Naturally the exit criterion for each penalty problem
and the way of decreasing Î²sdetermine the properties of such sequence, in
particular the rate of convergence of DINAS should be in line with the rate
of decreasing Î²s,to avoid oversolving of each penalty problem.
This approach is similar to the penalty decomposition methods in the
centralized framework where one transforms the original problems, possibly
with difficult constraints, into a sequence of problems that are easier to solve.
The main difference is due to the change of computational framework - while
in the penalty decomposition methods we distinguish between difficult and
easy constraints, [19], here we take exactly the same problem and change
26the value of Î²s,to achieve suitable proximity of the solution ((31) to the
solution of (2). We demonstrate the efficiency of this approach, stated below
as Algorithm SDINAS, in the next Section.
Algorithm 6.1 (SDINAS) .
Input: Îµ0, Î²0>0,Ë†x0âˆˆRnN, Î¸âˆˆ(0,1).
1:fors= 1,2, . . .do
2: use DINAS starting at Ë†xsâˆ’1to find Ë†xssuch that âˆ¥Î¦Î²s(Ë†xs)âˆ¥âˆâ‰¤Îµs
3: setÎ²s+1=Î¸Î²s
4: setÎµs+1=Î¸Îµs
5:end for
Remark 6.1. Different choices could be made at lines 3 and 4 for the update
of the penalty parameter Î²sand the tolerance Îµs. The fixed decrease proposed
here is suitable for the distributed case as it does not require any additional
communication among the nodes but the convergence theorem holds for more
general {Î²s}and{Îµs}.
The following theorem shows that every accumulation point of the se-
quence generated by Algorithm 6.1 is the solution of (5). Notice that the
matrix Iâˆ’Wis singular and thus the LICQ condition does not hold. There-
fore we need to prove that an iterative sequence defined by Algorithm 6.1
converges to the solution of (6), similarly to [13, Theorem 3.1]. The issue
with LICQ is another property that is common with penalty decomposi-
tion method, [19], where the constraint qualification might not hold and one
needs to define alternative optimality conditions.
Theorem 6.1. Let Assumptions A1 - A3 hold and let {Ë†xs}be a sequence
such that
âˆ¥âˆ‡Î¦Î²s(Ë†xs)âˆ¥âˆâ‰¤Îµs.
Iflimsâ†’+âˆÎ²s= lim sâ†’+âˆÎµs= 0, then every accumulation point of {Ë†xs}
satisfies the sufficient second order optimality conditions for problem (5).
Proof. LetÂ¯xbe an accumulation point of {Ë†xs}and let K1âŠ†N0be an
infinite subset such that lim kâˆˆK1Ë†xs=Â¯x.By definition of Ë†xsand Î¦ Î²s, we
have
ÎµÎ²sâ‰¥ âˆ¥âˆ‡ Î¦Î²s(Ë†xs)âˆ¥âˆâ‰¥1
Î²Î²sâˆ¥(Iâˆ’W)Ë†xsâˆ¥âˆâˆ’ âˆ¥âˆ‡ F(Ë†xs)âˆ¥âˆ,
which implies
âˆ¥(Iâˆ’W)Ë†xsâˆ¥âˆâ‰¤Î²s(Îµs+âˆ¥âˆ‡F(Ë†xs)âˆ¥âˆ). (32)
27Sinceâˆ‡Fis bounded over {Ë†xs}K1, and Î²stends to zero, we get
âˆ¥(Iâˆ’W)Â¯xâˆ¥âˆâ‰¤lim
kâˆˆK1Î²s(Îµs+âˆ¥âˆ‡F(Ë†xs)âˆ¥âˆ) = 0 ,
which also implies that ( Iâˆ’W)1/2Â¯x= 0 and therefore Â¯xis a feasible point
for (5). Let us now define for every sâˆˆN0the vectors
vs=1
Î²s(Iâˆ’W)1/2Ë†xs,zs=1
Î²s(Iâˆ’W)Ë†xs.
We will prove that {vs}sâˆˆK1is bounded. Let Iâˆ’W=UÎ›UâŠ¤be the eigen-
decomposition of Iâˆ’W, with Î› = diag( Î»1, . . . , Î» nN). From (32) we have
that{zs}sâˆˆK1is bounded. That is, there exists ZâˆˆRsuch that âˆ¥zsâˆ¥ â‰¤Z
for every sâˆˆK1. Since Uis an orthogonal matrix, by definition of zwe
have
Zâ‰¥ âˆ¥zsâˆ¥ â‰¥ âˆ¥ UâŠ¤zsâˆ¥=1
Î²sâˆ¥UâŠ¤UÎ›UâŠ¤Ë†xsâˆ¥=1
Î²sâˆ¥Î›UâŠ¤Ë†xsâˆ¥=1
Î²s nNX
i=1Î»2
i(UâŠ¤Ë†xs)2
i!1/2
Since Î»iâ‰¥0 for every i, this implies that {1
Î²sÎ»2
i(UâŠ¤xs)2
i}sâˆˆK1is bounded
for every iand therefore {1
Î²sÎ»i(UâŠ¤xs)2
i}sâˆˆK1is also bounded. By definition
ofvswe get
1
Î²s nNX
i=1Î»i(UâŠ¤xs)i!1/2
=1
Î²sâˆ¥Î›1/2UâŠ¤xâˆ¥=âˆ¥UâŠ¤vsâˆ¥.
The above equality implies that {vs}sâˆˆK1is bounded and therefore there
exists Â¯vâˆˆRnNandK2âŠ†K1,an infinite subset such that lim kâˆˆK2vs=Â¯v.
By definition of Ë†xs, Î¦s, and vswe have
Îµsâ‰¥ âˆ¥âˆ‡ Î¦s(Ë†xs)âˆ¥âˆ=âˆ‡F(Ë†xs) +1
Î²s(Iâˆ’W)Ë†xs
âˆ=âˆ‡F(Ë†xs) + (Iâˆ’W)1/2vs
âˆ.
Taking the limit for sâˆˆK2we get
âˆ‡F(Â¯x) + (Iâˆ’W)1/2Â¯v
âˆ= 0,
and thus Â¯xis satisfies the KKT conditions for (5). Denoting with Lthe La-
grangian function of problem (5), by Assumption A3 we have that âˆ‡2
xxL(Â¯x,Â¯v)
is positive definite, and therefore we get the thesis. â–¡
287 Numerical Results
We now present a set of numerical results to investigate the behavior of
DINAS when solving (1) and (2) and how it compares with relevant methods
from the literature.
7.1 Numerical results for distributed personalized optimiza-
tion
Given that the choice of the forcing terms forcing terms Î·kinfluences the
performance of the method , we begin by numerically veryfing theoretical re-
sults on the convergence rate. Consider the problem of minimizing a logistic
loss function with l2regularization. That is, given {aj}m
j=1âŠ‚Rn,{bj}m
j=1âŠ‚
{âˆ’1,1}, Ï > 0, the objective function fis defined as
f(y) =mX
j=1ln
1 + exp( âˆ’bjaâŠ¤
jy)
+1
2Ïâˆ¥yâˆ¥2
2 (33)
We set n= 100, m= 1000 and assume that node iholds{aj}jâˆˆRi,{bj}jâˆˆRi
forRi={(iâˆ’1)100+1 , . . . , 100i}For every j= 1, . . . , m the components of
ajare independent and uniformly drawn from (0 ,1),while bjtakes value 1 or
âˆ’1 with equal probability, while the regularization parameter is Ï= 0.01m.
The underlying communication network is defined as a random geometric
graph with communication radiusp
Nâˆ’1ln(N), and the consensus matrix
Was the Metropolis matrix [40]. To evaluate the methods, we define the
per-iteration total cost of each method as the sum of the computational cost
plus the communication traffic multiplied by a scaling constant r, [2]. That
is,
total cost = computation + rÂ·communication (34)
The computational cost is expressed in terms of scalar operations, while
the communication traffic is the total number of scalar quantities shared
by all nodes. The scaling factor ris introduced to reflect the fact that the
time necessary to share a variable between two nodes compared with the
time necessary to execute scalar computations depends on many factors of
technical nature, such as the kind of computational nodes that form the
network and the technology they use to communicate, that are beyond the
purpose of these experiments.
Given fin (33) as explained above and Î²= 0.1, the personalized op-
timization problem in the form of (6) is solved with DINAS algorithm for
29(a)Î´= 0
 (b)Î´= 0
(c)Î´= 1
 (d)Î´= 1
Figure 1: Choice of the forcing terms, Logistic Regression
different choices of the sequence of forcing terms {Î·k},defined as
Î·k= min {Î·, Î·âˆ¥gkâˆ¥Î´
âˆ},
forÎ´= 0,1 and Î·= 0.9,0.1,0.001. All nodes start with initial guess x0
i=
0âˆˆRnand the execution terminates when âˆ¥âˆ‡Î¦Î²(xk)âˆ¥ â‰¤10âˆ’5.For all the
methods we define Î³0= 1.In Figure 1 we plot the results for the six methods
given by the different combinations of Î´andÎ·.In Figure 1a, 1b we consider
the case Î´= 0 (that is, Î·k=Î·for all k), while in Figure 1c,1d we have
Î´= 1. In each subfigure we plot the value of log10(âˆ¥gkâˆ¥) versus iterations
(Figure 1a, 1c) and cost (1b, 1d), with scaling factor r= 1. Figures 1a,
1c confirm the results stated in Theorem 4.2: the sequence âˆ¥gkâˆ¥is linearly
decreasing for all the considered choices of Î·, while for Î´= 1 the convergence
is locally quadratic. For both values of Î´the number of iterations required
by the methods to arrive at termination depends directly on the choice of
the forcing term: smaller values of Î·ensure the stopping criterion is satisfied
in a smaller number of iterations. However, for Î´= 1 we notice that, when
compared in terms of overall cost, the method with the smallest value of Î·
30performs worse than the other two. For Î´= 0 the comparison among the
methods for the cost gives the same result as that in terms of iterations.
The results for different values of the cost scaling factor rare completely
analogous and are therefore omitted here.
7.2 Comparison with Exact Methods for consensus optimiza-
tion
We compare DINAS with NN [27], DAN and DAN-LA [48], Newton Track-
ing [47], DIGing [29] and EXTRA [35]. The proposed method DINAS is
designed to solve the penalty formulation of the problem and therefore, in
order to minimize (2), we apply Algorithm 6.1 with Î²0= 0.1,Î²s+1= 0.1Î²s
andÎµs= 0.01Î²s. For NN we proceed analogously, replacing DINAS in line 2
with Network Newton. All other methods are the so-called exact methods,
and therefore can be applied directly to minimize f. We take Î³0= 1,Î´= 0
andÎ·= 0.9 in Algorithm 3.2, i.e., we consider linearly convergent DINAS,
while for all other methods the step sizes are computed as in the respective
papers. For DAN-LA the constants are set as in [48]. In particular, we con-
sider four different values of the parameter c=M,10M,100M,1000Mand
denote them as DAN LR1,DAN LR2, DAN LR3, DAN LR4 in the figures
bellow.
First, we consider a logistic regression problem with the same parame-
ters as in the previous test. The exact solution yâˆ—of (33) is computed by
running the classical gradient method with tolerance 10âˆ’8on the norm of
the gradient. As in [27], the methods are evaluated considering the average
squared relative error, defined as
ek=1
NNX
i=1âˆ¥xk
iâˆ’xâˆ—âˆ¥2
âˆ¥xâˆ—âˆ¥2
where xâˆ—= (yâˆ—, . . . ,yâˆ—)âŠ¤âˆˆRnN.For all methods the initial guess is x0
i= 0
at every node, which yields e0= 1, and the execution is terminated when
ekâ‰¤10âˆ’4.We consider the same combined measure of computational cost
and communication defined in (34), with scaling factor r= 0.1,1,10 and
plot the results in Figure 2.
One can see that for all values of rDINAS outperforms all the other
methods. NN, DIGing and EXTRA all work with fixed step sizes that, in
order to ensure global convergence of the methods, need to be very small.
Despite the fact that each iteration of DIGing and EXTRA is very cheap
compared to an iteration of DINAS, this is not enough to compensate the
31(a)r= 0.1
 (b)r= 1
 (c)r= 10
Figure 2: Total cost, Logistic Regression
fact that both these methods require a large number of iterations to arrive
at termination. DAN and DAN-LA methods use an adaptive step size that
depends on the constants of the problem ÂµandLand on 1 /âˆ¥âˆ‡Î¦kâˆ¥âˆin such
a way that the full step size is accepted when the solution is approached.
In fact, we can clearly see from the plots that all these methods reach a
quadratic phase where etdecreases very quickly. However, the per-iteration
cost of these methods is, in general, significantly higher than the cost of
DINAS. DAN method requires all the local Hessians âˆ‡2fi(xk) to be shared
among all the nodes at each iteration. While using Algorithm 3.1 this can
be done in a finite number of rounds of communications, the overall com-
munication traffic is large as it scales quadratically with both the dimension
nof the problem and the number of nodes N. DAN-LA avoids the commu-
nication of matrices by computing and sharing the rank-1 approximations
of the local Hessians. While this reduces significantly the communication
traffic of the method, it increases the computational cost, as two eigenvalues
and one eigenvector need to be computed by every node at all iterations,
and the number of iterations, since the direction is computed using an ap-
proximation of the true Hessian. Overall, this leads to a larger per-iteration
cost than DINAS. Since Î³0= 1 and it only decreases when the conditions
(12),(13) do not hold, we have that Î±kin DINAS is relatively large compared
to the fixed step sizes employed by the other methods that we considered.
The per-iteration cost of DINAS is largely dominated by the cost of JOR
that we use to compute the direction dk. Since the method is run with Î·k
large, and dkâˆ’1is used as initial guess at the next iteration, a small number
of JOR iteration is needed on average to satisfy (8), which makes the over-
all computational and communication traffic of DINAS small compared to
DAN and DAN-LA.
The logistic regression problem is also solved with Voice rehabilitation
32dataset - LSVT,[37]. The dataset is made of m= 126 points with n= 309
features, and the datapoints are distributed among N= 30 nodes on a
random network generated as above. The results for different values of rare
presented in Figure 3, and they are completely analogous to those obtained
for the synthetic dataset in Figure 2.
(a)r= 0.1
 (b)r= 1
 (c)r= 10
Figure 3: Total cost, Logistic Regression, LSVT dataset
To investigate the influence of conditional number we consider a quadratic
problem defined as
f(y) =NX
i=1fi(y), fi(y) =yâŠ¤Aiy+yâŠ¤bi (35)
with AiâˆˆRnÃ—n,bâˆˆRnfor every i= 1, . . . , N. We take n= 100 and N= 10
and we generate Ai, bias follows. Given 0 < Î» min< Î» max, we define the
diagonal matrix Di= diag( Î»i
1, . . . , Î»i
n) where the scalars Î»i
jare independent
and uniformly sampled in [ Î»min, Î»max].Given a randomly generated orthog-
onal matrix PiâˆˆRnÃ—nwe define Ai=PiDiPâŠ¤
i.For every i= 1, . . . , n
the components of biare independent and from the uniform distribution in
[0,1].Fixing Î»min= 0.1 different problems of the form (35) with increasing
values of Î»maxare considered. For each problem the exact solution yâˆ—, the
initial guess and the termination condition are all set as in the previous test.
The same combined measure of the cost, with scaling factor ris used. All
methods are run with step sizes from the respective papers, while for NN
we use step size equal to 1, as suggested in [27] for quadratic problems. In
Figure 4 we plot the obtained results for Î»max= 1,10,100 and r= 0.1,10.
For this set of problems the advantages of DINAS, compared to the
other considered methods, become more evident as Î»maxincreases. When
Î»maxis larger, the Lipschitz constant of the problem also increases and
therefore the step sizes that ensure convergence of DIGing and EXTRA
33(a)Î»max= 1, r= 0.1
 (b)Î»max= 10, r= 0.1
 (c)Î»max= 100 , r= 0.1
(d)Î»max= 1, r= 10
 (e)Î»max= 10, r= 10
 (f)Î»max= 100 , r= 10
Figure 4: Total cost, quadratic problem
become progressively smaller. In fact we can see that EXTRA outperforms
the proposed method for Î»max= 1 when the cost is computed with r= 0.1
and for Î»max= 10 when r= 10, but DINAS becomes more efficient for
larger values of Î»max.Regarding DAN and DAN-LA, what we noticed for
the previous test also holds here. Moreover, their step size depends on the
ratio Âµ2/Lwhich, for large values of Î»maxcauses the step size to be small for
many iterations. While NN uses the full step size in this test, its performance
is in general more influenced by the condition number of the problem than
that of DINAS. Moreover, while the per-iteration communication traffic of
NN is fixed and generally lower than that of DINAS, the computational cost
is typically larger, as at each iteration every node has to solve multiple linear
systems of size n, exactly. Finally, we notice that for all the considered values
ofÎ»maxthe comparison between DINAS and the other method is better for
r= 0.1 which is a direct consequence of assigning different weight to the
communication traffic when computing the overall cost.
8 Conclusions
The results presented here extend the classical theory of Inexact Newton
methods to the distributed framework in the following aspects. An adaptive
34(large) step size selection protocol is proposed that yields global conver-
gence. When solving personalized distributed optimization problems, the
rate of convergence is governed by the forcing terms as in the classical case,
yielding linear, superlinear or quadratic convergence with respect to com-
putational cost. The rate of convergence with respect to the number of
communication rounds is linear. The step sizes are adaptive, as in [32]
for the Newton method, and they can be computed in a distributed way
with a minimized required knowledge of global constants beforehand. For
distributed consensus optimization, exact global convergence is achieved.
The advantages of the proposed DINAS method in terms of computational
and communication costs with respect to the state-of-the-art methods are
demonstrated through several numerical examples, including large- scale and
ill-conditioned problems. Finally, a consequence of the analysis for the dis-
tributed case is also convergence theory for a centralized setting, wherein
adaptive step sizes and an inexact Newton method with arbitrary linear
solvers is analyzed, hence extending the results in [32] to inexact Newton
steps.
References
[1] I. Almeida and J. Xavier. DJAM: Distributed Jacobi asynchronous
method for learning personal models. IEEE Signal Processing Letters ,
25(9):1389â€“1392, 2018.
[2] A. S. Berahas, R. Bollapragada, N. S. Keskar, and E. Wei. Balancing
communication and computation in distributed optimization. IEEE
Transactions on Automatic Control , 64(8):3141â€“3155, 2019.
[3] Erik Berglund, Sindri Magnusson, and Mikael Johansson. Distributed
newton method over graphs: Can sharing of second-order information
eliminate the condition number dependence? IEEE Signal Processing
Letters , PP:1â€“1, 05 2021.
[4] Amir Daneshmand, Gesualdo Scutari, Pavel Dvurechensky, and
Alexander Gasnikov. Newton method over networks is fast up to the
statistical precision. In Marina Meila and Tong Zhang, editors, Pro-
ceedings of the 38th International Conference on Machine Learning ,
volume 139 of Proceedings of Machine Learning Research , pages 2398â€“
2409. PMLR, 18â€“24 Jul 2021.
35[5] R. S. Dembo, S. C Eisenstat, and T. Steihaug. Inexact Newton meth-
ods. SIAM Journal on Optimization , (2):400â€“408, 1982.
[6] S. C. Eisenstat and H. F. Walker. Globally convergent inexact Newton
methods. SIAM Journal on Optimization , 4:393â€“422, 1994.
[7] Ceyhun Eksin and Alejandro Ribeiro. Distributed network optimization
with heuristic rational agents. IEEE Transactions on Signal Processing ,
60(10):5396â€“5411, 2012.
[8] A. Fromer and D. Szyld. On asychronous iterations. Journal of Com-
putational and Applied Mathematics , 123(1-2):201â€“216, 2000.
[9] F. Hanzely, S. Hanzely, S. HorvÂ´ ath, and P. RichtÂ´ arik. Lower bounds and
optimal algorithms for personalized federated learning. In Proceedings
of the 34th International Conference on Neural Information Processing
Systems , NIPSâ€™20. Curran Associates Inc., 2020.
[10] D. JakovetiÂ´ c. A unification and generalization of exact distributed first-
order methods. IEEE Transactions on Signal and Information Process-
ing over Networks , 5(1):31â€“46, 2019.
[11] D. JakovetiÂ´ c, D. BajoviÂ´ c, N. KrejiÂ´ c, and N. Krklec JerinkiÂ´ c. Newton-like
method with diagonal correction for distributed optimization. SIAM
Journal on Optimization , 27(2):1171â€“1203, 2017.
[12] D. JakovetiÂ´ c, N. KrejiÂ´ c, and N. Krklec JerinkiÂ´ c. Exact spectral-like gra-
dient method for distributed optimization. Computational Optimization
and Applications , 74:703â€“728, 2019.
[13] D. JakovetiÂ´ c, N. KrejiÂ´ c, and N. Krklec JerinkiÂ´ c. EFIX: Exact fixed point
methods for distributed optimization. Journal of Global Optimization ,
2022.
[14] D. JakovetiÂ´ c, N. KrejiÂ´ c, and N. Krklec JerinkiÂ´ c. A Hessian inversion-
free exact second order method for distributed consensus optimization.
IEEE Transactions on signal and information processing over networks ,
8:755â€“770, 2022.
[15] D. JakovetiÂ´ c, J. M. F. Moura, and J. Xavier. Nesterov-like gradient
algorithms. CDCâ€™12, 51stIEEE Conference on Decision and Control ,
pages 5459â€“5464, 2012.
36[16] D. JakovetiÂ´ c, J. Xavier, and J. M. F. Moura. Fast distributed gradient
methods. IEEE Transactions on Automatic Control , 59(5):1131â€“1146,
2014.
[17] D. JakovetiÂ´ c, N. KrejiÂ´ c, N. Krklec JerinkiÂ´ c, G. Malaspina, and
A. Micheletti. Distributed fixed point method for solving systems of
linear algebraic equations. Automatica , 134(8), 2021.
[18] C. Kanzow and M. Lapucci. Inexact penalty decomposition methods
for optimization problems with geometric constraint. Computational
Optimization and Applications , 85:937â€“971, 2023.
[19] N. KrejiÂ´ c and Z. LuË‡ zanin. Newton-like method with modification of
the right-hand side vector. Mathematics of Computation , 71:237â€“250,
2002.
[20] NataË‡ sa Krklec JerinkiÂ´ c, DuË‡ san JakovetiÂ´ c, NataË‡ sa KrejiÂ´ c, and Dragana
BajoviÂ´ c. Distributed second-order methods with increasing number of
working nodes. IEEE Transactions on Automatic Control , 65(2):846â€“
853, 2020.
[21] N. Li and G. Qu. Harnessing smoothness to accelerate distributed opti-
mization. IEEE Transactions Control of Network Systems , 5(3):1245â€“
1260, 2017.
[22] Huikang Liu, Jiaojiao Zhang, Anthony Man-Cho So, and Qing Ling. A
communication-efficient decentralized newtonâ€™s method with provably
faster convergence, 2022.
[23] J. Liu, A. S. Morse, A. NediÂ´ c, and T. BaÂ¸ sar. Exponential convergence
of a distributed algorithm for solving linear algebraic equations. Auto-
matica , 83:37â€“46, 2017.
[24] J. Liu, S. Mou, and A. S. Morse. A distributed algorithm for solving
a linear algebraic equation. Proceedings of the 51st Annual Allerton
Conference on Communication, Control, and Computing , 60(11):267â€“
274, 2013.
[25] F. Mansoori and E. Wei. Superlinearly convergent asynchronous dis-
tributed network newton method. 2017 IEEE 56th Annual Conference
on Decision and Control (CDC) , page 2874â€“2879, 2017.
37[26] F. Mansoori and E. Wei. Superlinearly convergent asynchronous dis-
tributed network Newton method. 2017 IEEE 56th Annual Conference
on Decision and Control (CDC) , pages 2874â€“2879, 2017.
[27] A. Mokhtari, Q. Ling, and A. Ribeiro. Network Newton distributed
optimization methods. IEEE Transactions on Signal Processing ,
65(1):146â€“161, 2017.
[28] A. Mokhtari, W. Shi, Q. Ling, and A. Ribeiro. A decentralized second-
order method with exact linear convergence rate for consensus opti-
mization. IEEE Transactions on Signal and Information Processing
over Networks , 2(4):507â€“522, 2016.
[29] A. NediÂ´ c, A. Olshevsky, and W. Shi. Achieving geometric convergence
for distributed optimization over time-varying graphs. SIAM Journal
on Optimization , 27(4):2597â€“2633, 2017.
[30] A. NediÂ´ c, A. Olshevsky, W. Shi, and C. A. Uribe. Geometrically conver-
gent distributed optimization with uncoordinated step sizes. American
Control Conference , pages 3950â€“3955, 2017.
[31] A. NediÂ´ c and A. Ozdaglar. Distributed subgradient methods for
multi-agent optimization. IEEE Transactions on Automatic Control ,
54(1):48â€“61, 2009.
[32] B. Polyak and A. Tremba. New versions of Newton method: Step-size
choice, convergence domain and under-determined equations. Opti-
mization Methods and Software , 35(6):1272â€“1303, 2020.
[33] F. Saadatniaki, R. Xin, and U. A. Khan. Decentralized optimization
over time-varying directed graphs with row and column-stochastic ma-
trices. IEEE Transactions on Automatic Control , 60(11):4769â€“4780,
2020.
[34] G. Shi and K. H. Johansson. Finite-time and asymptotic convergence
of distributed averaging and maximizing algorithms. arXiv:1205.1733 ,
2012.
[35] W. Shi, Q. Ling, G. Wu, and W. Yin. Extra: an exact first-order
algorithm for decentralized consensus optimization. SIAM Journal on
Optimization , 25(2):944â€“966, 2015.
38[36] A. Sundararajan, B. Van Scoy, and L. Lessard. Analysis and de-
sign of first-order distributed optimization algorithms over time-varying
graphs. arxiv preprint, arXiv:1907.05448 , 2019.
[37] A. Tsanas, M. A. Little, C. Fox, and L. O. Ramig. Objective automatic
assessment of rehabilitative speech treatment in parkinsonâ€™s disease.
IEEE Transactions on Neural Systems and Rehabilitation Engineering ,
22:181â€“190, 2014.
[38] Paul Vanhaesebrouck, AurÂ´ elien Bellet, and Marc Tommasi. Decentral-
ized collaborative learning of personalized models over networks. In
AISTATS , 2017.
[39] M. Wu, N. Xiong, Vasilakos A. V., V. C. M. Leung, and C. L. P. Chen.
Rnn-k: A reinforced Newton method for consensus-based distributed
optimization and control over multiagent systems. IEEE Transactions
on Cybernetics , 52(5):4012â€“4026, 2022.
[40] L. Xiao, S. Boyd, and S. Lall. Distributed average consensus with time-
varying metropolis weights. Automatica , 2006.
[41] R. Xin and U. A. Khan. Distributed heavy-ball: a generalization and
acceleration of first-order methods with gradient tracking. IEEE Trans-
actions on Automatic Control , 65(6):2627â€“2633, 2020.
[42] R. Xin, C. Xi, and U. A. Khan. Frostâ€”fast row-stochastic optimiza-
tion with uncoordinated step-sizes. EURASIP Journal on Advances in
Signal Processingâ€”Special Issue on Optimization, Learning, and Adap-
tation over Networks , 1, 2019.
[43] J. Xu, S. Zhu, Y. C. Soh, and L. Xie. Augmented distributed gradient
methods for multi-agent optimization under uncoordinated constant
step sizes. IEEE Conference on Decision and Control , pages 2055â€“
2060, 2015.
[44] D.M. Young. Iterative solution of large linear systems. Academic Press ,
1971.
[45] K. Yuan, Q. Ling, and W. Yin. On the convergence of decentralized
gradient descent. SIAM Journal on Optimization , 26(3):1835â€“1854,
2016.
39[46] K. Yuan, B. Ying, X. Zhao, and A. H. Sayed. Exact diffusion for dis-
tributed optimization and learning â€” part I: Algorithm development.
IEEE Transactions on Signal Processing , 67(3):708â€“723, 2019.
[47] J. Zhang, Q. Ling, and A. M. C. So. A Newton tracking algorithm
with exact linear convergence for decentralized consensus optimization.
IEEE Transactions on Signal and Information Processing over Net-
works , 7:346â€“358, 2021.
[48] J. Zhang, K. You, and BaÂ¸ sar T. Distributed adaptive Newton methods
with global superlinear convergence. Automatica , 138, 2022.
40