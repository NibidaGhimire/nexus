Distributed Inexact Newton Method with Adaptive
Step Sizes
Duˇ san Jakoveti´ c∗, Nataˇ sa Kreji´ c∗, Greta Malaspina†
Abstract
We consider two formulations for distributed optimization wherein
Nnodes in a generic connected network solve a problem of common
interest: distributed personalized optimization and consensus opti-
mization. A new method termed DINAS (Distributed Inexact Newton
method with Adaptive step size) is proposed. DINAS employs large
adaptively computed step sizes, requires a reduced global parameters
knowledge with respect to existing alternatives, and can operate with-
out any local Hessian inverse calculations nor Hessian communications.
When solving personalized distributed learning formulations, DINAS
achieves quadratic convergence with respect to computational cost and
linear convergence with respect to communication cost, the latter rate
being independent of the local functions condition numbers or of the
network topology. When solving consensus optimization problems, DI-
NAS is shown to converge to the global solution. Extensive numerical
experiments demonstrate significant improvements of DINAS over ex-
isting alternatives. As a result of independent interest, we provide for
the first time convergence analysis of the Newton method with the
adaptive Polyak’s step size when the Newton direction is computed
inexactly in centralized environment.
∗Department of Mathematics and Informatics, Faculty of Sciences, University
of Novi Sad, Trg Dositeja Obradovi´ ca 4, 21000 Novi Sad, Serbia, Email: du-
san.jakovetic@dmi.uns.ac.rs, natasak@uns.ac.rs, The work of D. Jakoveti´ c and N. Kreji´ c
was supported by the Science Fund of the Republic of Serbia, Grant no. 7359, Project
LASCADO.
†Dipartimento di Ingegneria Industriale, Universit` a degli studi di Firenze, Viale G.B.
Morgagni 40, 50134 Firenze, Italy. Member of the INdAM Research Group GNCS. Email:
greta.malaspina@unifi.it. This work is partially supported by the BIGMATH project
which has received funding by the European Union’s Horizon 2020 research and innovation
programme under the Marie Sk lodowska-Curie Grant Agreement no. 812912, and by
Partenariato esteso FAIR “Future Artificial Intelligence Research” SPOKE 1 Human-
Centered AI. Obiettivo 4, Project “Mathematical and Physical approaches to innovative
Machine Learning technologies (MaPLe)”.
1arXiv:2305.13985v2  [math.OC]  14 Jan 20251 Introduction
We consider distributed optimization problems where a network of Ncom-
putational nodes, interconnected by a generic undirected connected network,
collaborate in order to solve a problem of common interest. Specifically, we
consider the following two widely used problem formulations:
minNX
i=1fi(xi) +1
2βX
{i,j}∈Ewij∥xi−xj∥2(1)
minf(y) =NX
i=1fi(y). (2)
Here,∥ · ∥denotes the Euclidean norm; fi:Rn→Ris a local cost function
available to node i;xi∈Rn,i= 1, ..., n , and y∈Rnare optimization
variables; i= 1, ..., N ;Edenotes the set of undirected edges; β > 0 is a
parameter; and wij>0,{i, j} ∈E, are positive constants. Formulation (1)
arises, e.g., in personalized decentralized machine learning, e.g., [1, 7, 20,
25, 38]; see also [9] for a related formulation in federated learning settings.
Therein, each node iwants to find its personalized local model xiby fitting
it against its local data-based loss function fi. In typical scenarios, the data
available to other nodes j̸=iare also useful to node i. One way to enable
node ilearn from node j’s local data is hence to impose a similarity between
the different nodes’ models. This is done in (1) by adding a quadratic penalty
term, where parameter wij>0 encodes the “strength” of the similarity
between node i’s and node j’s models.1The quantities wij’s also respect
the sparsity pattern of the underlying network, i.e., they are non-zero only
for the node pairs i, jthat can communicate directly, i.e., for those pairs i, j
such that {i, j} ∈E.Throughout the paper, we refer to formulation (1) as
distributed personalized optimization, or penalty formulation.
Formulation (2) has also been extensively studied, e.g., [31, 10, 11, 15,
16, 21, 29, 35, 36, 43]. It is related with (1) but, unlike (1), there is a global
model (optimization variable) y∈Rncommon to all nodes, i.e., the nodes
want to reach a consensus (agreement) on the model. Formulation (1) may
be seen as an inexact penalty variant of (2), with the increasing approxi-
mation accuracy as βbecomes smaller. This connection between the two
formulations has also been exploited in prior works, e.g., [27], in order to de-
velop new methods for solving (2). In other words, once a distributed solver
1In order to simplify the presentation, we let the wij’s satisfyP
j̸=iwij<1 and also
introduce an arbitrary common multiplicative constant β >0.
2for (1) is available, one can also solve (2) approximately by taking a small
β, or exactly by solving a sequence of problems (2) with an appropriately
tuned decreasing sequence of β’s. We refer to formulation (2) as distributed
consensus optimization, or simply consensus optimization.
In this paper, we also follow this path and first devise a method for
solving (1) with a fixed β; we then capitalize on the latter to derive solvers
for (2).
There is a vast literature for solving problems of type (2) and (1). We
first discuss formulation (2). In general one can distinguish between several
classes of methods. To start, a distributed gradient (DG) method has been
considered in [31]. Given that the gradient method with fixed step size
cannot achieve exact convergence, a number of methods, belonging to the
class of gradient tracking methods which assume that additional information
is shared among nodes, are proposed and analysed, [10, 11, 15, 16, 21, 29,
35, 36, 43]. In these methods the objective function is assumed to be convex
with Lipschitz-continuos gradient, the gradient tracking scheme is employed
with a fixed steps size, and the exact convergence to is reached. The step
size required in order to ensure convergence needs to be smaller than a
threshold that depends on global constants such as strong convexity and
gradient’s Lipschitz constant; the constant also needs to be known by all
nodes beforehand.
In [30, 43, 41, 42, 46], the case of uncoordinated time-invariant step sizes
is considered.
In [12], a modification of the gradient tracking method, with step sizes
varying both across nodes and across iterations is proposed. Time varying
networks are considered in [29, 33]. Again, the step sizes in all of these meth-
ods depend on some global constants (like strong convexity and Lipschitz).
The actual implementation is subject to estimation of these constants and
very often leads to costly hand-tuning of step size parameters.
If the optimization problem of interest is ill-conditioned, first order meth-
ods might be very slow, and second order methods appear as an attractive
alternative. When considering second order methods in a distributed and
large-scale framework, there are a few issues that need to be addressed.
First, as in the classical (centralized) optimization framework, Hessian-based
methods are typically quite expensive: while in the distributed framework
the work of computing the Hessian is shared by the nodes and therefore may
not represent a major issue, solving the linear system typically required at
each iteration to compute the Newton-like direction may be prohibitively ex-
pensive for problems of very large sizes. Secondly, while we normally assume
that nodes can share the local vector of variables and the local gradients (or
3some other vectors of magnitudes comparable to the variable dimension n),
sharing the Hessian cause communication costs quadratic in n. Finally, one
would like to have superlinear or quadratic convergence for a second order
method. However, in a distributed framework when solving (2) or (1), there
are two main obstacles: reaching consensus, and the choice of the step size.
These issues are addressed in the literature in several ways so far.
We first discuss second order methods that solve (1). In [27] the au-
thors propose a distributed version of the classical Newton method, dubbed
Network Newton – NN, that relies on a truncated Taylor expansion of the
inverse Hessian matrix. NN solves exactly (1) and yields an inexact solution
of (2). The approximation of the inverse Hessian with NN involves inver-
sion of local (possibly dense) Hessians of the fi’s. Linear convergence of the
method to the solution of (1) is proved if standard assumptions for the New-
ton method hold, for a suitable choice of the step size. In [39] a modification
of NN method is proposed, that employs a reinforcement strategy.
Several second order methods are proposed that solve (2). In [28] the
direction is computed using the same approximation strategy as in NN,
but within primal-dual strategy. The method proposed in [14] relies on
primal-dual framework as well but computes the direction inexactly. Thus,
the method avoids any kind of matrix inversion and relies on a fixed point
iterative method for computing the search direction. This leads to favorable
performance for problems with a relatively large n.In [47] the gradient-
tracking strategy is extended to the case of the Newton method.
Current second order methods that solve (1) such as [27] and [25] con-
verge at best linearly to the solution of (1).2Moreover, the step size by
which a Newton-like step is taken depends on several global constants and
is usually very small, leading to slow convergence in applications. The choice
of the step size is of fundamental importance for a method to achieve both
global convergence and fast local convergence. Classical line-search strate-
gies, which effectively solve this issue in the centralized framework, are not
applicable in the distributed setting as they require knowledge of the value
of the global function at all nodes and may require several evaluation at
each iteration, which would yield prohibitively large communication traffic.
In [48] the authors propose a method termed DAN, [48] proposes a method
for solving (2), but it may be generalized to solving (1) such that similar
convergence rate guarantees hold order-wise. The method employs a finite-
2It has been shown that the methods in [27] and [25] exhibit an error decay of a
quadratic order only for a bounded number of iterations, while the actual convergence
rate is linear.
4time communication strategy to share the local hessians through the whole
network and makes use of the step size proposed in [32] for the Newton
method in the centralized case, which ensures both global convergence and
fast local convergence. Given that sharing all local hessians among nodes
might be too expensive for problems of even moderate size, a version of
DAN that employs and shares through the whole network rank one approx-
imations of the local hessians is proposed. The step size is again defined by
the global constants such as strong convexity and Lipschitz constants. In [4]
the authors propose a distributed Newton method with cubic regularization
for solving empirical risk minimization problems. In [3] the authors propose
a Distributed Newton method for the solution of quadratic problems that
requires the nodes to share both vectors and matrices, and prove that the
convergence on the method depends only on the logarithm of the condition
number of the problem. In particular they prove that sharing second or-
der information can improve the performance of distributed methods when
the condition number of the problem is large. In [22] the authors combine
the idea of sharing compressed Hessian information with that of performing
several rounds of consensus at each iteration of the method, then show that
the method they propose achieves asymptotically superlinear convergence
when the number of consensus rounds at every iterations tends to infinity.
In summary, current second order methods for solving (1) suffer from
at least one of the following drawbacks. Only linear convergence rate is
achieved, both with respect to the number of local functions fi’s gradient
and Hessian evaluations, and with respect to the number of inter-node com-
munication rounds. The methods require knowledge of global constants
beforehand in order for step size to be set, usually leading to small step size
choices and slow convergence. If a superlinear or quadratic convergence is
reached, this comes at a O(n2) cost of local Hessians’ communication.
Contributions . We propose a new method termed DINAS (Distributed
Inexact Newton method with Adaptive step size) that can solve both (1)
and (2) formulations. When solving (1), DINAS achieves linear, superlinear
or quadratic convergence to the solution in terms of the number of outer it-
erations. In more detail, the method achieves, in a best scenario, a quadratic
convergence with respect to the number of local gradient and local Hessian
evaluations, and a linear convergence with respect to the number of com-
munication rounds. Moreover, the communication-wise linear convergence
rate is independent of local functions’ condition numbers or of the underlying
network topology, and it is hence significantly improved over the linear rates
5achieved in the literature so far. DINAS uses an adaptive step size that can
be computed at each iteration with a reduced knowledge of global constants
required when compared with existing alternatives. It computes the search
direction by using a suitable linear solver, i.e., an approximate solution of
the Newton linear system is computed in a distributed way at each iteration
via an iterative solver. To make the presentation easier to follow we specify
here the method with Jacobi Overrelaxation, JOR, as the linear solver of
choice, but any other linear solver that is implementable in the distributed
environment can be applied. After computation of the approximate Newton
direction of suitable level of inexactness, the step size is computed based
on the progress in gradient decrease, and the new iteration is computed.
The step size computation is an adaptation to the distributed framework of
the step size presented in [32] for the classical Newton method. This way
we achieve global convergence of the method. Furthermore, adaptive step
size allows us to maintain fast local convergence. The rate of convergence
is controlled by the forcing terms as in the classical Inexact Newton meth-
ods, [5], depending on the quality of approximation of the Newton direction
obtained by JOR method. Thus one can balance the cost and convergence
rate depending on the desired precision and adjust the forcing term during
the iterative process. The fact that we do not need any matrix inversion and
solve the linear system only approximately reduces the computational cost
in practice by several orders of magnitude, in particular if the dimension n
is relatively large.
For formulation (2), we employ DINAS by solving a sequence of problems
(1) with an appropriately chosen decreasing sequence of penalty parameters
β, and show that the overall scheme converges to the solution of (2). While
we do not have theoretical convergence rate guarantees for solving (2), ex-
tensive numerical experiments demonstrate significant improvements over
state-of-the-art distributed second order solvers of (2). The results also
confirm that DINAS is particularly efficient for large dimensional (large n)
settings.
Finally, an important byproduct of the convergence theory for the dis-
tributed case developed here is the convergence of the classical (centralized)
Newton method with the Polyak adaptive step size when the Newton direc-
tions are computed inexactly. To the best of our knowledge, only the exact
Newton method with the Polyak step size has been analyzed to date.
This paper is organized as follows. In Section 2 we describe the dis-
tributed optimization framework that we consider and formulate the as-
sumptions. The DINAS algorithm is presented and discussed in Section 3.
The analysis of DINAS for formulation (1) is given in Section 4. The analy-
6sis of the centralized Newton method with the Polyak step size and inexact
Newton-like updates is given in Section 5, while the analysis for formulation
(2) is presented in Section 6. Numerical results are provided in Section 7.
We offer some conclusions in Section 8.
2 Model and preliminaries
Assume that a network G= (V,E) of computational nodes is such that node
iholds the function fiand can communicate directly with all its neighbors in
G. Moreover, assume that each node hold a local vector of variables xi∈Rn.
The properties of the communication network are stated in the assumption
below.
Assumption A1. The network G= (V,E)is undirected, simple and con-
nected, and it has self-loops at every node, i.e., (i, i)∈Efor every i=
1, . . . , N .
We associate the communication matrix Wto the graph Gas follows.
Assumption A2. The matrix W= [wij]∈RN×Nis symmetric and doubly
stochastic such that if (i, j)/∈Ethen wij= 0, wij̸= 0,(i, j)∈Eandwii̸=
0, i= 1, . . . , N.
Double stochastic matrix means that all elements of the matrix are non-
negative and they sum up to 1 by columns and rows, i.e.Pn
i=1wij=
1,Pn
j=1wij= 1.Hence wij∈[0,1].Given the communication matrix W
that satisfies Assumption A2 we can associate each node iwith its neigh-
borsj∈Oi.Clearly wij̸= 0 if j∈Oi, wii̸= 0 andP
j∈Oiwij+wii= 1.The
communication matrix is also called consensus matrix.
The method we propose here is a Newton-type method, hence we assume
the standard properties of the objective function. We use the symbol ≺to
denote the following matrix property: A≺Bmeans that A−Bis a positive
definite matrix.
Assumption A3. Let each fi, i= 1, . . . , N be a two times continuously
differentiable, strongly convex function such that for some 0< µ < M there
holds
µI≺ ∇2fi(y)≺MI. (3)
The Hessian is Lipschitz continuous and for some L >0and all y, z∈Rn
we have
∥∇2fi(y)− ∇2fi(z)∥∞≤L∥y−z∥∞. (4)
7We are also interested in (1). It can be expressed as follows. Let
F(x) =NX
i=1fi(xi),
where x= (x1, . . . ,xN)∈RnN,xi∈Rn.Then (2) is equivalent to the
following constrained problem
min
x∈RnNF(x) s.t. xi=xj, i, j∈ {1, . . . , N }.
Notice that Assumption A3 implies that Fis strongly convex and its Hessian
is Lipschitz continuous with the same constants µ, M andL.
Assuming that Wis a consensus matrix associated with the network G,
we define W=W⊗Inwith Inbeing the identity matrix in Rnand⊗the
Kronecker product. Since Wis a doubly stochastic matrix, we have that
Wx=xif and only if xi=xjfor every i, j= 1, . . . , N, [27] and therefore,
problem (2) is equivalent to the following problem
min
x∈RnNF(x),s.t. (I−W)1/2x= 0. (5)
Clearly, one can state the constraint in (5) in different ways, for example
(I−W)x= 0, but the formulation in (5) is the most common one as it
allows us to consider the quadratic penalty as stated in (6) below. Given
β >0, we consider the following problem, equivalent to (1):
min
x∈RnNΦβ(x) with Φ β(x) =F(x) +1
2βx⊤(I−W)x. (6)
The relationship between (6) and (2) is analysed in [45]. In particular, it is
known that the penalty problem (6) yields an approximate solution of (2)
such that ∥x∗
i−y∗∥=O(β/(1−λ2)) where x∗= (x∗
1, . . . ,x∗
N) is the solution
of (6), y∗is the solution of (2) and λ2is the second largest eigenvalue of
W.First we will be concerned with the solution of (6). Later in Section
6 we deal with a sequence of penalty problems, with decreasing values of
the penalty parameter βthat allow us to reach the solution of (2) with
an arbitrary precision. This approach in some sense mimics the penalty
decomposition methods in the classical computational framework, where
one deals with a sequence of penalty problems, defined in different ways, to
solve the original problems. The decomposition is usually defined splitting
the set of constraints into sets of easy and difficult constraints, and then a
sequence of problems is solved, possibly inexactly, using different optimality
conditions, for example see [18].
83 Algorithm DINAS: Personalized distributed op-
timization
The classical Inexact Newton iteration for (6), given the current iteration
xkand the forcing parameter ηk,is defined as
xk+1=xk+αkdk,
where αk>0 is the step size, dkis computed from
∇2Φβ(xk)dk=∇Φβ(xk) +rk(7)
andrkis the residual vector that satisfies
∥rk∥∞≤ηk∥∇Φβ(xk)∥∞. (8)
The forcing term ηkis bounded from above, ηk≤η <1 while the step size
αkis determined by line search or some other globalization strategy, [6]. If
ηk= 0 the method is in fact the Newton’s method and the step size can
be determined as in [32]. Notice that we are using the norm ∥ · ∥∞in the
above expressions as that norm is suitable for the distributed case we are
interested in.
In the context of the setting presented in (7)–(8), we can distinguish our
theoretical and numerical contributions. Our theoretical contributions are
grounded on 1) novel analysis of inexact Newton methods when the residual
error satisfies condition (8); and 2) showing that a wide class of iterative
distributed solvers can be designed such that it satisfies condition (8). Our
numerical contributions are to develop, test and validate efficient iterative
solvers that solve (7) up to accuracy (8).
To apply an Inexact Newton method in distributed framework we need
to compute the direction dksuch that (8) holds and to determine the step
size. Note that directly solving (7) would require the inversion of matrix
∇2Φβ(xk). This is however not amenable in distributed setting. Namely,
while the matrix ∇2Φβ(xk) has a block-sparsity structure that respects the
sparsity pattern of the network, its inverse may not have this property,
and hence a direct solution of (7) by the matrix inversion is not possible.
However, as the matrix ∇2Φβ(xk) is block-sparse according to the network
structure, we can apply carefully designed iterative fixed point solvers in
order to solve (7) up to the accuracy defined by (8). For this purpose, a
number of methods for solving linear systems in distributed framework may
be used, [24, 23, 17]. It turns out that a class of fixed point methods may be
9used without any changes, [13, 14]. The application of Jacobi Overrelaxation
(JOR) method to the system (7) is specified here but the theoretical analysis
holds for any solver assuming that (8) is valid.
For the sake of clarity let us briefly state the JOR method for solving
(7), while further details can be seen in [13, 14]. First of all notice that the
system matrix ∇2Φβ(xk) =∇2F(xk) +1
β(I−W) is symmetric and positive
definite due to strong convexity of F,positive βand the fact that ( I−W) is
positive semidefinite matrix. Given the current approximation dk,ℓ∈RnN,
where ℓdenotes the inner iteration counter ℓ= 0,1. . . ,for solving the linear
system, we can describe the next iteration of JOR method for solving (7) as
follows. Denoting the Hessian Hk= [Hk
ij] =∇2Φβ(xk)∈RnN×nN, Hk
ii=
∇2fi(xk
i) +1
β(1−wii)In, Hk
ij=−1
βwijIn, i̸=j,with the diagonal part of
each Hk
iidenoted by Dk
ii,the gradient gk= (gk
1, . . . ,gk
N),gk
i=∇fi(xk
i) +
1
β((1−wii)xk
i−P
j∈OIwijxk
j), i= 1, . . . , N and with the relaxation parameter
ω∈R, that will be defined later on, the next iteration of JOR method for
solving (7) is given by
dk,ℓ+1
i =dk,ℓ
i+ω(Dk
ii)−1
gk
i−NX
j=1Hk
ijdk,ℓ
j
. (9)
Performing enough iterations of (9) we can get dk=dk,ℓsuch that (8)
holds. It is easy to see that (9) is distributed as each node iholds the
blocks Hk
ii, Hk
ij, j∈Oi,i.e., each node holds the corresponding row Hk
iof
the Hessian Hk,the local gradient component gk
iand the nodes need to
share their approximate solutions dk,ℓ
ionly among neighbours. The method
is converging for a suitable value of 0 < ω < 2β(1−¯w)/(M+ 2β),with
¯w= max 1≤i≤Nwii,see [13] for details. From now on we will assume that
ωis chosen such that JOR method converges, with further implementation
details postponed to Section 7.
Notice that, in order for parameter ωto be properly set, nodes need to
know beforehand the global constants ¯ wandM. These two constants that
corresponds to maxima of certain local nodes’ quantities across the network
can be precomputed by running beforehand two independent algorithms for
the maximum computation such as [34]. In addition, DINAS can alleviate
the requirement for such knowledge if JOR is replaced by the following
iterative method:
dk,ℓ+1
i =h
∇2fi(xk
i) + (1 /β)Ii−1
X
j∈Oiwij(1/β)dk,ℓ
j+gk
i
, (10)
10fori= 1, ..., N in parallel. The iterative method (10) does not require any
beforehand knowledge of global parameters, at the cost of the requirement
for local Hessian inverse calculations. It is easy to see that (10) converges
linearly, and there holds:
∥dk,ℓ+1−dk,⋆∥ ≤1/β
1/β+µ∥dk,ℓ−dk,⋆∥,
where dk,⋆=
∇2Φβ(xk)−1∇Φβ(xk) is the exact solution of (7).
Having a distributed algorithm for solving the system of linear equations,
let us explain the adaptive step size strategy employed here. The basic
assumption is that the global constants µandLare not available. Classical
line search method, without the global constants, is not applicable in the
distributed settings as it requires the value of the global function at each
node, which would be very costly in terms of communications. Furthermore,
several values of global function value might be needed in each iteration to
compute the line search step size. Thus we employ the procedure that is
governed by a sequence of parameters {γk}that are used to generate the
step sizes, adopting the reasoning for the Newton method from [32] to the
case of distributed and inexact method. In each iteration we try the step
size based on the current value of γkand check if such step size generates
enough decrease in the gradient. If the decrease is large enough the step
size is accepted and we proceed to a new iteration. If not, the step size is
rejected, the value of γkis reduced and a new step size is tried with the
same direction. Thus the checking procedure is cheap as the direction stays
the same and we will show that it eventually ends up with a step size that
generates enough decrease.
The step size computation includes the infinity norm of the gradient
in the previous iteration and all nodes need this value. Therefore we use
the algorithm from [48] for exchange of information around the network.
Recall that in [48] the nodes exchange either local Hessians or their rank one
approximations, while in DINAS they exchange only scalars. The algorithm
is included here for the sake of completeness. The distributed maximum
computation can be performed exactly in a finite number of communication
rounds, at most equal to the network diameter [34]. However we used the
algorithm from [48] as this does not make an important difference for DINAS
and makes numerical comparison presented in Section 7 easier to follow.
Algorithm 3.1 (DSF) .
Input: Each node i:{Si}i∈Nscalar messages
1:SetI0
i={Si}
112:fork= 0, . . . , N −1do
3:forj∈Oido
4: take S∈Ik−1
0such that Swas not received from node jand not
sent to node jat the previous iterations
5: send Sto node j
6:end for
7: update Ik
iadding the messages received by the neighbors
8:end for
Once the step is accepted the nodes run DSF algorithm exchanging the
infinity norms of local gradients to get the infinity norm of the aggregate
gradient and proceed to the new iteration. The algorithm is stated in a node-
wise fashion, to facilitate the understanding of the distributed flow although
a condensed formulation will be used later on, for theoretical considerations.
Algorithm 3.2 (DINAS) .
Iteration k, each node iholds: ηk,xk
i,gk
i, Hk
i, γk>0,∥gk∥∞, q∈
(0,1)
1:All nodes run distributed JOR iterations (9) to compute {dk
i}N
i=1such
that
∥Hk
idk
i−gk
i∥∞≤ηk∥gk∥∞,∀i= 1, . . . , N (11)
2:All nodes compute the step size
αk= min
1,1−ηk
(1 +ηk)2γk1
∥gk∥∞
3:Each node icomputes ˆxi=xk
i−αkdk
i
4:All nodes share ˆxiwith the neighbors in Oi
5:Each node icomputes ˆgi=∇fi(ˆxi) +1
β
ˆxi−P
jwijˆxj
6:All nodes run DSF (Algorithm 3.1) with message at node igiven by
Si=∥ˆgi∥∞
7:Each node icomputes ∥ˆg∥∞= max j=1:NSj
8:Each node iperforms the following check and conditional updates
9:if
αk<1and∥ˆg∥∞≤ ∥gk∥∞−1
2(1−ηk)2
(1 +ηk)2γk (12)
or
αk= 1and∥ˆg∥∞≤ηk∥gk∥∞+1
2γk(1 +ηk)2∥gk∥2
∞ (13)
then
1210: setγk+1=γk
11: setxk+1
i=ˆxi,gk+1
i=ˆgi,∥gk+1∥∞=∥ˆg∥∞
12: define Hk+1
i=
Hk+1
i1, . . . , Hk+1
iN
∈Rn×nNwith
Hk+1
ii=∇2fi(xk+1
i) +1
β(1−wii)In, Hk+1
ij=−1
βwijIn, j̸=i
13:else
14: setγk=qγkand return to line 2
15:end if
Let us briefly comment the computational and computational costs of
DINAS here, with further details postponed to Section 7. Application of
JOR method for solving (7) implies that in each inner (JOR) iteration all
nodes share their current approximations dk,ℓ
iwith neighbours. Each itera-
tion of JOR method includes only the inversion of local diagonal matrix and
is hence rather cheap. Depending on the value of ηkthe number of inner
iterations can vary but the right hand side of (8) ensures that initially we
solve (7) rather loosely, with relative large residual and small computational
effort while the accuracy requirements increase as the gradients gets smaller
and we approach the solution. Therefore we completely avoid inversion of
(possibly very dense) local Hessians that is needed in NN method [27] and
in one version of DAN, [48]. Thus DINAS should be particularly effective
if the dimension of (2) is relatively large as the cost of JOR approximate
solution should be significantly smaller than the cost of exact solution (local
Hessian inversion) in each iteration of Network Newton method.
The condition (11) does not need to be verified online if a pre-defined
number of iterations is used and we will estimate that number later on.
Otherwise, if online verification is used, the nodes would need to run another
distributed maximum procedure to see that each node satisfies the condition
but such addition appears unnecessary. Communication costs of exchanges
needed to compute ∥g(xk)∥∞and∥ˆg∥∞are not large as the nodes exchange
only scalar values - the infinity norm of local gradient components.
The step size computation at line 2 is performed by each node but they
all compute the same value so that step is well defined. The check and
update defined at line 9 is again performed by all nodes using the same
values and hence the result will be the same at each node. Therefore, all
nodes go back to line 2 or all nodes update the approximate solution xk
iand
the if loop at line 9 is well defined. In the next section we will prove that
the if loop has finite termination.
13Regarding the global knowledge requirements of system constants, to
implement Step 6 (DSF or [34]), all nodes need to know beforehand an
upper bound on the number of nodes N, or on network diameter. Next, one
can utilize (10) with a single inner iteration and η= 1/(1 +βµ), and global
convergence of DINAS is ensured; see Theorem 4.1 ahead. Hence, for global
convergence, nodes only need to know beforehand an upper bound on Nand
a lower bound on µ. Notice that µcan be calculated beforehand by running
a distributed minimum algorithm computation [34] with the initialization at
node igiven by its local cost’s strong convexity constant. When compared
with alternative second order solvers such as NN [27] and [25], this is a
significantly reduced prior knowledge requirement as these methods require
the Lipschitz constans of Hessian and the gradient. When DINAS employs
additional tuning and knowledge of global constants, as it is assumed by
Theorems 4.2–4.4, then stronger results in terms of convergence rates are
ensured.
DINAS requires the scalar maximum-compute in Step 6 and synchro-
nized activities of all nodes in Steps 6–14. It is interesting to compare
DINAS with [48] that requires a similar procedure. While [48] utilizes such
procedure over local Hessians ( O(n2)-sized local messages), DINAS requires
Step 6 only for a scalar quantity. It is also worth noting that, in view of
Steps 6–14, DINAS is not easily generalizable to asynchronous settings as
done in [25], or to unreliable link/nodes settings although direction might be
computed by asynchronous JOR method [8]. However, for reliable and syn-
chronized networks, we emphasize that DINAS incurs drastic improvements
both theoretically (quadratic convergence) and in experiments, exhibiting
orders of magnitude faster rates when compared with existing alternatives.
4 Convergence analysis of DINAS for personalized
distributed optimization
Let us start the analysis proving that DINAS is well defined , i.e. proving
that the loop defined at line 9 has finite termination.
Lemma 4.1. Let Assumptions A1 - A3 hold. Then the following statements
hold:
i) if γk≤µ2/Lthen one of the condition at line 9 is satisfied;
ii) the number of times γkis reduced is bounded from above by log1/q 
γ0L/µ2
;
iii) for every k∈N0we have ¯γ < γ k≤γ0, with ¯γ=qµ2
L;
14iv) there exists ¯m1∈N0such that γk=γ¯m1for every k≥¯m1.
Proof. Since fis two times continuously differentiable we have that for any
α∈R
g(xk−αdk) =g(xk)−αHkdk−Z1
0α
H(xk−sαdk)−Hk
dkds
and therefore, by Assumption A3, (7) and (8)
∥g(xk−αdk)∥∞≤ ∥gk−α(gk+rk)∥∞+αZ1
0∥H(xk−sαdk)−Hk∥∞∥dk∥∞ds
≤ |1−α|∥gk∥∞+α∥rk∥∞+α2LZ1
0s∥dk∥2
∞ds
≤ |1−α|∥gk∥∞+αηk∥gk∥∞+α2L
2∥(Hk)−1(gk+rk)∥2
∞,
and we get
∥g(xk−αdk)∥∞≤(|1−α|+ηkα)∥gk∥∞+1
2L
µ2(1 +ηk)2α2∥gk∥2
∞.(14)
To prove the first statement we have to show that if γk≤µ2/Lthen either
(12) or (13) hold. From (14), if αk= 1 we have
∥ˆg∥∞≤ηk∥gk∥∞+1
2L
µ2(1 +ηk)2∥gk∥2
∞.
Otherwise, for αk<1, we get
∥ˆg∥∞≤
1−γk(1−ηk)2
∥gk∥∞(1 +ηk)2
∥gk∥∞+L
2µ2(1 +ηk)2γk(1−ηk)
(1 +ηk)2∥gk∥∞2
∥gk∥2
∞
≤ ∥gk∥∞+γk(1−ηk)2
(1 +ηk)2L
2µ2γk−1
.
Given that γk≤µ2/Lthe desired inequalities follow in both cases and we
geti).
By definition of γk+1(lines 10 and 13 in Algorithm DINAS), the sequence
{γk}is non increasing, the value of γkis reduced only when neither (12) nor
(13) are satisfied and in that case we decrease γkby a fixed q∈(0,1).This,
together with i) implies ii) and iii).Since we proved that {γk}is bounded
from below, iv) follows. □
15Lemma 4.1 implies in particular that for klarge enough γkbecomes
constant. While by iii) we know that γ¯m1≥qµ2/L, the Lemma does not
state that γkwill eventually reach qµ2/L.
Notice that the iteration of DINAS can be written in a compact form as
follows. Given xkanddksuch that (8) holds, we have xk+1=xk−αkdk
where
αk= min
1,1−ηk
(1 +ηk)2γk1
∥gk∥∞
. (15)
In the next theorem we prove convergence to the unique solution of (6).
Theorem 4.1. Assume that A1 - A3 hold, {ηk}is a nonincreasing sequence
such that 0≤ηk≤¯η <1andγ0>0.Let{xk}be an arbitrary sequence
generated by DINAS. Then
i) there exists ¯m2∈N0such that αk= 1for every k≥¯m1+ ¯m2, and
¯m2≤1
C
∥g¯m1∥∞−¯γ1−¯η
(1 + ¯η)2
+ 1
, C=qµ2
L(1−¯η)2
(1 + ¯η)2; (16)
ii)limk→∞∥gk∥∞= 0;
iii)limk→∞xk=x∗, where x∗is the unique solution of (6).
Proof. Let us first assume that at iteration kwe have step size
αk=1−ηk
(1 +ηk)2γk1
∥gk∥∞<1. (17)
Then (12) implies
∥gk+1∥∞≤ ∥gk∥∞−1
2γk(1−ηk)2
(1 +ηk)2. (18)
By Lemma 4.1 we have γk≥qµ2/L. Moreover, since(1−η)2
(1+η)2is a decreasing
function of ηforη∈(0,1) and ηk≤¯η <1 we have that, for every k
(1−ηk)2
(1 +ηk)2≥(1−¯η)2
(1 + ¯η)2>0,andγk(1−ηk)2
(1 +ηk)2≥qµ2
L(1−¯η)2
(1 + ¯η)2=:C >0
Replacing the last inequality in (18) we get
∥gk+1∥∞≤ ∥gk∥∞−C/2 (19)
16for every iteration index ksuch that αk<1.
Let us now consider the case where αk= 1.The by definition of αkthere
follows
∥gk∥∞≤γk1−ηk
(1 +ηk)2. (20)
From this inequality and (13) we have
∥gk+1∥∞≤ηk∥gk∥∞+1
2γk(1 +ηk)2∥gk∥2
∞
≤ηk∥gk∥∞+1
2(1−ηk)∥gk∥∞=1
2(1 +ηk)∥gk∥∞.(21)
Since ηk≤¯η <1, for every ksuch that αk= 1 we have, with ρ=1
2(1 + ¯η),
∥gk+1∥∞≤ρ∥gk∥∞. (22)
Letk > ¯m1. Ifαk= 1, by (20), (21), ηk+1≤ηk, and γk=γ¯m1=γk+1
we have
∥gk+1∥∞≤ρ∥gk∥∞≤ργk(1−ηk)
(1−ηk)2≤ργk+1(1−ηk+1)
(1−ηk+1)2,
which implies αk+1= 1.Denote with ¯ m2the smallest positive integer such
thatα¯m1+ ¯m2= 1. This, together with (17) which holds for k= ¯m1+ ¯m2−1
and (18) implies
γ¯m1+ ¯m2−11−η¯m1+ ¯m2−1
(1 +η¯m1+ ¯m2−1)2<∥g¯m1+ ¯m2−1∥∞≤ ∥g¯m1+ ¯m2−2∥∞−C
≤ ∥g¯m1∥∞−( ¯m2−1)C,
and thus
¯m2<1
C
∥g¯m1∥∞−γ¯m1+ ¯m2−11−η¯m1+ ¯m2−1
(1 +η¯m1+ ¯m2−1)2
+ 1
≤1
C
∥g¯m1∥∞−¯γ1−¯η
(1 + ¯η)2
+ 1.
Since we already proved that αk= 1 implies αk+1= 1 for every k≥¯m2,
i) holds. Inequalities (19) and (22), together with i), imply part ii) of the
statement.
It remains to prove that the sequence of iterates {xk}converges to the unique
17solution of (6). For every j∈Nwe have, by (7), (8), (22) and the bound on
ηk
∥d¯m1+ ¯m2+j∥∞≤ ∥ 
H¯m1+ ¯m2+j−1(g¯m1+ ¯m2+j+r¯m1+ ¯m2+j)∥∞
≤1
µ(1 + ¯η)∥g¯m1+ ¯m2+j∥∞≤1
µ(1 + ¯η)ρ∥g¯m1+ ¯m2+j−1∥∞≤1
µ(1 + ¯η)ρj∥g¯m1+ ¯m2∥∞.
Thus, for every s≥l≥0
∥x¯m1+ ¯m2+s−x¯m1+ ¯m2+l∥∞≤s−1X
j=l∥d¯m1+ ¯m2+j∥∞
≤1
µ(1 + ¯η)∥g¯m1+ ¯m2∥∞s−1X
j=lρj=1
µ(1 + ¯η)∥g¯m1+ ¯m2∥∞ρs−ρl
1−ρ.
So,{xk}is a Cauchy sequence and therefore there exists ¯x= lim k→+∞xk.
Since we already proved that lim k→+∞∥gk∥∞= 0, we have that ¯x=x∗.□
Remark 4.1. Theorem 4.1 shows that, like line search in the classical frame-
work, the adaptive strategy employed by Algorithm 3.2 ensures convergence
to the solution for any initial guess (i.e. global convergence), and also that
the full step αk= 1is accepted whenever ∥gk∥∞is small enough.
Remark 4.2. The method is convergent whenever ηk≤¯η <1.For suitable
choices of the relaxation parameter the spectral radius of the iterative matrix
of the JOR method is bounded away from 1, [44]. Therefore Theorem 4.1
hold if at each iteration of Algorithm 3.2 the nodes perform only one itera-
tion of JOR method and we have global convergence. The number of JOR
iterations needed for (11) is discussed later.
The forcing sequence {ηk}determines the rate of convergence as in the
centralized optimization, [5]. We obtain linear, superlinear or quadratic
convergence with a suitable choice of ηkas stated below.
Theorem 4.2. Assume that A1 - A3 hold, γ0>0and let {xk}be a sequence
generated by DINAS algorithm. If {ηk}is a nonincreasing sequence such that
ηk≤¯ηfor¯ηsmall enough then {xk}converges linearly in norm ∥ · ∥∞. If
ηk≤η∥gk∥δ
∞for some η≥0andklarge enough, then the convergence is
superlinear for δ∈(0,1)and quadratic for δ= 1.
Proof. We already proved in Theorem 4.1 that ∥gk∥∞andxkconverge to
0 and x∗respectively. In the following, we always assume that k≥¯m=
18¯m1+ ¯m2, and hence αk= 1 and γk=γ¯m.Forδ= 0, linear convergence
of∥gk∥∞follows directly from (22). Let us consider the case δ >0. For k
large enough, from (21) we have
∥gk+1∥∞≤ηk∥gk∥∞+1
2γk(1 +ηk)2∥gk∥2
∞
≤η∥gk∥1+δ
∞+1
γk∥gk∥2
∞≤η∥gk∥1+δ
∞+1
γ¯m∥gk∥2
∞.
Ifδ= 1 then
lim
k→+∞∥gk+1∥∞
∥gk∥2∞≤lim
k→+∞η∥gk∥2
∞+1
γ¯m∥gk∥2
∞
∥gk∥2∞=η+1
γ¯m,
which ensures quadratic convergence. If δ∈(0,1), then lim k→∞∥gk∥= 0
implies
lim
k→+∞∥gk+1∥∞
∥gk∥∞≤lim
k→+∞η∥gk∥1+δ
∞+1
γ¯m∥gk∥2
∞
∥gk∥∞= 0
Let us now consider the sequence xk.For every j∈Nwe have
∥x¯m+j+1−x∗∥∞=∥x¯m+j−x∗−d¯m+j∥∞
=∥x¯m+j−x∗−(H¯m+j)−1(g¯m+j+r¯m+j)∥∞
=∥(H¯m+j)−1∥∞∥H¯m+j(x¯m+j−x∗)−(g¯m+j+r¯m+j)∥∞
≤1
µ∥H¯m+j(x¯m+j−x∗)−(g¯m+j−g∗)∥∞+1
µ∥r¯m+j∥∞.
(23)
Since the objective function is twice continuously differentiable, we have
∥H¯m+j(x¯m+j−x∗)−(g¯m+j−g∗)∥∞
=Z1
0(H¯m+j−H(x¯m+j+s(x¯m+j−x∗))(x¯m+j−x∗)ds
∞
≤Z1
0sL∥x¯m+j−x∗)∥2
∞ds≤L
2∥x¯m+j−x∗)∥2
∞.
Replacing this term in (23) and using the bound on ∥rk∥∞we get
∥x¯m+j+1−x∗∥∞≤1
µL
2∥x¯m+j−x∗∥2
∞+1
µη¯m+j∥g¯m+j∥∞. (24)
19By Assumption A3 we have
∥gk∥∞=∥gk−g∗∥∞≤M∥xk−x∗∥∞.
Let us consider the case δ >0 and let us notice that, since xkconverges
tox∗, we can assume jis large enough so that ∥x¯m+j−x∗∥∞<1. So, by
definition of ηk
∥x¯m+j+1−x∗∥∞≤1
µL
2∥x¯m+j−x∗∥2
∞+1
µη∥g¯m+j∥1+δ
∞
≤1
µL
2+Mη
∥x¯m+j−x∗∥1+δ
∞
which proves superlinear and quadratic convergence for δ∈(0,1) and δ= 1,
respectively. For δ= 0 and ∥x¯m+j−x∗∥∞≤εwe have (24) and ηk≤¯η,
and
∥x¯m+j+1−x∗∥∞≤1
µL
2ε+M¯η
∥x¯m+j−x∗∥∞
Forε,¯ηsmall enough we have that1
µ L
2ε+M¯η
<1,which ensures linear
convergence and concludes the proof. □
The next statement gives the complexity result, i.e. we estimate the
number of iterations needed to achieve ∥gk∥∞≤ε.
Theorem 4.3. Assume that A1 - A3 hold, {ηk}is a nonincreasing sequence
of forcing parameters such that 0≤ηk≤¯η <1andγ0>0.Let{xk}be an
arbitrary sequence generated by DINAS. The number of iterations necessary
to reach ∥gk∥∞≤εfor a given ε >0is bounded from above by
kε=&
log 
ε−1∥g0∥∞
log(ˆρ−1)+ 1'
with
ˆρ= max(1 + ¯η)
2,1−qµ2
L(1−¯η)2
(1 + ¯η)21
∥g0∥∞
<1.
Proof. Let us consider inequalities (18) and (22) derived in the proof of
Theorem 4.1. For every index kwe have that if αk= 1 then ∥gk+1∥∞≤
ρ∥gk∥∞with ρ= (1 + ¯ η)/2. If αk<1 and C=qµ2
L(1−¯η)2
(1+¯η)2,then
∥gk+1∥∞≤ ∥gk∥∞−C/2≤ ∥gk∥∞
1−C
2∥g0∥∞
=:ρ2∥gk∥∞.
20Since αk<1, the definition of αkand inequalities γk≥qµ2/Landηk≤¯η <
1 imply
∥gk∥∞> γk1−¯ηk
(1 + ¯ηk)2≥qµ2
L1−¯η
(1 + ¯η)2> C
and thus ρ2∈(0,1).That is, denoting with ˆ ρ= max {ρ, ρ2}<1, we have
∥gk+1∥∞≤ˆρ∥gk∥∞.
Let us denote with kεthe first iteration such that ∥gkε∥∞≤ε.From the
inequality above, we have
ε <∥gkε−1∥∞≤ˆρ∥gkε−2∥∞≤ˆρkε−1∥g0∥∞,
which implies
ˆρkε−1>ε
∥g0∥∞
and thus
kε−1<log1/ˆρ 
ε−1∥g0∥∞
=log 
ε−1∥g0∥∞
log(ˆρ−1),
which concludes the proof. □
To complement the above result we give here an estimated number of
inner (JOR) iterations needed to satisfy (11).
Lemma 4.2. Assume that at every outer iteration kthe nodes run JOR
method starting at dk,0
i= 0for every i= 1, . . . , N, and let us denote with
Mk(ωk)the iterative matrix of JOR method. Then the number of JOR
iteration performed by the nodes to satisfy the termination condition (11)is
bounded from above by:
¯ℓk=ln (ηk)
ln (∥Mk(ωk)∥∞)
.
Proof. For every ℓ∈N, we have
∥Hkdk,ℓ−gk∥∞=∥Hkdk,ℓ−1+ωkHkD−1
k(gk−Hkdk,ℓ−1)−gk∥∞
=∥(I−ωkHkD−1
k)(Hkdk,ℓ−1−gk)∥∞≤ ∥Mk(ωk)∥∞∥Hdk,ℓ−1−gk∥∞.
Recursively applying this inequality and using the fact that dk,0= 0, we get
the following bound for the residual at the ℓ-th iteration of JOR method:
∥Hkdk,ℓ−gk∥∞≤ ∥Mk(ωk)∥ℓ
∞∥Hdk,0−gk∥∞=∥Mk(ωk)∥ℓ
∞∥gk∥∞.
Ifℓ≥l
ln(ηk)
ln(∥Mk(ωk)∥∞)m
then∥Hkdk,ℓ−gk∥∞≤ηk∥gk∥∞and therefore the
statement is proved. □
21Assume that for every iteration kthe forcing term ηkis given by ηk=
η∥gk∥δ. Theorem 4.2 then ensures local linear, superlinear or quadratic
convergence depending on the value of δand at each iteration the following
inequality holds
∥gk+1∥∞≤ηk∥gk∥∞+1
γ¯m∥gk∥2
∞=νk∥gk∥∞,
where
νk=
ηk+1
γ¯m∥gk∥∞
. (25)
Therefore we can estimate the rate of convergence with respect to the com-
munication rounds. Given that the step size αk= 1 is eventually accepted
forklarge enough, the total number of communications rounds per outer
iteration is ℓkcommunications for the JOR method, plus the sharing of
the local Newtonian directions, i.e. the total number of communications
is governed by ℓk.The following statement claims that the rate of conver-
gence with respect to the communication rounds is always linear, with the
convergence factor depending on ηk,i.e., on δ.
To be more precise, we introduce the following quantity:
ρδ:= lim
k→∞ν1/¯ℓk
k<1.
The above limit exists as shown ahead. Quantity ρδmay be seen as an
asymptotic convergence factor with respect to the number of communica-
tion rounds. Indeed, given that, at the outer iteration k, the number of
communication rounds is governed by ℓk, it follows that the multiplicative
factor of the error decay per a single inner iteration (communication round)
at iteration kequals ν1/¯ℓk
k. Hence, taking the limit of the latter quantity as
k→ ∞ gives the asymptotic (geometric–multiplicative) convergence factor
with respect to the number of communication rounds.
Theorem 4.4. Letδ∈[0,1]andηk=η∥gk∥δ
∞forη >0small enough and
assume that at each iteration the JOR parameter ωkis chosen in such a way
that∥Mk(ωk)∥∞≤σ <1. Then the rate of convergence with respect to the
communications rounds of DINAS method is linear, i.e. ρδ<1.
Proof. We will distinguish two cases, depending on the value of δ.Let us
first consider δ= 0. Since in this case ηk=ηfor every k, by Lemma 4.2 we
have that the number of inner iterations is bounded from above by
¯ℓk=ln (η)
ln (∥Mk(ωk)∥∞)
≤ln (η)
ln(σ)
=:¯ℓ.
22From (22) we have νk=ρfor every iteration index kand
ρ0= lim
k→∞ν1/¯ℓk
k≤ρln(σ)
ln(η)<1,
which proves the thesis for δ= 0.
Let us now consider the case δ∈(0,1].From (25), the definition of ηk, and
the fact that {∥gk∥}is a decreasing sequence that tends to 0, we have that
forklarge enough
νk≤
η+1
γ¯m
∥gk∥δ
∞.
Therefore
ρδ= lim
k→∞ν1/¯ℓk
k= lim
k→∞
η+1
γ¯m
∥gk∥δ
∞ ln(σ)
ln(η∥gk∥δ∞)
= lim
k→∞exp
ln(σ)ln
η+1
γ¯m
∥gk∥δ
∞
ln (η∥gk∥∞)
=eln(σ)=σ.
Since σ∈(0,1) this implies ρδ=σ <1, and the proof is complete. □
Remark 4.3. Theorem 4.4, jointly with Theorem 4.2, establish a quadratic
(respectively, superlinear) convergence rate for δ= 1(respectively, δ∈(0,1))
with respect to outer iterations (number of local gradient and local Hessian
evaluations) and a linear convergence rate with respect to the number of
communication rounds. This is a strict improvement with respect to ex-
isting results like, e.g., [26], that only establish a linear rate with respect
to the number of local gradient and Hessian evaluations and the number of
communication rounds. More precisely, [26] provides a bounded range of
iterations during which the “convergence rate” corresponds to a “quadratic”
regime. In contrast, we establish here the quadratic or superlinear rate in
the asymptotic sense.
Remark 4.4. Forδ > 0, the asymptotic linear rate with respect to the
number of communication rounds equals σ, i.e., it matches the rate of the
inner iteration JOR method. In other words, the rate is the same as if the
JOR method was run independently for solving (7)withrk= 0. Intuitively,
forδ >0, the outer iteration process exhibits at least a superlinear rate, and
therefore the outer iteration process has no effect (asymptotically) on the
communication-wise convergence rate.
23Remark 4.5. The convergence factor σfor the communication-wise linear
convergence rate established here (the δ >0case) is significantly improved
over the existing results like [26]. The rate here is improved as it corre-
sponds to the inner JOR process and is not constrained (deteriorated) by the
requirement on the sufficiently small Newton direction step size, as it is the
case in [26]. To further illustrate this, when (10) inner solver is used, the
final linear convergence factor communication-wise equals 1/(1 +βµ), and
it is hence independent of the local functions’ condition numbers, network
topology, or local Hessian Lipschitz constants.
5 Analysis of inexact centralized Newton method
with Polyak’s adaptive step size
The adaptive step size we use in DINAS can be traced back to the adaptive
step sizes proposed in [32] for the Newton method. The convergence results
we obtain are in fact derived generalizing the reasoning presented there,
taking into account both the distributed computational framework and ap-
proximate Newton search direction. Assuming that N= 1,i.e., considering
the classical problem of solving (2) on a single computational node we can
state the adaptive step size method for Inexact method with the same anal-
ysis as already presented. Thus if we consider the method stated for (2) in
the centralized computation framework we get the algorithm bellow. Here
∥ · ∥is an arbitrary norm.
Algorithm 5.1 (DINASC) .
Iteration k:ηk, yk, γk>0, q∈(0,1)
1:Compute dksuch that
∥∇2f(yk)dk− ∇f(yk)∥ ≤ηk∥∇f(yk)∥ (26)
2:Compute the step size
αk= min
1,1−ηk
(1 +ηk)2γk1
∥∇f(yk)∥
(27)
3:Compute the trial point ˆy=yk−αk∇f(yk)
4:if
αk<1and∥∇f(ˆy)∥ ≤ ∥∇ (f(yk)∥ −1
2(1−ηk)2
(1 +ηk)2γk (28)
24or
αk= 1and∥∇f(ˆy)∥ ≤ηk∥∇f(yk)∥+1
2γk(1 +ηk)2∥ ∇f(yk)∥2(29)
then
5: setγk+1=γkandyk+1= ˆy
6:else
7: setγk=qγkand return to line 2
8:end if
The statements already proved for the distributed case clearly imply the
global convergence of the sequence {yk}as stated below.
Theorem 5.1. Assume that A1 - A3 hold and that the iterative sequence
{yk}is generated by Algorithm DINASC. Then limkyk=y∗and the rate of
convergence is governed by the forcing sequence {ηk}as in Theorem 4.2.
Assuming that the constants µandLare available we get the following
statement for Inexact Newton methods with arbitrary linear solver.
Corollary 5.1. Assume that A1 - A3 hold and that the iterative sequence
{yk}is generated as yk+1=yk−ˆαkdk,where dksatisfies (26), and
ˆαk= min
1,1−ηk
(1 +ηk)2µ2
L1
∥∇f(yk)∥
. (30)
Then limkyk=y∗and the rate of convergence depends on the forcing se-
quence {ηk}as in Theorem 4.2.
Proof. The step size employed in DINASC algorithm reduces to ˆ αkwhenever
γk=µ2/L, while from part i) of Lemma 4.1 we have that for this choice of γk
either condition (28) or (29) is always satisfied. That is, for the considered
sequence, we have
∥∇f(yk+1)∥ ≤ ∥∇ f(yk)∥ −1
2µ2
L(1−ηk)2
(1 +ηk)2
for every ksuch that ˆ αk<1, and
∥∇f(yk+1)∥ ≤ηk∥∇f(yk)∥+1
2L
µ2(1 +ηk)2∥∇f(yk)∥2
for every ksuch that ˆ αk= 1. The thesis follows directly from the analysis
of DINAS. □
25Remark 5.1. The previous corollary provides a choice of the step size that
is accepted at all iterations. However, compared to ˆαk, the adaptive step
size(27), i.e. (15) in DINAS, presents several advantages. First of all,
the definition of ˆαkinvolves the regularity constants Landµ, which are
generally not known. Moreover, even when the constants are known, ˆαk
could be very small, especially if in the initial iterations the gradient is large.
The numerical experience so far implies that for a reasonable value of γ0
we have a rather small number of rejections in Step 4 (Step 9 of DINAS)
and the step size is mostly accepted although γk> µ2/L. Notice that when
γk> µ2/L, the right hand sides of inequalities (28) and(29) are smaller
than their equivalent for γk=µ2/L.That is, the adaptive step size generates
the decrease in the gradient is larger than the decrease induced by ˆαk.
6 Convergence analysis for DINAS: Consensus op-
timization
Let us finally address the issue of convergence towards solutions of (2) and
(6). As already explained the solution of (6) is an approximate solution of
(2), and each local component x∗
iof the penalty problem solution x∗is in
theβ- neighbourhood of y∗- the solution of (2). So, one might naturally
consider a sequence of penalty problem
min Φ βs=F(x) +1
2βsxT(I−W)x (31)
with a decreasing sequence βsto reach the solution of (2) with arbitrary
precision and mimic the so-called exact methods discussed in Introduction.
Thus we can solve each penalty method determined by βsby DINAS up to
a certain precision and use a warm start strategy (taking the solution of the
problem with βsas the starting point for the problem with βs+1) to generate
the solution of (2). Naturally the exit criterion for each penalty problem
and the way of decreasing βsdetermine the properties of such sequence, in
particular the rate of convergence of DINAS should be in line with the rate
of decreasing βs,to avoid oversolving of each penalty problem.
This approach is similar to the penalty decomposition methods in the
centralized framework where one transforms the original problems, possibly
with difficult constraints, into a sequence of problems that are easier to solve.
The main difference is due to the change of computational framework - while
in the penalty decomposition methods we distinguish between difficult and
easy constraints, [19], here we take exactly the same problem and change
26the value of βs,to achieve suitable proximity of the solution ((31) to the
solution of (2). We demonstrate the efficiency of this approach, stated below
as Algorithm SDINAS, in the next Section.
Algorithm 6.1 (SDINAS) .
Input: ε0, β0>0,ˆx0∈RnN, θ∈(0,1).
1:fors= 1,2, . . .do
2: use DINAS starting at ˆxs−1to find ˆxssuch that ∥Φβs(ˆxs)∥∞≤εs
3: setβs+1=θβs
4: setεs+1=θεs
5:end for
Remark 6.1. Different choices could be made at lines 3 and 4 for the update
of the penalty parameter βsand the tolerance εs. The fixed decrease proposed
here is suitable for the distributed case as it does not require any additional
communication among the nodes but the convergence theorem holds for more
general {βs}and{εs}.
The following theorem shows that every accumulation point of the se-
quence generated by Algorithm 6.1 is the solution of (5). Notice that the
matrix I−Wis singular and thus the LICQ condition does not hold. There-
fore we need to prove that an iterative sequence defined by Algorithm 6.1
converges to the solution of (6), similarly to [13, Theorem 3.1]. The issue
with LICQ is another property that is common with penalty decomposi-
tion method, [19], where the constraint qualification might not hold and one
needs to define alternative optimality conditions.
Theorem 6.1. Let Assumptions A1 - A3 hold and let {ˆxs}be a sequence
such that
∥∇Φβs(ˆxs)∥∞≤εs.
Iflims→+∞βs= lim s→+∞εs= 0, then every accumulation point of {ˆxs}
satisfies the sufficient second order optimality conditions for problem (5).
Proof. Let¯xbe an accumulation point of {ˆxs}and let K1⊆N0be an
infinite subset such that lim k∈K1ˆxs=¯x.By definition of ˆxsand Φ βs, we
have
εβs≥ ∥∇ Φβs(ˆxs)∥∞≥1
ββs∥(I−W)ˆxs∥∞− ∥∇ F(ˆxs)∥∞,
which implies
∥(I−W)ˆxs∥∞≤βs(εs+∥∇F(ˆxs)∥∞). (32)
27Since∇Fis bounded over {ˆxs}K1, and βstends to zero, we get
∥(I−W)¯x∥∞≤lim
k∈K1βs(εs+∥∇F(ˆxs)∥∞) = 0 ,
which also implies that ( I−W)1/2¯x= 0 and therefore ¯xis a feasible point
for (5). Let us now define for every s∈N0the vectors
vs=1
βs(I−W)1/2ˆxs,zs=1
βs(I−W)ˆxs.
We will prove that {vs}s∈K1is bounded. Let I−W=UΛU⊤be the eigen-
decomposition of I−W, with Λ = diag( λ1, . . . , λ nN). From (32) we have
that{zs}s∈K1is bounded. That is, there exists Z∈Rsuch that ∥zs∥ ≤Z
for every s∈K1. Since Uis an orthogonal matrix, by definition of zwe
have
Z≥ ∥zs∥ ≥ ∥ U⊤zs∥=1
βs∥U⊤UΛU⊤ˆxs∥=1
βs∥ΛU⊤ˆxs∥=1
βs nNX
i=1λ2
i(U⊤ˆxs)2
i!1/2
Since λi≥0 for every i, this implies that {1
βsλ2
i(U⊤xs)2
i}s∈K1is bounded
for every iand therefore {1
βsλi(U⊤xs)2
i}s∈K1is also bounded. By definition
ofvswe get
1
βs nNX
i=1λi(U⊤xs)i!1/2
=1
βs∥Λ1/2U⊤x∥=∥U⊤vs∥.
The above equality implies that {vs}s∈K1is bounded and therefore there
exists ¯v∈RnNandK2⊆K1,an infinite subset such that lim k∈K2vs=¯v.
By definition of ˆxs, Φs, and vswe have
εs≥ ∥∇ Φs(ˆxs)∥∞=∇F(ˆxs) +1
βs(I−W)ˆxs
∞=∇F(ˆxs) + (I−W)1/2vs
∞.
Taking the limit for s∈K2we get
∇F(¯x) + (I−W)1/2¯v
∞= 0,
and thus ¯xis satisfies the KKT conditions for (5). Denoting with Lthe La-
grangian function of problem (5), by Assumption A3 we have that ∇2
xxL(¯x,¯v)
is positive definite, and therefore we get the thesis. □
287 Numerical Results
We now present a set of numerical results to investigate the behavior of
DINAS when solving (1) and (2) and how it compares with relevant methods
from the literature.
7.1 Numerical results for distributed personalized optimiza-
tion
Given that the choice of the forcing terms forcing terms ηkinfluences the
performance of the method , we begin by numerically veryfing theoretical re-
sults on the convergence rate. Consider the problem of minimizing a logistic
loss function with l2regularization. That is, given {aj}m
j=1⊂Rn,{bj}m
j=1⊂
{−1,1}, ρ > 0, the objective function fis defined as
f(y) =mX
j=1ln
1 + exp( −bja⊤
jy)
+1
2ρ∥y∥2
2 (33)
We set n= 100, m= 1000 and assume that node iholds{aj}j∈Ri,{bj}j∈Ri
forRi={(i−1)100+1 , . . . , 100i}For every j= 1, . . . , m the components of
ajare independent and uniformly drawn from (0 ,1),while bjtakes value 1 or
−1 with equal probability, while the regularization parameter is ρ= 0.01m.
The underlying communication network is defined as a random geometric
graph with communication radiusp
N−1ln(N), and the consensus matrix
Was the Metropolis matrix [40]. To evaluate the methods, we define the
per-iteration total cost of each method as the sum of the computational cost
plus the communication traffic multiplied by a scaling constant r, [2]. That
is,
total cost = computation + r·communication (34)
The computational cost is expressed in terms of scalar operations, while
the communication traffic is the total number of scalar quantities shared
by all nodes. The scaling factor ris introduced to reflect the fact that the
time necessary to share a variable between two nodes compared with the
time necessary to execute scalar computations depends on many factors of
technical nature, such as the kind of computational nodes that form the
network and the technology they use to communicate, that are beyond the
purpose of these experiments.
Given fin (33) as explained above and β= 0.1, the personalized op-
timization problem in the form of (6) is solved with DINAS algorithm for
29(a)δ= 0
 (b)δ= 0
(c)δ= 1
 (d)δ= 1
Figure 1: Choice of the forcing terms, Logistic Regression
different choices of the sequence of forcing terms {ηk},defined as
ηk= min {η, η∥gk∥δ
∞},
forδ= 0,1 and η= 0.9,0.1,0.001. All nodes start with initial guess x0
i=
0∈Rnand the execution terminates when ∥∇Φβ(xk)∥ ≤10−5.For all the
methods we define γ0= 1.In Figure 1 we plot the results for the six methods
given by the different combinations of δandη.In Figure 1a, 1b we consider
the case δ= 0 (that is, ηk=ηfor all k), while in Figure 1c,1d we have
δ= 1. In each subfigure we plot the value of log10(∥gk∥) versus iterations
(Figure 1a, 1c) and cost (1b, 1d), with scaling factor r= 1. Figures 1a,
1c confirm the results stated in Theorem 4.2: the sequence ∥gk∥is linearly
decreasing for all the considered choices of η, while for δ= 1 the convergence
is locally quadratic. For both values of δthe number of iterations required
by the methods to arrive at termination depends directly on the choice of
the forcing term: smaller values of ηensure the stopping criterion is satisfied
in a smaller number of iterations. However, for δ= 1 we notice that, when
compared in terms of overall cost, the method with the smallest value of η
30performs worse than the other two. For δ= 0 the comparison among the
methods for the cost gives the same result as that in terms of iterations.
The results for different values of the cost scaling factor rare completely
analogous and are therefore omitted here.
7.2 Comparison with Exact Methods for consensus optimiza-
tion
We compare DINAS with NN [27], DAN and DAN-LA [48], Newton Track-
ing [47], DIGing [29] and EXTRA [35]. The proposed method DINAS is
designed to solve the penalty formulation of the problem and therefore, in
order to minimize (2), we apply Algorithm 6.1 with β0= 0.1,βs+1= 0.1βs
andεs= 0.01βs. For NN we proceed analogously, replacing DINAS in line 2
with Network Newton. All other methods are the so-called exact methods,
and therefore can be applied directly to minimize f. We take γ0= 1,δ= 0
andη= 0.9 in Algorithm 3.2, i.e., we consider linearly convergent DINAS,
while for all other methods the step sizes are computed as in the respective
papers. For DAN-LA the constants are set as in [48]. In particular, we con-
sider four different values of the parameter c=M,10M,100M,1000Mand
denote them as DAN LR1,DAN LR2, DAN LR3, DAN LR4 in the figures
bellow.
First, we consider a logistic regression problem with the same parame-
ters as in the previous test. The exact solution y∗of (33) is computed by
running the classical gradient method with tolerance 10−8on the norm of
the gradient. As in [27], the methods are evaluated considering the average
squared relative error, defined as
ek=1
NNX
i=1∥xk
i−x∗∥2
∥x∗∥2
where x∗= (y∗, . . . ,y∗)⊤∈RnN.For all methods the initial guess is x0
i= 0
at every node, which yields e0= 1, and the execution is terminated when
ek≤10−4.We consider the same combined measure of computational cost
and communication defined in (34), with scaling factor r= 0.1,1,10 and
plot the results in Figure 2.
One can see that for all values of rDINAS outperforms all the other
methods. NN, DIGing and EXTRA all work with fixed step sizes that, in
order to ensure global convergence of the methods, need to be very small.
Despite the fact that each iteration of DIGing and EXTRA is very cheap
compared to an iteration of DINAS, this is not enough to compensate the
31(a)r= 0.1
 (b)r= 1
 (c)r= 10
Figure 2: Total cost, Logistic Regression
fact that both these methods require a large number of iterations to arrive
at termination. DAN and DAN-LA methods use an adaptive step size that
depends on the constants of the problem µandLand on 1 /∥∇Φk∥∞in such
a way that the full step size is accepted when the solution is approached.
In fact, we can clearly see from the plots that all these methods reach a
quadratic phase where etdecreases very quickly. However, the per-iteration
cost of these methods is, in general, significantly higher than the cost of
DINAS. DAN method requires all the local Hessians ∇2fi(xk) to be shared
among all the nodes at each iteration. While using Algorithm 3.1 this can
be done in a finite number of rounds of communications, the overall com-
munication traffic is large as it scales quadratically with both the dimension
nof the problem and the number of nodes N. DAN-LA avoids the commu-
nication of matrices by computing and sharing the rank-1 approximations
of the local Hessians. While this reduces significantly the communication
traffic of the method, it increases the computational cost, as two eigenvalues
and one eigenvector need to be computed by every node at all iterations,
and the number of iterations, since the direction is computed using an ap-
proximation of the true Hessian. Overall, this leads to a larger per-iteration
cost than DINAS. Since γ0= 1 and it only decreases when the conditions
(12),(13) do not hold, we have that αkin DINAS is relatively large compared
to the fixed step sizes employed by the other methods that we considered.
The per-iteration cost of DINAS is largely dominated by the cost of JOR
that we use to compute the direction dk. Since the method is run with ηk
large, and dk−1is used as initial guess at the next iteration, a small number
of JOR iteration is needed on average to satisfy (8), which makes the over-
all computational and communication traffic of DINAS small compared to
DAN and DAN-LA.
The logistic regression problem is also solved with Voice rehabilitation
32dataset - LSVT,[37]. The dataset is made of m= 126 points with n= 309
features, and the datapoints are distributed among N= 30 nodes on a
random network generated as above. The results for different values of rare
presented in Figure 3, and they are completely analogous to those obtained
for the synthetic dataset in Figure 2.
(a)r= 0.1
 (b)r= 1
 (c)r= 10
Figure 3: Total cost, Logistic Regression, LSVT dataset
To investigate the influence of conditional number we consider a quadratic
problem defined as
f(y) =NX
i=1fi(y), fi(y) =y⊤Aiy+y⊤bi (35)
with Ai∈Rn×n,b∈Rnfor every i= 1, . . . , N. We take n= 100 and N= 10
and we generate Ai, bias follows. Given 0 < λ min< λ max, we define the
diagonal matrix Di= diag( λi
1, . . . , λi
n) where the scalars λi
jare independent
and uniformly sampled in [ λmin, λmax].Given a randomly generated orthog-
onal matrix Pi∈Rn×nwe define Ai=PiDiP⊤
i.For every i= 1, . . . , n
the components of biare independent and from the uniform distribution in
[0,1].Fixing λmin= 0.1 different problems of the form (35) with increasing
values of λmaxare considered. For each problem the exact solution y∗, the
initial guess and the termination condition are all set as in the previous test.
The same combined measure of the cost, with scaling factor ris used. All
methods are run with step sizes from the respective papers, while for NN
we use step size equal to 1, as suggested in [27] for quadratic problems. In
Figure 4 we plot the obtained results for λmax= 1,10,100 and r= 0.1,10.
For this set of problems the advantages of DINAS, compared to the
other considered methods, become more evident as λmaxincreases. When
λmaxis larger, the Lipschitz constant of the problem also increases and
therefore the step sizes that ensure convergence of DIGing and EXTRA
33(a)λmax= 1, r= 0.1
 (b)λmax= 10, r= 0.1
 (c)λmax= 100 , r= 0.1
(d)λmax= 1, r= 10
 (e)λmax= 10, r= 10
 (f)λmax= 100 , r= 10
Figure 4: Total cost, quadratic problem
become progressively smaller. In fact we can see that EXTRA outperforms
the proposed method for λmax= 1 when the cost is computed with r= 0.1
and for λmax= 10 when r= 10, but DINAS becomes more efficient for
larger values of λmax.Regarding DAN and DAN-LA, what we noticed for
the previous test also holds here. Moreover, their step size depends on the
ratio µ2/Lwhich, for large values of λmaxcauses the step size to be small for
many iterations. While NN uses the full step size in this test, its performance
is in general more influenced by the condition number of the problem than
that of DINAS. Moreover, while the per-iteration communication traffic of
NN is fixed and generally lower than that of DINAS, the computational cost
is typically larger, as at each iteration every node has to solve multiple linear
systems of size n, exactly. Finally, we notice that for all the considered values
ofλmaxthe comparison between DINAS and the other method is better for
r= 0.1 which is a direct consequence of assigning different weight to the
communication traffic when computing the overall cost.
8 Conclusions
The results presented here extend the classical theory of Inexact Newton
methods to the distributed framework in the following aspects. An adaptive
34(large) step size selection protocol is proposed that yields global conver-
gence. When solving personalized distributed optimization problems, the
rate of convergence is governed by the forcing terms as in the classical case,
yielding linear, superlinear or quadratic convergence with respect to com-
putational cost. The rate of convergence with respect to the number of
communication rounds is linear. The step sizes are adaptive, as in [32]
for the Newton method, and they can be computed in a distributed way
with a minimized required knowledge of global constants beforehand. For
distributed consensus optimization, exact global convergence is achieved.
The advantages of the proposed DINAS method in terms of computational
and communication costs with respect to the state-of-the-art methods are
demonstrated through several numerical examples, including large- scale and
ill-conditioned problems. Finally, a consequence of the analysis for the dis-
tributed case is also convergence theory for a centralized setting, wherein
adaptive step sizes and an inexact Newton method with arbitrary linear
solvers is analyzed, hence extending the results in [32] to inexact Newton
steps.
References
[1] I. Almeida and J. Xavier. DJAM: Distributed Jacobi asynchronous
method for learning personal models. IEEE Signal Processing Letters ,
25(9):1389–1392, 2018.
[2] A. S. Berahas, R. Bollapragada, N. S. Keskar, and E. Wei. Balancing
communication and computation in distributed optimization. IEEE
Transactions on Automatic Control , 64(8):3141–3155, 2019.
[3] Erik Berglund, Sindri Magnusson, and Mikael Johansson. Distributed
newton method over graphs: Can sharing of second-order information
eliminate the condition number dependence? IEEE Signal Processing
Letters , PP:1–1, 05 2021.
[4] Amir Daneshmand, Gesualdo Scutari, Pavel Dvurechensky, and
Alexander Gasnikov. Newton method over networks is fast up to the
statistical precision. In Marina Meila and Tong Zhang, editors, Pro-
ceedings of the 38th International Conference on Machine Learning ,
volume 139 of Proceedings of Machine Learning Research , pages 2398–
2409. PMLR, 18–24 Jul 2021.
35[5] R. S. Dembo, S. C Eisenstat, and T. Steihaug. Inexact Newton meth-
ods. SIAM Journal on Optimization , (2):400–408, 1982.
[6] S. C. Eisenstat and H. F. Walker. Globally convergent inexact Newton
methods. SIAM Journal on Optimization , 4:393–422, 1994.
[7] Ceyhun Eksin and Alejandro Ribeiro. Distributed network optimization
with heuristic rational agents. IEEE Transactions on Signal Processing ,
60(10):5396–5411, 2012.
[8] A. Fromer and D. Szyld. On asychronous iterations. Journal of Com-
putational and Applied Mathematics , 123(1-2):201–216, 2000.
[9] F. Hanzely, S. Hanzely, S. Horv´ ath, and P. Richt´ arik. Lower bounds and
optimal algorithms for personalized federated learning. In Proceedings
of the 34th International Conference on Neural Information Processing
Systems , NIPS’20. Curran Associates Inc., 2020.
[10] D. Jakoveti´ c. A unification and generalization of exact distributed first-
order methods. IEEE Transactions on Signal and Information Process-
ing over Networks , 5(1):31–46, 2019.
[11] D. Jakoveti´ c, D. Bajovi´ c, N. Kreji´ c, and N. Krklec Jerinki´ c. Newton-like
method with diagonal correction for distributed optimization. SIAM
Journal on Optimization , 27(2):1171–1203, 2017.
[12] D. Jakoveti´ c, N. Kreji´ c, and N. Krklec Jerinki´ c. Exact spectral-like gra-
dient method for distributed optimization. Computational Optimization
and Applications , 74:703–728, 2019.
[13] D. Jakoveti´ c, N. Kreji´ c, and N. Krklec Jerinki´ c. EFIX: Exact fixed point
methods for distributed optimization. Journal of Global Optimization ,
2022.
[14] D. Jakoveti´ c, N. Kreji´ c, and N. Krklec Jerinki´ c. A Hessian inversion-
free exact second order method for distributed consensus optimization.
IEEE Transactions on signal and information processing over networks ,
8:755–770, 2022.
[15] D. Jakoveti´ c, J. M. F. Moura, and J. Xavier. Nesterov-like gradient
algorithms. CDC’12, 51stIEEE Conference on Decision and Control ,
pages 5459–5464, 2012.
36[16] D. Jakoveti´ c, J. Xavier, and J. M. F. Moura. Fast distributed gradient
methods. IEEE Transactions on Automatic Control , 59(5):1131–1146,
2014.
[17] D. Jakoveti´ c, N. Kreji´ c, N. Krklec Jerinki´ c, G. Malaspina, and
A. Micheletti. Distributed fixed point method for solving systems of
linear algebraic equations. Automatica , 134(8), 2021.
[18] C. Kanzow and M. Lapucci. Inexact penalty decomposition methods
for optimization problems with geometric constraint. Computational
Optimization and Applications , 85:937–971, 2023.
[19] N. Kreji´ c and Z. Luˇ zanin. Newton-like method with modification of
the right-hand side vector. Mathematics of Computation , 71:237–250,
2002.
[20] Nataˇ sa Krklec Jerinki´ c, Duˇ san Jakoveti´ c, Nataˇ sa Kreji´ c, and Dragana
Bajovi´ c. Distributed second-order methods with increasing number of
working nodes. IEEE Transactions on Automatic Control , 65(2):846–
853, 2020.
[21] N. Li and G. Qu. Harnessing smoothness to accelerate distributed opti-
mization. IEEE Transactions Control of Network Systems , 5(3):1245–
1260, 2017.
[22] Huikang Liu, Jiaojiao Zhang, Anthony Man-Cho So, and Qing Ling. A
communication-efficient decentralized newton’s method with provably
faster convergence, 2022.
[23] J. Liu, A. S. Morse, A. Nedi´ c, and T. Ba¸ sar. Exponential convergence
of a distributed algorithm for solving linear algebraic equations. Auto-
matica , 83:37–46, 2017.
[24] J. Liu, S. Mou, and A. S. Morse. A distributed algorithm for solving
a linear algebraic equation. Proceedings of the 51st Annual Allerton
Conference on Communication, Control, and Computing , 60(11):267–
274, 2013.
[25] F. Mansoori and E. Wei. Superlinearly convergent asynchronous dis-
tributed network newton method. 2017 IEEE 56th Annual Conference
on Decision and Control (CDC) , page 2874–2879, 2017.
37[26] F. Mansoori and E. Wei. Superlinearly convergent asynchronous dis-
tributed network Newton method. 2017 IEEE 56th Annual Conference
on Decision and Control (CDC) , pages 2874–2879, 2017.
[27] A. Mokhtari, Q. Ling, and A. Ribeiro. Network Newton distributed
optimization methods. IEEE Transactions on Signal Processing ,
65(1):146–161, 2017.
[28] A. Mokhtari, W. Shi, Q. Ling, and A. Ribeiro. A decentralized second-
order method with exact linear convergence rate for consensus opti-
mization. IEEE Transactions on Signal and Information Processing
over Networks , 2(4):507–522, 2016.
[29] A. Nedi´ c, A. Olshevsky, and W. Shi. Achieving geometric convergence
for distributed optimization over time-varying graphs. SIAM Journal
on Optimization , 27(4):2597–2633, 2017.
[30] A. Nedi´ c, A. Olshevsky, W. Shi, and C. A. Uribe. Geometrically conver-
gent distributed optimization with uncoordinated step sizes. American
Control Conference , pages 3950–3955, 2017.
[31] A. Nedi´ c and A. Ozdaglar. Distributed subgradient methods for
multi-agent optimization. IEEE Transactions on Automatic Control ,
54(1):48–61, 2009.
[32] B. Polyak and A. Tremba. New versions of Newton method: Step-size
choice, convergence domain and under-determined equations. Opti-
mization Methods and Software , 35(6):1272–1303, 2020.
[33] F. Saadatniaki, R. Xin, and U. A. Khan. Decentralized optimization
over time-varying directed graphs with row and column-stochastic ma-
trices. IEEE Transactions on Automatic Control , 60(11):4769–4780,
2020.
[34] G. Shi and K. H. Johansson. Finite-time and asymptotic convergence
of distributed averaging and maximizing algorithms. arXiv:1205.1733 ,
2012.
[35] W. Shi, Q. Ling, G. Wu, and W. Yin. Extra: an exact first-order
algorithm for decentralized consensus optimization. SIAM Journal on
Optimization , 25(2):944–966, 2015.
38[36] A. Sundararajan, B. Van Scoy, and L. Lessard. Analysis and de-
sign of first-order distributed optimization algorithms over time-varying
graphs. arxiv preprint, arXiv:1907.05448 , 2019.
[37] A. Tsanas, M. A. Little, C. Fox, and L. O. Ramig. Objective automatic
assessment of rehabilitative speech treatment in parkinson’s disease.
IEEE Transactions on Neural Systems and Rehabilitation Engineering ,
22:181–190, 2014.
[38] Paul Vanhaesebrouck, Aur´ elien Bellet, and Marc Tommasi. Decentral-
ized collaborative learning of personalized models over networks. In
AISTATS , 2017.
[39] M. Wu, N. Xiong, Vasilakos A. V., V. C. M. Leung, and C. L. P. Chen.
Rnn-k: A reinforced Newton method for consensus-based distributed
optimization and control over multiagent systems. IEEE Transactions
on Cybernetics , 52(5):4012–4026, 2022.
[40] L. Xiao, S. Boyd, and S. Lall. Distributed average consensus with time-
varying metropolis weights. Automatica , 2006.
[41] R. Xin and U. A. Khan. Distributed heavy-ball: a generalization and
acceleration of first-order methods with gradient tracking. IEEE Trans-
actions on Automatic Control , 65(6):2627–2633, 2020.
[42] R. Xin, C. Xi, and U. A. Khan. Frost—fast row-stochastic optimiza-
tion with uncoordinated step-sizes. EURASIP Journal on Advances in
Signal Processing—Special Issue on Optimization, Learning, and Adap-
tation over Networks , 1, 2019.
[43] J. Xu, S. Zhu, Y. C. Soh, and L. Xie. Augmented distributed gradient
methods for multi-agent optimization under uncoordinated constant
step sizes. IEEE Conference on Decision and Control , pages 2055–
2060, 2015.
[44] D.M. Young. Iterative solution of large linear systems. Academic Press ,
1971.
[45] K. Yuan, Q. Ling, and W. Yin. On the convergence of decentralized
gradient descent. SIAM Journal on Optimization , 26(3):1835–1854,
2016.
39[46] K. Yuan, B. Ying, X. Zhao, and A. H. Sayed. Exact diffusion for dis-
tributed optimization and learning — part I: Algorithm development.
IEEE Transactions on Signal Processing , 67(3):708–723, 2019.
[47] J. Zhang, Q. Ling, and A. M. C. So. A Newton tracking algorithm
with exact linear convergence for decentralized consensus optimization.
IEEE Transactions on Signal and Information Processing over Net-
works , 7:346–358, 2021.
[48] J. Zhang, K. You, and Ba¸ sar T. Distributed adaptive Newton methods
with global superlinear convergence. Automatica , 138, 2022.
40