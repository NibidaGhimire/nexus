LANGUAGE AGNOSTIC DATA-DRIVEN INVERSE TEXT NORMALIZATION
Szu-Jui Chen1y, Debjyoti Paul2y,Yutong Pang2, Peng Su2, Xuedong Zhang2
Center for Robust Speech Systems (CRSS), University of Texas at Dallas, USA1,
Meta AI, USA2
ABSTRACT
With the emergence of automatic speech recognition (ASR)
models, converting the spoken form text (from ASR) to the
written form is in urgent need. This inverse text normalization
(ITN) problem attracts the attention of researchers from vari-
ous ﬁelds. Recently, several works show that data-driven ITN
methods can output high-quality written form text. Due to
the scarcity of labeled spoken-written datasets, the studies on
non-English data-driven ITN are quite limited. In this work,
we propose a language-agnostic data-driven ITN framework
to ﬁll this gap. Speciﬁcally, we leverage the data augmen-
tation in conjunction with neural machine translated data for
low resource languages. Moreover, we design an evaluation
method for language agnostic ITN model when only English
data is available. Our empirical evaluation shows this lan-
guage agnostic modeling approach is effective for low re-
source languages while preserving the performance for high
resource languages.
Index Terms —Inverse text normalization, Multilingual,
Language-agnostic
1. INTRODUCTION
Recent progress in automatic speech recognition (ASR) tech-
nologies brings world-wide adoption to use voice as a source
of input to interact and communicate with digital environ-
ments. Moreover, ASR systems are now expanding language
horizons to bring same or better experience to native lan-
guage speaker around the world. For communication and bet-
ter readability of spoken form output from an ASR system, it
needs to be paired with an inverse text normalization (ITN)
system to produce corresponding written form texts.
Converting spoken form texts to written form is not an
easy task. For example, the spoken form twenty twenty can
be written as (a) 2020 to express the year/number, (b) 20:20
for time, (c) 20/20 for eye-vision, (d) 20-20 for a score in
game or a cricket match. Taking another example of ten to
twelve , which can be written as (a) 10-12 as a cardinal number
range, (b) 10:00-12:00 as time range, (c) 11:50 am/pm as a
time instance, etc. It is evident from these examples that the
speaker contexts could help in determining the correct written
form which is hard to abide by a rule-based system. Therefore
data-driven based systems are gaining attention of researchers
[1–4] to improve ITN systems, dub as DD-ITN models.
Dataset of spoken-written text pairs are used to train these
neural network based DD-ITN models. Obtaining spoken-
Work performed during an internship at Meta Platforms, Inc.
yEqual contribution.written text pairs that covers diverse ITN entities such as
cardinals, ordinals, date-time, money, fractions, decimals,
address, metrics, email, URL, abbreviation etc. is hard but
doable for high-resource languages such as English. In addi-
tion, the written representation of same entity can vary across
languages, e.g., 3:30 pm is commonly represented as 15h30
in French. The challenge grows multi-fold while expanding
to more languages, especially low-resource ones where it is
hard to obtain spoken-written text pairs dataset.
We discovered that separating the ITN component from
the end-to-end ASR system allows for independent perfor-
mance improvements using a relatively large text only dataset.
Moreover, our in-house on-device spoken-form ASR sys-
tems have achieved a signiﬁcant reduction in word-error-rate
(WER) of >10%, a reduction in real-time-factor (RTF) of
>8%, and lower memory consumption. This has led us to
propose using the ITN as a low-latency post-processing ser-
vice. In this study, we aim to internationalize (i18n) and
expand the language capabilities of ITN models by address-
ing the problem of data scarcity and presenting a uniﬁed,
language-agnostic ITN model that supports multiple lan-
guages. The main contributions of this work are as follows:
• We propose a text normalization method for English that
transforms written form texts to spoken form texts. Unlike
conventional text normalization system, our data augmen-
tation system generates more possible variants of spoken
forms; which can help build robust ITN system.
• We propose to apply neural machine translation for interna-
tionalization of the ITN models, which can be considered as
a knowledge distillation approach. We use neural machine
translation on English spoken-written text pairs to generate
spoken-written pairs on target languages; and it helps ITN
expanding to more languages.
• We present a language agnostic data-driven ITN model that
supports inverse normalization of spoken form texts for
12 languages. We also present a study of system design
choices in our experiment section.
2. METHODOLOGY
2.1. Data Augmentation
To train a language agnostic ITN system, we need spoken-
written text pairs for every language. However, there are not
much public available resources having spoken-written text
pairs in English, not to mention other languages. Hence, we
propose a two-step data augmentation method to generate
spoken-written text pairs for multiple languages. First, we
generate spoken form texts from highly available written text
resources in English. Then, we use machine translation to
generate text pairs for other languages.arXiv:2301.08506v2  [cs.CL]  24 Jan 2023Fig. 1 . Multilingual data generation using rule based text normalization system and machine translation model.
2.1.1. Enhanced Text Normalization
Traditional text normalization (TN) used in text-to-speech
(TTS) systems generates ﬁxed variation of spoken forms (of-
ten with rule-based approach) that conforms to the verbalizer
standard for any given written text with TN-ITN entities. As
mentioned previously, spoken forms lack full information
about the subject; hence, it is important to cover more spoken
variations and alternatives. With abundant written text re-
sources in hand, we apply our specialized text normalization
augmentation system that generates many possible spoken
variations; statistically 22 more diverse than conventional
TN system. See Table 1 for a few examples and we recom-
mend readers to check the Appendix Sec. 6.1 in our extended
version of paper for details [5].
Table 1 . Examples of generated spoken form using conven-
tional TN system and our data augmentation system
Written Text Spoken Text from Spoken Text from
Input Conventional TN Enhanced TN System
6:15 amsix ﬁfteen a msix ﬁfteen a m
six ﬁfteen in the morning
six ﬁfteen
six past ﬁfteen a m
quarter past six a m
quarter past six morning
six and quarter a m
$1.20one dollar and twenty centsone dollar and twenty cents
one dollar twenty cents
one dollar two zero cents
one point two zero dollars
a dollar twenty cents
2.1.2. Multilingual spoken-written text pairs
We propose using neural machine translation (NMT) models
to generate spoken-written text pairs in target languages for
which we do not have adequate pairs. However, we have
found that the outputs of the NMT model do not always
meet our criteria for quality. To ensure the quality of our
spoken-written text pairs, we have implemented the follow-
ing measures: (a) Spoken/Written Mismatch: Discarding
translated texts that have mismatches between written and
spoken forms, (b) Word Error Rate (WER): Strictly adhering
to the Word Error Rate (WER) metric for selecting non-ITN
text segments, (c) Target Language Conformity: Ensuring
conformity between the source and target languages, and ﬁl-
tering out any malformed or incorrect translations with input
from linguists, like 801!eight o one [en]6=otto o uno [it] ,
etc. We provide translation accuracy in Table 6, the pictorial
position of translation module in the pipeline in Fig. 1, and a
few translation examples in Table 2 for reference.Table 2 . Examples of data augmentation with machine trans-
lation models for French [ fr], Italian [ it], Spanish [ es].
Form Text in English Translated text
spokenHistorical average for
January is thirty one
degrees.La moyenne historique de janvier
est de trente et un degr ´es [fr]
La media storica di gennaio
`e di trentuno gradi. [ it]
La media hist ´orica de enero
es de treinta y un grados. [ es]
writtenHistorical average for
January is 31 degrees.La moyenne historique pour janvier
est de 31 degr ´es. [fr]
La media storica di gennaio
`e di 31 gradi. [ it]
La media hist ´orica de enero
es de 31 grados. [ es]
2.2. Model Architecture
For our ITN task, it can be seen as a sequence-to-sequence
(Seq2Seq) problem, which turns a sequence in one domain
(e.g., spoken domain) to a sequence in another domain (e.g.,
written domain). For this Seq2Seq problem, we employ
the Encoder-Decoder architecture (Fig. 2) to solve it. More
speciﬁcally, two types of Encoder-Decoder model are investi-
gated in this work: the LSTM-based Seq2Seq model and the
Transformer model.
With the sequence data, a natural idea is to use the recur-
rent neural network (RNN), and Long Short-Term Memory
(LSTM) [6] is the ﬁrst choice among Recurrent Neural Net-
works (RNNs). In our LSTM-based Seq2Seq model, we uti-
lize the LSTM in both the encoder and decoder. In order to
encode the input sequence better, we employ bi-directional
encoder to consider both the left context and right context
in the sequence. Also, in the decoder side, we use attention
mechanism to derive a context vector that captures the rel-
evant source-side (encoder-side) information to help predic-
tion. Initially, this type of Seq2Seq model is used for transla-
tion task. For more details about the model, we refer readers
to paper [7].
For the Transformer model, we employ the original model
from [8]. Its encoder and decoder are composed of stacked
modules (or layers), and each module mainly consists of
Fig. 2 . Encoder-Decoder model architecture for ITN.Table 3 . Model Parameters.
LSTM Transformer
No. of Parameter 19.98M 19.67M
Encoder Layer 2 4
Decoder Layer 2 4
Hidden Size 256 256
Attention Head n/a 8
multi-head attention and feed forward networks. The atten-
tion mechanism will take the whole sequence into account by
learning weights for input tokens in the encoder. In the de-
coder, the masked attention mechanism is applied to predict
the next token based on the previous tokens.
For fair comparison, we experiment with both models
with similar parameter sizes. The details of the model param-
eter can be found in Table 3.
3. EXPERIMENTS
We select 12 languages based on their richness of resources
and their writing script, as shown in Table 4. For example,
we see Russian and Kazakh share the same Cyrillic script
where the latter is a low-resource language. For the model in-
put/output text tokenization, we use SentencePiece tokenizer
model (SPM) [9] with a vocabulary size of 20,000. Our ab-
lation study with varying SPM vocabulary sizes (omitted due
to space constraints) shows little performance improvement
beyond that. To note, unless speciﬁed in experiment results,
LSTM based Seq2Seq architecture is our default ITN model
as described in Section 2.2. As choice of NMT models for
our experiments, we use (a) Opus-MT [10] with EasyNMT
library support, (b) MetaNMT, an in-house version of NMT
with comparable performance to NLLB [11]. Also, unless
speciﬁed, we use MetaNMT for data augmentation as it has
better BLEU scores (see respective papers) and ITN perfor-
mance impact (see Table 8).
Table 4 . 12 languages selected for experiments.
Resources Latin Script Non-Latin Script
HighItalian [ it], French [ fr], Spanish [ es], Russian [ ru], Greek [ el]
English [ en], Turkish [ tr], German [ de]
Low Icelandic [ is], Afrikaans [ af] Tamil [ ta], Kazakh [ kk]
3.1. Dataset
We use the OpenSubtitles [12] and TED2020 [13] datasets
from OPUS1as our training data. To be speciﬁc, only the
written English texts from OPUS are used in our method.
The spoken-written pairs for training are generated using the
pipeline in Fig. 1.
We evaluate our models on two datasets: (a) Dictation
testset: Human annotated 6,810 spoken-written conversa-
tional text pairs in English containing diverse ITN entities in
mixed proportions. We apply the Case B strategy described
in Fig 3 and Section 3.2 to generate evaluation data for non-
English languages. (b) Caption testset: Mostly containing
mathematical expressions, measures, metrics, phone numbers
collected from audios with uploaded caption . This dataset
has [ en]:22332, [ es]:21216, [ fr]:27300, [ it]:14939, [ de]:5960
spoken-written text pairs for respective languages.
1https://opus.nlpl.eu/
Fig. 3 . ITN evaluation strategy with case A: Target language
evaluation dataset is available; Case B: Target language eval-
uation dataset is not available. We use translation model to
prepare spoken target texts. In both cases, we compare nu-
merical entities output from the ITN model.
3.2. ITN Evaluation
For the evaluation of our ITN model, we mainly focus on the
numerical entities in the text. The evaluation is straightfor-
ward when ground-truth target language spoken-written pairs
are available. But the lacking of proper human annotated
spoken-written pairs for mid/low resource languages moti-
vates us to propose an approach to measure the model per-
formance on the numerical entities shown in Fig. 3.
3.2.1. ITN normalized accuracy
In Fig. 3, Case A shows the evaluation approach when target
language spoken-written pair dataset is available. We apply
Case B where target language pair dataset is not available, we
translate the spoken form text from English human annotated
dataset to target language. We then apply the trained ITN
model to obtain written form text in target language. There-
after, we verify the digit in the written form is the same as the
original one in English. If they are the same, we count it as a
correct instance, if not, we count it as a incorrect one. To note,
translation models may output written form in target language
for spoken source input, we discard them and only evaluate
the ITN model on correctly translated spoken form texts. We
use normalized accuracy to measure the performance of our
ITN model expressed as the fraction of correct prediction over
all the ITN entities.
Table 5 shows ITN entities in bold , the correct spoken
and written form translated entities are in blue and errors are
colored with redwith correct form in (parenthesis) . When
comparing written form English and written form in target
language, we take care of special cases; for example see the
following examples:
•12/24 hour conversion : Use of 24 hours system in French
and other target language; 1:30 p.m. [en] vs.13h30 [fr] .
•Accommodating Zeros : Use alternate magnitudes; e.g.,
24,000 [en] vs.24 mille [fr] .Table 5 . Examples of errors for ITN evaluation. The sec-
ond row is an example of ITN error while the third row is an
example of NMT error.
Spoken Written
[en] I found out that nine out of ten
statistics are wrong.[en] I found out that 9out of 10
statistics are wrong.
[fr] J’ai d ´ecouvert que neuf statistiques
surdixsont fausses.[fr] J’ai r ´ecemment d ´ecouvert que
neuf (9) statistiques sur 10sont fausses
[en] Dad’s surprise sixtieth is on this
Saturday. Arrive before six PM .[en] Dad’s surprise 60th is on this
Saturday. Arrive before 6 PM .
[fr] La soixanti `eme surprise de papa
a lieu ce samedi. Arriv ´ee avant 18h
(dix-huit heures) .[fr] La 60`eme surprise de papa
a lieu ce samedi. Arriv ´ee avant 18h.
•Small cardinal : Disambiguate use of spoken/written form
for small cardinals (1-9) based on target language prefer-
ences; e.g., two children [en] vs.2 enfants [fr] .
•Separators : Some languages like French use comma(,) for
decimal point. Also, there are languages that use 2 or 3
digit separators with either comma, space or period; e.g.,
25,000.00 [en] vs.25 000,00 [fr] vs.25.000,00 [de] .
3.2.2. ITN entity translation accuracy
In order to evaluate the NMT model translation accuracy on
ITN entities, we propose the ITN entity translation accuracy.
Here we compare whether the numerical entities from trans-
lations produces consistent spoken/written form output w.r.t.
input text form. An example is provided in the last row of Ta-
ble 5. Furthermore, we apply back-translation strategy with
the same/other NMT and compare it with original text ensur-
ing quality dataset from translation.
3.3. Results and Analysis
We show the performance of monolingual baseline models
and multilingual models on the Dictation testset in Table 6.
Since the multilingual models have the same size with the
monolingual models, these results are showing the impact
of training data. For the high-resource languages, the per-
formance gain of multilingual model is quite limited, and
even worse performance is obtained (e.g., [ es]). On the other
hand, we observe that the multilingual models signiﬁcantly
improve the performance on low-resource languages (except
Tamil [ ta] since it is using a different script). For example,
the normalized accuracy of monolingual model on Kazakh
[kk] is only 0.03%, and the multilingual models could achieve
the performance of 37.69%. Thus, we could say that adding
training data from the same script can improve the model per-
formance on low-resource languages. As a reference, we also
provide the ITN entities translation accuracy in the last col-
umn of Table 6. The higher the accuracy, the more ITN enti-
ties are evaluated in the Dictation testset.
Similarly, Table 7 shows the performance of monolingual
baseline models and the 12-language model on the Caption
Testset. This is computed by the case A strategy in Fig. 3. The
12-language ITN model is able to perform better accuracy on
[en, es, de ] while maintain competitive accuracy on [ fr, it].
From these two tables, we can see that the normalized
accuracy is much higher on the Dictation testset than on the
Caption Testset. We ﬁnd that there is a domain mismatch in
training and testset, as we ﬁnd a lot of complex math expres-Table 6 . Normalized accuracy of monolingual and multilin-
gual models on the Dictation testset.
Lang.zMonolingual 3-lang.z6-lang.z12-lang.zITN trans.zacc.z
es 79.15% 78.09% 76.80% 75.17% 91.34%
fr 62.35% 62.99% 60.98% 60.07% 62.81%
it 70.71% 71.42% 69.96% 69.87% 76.02%
en 71.73% - 72.75% 71.96% -
ru 68.39% - 64.66% 66.33% 82.86%
kk†0.03% - 37.69% 32.41% 99.63%
tr 60.07% - - 53.95% 46.19%
de 68.24% - - 63.74% 61.67%
el 66.84% - - 65.29% 64.64%
is†48.50% - - 61.75% 99.36%
af†29.21% - - 50.51% 96.45%
ta†25.63% - - 27.30% 99.74%
zlang., trans., and acc. stands for languages, translation, and accuracy.
†low resource languages.
Table 7 . Normalized accuracy of monolingual and 12-
language model on the Caption testset.
Language en es fr it de
Monolingual 63.70% 64.51% 55.24% 57.57% 48.10%
12-language 64.74% 65.58% 54.90% 56.77% 50.19%
Table 8 . Normalized accuracy when comparing of architec-
ture and translation tools on 3-langs ([ es], [fr], [it]) model and
SPM token size of 20,000 on the Dictation testset.
Arch. NMT es fr it
Seq2Seq MetaNMT 78.09% 62.99% 71.42%
Seq2Seq Opus-MT 71.11% 60.03% 55.89%
Transformer MetaNMT 72.55% 57.27% 64.76%
Table 9 . Comparison of standard rule-based ITN system and
data-driven ITN with/without data augmentation for English.
DD-ITN without DD-ITN with
Rule-based ITN data augmentation data augmentation
en 63.20% 51.40% 86.20%
sions in the Caption testset (e.g., 2 + 4 + 2 + 7 + 4 = 19 )
while none is found in the open subtitles training set.
Finally, Table 8 shows the ITN normalized accuracy when
using a different model architecture and different machine
translation model [10]; shows that the LSTM-based Seq2Seq
model is better than the Transformer model, and MetaNMT is
better than the Opus-MT for our task. Table 9 compares stan-
dard rule-based ITN with DD-ITN and illustrates the impact
of utilizing data-driven ITN modeling with our enhanced text
normalization data augmentation for English on the Google
TN evaluation dataset [14] with more than 70KITN entities.
4. CONCLUSION
This work investigates the effectiveness of language agnos-
tic data-driven ITN model. With the same model size, a 12-
languages ITN model can signiﬁcantly improves the normal-
ized accuracy of low resource languages while maintain rea-
sonable performance for high resource languages. Also, we
explore the architecture and the machine translation model
used in our framework and found that Seq2Seq model with
MetaNMT is our best system. Our future work will include
designing better architecture for on-device deployment, eval-
uation with clean and native language dataset, adapt data aug-
mentation to support native language nuances/variation, and
expanding to more languages.5. REFERENCES
[1] Ernest Pusateri, Bharat Ram Ambati, Elizabeth Brooks,
Ondrej Platek, Donald McAllaster, and Venki Nagesha,
“A mostly data-driven approach to inverse text normal-
ization.,” in INTERSPEECH . Stockholm, 2017, pp.
2784–2788.
[2] Tuan Manh Lai, Yang Zhang, Evelina Bakhturina,
Boris Ginsburg, and Heng Ji, “A uniﬁed transformer-
based framework for duplex text normalization,” arXiv
preprint arXiv:2108.09889 , 2021.
[3] Monica Sunkara, Chaitanya Shivade, Sravan Bodapati,
and Katrin Kirchhoff, “Neural inverse text normaliza-
tion,” in ICASSP 2021-2021 IEEE International Con-
ference on Acoustics, Speech and Signal Processing
(ICASSP) . IEEE, 2021, pp. 7573–7577.
[4] Alexandra Antonova, Evelina Bakhturina, and Boris
Ginsburg, “Thutmose tagger: Single-pass neural
model for inverse text normalization,” arXiv preprint
arXiv:2208.00064 , 2022.
[5] Szu-Jui Chen, Debjyoti Paul, Yutong Pang, Peng Su,
and Xuedong Zhang, “Language Agnostic Data-
Driven Inverse Text Normalization,” arXiv preprint
arXiv:2301.08506 , 2023.
[6] Sepp Hochreiter and J ¨urgen Schmidhuber, “Long short-
term memory,” Neural computation , vol. 9, no. 8, pp.
1735–1780, 1997.
[7] Minh-Thang Luong, Hieu Pham, and Christopher D
Manning, “Effective approaches to attention-
based neural machine translation,” arXiv preprint
arXiv:1508.04025 , 2015.
[8] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser,
and Illia Polosukhin, “Attention is all you need,” Ad-
vances in neural information processing systems , vol.
30, 2017.
[9] Taku Kudo and John Richardson, “Sentencepiece: A
simple and language independent subword tokenizer
and detokenizer for neural text processing,” arXiv
preprint arXiv:1808.06226 , 2018.
[10] J ¨org Tiedemann and Santhosh Thottingal, “OPUS-MT
— Building open translation services for the World,” in
Proceedings of the 22nd Annual Conferenec of the Euro-
pean Association for Machine Translation (EAMT) , Lis-
bon, Portugal, 2020.
[11] NLLB Team, Marta R. Costa-juss `a, James Cross, Onur
C ¸ elebi, Maha Elbayad, and et al. Heaﬁeld, “No lan-
guage left behind: Scaling human-centered machine
translation,” 2022.[12] Pierre Lison and J ¨org Tiedemann, “Opensubtitles2016:
Extracting large parallel corpora from movie and tv sub-
titles,” 2016.
[13] Nils Reimers and Iryna Gurevych, “Making mono-
lingual sentence embeddings multilingual using knowl-
edge distillation,” in Proceedings of the 2020 Confer-
ence on Empirical Methods in Natural Language Pro-
cessing . 11 2020, Association for Computational Lin-
guistics.
[14] Kaggle Dataset, “Google Text Normalization Chal-
lenge,” https://www.kaggle.com/datasets/google-
nlu/text-normalization, 2023, [Online; accessed
20-Jan-2023].6. APPENDIX
6.1. Data Augmentation with enhanced TN
Unlike a conventional written to spoken text normalization
system, our enhanced text normalization data augmentation
system for data-driven ITN is capable of generating much
diversiﬁed spoken forms by introducing almost all possible
spoken variations to the written forms as shown in Table 10.
Our rule-based enhance TN system supports cardinal, ordinal,
decimal, fraction, measures, money, date, time and telephone
entities. This system performs a series of steps for each writ-
ten text as input; pictorially depicted in Figure 1 and describe
as follows.
a.Pick: From the text corpus pick up sentences with nu-
merical ITN entities and discard other sentences.
b.Categorize and Segment: Extract text chunks that
matches our carefully prepared regular expressions
for each type of ITN entities in a predeﬁned order.
First, time and date entities segments are collected,
followed by measures, currency, abbreviations. Then
we ﬁnd fractions, decimals, ordinals, phone numbers
and cardinal in respective order.
c.Verbalize: Entities matching text segment are then
cleaned, formatted and normalized with digit and spo-
ken words to its closest verbalized form. For exam-
ples, Time: 12:45!12 hours 45 minutes. ;Date:
12/31/2022 or (31-12-2022) !31 December 2022 ;
Measures: 10K lb !10000 lb.; 207.6 kmps !207.6
kilometers per second.; 2 kg !two kilogram, two ki-
los, two kilo , etc.
d.Numeric Normalization: With verbalized text, we ap-
ply our rewrite mapping rules with core logic by select-
ing all possible combination of digits in order (and ap-
ply recursively, if required) to generate Nspoken form
texts for corresponding written text.
e.Rewrite: Finally, a rewrite module replaces the written-
form text in the original sentence with Ngenerated di-
verse spoken forms.
Table 10 . Examples of generated spoken form using conven-
tional TN system and our enhanced TN system
Input Conventional TN Our Augmentation System
123one hundred
twenty threeone hundred twenty three
one twenty three
one hundred and twenty three
one two three
$123one hundred
twenty three dollarsone hundred twenty three dollars
one hundred twenty three dollar
one twenty three dollars
one twenty three dollar
one hundred and twenty three dollars
one twenty three dollars zero cents
123gone hundred
twenty three gramsone hundred twenty three grams
one hundred twenty three gram
one twenty three grams
one twenty three gram
one hundred and twenty three grams
one hundred and twenty three gram
one two three grams6.2. Non-ITN Accuracy:
To minimize errors related to entities that are not part of the
ITN (i.e., non-ITN entities) from our sequence-to-sequence
based model, we have implemented the following measures:
a.Cleansing at source: We ﬁlter out spoken-written
pairs with non-zero or very low word-error-rate for
non-numerical segments from our training data. It is
important to note that dividing large texts into small
segments helps in achieving highly accurate alignment
and thus aids in the removal of errors at the source.
b.Selective Inference: Recent ASR systems can provide
hints about the entity type of a text segment, which is a
simpler task than performing the ITN post-processing
with ASR. Additionally, it is also easy to train a stan-
dalone non-ITN text classiﬁer using a sequence en-
coder model with our augmentation dataset. We apply
selective inference of numerical entities to ensure that
non-ITN entities are not translated.
c.Accuracy Metric: We have also performed evaluations
of non-ITN accuracy for languages such as Spanish,
French, Italian, and German, and found that the accu-
racy is greater than 98% on a human-annotated dataset.
6.3. Comparison of ITN systems
Here we present experiment and analysis of rule-based ITN
system and data-driven ITN with/without our enhanced text
normalization data augmentation system for English language
on evaluation set of Google’s Text Normalization dataset [14].
The rule-based ITN model, which relies on manually
crafted grammars, is difﬁcult to maintain and prone to er-
rors due to its complexity. Additionally, it performs poorly
on entities that require contextual information. In contrast,
our end-to-end data-driven approach eliminates the need for
complex rules, making it easier to scale to new languages and
perform better on entities requiring contextual information.
From the result, it shows that data driven ITN together with
augmentation perform signiﬁcantly better than rule based
ITN, which achieved 36.4% improvement on overall entity
accuracy. We see signiﬁcant improvement on Decimal, Mea-
sure and Time entities.
Table 11 . Comparison of normalized accuracy for rule-based
ITN system and data-driven ITN with/without enhanced TN
data augmentation for English language.
Rule-based Data-driven ITN Data-driven ITN
Class Size ITN without data with data
augmentation augmentation
Cardinal 10000 92.00% 55.00% 97.00%
Ordinal 10000 82.87% 50.90% 97.50%
Decimal 10000 2.20% 53.10% 90.80%
Measure 10000 46.70% 42.79% 88.20%
Telephone 4024 93.20% 88.00% 93.80%
Digit 5442 77.60% 56.80% 90.60%
Time 1159 36.10% 35.40% 73.60%
Date 10000 84.50% 46.00% 89.40%
Money 10000 53.80% 34.90% 55.40%
Overall 70625 63.20% 51.40% 86.20%