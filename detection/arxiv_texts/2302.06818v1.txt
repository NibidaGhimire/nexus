Masked Multi-Step Probabilistic Forecasting for
Short-to-Mid-Term Electricity Demand*
Yiwei Fu
GE Research
Niskayuna, NY , USA 12309
yiwei.fu@ge.comNurali Virani
GE Research
Niskayuna, NY , USA 12309
nurali.virani@ge.comHonggang Wangy
Upstart Power
Southborough, MA, USA 01772
hgwang2010@gmail.com
Abstract ‚ÄîPredicting the demand for electricity with uncer-
tainty helps in planning and operation of the grid to provide
reliable supply of power to the consumers. Machine learning
(ML)-based demand forecasting approaches can be categorized
into (1) sample-based approaches, where each forecast is made
independently, and (2) time series regression approaches, where
some historical load and other feature information is used. When
making a short-to-mid-term electricity demand forecast, some
future information is available, such as the weather forecast and
calendar variables. However, in existing forecasting models this
future information is not fully incorporated. To overcome this
limitation of existing approaches, we propose Masked Multi-Step
Multivariate Probabilistic Forecasting (MMMPF), a novel and
general framework to train any neural network model capable
of generating a sequence of outputs, that combines both the
temporal information from the past and the known information
about the future to make probabilistic predictions. Experiments
are performed on a real-world dataset for short-to-mid-term
electricity demand forecasting for multiple regions and compared
with various ML methods. They show that the proposed MMMPF
framework outperforms not only sample-based methods but
also existing time-series forecasting models with the exact same
base models. Models trainded with MMMPF can also generate
desired quantiles to capture uncertainty and enable probabilistic
planning for grid of the future.
Index Terms ‚ÄîTime series, energy forecasting, deep learning,
self-supervised learning
I. I NTRODUCTION
The paradigm shift towards low carbon and more inter-
mittent renewable power generation, perplexes the load and
generation balancing for the power grid planners and operators.
Accurately forecasting electricity demand is becoming more
critical for effective power system management, dispatch
optimization, maintenance scheduling, energy trading, and
capacity planning. These forecasting processes can be grouped
into four categories based on their horizons [1]: very short
term, short term, mid term, and long term load forecasting, and
there are many papers on them [2]. Most relevant to this paper
are deep learning-based short-to-mid-term forecasting models
that provide multi-step outputs. These include convolutional
neural networks (CNN) for short-term load forecasting [3],
sequence-to-sequence long short-term memory (LSTM) for
single house load forecasting [4], and hybrid CNN and LSTM
for short-term consumption forecasting [5]. However, accurate
*This work was supported by GE Digital.yDr. Wang contributed to this work when he was at GE Research.forecasting is also becoming difÔ¨Åcult due to variability in the
behind-the-meter residential-scale, community-scale, and utility-
scale distributed renewable energy generation that impacts the
net demand. Thus, probabilistic forecasting tools are gaining
more importance to help operators understand plausible peak
net load that they expect to see on their network. In this work,
we focus on a novel framework for short-term and mid-term
electricity demand forecasting with uncertainty.
The electricity demand forecasting models can be grouped
into two categories according to forecasting steps: one-step
forecasting, which estimates future demand one step ahead in
time, and multi-step forecasting that predicts multiple time steps
into the future. This paper addresses the multi-step forecasting
problem. Time series models for multi-step forecasting can be
categorized into two kinds of approaches: recursive methods
and direct methods [6]. Recursive methods typically use an auto-
regressive approach for one-step-ahead prediction and produce
multi-step forecasts by recursively feeding predictions as inputs
into the future time steps. However, there is often some error
at each step, so the recursive structure tends to accumulate
large errors over long forecasting horizons. Alternately, direct
methods directly map all available inputs to multi-step forecasts
and typically use a sequence-to-sequence (seq2seq) structure.
The disadvantage of this method is that it is harder to train,
especially when the forecast horizon is large [7].
For short-term and mid-term electricity demand forecasting
problem, there is often some estimate or known future informa-
tion available, such as weather forecasts and calendar variables,
how to make most use of these future information is the key
focus of this paper. Most existing work does not incorporate
known future information directly during training. Recursive
methods use the future information when making iterative
forecasts, but they are trained on 1-step predictions only.
Partially inspired by the success of natural language models
such as BERT [8], and to address the gap in incorporating
known future information in multi-step forecasting, we pro-
pose Masked Multi-Step Multivariate Probabilistic Forecasting
(MMMPF) framework. MMMPF is not a model, but a general
self-supervised learning task for training all NN time series
models (including recurrent NNs, CNNs, and attention-based
models) to make multi-step probabilistic forecasts with known
future information. MMMPF is a Ô¨Çexible learning framework
that improves upon existing methods by taking into accountarXiv:2302.06818v1  [cs.LG]  14 Feb 2023both recent history and known future information.
The contributions of this paper are as follows:
We propose MMMPF, a novel and general framework
for training NN-based multi-step forecasting models with
known future information. It uses a masking technique
that is Ô¨Çexible and can generate forecasts over different
horizons. It improves existing methods by combining both
recent history and known future information.
MMMPF can incorporate quantile regression loss func-
tions and generate probabilistic forecasts.
The proposed framework is validated by an electricity
demand forecasting challenge. MMMPF shows consis-
tently better results for different forecasting horizons on
different models in this real-world dataset.
It should be emphasized that the goal of this paper is not to
solve one forecasting problem with the best-tuned model, rather,
to offer a new learning framework which could be applied
to any NN model. The comparisons with existing time series
forecasting methods are by no means exhaustive, but they are
fair because they use the same base model and hyperparameters.
It should also be noted that studying how the future information
(i.e., weather forecasts) is generated, or evaluating how good
it is, are beyond the scope of this paper. We have focused on
developing a general deep learning framework for time series
probabilistic modeling that can incorporate future information
in making multi-step forecasts when it is available.
II. B ACKGROUND
Machine learning-based forecasting models can be cate-
gorized into sample-based models and time-series models.
Traditionally, sample-based regression models such as multiple
linear regression and hidden Markov model [9], feed-forward
neural networks [7], nearest neighbors [10], decision trees [11],
support vector regression [12], ensemble of varied length
mixture models [13] have been used for forecasting. To achieve
multi-step forecasting, one simply run the sample-based model
multiple times for each step.
Time series models can be further categorized into recursive
methods and direct methods. Recursive methods [14]‚Äì[17]
generate multi-step forecasts by recursively feeding 1-step
forward predictions into future time steps. These approaches
often lead to error accumulation because a forecast is based
on all previous forecasts. Direct methods [4], [18]‚Äì[22] map
all available input directly to all forecasts using sequence-to-
sequence models, but they do not use future inputs.
Figure 1 illustrates the key insight of MMMPF: to make
accurate multi-step forecasts, it is imperative to incorporate
all past information, as well as any known future information.
Existing methods fall short at some of these aspects: sample-
based models do not consider the recent history and time
series models do typically use all known future information or
make forecasts for multi-steps at once. In the context of load
forecasting, sample-based methods do not consider previous
day‚Äôs load, while time series models do not use all future
weather information in their models. In contrast, MMMPF
ùë•!‚Ä¶ùë•"ùë¶!‚Ä¶ùë¶#‚Ä¶ùë°‚àí1ùë°ùë°+1ùë•!‚Ä¶ùë•"ùë¶!‚Ä¶ùë¶#ùë•!‚Ä¶ùë•"ùë¶!‚Ä¶ùë¶#(a) MMMPF(b) Sample-based
‚Ä¶(c) Time series (recursive)Fig. 1: Multi-step forecasting, variables in blue (darker shade)
are used to forecast those in green (lighter shade). (a) MMMPF
uses all past and future information to predict forecast variables.
(b) Sample-based methods do not consider recent history. (c)
Existing time series models do not use all future information.
is designed to maximally take advantage of all available
information, past or future, while keeping the forecasting
horizon Ô¨Çexible. This is the intuition why MMMPF could
potentially outperform existing forecasting frameworks.
III. P ROBLEM FORMULATION AND PROPOSED SOLUTION
A. Masked Multi-Step Multivariate Probabilistic Forecasting
Consider a multivariate time series forecasting problem:
letxt2Rnbe a sample of predictor variables with dimension
nat timetand thej-th dimension is denoted as xj
t(i.e.,xt=
[x1
t;x2
t;:::;xn
t]),yt2Rmbe a sample of forecast variables
with dimension mat timet(i.e., yt= [y1
t;y2
t;:::;ym
t]), the
task is to predict up to (k+ 1) steps (k0) of forecast
variables yt;yt+1;:::;yt+kfrom pastT-step information as
well as the future information for predictor variables up to time
t+k. A distinct feature of this problem formulation compared
to a standard time series forecasting problem is the need to
incorporate future information into the predictions directly.
For example, when forecasting electric demand for a particular
region over the next month, the calendar variables (date, month,
day of week, etc.) and some weather forecasts are known, yet
traditional forecasting formulations do not take full advantage
of the future information.
Our recently proposed Masked Multi-Step Multivariate
Forecasting (MMMF) [23] directly models the following:
^yt;:::;^yt+k=f(xt 1;:::;xt T;yt 1;:::;yt T;xt;:::;xt+k)
(1)
wherefis the function being modeled, ^ytare estimations
of the ground truth ytvalues, xt 1;:::;xt Tare the past
predictor variables, yt 1;:::;yt Tare the past forecast vari-
ables, and xt;:::;xt+kare the future predictor variables.
We propose Masked Multi-Step Multivariate Probabilistic
Forecasting (MMMPF) by combining MMMPF with quantile
regression (QR) [24], i.e., instead of learning a deterministic
relationship with mean squared error as the loss function, we
learn probabilistic forecasts in MMMPF. Quantiles provide an
interpretable representation for uncertainty because they can
be used to model complex distributions without parametric
assumptions, and allow for simple construction of prediction
intervals. QR involves optimizing the pinball loss between the
ground truth yand prediction ^y:
(y;^y) = (^y y)( 1y^y ) (2)whereis the desired quantile level and 0<  < 1and
indicator function 1y^y= 1, ify^y, else it is 0.
In comparison, traditionally there are three most common
machine learning formulations for modeling such a multi-step
multivariate forecasting problem:
1)Sample-based forecasting (SBF) approach: this formu-
lation maps the predictor variables to forecast variables
directly without considering the temporal dependency:
^yt=f(xt);:::;^yt+k=f(xt+k) (3)
2)Recursive single-step forecasting (RSF) approach: this
formulation learns a one-step forward prediction model
and apply that recursively during inference, i.e.:
^yt=f(xt 1;:::;xt T;yt 1;:::;yt T)
^yt+1=f(xt;:::;xt T+1;^yt;yt 1;:::;yt T+1)(4)
3)Direct multi-step forecasting (DMF) approach: this
formulation directly generates multiple steps of forecast
variables given past information, i.e.:
^yt;:::;^yt+k=f(xt 1;:::;xt T;yt 1;:::;yt T)(5)
MMMPF, RSF and DMF are time-series models, while SBF
approaches are sample-based.
B. Proposed Algorithm
To solve this multi-step multivariate probabilistic forecast-
ing problem, our proposed MMMPF uses a masked time series
model (MTSM) approach. Inspired by [25] where MTSMs
are used for time series anomaly detection and have shown
superior performance to traditional regression models, we
detail MMMPF training in Algorithm 1. In this algorithm,
we replaced all masked variables with random values within
the ranges of those variables. The time series model fin this
algorithm can be any neural network model that generates a
sequence of outputs, such as Long Short-Term Memory (LSTM)
network [26], Temporal Convolutional Network (TCN) [27]
Transformer [28], etc. MMMPF is not limited to one model but
is a general learning task for all time series NN models. For the
loss functionsfg, we could choose =f0:05;0:50;0:95g
corresponding to the 5%;50%;95% quantiles.
A major advantage of the MMMPF learning task, which
uses all the available information to forecast the variable-length
masked variables, is that once it is trained, a base NN model can
generate forecasts for any forecast length lffor0<lfk+1,
by simply masking the last lfsteps of the desired forecast
variables. Fundamentally, the self-supervised learning approach
should learn a representation of the data by being able to Ô¨Åll in
the blanks when some forecast variables are masked. This leads
to the Ô¨Çexibility of MMMPF-trained models during inference:
they are not restricted to making Ô¨Åxed-length forecasts. Instead,
the models can generate any forecasts of length from 1to
the maximum forecast horizon k. This could potentially be
useful in some real-world applications, e.g., when an electricity
load demand forecast model is trained, it needs to be able
to make both short-term forecasts for unit commitment andAlgorithm 1: MMMPF Training
Input: Time series model fwith trainable parameters
, maximum forecasting horizon k, maximum
history length T, loss functionsfg
Data: Time series dataset S=fzig=f(xi;yi)g,
whereirepresents the i-th time step, xiare the
predictor variables, yiare the forecast variables
1Preprocessing dataset with a sliding window of length
(T+k+ 1) tofzt T;:::;zt 1;zt;zt+1;:::;zt+kg
sequences, where ztis the sample at current step;
2Initializing model parameters ;
3while not at end of training epochs do
4 while not at the end of all mini-batches do
5 Randomly choose a batch of sequences;
6 Randomly choose an integer mask length lmfor
this current batch, 0<lmk+ 1;
7 foreach sequence in the mini-batch do
8 Mask lastlmsteps of forecast variables y;
9 Feed masked sequences to model f, generate
estimations ^yusing information of predictor
variables from both the past and future
xt T;:::;xt+k, and unmasked forecast
variables yt T;:::;yt+k lm;
10 Calculate losses on masked predictionsPi=k
i=k lm(yi;^yi)for all quantiles ;
11 Backpropagation, update model parameters ;
Output: Trained model f
mid-term forecasts for fuel planning and maintenance planning.
Instead of having multiple models for each horizon, a single
MMMPF-trained model could complete all of the tasks.
It should also be noted that some existing time series ap-
proaches can concatenate future predictor variables xt;:::;xt+k
into the input vectors and train a model to incorporate
both future and past information, but because of the Ô¨Åxed
concatenation length they can only generate forecasts of the
same length (horizon), unlike MMMPF where the forecast
horizon is Ô¨Çexible.
IV. E XPERIMENTAL RESULTS
In this section, we apply Masked Multi-Step Multivariate
Probabilistic Forecasting (MMMPF) to the ISO New England
electricity demand forecasting dataset, and compare the results
with existing forecasting formulations. For fair comparison,
MMMPF, RSF, and DMF all use the same base models. The
task is to forecast electricity demand from 1-day to 60-day
ahead, given calendar variables and future weather information,
as well as the most recent 30-day demand history. It should be
noted that MMMPF is not limited to only 60-day forecasts. As
a general framework, MMMPF can support any length during
training, but in reality the weather forecasts for more than
60-day ahead may not available or accurate, thus we limit the
problem to short-to-mid-term forecasting.A. Dataset and Models
The ISO New England zonal dataset1includes the
demands from year 2011 to 2021 for 8 different zones:
Connecticut, Maine, Northeast Massachusetts and Boston, Hew
Hampshire, Rhode Island, Southeast Massachusetts, Vermont
and West/Central Massachusetts. Hourly data from 2011 to
2020 are used for training (87,672 samples in total), and 2021
used for testing (8,760 samples in total).
For unit commitment, fuel planning, or maintenance planning,
forecasting daily peak electricity demand from 1-day ahead
to 60-day ahead is often studied [1]. To accomplish this
daily peak forecasting task, the original hourly dataset is
downsampled to daily by taking the maximum values of the
day. Predictor variables include month, date, day of week, dry
bulb temperature, and dew point temperatures for each zone.
Forecast variables are the electricity demands for each zone,
with a total of 8 variables at each step. For the time series
frameworks (MMMPF, RSF, DMF), they use the same base
models and hyperparameters for fair comparisons:
LSTM [26]: 2hidden layers, each with dimension 50.
TCN [27]: 2hidden layers with channel size 50each,
convolutional kernel size 3and stride 1, dilation factor is
2iwhereiis thei-th layer, and dropout rate 0:2.
Transformer [28]: model dimension 64, feed-forward
dimension 256, number of heads 4, number of encoder
layers 2, and dropout rate 0:1. Only encoder is used.
For these time series models, we train with an Adam opti-
mizer [29] with a learning rate of 0:001. Model batch size
is1000 and the number of epochs is 1000 . We report the
mean absolute percentage error (MAPE) for test results in this
subsection following common practices in the Ô¨Åeld of electricity
demand forecasting. For training sets, 80% of the data were
used for training and 20% for validation. For categorical
variables, an embedding layer with dimension 5is used.
For SBF, we trained the following standard ML models:
LR-O : ordinary linear regression.
LR-R : Linear model with ridge regression.
LR-L : Linear model with Lasso regression.
SVM-L : Support vector machine (SVM) linear kernel.
SVM-RBF : SVM w/ Radial Basis Function kernel.
GP: Gaussian Process w/ Matern kernel = 1:5.
DT: Decision tree (DT) with max depth of 5.
RF: Random forest of 100 DT as above.
FCNN : fully-connected NN with 2 layers of 50 neurons.
B. Multi-Step Multivariate Probabilistic Forecasting Results
The results for 1-to-60-day ahead electricity demand
forecasting is listed in Table I and grouped by different
base models and training methods. MAPE is averaged over
8 different zones and all forecasting horizons from 1 to 60
days. It can be seen from the right columns that for this
multi-step forecasting problem with known future information,
MMMPF signiÔ¨Åcantly outperforms RSF and DMF with exactly
1Raw data Ô¨Åles can be downloaded at https://www.iso-ne.com/isoexpress/
web/reports/load-and-demand/-/tree/zone-info
0 10 20 30 40 50 60
Forecasting Time Steps into the Future5.07.510.012.515.017.520.0MAPEMMMPF
SBF
RSF
DMFFig. 2: Daily peak demand forecasting with horizon from 1
to 60 days, average MAPE for 8 zones are shown. MMMPF,
RSF, and DMF use LSTM base model, SBF uses LR-O model.
the same base model and hyperparameters. This is because
MMMPF directly incorporates known future information in its
training processes. From the left column, several traditional ML
models perform relatively poorly compared to MMMPF models,
because these models are not time-series models, i.e., they do
not use recent history at all. This results illustrate a simple
point: when history information and some future information
are known, a ML framework should use both to make better
forecasts. However, standard time series frameworks (RSF &
DMF) fails to incorporate all future information, while non-
time series models (DBF) fails to consider the history, leading
to worse forecasting results than MMMPF.
TABLE I: Mid-term electricity demand forecasting results.
Average MAPE for different forecasts (of horizon 1 day to 60
days) is reported for different methods (lower is better). For
all NN-based models MAPE is reported on quantile = 0:5.
Base Model Method MAPE SBF Model MAPE
LSTMMMMPF 4.99 LR-O 13.91
RSF 8.63 LR-R 13.99
DMF 19.22 LR-L 14.95
TCNMMMPF 6.00 SVM-L 13.53
RSF 9.62 SVM-RBF 5.99
DMF 18.67 GP 6.22
TransformerMMMPF 5.56 DT 7.85
RSF 7.92 RF 7.27
DMF 17.72 FCNN 7.59
Figure 2 shows the MAPE from 1-day to 60-day ahead
forecasting. Because RSF is trained on 1-step forward predic-
tions, its performance worsens signiÔ¨Åcantly as the number of
steps increases and predictions are made by using previous
predictions. The performance of DMF is the worst because it
needs to directly map the historical data to all 60-step forecasts
without using the future information. Since all 60 steps are
being generated simultaneously, the performance does not
worsen with increasing forecasting horizon.
As probabilistic forecasting becomes increasingly important
for the planning and operation of energy systems, the traditional
point outputs at each step may not be adequate for many real-
world tasks anymore. Our proposed MMMPF model could
generate probabilistic forecasts as shown in Figure 3 with
models trained by different quantiles =f0:05;0:50;0:95g.2021-01 2021-03 2021-05 2021-07 2021-09 2021-11 2022-01
Date1200014000160001800020000220002400026000ISONE Demand
Predicted Mean
True
5% - 95% QuantileFig. 3: 60-step ahead probabilistic forecasting with MMMPF
and LSTM base model.
V. C ONCLUSION
In this paper, we proposed and experimentally vali-
dated Masked Multi-Step Multivariate Probabilistic Forecasting
(MMMPF), a new self-supervised learning framework for
multi-step time series probabilistic forecasting with known
future information. MMMPF will help grid planners and
operators obtain multi-step forecasts with uncertainty at several
nodes in their network. MMMPF has been experimentally
validated on a real-world short-to-mid-term electricity demand
forecasting dataset. The main contribution of this paper is
to show that MMMPF as a general machine learning task
can outperform existing time series forecasting approaches,
including recursive methods and direct methods while using
the same base model, by incorporating future information;
and it can outperform existing non-time series models, by
incorporating past information. Once trained with MMMPF, a
time series model can generate any length forecasts below
the maximum forecast length during training, as well as
different forecasting quantiles. This makes MMMPF an ideal
upgrade to any existing deep learning-based multi-step time
series forecasting models, and potentially has signiÔ¨Åcant
impacts on many other real-world forecasting applications
where some future information is available. The effect of
uncertainty and errors in weather forecasts on the generated
demand forecasts with uncertainty will be considered in future
work. The calibration of prediction intervals obtained from
MMMPF will be explored in future. Other applications, such
as renewable energy generation forecasting and electricity spot
price forecasting, will be explored in future.
REFERENCES
[1]T. Hong and S. Fan, ‚ÄúProbabilistic electric load forecasting: A tutorial
review,‚Äù International Journal of Forecasting , vol. 32, no. 3, pp. 914‚Äì938,
2016.
[2]T. Hong, P. Pinson, Y . Wang, R. Weron, D. Yang, and H. Zareipour,
‚ÄúEnergy forecasting: A review and outlook,‚Äù IEEE Open Access Journal
of Power and Energy , vol. 7, pp. 376‚Äì388, 2020.
[3]Z. Deng, B. Wang, Y . Xu, T. Xu, C. Liu, and Z. Zhu, ‚ÄúMulti-scale
convolutional neural network with time-cognition for multi-step short-
term load forecasting,‚Äù IEEE Access , vol. 7, pp. 88 058‚Äì88 071, 2019.
[4]Z. Masood, R. Gantassi, and Y . Choi, ‚ÄúA multi-step time-series clustering-
based seq2seq lstm learning for a single household electricity load
forecasting,‚Äù Energies , vol. 15, no. 7, p. 2623, 2022.
[5]K. Yan, X. Wang, Y . Du, N. Jin, H. Huang, and H. Zhou, ‚ÄúMulti-step
short-term power consumption forecasting with a hybrid deep learning
strategy,‚Äù Energies , vol. 11, no. 11, p. 3089, 2018.[6]B. Lim and S. Zohren, ‚ÄúTime-series forecasting with deep learning: a
survey,‚Äù Philosophical Transactions of the Royal Society A , vol. 379, no.
2194, p. 20200209, 2021.
[7]D. M. Kline, ‚ÄúMethods for multi-step time series forecasting neural
networks,‚Äù in Neural networks in business forecasting . IGI Global,
2004, pp. 226‚Äì250.
[8]J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ‚ÄúBert: Pre-training
of deep bidirectional transformers for language understanding,‚Äù arXiv
preprint arXiv:1810.04805 , 2018.
[9]H. Cheng, P.-N. Tan, J. Gao, and J. Scripps, ‚ÄúMultistep-ahead time series
prediction,‚Äù in PaciÔ¨Åc-Asia Conference on Knowledge Discovery and
Data Mining . Springer, 2006, pp. 765‚Äì774.
[10] A. Sorjamaa, J. Hao, N. Reyhani, Y . Ji, and A. Lendasse, ‚ÄúMethodology
for long-term prediction of time series,‚Äù Neurocomputing , vol. 70, no.
16-18, pp. 2861‚Äì2869, 2007.
[11] B.-S. Yang, A. C. C. Tan et al. , ‚ÄúMulti-step ahead direct prediction for
the machine condition prognosis using regression trees and neuro-fuzzy
systems,‚Äù Expert systems with applications , vol. 36, no. 5, pp. 9378‚Äì9387,
2009.
[12] Y . Bao, T. Xiong, and Z. Hu, ‚ÄúMulti-step-ahead time series prediction
using multiple-output support vector regression,‚Äù Neurocomputing , vol.
129, pp. 482‚Äì493, 2014.
[13] Y . Ouyang and H. Yin, ‚ÄúMulti-step time series forecasting with an
ensemble of varied length mixture models,‚Äù International journal of
neural systems , vol. 28, no. 04, p. 1750053, 2018.
[14] S. Li, X. Jin, Y . Xuan, X. Zhou, W. Chen, Y .-X. Wang, and X. Yan, ‚ÄúEn-
hancing the locality and breaking the memory bottleneck of transformer
on time series forecasting,‚Äù arXiv preprint arXiv:1907.00235 , 2019.
[15] D. Salinas, V . Flunkert, J. Gasthaus, and T. Januschowski, ‚ÄúDeepAR:
Probabilistic forecasting with autoregressive recurrent networks,‚Äù Inter-
national Journal of Forecasting , vol. 36, no. 3, pp. 1181‚Äì1191, 2020.
[16] B. Lim, S. Zohren, and S. Roberts, ‚ÄúRecurrent neural Ô¨Ålters: Learning
independent bayesian Ô¨Åltering steps for time series prediction,‚Äù in 2020
International Joint Conference on Neural Networks (IJCNN) . IEEE,
2020, pp. 1‚Äì8.
[17] S. Suradhaniwar, S. Kar, S. S. Durbha, and A. Jagarlapudi, ‚ÄúTime
series forecasting of univariate agrometeorological data: a comparative
performance evaluation via one-step and multi-step ahead forecasting
strategies,‚Äù Sensors , vol. 21, no. 7, p. 2430, 2021.
[18] M. Hauser, Y . Fu, Y . Li, S. Phoha, and A. Ray, ‚ÄúProbabilistic forecasting
of symbol sequences with deep neural networks,‚Äù in 2017 American
Control Conference (ACC) . IEEE, 2017, pp. 3147‚Äì3152.
[19] C. Fan, Y . Zhang, Y . Pan, X. Li, C. Zhang, R. Yuan, D. Wu, W. Wang,
J. Pei, and H. Huang, ‚ÄúMulti-horizon time series forecasting with
temporal attention learning,‚Äù in Proceedings of the 25th ACM SIGKDD
International conference on knowledge discovery & data mining , 2019,
pp. 2527‚Äì2535.
[20] M. Hauser, Y . Fu, S. Phoha, and A. Ray, ‚ÄúNeural probabilistic forecasting
of symbolic sequences with long short-term memory,‚Äù Journal of Dynamic
Systems, Measurement, and Control , vol. 140, no. 8, 2018.
[21] B. Lim, S. ¬®O. Arƒ±k, N. Loeff, and T. PÔ¨Åster, ‚ÄúTemporal fusion transformers
for interpretable multi-horizon time series forecasting,‚Äù International
Journal of Forecasting , vol. 37, no. 4, pp. 1748‚Äì1764, 2021.
[22] J. J. Dabrowski, Y . Zhang, and A. Rahman, ‚ÄúForecastnet: a time-variant
deep feed-forward neural network architecture for multi-step-ahead time-
series forecasting,‚Äù in International conference on neural information
processing . Springer, 2020, pp. 579‚Äì591.
[23] Y . Fu, H. Wang, and N. Virani, ‚ÄúMasked multi-step multivari-
ate time series forecasting with future information,‚Äù arXiv preprint
arXiv:2209.14413 , 2022.
[24] R. Koenker and K. F. Hallock, ‚ÄúQuantile regression,‚Äù Journal of economic
perspectives , vol. 15, no. 4, pp. 143‚Äì156, 2001.
[25] Y . Fu and F. Xue, ‚ÄúMAD: self-supervised masked anomaly detection task
for multivariate time series,‚Äù arXiv preprint arXiv:2205.02100 , 2022.
[26] S. Hochreiter and J. Schmidhuber, ‚ÄúLong short-term memory,‚Äù Neural
computation , vol. 9, no. 8, pp. 1735‚Äì1780, 1997.
[27] S. Bai, J. Z. Kolter, and V . Koltun, ‚ÄúAn empirical evaluation of generic
convolutional and recurrent networks for sequence modeling,‚Äù arXiv
preprint arXiv:1803.01271 , 2018.
[28] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
L. Kaiser, and I. Polosukhin, ‚ÄúAttention is all you need,‚Äù arXiv preprint
arXiv:1706.03762 , 2017.
[29] D. P. Kingma and J. Ba, ‚ÄúAdam: A method for stochastic optimization,‚Äù
arXiv preprint arXiv:1412.6980 , 2014.