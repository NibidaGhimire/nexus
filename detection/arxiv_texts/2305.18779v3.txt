IT BEGINS WITH A BOUNDARY: A GEOMETRIC VIEW ON
PROBABILISTICALLY ROBUST LEARNING
LEON BUNGERT, NICOLÁS GARCÍA TRILLOS, MATT JACOBS, DANIEL MCKENZIE,
ÐORÐE NIKOLIĆ, AND QINGSONG WANG
Abstract. Although deep neural networks have achieved super-human performance on
many classification tasks, they often exhibit a worrying lack of robustness towards adver-
sarially generated examples. Thus, considerable effort has been invested into reformulating
standard Risk Minimization (RM) into an adversarially robust framework. Recently, at-
tention has shifted towards approaches which interpolate between the robustness offered by
adversarial training and the higher clean accuracy and faster training times of RM. In this
paper, we take a fresh and geometric view on one such method—Probabilistically Robust
Learning (PRL) [30]. We propose a mathematical framework for understanding PRL, which
allows us to identify geometric pathologies in its original formulation and to introduce a
family of probabilistic nonlocal perimeter functionals to rectify them. We prove existence
of solutions to the original and modified problems using novel relaxation methods and also
study properties, as well as local limits, of the introduced perimeters. We also clarify,
through a suitable Γ-convergence analysis, the way in which the original and modified PRL
models interpolate between risk minimization and adversarial training.
Contents
1. Introduction 2
1.1. From empirical risk minimization to robustness 3
1.2. Modifying PRL for binary classification 4
1.3. A larger class of PRL models for binary classification 5
1.4. Informal statements of main results 6
1.5. Related work 9
1.6. Outline 9
2. Existence of probabilistically robust classifiers 10
2.1. Preliminaries 10
2.2. Model family for hard classifiers 12
2.3. Model family for soft classifiers 14
2.4. Existence proofs 17
3. The functional ProbPer Ψas a perimeter 22
4. Interpolation properties of probabilistically robust learning 28
5. PRL for general learning settings and the conditional value at risk 35
6. Numerical experiments 36
6.1. Comparing accuracy and robustness 36
6.2. On the existence of pathological points 37
7. Discussion and Conclusion 38
Acknowledgment 39
References 39
1arXiv:2305.18779v3  [cs.LG]  30 Sep 2024Appendix A. Pathological points in the modified PRL model 42
Appendix B. Computational aspects of PRL 43
B.1. Pseudocode for geometric probabilistically robust learning 43
B.2. Training details 43
B.3. Computational resources used 44
B.4. Further numerical experiments 45
1.Introduction
The fragility of deep neural network (DNN) based classifiers in the face of adversarial
examples [9, 12, 20, 27] and distributional shifts [22, 28] is by now nearly as familiar as
their success stories. In light of this, a multitude of works (see Section 1.5) propose replac-
ing standard Risk Minimization (RM) [36] with a more robust alternative, with adversarial
training (AT) [20, 23] being a leading example. Unfortunately, there is no free lunch: robust
classifiers frequently exhibit degraded performance on clean data and significantly longer
training times [35]. Consequently, identifying frameworks which balance performance and
robustness is of pressing interest to the Machine Learning (ML) community, and over the
past several years a few such frameworks have been proposed [30, 37, 41]. From the theoret-
ical perspective, it is crucial that the mechanisms by which such frameworks balance these
competing aims are understood.
InthispaperwerevisittheProbabilisticallyRobustLearning(PRL)frameworkintroduced
in[30]anddiscussit,analyzeit,andextenditusingageometricperspective. Thisperspective
reveals certain subtle and paradoxical aspect of PRL: It can have solutions which are very
pathological classifiers, see Figure 1. Building on this observation one can conclude that
solutions of PRL do not necessarily interpolate between standard risk minimization and AT.
This interpolating property was one of the main theoretical motivations for designing the
PRL model in [30]; see Section 4 for an extensive discussion on this.
A≜class redAc≜class blue
(a)This pathological classifier minimizes the
original PRL risk but notthe modified one.
A≜class redAc≜class blue
(b)This classifier minimizes the original PRL
risk andthe modified one.
Figure 1. Even for the simple task of classifying two data points one can
easily construct a pathological solution (Figure 1a) of PRL, observing that
all but the small red set of perturbations of the misclassified blue point are
correctly classified as blue. Both classifiers depicted in Figures 1a and 1b have
zero PRL loss.
Fortunately, our geometric perspective suggests a natural remedy which leads to an inter-
pretation of the modified PRL as regularized RM, where a new notion of nonlocal length (or
2perimeter) of decision boundaries acts as a regularizer; this notion of perimeter (see (9) for its
definition) is of interest in its own right and in Section 3 we will discuss some of its properties.
The interpretation of PRL as perimeter-regularized RM leads us to further generalizations
and allows us to provide a novel view of the Conditional Value at Risk (CVaR) relaxation
of PRL proposed in [30]. We provide conditions that guarantee the existence of solutions
to the optimization problems determining our models as well as the original PRL models,
and clarify, through rigorous analysis using the notion of Γ-convergence, the sense in which
the original PRL and the modified PRL models interpolate between adversarial training and
standard risk minimization. Our existence proofs exploit very interesting structural prop-
erties of our functionals that allow us to circumvent the apparent incompatibility between
the topologies under which our functionals are lower semicontinuous and under which the
compactness of minimizing sequences can be guaranteed.
1.1.From empirical risk minimization to robustness. Given an input space X, an
output space Y, a probability measure µ∈ P(X × Y ), a loss function ℓ:Y × Y → R, and a
hypothesis class H(i.e., a class of measurable functions from XintoY), the standard risk
minimization problem is
inf
h∈HE(x,y)∼µ[ℓ(h(x), y)]. (RM)
To train classifiers which are robust against adversarial attacks, [20, 23] suggested adversarial
training:
inf
h∈HE(x,y)∼µ"
sup
x′∈Bε(x)ℓ(h(x′), y)#
. (AT)
In the above, Xis assumed to have the structure of a metric space and Bε(x)forε >0
denotes the (open or closed) ball of radius εaround x, although for convenience we will
consider open balls whenever is needed.
The recent work [30] offered an alternative to adversarial training that attempts to reduce
the (in general) large trade-off between accuracy and robustness inherent in (AT); see [30,
35] for discussion. Instead of requiring classifiers to be robust to allpossible attacks around
a point x—as enforced through the supremum in (AT)—one may consider a less stringent
notion of robustness, only requiring classifiers to be robust to 100×(1−p)%of attacks drawn
from a certain distribution mxcentered at x. For this, the authors replace the supremum in
(AT) by the so-called p-ess supoperator for some value p∈[0,1). To define this operator,
consider a probability distribution mand a function fand let
p-ess sup
x′∼mf(x′) := inf {t∈R:Px′∼m[f(x′)> t]≤p}.
In the mathematical finance or economics literature the p-ess supoperator is better known
as the value at risk (VaR) of a random variable at level p. It is the smallest value t∈R
such that the probability that a randomly chosen point x′∼msatisfies f(x′)> tis smaller
than p. This notion reduces to the usual essential supremum of fwith respect to mifp= 0,
which explains the name p-ess sup. In [30], it was thus suggested to replace (AT) with the
probabilistically robust learning problem
inf
h∈HE(x,y)∼µ
p-ess sup
x′∼mxℓ(h(x′), y)
, (PRL)
3where {mx}x∈Xis a suitable family of probability distributions, one for each xin the data
space, interpreted as user-chosen distributions “centered” around the different x. The pro-
totypical example to keep in mind for X=Rdis the uniform distribution over the ε-ball
around x, i.e., mx:= Unif( Bε(x)), which is particularly relevant when dealing with adversar-
ial attacks on image classifiers. We will provide further theoretical discussion on the choice
of the measures mxin Section 4.
1.2.Modifying PRL for binary classification. To understand (PRL) better, we focus
first (and mostly) on the binary classification problem (i.e., Y={0,1}) using indicator
functions of admissible sets (i.e., H:={1A:A∈ A}). For now, one can think of A ⊂ 2X
as a suitable σ-algebra which fits to the problem. Note that we identify the two expressions
1A(x) =1x∈A. We focus on the standard 0-1lossℓ(˜y, y) =1˜y̸=y, which equals one if y̸= ˜y
and zero otherwise. In this scenario, the standard risk minimization problem (RM) reduces
to
inf
A∈An
Rstd(A) :=E(x,y)∼µ[y1x∈Ac+ (1−y)1x∈A]o
, (1)
and we refer to its minimizers as Bayes classifiers and to its minimum value as Bayes risk .
Similarly, (AT) can be rewritten as
inf
A∈A
Radv(A) :=E(x,y)∼µh
y1x∈(Ac)⊕ε+ (1−y)1x∈A⊕εi
, (2)
where for a set A∈ Aits fattening by ε-balls is defined as A⊕ε:=S
x∈ABε(x). As for (PRL),
it reduces to
inf
A∈A
Rprob(A) :=E(x,y)∼µh
y1Px′∼mx[x′∈Ac]>p+ (1−y)1Px′∼mx[x′∈A]>pi
, (3)
where, in comparison to (2), the fattenings A⊕εand(Ac)⊕εare replaced by the set of all
points x∈ Xfor which the probability that a neighboring point sampled from mxlies inside
A, orAc, respectively, is larger than p. From this definition one can see that PRL may lead to
counter-intuitive classifiers like the ones observed in Figure 1a. Indeed, taking mxto be the
uniform measure over Bε(x), we see that the red-shaded spiky region therein has such a small
volume that the blue point with label y= 0lies in the set {x∈ X :Px′∼mx[[x′∈A]≤p]}.
Hence, the second term in (3) is zero and the spike adds zero cost to the overall energy.
At an abstract level, the issue with (3) is that sets {x∈ X :Px′∼mx[[x′∈Ac]> p]}and
{x∈ X :Px′∼mx[[x′∈Ac]> p]}are not fattenings, i.e., supersets, of AcandA. Speaking
the language of classification, it means that points which are incorrectly classified incur zero
loss if most of their perturbations are correctly classified.
Inordertoobtainamodelwhichdoesnotexhibitthiscounter-intuitivebehaviorwemodify
(3) slightly, thereby obtaining a model which has a geometric regularization interpretation
and can be embedded in a rich class of models that allows to interpolate between risk
minimization and adversarial training. To motivate our modified PRL risk, we first observe
that the original adversarial training risk Radvadmits the following decomposition:
Radv(A) = R std(A) + Per adv(A),
4where Peradv(A)is the non-negative functional
Peradv(A) :=Z
Acsup
x′∈Bε(x)1A(x′) dρ0(x) +Z
Asup
x′∈Bε(x)1Ac(x′) dρ1(x)
andρi(•) :=µ(• × { i}), i.e., the weighted conditional distribution of the points with label
i∈ {0,1}. We refer the interested reader to [6], where a detailed discussion on this decom-
position, results on existence of minimizers for adversarial training, and a discussion on the
interpretation of the functional Peradvas a nonlocal perimeter are presented. The two terms
in the decomposition of Radvcan be interpreted as follows: 1) the term Rstd(A)is the stan-
dard risk and captures the contribution to the overall adversarial risk by misclassified points;
2)Peradv(A)captures the contribution of the points that, although classified correctly by
the binary classifier 1A, are within distance εfrom the decision boundary and thus can be
perturbed by the adversary to make the classifier’s output differ from the correct label. Mo-
tivated by the above decomposition for Radv, by substituting the suprema in the definition
ofPeradvwith a softer penalty, the following modified PRL model becomes natural:
(4) inf
A∈A
ProbR( A) := R std(A) + ProbPer( A)
,
where ProbPer is the non-negative functional
(5) ProbPer( A) :=Z
Ac1Px′∼mx[x′∈A]>pdρ0(x) +Z
A1Px′∼mx[x′∈Ac]>pdρ1(x).
The notation that we have chosen for the functional ProbPer suggests a perimeter interpre-
tation, and we will justify this choice shortly. With this interpretation, it becomes clear that
the modified PRL model (4) has the structure of a regularized risk minimization problem
where the regularization term penalizes the size of the boundary of a set. As discussed
earlier, this interpretation also holds for AT.
A simple computation (see Proposition 1 below) allows us to rewrite ProbRas
(6) ProbR( A) =E(x,y)∼µh
y1x∈Ac∨Px′∼mx[x′∈Ac]>p+ (1−y)1x∈A∨Px′∼mx[x′∈A]>pi
.
From this rewriting it is apparent that a point xwith label ycontributes to the modified PRL
risk if it is either non-robust in a probabilistic sense orif it is misclassified. For instance, if
y= 0, the loss is one when Px′∼mx[x′∈A]> por when x∈A. This second condition is not
captured by the original PRL formulation.
1.3.A larger class of PRL models for binary classification. For theoretical and com-
putational reasons that we will soon discuss, it is convenient to generalize problems (3) and
(4) further. Precisely, given an arbitrary function Ψ : [0 ,1]→[0,1]we define
RΨ(A) :=Z
XΨ (Px′∼mx[x′∈A]) dρ0(x) +Z
XΨ (Px′∼mx[x′∈Ac]) dρ1(x), (7)
as well as
ProbR Ψ(A) := R std(A) + ProbPer Ψ(A), (8)
where
ProbPer Ψ(A) :=Z
AcΨ (Px′∼mx[x′∈A]) dρ0(x) +Z
AΨ (Px′∼mx[x′∈Ac]) dρ1(x). (9)
5The functionals RΨandProbR Ψare indeed generalizations of RprobandProbR, respec-
tively. This can be seen by taking Ψto be Ψ(t) := 1t>p, as can be easily verified. An-
other important choice for Ψthat we will discuss extensively in the sequel is the function
Ψp(t) := min {t
p,1}, which is the smallest concave function larger than 1t>p. Later, in Propo-
sition 3 and in Section 5, we will discuss the connection between the CVaR relaxation of
PRL introduced for computational convenience in [30] (see more discussion in Appendix B)
and the optimization of the risks RΨandProbR Ψfor the choice Ψ = Ψ p. From a theoretical
perspective, we will establish several structural properties satisfied by the functionals RΨ
andProbR Ψwhen Ψis concave. In particular, while we are not able to prove existence
of minimizers (in a large class of sets A) for the original binary problem (3) nor for our
modification (4), we will be able to do it for the minimization of RΨandProbR Ψwhen Ψ
is concave, e.g., when Ψ = Ψ p. Without concavity the problems are degenerate because of
the hard thresholding imposed by the constraints Px′∼mx
x′∈A(c)
and we will only be able
to establish existence of solutions within the enlarged family of “soft” classifiers. A detailed
discussion on this is presented in Section 2 below.
1.4.Informal statements of main results. This paper investigates three main questions
related to PRL. First, we study the existence of minimizers to PRL and to modified PRL.
Second, we explore different geometric interpretations of the functionals ProbPer Ψ. In par-
ticular, we establish two types of results that characterize these functionals as perimeters ,
thereby further suggesting how the models studied in this paper for robust training of classi-
fiers are closely related to geometric regularization methods that explicitly penalize the size
of decision boundaries of classifiers. Finally, we present rigorous analysis that describes, in
detail, the way in which PRL and modified PRL interpolate between adversarial training
and standard risk minimization.
1.4.1.Existence of minimizers of PRL models. In [30], an explicit solution to (PRL) is
presented for the case where the hypothesis class consists of linear classifiers and µis a
mixture of normal distributions. To the best of our knowledge, existence of solutions to
(PRL) for general data distributions or hypothesis classes—even for the binary problem
(3)—has not been proved so far.
Our first main results assert the existence of minimizers of the risks ProbR ΨandRΨ
for suitable choices of Ψ. We impose no restrictions on the data distribution but consider
families of classifiers satisfying certain closure relations discussed precisely in later sections.
Informal Theorem 1 (Existence of hard classifiers) .For every concave and non-increasing
function Ψ : [0 ,1]→[0,1]there exists a solution to the problem
min
A⊂XProbR Ψ(A).
Informal Theorem 2 (Existence of hard classifiers) .For every concave and non-increasing
function Ψ : [0 ,1]→[0,1]there exists a solution to the problem
min
A⊂XRΨ(A).
Note that these existence results do not cover the problem (4) since the function Ψ(t) =
1t>pis not concave. They do include, however, the CVaR model from Proposition 3 below
since this model is realized by the choice Ψp(t) := min {t/p,1}, which is a concave and
6non-decreasing function. We believe that our proof strategy, which takes advantage of some
interesting structural properties of the functionals ProbR ΨandRΨ, is of interest in its own
right and is captured by our Meta Theorem 1 in Section 2.4 below. Precise statements of
our results can be found in Section 2.2.
We also present existence results for more general, non-concave functions Ψ, including the
choice Ψ(t) =1t>pgiving rise to the original PRL model and its modified version introduced
here. These results, however, apply when we optimize over “soft” classifiers instead of “hard”
ones, meaning we optimize over functions u:X → [0,1]in a suitably closed hypothesis class
Hinstead of characteristic functions u=1Aof sets A. To make sense of our statements,
we first need to replace the functional ProbPer Ψ(A)of a set Aby a suitable regularization
functional defined according to
ProbJ Ψ(u) :=Z
X(1−u(x)) Ψ (Ex′∼mx[u(x′)]) dρ0(x)
+Z
Xu(x)Ψ (Ex′∼mx[1−u(x′)]) dρ1(x).(10)
A straightforward computation reveals that ProbJ Ψ(1A) = ProbPer Ψ(A).
Informal Theorem 3 (Existence of soft classifiers) .For every lower semicontinuous func-
tionΨ : [0 ,1]→[0,1]and every hypothesis class Hwhich is closed in a suitable sense there
exists a solution to the problem
min
u∈HE(x,y)∼µ[|u(x)−y|] + ProbJ Ψ(u).
Informal Theorem 4 (Existence of soft classifiers) .For every lower semicontinuous func-
tionΨ : [0 ,1]→[0,1]and every hypothesis class Hwhich is closed in a suitable sense there
exists a solution to the problem
min
u∈HZ
XΨ (Ex′∼mx[u(x′)]) dρ0(x) +Z
XΨ (Ex′∼mx[1−u(x′)]) dρ1(x).
Note that the objective functions in Informal Theorems 3 and 4 coincide with ProbR Ψand
RΨ, respectively, when uis an indicator function. When Ψis non-decreasing and concave,
andHis suitably chosen, these optimization problems are continuous and exact relaxations
ofinfA∈AProbR ΨandinfA∈ARΨ, respectively. Other hypothesis classes Hof interest that
are admissible in Informal Theorems 3 and 4 include functions which are parameterized by
neural networks, as discussed in Example 2.
1.4.2.Interpretation of ProbPer Ψas a perimeter. As suggested by our discussion in earlier
sections, the functional ProbPer Ψcan be interpreted as a perimeter functional. We can
justify this interpretation from two different perspectives.
First, we establish the following structural properties for the functional ProbPer Ψwhen Ψ
is non-decreasing and concave, the exact same assumptions needed in our existence results
discussed in Section 1.4.1. These properties allow us to view ProbPer Ψas a generalized
perimeter.
InformalTheorem5 (Submodularity) .Provided Ψis concave, non-decreasing, and Ψ(0) =
0the functional ProbPer Ψis a generalized perimeter. In particular,
ProbPer Ψ(∅) = ProbPer Ψ(X) = 0
7andProbPer Ψis submodular, i.e.,
ProbPer Ψ(A∪B) + ProbPer Ψ(A∩B)≤ProbPer Ψ(A) + ProbPer Ψ(B)∀A, B∈ A.
As a generalized perimeter, ProbPer Ψadmits a convex extension (its total variation) that
is denoted by ProbTV Ψand that we define precisely in (19). Interestingly, ProbPer Ψhas
a second extension, the functional ProbJ Ψdefined in (10), which is sequentially lower-
semicontinuous (although it fails to be convex) w.r.t. the weak topology where we can
guarantee precompactness of minimizing sequences and is always greater than or equal to
ProbTV Ψ. We use this ordering in our proof strategy for the existence of optimal hard clas-
sifiers. We also note that, while non-convex, the extension ProbJ Ψhas a relatively simple
explicit expression that makes it useful for computations, while the same is not true for
ProbTV Ψ, which instead has a complicated expression that would be hard to compute with.
When Ψis more general, we can still give a perimeter interpretation to the functional
ProbPer Ψ, at least in an asymptotic sense. For this purpose, we assume that mxlocalizes to
a point mass at x.
Informal Theorem 6 (Local asymptotics) .LetX=Rd. Ifmx≡mx,εforε >0andmx,ε
converges to the Dirac delta δxin a suitable way, then the rescaled probabilistic perimeters
1
εProbPer Ψ(A)of a smooth set Aconverge to the weighted local perimeter
Per(A) :=Z
∂Af(x, n(x)) dHd−1,
where n(x)denotes the outer unit normal at x∈∂Aandfis a suitable weight function, de-
pending on the distributions mx,ε, and ρifori∈ {0,1}.Hd−1denotes the (d−1)-dimensional
Hausdorff measure in Rd.
1.4.3.Interpolation properties of PRL and modified PRL. Our last main results describe the
relation between adversarial training, RM, and the PRL and modified PRL models, at least
in the agnostic setting where the family of admissible binary classifiers consists of all Borel
measurable sets. We focus on the energies ProbR ΨpandRΨpasptends to zero or ∞for the
choice Ψp(t) = min {t/p,1}.
InformalTheorem7 (Convergencetominimumadversarialtraining) .LetΨp(t) := min {t/p,1}.
Then the minimum value of ProbR Ψpconverges to the minimum value of the adversarial
training problem (2)asp→0. If, in addition, for every xthe measure mxdominates the
data measures ρ0andρ1restricted to the support of mx, then minimizers of ProbR Ψpconverge
to minimizers of (2)asp→0.
Analogous statements hold for the minimization of RΨp.
While the convergence of the minimal risks holds under fairly general assumptions, we
emphasizethattheconvergenceofminimizersholdsprovidedweimposeadditionalconditions
on the measures {mx}x∈X, as our examples in Section 4 illustrate.
For large values of pwe have the following result.
Informal Theorem 8 (Convergence to minimum standard risk) .LetΨp(t) := min {t/p,1}.
Then the minimum value of ProbR Ψpconverges to the minimum value of the RM problem
(2)asp→ ∞. Also, minimizers of ProbR Ψpconverge to minimizers of (2)asp→ ∞.
8We emphasize that the above statement holds for ProbR Ψpbut not for RΨp. In fact, there
is no value or limiting value of pthat makes RΨpinto the standard risk functional. This
means that the family of functionals {RΨp}pdoes not actually interpolate between AT and
RM, while the family of functionals {ProbR Ψp}pdoes. The latter model has the additional
advantage of being interpretable as a geometric regularization model.
1.5.Related work. Adversarial training was developed in [20, 23] as an approach to pro-
duce networks that are less sensitive to adversarial attacks. [34] reduced its computational
complexity by reusing gradients from the backpropagation when training neural networks.
[39] showed that training with noise perturbations followed by a single signed gradient as-
cent (FGSM) step can be on par with adversarial training while being much cheaper. This
approach was picked up and improved upon in [1] based on gradient alignment. Different
authors also investigated test-time robustification of pretrained classifiers using randomized
smoothing[13]orgeometric/gradient-basedapproaches[32, 33]. Whilesomeoftheprevious
models use a combination of random perturbations and gradient-based adversarial attacks to
robustifyclassifiers, [30]proposedprobabilisticallyrobustlearning, whichisentirelybasedon
random perturbations. PRL aims to interpolate between clean and adversarial accuracy and
enjoys the favorable sample complexity of vanilla empirical risk minimization; see also [29]
for more insights on this issue. Connections between adversarial training and local perimeter
regularization as well as mean curvature flows of decision boundaries were explored in [19,
41] and recently rigorously tied in [7, 8]. Furthermore, in [8] it was proved that solutions to
adversarial training converge to distinguished minimizers of standard risk minimization as
ε→0which was later quantified and extended to the probablistically robust setting in [25].
An interpretation of adversarial training as gradient flow is given in [38].
Our work is in line with a series of papers [2, 3, 6, 16, 17, 18, 26] that explore the
existence of solutions to adversarial training problems in different settings. These existence
proofs involve dealing with different kinds of measurability issues, depending on whether
open or closed balls Bε(x)are used in the attack model. For open balls one can work with
the Borel σ-algebra A=B(X)[6], whereas closed balls require the use of the universal σ-
algebra to make sure that A⊕εis measurable [2, 3, 26]. Recently, these results were improved
in [18] where it was proved that, for the case of multi-class classification, even for the closed
ball model Borel measurable classifiers exist, although they are not necessarily indicator
functions of measurable sets. Moreover, [18] showed that for all but countably many values
of the adversarial budget ε >0the open and the closed ball models have the same minimal
value.
1.6.Outline. The rest of the paper is organized as follows. In Section 2 we make the setting
for our variational problems precise and then present a series of results on the existence of
minimizers of these problems. In particular, in Sections 2.2 and 2.3 we make precise our
Informal Theorems 1 and 2, and in Section 2.4 present their proofs. Section 3 is devoted
to the study of the functional ProbPer Ψand its interpretation as a perimeter. There, we
make the Informal Theorems 5 and 6 precise and present their proofs. Section 4 is devoted
to the interpolation properties of the different PRL models. There we make our Informal
Theorems 7 and 8 precise using the notion of Γ-convergence. In Section 5, we introduce a
modified PRL model for general supervised learning problems beyond binary classification
and discuss the connection between the CVar relaxation of PRL in [30] and our geometric
9framework. In Section 6 we present some numerical results of an implementation of our
models in real data settings. We wrap up the paper in Section 7 with some conclusions and
perspectives for future research.
2.Existence of probabilistically robust classifiers
2.1.Preliminaries. In this section we discuss a few other reformulations for the energies
discussed in the introduction. These reformulations provide some additional context and
connections to the literature that will later be used in our discussion.
To start, we first present a reformulation of the probabilistic risk ProbRas the expected
maximum of the sample-wise standard risk and the probabilistically robust risk from [30].
Proposition 1. For the 0-1lossℓ(˜y, y) :=1˜y̸=ywe can rewrite the probabilistic risk ProbR
as in(6). In that same setting, ProbRcan also be written as the expectation of a sample-wise
maximum of the standard loss and the loss suggested in [30], that is:
ProbR( A) =E(x,y)∼µ
max
ℓ(1A(x), y), p-ess sup
x′∼mxℓ(1A(x′), y)
. (11)
Remark 1. This result will be key for generalizing ProbRto multi-class classification as
well as general hypothesis classes and loss functions. See Section 5
Remark 2. In its original expression, ProbRis written as the sum of the standard risk and
a nonlocal perimeter functional. This probabilistic perimeter , which we will discuss in more
detail in Section 3, can be rewritten as:
ProbPer( A) =ρ0({x∈Ac:Px′∼mx[x′∈A]> p})
+ρ1({x∈A:Px′∼mx[x′∈Ac]> p}).
Note that ProbPer( A)counts the proportion of correctly classified points xfor which more
than 100×p%of their neighbors, sampled from mx, constitute an attack. From this it should
be intuitively clear that ProbPer( A)is a boundary term.
Remark 3. The interpretation of the statement of this proposition in the light of Figure 1
is clear: Only if a point xis correctly classified—meaning 11A(x)̸=y= 0—the probabilistically
robust regularization kicks in through the second term in the maximum. Points which are
incorrectly classified will always be penalized even if most attacks correct the label, i.e., if
1Px′∼mx[1A(x′)̸=y]>p= 0. Thus, minimizing ProbRinstead of Rprobcorrects the pathology of
the original PRL formulation.
Proof of Proposition 1. Disintegrating the risk functional Rstdwe can write
Rstd(A) =Z
X1x∈Adρ0(x) +1x∈Acdρ1(x).
Also,
ProbPer( A) =Z
X1x∈A∨Px′∼mx[x′∈A]>p−1x∈Adρ0(x)
+Z
X1x∈Ac∨Px′∼mx[x′∈Ac]>p−1x∈Acdρ1(x).
10Adding the above two identities we deduce (6). Now that (6) has been established we see
that
ProbR( A)
=Z
X1x∈A∨Px′∼mx[x′∈A]>pdρ0(x) +1x∈Ac∨Px′∼mx[x′∈Ac]>pdρ1(x)
=Z
Xmaxn
1x∈A,1Px′∼mx[x′∈A]>po
dρ0(x) +Z
Xmaxn
1x∈Ac,1Px′∼mx[x′∈Ac]>po
dρ1(x),
where we used the fact that the indicator function of the union of two sets equals the
maximum of the two indicator functions. (11) follows immediately. □
In the same spirit as in Proposition 1, we can rewrite ProbR Ψfor general Ψas follows.
Proposition 2. For the 0-1lossℓ(˜y, y) :=1˜y̸=yand for any function Ψ : [0 ,1]→[0,1]we
can rewrite the probabilistic risk ProbR Ψas sample-wise maximum in the following way:
ProbR Ψ(A) =E(x,y)∼µ[max{ℓ(1A(x), y),Ψ (Px′∼mx[ℓ(1A(x′), y)])}].
Besides the choice Ψ(t) =1t>panother interesting choice is the smallest concave function
which lies above it, i.e., Ψ(t) = min {t/p,1}. For this choice we can connect the probabilistic
risk with the conditional value at risk (CVaR) [31] which was suggested in [30] as a com-
putationally feasible replacement for the p-ess supoperator in problem (PRL). Its precise
definition will be important later and can be found in (37) in Section 5.
Proposition 3. For the 0-1lossℓ(˜y, y) :=1˜y̸=yand for Ψp(t) := min {t/p,1}withp∈(0,1)
it holds that
ProbR Ψp(A) =E(x,y)∼µ[max{ℓ(1A(x), y),CVaR p(ℓ(1A(·), y);mx)}].
We proceed to prove Proposition 2.
Proof of Proposition 2. The proof is similar to that of Proposition 1 after noting that for
Ψ : [0 ,1]→[0,1]
1x∈A+1x∈AcΨ (Px′∼mx[x′∈A]) = max {1x∈A,Ψ (Px′∼mx[x′∈A])}
which can easily be shown by checking cases. Then:
ProbR Ψ(A) =Z
X1x∈Adρ0(x) +Z
X1x∈Acdρ1(x)
+Z
X1x∈AcΨ (Px′∼mx[x′∈A]) dρ0(x) +Z
X1x∈AΨ (Px′∼mx[x′∈Ac]) dρ1(x)
=Z
X[1x∈A+1x∈AcΨ (Px′∼mx[x′∈A])] dρ0(x)
+Z
X[1x∈Ac+1x∈AΨ (Px′∼mx[x′∈Ac])] dρ1(x)
=Z
Xmax{1x∈A,Ψ (Px′∼mx[x′∈A])}dρ0(x)
+Z
Xmax{1x∈Ac,Ψ (Px′∼mx[x′∈Ac])}dρ1(x).
□
11We postpone the proof of Proposition 3, which discusses another reformulation of ProbR Ψ
in terms of the so-called conditional value at risk (CVaR), to Section 5, since Proposition 3
will not be used in the remainder of this section.
2.2.Model family for hard classifiers. We now begin the discussion of existence of
solutions to the minimization problems associated with the risks RΨandProbR Ψdefined in
(7) and (8). As was discussed in the introduction, these families of risks include Rproband
ProbR(forΨ(t) :=1t>p) but also a relaxation of the adversarial risk Radv(forΨ(t) :=1t>0).
We start our discussion by making our setting precise.
Assumption 1. We let Xbe a set and A ⊂ 2Xbe a σ-algebra. We assume that:
•(X × Y ,A ⊗2{0,1}, µ)is a probability space;
•(X,A, ρ)is a probability space, where we define ρ(•) :=µ(• × { 0,1});
• {mx}x∈Xis a family such that (X,A,mx)is a probability space for ρ-almost every
x∈ X.
We also define the probability measures
ρ:=ρ0+ρ1, (12)
ν(A) :=1
2Z
Xmx(A) dρ(x) +1
2ρ(A), A ∈ A. (13)
The measure ρequals the first marginal of µand models the distribution of all data, irre-
spective of their label. The first summand of the measure νis the convolution of ρwith the
family of probability measures {mx}x∈X.
By construction we have the following two important properties:
ν(A) = 0 = ⇒h
ρ(A) = 0and mx(A) = 0forρ-almost every x∈ Xi
, (14)
ρ(A) = 0 = ⇒h
ρ0(A) = 0and ρ1(A) = 0i
. (15)
A simple example for X=Rdisρ:=1
NPN
i=1δxiandmx:= Unif( Bε(x))in which case
ν=1
2NNX
i=1
Unif( Bε(xi)) +δxi
is a sum of absolutely continuous measures on balls centered at xiand the empirical measure
of the points xi.
Using the measure νwe will work with the weak-* topology of L∞(X;ν)which is the dual
space of L1(X;ν)since νisa fortiori aσ-finite measure [15, IV.8.3, Theorem 5].
Definition 1. Under Assumption 1 we say that a sequence of functions (un)n∈N⊂L∞(X;ν)
converges to u∈L∞(X;ν)in the weak-* sense (written un∗⇀ u) asn→ ∞if
lim
n→∞Z
Xunφdν=Z
Xuφdν∀φ∈L1(X;ν). (16)
We will use this topology to prove existence of minimizers of the probabilistic risks RΨ
andProbR Ψ. Furthermore, we use this same topology for proving that our modified PRL
using the function Ψpconverges to adversarial training as p→0, at least when the family
of measures {mx}xsatisfies a suitable assumption; see the discussion in Section 4.
12The following theorem establishes existence of minimizers of the risk ProbR Ψfor concave
and non-decreasing functions Ψ.
Interestingly, we establish the existence of hard classifiers using a novel abstract strategy,
rather than the usual direct method in the calculus of variations. We take this approach as
it is rather nontrivial to establish lower semicontinuity for an extension of ProbPer Ψto soft
classifiers that behaves well with respect to thresholding operations. Instead, we introduce
twodifferentrelaxations; onewhichislowersemicontinuous, andonewhichisdefinedthrough
a coarea formula and hence behaves well with respect to thresholding; our result then follows
from an ordering relation on the two relaxations if Ψis concave and non-decreasing.
We arrive at the rigorous versions of Informal Theorem 1 and Informal Theorem 2.
Theorem 1. Suppose Ψ : [0 ,1]→[0,1]is concave and non-decreasing, and that Assump-
tion 1 holds. Then, there exists a solution to the problem
inf
A∈AProbR Ψ(A). (17)
Theorem 2. Suppose Ψ : [0 ,1]→[0,1]is concave and non-decreasing, and that Assump-
tion 1 holds. Then, there exists a solution to the problem
inf
A∈ARΨ(A). (18)
The proofs of Theorems 1 and 2 are provided in Section 2.4. The reason why an existence
proof for (17) (or (18)) for non-concave functions Ψis currently not available is illustrated
in the following example.
(a)Homogenizing minimizer for Ψ(t) :=1t>p.
 (b)Superlevel set which is not a minimizer.
Figure 2. Non-compactness of minimizing sequences.
Example 1 (Homogenizing solutions) .In this example we consider the situation of two data
points (red and blue) which are so close that the ε-balls around them intersect. Furthermore,
we assume that p∈(0,1)is0.9times the ratio of the volume of the intersection to the
volume of one ε-ball. If we pick Ψp=1t>p, there exist infinitely many minimizers of (17)
with oscillatory boundaries in the intersection. One such minimizer is depicted in Figure 2a.
The minimizers can be arranged such that the ratios of the red or the blue volume to the
volume of the intersection are in the interval [0.4,0.6]. Consequently, all such sets have
zero loss and are global minimizers. However, the set of such minimizers is not compact
and has an accumulation point which is not a characteristic function, namely the function
u:X → [0,1]with values u= 1on the red ball without the blue ball, u= 0on the blue ball
13without the red ball, and u= 0.5on the intersection of the two balls. Hence, minimizing
sequences of (17) are not compact. The issue of non-compactness of minimizing sequences
can in fact also happen for concave functions Ψwhich is why in the proof of Theorem 1 we
show that almost every superlevel set {u > t}of a function uwhich is an accumulation point
of a minimizing sequences is a minimizer of (17). However, not even this strategy works in
the non-concave case since the superlevel set {u > t}for all t∈[0,1/2]is given by the set
in Figure 2b which is not a minimizer of PRL.
2.3.Model family for soft classifiers. Note that, besides the reasons given in Exam-
ple 1, an existence result similar to Theorem 1 for the non-concave function Ψ(t) =1t>pis
currently not available since our relaxation techniques rely on concavity of Ψ. However, in
this section we shall state an existence theorem for “soft classifiers” which is valid for very
general functions Ψ, including Ψ(t) =1t>p, since no relaxation is needed.
Such soft classifiers are particularly relevant since they include neural network based mod-
els with Softmax activation in the last layer which are used in practice. A suitable regular-
ization functional for soft classifiers is given by ProbJ Ψdefined in (10). For convenience we
repeat its definition. Given an A-measurable function u:X → [0,1]we let
ProbJ Ψ(u) :=Z
X(1−u(x)) Ψ (Ex′∼mx[u(x′)]) dρ0(x)
+Z
Xu(x)Ψ (Ex′∼mx[1−u(x′)]) dρ1(x)
which satisfies ProbJ Ψ(1A) = ProbPer Ψ(A)for every choice of Ψ. Hence, it is a natural
generalization of the perimeter to soft classifiers and one could call ProbJ Ψa total variation.
However, it is neither positively homogeneous nor convex so this name would be misleading.
Instead, for the proof of Theorem 1 we shall also work with the total variation functional
ProbTV Ψdefined as
ProbTV Ψ(u) :=Z1
0ProbPer Ψ({u > t}) dt, (19)
for all A-measurable functions u:X → [0,1]. Note that also the total variation satisfies
ProbTV Ψ(1A) = ProbPer Ψ(A). Both ProbJ ΨandProbTV Ψare of paramount importance
for the proof of Theorem 1.
The next theorem is the rigorous version of Informal Theorem 3 and asserts existence of
soft classifiers for the regularized risk minimization using ProbJ Ψfor very general functions
Ψand hypothesis classes H. It is sufficient that Ψis lower semicontinuous which is satisfied
by every continuous function and also by Ψ(t) = 1t>pforp∈[0,1]. Furthermore, the
existence theorem is valid for all hypotheses classes which are closed in the weak-* topology
ofL∞(X;ν).
Theorem 3 (Existence of soft classifiers for modified PRL) .Under Assumption 1, for every
lower semicontinuous function Ψ : [0 ,1]→[0,1], and whenever His a weak-* closed hypoth-
esis class of A-measurable functions u:X → [0,1]in the sense of Definition 1, there exists
a solution to the problem
inf
u∈HE(x,y)∼µ[|u(x)−y|] + ProbJ Ψ(u). (20)
14Example 2 (Hypothesis classes) .The hypothesis class consisting of measurable sets, i.e.,
H={1A:A∈ A}is not weak-* closed which is why Theorem 1 needs stronger assumptions
onΨthan Theorem 3. Let us instead consider three interesting hypothesis classes of weak-*
closed (in fact, even compact) classifiers for which Theorem 3 applies.
(1) Thesimplestsuchclass Histheclassof allA-measurablesoftclassifiers u:X → [0,1]
whichcouldbereferredtoas agnostic classifierssincetheyarenotparametrized. This
class is a bounded subset of L∞(X;ν)and therefore, by the Banach–Alaoglu theorem,
it is weak-* compact.
(2) An example with more practical relevance is the class of (feedforward or residual)
neural networks defined on the unit cube X:= [−1,1]dwith uniformly bounded
parameters
H:=n
ΦL◦ ··· ◦ Φ1: [−1,1]d→[0,1] : Φ l(•) =Al•+σl(Wl•+bl),
∥(Al, Wl, bl)∥ ≤C∀l∈ {1, . . . , L }o
,
where we assume that the activations σl:R→Rare continuous. Note that the
boundedness of the weights cannot be relaxed. To see this, consider the (very sim-
plistic) neural network un(x) = tanh( wnx)forx∈[−1,1]andwn∈R. For wn→ ∞
it is easy to see that unconverges to u(x) := sign( x)which does not lie in the same
hypothesis class.
To argue why neural networks with bounded parameters and continuous activa-
tion functions are weak-* compact, let (un)n∈N⊂ Hbe a sequence. Thanks to
finite-dimensional compactness a subsequence of the associated parameters converge
to some limiting parameters. The continuity of the activations implies that the as-
sociated neural networks converge (uniformly in the space of continuous functions
on the unit cube [−1,1]d) to a limiting neural network u∈ H. In particular, the
convergence is true in the weak-* sense, which shows that His weak-* compact.
(3) Finally, one can also consider the class of hard linear classifiers on Rd. Letting
θ(t) :=1t>0denote the Heaviside function, this class is given by
H:=
θ(w·x+b) :w∈Rd,|w|= 1, b∈[−∞,∞]	
,
where one interprets u(x) :=θ(w·x+b)asu≡1ifb=∞andu≡0ifb=−∞.
If the distributions ρ0,ρ1, and mxare are such that νdefined in (13) has a density
with respect to the Lebesgue measure, then Hhas the desired closedness property. A
sufficient condition for this to hold is that ρ0,ρ1, and mxhave densities with respect
to the Lebesgue measure.
Let us prove the closedness under the above conditions. If (un)n∈N⊂ His a
sequence of linear classifiers, thanks to finite-dimensional compactness a subsequence
(which we do not relabel) of the associated parameters (wn, bn)converges to w∈Rd
with|w|= 1andb∈[−∞,∞]. For simplicity we only consider the case where
b̸=±∞. In this case one can define the half-spaces
An:=
x∈Rd:wn·x+b >0	
,
A:=
x∈Rd:w·x+b >0	
,
15upon which unanduare supported. Then for any ϕ∈L1(Rd;ν)it holds
Z
Rd(un−u)ϕdν=Z
Anϕdν−Z
Aϕdν≤Z
An△A|ϕ|dν
where we used the symmetric difference An△A:= (An\A)∪(A\An). Note that
this set is either a double cone (if wn̸=w) or a strip of width |bn−b|(ifwn=w).
Since ϕ∈L1(Rd;ν)andνis a probability measure, for every ε >0there exists a
compact set K⊂Rdsuch thatR
Rd\K|ϕ|dν < ε. Using this, we can compute
Z
Rd(un−u)ϕdν≤Z
An△A|ϕ|dν≤Z
(An△A)∩K|ϕ|dν+ε.
Using that νhas a density with respect to the Lebesgue measure Ldand using also
thatLd(An△A∩K)→0asn→ ∞, we obtain
lim
n→∞Z
Rd(un−u)ϕdν≤ε
and since ε >0was arbitrary we get
lim
n→∞Z
Rd(un−u)ϕdν= 0,
which implies the weak-* convergence of untou∈ Hand hence the weak-* compact-
ness of H.
Note that for general measures νthe above argument fails. For instance,the se-
quence of linear classifiers un(x) = 1x1>−1/nhas the natural limit u(x) = 1x1>0.
However, if ν=δ0thenR
Rdundν= 1for all n∈NbutR
Rdudν= 0, meaning that u
is not the weak-* limit of un.
Similarly, we can state a precise version of Informal Theorem 4. For this, it is convenient
to introduce the probability measure σdefined via
σ(A) :=Z
Xmx(A) dρ(x), (21)
which clearly satisfies
(22) σ(A) = 0 = ⇒mx(A) = 0forρ-almost every x∈ X.
Theorem 4 (Existence of soft classifiers for original PRL) .Under Assumption 1, for every
lower semicontinuous function Ψ : [0 ,1]→[0,1], and whenever His a hypothesis class of
A-measurable functions u:X → [0,1]that is closed in the weak* topology of L∞(X;σ), there
exists a solution to the problem
inf
u∈HZ
XΨ (Ex′∼mx[u(x′)]) dρ0(x) +Z
XΨ (Ex′∼mx[1−u(x′)]) dρ1(x). (23)
162.4.Existence proofs. In this section we will prove all theorems stated in the previous
section using the direct method of calculus of variations together with new relaxation ar-
guments. For this we first outline our proof strategy in a very abstract way by using the
quadruple
Q:= (R, S, T, T), (24)
where R:A → [0,∞]is a functional defined on A-measurable sets, S, T :U → [0,∞]
are proper functionals defined on the unit ball U:={u:X → [0,1]A-measurable }of the
A-measurable functions, and Tis a topology on the unit ball. The key ingredients and
properties of Qare the following:
(D1)Compactness :Uis compact with respect to T;
(D2)Lower semicontinuity : For all sequences of measurable functions (un)n∈N⊂ Ucon-
verging to u∈ Uin the topology Tit holds
S(u)≤lim inf
n→∞S(un);
(D3)Consistency : It holds for all A∈ Athat
R(A) =S(1A).
(D4)Coarea formula : For all u∈ Uit holds
T(u) =Z1
0R({u≥t}) dt,
and in particular R(A) =T(1A)for all A∈ A;
(D5)Ordering : For all u∈ Uit holds
T(u)≤S(u).
Under these conditions we can prove the following meta-theorem.
Meta Theorem 1. Assuming desiderata (D1) and (D2) there exists
u∈argminu∈US(u). (25)
Assuming desiderata (D1) to (D5), for Lebesgue almost every t∈[0,1]the set At:={u≥t}
satisfies
At∈argminA∈AR(A). (26)
Proof.Since Sis proper, there exists a minimizing sequence {un}n∈N⊂ Ufor (25). By
assumption, {un}n∈Nis precompact in the topology T. Therefore, up to a subsequence that
we do not relabel, we can assume that un→Tufor some u:X → [0,1]which solves (25) by
lower semicontinuity of S.
Defining At:={u≥t}fort∈[0,1]it holds
inf
A∈AR(A) =Z1
0inf
A∈AR(A) dt≤Z1
0R(At) dt=T(u)≤S(u)≤S(1A) =R(A)∀A∈ A,
17and therefore, after taking the infimum over A∈ A, we get
Z1
0R(At) dt= inf
A∈AR(A). (27)
Let us assume that for a subset N⊂[0,1]of positive Lebesgue measure it holds
inf
A∈AR(A)< R(At)∀t∈N.
Integrating this inequality and using (27) we would then have
inf
A∈AR(A)<Z1
0R(At) dt= inf
A∈AR(A),
which is a contradiction. Hence we have proved that for Lebesgue almost every t∈[0,1]the
setAtsolves (26). □
To use this theorem we need to specify Qand verify the desiderata. We consider the
following choices:
R(A) := ProbR Ψ(A), A∈ A,
S(u) :=E(x,y)∼µ[|u(x)−y|] + ProbJ Ψ(u), u∈ U,
T(u) :=E(x,y)∼µ[|u(x)−y|] + ProbTV Ψ(u), u∈ U,
T:=weak-* topology of L∞(X;ν),
where νwas defined in (13). We note that desideratum (D1) follows from the Banach–
Alaoglu theorem. By definition of the functionals ProbJ ΨandProbTV Ψin (10) and (19)
the desiderata (D3) and (D4) are satisfied, as well. It remains to prove the lower semiconti-
nuity desideratum (D2) and the ordering desideratum (D5).
We start with the following lemma:
Lemma 1. Under Assumption 1, let νbe a measure on Xwhich satisfies mx≪νforρ-
almost every x∈ X, and let (un)n∈N⊂L∞(X;ν)satisfy un∗⇀ uin the sense of Definition 1.
Then it holds
lim
n→∞Ex′∼mx[un(x′)] =Ex′∼mx[u(x′)]forρ-almost every x∈ X.
Proof.UsingtheRadon–Nikodýmtheorem, theweak-*convergenceimpliesthatfor ρ-almost
every x∈ Xit holds
lim
n→∞Ex′∼mx[un(x′)] = lim
n→∞Z
Xun(x′) dmx(x′) = lim
n→∞Z
Xun(x′)dmx
dν(x′) dν(x′)
=Z
Xu(x′)dmx
dν(x′) dν(x′) =Z
Xu(x′) dmx(x′) =Ex′∼mx[u(x′)]
sincedmx
dν∈L1(X;ν). □
Using Lemma 1 it is relatively straightforward to prove lower semicontinuity of ProbJ Ψif
Ψis a continuous function. If, however, Ψis only lower semicontinuous, e.g., Ψ(t) =1t>p,
we will employ a suitable approximation from below of Ψby continuous functions.
18Proposition 4 (Lower semicontinuity of ProbJ Ψ).Under Assumption 1 let (un)n∈N⊂
L∞(X;ν)be a sequence of functions with values in [0,1]satisfying un∗⇀ uin the sense
of Definition 1, and let Ψ : [0 ,1]→[0,1]be lower semicontinuous. Then 0≤u≤1holds
ν-almost everywhere and furthermore
ProbJ Ψ(u)≤lim inf
n→∞ProbJ Ψ(un).
Proof.First we show that 0≤u≤1. By the weak-* lower semicontinuity of the L∞-norm
we get u≤1from the fact that 0≤un≤1. To show that u≥0we assume that on a
measurable set Nwith ν(N)>0it holds u <0. Then from the weak-* convergence and the
fact that un≥0we obtain
0>Z
Xu1Ndν= lim
n→∞Z
Xun1Ndν≥0
which is a contradiction. Therefore, u≥0holds ν-almost everywhere.
Since both terms in the definition of ProbJ Ψare dealt with symmetrically, we assume
without loss of generality and for an easier notation that ρ1= 0and rewrite ProbJ Ψas
ProbJ Ψ(u) =Z
X(1−u(x)) Ψ (Ex′∼mx[u(x′)]) dρ0(x).
Since Ψis lower semicontinuous there exists a sequence of continuous functions Ψδ: [0,1]→
[0,1]which converge to Ψin the pointwise sense as δ→0and satisfy Ψδ≤Ψ. For instance,
the functions
Ψδ(t) := inf
s∈[0,1]Ψ(s) +1
δ|s−t|, t ∈[0,1],
suffice. Lemma1impliesthat Ex′∼mx[un(x′)]→Ex′∼mx[u(x′)]forρ-almostevery xasn→ ∞.
Since Ψδis continuous, we get Ψδ(Ex′∼mx[un(x′)])→Ψδ(Ex′∼mx[u(x′)])forρ-almost every
xasn→ ∞. Since 0≤un≤1and hence Ψδ(Ex′∼mx[un(x′)])is uniformly bounded, the
convergence even holds true in L1(X;ρ). Taking into account (15), this implies convergence
inL1(X;ρ0)and therefore
lim
n→∞Z
X(1−un(x)) Ψ δ(Ex′∼mx[un(x′)]) dρ0(x)
=Z
X(1−u(x)) Ψ δ(Ex′∼mx[u(x′)]) dρ0(x).(28)
Next we would like to use the Fatou lemma to take the limit as δ→0on both sides. For
this we notice that the sequence of functions
fδ(x) := (1 −un(x)) Ψ δ(Ex′∼mx[un(x′)])
converges to (1−un(x)) Ψ (Ex′∼mx[un(x′)])pointwise as δ→0and satisfies the bounds
fδ≥0. Thanks to the non-negativity we can apply the standard Fatou lemma. Using
19Ψδ≤Ψand (28) we get
ProbJ Ψ(u) =Z
X(1−u(x)) Ψ (Ex′∼mx[u(x′)]) dρ0(x)
≤lim inf
δ→0Z
X(1−u(x)) Ψ δ(Ex′∼mx[u(x′)]) dρ0(x)
= lim inf
δ→0lim
n→∞Z
X(1−un(x)) Ψ δ(Ex′∼mx[un(x′)]) dρ0(x)
≤lim inf
n→∞Z
X(1−un(x)) Ψ (Ex′∼mx[un(x′)]) dρ0(x)
= lim inf
n→∞ProbJ Ψ(un).
□
We recall the definition of the total variation in (19) for which we now prove the following
ordering with respect to ProbJ Ψdefined in (10) in case that Ψis concave and non-decreasing.
Proposition 5. IfΨis concave and non-decreasing it holds for every A-measurable function
u:X → [0,1]that
ProbTV Ψ(u)≤ProbJ Ψ(u).
Proof.As in the proof of Proposition 4 we assume without loss of generality that ρ1= 0.
We compute
ProbTV Ψ(u) =Z1
0ProbPer Ψ({u≥t}) dt
=Z
XZ1
01u(x)<tΨ (Px′∼mx[u(x′)≥t]) dtdρ0(x)
=Z
XZ1
01u(x)<tΨ 
Ex′∼mx
1{u≥t}(x′)
dtdρ0(x)
=Z
XZ1
u(x)Ψ 
Ex′∼mx
1{u≥t}(x′)
dtdρ0(x). (29)
Since Ψis concave and non-decreasing, we get from (29) and Jensen’s inequality that
ProbTV Ψ(u)≤Z
X(1−u(x)) Ψ1
1−u(x)Z1
u(x)Ex′∼mx
1{u≥t}(x′)
dt
dρ0(x)
=Z
X(1−u(x)) Ψ1
1−u(x)Ex′∼mxZ1
u(x)1{u≥t}(x′) dt
dρ0(x)
=Z
X(1−u(x)) Ψ1
1−u(x)Ex′∼mxh 
u(x′)−u(x)
+i
dρ0(x)
≤Z
X(1−u(x)) Ψ1
1−u(x)Ex′∼mx[u(x′)(1−u(x))]
dρ0(x)
=Z
X(1−u(x)) Ψ (Ex′∼mx[u(x′)]) dρ0(x) = ProbJ Ψ(u).
20□
A remarkable consequence of this lower bound and the lower semicontinuity of ProbJ Ψ
from Proposition 4 is the following proof of lower semicontinuity of ProbTV Ψfor sequences
of characteristic functions that doesn’t use any abstract functional analysis machinery).
Corollary 1. Let(An)⊂ Abe a sequence of measurable sets such that 1An∗⇀ uinL∞(X;ν).
Then it holds
ProbTV Ψ(u)≤lim inf
n→∞ProbTV Ψ(1An).
Proof.The result follows from Propositions 4 and 5 and the following computation
ProbTV Ψ(u)≤ProbJ Ψ(u)≤lim inf
n→∞ProbJ Ψ(1An) = lim inf
n→∞ProbPer Ψ(An)
= lim inf
n→∞ProbTV Ψ(1An).
□
Now we are ready to prove Theorems 1 and 3 as special cases of the meta-theorem in the
beginning of this section.
Proof of Theorem 1 . TheresultfollowsfromMetaTheorem1noticingthatdesideratum(D5)
follows from Proposition 5 and desideratum (D2) follows from Proposition 4 together with
thetriviallowersemicontinuityofthestandardrisk u7→E(x,y)∼µ[|u(x)−y|]since ρ≪ν.□
We remark that the main issue with proving the existence result of Theorem 1 for non-
concave functions Ψis that the ordering desideratum (D5) is violated which was essential
for the proof of Meta Theorem 1.
However, if we already consider the relaxed problem (20) of optimizing over soft classifiers
instead of characteristic functions and regularizing with ProbJ Ψ, no ordering is necessary
and we obtain existence for very general functions Ψ.
Proof of Theorem 3. The result is the first part of Meta Theorem 1 for the choices made in
the proof of Theorem 1. □
Remark 4. From the proof of Meta Theorem 1 it follows that when Ψis concave and
non-decreasing, then
min
A∈AProbR Ψ(A) = min
u∈UProbS Ψ(u),
where
(30) ProbS Ψ(u) :=E(x,y)∼µ[|u(x)−y|] + ProbJ Ψ(u).
Next we discuss the existsence results for the original PRL model.
Proof of Theorem 2. We apply Meta Theorem 1 with the choices R= R ΨandS=SΨ,
where SΨis defined over soft classifiers u:X → [0,1]according to:
SΨ(u) :=Z
XΨ (Ex′∼mx[u(x′)]) dρ0(x) +Z
XΨ (Ex′∼mx[1−u(x′)]) dρ1(x), (31)
21which by definition satisfies SΨ(1A) = R Ψ(A). We also consider the functional
T(u) :=Z1
0R({u≥t}) dt.
As topology Twe choose the weak-* topology of L∞(X;σ)where the probability measure
σis as in (21).
It is straightforward to check that the quadruple Q:= (R, S, T, T)satisfies all five require-
ments for Meta Theorem 1 to be applicable: (1) is clear, (2) is proved as Proposition 4 using
Lemma 1 with σinstead of ν, (3) and (4) are trivial consequences of the definitions, and (5)
is an easy consequence of the layer cake representation and Jensen’s inequality for concave
Ψ. Note that (5) is only true if Ψis concave. □
Proof of Theorem 4. The result is the first part of Meta Theorem 1 for the choices made in
the proof of Theorem 2. □
Remark 5. As in Remark 5, it is easy to verify that when Ψis concave and non-decreasing,
then
min
A∈ARΨ(A) = min
u∈USΨ(u).
3.The functional ProbPer Ψas a perimeter
In this section we shall discuss the interpretation of the functional ProbPer Ψdefined in
(9) as aperimeter . We do this in two ways.
First, wefocusonthecasewhere Ψisconcaveandnon-decreasingandprovethat ProbPer Ψ
is asubmodular functional . If, in addition, Ψis assumed to satisfy Ψ(0) = 0 , then
ProbPer Ψ(X) = ProbPer Ψ(∅) = 0 .
Following [11], for Ψsatisfying these properties one can interpret ProbPer Ψas a generalized
perimeter, i.e., a functional that can be used to measure the “size” of the boundary of a set.
This discussion is summarized in the next proposition.
Proposition 6. IfΨ(0) = 0 , then ProbPer Ψ(X) = ProbPer Ψ(∅) = 0. IfΨis concave and
non-decreasing, then the functional ProbPer Ψis submodular, meaning that
ProbPer Ψ(A∪B) + ProbPer Ψ(A∩B)≤ProbPer Ψ(A) + ProbPer Ψ(B)∀A, B∈ A.
Example 3. ForΨ(t) =tour perimeter reduces to the perimeter on the random walk space
(X,m), introduced in [24]: ProbPer Ψ(A) =R
X\AR
Admxdρ0(x) +R
AR
X\Admxdρ1(x).
For proving Proposition 6 we need the following lemma.
Lemma 2. LetΨ : [0 ,∞)→Rbe a concave and non-decreasing function, and let 0≤a≤
b≤b′≤a′be real numbers with a+a′≤b+b′. Then
Ψ(a) + Ψ( a′)≤Ψ(b) + Ψ( b′).
Proof.Leta, a′, b, b′be as stated. Since Ψis concave and finite, it satisfies the fundamental
theorem of calculus and thus it is possible to write
Ψ(s) = Ψ( a) +Zs
aΨ′(r) dr, s≥a
22for a function Ψ′that is non-increasing and non-negative. It follows that
Ψ(b)−Ψ(a) =Zb
aΨ′(r) dr≥(b−a)Ψ′(b)≥(a′−b′)Ψ′(b)≥Za′
b′Ψ′(r) dr= Ψ( a′)−Ψ(b′),
which is precisely what we wanted to show. □
With the above preliminary results in hand, we are ready to prove Proposition 6.
Proof of Proposition 6. First, the fact that ProbPer Ψ(X) = ProbPer Ψ(∅) = 0ifΨ(0) = 0 is
easy to see from the definition of ProbPer Ψ. Second, we trivially have
Px′∼mx[x′∈A∪B] +Px′∼mx[x′∈A∩B]≤Px′∼mx[x′∈A] +Px′∼mx[x′∈B].
Define
a′:=Px′∼mx[x′∈A∪B], b′:=Px′∼mx[x′∈B]
b:=Px′∼mx[x′∈A], a :=Px′∼mx[x′∈A∩B] ;
without the loss of generality we can assume that bandb′defined above satisfy b≤b′, for
otherwise we can simply swap these labels. We can then use Lemma 2 to conclude that:
Ψ (Px′∼mx[x′∈A∪B]) + Ψ ( Px′∼mx[x′∈A∩B])
≤Ψ (Px′∼mx[x′∈A]) + Ψ ( Px′∼mx[x′∈B]).(32)
The submodularity follows directly once we have verified the following pointwise identity:
1x∈(A∪B)cΨ (Px′∼mx[x′∈A∪B]) +1x∈(A∩B)cΨ (Px′∼mx[x′∈A∩B])
≤1x∈AcΨ (Px′∼mx[x′∈A]) +1x∈BcΨ (Px′∼mx[x′∈B]).(33)
To do this we consider two complementary cases:
Case 1, x∈(A∪B)c:This is equivalent to x∈Ac∩Bc. Furthermore, since (A∪B)c⊂
(A∩B)cwe also have that x∈(A∩B)c. Hence, all indicator functions in (33) take the
value one and (33) is the same as (32), which we have already verified.
Case 2, x∈A∪B:In this case the first indicator function on the left hand side of (33)
is zero.
Case 2.1, x∈A∩B:In this subcase all indicator functions are equal to zero and the
inequality is trivially satisfied.
Case 2.2, x∈A∪B\(A∩B):Without loss of generality we can assume that x∈A\B=
A∩Bc. In this case only the second indicator function on the left hand side and the second
one on the right hand side of (33) take the value one and the inequality reduces to the trivial
inequality
Ψ (Px′∼mx[x′∈A∩B])≤Ψ (Px′∼mx[x′∈B])
which is true since Ψis non-decreasing and A∩B⊂B. □
Remark6. Fromthesubmodularityof ProbPer Ψonecanshowthatthefunctional ProbTV Ψ
defined in (19) is convex. Indeed, this can be proved following the proof of Proposition 3.4
in [10], where, actually, we do not need to assume the lower semicontinuity of the functional
a priori.
23Next, we consider rather general Ψand show that ProbPer Ψis related to a standard local
perimeter when X=Rdand the probability measure mxlocalizes to a Dirac delta δx; for the
case of adversarial training such a connection was proved in [8], where the authors utilized
the notion of Γ-convergence of functionals. We take a first step in this direction by proving
that for sufficiently smooth sets the probabilistic perimeter converges to a local one if the
family of probability distributions mxlocalizes suitably. For example, one could think of
mx:= Unif( Bε(x)), which converges to a point mass at xifε→0. To make our setting
precise, we pose the following general assumption:
Assumption 2. We assume that X=Rd,Ψ(0) = 0 ,Ψis Borel measurable and bounded,
andρ1, ρ0have continuous densities with respect to the Lebesgue measure which we shall
also denote as ρ1, ρ0. Furthermore, we assume that there is ε >0and a measurable function
K:X ×Rd→[0,∞)such that for every x∈Rdwe have the representation
dmx(x′) =ε−dK
x,x′−x
ε
dx′.
We also assume that for every x∈ Xwe have K(x,•)∈L1(Rd),R
RdK(x, z) dz= 1,
K(x, z) = 0if|z|>1, and that for every z∈Rdthe mapping x7→K(x, z)is continuous.
In the more difficult case when Ψis not necessarily continuous, we shall need some addi-
tional assumptions on the kernel.
Assumption 3. For our extra assumptions on the kernel, we shall require that for every
z∈Rdthe mapping x7→K(x, z)isC1and for every x∈Rdthe mapping z7→K(x, z)is
lower semicontinuous. Furthermore, for all x∈Rd,t∈(−1,1), and n∈Sd−1, the Radon
transform of Kwith respect to the z-variable
R(K(x,·))(n, t) :=Z
{z·n=t}K(x, z) dHd−1(z)
is strictly positive.
The following theorem derives the asymptotics of the probabilistic perimeter as ε→0and
is the rigorous counterpart of Informal Theorem 6.
Theorem 5. LetX=Rd. Under Assumption 2, if Ahas a compact C1,1boundary and
either Ψis continuous or Ksatisfies the additional Assumption 3, then
lim
ε→01
εProbPer Ψ(A) =Z
∂Aσ0,Ψ[x, n(x)]ρ0(x) +σ1,Ψ[x, n(x)]ρ1(x) dHd−1(x), (34)
where we let n(x)denote the normal to ∂Aat a point x∈∂A, and for any vector v∈Rdwe
define
σ0
Ψ[x, v] :=Z1
0ΨZ
{z·v≤−t}K(x, z) dz
dt, σ1
Ψ[x, v] :=Z1
0ΨZ
{z·v≥t}K(x, z) dz
dt.
Remark7. IfKisradiallysymmetricandindependentof x∈ X, then σ0
Ψ=σ1
Ψ=:σΨisjust
a constant. E.g., for K(x, z) :=|B1(0)|−11|z|≤1andΨ(t) =1t>pit is trivial that for p= 0we
have σΨ= 1. However, for p≥1
2one easily sees σΨ= 0, hence the limiting perimeter equals
zero and there is no regularization effect. Using the function Ψ(t) = min {t/p,1}corrects
this degeneracy.
24Notably, for radially symmetric Kthe limiting perimeter in (34) coincides, provided
σΨ>0, with the one derived for adversarial training (problem (2)) in [8], although they
considered more general (potentially discontinuous) densities ρi. In particular, our result
indicates that for very small adversarial budgets the regularization effect of both proba-
bilistically robust learning and adversarial training is dominated by the perimeter in (34).
While Theorem 5 already completes half of the proof (namely the limsup inequality) of
Γ-convergence of1
εProbPer Ψto the limiting perimeter, the remaining liminf inequality is
beyond the scope of this paper. Proving that the convergence (34) does not only hold for
sufficiently smooth sets as assumed in Theorem 5 but even in the sense of Γ-convergence is
an extremely important topic for future work since only Γ-convergence allows to deduce from
the convergence of the perimeters that also the solutions of probabilistically robust learning
converge to certain regular Bayes classifiers as ε→0, see [8, Section 4.2]. The exploration
of this is left for future work.
Proof of Theorem 5. UnderAssumption 2, a simple change of variables shows
ProbPer Ψ(A) =Z
AcΨZ
Rd1A(x+εz)K(x, z) dz
ρ0(x) dx
+Z
AΨZ
Rd1Ac(x+εz)K(x, z) dz
ρ1(x) dx.
Letτ:Rd→Rbe the signed distance function to ∂Asuch that τ(x)≤0forx∈A. Using
τ, we can rewrite the previous line as
ProbPer Ψ(A) =Z
{τ(x)≥0}ΨZ
{τ(x+εz)≤0}K(x, z) dz
ρ0(x) dx
+Z
{τ(x)≤0}ΨZ
{τ(x+εz)≥0}K(x, z) dz
ρ1(x) dx.
Recalling that K(x, z) = 0whenever |z|>1, it follows that
ProbPer Ψ(A) =Z
{0≤τ(x)≤ε}ΨZ
{τ(x+εz)≤0}K(x, z) dz
ρ0(x) dx
+Z
{−ε≤τ(x)≤0}ΨZ
{τ(x+εz)≥0}K(x, z) dz
ρ1(x) dx.
In the rest of what follows, we will focus on proving that
lim
ε→01
εZ
{0≤τ(x)≤ε}ΨZ
{τ(x+εz)≤0}K(x, z) dz
ρ0(x) dx=Z
∂Aσ0,Ψ[x, n(x)]ρ0(x) dHd−1(x),
the argument for showing that
lim
ε→01
εZ
{−ε≤τ(x)≤0}ΨZ
{τ(x+εz)≥0}K(x, z) dz
ρ1(x) dx=Z
∂Aσ1,Ψ[x, n(x)]ρ1(x) dHd−1(x)
will be identical.
Since ∂AisC1,1, there exists some ε0>0and such that for all ε < ε 0the map Tε(y, t) :
∂A×[−1,1]→ {x∈Rd: 0≤τ(x)≤ε}given by Tε(y, t) =y+tn(y)is a bijection and
25ε−1det(DTε)converges uniformly to 1 as ε→0. Using this change of variables, we may
write
1
εZ
{0≤τ(x)≤ε}ΨZ
{τ(x+εz)≤0}K(x, z) dz
ρ0(x) dx
=Z
∂AZ1
01
εdet(DTε(y, t))Ψ (aε(y, t))ρ0(y+εtn(y)) dtdHd−1(y)
where we abbreviate
aε(y, t) :=Z
{τ(y+ε(tn(y)+z))≤0}K(y+εtn(y), z) dz
Since we know that limε→0det(DTε(y,t))
ε= 1andlimε→0ρ0(y+εtn(y)) = ρ0(y)pointwise
almost everywhere, the main difficulty lies in passing to the limit in the term involving Ψ.
For this we shall first prove convergence of aε(y, t)to
a(y, t) :=Z
{z·n(y)≤−t}K(y, z) dz
Since∇τ(y) =n(y)for any y∈∂A, we have the expansion
τ(y+ε(tn(y) +z)) =ε(t+z·n(y)) +O(ε2).
It now follows from our assumptions on Kthat for all y∈∂Aand all t∈[0,1]
lim
ε→0aε(y, t) =a(y, t).
IfΨiscontinuous, theresultnowfollowsfromdominatedconvergence. If Ψisnotcontinuous,
then we must work harder.
Since Ψ∈L1([0,1])∩L∞([0,1]), we can always find a sequence of smooth functions Ψn
such that ∥Ψn∥L∞([0,1])≤ ∥Ψ∥L∞([0,1])andΨnconverges pointwise almost everywhere to Ψ
on[0,1]. If we can show that
lim
n→∞lim sup
ε→0Z
∂AZ1
0 
Ψ(aε(y, t))−Ψn(aε(y, t))
dtdHd−1(y)= 0,
and
lim
n→∞Z
∂AZ1
0 
Ψ(a(t, y))−Ψn(a(t, y))
dtdHd−1(y)= 0,
then we can safely approximate ΨbyΨnand use the previous argument where Ψwas
continuous to conclude the result. Hence, it remains to show that the above integrals vanish.
Viewing aεas maps from ∂A×[0,1]→[0,1]we can construct measures µε, µon[0,1]via
pushforwards by setting
Z1
0g(s) dµε(s) :=Z1
0Z
∂Ag(aε(y, t)) dtdHd−1(y)
Z1
0g(s) dµ(s) :=Z1
0Z
∂Ag(a(y, t)) dtdHd−1(y)
26for any bounded continuous function g:∂A×[0,1]→R. Using these definitions, we can
writeZ
∂AZ1
0 
Ψ(aε(t, y))−Ψn(aε(t, y))
dtdHd−1(y)=Z
∂AZ1
0 
Ψ(s)−Ψn(s)
dµε(s),
andZ
∂AZ1
0 
Ψ(a(t, y))−Ψn(aε(t, y))
dtdHd−1(y)=Z
∂AZ1
0 
Ψ(s)−Ψn(s)
dµ(s).
If we can show that the µεare uniformly integrable on ∂A×[0,1](with respect to the product
measure dtdHd−1(y)) then the pointwise almost everywhere convergence of ΨntoΨalong
with the control ∥Ψn∥L∞([0,1]≤ ∥Ψ∥L∞([0,1]will imply that
lim
n→∞lim sup
ε→0Z
∂AZ1
0 
Ψ(t′)−Ψn(t′)
dµε(y, t′)= 0,
and for free it will give us
lim
n→∞Z
∂AZ1
0 
Ψ(t′)−Ψn(t′)
dµ(y, t′)= 0,
since µis the distributional limit of the µε(from the pointwise convergence of aεtoa).
To prove that the µεare uniformly integrable, we will show that |∂taε|is strictly bounded
away from 0 whenever tis bounded away from 1. To do this, we shall need the additional
Assumption 3 on our kernel K. Let us first assume that KisC1in both variables. Changing
variables z′=z+tn(y)we can write
aε(y, t) =Z
{τ(y+εz′)≤0}K(y+εtn(y), z′−tn(y)) dz′,
and hence
∂taε(y, t) =Z
{τ(y+εz′)≤0}ε∇yK(y+εtn(y), z′−tn(y))·n(y) dz′
−Z
{τ(y+εz′)≤0}∇z′K(y+εtn(y), z′−tn(y))·n(y) dz′.
Since the second term is the complete derivative with respect to z′, we can integrate by parts
to obtain
∂taε(y, t) =Z
{τ(y+εz′)≤0}ε∇yK 
y+εtn(y), z′−tn(y)
·n(y) dz′
−Z
{τ(y+εz′)=0}K 
y+εtn(y), z′−tn(y)
n(y)· ∇τ(y+εz′) dHd−1(z′)
Using the expansion ∇τ(y+εz) =n(y) +O(ε)and the smoothness properties of K, we see
that
∂taε(y, t) =−Z
{τ(y+εz′)=0}K(y, z′−tn(y)) dHd−1(z′) +O(ε)
27where we note that the constant in the big O bound does not depend on the differentiability
ofKwith respect to the zvariable. Hence, after approximating Kwith C1kernels, we can
assume the above control holds for any kernel Ksatisfying both Assumptions 2 and 3.
Thus, for each fixed y∈∂A, t∈[0,1]we have
lim inf
ε→0|∂taε(t, y)| ≥Z
{z′·n(y)=0}K(y, z′−tn(y)) dHd−1(z′) =Z
{z·n(y)=−t}K(y, z) dHd−1(z),
where we have used the lower semicontinuity of Kwith respect to z. We can also now
recognize that the right hand side is the Radon transform R(K(y,·))(−t, n(y)). From our
additional Assumption 3, we know that R(K(y,·))(t, n(y))>0for each fixed y∈∂A,
t∈(−1,1)andn∈Sd−1. Fix some δ > 0. Since the set ∂A×[0,1−δ]×Sd−1is
compact, it follows that there exists some cδ>0such that R(K(y,·))(−t, n(y))≥cδfor all
y∈∂A, n (y)∈Sd−1, t∈[0,1−δ]. Therefore,
lim inf
ε→0|∂taε(t, y)| ≥cδ
for all y∈∂Aandt∈[0,1−δ]. Thus, for all ε >0sufficiently small we have
|∂taε(t, y)| ≥cδ/2
for all y∈∂Aandt∈[0,1−δ].
Now we are ready to show that µεis uniformly integrable. Let L[a,b]denote the Lebesgue
measure on the interval [a, b]. From our work above, for all ε >0sufficiently small, we have
the inequality
µε=aε# 
Hd−1
∂A⊗ L [0,1]
≤2Hd−1(∂A)
cδL[0,1]+aε# 
Hd−1
∂A⊗ L [1−δ,1]
.
Thus, for any measurable E⊂[0,1], we have
µε(E)≤2|E|Hd−1(∂A)
cδ+Z
a−1
ε(E)∩(∂A×[1−δ,1])dtdHd−1(y)
≤2|E|Hd−1(∂A)
cδ+δHd−1(∂A).
Hence, for all δ >0,
lim
|E|→0lim sup
ε→0µε(E)≤δHd−1(∂A).
Thus, the µεare uniformly integrable so we are done.
□
4.Interpolation properties of probabilistically robust learning
In this section we discuss the limiting behavior of the energies ProbR ΨpandRΨp, for
Ψp(t) := min {t/p,1}, asp→0oras pgrows. Thislimitingbehaviorisstudiedinthesenseof
Γ-convergence, which, in particular, is closely connected to the convergence of minimizers of
the sequence of functionals. We start by recalling the definition of this notion of convergence
for functionals defined over arbitrary metric spaces.
Definition 2. Given a topological space (U, τ)and a sequence of functionals Fn:U →
[0,∞], and another functional F:U → [0,∞], we say that the sequence of functionals Fn
Γ-converges toward F(with respect to the topology τ) if the following two conditions hold:
28(1)Liminf inequality: For any u∈ Uand any sequence {un}n∈Nconverging (in the τ
topology) toward uwe have:
lim inf
n→∞Fn(un)≥F(u).
(2)Limsup inequality: For every u∈ Uthere exists a sequence {un}n∈Nconverging
(in the τtopology) toward usuch that:
lim sup
n→∞Fn(un)≤F(u).
The relevance of the notion of Γ-convergence becomes apparent when an additional com-
pactness property holds.
Proposition 7 (Fundamental Theorem of Γ-convergence; see [4] and [14]) .Let(U, τ)be a
topological space. Let Fn:U → [0,∞]be a sequence of functionals Γ-converging toward a
functional F:U → [0,∞]that is not identically equal to +∞. Suppose, in addition, that the
sequence of functionals {Fn}n∈Nsatisfies the following compactness property: any sequence
{un}n∈Nsatisfying
sup
n∈NFn(un)<∞
is precompact in the topology τ, i.e., every subsequence of {un}n∈Nhas a further subsequence
that converges to an element of U.
Then
lim
n→∞inf
u∈UFn(u) = inf
u∈UF(u).
Moreover, if unfor every n∈Nis a minimizer of Fn, then any cluster point of {un}n∈Nis
a minimizer of F.
For our analysis in this section it will be useful to define Ψ0(t) :=1t>0fort≥0, which is
a concave and non-decreasing function in its domain. The probabilistic perimeter associated
to this function is
ProbPer Ψ0(A) =Z
Ac1Px′∼mx[x′∈A]>0dρ0(x) +Z
A1Px′∼mx[x′∈Ac]>0dρ1(x)
=Z
Acmx-ess sup 1Adρ0(x) +Z
Amx-ess sup 1Acdρ1(x),
and the corresponding probabilistic risk (8) can be written as
ProbR Ψ0(A) =Z
X(1Ac(x)·mx-ess sup 1A+1A(x)) dρ0(x)
+Z
X(1A(x)·mx-ess sup 1Ac+1Ac(x)) dρ1(x).
Likewise, the risk RΨ0takes the form
RΨ0(A) =Z
Xmx-ess sup 1Adρ0(x) +Z
Xmx-ess sup 1c
Adρ1(x).
We start by proving Γ-convergence of ProbR Ψptoward ProbR Ψ0asp→0in the weak-*
topology of L∞(X;ν).
29Proposition 8 (Γ-convergence of modified PRL) .For the functions Ψp(t) := min {t/p,1}
it holds that ProbPer ΨpΓ-converges to ProbPer Ψ0andProbR ΨpΓ-converges to ProbR Ψ0as
p→0in the weak-* topology of L∞(X;ν), where νis as in(13).
Proof.Without loss of generality we assume ρ1= 0for a more concise notation.
We start with the liminf inequality. Let {Ap}p∈(0,1)be a sequence of sets such that 1Ap
converges to 1Aasp→0in the weak-* sense. Then Lemma 1 implies that
lim
p→0Px′∼mx[x′∈Ap] = lim
p→0Ex′∼mx
1Ap(x′)
=Ex′∼mx[1A(x′)] =Px′∼mx[x′∈A].
Next, we note that for 0< p < lit holds Ψp≥Ψl. Hence we get
ProbPer Ψp(Ap)≥Z
AcpΨl(Px′∼mx[x′∈Ap]) dρ0(x)
=Z
X(1−1Ap)Ψl(Px′∼mx[x′∈Ap]) dρ0(x).
As argued in the proof of Proposition 4, the functions x7→Ψl(Px′∼mx[x′∈Ap])converge
tox7→Ψl(Px′∼mx[x′∈A])inL1(X;ρ0)asp→0. Using this together with 1Ap∗⇀1Ain
L∞(X;ν)and taking into account (14) and (15) we get
lim inf
p→0ProbPer Ψp(Ap)≥Z
AcΨl(Px′∼mx[x′∈A]) dρ0(x).
Since l >0was arbitrary we can let l→0and use Fatou’s lemma to obtain
lim inf
p→0ProbPer Ψp(Ap)≥Z
AcΨ0(Px′∼mx[x′∈A]) dρ0(x) = ProbPer Ψ0(A).
For the limsup inequality we observe that, since Ψp≤Ψ0for all p∈(0,1), it holds
ProbPer Ψp(A)≤ProbPer Ψ0(A)andthereforethelimsupinequality lim supp→0ProbPer Ψp(A)≤
ProbPer Ψ0(A)is true for the constant sequence equal to A.
Being continuous perturbations of the probabilistic perimeters with respect to the weak-*
topology of L∞(X;ν), the probabilistic risks ProbR Ψpare easily seen to Γ-converge to
ProbR Ψ0asp→0; see the background section in [5]. □
Remark 8. With essentially the same proof as in Proposition 8, one can show that ProbS Ψp
Γ-converges in the weak-* topology of L∞(X;ν)toward the functional ProbS Ψ0asp→0. We
recall that ProbS Ψwas introduced in (30) and corresponds to the l.s.c extension of ProbR Ψ
to soft classifiers.
Next, we discuss the Γ-convergence of RΨptoward RΨ0. This limiting energy may in
general be different from ProbR Ψ0.
Proposition 9 (Γ-convergence of original PRL) .For the functions Ψp(t) := min {t/p,1}it
holds that RΨpΓ-converges to RΨ0asp→0in the weak-* topology of L∞(X;σ), where σis
as in(21).
Furthermore, the Γ-convergence also holds with respect to the weak* topology of L∞(X;ν),
where νis as in(13).
30Proof.For simplicity, we again assume ρ1= 0. The proof starts verbatim as the proof of
Proposition 8, using Lemma 1 with σinstead of ν. Then one gets for 0< p < lthat
lim inf
p→0RΨp(Ap)≥Z
XΨl(Px′∼mx[x′∈A]) dρ0(x).
Taking also the limit l→0one obtains
lim inf
p→0RΨp(Ap)≥Z
XΨ0(Px′∼mx[x′∈A]) dρ0(x).
The limsup inequality is again trivial, using that Ψp≤Ψ0for all p >0.
Wepointoutthat,sinceconstantsequencesworkforthelimsupinequality,the Γ-convergence
also holds with respect to any stronger topology as well. In particular, the Γ-convergence
holds under the weak-* topology of L∞(X;ν).
□
Remark 9. With essentially the same proof as in Proposition 9, one can prove that SΨp
Γ-converges in the weak-* topology of L∞(X;σ)(or of L∞(X;ν)) toward the functional SΨ0
asp→0. We recall that SΨwas introduced in (31) and corresponds to the l.s.c. extension
ofRΨto soft classifiers.
The next example shows that the functionals ProbR Ψ0andRΨ0, the Γ-limits of modified
PRL and original PRL, respectively, may in general be different from each other.
Example 4. Consider the data distribution µ=1
2δ(x0,0)+1
2δ(x1,1)where x0= (a,0), x1=
(b,0)∈R2with a < b. Let furthermore mx:= Unif( Bε(x))where 0< ε <|b−a|
2. Let
A:={x= (x1, x2)∈R2:x1> a+b−a
2} ∪ {x0}. Then it follows that
ProbR Ψ0(A) = 1 /2>0 = R Ψ0(A).
While the energies ProbR Ψ0,RΨ0, and Radvmay in general be different, they are always
ordered, with Radvbeing the largest. This is the content of the next proposition.
Proposition 10. Suppose that for every x∈ Xthe following identity holds mx(X \Bε(x)) =
0. Then for every measurable Athe following holds:
(35) RΨ0(A)≤ProbR Ψ0(A)≤Radv(A).
Proof.It is straightforward to show that the following pointwise identity holds for any mea-
surable set A:
sup
˜x∈Bε(x)1A(˜x)≥1Ac(x)·mx-ess sup 1A+1A(x)≥mx-ess sup 1A.
Applying this identity to Acwe get:
sup
˜x∈Bε(x)1Ac(˜x)≥1A(x)·mx-ess sup 1Ac+1Ac(x)≥mx-ess sup 1Ac.
Integrating the first chain of inequalities with respect to ρ0, the second with respect to ρ1,
and adding up the resulting expressions, we obtain (35).
□
31Next, we specialize to the case where the admissible set of hard classifiers is A=B(X),
i.e., the set of all Borel measurable subsets of X(in the machine learning literature this is
an agnostic learning setting) and then show that, while ProbR Ψ0andRΨ0may be different,
their minimal values coincide with that of the adversarial training value functional Radvif we
impose some reasonable assumptions on the family of measures {mx}x∈X. Our result implies
that, under Assumption 4 below, both PRL and modified PRL models are consistent with
AT, provided consistency is interpreted as consistency in minimal risks.
Assumption 4. For every x∈supp( ρ)(where supp( ρ)denotes the support of the Borel
probability measure ρ) the following conditions hold:
(1)mx(X \Bε(x)) = 0.
(2)Bε(x)⊆supp( mx).
(3) For every x′∈supp( ρ)the measure mx′⌊Bε(x)is absolutely continuous with respect
tomx.
Remark 10. Assumption 4 is very mild and in the Euclidean setting, when X=Rd, is
satisfied by the simple model mx= Unif( Bε(x)).
Theorem 6 (Consistency of optimal energies for PRL and modified PRL) .LetA=B(X)
be the Borel σ-algebra over X. Under Assumption 4,
lim
p→0min
A∈ARΨp(A) = min
A∈ARΨ0(A) = min
A∈ARadv(A),
as well as
lim
p→0min
A∈AProbR Ψp(A) = min
A∈AProbR Ψ0(A) = min
A∈ARadv(A),
where we recall Ψp(t) = min {t/p,1}andΨ0(t) =1t>0.
Proof.Thanks to Remarks 8 and 9 and the Banach–Alaoglu theorem, we can apply the
fundamental theorem of Γ-convergence (i.e., Proposition 7) to conclude that
lim
p→0min
u∈USΨp(u) = min
u∈USΨ0(u)
and
lim
p→0min
u∈UProbS Ψp(u) = min
u∈UProbS Ψ0(u).
In addition, since Ψpis concave and non-decreasing for every p≥0, we have, thanks to
Remarks 4 and 5,
min
A∈ARΨp= min
u∈USΨp(u)
as well as
min
A∈AProbR Ψp= min
u∈UProbS Ψp(u).
Therefore
lim
p→0min
A∈ARΨp(A) = min
A∈ARΨ0(A)
and
lim
p→0min
A∈AProbR Ψp(A) = min
A∈AProbR Ψ0(A).
On the other hand, thanks to Proposition 10, we have
min
A∈ARadv(A)≥min
A∈AProbR Ψ0(A)≥min
A∈ARΨ0(A).
32Thus it suffices to prove that
min
A∈ARΨ0(A)≥min
A∈ARadv(A).
To see this, let Abe an arbitrary measurable subset of X. We can then proceed as in the
proof of [6, Lemma 3.8] and use the fact that
{x∈ Xs.t.dist(x,supp( ρ))< ε} ⊆supp( σ),
which follows from (2) in Assumption 4, to conclude that we can find a measurable set A′
which is σ-equivalent to A(i.e., σ(A△A′) = 0) and satisfies:
σ-ess sup
˜x∈Bε(x)1A(˜x) = sup
˜x∈Bε(x)1A′(˜x), σ-ess sup
˜x∈Bε(x)1Ac(˜x) = sup
˜x∈Bε(x)1A′c(˜x)
forρ-a.e. x∈ X. Thanks to (22), we deduce that
mx(A△A′) = 0 , ρ-a.e. x∈ X.
It follows that for ρalmost every x∈ Xwe have
σ-ess sup
˜x∈Bε(x)1A(˜x) = sup
˜x∈Bε(x)1A′(˜x)≥mx-ess sup 1A′(˜x) =mx-ess sup 1A(˜x).
as well as
σ-ess sup
˜x∈Bε(x)1Ac(˜x)≥mx-ess sup 1Ac(˜x).
Since σis absolutely continuous with respect to mxforρa.e.x∈ X(thanks to Assump-
tion 4), we deduce that
mx-ess sup 1Ac(˜x)≥σ-ess sup
˜x∈Bε(x)1Ac(˜x),mx-ess sup 1A(˜x)≥σ-ess sup
˜x∈Bε(x)1A(˜x)
forρ-a.e. x∈ X. Combining the above, we deduce that for ρ-a.e. x∈ X
mx-ess sup 1Ac(˜x) = sup
˜x∈Bε(x)1A′c(˜x),mx-ess sup 1A(˜x) = sup
˜x∈Bε(x)1A′(˜x).
From this fact, we deduce that
RΨ0(A) =Z
Xmx-ess sup
˜x∈Bε(x)1Adρ0(x) +Z
Xmx-ess sup
˜x∈Bε(x)1Acdρ1(x)
=Z
Xsup
˜x∈Bε(x)1A′(˜x) dρ0(x) +Z
Xsup
˜x∈Bε(x)1A′c(˜x) dρ1(x)
= R adv(A′)
≥min
˜A∈ARadv(˜A).
Taking the infimum over Aon the left hand side we obtain the desired result.
□
While the above result states that both PRL and modified PRL models recover the AT
model from the perspective of consistency of their optimal energies (at least in the agnos-
tic setting, where we can prove existence of minimizers to AT; see [6]), the next example
illustrates that minimizers of the PRL energies may not converge to AT minimizers as the
parameter pgoes to zero. Studying the behavior of minimizers is important, since, after all,
33PRL models and AT are used to produce robust classifiers by minimizing energy functionals.
We start with an example.
Example 5. LetX=Rand for every x∈Rletmxbe the uniform measure over Bε(x), the
open Euclidean ball of radius εand center x. Consider the probability distribution µover
X × { 0,1}given by
µ=2
5δ(x1,0)+1
5δ(x2,0)+2
5δ(x3,1),
where x1< x2< x3,|x1−x2|< ε, and Bε(x2)∩Bε(x3)̸=∅,Bε(x1)∩Bε(x3) =∅.
It is straightforward to show that the optimal adversarial risk R∗
advin this situation is 1/5
and that A′achieves this adversarial risk if and only if Bε(x3)⊆A′andBε(x1)⊆A′c. On the
other hand, the set ˜A=Bε(x3)∪ {x2}satisfies ProbR Ψ0(˜A) = 1 /5. In particular, thanks to
Theorem 6, ˜Ais a minimizer of both ProbR Ψ0andRΨ0(i.e., the Γ-limits of the PRL models
asp→0). Note, however, that there does not exist a set A′∼ν˜Athat is a minimizer of
Radv. This is because for A′to be a minimizer of Radvwe would need to exclude x2from ˜A,
but it is impossible to achieve this while maintaining the condition ˜A∼νA′, since ρassigns
mass strictly larger than zero to {x2}.
From the above example it is clear that in general we cannot expect that an arbitrary min-
imizer of RΨ0orProbR Ψ0can be turned into a solution to adversarial training by modifying
it within a set of νmeasure zero, in particular by only modifying the classifier outside of
the observed data (the support of the distribution ρ) and their admissible perturbations. In
other words, this means that there may be solutions to PRL or modified PRL for p≈0that,
putting measure theoretic technicalities aside, aren’t solutions to AT. In this sense, PRL or
its modified version may not necessarily recover the AT model when p→0. Fortunately,
it is possible to avoid the issue described above by imposing one extra assumption on the
family of distributions {mx}x∈X.
Assumption 5. Suppose that for every x∈supp( ρ)the measure ρ⌊Bε(x), the restriction of
ρto the ball Bε(x), is absolutely continuous with respect to mx.
Remark 11. If for x∈supp( ρ)we choose mxto be mx=1
2Unif( Bε(x)) +1
2ρ(Bε(x))ρ⌊Bε(x),
then the family {mx}x∈Xsatisfies Assumptions 4 and 5.
Theorem 7. Suppose that Assumptions 4 and 5 hold. Suppose that for every p >0the set
Apis a minimizer of ProbR ΨpoverA=B(X), and suppose that, as p→0,Apconverges
towards a set Ain the weak* topology of L∞(X;ν). Then there is a set A′with A′∼νA
such that A′is a minimizer of Radvover the class of all Borel measurable sets.
The above continues to be true if we substitute ProbR Ψpwith RΨp.
Proof.TheΓ-convergence in Proposition 8 implies that Aas in the statement must be a
minimizer of ProbR Ψ0. Following the proof of Theorem 6 we know there exists a set A′
which is σequivalent to Aand satisfies ProbR Ψ0(A)≥RΨ0(A) = R adv(A′). Thanks to
Theorem 6, it follows that A′is a minimizer of Radv. The desired result now follows from
Assumption 5, since this assumption implies that νis absolutely continuous with respect to
σand as a consequence A∼νA′.
□
34So far we have studied the behaviors of the energies ProbR ΨpandRpasp→0. To wrap
up this section we discuss the limits of these energies as pgrows.
Theorem 8. For the functions Ψp(t) := min {t/p,1}it holds that ProbR ΨpΓ-converges to
E(x,y)∼µ[|1A(x)−y|] +Z
AZ
Acdmx(˜x) dρ1(x) +Z
AcZ
Admx(˜x) dρ0(x)
asp→1, and to E(x,y)∼µ[|1A(x)−y|]asp→ ∞, in the weak-* topology of L∞(X;ν). We
recall νwas introduced in (13).
Proof.This easily follows from the fact that, actually, the convergence of the energies is
uniform over all measurable Aasp→1and as p→ ∞. □
Remark 12. In the previous result we have highlighted the case p= 1, as this is the case
where the modified PRL model coincides with a regularized risk minimization problem with
nonlocal perimeter penalty of the type investigated in [24] in the context of random walk
metric spaces.
Remark 13. In contrast to the modified PRL model, which recovers the standard risk
minimization model as pgrows, the energy RΨpis easily seen to converge uniformly toward
the zero functional as p→ ∞.
5.PRL for general learning settings and the conditional value at risk
After extensively discussing the binary and 0-1 loss case in the previous sections, we shift
ourattentiontotraininggeneralhypotheses h∈ Husinggenerallossfunctions ℓ:Y×Y → R,
even when Yis not binary. Motivated by Propositions 1 and 2 it is natural to consider the
following probabilistically robust optimization problem
inf
h∈HE(x,y)∼µ
max
ℓ(h(x), y), p-ess sup
x′∼mxℓ(h(x′), y)
. (36)
Since the p-ess supoperator is notoriously hard to optimize, one shall replace it with the
conditional value at risk (CVaR) which is convex and easier to optimize [30, 31]. For a
function f:X →Rand a probability distribution mthe CVaR at level p∈(0,1)is defined
as
CVaR p(f;m) := inf
α∈Rα+Ex′∼mx
(f(x′)−α)+
p. (37)
Itiseasytoseethat p-ess supx′∼mf(x′)≤CVaR p(f;m). UsingCVaRinplaceofthe p-ess sup
operator, a tractable version of (36) is
inf
h∈HE(x,y)∼µh
maxn
ℓ(h(x), y),CVaR p(ℓ(h(•), y);mx)oi
. (38)
We emphasize that, if the loss function ℓ(•,•)is convex in its first argument, then (38) is
a convex function of the hypothesis h. Furthermore, CVaR is positively homogeneous and
hence also (38) is positively homogeneous in the loss function. So, taking the maximum of
the samplewise CVaR and standard risk is consistent with a standard dimensionality analysis
as both terms scale in the same way.
35In the binary classification case we can prove Proposition 3 which states that the CVaR
relaxation corresponds precisely to using the risk ProbR Ψpwith the piecewise linear and
concave function Ψp(t) = min {t/p,1}for which our theory from Section 2.2 applies.
Proof of Proposition 3. Ifℓis the 0-1-loss then the function f:=ℓ(1A(·), y)forA∈ Acan
be written as f=1Sfor set S∈ {A, Ac}, depending on whether y= 0ory= 1. So it
suffices to deal with the case f=1Awhere we can write
CVaR p(f;mx) = inf
α∈Rα+ (1−α)+mx(A)
p+ (−α)+1−mx(A)
p.
Notice that the function
ζ(α) :=α+ (1−α)+mx(A)
p+ (−α)+1−mx(A)
p, α∈R,
is continuous and piecewise linear with kinks at α= 0andα= 1. Moreover, since 0< p < 1
it holds ζ(α)≥ζ(1)forα > 1, and ζ(α)≥ζ(0)forα < 0. Thus the minimum of ζis
attained at either α= 0orα= 1. Therefore
CVaR p(f;mx) = min {ζ(0), ζ(1)}= minmx(A)
p,1
= Ψ p(Px′∼mx[1A(x′)]).
This together with Proposition 2 implies the claim. □
6.Numerical experiments
In this section, we conduct a comparative analysis between the original formulation of
PRL (denoted as “PRL” in Table 1) and our modification of PRL which is based on (38)
(denoted as “m-PRL”). We build upon the code of [30] and our implementation is available
onGitHub.1The algorithmic realization of (38) is a straightforward adaptation of their
algorithm, which alternatingly minimizes the inner optimization problem that defines CVaR
and the outer optimization to find a suitable classifier, see Algorithm 1 in Appendix B.
Our experiments are conducted on MNIST and CIFAR-10 and to ensure a fair comparison
we adhere to the hyperparameter settings described in [30], such that both the original and
modified algorithms utilize the same set of hyperparameters for each specified value of p. The
corresponding results for several baseline algorithms including empirical risk minimization
and adversarial training can be found in [30].
6.1.Comparingaccuracyandrobustness. Wereportthecleanaccuracy, adversarialac-
curacy (subject to PGD attacks), accuracy on noise-augmented data, and quantile accuracies
for different values of ρdefined—as in [30, (6.1)]—for a single data point (x, y)by
(39) ProbAcc ρ(x, y) =1Px′∼mx[h(x′)=y]>p.
In practice, we use an empirical proportion, computed over 100 samples from mx, in lieu of
the true probability, as done in [30]. All quantities are averaged over three runs, and we
perform model selection based on the best clean validation accuracy; see Appendix B.2 for
more training details.
The results in Table 1 demonstrate that the geometric modification does not compromise
the accuracy of the original algorithm, and sometimes leads to improved performance, even
as it provides stronger theoretical guarantees. Note that neither PRL nor m-PRL should be
1https://github.com/DanielMckenzie/Begins_with_a_boundary
36Table 1. Accuracies [%] of the geometric and original algorithm for different
values of p.
Data pAlgorithm Clean Adv Aug ProbAcc(0.1) ProbAcc(0.05) ProbAcc(0.01)MNIST0.01m-PRL 99.20 12.19 99.04 98.18 97.69 96.38
PRL 99.19 10.76 98.90 97.94 97.38 95.67
0.1m-PRL 99.28 14.2099.22 98.70 98.45 97.86
PRL 99.32 8.94 99.22 98.70 98.46 97.80
0.3m-PRL 99.29 3.02 99.21 98.76 98.53 97.95
PRL 99.27 3.0299.22 98.77 98.55 98.01
0.5m-PRL 99.27 1.80 99.21 98.72 98.44 97.93
PRL 99.26 1.68 99.19 98.72 98.47 97.80CIFAR-100.01m-PRL 80.65 0.15 78.13 73.44 72.13 68.80
PRL 81.73 0.24 79.16 74.61 73.19 69.96
0.1m-PRL 88.15 0.14 85.96 82.55 81.46 78.81
PRL 88.28 0.19 85.61 82.21 81.06 78.28
0.3m-PRL 90.43 11.80 88.70 85.17 83.93 80.93
PRL 89.97 7.20 88.62 85.07 83.75 80.87
0.5m-PRL 91.51 1.93 88.94 85.53 84.18 81.21
PRL 90.74 1.9988.94 85.54 84.35 81.57
expected to match the adversarial robustness of classifiers trained with PGD attacks [23] or
other worst-case optimization techniques. Instead, they shine with superior clean accuracy
and easier training while maintaining probabilistic robustnesss, as well as a certain degree
of adversarial robustness. This corroborates the findings of [30].
6.2.On the existence of pathological points. We say (x, y)is a pathological data point
ifxis incorrectly classified yet a large proportion of perturbations to xyield a correct
classification. See Figure 1 for a simple example. Although the discussion of Section 1
asserts that such points canarise for classifiers trained using PRL, it is interesting to verify
whether this phenomenon occurs in practice.
To do so, we examine all misclassified CIFAR-10 images, in both test and train splits, for
a model trained using PRL as described above. For each image x, we generate 100 samples
x′∼mxand compute the proportion of such samples which are correctly classified. As shown
in Figure 3, while for the vast majority of such x, all 100x′remain incorrectly classified,
images xexist where an arbitrarily large proportion of the x′are correctly classified. In
short, pathological points do occur in practice.
We repeated the same experiment, but with a model trained using m-PRL. Intriguingly,
while m-PRL is guaranteed in theory to prevent pathological points (see Proposition 11 in
the Appendix), in practice they still occur, see Figure 3. We did not find strong empirical
evidence that using m-PRL results in fewer pathological points in practice, see also Figures 4
to 6. We attribute this gap between theory and practice to the fact that m-PRL (as well
37as PRL) approximates the value of CVaR p, which involves a high-dimensional expectation,
with an empirical average, see (38) and line 7 in Algorithm 1).
0 20 40 60 80 100
Percentage of perturbations yielding correct classification102103Number of  Incorrectly Classified Images0 25 50 75 100102
(a)p= 0.01, train, original PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification102103Number of  Incorrectly Classified Images0 25 50 75 100102 (b)p= 0.01, train, m-PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification101102103Number of  Incorrectly Classified Images0 25 50 75 100101102
(c)p= 0.01, test, original PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification101102103Number of  Incorrectly Classified Images0 25 50 75 100100101102 (d)p= 0.01, test, m-PRL
Figure 3. Histograms display the distribution of percentages of correctly
classified perturbations among misclassified images for both original and m-
PRL with parameter p= 0.01. The inner plot excludes the prevalent 0%
case. The plots show that pathological data points—i.e. data points which are
misclassified yet most perturbations to the data point are correctly classified—
occur in real datasets.
7.Discussion and Conclusion
In this paper we considered probabilistically robust learning (PRL), originally proposed
in [30]. We introduced a modification of the original PRL model that allowed us to address,
at least theoretically, the possibility that certain solutions to the model possess pathological
points as described in Figure 1. This modification has the appeal of being interpretable
through the lens of regularized risk minimization, where the regularization terms take the
form of a non-local perimeters of interest in their own right. We discussed an asymptotic
expansion for smooth decision boundaries to show that for small adversarial budgets these
38probabilisticperimetersinducethesameregularizationeffectastheoriginaladversarialtrain-
ingmodel. Forbinaryclassificationweprovedexistenceofoptimalhardclassifiersandofvery
general classes of soft classifiers including neural networks in both the original and modified
PRL settings. This was done through novel relaxation techniques taking advantage of the
structure of our functionals. Finally, through rigurous Γ-convergence analysis we provided
a detailed discussion on the relation between adversarial training, risk minimization, and all
the PRL models, highlighting that the original PRL model fails to interpolate between risk
minimization and adversarial training, contrary to claims in previous works. For general
(not necessarily binary) problems we showed that the natural loss function to choose is the
sample-wise maximum of the standard loss and conditional value at risk (CVaR).
One limitation of PRL is that it does not completely solve the accuracy vs. robustness
trade-off, which remains a challenging problem. Furthermore, while the formal limit of PRL
asp→0is the worst-case adversarial problem, the algorithms for solving PRL exhibit
limitations for very small values of p(in the computation of CVaR p). Still, the results for
moderately large values of pare encouraging and future work should focus on understanding
of this trade-off better.
The rich mathematical theory developed in this paper opens up new avenues for research,
such as the explicit design of probabilistic regularizers for algorithms and exploring the
variational convergence of the probabilistic perimeter and its implications for adversarial
robustness.
Acknowledgment
This material is based upon work supported by the National Science Foundation under
Grant Number DMS 1641020 and was started during the summer of 2022 as part of the
AMS-MRC program Data Science at the Crossroads of Analysis, Geometry, and Topology .
NGT was supported by the NSF grants DMS-2005797 and DMS-2236447. MJ was supported
by NSF grant DMS-2400641.
References
[1] Maksym Andriushchenko and Nicolas Flammarion. “Understanding and improving fast
adversarialtraining”.In: Advances in Neural Information Processing Systems 33(2020),
pp. 16048–16059.
[2] Pranjal Awasthi, Natalie S Frank, and Mehryar Mohri. “On the existence of the ad-
versarial Bayes classifier”. In: Advances in Neural Information Processing Systems 34
(2021), pp. 2978–2990.
[3] Pranjal Awasthi, Natalie S Frank, and Mehryar Mohri. “On the Existence of the Ad-
versarial Bayes Classifier (Extended Version)”. In: arXiv preprint arXiv:2112.01694
(2021).
[4] Andrea Braides. Gamma-Convergence for Beginners . Oxford University Press, July
2002. isbn: 9780198507840.
[5] Andrea Braides and Lev Truskinovsky. “Asymptotic Expansions by Γ-convergence”.
In:Continuum Mechanics and Thermodynamics 20.1 (Apr. 2008), pp. 21–62. issn:
0935-1175, 1432-0959.
39[6] Leon Bungert, Nicolás García Trillos, and Ryan Murray. “The geometry of adversarial
training in binary classification”. In: Information and Inference: A Journal of the IMA
12.2 (June 2023), pp. 921–968. issn: 2049-8772.
[7] Leon Bungert, Tim Laux, and Kerrek Stinson. A mean curvature flow arising in ad-
versarial training . 2024. arXiv: 2404.14402 [math.AP] .
[8] LeonBungertandKerrekStinson.“Gamma-convergenceofanonlocalperimeterarising
in adversarial machine learning”. In: Calculus of Variations and Partial Differential
Equations 63.5 (2024), p. 114.
[9] HanQin Cai et al. “A zeroth-order block coordinate descent algorithm for huge-scale
black-box optimization”. In: International Conference on Machine Learning . PMLR.
2021, pp. 1193–1203.
[10] Antonin Chambolle, Alessandro Giacomini, and Luca Lussardi. “Continuous limits of
discrete perimeters”. In: ESAIM: Mathematical Modelling and Numerical Analysis 44.2
(2010), pp. 207–230.
[11] Antonin Chambolle, Massimiliano Morini, and Marcello Ponsiglione. “Nonlocal curva-
ture flows”. In: Archive for Rational Mechanics and Analysis 218 (2015), pp. 1263–
1329.
[12] Pin-Yu Chen et al. “ZOO: Zeroth order optimization based black-box attacks to deep
neural networks without training substitute models”. In: Proceedings of the 10th ACM
workshop on artificial intelligence and security . 2017, pp. 15–26.
[13] Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. “Certified adversarial robustness via
randomized smoothing”. In: international conference on machine learning . PMLR.
2019, pp. 1310–1320.
[14] Gianni Dal Maso. An Introduction to Γ-Convergence . Birkhäuser Boston, 1993. isbn:
9781461203278.
[15] Nelson Dunford and Jacob T Schwartz. Linear Operators: General theory . Linear Op-
erators. Interscience Publishers, 1958. isbn: 9780470226056.
[16] NatalieSFrankandJonathanNiles-Weed.“Existenceandminimaxtheoremsforadver-
sarialsurrogaterisksinbinaryclassification”.In: Journal of Machine Learning Research
25.58 (2024), pp. 1–41.
[17] Natalie S Frank and Jonathan Niles-Weed. “The Consistency of Adversarial Training
for Binary Classification”. In: arXiv preprint arXiv:2206.09099 (2022).
[18] Nicolás García Trillos, Matt Jacobs, and Jakwang Kim. “On the existence of solutions
to adversarial training in multiclass classification”. In: arXiv preprint arXiv:2305.00075
(2023).
[19] Nicolás García Trillos and Ryan Murray. “Adversarial Classification: Necessary Condi-
tions and Geometric Flows”. In: Journal of Machine Learning Research 23.187 (2022),
pp. 1–38.
[20] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. “Explaining and harnessing
adversarial examples”. In: arXiv preprint arXiv:1412.6572 (2014).
[21] Kaiming He et al. “Deep residual learning for image recognition”. In: Proceedings of the
IEEE conference on computer vision and pattern recognition . 2016, pp. 770–778.
[22] Dan Hendrycks et al. “The many faces of robustness: A critical analysis of out-of-
distributiongeneralization”.In: Proceedings of the IEEE/CVF International Conference
on Computer Vision . 2021, pp. 8340–8349.
40[23] Aleksander Madry et al. “Towards deep learning models resistant to adversarial at-
tacks”. In: arXiv preprint arXiv:1706.06083 (2017).
[24] José M Mazón, Marcos Solera, and Julián Toledo. “The total variation flow in metric
random walk spaces”. In: Calculus of Variations and Partial Differential Equations 59
(2020), pp. 1–64.
[25] Rachel Morris and Ryan Murray. Uniform Convergence of Adversarially Robust Clas-
sifiers. 2024. arXiv: 2406.14682 [math.AP] .
[26] Muni Sreenivas Pydi and Varun Jog. “The many faces of adversarial risk”. In: Advances
in Neural Information Processing Systems 34 (2021), pp. 10000–10012.
[27] Yao Qin et al. “Imperceptible, robust, and targeted adversarial examples for automatic
speech recognition”. In: International conference on machine learning . PMLR. 2019,
pp. 5231–5240.
[28] Joaquin Quinoñero-Candela et al. Dataset shift in machine learning . Mit Press, 2008.
[29] Vinod Raman, Unique Subedi, and Ambuj Tewari. “On Proper Learnability between
Average- and Worst-case Robustness”. In: arXiv preprint arXiv:2211.05656 (2023).
[30] Alexander Robey et al. “Probabilistically Robust Learning: Balancing Average and
Worst-case Performance”. In: International Conference on Machine Learning . PMLR.
2022, pp. 18667–18686.
[31] R Tyrrell Rockafellar, Stanislav Uryasev, et al. “Optimization of conditional value-at-
risk”. In: Journal of risk 2 (2000), pp. 21–42.
[32] LeoSchwinnetal.“Identifyinguntrustworthypredictionsinneuralnetworksbygeomet-
ric gradient analysis”. In: Uncertainty in Artificial Intelligence . PMLR. 2021, pp. 854–
864.
[33] Leo Schwinn et al. “Improving Robustness against Real-World and Worst-Case Dis-
tribution Shifts through Decision Region Quantification”. In: International Conference
on Machine Learning . PMLR. 2022, pp. 19434–19449.
[34] Ali Shafahi et al. “Adversarial training for free!” In: Advances in Neural Information
Processing Systems 32 (2019).
[35] Dimitris Tsipras et al. “Robustness may be at odds with accuracy”. In: arXiv preprint
arXiv:1805.12152 (2018).
[36] Vladimir Vapnik. The nature of statistical learning theory . Springer science & business
media, 1999.
[37] Bao Wang et al. “EnResNet: ResNets Ensemble via the Feynman–Kac Formalism for
Adversarial Defense and Beyond”. In: SIAM Journal on Mathematics of Data Science
2.3 (2020), pp. 559–582.
[38] Lukas Weigand, Tim Roith, and Martin Burger. Adversarial flows: A gradient flow
characterization of adversarial attacks . 2024. arXiv: 2406.05376 [cs.LG] .
[39] Eric Wong, Leslie Rice, and J Zico Kolter. “Fast is better than free: Revisiting adver-
sarial training”. In: arXiv preprint arXiv:2001.03994 (2020).
[40] Matthew D Zeiler. “Adadelta: an adaptive learning rate method”. In: arXiv preprint
arXiv:1212.5701 (2012).
[41] Hongyang Zhang et al. “Theoretically principled trade-off between robustness and ac-
curacy”. In: International conference on machine learning . PMLR. 2019, pp. 7472–
7482.
41Appendix A.Pathological points in the modified PRL model
Contrary to the situation presented in Figure 1, where we describe unintuitive features
of a solution of the original PRL model, the modified PRL model possesses an interesting
stability property that prevents their minimizers from having pathological points (recall
the discussion in Section 6.2). This property is independent of any specifics of the family
{mx}x∈Xand for example holds in the Euclidean setting when we set mxto be the uniform
measure over the ball Bε(x).
Proposition 11. IfAis a minimizer of ProbR Ψ0withΨ0(t) =1t>0, then for ρ0-a.e. x∈ X
we have: 1A(x) = 1implies mx-ess sup 1A= 1. Likewise, for ρ1-a.e. x∈ X,1Ac(x) = 1
implies mx-ess sup 1Ac= 1.
Proof.We first observe that if Aminimizes ProbR Ψ0, then it also minimizes RΨ0. To see
this, let ProbR∗
Ψ0andR∗
Ψ0be the infima of ProbR Ψ0andRΨ0, respectively. We then observe
that for any given measurable ˜Awe have
RΨ0(˜A)≥R∗
Ψ0= ProbR∗
Ψ0= ProbR Ψ0(A)≥RΨ0(A),
where the second equality follows from Theorem 6 and the last inequality from Proposi-
tion 10. This proves that Ais indeed a minimizer of RΨ0. From the proof of Proposition 10
we had already observed that for every x∈ X
1Ac(x)·mx-ess sup 1A+1A(x)≥mx-ess sup 1A,
as well as
1A(x)·mx-ess sup 1Ac+1Ac(x)≥mx-ess sup 1Ac.
But since we also have
RΨ0(A) = ProbR Ψ0(A)≥Z
X(1Ac(x)·mx-ess sup 1A+1A(x)) dρ0(x)
+Z
X(1A(x)·mx-ess sup 1Ac+1Ac(x)) dρ1(x)
≥Z
Xmx-ess sup 1Adρ0(x) +Z
Xmx-ess sup 1Acdρ1(x)
= R Ψ0(A),
we deduce that for ρ0-a.e. x∈ X
1Ac(x)·mx-ess sup 1A+1A(x) =mx-ess sup 1A
and for ρ1-a.e. x∈ X
1A(x)·mx-ess sup 1Ac+1Ac(x) =mx-ess sup 1Ac.
The desired implications now follow. □
42Appendix B.Computational aspects of PRL
B.1.Pseudocode for geometric probabilistically robust learning. In Algorithm 1
we provide a pseudocode for parametrized classifiers f≡fθ:X → Y based on stochastic
gradient descent with batch size B. Furthermore, it involves a sample size of Msamples from
a distribution mxaround an input x∈ X, a learning rate ηαfor the inner optimization in
CVaR, and a learning rate ηfor the parameter updates. The pseudocode is a straightforward
generalization of [30, Algorithm 1] and we implemented it in their code framework.2The
code which can be used to reproduce our results is part of the supplementary material of
this paper.
Algorithm 1 Proposed algorithm for solving (38) for p∈(0,1).
1:forminibatch (xj, yj)B
j=1do
2:forTstepsdo ▷Approximate solution of inner problem
3: Draw x′
k∼mxj,k= 1, . . . , M
4: gαj←1−1
pMMX
k=11ℓ(fθ(x′
k), yj)≥αj
5: αj←αj−ηαgαj
6:end for
7: Sj←αj+1
pMMX
k=1(ℓ(fθ(x′
k), yj)−αj)+▷Approximate value of CVaR p
8:ifSj> ℓ(fθ(xj), yj))then ▷IfCVaR pkicks in
9: gj←1
pMMX
k=1∇θ(ℓ(fθ(x′
k), yj)−αj)+
10:else ▷If it doesn’t
11: gj← ∇ θℓ(fθ(xj), yj)
12:end if
13: g←1
BBX
j=1gj ▷Compute full θ-gradient
14: v←optimizer( g) ▷AdaDelta or SGD(+M)
15: θ←θ−ηv ▷Update parameters
16:end for
B.2.Training details. Hyperparameter values specific to Algorithm 1 used in training are
presented in Table 2. Following [30], we use AdaDelta [40] for MNIST experiments and
SGD with momentum for CIFAR-10 experiments. The MNIST experiments use a CNN
architecture with two convolutional layers (32 and 64 filters, size 3x3), two dropout layers
(dropout probabilities 0.25, 0.5), and two fully connected layers (dimensions 9216 to 128 and
128 to 10). A ResNet-18 [21] is used in the CIFAR-10 experiments. The hyperparameter
valuesusedforthesealgorithmsarecontainedin hparams_registry.py intheaccompanying
code.
2https://github.com/arobey1/advbench
43Table 2. Hyperparameters used for training. The probability distribution
mxis always taken to be the uniform distribution over the ball Bε(x). Note
that pis called betain the code. For consistency we always used the same
hyperparameter values for the “Geometric” and “Original” versions.
Data p ε η αM TMNIST0.01 0 .3 0 .1 20 5
0.1 0 .3 1 .0 20 5
0.3 0 .3 1 .0 20 5
0.5 0 .3 1 .0 20 5CIFAR-100.01 8 /255 0 .1 20 5
0.1 8 /255 1 .0 20 5
0.3 8 /255 1 .0 20 5
0.5 8 /255 1 .0 20 5
B.3.Computational resources used. We performed the majority of the prototyping and
someexperimentationonaLambdaLabsVectorworkstationequippedwith3NVIDIAA6000
GPUs. We estimate that we used approximately 500 GPU-hours on this machine. We
supplemented this with 550 GPU-hours of cloud compute—using the Lambda GPU cloud—
predominately on instances equipped with a single A10 GPU.
44B.4.Further numerical experiments. In Figures 4 to 6 we provide further numerical
experiments on pathological points with parameters p= 0.1,0.3, and 0.5
0 20 40 60 80 100
Percentage of perturbations yielding correct classification102103Number of  Incorrectly Classified Images0 25 50 75 100102
(a)p= 0.1, train, original PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification101102103Number of  Incorrectly Classified Images0 25 50 75 100102 (b)p= 0.1, train, m-PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification100101102103Number of  Incorrectly Classified Images0 25 50 75 100100101102
(c)p= 0.1, test, original PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification100101102103Number of  Incorrectly Classified Images0 25 50 75 100100101102 (d)p= 0.1, test, m-PRL
Figure 4. Histograms showing the distribution of percentages of correctly
classified perturbations among misclassified images for both original and m-
PRL with parameter p= 0.1.
450 20 40 60 80 100
Percentage of perturbations yielding correct classification101102103Number of  Incorrectly Classified Images0 25 50 75 100101102(a)p= 0.3, train, original PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification101102103Number of  Incorrectly Classified Images0 25 50 75 100101102 (b)p= 0.3, train, m-PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification100101102Number of  Incorrectly Classified Images0 25 50 75 100100101102
(c)p= 0.3, test, original PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification100101102Number of  Incorrectly Classified Images0 25 50 75 100100101102 (d)p= 0.3, test, m-PRL
Figure 5. Histograms showing the distribution of percentages of correctly
classified perturbations among misclassified images for both original and m-
PRL with parameter p= 0.3.
460 20 40 60 80 100
Percentage of perturbations yielding correct classification101102103Number of  Incorrectly Classified Images0 25 50 75 100102(a)p= 0.5, train, original PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification101102103Number of  Incorrectly Classified Images0 25 50 75 100101102 (b)p= 0.5, train, m-PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification101102Number of  Incorrectly Classified Images0 25 50 75 100101
(c)p= 0.5, test, original PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification100101102Number of  Incorrectly Classified Images0 25 50 75 100100101102 (d)p= 0.5, test, m-PRL
Figure 6. Histograms showing the distribution of percentages of correctly
classified perturbations among misclassified images for both original and m-
PRL with parameter p= 0.5.
47Institute of Mathematics & Center for Artifical Intelligence and Data Science (CAIDAS),
University of Würzburg, Germany
Email address :leon.bungert@uni-wuerzburg.de
Department of Statistics, University of Wisconsin-Madison, US
Email address :garciatrillo@wisc.edu
Department of Mathematics, University of California Santa Barbara, US
Email address :majaco@ucsb.edu
Department of Applied Mathematics and Statistics, Colorado School of Mines, US
Email address :dmckenzie@mines.edu
Department of Mathematics, University of California Santa Barbara, US
Email address :nikolic@math.ucsb.edu
Department of Mathematics, University of Utah, US
Email address :qswang@math.utah.edu
48