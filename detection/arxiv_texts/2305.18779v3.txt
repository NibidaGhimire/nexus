IT BEGINS WITH A BOUNDARY: A GEOMETRIC VIEW ON
PROBABILISTICALLY ROBUST LEARNING
LEON BUNGERT, NICOLÃS GARCÃA TRILLOS, MATT JACOBS, DANIEL MCKENZIE,
ÃORÃE NIKOLIÄ†, AND QINGSONG WANG
Abstract. Although deep neural networks have achieved super-human performance on
many classification tasks, they often exhibit a worrying lack of robustness towards adver-
sarially generated examples. Thus, considerable effort has been invested into reformulating
standard Risk Minimization (RM) into an adversarially robust framework. Recently, at-
tention has shifted towards approaches which interpolate between the robustness offered by
adversarial training and the higher clean accuracy and faster training times of RM. In this
paper, we take a fresh and geometric view on one such methodâ€”Probabilistically Robust
Learning (PRL) [30]. We propose a mathematical framework for understanding PRL, which
allows us to identify geometric pathologies in its original formulation and to introduce a
family of probabilistic nonlocal perimeter functionals to rectify them. We prove existence
of solutions to the original and modified problems using novel relaxation methods and also
study properties, as well as local limits, of the introduced perimeters. We also clarify,
through a suitable Î“-convergence analysis, the way in which the original and modified PRL
models interpolate between risk minimization and adversarial training.
Contents
1. Introduction 2
1.1. From empirical risk minimization to robustness 3
1.2. Modifying PRL for binary classification 4
1.3. A larger class of PRL models for binary classification 5
1.4. Informal statements of main results 6
1.5. Related work 9
1.6. Outline 9
2. Existence of probabilistically robust classifiers 10
2.1. Preliminaries 10
2.2. Model family for hard classifiers 12
2.3. Model family for soft classifiers 14
2.4. Existence proofs 17
3. The functional ProbPer Î¨as a perimeter 22
4. Interpolation properties of probabilistically robust learning 28
5. PRL for general learning settings and the conditional value at risk 35
6. Numerical experiments 36
6.1. Comparing accuracy and robustness 36
6.2. On the existence of pathological points 37
7. Discussion and Conclusion 38
Acknowledgment 39
References 39
1arXiv:2305.18779v3  [cs.LG]  30 Sep 2024Appendix A. Pathological points in the modified PRL model 42
Appendix B. Computational aspects of PRL 43
B.1. Pseudocode for geometric probabilistically robust learning 43
B.2. Training details 43
B.3. Computational resources used 44
B.4. Further numerical experiments 45
1.Introduction
The fragility of deep neural network (DNN) based classifiers in the face of adversarial
examples [9, 12, 20, 27] and distributional shifts [22, 28] is by now nearly as familiar as
their success stories. In light of this, a multitude of works (see Section 1.5) propose replac-
ing standard Risk Minimization (RM) [36] with a more robust alternative, with adversarial
training (AT) [20, 23] being a leading example. Unfortunately, there is no free lunch: robust
classifiers frequently exhibit degraded performance on clean data and significantly longer
training times [35]. Consequently, identifying frameworks which balance performance and
robustness is of pressing interest to the Machine Learning (ML) community, and over the
past several years a few such frameworks have been proposed [30, 37, 41]. From the theoret-
ical perspective, it is crucial that the mechanisms by which such frameworks balance these
competing aims are understood.
InthispaperwerevisittheProbabilisticallyRobustLearning(PRL)frameworkintroduced
in[30]anddiscussit,analyzeit,andextenditusingageometricperspective. Thisperspective
reveals certain subtle and paradoxical aspect of PRL: It can have solutions which are very
pathological classifiers, see Figure 1. Building on this observation one can conclude that
solutions of PRL do not necessarily interpolate between standard risk minimization and AT.
This interpolating property was one of the main theoretical motivations for designing the
PRL model in [30]; see Section 4 for an extensive discussion on this.
Aâ‰œclass redAcâ‰œclass blue
(a)This pathological classifier minimizes the
original PRL risk but notthe modified one.
Aâ‰œclass redAcâ‰œclass blue
(b)This classifier minimizes the original PRL
risk andthe modified one.
Figure 1. Even for the simple task of classifying two data points one can
easily construct a pathological solution (Figure 1a) of PRL, observing that
all but the small red set of perturbations of the misclassified blue point are
correctly classified as blue. Both classifiers depicted in Figures 1a and 1b have
zero PRL loss.
Fortunately, our geometric perspective suggests a natural remedy which leads to an inter-
pretation of the modified PRL as regularized RM, where a new notion of nonlocal length (or
2perimeter) of decision boundaries acts as a regularizer; this notion of perimeter (see (9) for its
definition) is of interest in its own right and in Section 3 we will discuss some of its properties.
The interpretation of PRL as perimeter-regularized RM leads us to further generalizations
and allows us to provide a novel view of the Conditional Value at Risk (CVaR) relaxation
of PRL proposed in [30]. We provide conditions that guarantee the existence of solutions
to the optimization problems determining our models as well as the original PRL models,
and clarify, through rigorous analysis using the notion of Î“-convergence, the sense in which
the original PRL and the modified PRL models interpolate between adversarial training and
standard risk minimization. Our existence proofs exploit very interesting structural prop-
erties of our functionals that allow us to circumvent the apparent incompatibility between
the topologies under which our functionals are lower semicontinuous and under which the
compactness of minimizing sequences can be guaranteed.
1.1.From empirical risk minimization to robustness. Given an input space X, an
output space Y, a probability measure Âµâˆˆ P(X Ã— Y ), a loss function â„“:Y Ã— Y â†’ R, and a
hypothesis class H(i.e., a class of measurable functions from XintoY), the standard risk
minimization problem is
inf
hâˆˆHE(x,y)âˆ¼Âµ[â„“(h(x), y)]. (RM)
To train classifiers which are robust against adversarial attacks, [20, 23] suggested adversarial
training:
inf
hâˆˆHE(x,y)âˆ¼Âµ"
sup
xâ€²âˆˆBÎµ(x)â„“(h(xâ€²), y)#
. (AT)
In the above, Xis assumed to have the structure of a metric space and BÎµ(x)forÎµ >0
denotes the (open or closed) ball of radius Îµaround x, although for convenience we will
consider open balls whenever is needed.
The recent work [30] offered an alternative to adversarial training that attempts to reduce
the (in general) large trade-off between accuracy and robustness inherent in (AT); see [30,
35] for discussion. Instead of requiring classifiers to be robust to allpossible attacks around
a point xâ€”as enforced through the supremum in (AT)â€”one may consider a less stringent
notion of robustness, only requiring classifiers to be robust to 100Ã—(1âˆ’p)%of attacks drawn
from a certain distribution mxcentered at x. For this, the authors replace the supremum in
(AT) by the so-called p-ess supoperator for some value pâˆˆ[0,1). To define this operator,
consider a probability distribution mand a function fand let
p-ess sup
xâ€²âˆ¼mf(xâ€²) := inf {tâˆˆR:Pxâ€²âˆ¼m[f(xâ€²)> t]â‰¤p}.
In the mathematical finance or economics literature the p-ess supoperator is better known
as the value at risk (VaR) of a random variable at level p. It is the smallest value tâˆˆR
such that the probability that a randomly chosen point xâ€²âˆ¼msatisfies f(xâ€²)> tis smaller
than p. This notion reduces to the usual essential supremum of fwith respect to mifp= 0,
which explains the name p-ess sup. In [30], it was thus suggested to replace (AT) with the
probabilistically robust learning problem
inf
hâˆˆHE(x,y)âˆ¼Âµ
p-ess sup
xâ€²âˆ¼mxâ„“(h(xâ€²), y)
, (PRL)
3where {mx}xâˆˆXis a suitable family of probability distributions, one for each xin the data
space, interpreted as user-chosen distributions â€œcenteredâ€ around the different x. The pro-
totypical example to keep in mind for X=Rdis the uniform distribution over the Îµ-ball
around x, i.e., mx:= Unif( BÎµ(x)), which is particularly relevant when dealing with adversar-
ial attacks on image classifiers. We will provide further theoretical discussion on the choice
of the measures mxin Section 4.
1.2.Modifying PRL for binary classification. To understand (PRL) better, we focus
first (and mostly) on the binary classification problem (i.e., Y={0,1}) using indicator
functions of admissible sets (i.e., H:={1A:Aâˆˆ A}). For now, one can think of A âŠ‚ 2X
as a suitable Ïƒ-algebra which fits to the problem. Note that we identify the two expressions
1A(x) =1xâˆˆA. We focus on the standard 0-1lossâ„“(Ëœy, y) =1ËœyÌ¸=y, which equals one if yÌ¸= Ëœy
and zero otherwise. In this scenario, the standard risk minimization problem (RM) reduces
to
inf
AâˆˆAn
Rstd(A) :=E(x,y)âˆ¼Âµ[y1xâˆˆAc+ (1âˆ’y)1xâˆˆA]o
, (1)
and we refer to its minimizers as Bayes classifiers and to its minimum value as Bayes risk .
Similarly, (AT) can be rewritten as
inf
AâˆˆA
Radv(A) :=E(x,y)âˆ¼Âµh
y1xâˆˆ(Ac)âŠ•Îµ+ (1âˆ’y)1xâˆˆAâŠ•Îµi
, (2)
where for a set Aâˆˆ Aits fattening by Îµ-balls is defined as AâŠ•Îµ:=S
xâˆˆABÎµ(x). As for (PRL),
it reduces to
inf
AâˆˆA
Rprob(A) :=E(x,y)âˆ¼Âµh
y1Pxâ€²âˆ¼mx[xâ€²âˆˆAc]>p+ (1âˆ’y)1Pxâ€²âˆ¼mx[xâ€²âˆˆA]>pi
, (3)
where, in comparison to (2), the fattenings AâŠ•Îµand(Ac)âŠ•Îµare replaced by the set of all
points xâˆˆ Xfor which the probability that a neighboring point sampled from mxlies inside
A, orAc, respectively, is larger than p. From this definition one can see that PRL may lead to
counter-intuitive classifiers like the ones observed in Figure 1a. Indeed, taking mxto be the
uniform measure over BÎµ(x), we see that the red-shaded spiky region therein has such a small
volume that the blue point with label y= 0lies in the set {xâˆˆ X :Pxâ€²âˆ¼mx[[xâ€²âˆˆA]â‰¤p]}.
Hence, the second term in (3) is zero and the spike adds zero cost to the overall energy.
At an abstract level, the issue with (3) is that sets {xâˆˆ X :Pxâ€²âˆ¼mx[[xâ€²âˆˆAc]> p]}and
{xâˆˆ X :Pxâ€²âˆ¼mx[[xâ€²âˆˆAc]> p]}are not fattenings, i.e., supersets, of AcandA. Speaking
the language of classification, it means that points which are incorrectly classified incur zero
loss if most of their perturbations are correctly classified.
Inordertoobtainamodelwhichdoesnotexhibitthiscounter-intuitivebehaviorwemodify
(3) slightly, thereby obtaining a model which has a geometric regularization interpretation
and can be embedded in a rich class of models that allows to interpolate between risk
minimization and adversarial training. To motivate our modified PRL risk, we first observe
that the original adversarial training risk Radvadmits the following decomposition:
Radv(A) = R std(A) + Per adv(A),
4where Peradv(A)is the non-negative functional
Peradv(A) :=Z
Acsup
xâ€²âˆˆBÎµ(x)1A(xâ€²) dÏ0(x) +Z
Asup
xâ€²âˆˆBÎµ(x)1Ac(xâ€²) dÏ1(x)
andÏi(â€¢) :=Âµ(â€¢ Ã— { i}), i.e., the weighted conditional distribution of the points with label
iâˆˆ {0,1}. We refer the interested reader to [6], where a detailed discussion on this decom-
position, results on existence of minimizers for adversarial training, and a discussion on the
interpretation of the functional Peradvas a nonlocal perimeter are presented. The two terms
in the decomposition of Radvcan be interpreted as follows: 1) the term Rstd(A)is the stan-
dard risk and captures the contribution to the overall adversarial risk by misclassified points;
2)Peradv(A)captures the contribution of the points that, although classified correctly by
the binary classifier 1A, are within distance Îµfrom the decision boundary and thus can be
perturbed by the adversary to make the classifierâ€™s output differ from the correct label. Mo-
tivated by the above decomposition for Radv, by substituting the suprema in the definition
ofPeradvwith a softer penalty, the following modified PRL model becomes natural:
(4) inf
AâˆˆA
ProbR( A) := R std(A) + ProbPer( A)
,
where ProbPer is the non-negative functional
(5) ProbPer( A) :=Z
Ac1Pxâ€²âˆ¼mx[xâ€²âˆˆA]>pdÏ0(x) +Z
A1Pxâ€²âˆ¼mx[xâ€²âˆˆAc]>pdÏ1(x).
The notation that we have chosen for the functional ProbPer suggests a perimeter interpre-
tation, and we will justify this choice shortly. With this interpretation, it becomes clear that
the modified PRL model (4) has the structure of a regularized risk minimization problem
where the regularization term penalizes the size of the boundary of a set. As discussed
earlier, this interpretation also holds for AT.
A simple computation (see Proposition 1 below) allows us to rewrite ProbRas
(6) ProbR( A) =E(x,y)âˆ¼Âµh
y1xâˆˆAcâˆ¨Pxâ€²âˆ¼mx[xâ€²âˆˆAc]>p+ (1âˆ’y)1xâˆˆAâˆ¨Pxâ€²âˆ¼mx[xâ€²âˆˆA]>pi
.
From this rewriting it is apparent that a point xwith label ycontributes to the modified PRL
risk if it is either non-robust in a probabilistic sense orif it is misclassified. For instance, if
y= 0, the loss is one when Pxâ€²âˆ¼mx[xâ€²âˆˆA]> por when xâˆˆA. This second condition is not
captured by the original PRL formulation.
1.3.A larger class of PRL models for binary classification. For theoretical and com-
putational reasons that we will soon discuss, it is convenient to generalize problems (3) and
(4) further. Precisely, given an arbitrary function Î¨ : [0 ,1]â†’[0,1]we define
RÎ¨(A) :=Z
XÎ¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆA]) dÏ0(x) +Z
XÎ¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆAc]) dÏ1(x), (7)
as well as
ProbR Î¨(A) := R std(A) + ProbPer Î¨(A), (8)
where
ProbPer Î¨(A) :=Z
AcÎ¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆA]) dÏ0(x) +Z
AÎ¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆAc]) dÏ1(x). (9)
5The functionals RÎ¨andProbR Î¨are indeed generalizations of RprobandProbR, respec-
tively. This can be seen by taking Î¨to be Î¨(t) := 1t>p, as can be easily verified. An-
other important choice for Î¨that we will discuss extensively in the sequel is the function
Î¨p(t) := min {t
p,1}, which is the smallest concave function larger than 1t>p. Later, in Propo-
sition 3 and in Section 5, we will discuss the connection between the CVaR relaxation of
PRL introduced for computational convenience in [30] (see more discussion in Appendix B)
and the optimization of the risks RÎ¨andProbR Î¨for the choice Î¨ = Î¨ p. From a theoretical
perspective, we will establish several structural properties satisfied by the functionals RÎ¨
andProbR Î¨when Î¨is concave. In particular, while we are not able to prove existence
of minimizers (in a large class of sets A) for the original binary problem (3) nor for our
modification (4), we will be able to do it for the minimization of RÎ¨andProbR Î¨when Î¨
is concave, e.g., when Î¨ = Î¨ p. Without concavity the problems are degenerate because of
the hard thresholding imposed by the constraints Pxâ€²âˆ¼mx
xâ€²âˆˆA(c)
and we will only be able
to establish existence of solutions within the enlarged family of â€œsoftâ€ classifiers. A detailed
discussion on this is presented in Section 2 below.
1.4.Informal statements of main results. This paper investigates three main questions
related to PRL. First, we study the existence of minimizers to PRL and to modified PRL.
Second, we explore different geometric interpretations of the functionals ProbPer Î¨. In par-
ticular, we establish two types of results that characterize these functionals as perimeters ,
thereby further suggesting how the models studied in this paper for robust training of classi-
fiers are closely related to geometric regularization methods that explicitly penalize the size
of decision boundaries of classifiers. Finally, we present rigorous analysis that describes, in
detail, the way in which PRL and modified PRL interpolate between adversarial training
and standard risk minimization.
1.4.1.Existence of minimizers of PRL models. In [30], an explicit solution to (PRL) is
presented for the case where the hypothesis class consists of linear classifiers and Âµis a
mixture of normal distributions. To the best of our knowledge, existence of solutions to
(PRL) for general data distributions or hypothesis classesâ€”even for the binary problem
(3)â€”has not been proved so far.
Our first main results assert the existence of minimizers of the risks ProbR Î¨andRÎ¨
for suitable choices of Î¨. We impose no restrictions on the data distribution but consider
families of classifiers satisfying certain closure relations discussed precisely in later sections.
Informal Theorem 1 (Existence of hard classifiers) .For every concave and non-increasing
function Î¨ : [0 ,1]â†’[0,1]there exists a solution to the problem
min
AâŠ‚XProbR Î¨(A).
Informal Theorem 2 (Existence of hard classifiers) .For every concave and non-increasing
function Î¨ : [0 ,1]â†’[0,1]there exists a solution to the problem
min
AâŠ‚XRÎ¨(A).
Note that these existence results do not cover the problem (4) since the function Î¨(t) =
1t>pis not concave. They do include, however, the CVaR model from Proposition 3 below
since this model is realized by the choice Î¨p(t) := min {t/p,1}, which is a concave and
6non-decreasing function. We believe that our proof strategy, which takes advantage of some
interesting structural properties of the functionals ProbR Î¨andRÎ¨, is of interest in its own
right and is captured by our Meta Theorem 1 in Section 2.4 below. Precise statements of
our results can be found in Section 2.2.
We also present existence results for more general, non-concave functions Î¨, including the
choice Î¨(t) =1t>pgiving rise to the original PRL model and its modified version introduced
here. These results, however, apply when we optimize over â€œsoftâ€ classifiers instead of â€œhardâ€
ones, meaning we optimize over functions u:X â†’ [0,1]in a suitably closed hypothesis class
Hinstead of characteristic functions u=1Aof sets A. To make sense of our statements,
we first need to replace the functional ProbPer Î¨(A)of a set Aby a suitable regularization
functional defined according to
ProbJ Î¨(u) :=Z
X(1âˆ’u(x)) Î¨ (Exâ€²âˆ¼mx[u(xâ€²)]) dÏ0(x)
+Z
Xu(x)Î¨ (Exâ€²âˆ¼mx[1âˆ’u(xâ€²)]) dÏ1(x).(10)
A straightforward computation reveals that ProbJ Î¨(1A) = ProbPer Î¨(A).
Informal Theorem 3 (Existence of soft classifiers) .For every lower semicontinuous func-
tionÎ¨ : [0 ,1]â†’[0,1]and every hypothesis class Hwhich is closed in a suitable sense there
exists a solution to the problem
min
uâˆˆHE(x,y)âˆ¼Âµ[|u(x)âˆ’y|] + ProbJ Î¨(u).
Informal Theorem 4 (Existence of soft classifiers) .For every lower semicontinuous func-
tionÎ¨ : [0 ,1]â†’[0,1]and every hypothesis class Hwhich is closed in a suitable sense there
exists a solution to the problem
min
uâˆˆHZ
XÎ¨ (Exâ€²âˆ¼mx[u(xâ€²)]) dÏ0(x) +Z
XÎ¨ (Exâ€²âˆ¼mx[1âˆ’u(xâ€²)]) dÏ1(x).
Note that the objective functions in Informal Theorems 3 and 4 coincide with ProbR Î¨and
RÎ¨, respectively, when uis an indicator function. When Î¨is non-decreasing and concave,
andHis suitably chosen, these optimization problems are continuous and exact relaxations
ofinfAâˆˆAProbR Î¨andinfAâˆˆARÎ¨, respectively. Other hypothesis classes Hof interest that
are admissible in Informal Theorems 3 and 4 include functions which are parameterized by
neural networks, as discussed in Example 2.
1.4.2.Interpretation of ProbPer Î¨as a perimeter. As suggested by our discussion in earlier
sections, the functional ProbPer Î¨can be interpreted as a perimeter functional. We can
justify this interpretation from two different perspectives.
First, we establish the following structural properties for the functional ProbPer Î¨when Î¨
is non-decreasing and concave, the exact same assumptions needed in our existence results
discussed in Section 1.4.1. These properties allow us to view ProbPer Î¨as a generalized
perimeter.
InformalTheorem5 (Submodularity) .Provided Î¨is concave, non-decreasing, and Î¨(0) =
0the functional ProbPer Î¨is a generalized perimeter. In particular,
ProbPer Î¨(âˆ…) = ProbPer Î¨(X) = 0
7andProbPer Î¨is submodular, i.e.,
ProbPer Î¨(AâˆªB) + ProbPer Î¨(Aâˆ©B)â‰¤ProbPer Î¨(A) + ProbPer Î¨(B)âˆ€A, Bâˆˆ A.
As a generalized perimeter, ProbPer Î¨admits a convex extension (its total variation) that
is denoted by ProbTV Î¨and that we define precisely in (19). Interestingly, ProbPer Î¨has
a second extension, the functional ProbJ Î¨defined in (10), which is sequentially lower-
semicontinuous (although it fails to be convex) w.r.t. the weak topology where we can
guarantee precompactness of minimizing sequences and is always greater than or equal to
ProbTV Î¨. We use this ordering in our proof strategy for the existence of optimal hard clas-
sifiers. We also note that, while non-convex, the extension ProbJ Î¨has a relatively simple
explicit expression that makes it useful for computations, while the same is not true for
ProbTV Î¨, which instead has a complicated expression that would be hard to compute with.
When Î¨is more general, we can still give a perimeter interpretation to the functional
ProbPer Î¨, at least in an asymptotic sense. For this purpose, we assume that mxlocalizes to
a point mass at x.
Informal Theorem 6 (Local asymptotics) .LetX=Rd. Ifmxâ‰¡mx,ÎµforÎµ >0andmx,Îµ
converges to the Dirac delta Î´xin a suitable way, then the rescaled probabilistic perimeters
1
ÎµProbPer Î¨(A)of a smooth set Aconverge to the weighted local perimeter
Per(A) :=Z
âˆ‚Af(x, n(x)) dHdâˆ’1,
where n(x)denotes the outer unit normal at xâˆˆâˆ‚Aandfis a suitable weight function, de-
pending on the distributions mx,Îµ, and Ïiforiâˆˆ {0,1}.Hdâˆ’1denotes the (dâˆ’1)-dimensional
Hausdorff measure in Rd.
1.4.3.Interpolation properties of PRL and modified PRL. Our last main results describe the
relation between adversarial training, RM, and the PRL and modified PRL models, at least
in the agnostic setting where the family of admissible binary classifiers consists of all Borel
measurable sets. We focus on the energies ProbR Î¨pandRÎ¨pasptends to zero or âˆfor the
choice Î¨p(t) = min {t/p,1}.
InformalTheorem7 (Convergencetominimumadversarialtraining) .LetÎ¨p(t) := min {t/p,1}.
Then the minimum value of ProbR Î¨pconverges to the minimum value of the adversarial
training problem (2)aspâ†’0. If, in addition, for every xthe measure mxdominates the
data measures Ï0andÏ1restricted to the support of mx, then minimizers of ProbR Î¨pconverge
to minimizers of (2)aspâ†’0.
Analogous statements hold for the minimization of RÎ¨p.
While the convergence of the minimal risks holds under fairly general assumptions, we
emphasizethattheconvergenceofminimizersholdsprovidedweimposeadditionalconditions
on the measures {mx}xâˆˆX, as our examples in Section 4 illustrate.
For large values of pwe have the following result.
Informal Theorem 8 (Convergence to minimum standard risk) .LetÎ¨p(t) := min {t/p,1}.
Then the minimum value of ProbR Î¨pconverges to the minimum value of the RM problem
(2)aspâ†’ âˆ. Also, minimizers of ProbR Î¨pconverge to minimizers of (2)aspâ†’ âˆ.
8We emphasize that the above statement holds for ProbR Î¨pbut not for RÎ¨p. In fact, there
is no value or limiting value of pthat makes RÎ¨pinto the standard risk functional. This
means that the family of functionals {RÎ¨p}pdoes not actually interpolate between AT and
RM, while the family of functionals {ProbR Î¨p}pdoes. The latter model has the additional
advantage of being interpretable as a geometric regularization model.
1.5.Related work. Adversarial training was developed in [20, 23] as an approach to pro-
duce networks that are less sensitive to adversarial attacks. [34] reduced its computational
complexity by reusing gradients from the backpropagation when training neural networks.
[39] showed that training with noise perturbations followed by a single signed gradient as-
cent (FGSM) step can be on par with adversarial training while being much cheaper. This
approach was picked up and improved upon in [1] based on gradient alignment. Different
authors also investigated test-time robustification of pretrained classifiers using randomized
smoothing[13]orgeometric/gradient-basedapproaches[32, 33]. Whilesomeoftheprevious
models use a combination of random perturbations and gradient-based adversarial attacks to
robustifyclassifiers, [30]proposedprobabilisticallyrobustlearning, whichisentirelybasedon
random perturbations. PRL aims to interpolate between clean and adversarial accuracy and
enjoys the favorable sample complexity of vanilla empirical risk minimization; see also [29]
for more insights on this issue. Connections between adversarial training and local perimeter
regularization as well as mean curvature flows of decision boundaries were explored in [19,
41] and recently rigorously tied in [7, 8]. Furthermore, in [8] it was proved that solutions to
adversarial training converge to distinguished minimizers of standard risk minimization as
Îµâ†’0which was later quantified and extended to the probablistically robust setting in [25].
An interpretation of adversarial training as gradient flow is given in [38].
Our work is in line with a series of papers [2, 3, 6, 16, 17, 18, 26] that explore the
existence of solutions to adversarial training problems in different settings. These existence
proofs involve dealing with different kinds of measurability issues, depending on whether
open or closed balls BÎµ(x)are used in the attack model. For open balls one can work with
the Borel Ïƒ-algebra A=B(X)[6], whereas closed balls require the use of the universal Ïƒ-
algebra to make sure that AâŠ•Îµis measurable [2, 3, 26]. Recently, these results were improved
in [18] where it was proved that, for the case of multi-class classification, even for the closed
ball model Borel measurable classifiers exist, although they are not necessarily indicator
functions of measurable sets. Moreover, [18] showed that for all but countably many values
of the adversarial budget Îµ >0the open and the closed ball models have the same minimal
value.
1.6.Outline. The rest of the paper is organized as follows. In Section 2 we make the setting
for our variational problems precise and then present a series of results on the existence of
minimizers of these problems. In particular, in Sections 2.2 and 2.3 we make precise our
Informal Theorems 1 and 2, and in Section 2.4 present their proofs. Section 3 is devoted
to the study of the functional ProbPer Î¨and its interpretation as a perimeter. There, we
make the Informal Theorems 5 and 6 precise and present their proofs. Section 4 is devoted
to the interpolation properties of the different PRL models. There we make our Informal
Theorems 7 and 8 precise using the notion of Î“-convergence. In Section 5, we introduce a
modified PRL model for general supervised learning problems beyond binary classification
and discuss the connection between the CVar relaxation of PRL in [30] and our geometric
9framework. In Section 6 we present some numerical results of an implementation of our
models in real data settings. We wrap up the paper in Section 7 with some conclusions and
perspectives for future research.
2.Existence of probabilistically robust classifiers
2.1.Preliminaries. In this section we discuss a few other reformulations for the energies
discussed in the introduction. These reformulations provide some additional context and
connections to the literature that will later be used in our discussion.
To start, we first present a reformulation of the probabilistic risk ProbRas the expected
maximum of the sample-wise standard risk and the probabilistically robust risk from [30].
Proposition 1. For the 0-1lossâ„“(Ëœy, y) :=1ËœyÌ¸=ywe can rewrite the probabilistic risk ProbR
as in(6). In that same setting, ProbRcan also be written as the expectation of a sample-wise
maximum of the standard loss and the loss suggested in [30], that is:
ProbR( A) =E(x,y)âˆ¼Âµ
max
â„“(1A(x), y), p-ess sup
xâ€²âˆ¼mxâ„“(1A(xâ€²), y)
. (11)
Remark 1. This result will be key for generalizing ProbRto multi-class classification as
well as general hypothesis classes and loss functions. See Section 5
Remark 2. In its original expression, ProbRis written as the sum of the standard risk and
a nonlocal perimeter functional. This probabilistic perimeter , which we will discuss in more
detail in Section 3, can be rewritten as:
ProbPer( A) =Ï0({xâˆˆAc:Pxâ€²âˆ¼mx[xâ€²âˆˆA]> p})
+Ï1({xâˆˆA:Pxâ€²âˆ¼mx[xâ€²âˆˆAc]> p}).
Note that ProbPer( A)counts the proportion of correctly classified points xfor which more
than 100Ã—p%of their neighbors, sampled from mx, constitute an attack. From this it should
be intuitively clear that ProbPer( A)is a boundary term.
Remark 3. The interpretation of the statement of this proposition in the light of Figure 1
is clear: Only if a point xis correctly classifiedâ€”meaning 11A(x)Ì¸=y= 0â€”the probabilistically
robust regularization kicks in through the second term in the maximum. Points which are
incorrectly classified will always be penalized even if most attacks correct the label, i.e., if
1Pxâ€²âˆ¼mx[1A(xâ€²)Ì¸=y]>p= 0. Thus, minimizing ProbRinstead of Rprobcorrects the pathology of
the original PRL formulation.
Proof of Proposition 1. Disintegrating the risk functional Rstdwe can write
Rstd(A) =Z
X1xâˆˆAdÏ0(x) +1xâˆˆAcdÏ1(x).
Also,
ProbPer( A) =Z
X1xâˆˆAâˆ¨Pxâ€²âˆ¼mx[xâ€²âˆˆA]>pâˆ’1xâˆˆAdÏ0(x)
+Z
X1xâˆˆAcâˆ¨Pxâ€²âˆ¼mx[xâ€²âˆˆAc]>pâˆ’1xâˆˆAcdÏ1(x).
10Adding the above two identities we deduce (6). Now that (6) has been established we see
that
ProbR( A)
=Z
X1xâˆˆAâˆ¨Pxâ€²âˆ¼mx[xâ€²âˆˆA]>pdÏ0(x) +1xâˆˆAcâˆ¨Pxâ€²âˆ¼mx[xâ€²âˆˆAc]>pdÏ1(x)
=Z
Xmaxn
1xâˆˆA,1Pxâ€²âˆ¼mx[xâ€²âˆˆA]>po
dÏ0(x) +Z
Xmaxn
1xâˆˆAc,1Pxâ€²âˆ¼mx[xâ€²âˆˆAc]>po
dÏ1(x),
where we used the fact that the indicator function of the union of two sets equals the
maximum of the two indicator functions. (11) follows immediately. â–¡
In the same spirit as in Proposition 1, we can rewrite ProbR Î¨for general Î¨as follows.
Proposition 2. For the 0-1lossâ„“(Ëœy, y) :=1ËœyÌ¸=yand for any function Î¨ : [0 ,1]â†’[0,1]we
can rewrite the probabilistic risk ProbR Î¨as sample-wise maximum in the following way:
ProbR Î¨(A) =E(x,y)âˆ¼Âµ[max{â„“(1A(x), y),Î¨ (Pxâ€²âˆ¼mx[â„“(1A(xâ€²), y)])}].
Besides the choice Î¨(t) =1t>panother interesting choice is the smallest concave function
which lies above it, i.e., Î¨(t) = min {t/p,1}. For this choice we can connect the probabilistic
risk with the conditional value at risk (CVaR) [31] which was suggested in [30] as a com-
putationally feasible replacement for the p-ess supoperator in problem (PRL). Its precise
definition will be important later and can be found in (37) in Section 5.
Proposition 3. For the 0-1lossâ„“(Ëœy, y) :=1ËœyÌ¸=yand for Î¨p(t) := min {t/p,1}withpâˆˆ(0,1)
it holds that
ProbR Î¨p(A) =E(x,y)âˆ¼Âµ[max{â„“(1A(x), y),CVaR p(â„“(1A(Â·), y);mx)}].
We proceed to prove Proposition 2.
Proof of Proposition 2. The proof is similar to that of Proposition 1 after noting that for
Î¨ : [0 ,1]â†’[0,1]
1xâˆˆA+1xâˆˆAcÎ¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆA]) = max {1xâˆˆA,Î¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆA])}
which can easily be shown by checking cases. Then:
ProbR Î¨(A) =Z
X1xâˆˆAdÏ0(x) +Z
X1xâˆˆAcdÏ1(x)
+Z
X1xâˆˆAcÎ¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆA]) dÏ0(x) +Z
X1xâˆˆAÎ¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆAc]) dÏ1(x)
=Z
X[1xâˆˆA+1xâˆˆAcÎ¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆA])] dÏ0(x)
+Z
X[1xâˆˆAc+1xâˆˆAÎ¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆAc])] dÏ1(x)
=Z
Xmax{1xâˆˆA,Î¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆA])}dÏ0(x)
+Z
Xmax{1xâˆˆAc,Î¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆAc])}dÏ1(x).
â–¡
11We postpone the proof of Proposition 3, which discusses another reformulation of ProbR Î¨
in terms of the so-called conditional value at risk (CVaR), to Section 5, since Proposition 3
will not be used in the remainder of this section.
2.2.Model family for hard classifiers. We now begin the discussion of existence of
solutions to the minimization problems associated with the risks RÎ¨andProbR Î¨defined in
(7) and (8). As was discussed in the introduction, these families of risks include Rproband
ProbR(forÎ¨(t) :=1t>p) but also a relaxation of the adversarial risk Radv(forÎ¨(t) :=1t>0).
We start our discussion by making our setting precise.
Assumption 1. We let Xbe a set and A âŠ‚ 2Xbe a Ïƒ-algebra. We assume that:
â€¢(X Ã— Y ,A âŠ—2{0,1}, Âµ)is a probability space;
â€¢(X,A, Ï)is a probability space, where we define Ï(â€¢) :=Âµ(â€¢ Ã— { 0,1});
â€¢ {mx}xâˆˆXis a family such that (X,A,mx)is a probability space for Ï-almost every
xâˆˆ X.
We also define the probability measures
Ï:=Ï0+Ï1, (12)
Î½(A) :=1
2Z
Xmx(A) dÏ(x) +1
2Ï(A), A âˆˆ A. (13)
The measure Ïequals the first marginal of Âµand models the distribution of all data, irre-
spective of their label. The first summand of the measure Î½is the convolution of Ïwith the
family of probability measures {mx}xâˆˆX.
By construction we have the following two important properties:
Î½(A) = 0 = â‡’h
Ï(A) = 0and mx(A) = 0forÏ-almost every xâˆˆ Xi
, (14)
Ï(A) = 0 = â‡’h
Ï0(A) = 0and Ï1(A) = 0i
. (15)
A simple example for X=RdisÏ:=1
NPN
i=1Î´xiandmx:= Unif( BÎµ(x))in which case
Î½=1
2NNX
i=1
Unif( BÎµ(xi)) +Î´xi
is a sum of absolutely continuous measures on balls centered at xiand the empirical measure
of the points xi.
Using the measure Î½we will work with the weak-* topology of Lâˆ(X;Î½)which is the dual
space of L1(X;Î½)since Î½isa fortiori aÏƒ-finite measure [15, IV.8.3, Theorem 5].
Definition 1. Under Assumption 1 we say that a sequence of functions (un)nâˆˆNâŠ‚Lâˆ(X;Î½)
converges to uâˆˆLâˆ(X;Î½)in the weak-* sense (written unâˆ—â‡€ u) asnâ†’ âˆif
lim
nâ†’âˆZ
XunÏ†dÎ½=Z
XuÏ†dÎ½âˆ€Ï†âˆˆL1(X;Î½). (16)
We will use this topology to prove existence of minimizers of the probabilistic risks RÎ¨
andProbR Î¨. Furthermore, we use this same topology for proving that our modified PRL
using the function Î¨pconverges to adversarial training as pâ†’0, at least when the family
of measures {mx}xsatisfies a suitable assumption; see the discussion in Section 4.
12The following theorem establishes existence of minimizers of the risk ProbR Î¨for concave
and non-decreasing functions Î¨.
Interestingly, we establish the existence of hard classifiers using a novel abstract strategy,
rather than the usual direct method in the calculus of variations. We take this approach as
it is rather nontrivial to establish lower semicontinuity for an extension of ProbPer Î¨to soft
classifiers that behaves well with respect to thresholding operations. Instead, we introduce
twodifferentrelaxations; onewhichislowersemicontinuous, andonewhichisdefinedthrough
a coarea formula and hence behaves well with respect to thresholding; our result then follows
from an ordering relation on the two relaxations if Î¨is concave and non-decreasing.
We arrive at the rigorous versions of Informal Theorem 1 and Informal Theorem 2.
Theorem 1. Suppose Î¨ : [0 ,1]â†’[0,1]is concave and non-decreasing, and that Assump-
tion 1 holds. Then, there exists a solution to the problem
inf
AâˆˆAProbR Î¨(A). (17)
Theorem 2. Suppose Î¨ : [0 ,1]â†’[0,1]is concave and non-decreasing, and that Assump-
tion 1 holds. Then, there exists a solution to the problem
inf
AâˆˆARÎ¨(A). (18)
The proofs of Theorems 1 and 2 are provided in Section 2.4. The reason why an existence
proof for (17) (or (18)) for non-concave functions Î¨is currently not available is illustrated
in the following example.
(a)Homogenizing minimizer for Î¨(t) :=1t>p.
 (b)Superlevel set which is not a minimizer.
Figure 2. Non-compactness of minimizing sequences.
Example 1 (Homogenizing solutions) .In this example we consider the situation of two data
points (red and blue) which are so close that the Îµ-balls around them intersect. Furthermore,
we assume that pâˆˆ(0,1)is0.9times the ratio of the volume of the intersection to the
volume of one Îµ-ball. If we pick Î¨p=1t>p, there exist infinitely many minimizers of (17)
with oscillatory boundaries in the intersection. One such minimizer is depicted in Figure 2a.
The minimizers can be arranged such that the ratios of the red or the blue volume to the
volume of the intersection are in the interval [0.4,0.6]. Consequently, all such sets have
zero loss and are global minimizers. However, the set of such minimizers is not compact
and has an accumulation point which is not a characteristic function, namely the function
u:X â†’ [0,1]with values u= 1on the red ball without the blue ball, u= 0on the blue ball
13without the red ball, and u= 0.5on the intersection of the two balls. Hence, minimizing
sequences of (17) are not compact. The issue of non-compactness of minimizing sequences
can in fact also happen for concave functions Î¨which is why in the proof of Theorem 1 we
show that almost every superlevel set {u > t}of a function uwhich is an accumulation point
of a minimizing sequences is a minimizer of (17). However, not even this strategy works in
the non-concave case since the superlevel set {u > t}for all tâˆˆ[0,1/2]is given by the set
in Figure 2b which is not a minimizer of PRL.
2.3.Model family for soft classifiers. Note that, besides the reasons given in Exam-
ple 1, an existence result similar to Theorem 1 for the non-concave function Î¨(t) =1t>pis
currently not available since our relaxation techniques rely on concavity of Î¨. However, in
this section we shall state an existence theorem for â€œsoft classifiersâ€ which is valid for very
general functions Î¨, including Î¨(t) =1t>p, since no relaxation is needed.
Such soft classifiers are particularly relevant since they include neural network based mod-
els with Softmax activation in the last layer which are used in practice. A suitable regular-
ization functional for soft classifiers is given by ProbJ Î¨defined in (10). For convenience we
repeat its definition. Given an A-measurable function u:X â†’ [0,1]we let
ProbJ Î¨(u) :=Z
X(1âˆ’u(x)) Î¨ (Exâ€²âˆ¼mx[u(xâ€²)]) dÏ0(x)
+Z
Xu(x)Î¨ (Exâ€²âˆ¼mx[1âˆ’u(xâ€²)]) dÏ1(x)
which satisfies ProbJ Î¨(1A) = ProbPer Î¨(A)for every choice of Î¨. Hence, it is a natural
generalization of the perimeter to soft classifiers and one could call ProbJ Î¨a total variation.
However, it is neither positively homogeneous nor convex so this name would be misleading.
Instead, for the proof of Theorem 1 we shall also work with the total variation functional
ProbTV Î¨defined as
ProbTV Î¨(u) :=Z1
0ProbPer Î¨({u > t}) dt, (19)
for all A-measurable functions u:X â†’ [0,1]. Note that also the total variation satisfies
ProbTV Î¨(1A) = ProbPer Î¨(A). Both ProbJ Î¨andProbTV Î¨are of paramount importance
for the proof of Theorem 1.
The next theorem is the rigorous version of Informal Theorem 3 and asserts existence of
soft classifiers for the regularized risk minimization using ProbJ Î¨for very general functions
Î¨and hypothesis classes H. It is sufficient that Î¨is lower semicontinuous which is satisfied
by every continuous function and also by Î¨(t) = 1t>pforpâˆˆ[0,1]. Furthermore, the
existence theorem is valid for all hypotheses classes which are closed in the weak-* topology
ofLâˆ(X;Î½).
Theorem 3 (Existence of soft classifiers for modified PRL) .Under Assumption 1, for every
lower semicontinuous function Î¨ : [0 ,1]â†’[0,1], and whenever His a weak-* closed hypoth-
esis class of A-measurable functions u:X â†’ [0,1]in the sense of Definition 1, there exists
a solution to the problem
inf
uâˆˆHE(x,y)âˆ¼Âµ[|u(x)âˆ’y|] + ProbJ Î¨(u). (20)
14Example 2 (Hypothesis classes) .The hypothesis class consisting of measurable sets, i.e.,
H={1A:Aâˆˆ A}is not weak-* closed which is why Theorem 1 needs stronger assumptions
onÎ¨than Theorem 3. Let us instead consider three interesting hypothesis classes of weak-*
closed (in fact, even compact) classifiers for which Theorem 3 applies.
(1) Thesimplestsuchclass Histheclassof allA-measurablesoftclassifiers u:X â†’ [0,1]
whichcouldbereferredtoas agnostic classifierssincetheyarenotparametrized. This
class is a bounded subset of Lâˆ(X;Î½)and therefore, by the Banachâ€“Alaoglu theorem,
it is weak-* compact.
(2) An example with more practical relevance is the class of (feedforward or residual)
neural networks defined on the unit cube X:= [âˆ’1,1]dwith uniformly bounded
parameters
H:=n
Î¦Lâ—¦ Â·Â·Â· â—¦ Î¦1: [âˆ’1,1]dâ†’[0,1] : Î¦ l(â€¢) =Alâ€¢+Ïƒl(Wlâ€¢+bl),
âˆ¥(Al, Wl, bl)âˆ¥ â‰¤Câˆ€lâˆˆ {1, . . . , L }o
,
where we assume that the activations Ïƒl:Râ†’Rare continuous. Note that the
boundedness of the weights cannot be relaxed. To see this, consider the (very sim-
plistic) neural network un(x) = tanh( wnx)forxâˆˆ[âˆ’1,1]andwnâˆˆR. For wnâ†’ âˆ
it is easy to see that unconverges to u(x) := sign( x)which does not lie in the same
hypothesis class.
To argue why neural networks with bounded parameters and continuous activa-
tion functions are weak-* compact, let (un)nâˆˆNâŠ‚ Hbe a sequence. Thanks to
finite-dimensional compactness a subsequence of the associated parameters converge
to some limiting parameters. The continuity of the activations implies that the as-
sociated neural networks converge (uniformly in the space of continuous functions
on the unit cube [âˆ’1,1]d) to a limiting neural network uâˆˆ H. In particular, the
convergence is true in the weak-* sense, which shows that His weak-* compact.
(3) Finally, one can also consider the class of hard linear classifiers on Rd. Letting
Î¸(t) :=1t>0denote the Heaviside function, this class is given by
H:=
Î¸(wÂ·x+b) :wâˆˆRd,|w|= 1, bâˆˆ[âˆ’âˆ,âˆ]	
,
where one interprets u(x) :=Î¸(wÂ·x+b)asuâ‰¡1ifb=âˆanduâ‰¡0ifb=âˆ’âˆ.
If the distributions Ï0,Ï1, and mxare are such that Î½defined in (13) has a density
with respect to the Lebesgue measure, then Hhas the desired closedness property. A
sufficient condition for this to hold is that Ï0,Ï1, and mxhave densities with respect
to the Lebesgue measure.
Let us prove the closedness under the above conditions. If (un)nâˆˆNâŠ‚ His a
sequence of linear classifiers, thanks to finite-dimensional compactness a subsequence
(which we do not relabel) of the associated parameters (wn, bn)converges to wâˆˆRd
with|w|= 1andbâˆˆ[âˆ’âˆ,âˆ]. For simplicity we only consider the case where
bÌ¸=Â±âˆ. In this case one can define the half-spaces
An:=
xâˆˆRd:wnÂ·x+b >0	
,
A:=
xâˆˆRd:wÂ·x+b >0	
,
15upon which unanduare supported. Then for any Ï•âˆˆL1(Rd;Î½)it holds
Z
Rd(unâˆ’u)Ï•dÎ½=Z
AnÏ•dÎ½âˆ’Z
AÏ•dÎ½â‰¤Z
Anâ–³A|Ï•|dÎ½
where we used the symmetric difference Anâ–³A:= (An\A)âˆª(A\An). Note that
this set is either a double cone (if wnÌ¸=w) or a strip of width |bnâˆ’b|(ifwn=w).
Since Ï•âˆˆL1(Rd;Î½)andÎ½is a probability measure, for every Îµ >0there exists a
compact set KâŠ‚Rdsuch thatR
Rd\K|Ï•|dÎ½ < Îµ. Using this, we can compute
Z
Rd(unâˆ’u)Ï•dÎ½â‰¤Z
Anâ–³A|Ï•|dÎ½â‰¤Z
(Anâ–³A)âˆ©K|Ï•|dÎ½+Îµ.
Using that Î½has a density with respect to the Lebesgue measure Ldand using also
thatLd(Anâ–³Aâˆ©K)â†’0asnâ†’ âˆ, we obtain
lim
nâ†’âˆZ
Rd(unâˆ’u)Ï•dÎ½â‰¤Îµ
and since Îµ >0was arbitrary we get
lim
nâ†’âˆZ
Rd(unâˆ’u)Ï•dÎ½= 0,
which implies the weak-* convergence of untouâˆˆ Hand hence the weak-* compact-
ness of H.
Note that for general measures Î½the above argument fails. For instance,the se-
quence of linear classifiers un(x) = 1x1>âˆ’1/nhas the natural limit u(x) = 1x1>0.
However, if Î½=Î´0thenR
RdundÎ½= 1for all nâˆˆNbutR
RdudÎ½= 0, meaning that u
is not the weak-* limit of un.
Similarly, we can state a precise version of Informal Theorem 4. For this, it is convenient
to introduce the probability measure Ïƒdefined via
Ïƒ(A) :=Z
Xmx(A) dÏ(x), (21)
which clearly satisfies
(22) Ïƒ(A) = 0 = â‡’mx(A) = 0forÏ-almost every xâˆˆ X.
Theorem 4 (Existence of soft classifiers for original PRL) .Under Assumption 1, for every
lower semicontinuous function Î¨ : [0 ,1]â†’[0,1], and whenever His a hypothesis class of
A-measurable functions u:X â†’ [0,1]that is closed in the weak* topology of Lâˆ(X;Ïƒ), there
exists a solution to the problem
inf
uâˆˆHZ
XÎ¨ (Exâ€²âˆ¼mx[u(xâ€²)]) dÏ0(x) +Z
XÎ¨ (Exâ€²âˆ¼mx[1âˆ’u(xâ€²)]) dÏ1(x). (23)
162.4.Existence proofs. In this section we will prove all theorems stated in the previous
section using the direct method of calculus of variations together with new relaxation ar-
guments. For this we first outline our proof strategy in a very abstract way by using the
quadruple
Q:= (R, S, T, T), (24)
where R:A â†’ [0,âˆ]is a functional defined on A-measurable sets, S, T :U â†’ [0,âˆ]
are proper functionals defined on the unit ball U:={u:X â†’ [0,1]A-measurable }of the
A-measurable functions, and Tis a topology on the unit ball. The key ingredients and
properties of Qare the following:
(D1)Compactness :Uis compact with respect to T;
(D2)Lower semicontinuity : For all sequences of measurable functions (un)nâˆˆNâŠ‚ Ucon-
verging to uâˆˆ Uin the topology Tit holds
S(u)â‰¤lim inf
nâ†’âˆS(un);
(D3)Consistency : It holds for all Aâˆˆ Athat
R(A) =S(1A).
(D4)Coarea formula : For all uâˆˆ Uit holds
T(u) =Z1
0R({uâ‰¥t}) dt,
and in particular R(A) =T(1A)for all Aâˆˆ A;
(D5)Ordering : For all uâˆˆ Uit holds
T(u)â‰¤S(u).
Under these conditions we can prove the following meta-theorem.
Meta Theorem 1. Assuming desiderata (D1) and (D2) there exists
uâˆˆargminuâˆˆUS(u). (25)
Assuming desiderata (D1) to (D5), for Lebesgue almost every tâˆˆ[0,1]the set At:={uâ‰¥t}
satisfies
AtâˆˆargminAâˆˆAR(A). (26)
Proof.Since Sis proper, there exists a minimizing sequence {un}nâˆˆNâŠ‚ Ufor (25). By
assumption, {un}nâˆˆNis precompact in the topology T. Therefore, up to a subsequence that
we do not relabel, we can assume that unâ†’Tufor some u:X â†’ [0,1]which solves (25) by
lower semicontinuity of S.
Defining At:={uâ‰¥t}fortâˆˆ[0,1]it holds
inf
AâˆˆAR(A) =Z1
0inf
AâˆˆAR(A) dtâ‰¤Z1
0R(At) dt=T(u)â‰¤S(u)â‰¤S(1A) =R(A)âˆ€Aâˆˆ A,
17and therefore, after taking the infimum over Aâˆˆ A, we get
Z1
0R(At) dt= inf
AâˆˆAR(A). (27)
Let us assume that for a subset NâŠ‚[0,1]of positive Lebesgue measure it holds
inf
AâˆˆAR(A)< R(At)âˆ€tâˆˆN.
Integrating this inequality and using (27) we would then have
inf
AâˆˆAR(A)<Z1
0R(At) dt= inf
AâˆˆAR(A),
which is a contradiction. Hence we have proved that for Lebesgue almost every tâˆˆ[0,1]the
setAtsolves (26). â–¡
To use this theorem we need to specify Qand verify the desiderata. We consider the
following choices:
R(A) := ProbR Î¨(A), Aâˆˆ A,
S(u) :=E(x,y)âˆ¼Âµ[|u(x)âˆ’y|] + ProbJ Î¨(u), uâˆˆ U,
T(u) :=E(x,y)âˆ¼Âµ[|u(x)âˆ’y|] + ProbTV Î¨(u), uâˆˆ U,
T:=weak-* topology of Lâˆ(X;Î½),
where Î½was defined in (13). We note that desideratum (D1) follows from the Banachâ€“
Alaoglu theorem. By definition of the functionals ProbJ Î¨andProbTV Î¨in (10) and (19)
the desiderata (D3) and (D4) are satisfied, as well. It remains to prove the lower semiconti-
nuity desideratum (D2) and the ordering desideratum (D5).
We start with the following lemma:
Lemma 1. Under Assumption 1, let Î½be a measure on Xwhich satisfies mxâ‰ªÎ½forÏ-
almost every xâˆˆ X, and let (un)nâˆˆNâŠ‚Lâˆ(X;Î½)satisfy unâˆ—â‡€ uin the sense of Definition 1.
Then it holds
lim
nâ†’âˆExâ€²âˆ¼mx[un(xâ€²)] =Exâ€²âˆ¼mx[u(xâ€²)]forÏ-almost every xâˆˆ X.
Proof.UsingtheRadonâ€“NikodÃ½mtheorem, theweak-*convergenceimpliesthatfor Ï-almost
every xâˆˆ Xit holds
lim
nâ†’âˆExâ€²âˆ¼mx[un(xâ€²)] = lim
nâ†’âˆZ
Xun(xâ€²) dmx(xâ€²) = lim
nâ†’âˆZ
Xun(xâ€²)dmx
dÎ½(xâ€²) dÎ½(xâ€²)
=Z
Xu(xâ€²)dmx
dÎ½(xâ€²) dÎ½(xâ€²) =Z
Xu(xâ€²) dmx(xâ€²) =Exâ€²âˆ¼mx[u(xâ€²)]
sincedmx
dÎ½âˆˆL1(X;Î½). â–¡
Using Lemma 1 it is relatively straightforward to prove lower semicontinuity of ProbJ Î¨if
Î¨is a continuous function. If, however, Î¨is only lower semicontinuous, e.g., Î¨(t) =1t>p,
we will employ a suitable approximation from below of Î¨by continuous functions.
18Proposition 4 (Lower semicontinuity of ProbJ Î¨).Under Assumption 1 let (un)nâˆˆNâŠ‚
Lâˆ(X;Î½)be a sequence of functions with values in [0,1]satisfying unâˆ—â‡€ uin the sense
of Definition 1, and let Î¨ : [0 ,1]â†’[0,1]be lower semicontinuous. Then 0â‰¤uâ‰¤1holds
Î½-almost everywhere and furthermore
ProbJ Î¨(u)â‰¤lim inf
nâ†’âˆProbJ Î¨(un).
Proof.First we show that 0â‰¤uâ‰¤1. By the weak-* lower semicontinuity of the Lâˆ-norm
we get uâ‰¤1from the fact that 0â‰¤unâ‰¤1. To show that uâ‰¥0we assume that on a
measurable set Nwith Î½(N)>0it holds u <0. Then from the weak-* convergence and the
fact that unâ‰¥0we obtain
0>Z
Xu1NdÎ½= lim
nâ†’âˆZ
Xun1NdÎ½â‰¥0
which is a contradiction. Therefore, uâ‰¥0holds Î½-almost everywhere.
Since both terms in the definition of ProbJ Î¨are dealt with symmetrically, we assume
without loss of generality and for an easier notation that Ï1= 0and rewrite ProbJ Î¨as
ProbJ Î¨(u) =Z
X(1âˆ’u(x)) Î¨ (Exâ€²âˆ¼mx[u(xâ€²)]) dÏ0(x).
Since Î¨is lower semicontinuous there exists a sequence of continuous functions Î¨Î´: [0,1]â†’
[0,1]which converge to Î¨in the pointwise sense as Î´â†’0and satisfy Î¨Î´â‰¤Î¨. For instance,
the functions
Î¨Î´(t) := inf
sâˆˆ[0,1]Î¨(s) +1
Î´|sâˆ’t|, t âˆˆ[0,1],
suffice. Lemma1impliesthat Exâ€²âˆ¼mx[un(xâ€²)]â†’Exâ€²âˆ¼mx[u(xâ€²)]forÏ-almostevery xasnâ†’ âˆ.
Since Î¨Î´is continuous, we get Î¨Î´(Exâ€²âˆ¼mx[un(xâ€²)])â†’Î¨Î´(Exâ€²âˆ¼mx[u(xâ€²)])forÏ-almost every
xasnâ†’ âˆ. Since 0â‰¤unâ‰¤1and hence Î¨Î´(Exâ€²âˆ¼mx[un(xâ€²)])is uniformly bounded, the
convergence even holds true in L1(X;Ï). Taking into account (15), this implies convergence
inL1(X;Ï0)and therefore
lim
nâ†’âˆZ
X(1âˆ’un(x)) Î¨ Î´(Exâ€²âˆ¼mx[un(xâ€²)]) dÏ0(x)
=Z
X(1âˆ’u(x)) Î¨ Î´(Exâ€²âˆ¼mx[u(xâ€²)]) dÏ0(x).(28)
Next we would like to use the Fatou lemma to take the limit as Î´â†’0on both sides. For
this we notice that the sequence of functions
fÎ´(x) := (1 âˆ’un(x)) Î¨ Î´(Exâ€²âˆ¼mx[un(xâ€²)])
converges to (1âˆ’un(x)) Î¨ (Exâ€²âˆ¼mx[un(xâ€²)])pointwise as Î´â†’0and satisfies the bounds
fÎ´â‰¥0. Thanks to the non-negativity we can apply the standard Fatou lemma. Using
19Î¨Î´â‰¤Î¨and (28) we get
ProbJ Î¨(u) =Z
X(1âˆ’u(x)) Î¨ (Exâ€²âˆ¼mx[u(xâ€²)]) dÏ0(x)
â‰¤lim inf
Î´â†’0Z
X(1âˆ’u(x)) Î¨ Î´(Exâ€²âˆ¼mx[u(xâ€²)]) dÏ0(x)
= lim inf
Î´â†’0lim
nâ†’âˆZ
X(1âˆ’un(x)) Î¨ Î´(Exâ€²âˆ¼mx[un(xâ€²)]) dÏ0(x)
â‰¤lim inf
nâ†’âˆZ
X(1âˆ’un(x)) Î¨ (Exâ€²âˆ¼mx[un(xâ€²)]) dÏ0(x)
= lim inf
nâ†’âˆProbJ Î¨(un).
â–¡
We recall the definition of the total variation in (19) for which we now prove the following
ordering with respect to ProbJ Î¨defined in (10) in case that Î¨is concave and non-decreasing.
Proposition 5. IfÎ¨is concave and non-decreasing it holds for every A-measurable function
u:X â†’ [0,1]that
ProbTV Î¨(u)â‰¤ProbJ Î¨(u).
Proof.As in the proof of Proposition 4 we assume without loss of generality that Ï1= 0.
We compute
ProbTV Î¨(u) =Z1
0ProbPer Î¨({uâ‰¥t}) dt
=Z
XZ1
01u(x)<tÎ¨ (Pxâ€²âˆ¼mx[u(xâ€²)â‰¥t]) dtdÏ0(x)
=Z
XZ1
01u(x)<tÎ¨ 
Exâ€²âˆ¼mx
1{uâ‰¥t}(xâ€²)
dtdÏ0(x)
=Z
XZ1
u(x)Î¨ 
Exâ€²âˆ¼mx
1{uâ‰¥t}(xâ€²)
dtdÏ0(x). (29)
Since Î¨is concave and non-decreasing, we get from (29) and Jensenâ€™s inequality that
ProbTV Î¨(u)â‰¤Z
X(1âˆ’u(x)) Î¨1
1âˆ’u(x)Z1
u(x)Exâ€²âˆ¼mx
1{uâ‰¥t}(xâ€²)
dt
dÏ0(x)
=Z
X(1âˆ’u(x)) Î¨1
1âˆ’u(x)Exâ€²âˆ¼mxZ1
u(x)1{uâ‰¥t}(xâ€²) dt
dÏ0(x)
=Z
X(1âˆ’u(x)) Î¨1
1âˆ’u(x)Exâ€²âˆ¼mxh 
u(xâ€²)âˆ’u(x)
+i
dÏ0(x)
â‰¤Z
X(1âˆ’u(x)) Î¨1
1âˆ’u(x)Exâ€²âˆ¼mx[u(xâ€²)(1âˆ’u(x))]
dÏ0(x)
=Z
X(1âˆ’u(x)) Î¨ (Exâ€²âˆ¼mx[u(xâ€²)]) dÏ0(x) = ProbJ Î¨(u).
20â–¡
A remarkable consequence of this lower bound and the lower semicontinuity of ProbJ Î¨
from Proposition 4 is the following proof of lower semicontinuity of ProbTV Î¨for sequences
of characteristic functions that doesnâ€™t use any abstract functional analysis machinery).
Corollary 1. Let(An)âŠ‚ Abe a sequence of measurable sets such that 1Anâˆ—â‡€ uinLâˆ(X;Î½).
Then it holds
ProbTV Î¨(u)â‰¤lim inf
nâ†’âˆProbTV Î¨(1An).
Proof.The result follows from Propositions 4 and 5 and the following computation
ProbTV Î¨(u)â‰¤ProbJ Î¨(u)â‰¤lim inf
nâ†’âˆProbJ Î¨(1An) = lim inf
nâ†’âˆProbPer Î¨(An)
= lim inf
nâ†’âˆProbTV Î¨(1An).
â–¡
Now we are ready to prove Theorems 1 and 3 as special cases of the meta-theorem in the
beginning of this section.
Proof of Theorem 1 . TheresultfollowsfromMetaTheorem1noticingthatdesideratum(D5)
follows from Proposition 5 and desideratum (D2) follows from Proposition 4 together with
thetriviallowersemicontinuityofthestandardrisk u7â†’E(x,y)âˆ¼Âµ[|u(x)âˆ’y|]since Ïâ‰ªÎ½.â–¡
We remark that the main issue with proving the existence result of Theorem 1 for non-
concave functions Î¨is that the ordering desideratum (D5) is violated which was essential
for the proof of Meta Theorem 1.
However, if we already consider the relaxed problem (20) of optimizing over soft classifiers
instead of characteristic functions and regularizing with ProbJ Î¨, no ordering is necessary
and we obtain existence for very general functions Î¨.
Proof of Theorem 3. The result is the first part of Meta Theorem 1 for the choices made in
the proof of Theorem 1. â–¡
Remark 4. From the proof of Meta Theorem 1 it follows that when Î¨is concave and
non-decreasing, then
min
AâˆˆAProbR Î¨(A) = min
uâˆˆUProbS Î¨(u),
where
(30) ProbS Î¨(u) :=E(x,y)âˆ¼Âµ[|u(x)âˆ’y|] + ProbJ Î¨(u).
Next we discuss the existsence results for the original PRL model.
Proof of Theorem 2. We apply Meta Theorem 1 with the choices R= R Î¨andS=SÎ¨,
where SÎ¨is defined over soft classifiers u:X â†’ [0,1]according to:
SÎ¨(u) :=Z
XÎ¨ (Exâ€²âˆ¼mx[u(xâ€²)]) dÏ0(x) +Z
XÎ¨ (Exâ€²âˆ¼mx[1âˆ’u(xâ€²)]) dÏ1(x), (31)
21which by definition satisfies SÎ¨(1A) = R Î¨(A). We also consider the functional
T(u) :=Z1
0R({uâ‰¥t}) dt.
As topology Twe choose the weak-* topology of Lâˆ(X;Ïƒ)where the probability measure
Ïƒis as in (21).
It is straightforward to check that the quadruple Q:= (R, S, T, T)satisfies all five require-
ments for Meta Theorem 1 to be applicable: (1) is clear, (2) is proved as Proposition 4 using
Lemma 1 with Ïƒinstead of Î½, (3) and (4) are trivial consequences of the definitions, and (5)
is an easy consequence of the layer cake representation and Jensenâ€™s inequality for concave
Î¨. Note that (5) is only true if Î¨is concave. â–¡
Proof of Theorem 4. The result is the first part of Meta Theorem 1 for the choices made in
the proof of Theorem 2. â–¡
Remark 5. As in Remark 5, it is easy to verify that when Î¨is concave and non-decreasing,
then
min
AâˆˆARÎ¨(A) = min
uâˆˆUSÎ¨(u).
3.The functional ProbPer Î¨as a perimeter
In this section we shall discuss the interpretation of the functional ProbPer Î¨defined in
(9) as aperimeter . We do this in two ways.
First, wefocusonthecasewhere Î¨isconcaveandnon-decreasingandprovethat ProbPer Î¨
is asubmodular functional . If, in addition, Î¨is assumed to satisfy Î¨(0) = 0 , then
ProbPer Î¨(X) = ProbPer Î¨(âˆ…) = 0 .
Following [11], for Î¨satisfying these properties one can interpret ProbPer Î¨as a generalized
perimeter, i.e., a functional that can be used to measure the â€œsizeâ€ of the boundary of a set.
This discussion is summarized in the next proposition.
Proposition 6. IfÎ¨(0) = 0 , then ProbPer Î¨(X) = ProbPer Î¨(âˆ…) = 0. IfÎ¨is concave and
non-decreasing, then the functional ProbPer Î¨is submodular, meaning that
ProbPer Î¨(AâˆªB) + ProbPer Î¨(Aâˆ©B)â‰¤ProbPer Î¨(A) + ProbPer Î¨(B)âˆ€A, Bâˆˆ A.
Example 3. ForÎ¨(t) =tour perimeter reduces to the perimeter on the random walk space
(X,m), introduced in [24]: ProbPer Î¨(A) =R
X\AR
AdmxdÏ0(x) +R
AR
X\AdmxdÏ1(x).
For proving Proposition 6 we need the following lemma.
Lemma 2. LetÎ¨ : [0 ,âˆ)â†’Rbe a concave and non-decreasing function, and let 0â‰¤aâ‰¤
bâ‰¤bâ€²â‰¤aâ€²be real numbers with a+aâ€²â‰¤b+bâ€². Then
Î¨(a) + Î¨( aâ€²)â‰¤Î¨(b) + Î¨( bâ€²).
Proof.Leta, aâ€², b, bâ€²be as stated. Since Î¨is concave and finite, it satisfies the fundamental
theorem of calculus and thus it is possible to write
Î¨(s) = Î¨( a) +Zs
aÎ¨â€²(r) dr, sâ‰¥a
22for a function Î¨â€²that is non-increasing and non-negative. It follows that
Î¨(b)âˆ’Î¨(a) =Zb
aÎ¨â€²(r) drâ‰¥(bâˆ’a)Î¨â€²(b)â‰¥(aâ€²âˆ’bâ€²)Î¨â€²(b)â‰¥Zaâ€²
bâ€²Î¨â€²(r) dr= Î¨( aâ€²)âˆ’Î¨(bâ€²),
which is precisely what we wanted to show. â–¡
With the above preliminary results in hand, we are ready to prove Proposition 6.
Proof of Proposition 6. First, the fact that ProbPer Î¨(X) = ProbPer Î¨(âˆ…) = 0ifÎ¨(0) = 0 is
easy to see from the definition of ProbPer Î¨. Second, we trivially have
Pxâ€²âˆ¼mx[xâ€²âˆˆAâˆªB] +Pxâ€²âˆ¼mx[xâ€²âˆˆAâˆ©B]â‰¤Pxâ€²âˆ¼mx[xâ€²âˆˆA] +Pxâ€²âˆ¼mx[xâ€²âˆˆB].
Define
aâ€²:=Pxâ€²âˆ¼mx[xâ€²âˆˆAâˆªB], bâ€²:=Pxâ€²âˆ¼mx[xâ€²âˆˆB]
b:=Pxâ€²âˆ¼mx[xâ€²âˆˆA], a :=Pxâ€²âˆ¼mx[xâ€²âˆˆAâˆ©B] ;
without the loss of generality we can assume that bandbâ€²defined above satisfy bâ‰¤bâ€², for
otherwise we can simply swap these labels. We can then use Lemma 2 to conclude that:
Î¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆAâˆªB]) + Î¨ ( Pxâ€²âˆ¼mx[xâ€²âˆˆAâˆ©B])
â‰¤Î¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆA]) + Î¨ ( Pxâ€²âˆ¼mx[xâ€²âˆˆB]).(32)
The submodularity follows directly once we have verified the following pointwise identity:
1xâˆˆ(AâˆªB)cÎ¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆAâˆªB]) +1xâˆˆ(Aâˆ©B)cÎ¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆAâˆ©B])
â‰¤1xâˆˆAcÎ¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆA]) +1xâˆˆBcÎ¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆB]).(33)
To do this we consider two complementary cases:
Case 1, xâˆˆ(AâˆªB)c:This is equivalent to xâˆˆAcâˆ©Bc. Furthermore, since (AâˆªB)câŠ‚
(Aâˆ©B)cwe also have that xâˆˆ(Aâˆ©B)c. Hence, all indicator functions in (33) take the
value one and (33) is the same as (32), which we have already verified.
Case 2, xâˆˆAâˆªB:In this case the first indicator function on the left hand side of (33)
is zero.
Case 2.1, xâˆˆAâˆ©B:In this subcase all indicator functions are equal to zero and the
inequality is trivially satisfied.
Case 2.2, xâˆˆAâˆªB\(Aâˆ©B):Without loss of generality we can assume that xâˆˆA\B=
Aâˆ©Bc. In this case only the second indicator function on the left hand side and the second
one on the right hand side of (33) take the value one and the inequality reduces to the trivial
inequality
Î¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆAâˆ©B])â‰¤Î¨ (Pxâ€²âˆ¼mx[xâ€²âˆˆB])
which is true since Î¨is non-decreasing and Aâˆ©BâŠ‚B. â–¡
Remark6. Fromthesubmodularityof ProbPer Î¨onecanshowthatthefunctional ProbTV Î¨
defined in (19) is convex. Indeed, this can be proved following the proof of Proposition 3.4
in [10], where, actually, we do not need to assume the lower semicontinuity of the functional
a priori.
23Next, we consider rather general Î¨and show that ProbPer Î¨is related to a standard local
perimeter when X=Rdand the probability measure mxlocalizes to a Dirac delta Î´x; for the
case of adversarial training such a connection was proved in [8], where the authors utilized
the notion of Î“-convergence of functionals. We take a first step in this direction by proving
that for sufficiently smooth sets the probabilistic perimeter converges to a local one if the
family of probability distributions mxlocalizes suitably. For example, one could think of
mx:= Unif( BÎµ(x)), which converges to a point mass at xifÎµâ†’0. To make our setting
precise, we pose the following general assumption:
Assumption 2. We assume that X=Rd,Î¨(0) = 0 ,Î¨is Borel measurable and bounded,
andÏ1, Ï0have continuous densities with respect to the Lebesgue measure which we shall
also denote as Ï1, Ï0. Furthermore, we assume that there is Îµ >0and a measurable function
K:X Ã—Rdâ†’[0,âˆ)such that for every xâˆˆRdwe have the representation
dmx(xâ€²) =Îµâˆ’dK
x,xâ€²âˆ’x
Îµ
dxâ€².
We also assume that for every xâˆˆ Xwe have K(x,â€¢)âˆˆL1(Rd),R
RdK(x, z) dz= 1,
K(x, z) = 0if|z|>1, and that for every zâˆˆRdthe mapping x7â†’K(x, z)is continuous.
In the more difficult case when Î¨is not necessarily continuous, we shall need some addi-
tional assumptions on the kernel.
Assumption 3. For our extra assumptions on the kernel, we shall require that for every
zâˆˆRdthe mapping x7â†’K(x, z)isC1and for every xâˆˆRdthe mapping z7â†’K(x, z)is
lower semicontinuous. Furthermore, for all xâˆˆRd,tâˆˆ(âˆ’1,1), and nâˆˆSdâˆ’1, the Radon
transform of Kwith respect to the z-variable
R(K(x,Â·))(n, t) :=Z
{zÂ·n=t}K(x, z) dHdâˆ’1(z)
is strictly positive.
The following theorem derives the asymptotics of the probabilistic perimeter as Îµâ†’0and
is the rigorous counterpart of Informal Theorem 6.
Theorem 5. LetX=Rd. Under Assumption 2, if Ahas a compact C1,1boundary and
either Î¨is continuous or Ksatisfies the additional Assumption 3, then
lim
Îµâ†’01
ÎµProbPer Î¨(A) =Z
âˆ‚AÏƒ0,Î¨[x, n(x)]Ï0(x) +Ïƒ1,Î¨[x, n(x)]Ï1(x) dHdâˆ’1(x), (34)
where we let n(x)denote the normal to âˆ‚Aat a point xâˆˆâˆ‚A, and for any vector vâˆˆRdwe
define
Ïƒ0
Î¨[x, v] :=Z1
0Î¨Z
{zÂ·vâ‰¤âˆ’t}K(x, z) dz
dt, Ïƒ1
Î¨[x, v] :=Z1
0Î¨Z
{zÂ·vâ‰¥t}K(x, z) dz
dt.
Remark7. IfKisradiallysymmetricandindependentof xâˆˆ X, then Ïƒ0
Î¨=Ïƒ1
Î¨=:ÏƒÎ¨isjust
a constant. E.g., for K(x, z) :=|B1(0)|âˆ’11|z|â‰¤1andÎ¨(t) =1t>pit is trivial that for p= 0we
have ÏƒÎ¨= 1. However, for pâ‰¥1
2one easily sees ÏƒÎ¨= 0, hence the limiting perimeter equals
zero and there is no regularization effect. Using the function Î¨(t) = min {t/p,1}corrects
this degeneracy.
24Notably, for radially symmetric Kthe limiting perimeter in (34) coincides, provided
ÏƒÎ¨>0, with the one derived for adversarial training (problem (2)) in [8], although they
considered more general (potentially discontinuous) densities Ïi. In particular, our result
indicates that for very small adversarial budgets the regularization effect of both proba-
bilistically robust learning and adversarial training is dominated by the perimeter in (34).
While Theorem 5 already completes half of the proof (namely the limsup inequality) of
Î“-convergence of1
ÎµProbPer Î¨to the limiting perimeter, the remaining liminf inequality is
beyond the scope of this paper. Proving that the convergence (34) does not only hold for
sufficiently smooth sets as assumed in Theorem 5 but even in the sense of Î“-convergence is
an extremely important topic for future work since only Î“-convergence allows to deduce from
the convergence of the perimeters that also the solutions of probabilistically robust learning
converge to certain regular Bayes classifiers as Îµâ†’0, see [8, Section 4.2]. The exploration
of this is left for future work.
Proof of Theorem 5. UnderAssumption 2, a simple change of variables shows
ProbPer Î¨(A) =Z
AcÎ¨Z
Rd1A(x+Îµz)K(x, z) dz
Ï0(x) dx
+Z
AÎ¨Z
Rd1Ac(x+Îµz)K(x, z) dz
Ï1(x) dx.
LetÏ„:Rdâ†’Rbe the signed distance function to âˆ‚Asuch that Ï„(x)â‰¤0forxâˆˆA. Using
Ï„, we can rewrite the previous line as
ProbPer Î¨(A) =Z
{Ï„(x)â‰¥0}Î¨Z
{Ï„(x+Îµz)â‰¤0}K(x, z) dz
Ï0(x) dx
+Z
{Ï„(x)â‰¤0}Î¨Z
{Ï„(x+Îµz)â‰¥0}K(x, z) dz
Ï1(x) dx.
Recalling that K(x, z) = 0whenever |z|>1, it follows that
ProbPer Î¨(A) =Z
{0â‰¤Ï„(x)â‰¤Îµ}Î¨Z
{Ï„(x+Îµz)â‰¤0}K(x, z) dz
Ï0(x) dx
+Z
{âˆ’Îµâ‰¤Ï„(x)â‰¤0}Î¨Z
{Ï„(x+Îµz)â‰¥0}K(x, z) dz
Ï1(x) dx.
In the rest of what follows, we will focus on proving that
lim
Îµâ†’01
ÎµZ
{0â‰¤Ï„(x)â‰¤Îµ}Î¨Z
{Ï„(x+Îµz)â‰¤0}K(x, z) dz
Ï0(x) dx=Z
âˆ‚AÏƒ0,Î¨[x, n(x)]Ï0(x) dHdâˆ’1(x),
the argument for showing that
lim
Îµâ†’01
ÎµZ
{âˆ’Îµâ‰¤Ï„(x)â‰¤0}Î¨Z
{Ï„(x+Îµz)â‰¥0}K(x, z) dz
Ï1(x) dx=Z
âˆ‚AÏƒ1,Î¨[x, n(x)]Ï1(x) dHdâˆ’1(x)
will be identical.
Since âˆ‚AisC1,1, there exists some Îµ0>0and such that for all Îµ < Îµ 0the map TÎµ(y, t) :
âˆ‚AÃ—[âˆ’1,1]â†’ {xâˆˆRd: 0â‰¤Ï„(x)â‰¤Îµ}given by TÎµ(y, t) =y+tn(y)is a bijection and
25Îµâˆ’1det(DTÎµ)converges uniformly to 1 as Îµâ†’0. Using this change of variables, we may
write
1
ÎµZ
{0â‰¤Ï„(x)â‰¤Îµ}Î¨Z
{Ï„(x+Îµz)â‰¤0}K(x, z) dz
Ï0(x) dx
=Z
âˆ‚AZ1
01
Îµdet(DTÎµ(y, t))Î¨ (aÎµ(y, t))Ï0(y+Îµtn(y)) dtdHdâˆ’1(y)
where we abbreviate
aÎµ(y, t) :=Z
{Ï„(y+Îµ(tn(y)+z))â‰¤0}K(y+Îµtn(y), z) dz
Since we know that limÎµâ†’0det(DTÎµ(y,t))
Îµ= 1andlimÎµâ†’0Ï0(y+Îµtn(y)) = Ï0(y)pointwise
almost everywhere, the main difficulty lies in passing to the limit in the term involving Î¨.
For this we shall first prove convergence of aÎµ(y, t)to
a(y, t) :=Z
{zÂ·n(y)â‰¤âˆ’t}K(y, z) dz
Sinceâˆ‡Ï„(y) =n(y)for any yâˆˆâˆ‚A, we have the expansion
Ï„(y+Îµ(tn(y) +z)) =Îµ(t+zÂ·n(y)) +O(Îµ2).
It now follows from our assumptions on Kthat for all yâˆˆâˆ‚Aand all tâˆˆ[0,1]
lim
Îµâ†’0aÎµ(y, t) =a(y, t).
IfÎ¨iscontinuous, theresultnowfollowsfromdominatedconvergence. If Î¨isnotcontinuous,
then we must work harder.
Since Î¨âˆˆL1([0,1])âˆ©Lâˆ([0,1]), we can always find a sequence of smooth functions Î¨n
such that âˆ¥Î¨nâˆ¥Lâˆ([0,1])â‰¤ âˆ¥Î¨âˆ¥Lâˆ([0,1])andÎ¨nconverges pointwise almost everywhere to Î¨
on[0,1]. If we can show that
lim
nâ†’âˆlim sup
Îµâ†’0Z
âˆ‚AZ1
0 
Î¨(aÎµ(y, t))âˆ’Î¨n(aÎµ(y, t))
dtdHdâˆ’1(y)= 0,
and
lim
nâ†’âˆZ
âˆ‚AZ1
0 
Î¨(a(t, y))âˆ’Î¨n(a(t, y))
dtdHdâˆ’1(y)= 0,
then we can safely approximate Î¨byÎ¨nand use the previous argument where Î¨was
continuous to conclude the result. Hence, it remains to show that the above integrals vanish.
Viewing aÎµas maps from âˆ‚AÃ—[0,1]â†’[0,1]we can construct measures ÂµÎµ, Âµon[0,1]via
pushforwards by setting
Z1
0g(s) dÂµÎµ(s) :=Z1
0Z
âˆ‚Ag(aÎµ(y, t)) dtdHdâˆ’1(y)
Z1
0g(s) dÂµ(s) :=Z1
0Z
âˆ‚Ag(a(y, t)) dtdHdâˆ’1(y)
26for any bounded continuous function g:âˆ‚AÃ—[0,1]â†’R. Using these definitions, we can
writeZ
âˆ‚AZ1
0 
Î¨(aÎµ(t, y))âˆ’Î¨n(aÎµ(t, y))
dtdHdâˆ’1(y)=Z
âˆ‚AZ1
0 
Î¨(s)âˆ’Î¨n(s)
dÂµÎµ(s),
andZ
âˆ‚AZ1
0 
Î¨(a(t, y))âˆ’Î¨n(aÎµ(t, y))
dtdHdâˆ’1(y)=Z
âˆ‚AZ1
0 
Î¨(s)âˆ’Î¨n(s)
dÂµ(s).
If we can show that the ÂµÎµare uniformly integrable on âˆ‚AÃ—[0,1](with respect to the product
measure dtdHdâˆ’1(y)) then the pointwise almost everywhere convergence of Î¨ntoÎ¨along
with the control âˆ¥Î¨nâˆ¥Lâˆ([0,1]â‰¤ âˆ¥Î¨âˆ¥Lâˆ([0,1]will imply that
lim
nâ†’âˆlim sup
Îµâ†’0Z
âˆ‚AZ1
0 
Î¨(tâ€²)âˆ’Î¨n(tâ€²)
dÂµÎµ(y, tâ€²)= 0,
and for free it will give us
lim
nâ†’âˆZ
âˆ‚AZ1
0 
Î¨(tâ€²)âˆ’Î¨n(tâ€²)
dÂµ(y, tâ€²)= 0,
since Âµis the distributional limit of the ÂµÎµ(from the pointwise convergence of aÎµtoa).
To prove that the ÂµÎµare uniformly integrable, we will show that |âˆ‚taÎµ|is strictly bounded
away from 0 whenever tis bounded away from 1. To do this, we shall need the additional
Assumption 3 on our kernel K. Let us first assume that KisC1in both variables. Changing
variables zâ€²=z+tn(y)we can write
aÎµ(y, t) =Z
{Ï„(y+Îµzâ€²)â‰¤0}K(y+Îµtn(y), zâ€²âˆ’tn(y)) dzâ€²,
and hence
âˆ‚taÎµ(y, t) =Z
{Ï„(y+Îµzâ€²)â‰¤0}Îµâˆ‡yK(y+Îµtn(y), zâ€²âˆ’tn(y))Â·n(y) dzâ€²
âˆ’Z
{Ï„(y+Îµzâ€²)â‰¤0}âˆ‡zâ€²K(y+Îµtn(y), zâ€²âˆ’tn(y))Â·n(y) dzâ€².
Since the second term is the complete derivative with respect to zâ€², we can integrate by parts
to obtain
âˆ‚taÎµ(y, t) =Z
{Ï„(y+Îµzâ€²)â‰¤0}Îµâˆ‡yK 
y+Îµtn(y), zâ€²âˆ’tn(y)
Â·n(y) dzâ€²
âˆ’Z
{Ï„(y+Îµzâ€²)=0}K 
y+Îµtn(y), zâ€²âˆ’tn(y)
n(y)Â· âˆ‡Ï„(y+Îµzâ€²) dHdâˆ’1(zâ€²)
Using the expansion âˆ‡Ï„(y+Îµz) =n(y) +O(Îµ)and the smoothness properties of K, we see
that
âˆ‚taÎµ(y, t) =âˆ’Z
{Ï„(y+Îµzâ€²)=0}K(y, zâ€²âˆ’tn(y)) dHdâˆ’1(zâ€²) +O(Îµ)
27where we note that the constant in the big O bound does not depend on the differentiability
ofKwith respect to the zvariable. Hence, after approximating Kwith C1kernels, we can
assume the above control holds for any kernel Ksatisfying both Assumptions 2 and 3.
Thus, for each fixed yâˆˆâˆ‚A, tâˆˆ[0,1]we have
lim inf
Îµâ†’0|âˆ‚taÎµ(t, y)| â‰¥Z
{zâ€²Â·n(y)=0}K(y, zâ€²âˆ’tn(y)) dHdâˆ’1(zâ€²) =Z
{zÂ·n(y)=âˆ’t}K(y, z) dHdâˆ’1(z),
where we have used the lower semicontinuity of Kwith respect to z. We can also now
recognize that the right hand side is the Radon transform R(K(y,Â·))(âˆ’t, n(y)). From our
additional Assumption 3, we know that R(K(y,Â·))(t, n(y))>0for each fixed yâˆˆâˆ‚A,
tâˆˆ(âˆ’1,1)andnâˆˆSdâˆ’1. Fix some Î´ > 0. Since the set âˆ‚AÃ—[0,1âˆ’Î´]Ã—Sdâˆ’1is
compact, it follows that there exists some cÎ´>0such that R(K(y,Â·))(âˆ’t, n(y))â‰¥cÎ´for all
yâˆˆâˆ‚A, n (y)âˆˆSdâˆ’1, tâˆˆ[0,1âˆ’Î´]. Therefore,
lim inf
Îµâ†’0|âˆ‚taÎµ(t, y)| â‰¥cÎ´
for all yâˆˆâˆ‚Aandtâˆˆ[0,1âˆ’Î´]. Thus, for all Îµ >0sufficiently small we have
|âˆ‚taÎµ(t, y)| â‰¥cÎ´/2
for all yâˆˆâˆ‚Aandtâˆˆ[0,1âˆ’Î´].
Now we are ready to show that ÂµÎµis uniformly integrable. Let L[a,b]denote the Lebesgue
measure on the interval [a, b]. From our work above, for all Îµ >0sufficiently small, we have
the inequality
ÂµÎµ=aÎµ# 
Hdâˆ’1
âˆ‚AâŠ— L [0,1]
â‰¤2Hdâˆ’1(âˆ‚A)
cÎ´L[0,1]+aÎµ# 
Hdâˆ’1
âˆ‚AâŠ— L [1âˆ’Î´,1]
.
Thus, for any measurable EâŠ‚[0,1], we have
ÂµÎµ(E)â‰¤2|E|Hdâˆ’1(âˆ‚A)
cÎ´+Z
aâˆ’1
Îµ(E)âˆ©(âˆ‚AÃ—[1âˆ’Î´,1])dtdHdâˆ’1(y)
â‰¤2|E|Hdâˆ’1(âˆ‚A)
cÎ´+Î´Hdâˆ’1(âˆ‚A).
Hence, for all Î´ >0,
lim
|E|â†’0lim sup
Îµâ†’0ÂµÎµ(E)â‰¤Î´Hdâˆ’1(âˆ‚A).
Thus, the ÂµÎµare uniformly integrable so we are done.
â–¡
4.Interpolation properties of probabilistically robust learning
In this section we discuss the limiting behavior of the energies ProbR Î¨pandRÎ¨p, for
Î¨p(t) := min {t/p,1}, aspâ†’0oras pgrows. Thislimitingbehaviorisstudiedinthesenseof
Î“-convergence, which, in particular, is closely connected to the convergence of minimizers of
the sequence of functionals. We start by recalling the definition of this notion of convergence
for functionals defined over arbitrary metric spaces.
Definition 2. Given a topological space (U, Ï„)and a sequence of functionals Fn:U â†’
[0,âˆ], and another functional F:U â†’ [0,âˆ], we say that the sequence of functionals Fn
Î“-converges toward F(with respect to the topology Ï„) if the following two conditions hold:
28(1)Liminf inequality: For any uâˆˆ Uand any sequence {un}nâˆˆNconverging (in the Ï„
topology) toward uwe have:
lim inf
nâ†’âˆFn(un)â‰¥F(u).
(2)Limsup inequality: For every uâˆˆ Uthere exists a sequence {un}nâˆˆNconverging
(in the Ï„topology) toward usuch that:
lim sup
nâ†’âˆFn(un)â‰¤F(u).
The relevance of the notion of Î“-convergence becomes apparent when an additional com-
pactness property holds.
Proposition 7 (Fundamental Theorem of Î“-convergence; see [4] and [14]) .Let(U, Ï„)be a
topological space. Let Fn:U â†’ [0,âˆ]be a sequence of functionals Î“-converging toward a
functional F:U â†’ [0,âˆ]that is not identically equal to +âˆ. Suppose, in addition, that the
sequence of functionals {Fn}nâˆˆNsatisfies the following compactness property: any sequence
{un}nâˆˆNsatisfying
sup
nâˆˆNFn(un)<âˆ
is precompact in the topology Ï„, i.e., every subsequence of {un}nâˆˆNhas a further subsequence
that converges to an element of U.
Then
lim
nâ†’âˆinf
uâˆˆUFn(u) = inf
uâˆˆUF(u).
Moreover, if unfor every nâˆˆNis a minimizer of Fn, then any cluster point of {un}nâˆˆNis
a minimizer of F.
For our analysis in this section it will be useful to define Î¨0(t) :=1t>0fortâ‰¥0, which is
a concave and non-decreasing function in its domain. The probabilistic perimeter associated
to this function is
ProbPer Î¨0(A) =Z
Ac1Pxâ€²âˆ¼mx[xâ€²âˆˆA]>0dÏ0(x) +Z
A1Pxâ€²âˆ¼mx[xâ€²âˆˆAc]>0dÏ1(x)
=Z
Acmx-ess sup 1AdÏ0(x) +Z
Amx-ess sup 1AcdÏ1(x),
and the corresponding probabilistic risk (8) can be written as
ProbR Î¨0(A) =Z
X(1Ac(x)Â·mx-ess sup 1A+1A(x)) dÏ0(x)
+Z
X(1A(x)Â·mx-ess sup 1Ac+1Ac(x)) dÏ1(x).
Likewise, the risk RÎ¨0takes the form
RÎ¨0(A) =Z
Xmx-ess sup 1AdÏ0(x) +Z
Xmx-ess sup 1c
AdÏ1(x).
We start by proving Î“-convergence of ProbR Î¨ptoward ProbR Î¨0aspâ†’0in the weak-*
topology of Lâˆ(X;Î½).
29Proposition 8 (Î“-convergence of modified PRL) .For the functions Î¨p(t) := min {t/p,1}
it holds that ProbPer Î¨pÎ“-converges to ProbPer Î¨0andProbR Î¨pÎ“-converges to ProbR Î¨0as
pâ†’0in the weak-* topology of Lâˆ(X;Î½), where Î½is as in(13).
Proof.Without loss of generality we assume Ï1= 0for a more concise notation.
We start with the liminf inequality. Let {Ap}pâˆˆ(0,1)be a sequence of sets such that 1Ap
converges to 1Aaspâ†’0in the weak-* sense. Then Lemma 1 implies that
lim
pâ†’0Pxâ€²âˆ¼mx[xâ€²âˆˆAp] = lim
pâ†’0Exâ€²âˆ¼mx
1Ap(xâ€²)
=Exâ€²âˆ¼mx[1A(xâ€²)] =Pxâ€²âˆ¼mx[xâ€²âˆˆA].
Next, we note that for 0< p < lit holds Î¨pâ‰¥Î¨l. Hence we get
ProbPer Î¨p(Ap)â‰¥Z
AcpÎ¨l(Pxâ€²âˆ¼mx[xâ€²âˆˆAp]) dÏ0(x)
=Z
X(1âˆ’1Ap)Î¨l(Pxâ€²âˆ¼mx[xâ€²âˆˆAp]) dÏ0(x).
As argued in the proof of Proposition 4, the functions x7â†’Î¨l(Pxâ€²âˆ¼mx[xâ€²âˆˆAp])converge
tox7â†’Î¨l(Pxâ€²âˆ¼mx[xâ€²âˆˆA])inL1(X;Ï0)aspâ†’0. Using this together with 1Apâˆ—â‡€1Ain
Lâˆ(X;Î½)and taking into account (14) and (15) we get
lim inf
pâ†’0ProbPer Î¨p(Ap)â‰¥Z
AcÎ¨l(Pxâ€²âˆ¼mx[xâ€²âˆˆA]) dÏ0(x).
Since l >0was arbitrary we can let lâ†’0and use Fatouâ€™s lemma to obtain
lim inf
pâ†’0ProbPer Î¨p(Ap)â‰¥Z
AcÎ¨0(Pxâ€²âˆ¼mx[xâ€²âˆˆA]) dÏ0(x) = ProbPer Î¨0(A).
For the limsup inequality we observe that, since Î¨pâ‰¤Î¨0for all pâˆˆ(0,1), it holds
ProbPer Î¨p(A)â‰¤ProbPer Î¨0(A)andthereforethelimsupinequality lim suppâ†’0ProbPer Î¨p(A)â‰¤
ProbPer Î¨0(A)is true for the constant sequence equal to A.
Being continuous perturbations of the probabilistic perimeters with respect to the weak-*
topology of Lâˆ(X;Î½), the probabilistic risks ProbR Î¨pare easily seen to Î“-converge to
ProbR Î¨0aspâ†’0; see the background section in [5]. â–¡
Remark 8. With essentially the same proof as in Proposition 8, one can show that ProbS Î¨p
Î“-converges in the weak-* topology of Lâˆ(X;Î½)toward the functional ProbS Î¨0aspâ†’0. We
recall that ProbS Î¨was introduced in (30) and corresponds to the l.s.c extension of ProbR Î¨
to soft classifiers.
Next, we discuss the Î“-convergence of RÎ¨ptoward RÎ¨0. This limiting energy may in
general be different from ProbR Î¨0.
Proposition 9 (Î“-convergence of original PRL) .For the functions Î¨p(t) := min {t/p,1}it
holds that RÎ¨pÎ“-converges to RÎ¨0aspâ†’0in the weak-* topology of Lâˆ(X;Ïƒ), where Ïƒis
as in(21).
Furthermore, the Î“-convergence also holds with respect to the weak* topology of Lâˆ(X;Î½),
where Î½is as in(13).
30Proof.For simplicity, we again assume Ï1= 0. The proof starts verbatim as the proof of
Proposition 8, using Lemma 1 with Ïƒinstead of Î½. Then one gets for 0< p < lthat
lim inf
pâ†’0RÎ¨p(Ap)â‰¥Z
XÎ¨l(Pxâ€²âˆ¼mx[xâ€²âˆˆA]) dÏ0(x).
Taking also the limit lâ†’0one obtains
lim inf
pâ†’0RÎ¨p(Ap)â‰¥Z
XÎ¨0(Pxâ€²âˆ¼mx[xâ€²âˆˆA]) dÏ0(x).
The limsup inequality is again trivial, using that Î¨pâ‰¤Î¨0for all p >0.
Wepointoutthat,sinceconstantsequencesworkforthelimsupinequality,the Î“-convergence
also holds with respect to any stronger topology as well. In particular, the Î“-convergence
holds under the weak-* topology of Lâˆ(X;Î½).
â–¡
Remark 9. With essentially the same proof as in Proposition 9, one can prove that SÎ¨p
Î“-converges in the weak-* topology of Lâˆ(X;Ïƒ)(or of Lâˆ(X;Î½)) toward the functional SÎ¨0
aspâ†’0. We recall that SÎ¨was introduced in (31) and corresponds to the l.s.c. extension
ofRÎ¨to soft classifiers.
The next example shows that the functionals ProbR Î¨0andRÎ¨0, the Î“-limits of modified
PRL and original PRL, respectively, may in general be different from each other.
Example 4. Consider the data distribution Âµ=1
2Î´(x0,0)+1
2Î´(x1,1)where x0= (a,0), x1=
(b,0)âˆˆR2with a < b. Let furthermore mx:= Unif( BÎµ(x))where 0< Îµ <|bâˆ’a|
2. Let
A:={x= (x1, x2)âˆˆR2:x1> a+bâˆ’a
2} âˆª {x0}. Then it follows that
ProbR Î¨0(A) = 1 /2>0 = R Î¨0(A).
While the energies ProbR Î¨0,RÎ¨0, and Radvmay in general be different, they are always
ordered, with Radvbeing the largest. This is the content of the next proposition.
Proposition 10. Suppose that for every xâˆˆ Xthe following identity holds mx(X \BÎµ(x)) =
0. Then for every measurable Athe following holds:
(35) RÎ¨0(A)â‰¤ProbR Î¨0(A)â‰¤Radv(A).
Proof.It is straightforward to show that the following pointwise identity holds for any mea-
surable set A:
sup
ËœxâˆˆBÎµ(x)1A(Ëœx)â‰¥1Ac(x)Â·mx-ess sup 1A+1A(x)â‰¥mx-ess sup 1A.
Applying this identity to Acwe get:
sup
ËœxâˆˆBÎµ(x)1Ac(Ëœx)â‰¥1A(x)Â·mx-ess sup 1Ac+1Ac(x)â‰¥mx-ess sup 1Ac.
Integrating the first chain of inequalities with respect to Ï0, the second with respect to Ï1,
and adding up the resulting expressions, we obtain (35).
â–¡
31Next, we specialize to the case where the admissible set of hard classifiers is A=B(X),
i.e., the set of all Borel measurable subsets of X(in the machine learning literature this is
an agnostic learning setting) and then show that, while ProbR Î¨0andRÎ¨0may be different,
their minimal values coincide with that of the adversarial training value functional Radvif we
impose some reasonable assumptions on the family of measures {mx}xâˆˆX. Our result implies
that, under Assumption 4 below, both PRL and modified PRL models are consistent with
AT, provided consistency is interpreted as consistency in minimal risks.
Assumption 4. For every xâˆˆsupp( Ï)(where supp( Ï)denotes the support of the Borel
probability measure Ï) the following conditions hold:
(1)mx(X \BÎµ(x)) = 0.
(2)BÎµ(x)âŠ†supp( mx).
(3) For every xâ€²âˆˆsupp( Ï)the measure mxâ€²âŒŠBÎµ(x)is absolutely continuous with respect
tomx.
Remark 10. Assumption 4 is very mild and in the Euclidean setting, when X=Rd, is
satisfied by the simple model mx= Unif( BÎµ(x)).
Theorem 6 (Consistency of optimal energies for PRL and modified PRL) .LetA=B(X)
be the Borel Ïƒ-algebra over X. Under Assumption 4,
lim
pâ†’0min
AâˆˆARÎ¨p(A) = min
AâˆˆARÎ¨0(A) = min
AâˆˆARadv(A),
as well as
lim
pâ†’0min
AâˆˆAProbR Î¨p(A) = min
AâˆˆAProbR Î¨0(A) = min
AâˆˆARadv(A),
where we recall Î¨p(t) = min {t/p,1}andÎ¨0(t) =1t>0.
Proof.Thanks to Remarks 8 and 9 and the Banachâ€“Alaoglu theorem, we can apply the
fundamental theorem of Î“-convergence (i.e., Proposition 7) to conclude that
lim
pâ†’0min
uâˆˆUSÎ¨p(u) = min
uâˆˆUSÎ¨0(u)
and
lim
pâ†’0min
uâˆˆUProbS Î¨p(u) = min
uâˆˆUProbS Î¨0(u).
In addition, since Î¨pis concave and non-decreasing for every pâ‰¥0, we have, thanks to
Remarks 4 and 5,
min
AâˆˆARÎ¨p= min
uâˆˆUSÎ¨p(u)
as well as
min
AâˆˆAProbR Î¨p= min
uâˆˆUProbS Î¨p(u).
Therefore
lim
pâ†’0min
AâˆˆARÎ¨p(A) = min
AâˆˆARÎ¨0(A)
and
lim
pâ†’0min
AâˆˆAProbR Î¨p(A) = min
AâˆˆAProbR Î¨0(A).
On the other hand, thanks to Proposition 10, we have
min
AâˆˆARadv(A)â‰¥min
AâˆˆAProbR Î¨0(A)â‰¥min
AâˆˆARÎ¨0(A).
32Thus it suffices to prove that
min
AâˆˆARÎ¨0(A)â‰¥min
AâˆˆARadv(A).
To see this, let Abe an arbitrary measurable subset of X. We can then proceed as in the
proof of [6, Lemma 3.8] and use the fact that
{xâˆˆ Xs.t.dist(x,supp( Ï))< Îµ} âŠ†supp( Ïƒ),
which follows from (2) in Assumption 4, to conclude that we can find a measurable set Aâ€²
which is Ïƒ-equivalent to A(i.e., Ïƒ(Aâ–³Aâ€²) = 0) and satisfies:
Ïƒ-ess sup
ËœxâˆˆBÎµ(x)1A(Ëœx) = sup
ËœxâˆˆBÎµ(x)1Aâ€²(Ëœx), Ïƒ-ess sup
ËœxâˆˆBÎµ(x)1Ac(Ëœx) = sup
ËœxâˆˆBÎµ(x)1Aâ€²c(Ëœx)
forÏ-a.e. xâˆˆ X. Thanks to (22), we deduce that
mx(Aâ–³Aâ€²) = 0 , Ï-a.e. xâˆˆ X.
It follows that for Ïalmost every xâˆˆ Xwe have
Ïƒ-ess sup
ËœxâˆˆBÎµ(x)1A(Ëœx) = sup
ËœxâˆˆBÎµ(x)1Aâ€²(Ëœx)â‰¥mx-ess sup 1Aâ€²(Ëœx) =mx-ess sup 1A(Ëœx).
as well as
Ïƒ-ess sup
ËœxâˆˆBÎµ(x)1Ac(Ëœx)â‰¥mx-ess sup 1Ac(Ëœx).
Since Ïƒis absolutely continuous with respect to mxforÏa.e.xâˆˆ X(thanks to Assump-
tion 4), we deduce that
mx-ess sup 1Ac(Ëœx)â‰¥Ïƒ-ess sup
ËœxâˆˆBÎµ(x)1Ac(Ëœx),mx-ess sup 1A(Ëœx)â‰¥Ïƒ-ess sup
ËœxâˆˆBÎµ(x)1A(Ëœx)
forÏ-a.e. xâˆˆ X. Combining the above, we deduce that for Ï-a.e. xâˆˆ X
mx-ess sup 1Ac(Ëœx) = sup
ËœxâˆˆBÎµ(x)1Aâ€²c(Ëœx),mx-ess sup 1A(Ëœx) = sup
ËœxâˆˆBÎµ(x)1Aâ€²(Ëœx).
From this fact, we deduce that
RÎ¨0(A) =Z
Xmx-ess sup
ËœxâˆˆBÎµ(x)1AdÏ0(x) +Z
Xmx-ess sup
ËœxâˆˆBÎµ(x)1AcdÏ1(x)
=Z
Xsup
ËœxâˆˆBÎµ(x)1Aâ€²(Ëœx) dÏ0(x) +Z
Xsup
ËœxâˆˆBÎµ(x)1Aâ€²c(Ëœx) dÏ1(x)
= R adv(Aâ€²)
â‰¥min
ËœAâˆˆARadv(ËœA).
Taking the infimum over Aon the left hand side we obtain the desired result.
â–¡
While the above result states that both PRL and modified PRL models recover the AT
model from the perspective of consistency of their optimal energies (at least in the agnos-
tic setting, where we can prove existence of minimizers to AT; see [6]), the next example
illustrates that minimizers of the PRL energies may not converge to AT minimizers as the
parameter pgoes to zero. Studying the behavior of minimizers is important, since, after all,
33PRL models and AT are used to produce robust classifiers by minimizing energy functionals.
We start with an example.
Example 5. LetX=Rand for every xâˆˆRletmxbe the uniform measure over BÎµ(x), the
open Euclidean ball of radius Îµand center x. Consider the probability distribution Âµover
X Ã— { 0,1}given by
Âµ=2
5Î´(x1,0)+1
5Î´(x2,0)+2
5Î´(x3,1),
where x1< x2< x3,|x1âˆ’x2|< Îµ, and BÎµ(x2)âˆ©BÎµ(x3)Ì¸=âˆ…,BÎµ(x1)âˆ©BÎµ(x3) =âˆ….
It is straightforward to show that the optimal adversarial risk Râˆ—
advin this situation is 1/5
and that Aâ€²achieves this adversarial risk if and only if BÎµ(x3)âŠ†Aâ€²andBÎµ(x1)âŠ†Aâ€²c. On the
other hand, the set ËœA=BÎµ(x3)âˆª {x2}satisfies ProbR Î¨0(ËœA) = 1 /5. In particular, thanks to
Theorem 6, ËœAis a minimizer of both ProbR Î¨0andRÎ¨0(i.e., the Î“-limits of the PRL models
aspâ†’0). Note, however, that there does not exist a set Aâ€²âˆ¼Î½ËœAthat is a minimizer of
Radv. This is because for Aâ€²to be a minimizer of Radvwe would need to exclude x2from ËœA,
but it is impossible to achieve this while maintaining the condition ËœAâˆ¼Î½Aâ€², since Ïassigns
mass strictly larger than zero to {x2}.
From the above example it is clear that in general we cannot expect that an arbitrary min-
imizer of RÎ¨0orProbR Î¨0can be turned into a solution to adversarial training by modifying
it within a set of Î½measure zero, in particular by only modifying the classifier outside of
the observed data (the support of the distribution Ï) and their admissible perturbations. In
other words, this means that there may be solutions to PRL or modified PRL for pâ‰ˆ0that,
putting measure theoretic technicalities aside, arenâ€™t solutions to AT. In this sense, PRL or
its modified version may not necessarily recover the AT model when pâ†’0. Fortunately,
it is possible to avoid the issue described above by imposing one extra assumption on the
family of distributions {mx}xâˆˆX.
Assumption 5. Suppose that for every xâˆˆsupp( Ï)the measure ÏâŒŠBÎµ(x), the restriction of
Ïto the ball BÎµ(x), is absolutely continuous with respect to mx.
Remark 11. If for xâˆˆsupp( Ï)we choose mxto be mx=1
2Unif( BÎµ(x)) +1
2Ï(BÎµ(x))ÏâŒŠBÎµ(x),
then the family {mx}xâˆˆXsatisfies Assumptions 4 and 5.
Theorem 7. Suppose that Assumptions 4 and 5 hold. Suppose that for every p >0the set
Apis a minimizer of ProbR Î¨poverA=B(X), and suppose that, as pâ†’0,Apconverges
towards a set Ain the weak* topology of Lâˆ(X;Î½). Then there is a set Aâ€²with Aâ€²âˆ¼Î½A
such that Aâ€²is a minimizer of Radvover the class of all Borel measurable sets.
The above continues to be true if we substitute ProbR Î¨pwith RÎ¨p.
Proof.TheÎ“-convergence in Proposition 8 implies that Aas in the statement must be a
minimizer of ProbR Î¨0. Following the proof of Theorem 6 we know there exists a set Aâ€²
which is Ïƒequivalent to Aand satisfies ProbR Î¨0(A)â‰¥RÎ¨0(A) = R adv(Aâ€²). Thanks to
Theorem 6, it follows that Aâ€²is a minimizer of Radv. The desired result now follows from
Assumption 5, since this assumption implies that Î½is absolutely continuous with respect to
Ïƒand as a consequence Aâˆ¼Î½Aâ€².
â–¡
34So far we have studied the behaviors of the energies ProbR Î¨pandRpaspâ†’0. To wrap
up this section we discuss the limits of these energies as pgrows.
Theorem 8. For the functions Î¨p(t) := min {t/p,1}it holds that ProbR Î¨pÎ“-converges to
E(x,y)âˆ¼Âµ[|1A(x)âˆ’y|] +Z
AZ
Acdmx(Ëœx) dÏ1(x) +Z
AcZ
Admx(Ëœx) dÏ0(x)
aspâ†’1, and to E(x,y)âˆ¼Âµ[|1A(x)âˆ’y|]aspâ†’ âˆ, in the weak-* topology of Lâˆ(X;Î½). We
recall Î½was introduced in (13).
Proof.This easily follows from the fact that, actually, the convergence of the energies is
uniform over all measurable Aaspâ†’1and as pâ†’ âˆ. â–¡
Remark 12. In the previous result we have highlighted the case p= 1, as this is the case
where the modified PRL model coincides with a regularized risk minimization problem with
nonlocal perimeter penalty of the type investigated in [24] in the context of random walk
metric spaces.
Remark 13. In contrast to the modified PRL model, which recovers the standard risk
minimization model as pgrows, the energy RÎ¨pis easily seen to converge uniformly toward
the zero functional as pâ†’ âˆ.
5.PRL for general learning settings and the conditional value at risk
After extensively discussing the binary and 0-1 loss case in the previous sections, we shift
ourattentiontotraininggeneralhypotheses hâˆˆ Husinggenerallossfunctions â„“:YÃ—Y â†’ R,
even when Yis not binary. Motivated by Propositions 1 and 2 it is natural to consider the
following probabilistically robust optimization problem
inf
hâˆˆHE(x,y)âˆ¼Âµ
max
â„“(h(x), y), p-ess sup
xâ€²âˆ¼mxâ„“(h(xâ€²), y)
. (36)
Since the p-ess supoperator is notoriously hard to optimize, one shall replace it with the
conditional value at risk (CVaR) which is convex and easier to optimize [30, 31]. For a
function f:X â†’Rand a probability distribution mthe CVaR at level pâˆˆ(0,1)is defined
as
CVaR p(f;m) := inf
Î±âˆˆRÎ±+Exâ€²âˆ¼mx
(f(xâ€²)âˆ’Î±)+
p. (37)
Itiseasytoseethat p-ess supxâ€²âˆ¼mf(xâ€²)â‰¤CVaR p(f;m). UsingCVaRinplaceofthe p-ess sup
operator, a tractable version of (36) is
inf
hâˆˆHE(x,y)âˆ¼Âµh
maxn
â„“(h(x), y),CVaR p(â„“(h(â€¢), y);mx)oi
. (38)
We emphasize that, if the loss function â„“(â€¢,â€¢)is convex in its first argument, then (38) is
a convex function of the hypothesis h. Furthermore, CVaR is positively homogeneous and
hence also (38) is positively homogeneous in the loss function. So, taking the maximum of
the samplewise CVaR and standard risk is consistent with a standard dimensionality analysis
as both terms scale in the same way.
35In the binary classification case we can prove Proposition 3 which states that the CVaR
relaxation corresponds precisely to using the risk ProbR Î¨pwith the piecewise linear and
concave function Î¨p(t) = min {t/p,1}for which our theory from Section 2.2 applies.
Proof of Proposition 3. Ifâ„“is the 0-1-loss then the function f:=â„“(1A(Â·), y)forAâˆˆ Acan
be written as f=1Sfor set Sâˆˆ {A, Ac}, depending on whether y= 0ory= 1. So it
suffices to deal with the case f=1Awhere we can write
CVaR p(f;mx) = inf
Î±âˆˆRÎ±+ (1âˆ’Î±)+mx(A)
p+ (âˆ’Î±)+1âˆ’mx(A)
p.
Notice that the function
Î¶(Î±) :=Î±+ (1âˆ’Î±)+mx(A)
p+ (âˆ’Î±)+1âˆ’mx(A)
p, Î±âˆˆR,
is continuous and piecewise linear with kinks at Î±= 0andÎ±= 1. Moreover, since 0< p < 1
it holds Î¶(Î±)â‰¥Î¶(1)forÎ± > 1, and Î¶(Î±)â‰¥Î¶(0)forÎ± < 0. Thus the minimum of Î¶is
attained at either Î±= 0orÎ±= 1. Therefore
CVaR p(f;mx) = min {Î¶(0), Î¶(1)}= minmx(A)
p,1
= Î¨ p(Pxâ€²âˆ¼mx[1A(xâ€²)]).
This together with Proposition 2 implies the claim. â–¡
6.Numerical experiments
In this section, we conduct a comparative analysis between the original formulation of
PRL (denoted as â€œPRLâ€ in Table 1) and our modification of PRL which is based on (38)
(denoted as â€œm-PRLâ€). We build upon the code of [30] and our implementation is available
onGitHub.1The algorithmic realization of (38) is a straightforward adaptation of their
algorithm, which alternatingly minimizes the inner optimization problem that defines CVaR
and the outer optimization to find a suitable classifier, see Algorithm 1 in Appendix B.
Our experiments are conducted on MNIST and CIFAR-10 and to ensure a fair comparison
we adhere to the hyperparameter settings described in [30], such that both the original and
modified algorithms utilize the same set of hyperparameters for each specified value of p. The
corresponding results for several baseline algorithms including empirical risk minimization
and adversarial training can be found in [30].
6.1.Comparingaccuracyandrobustness. Wereportthecleanaccuracy, adversarialac-
curacy (subject to PGD attacks), accuracy on noise-augmented data, and quantile accuracies
for different values of Ïdefinedâ€”as in [30, (6.1)]â€”for a single data point (x, y)by
(39) ProbAcc Ï(x, y) =1Pxâ€²âˆ¼mx[h(xâ€²)=y]>p.
In practice, we use an empirical proportion, computed over 100 samples from mx, in lieu of
the true probability, as done in [30]. All quantities are averaged over three runs, and we
perform model selection based on the best clean validation accuracy; see Appendix B.2 for
more training details.
The results in Table 1 demonstrate that the geometric modification does not compromise
the accuracy of the original algorithm, and sometimes leads to improved performance, even
as it provides stronger theoretical guarantees. Note that neither PRL nor m-PRL should be
1https://github.com/DanielMckenzie/Begins_with_a_boundary
36Table 1. Accuracies [%] of the geometric and original algorithm for different
values of p.
Data pAlgorithm Clean Adv Aug ProbAcc(0.1) ProbAcc(0.05) ProbAcc(0.01)MNIST0.01m-PRL 99.20 12.19 99.04 98.18 97.69 96.38
PRL 99.19 10.76 98.90 97.94 97.38 95.67
0.1m-PRL 99.28 14.2099.22 98.70 98.45 97.86
PRL 99.32 8.94 99.22 98.70 98.46 97.80
0.3m-PRL 99.29 3.02 99.21 98.76 98.53 97.95
PRL 99.27 3.0299.22 98.77 98.55 98.01
0.5m-PRL 99.27 1.80 99.21 98.72 98.44 97.93
PRL 99.26 1.68 99.19 98.72 98.47 97.80CIFAR-100.01m-PRL 80.65 0.15 78.13 73.44 72.13 68.80
PRL 81.73 0.24 79.16 74.61 73.19 69.96
0.1m-PRL 88.15 0.14 85.96 82.55 81.46 78.81
PRL 88.28 0.19 85.61 82.21 81.06 78.28
0.3m-PRL 90.43 11.80 88.70 85.17 83.93 80.93
PRL 89.97 7.20 88.62 85.07 83.75 80.87
0.5m-PRL 91.51 1.93 88.94 85.53 84.18 81.21
PRL 90.74 1.9988.94 85.54 84.35 81.57
expected to match the adversarial robustness of classifiers trained with PGD attacks [23] or
other worst-case optimization techniques. Instead, they shine with superior clean accuracy
and easier training while maintaining probabilistic robustnesss, as well as a certain degree
of adversarial robustness. This corroborates the findings of [30].
6.2.On the existence of pathological points. We say (x, y)is a pathological data point
ifxis incorrectly classified yet a large proportion of perturbations to xyield a correct
classification. See Figure 1 for a simple example. Although the discussion of Section 1
asserts that such points canarise for classifiers trained using PRL, it is interesting to verify
whether this phenomenon occurs in practice.
To do so, we examine all misclassified CIFAR-10 images, in both test and train splits, for
a model trained using PRL as described above. For each image x, we generate 100 samples
xâ€²âˆ¼mxand compute the proportion of such samples which are correctly classified. As shown
in Figure 3, while for the vast majority of such x, all 100xâ€²remain incorrectly classified,
images xexist where an arbitrarily large proportion of the xâ€²are correctly classified. In
short, pathological points do occur in practice.
We repeated the same experiment, but with a model trained using m-PRL. Intriguingly,
while m-PRL is guaranteed in theory to prevent pathological points (see Proposition 11 in
the Appendix), in practice they still occur, see Figure 3. We did not find strong empirical
evidence that using m-PRL results in fewer pathological points in practice, see also Figures 4
to 6. We attribute this gap between theory and practice to the fact that m-PRL (as well
37as PRL) approximates the value of CVaR p, which involves a high-dimensional expectation,
with an empirical average, see (38) and line 7 in Algorithm 1).
0 20 40 60 80 100
Percentage of perturbations yielding correct classification102103Number of  Incorrectly Classified Images0 25 50 75 100102
(a)p= 0.01, train, original PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification102103Number of  Incorrectly Classified Images0 25 50 75 100102 (b)p= 0.01, train, m-PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification101102103Number of  Incorrectly Classified Images0 25 50 75 100101102
(c)p= 0.01, test, original PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification101102103Number of  Incorrectly Classified Images0 25 50 75 100100101102 (d)p= 0.01, test, m-PRL
Figure 3. Histograms display the distribution of percentages of correctly
classified perturbations among misclassified images for both original and m-
PRL with parameter p= 0.01. The inner plot excludes the prevalent 0%
case. The plots show that pathological data pointsâ€”i.e. data points which are
misclassified yet most perturbations to the data point are correctly classifiedâ€”
occur in real datasets.
7.Discussion and Conclusion
In this paper we considered probabilistically robust learning (PRL), originally proposed
in [30]. We introduced a modification of the original PRL model that allowed us to address,
at least theoretically, the possibility that certain solutions to the model possess pathological
points as described in Figure 1. This modification has the appeal of being interpretable
through the lens of regularized risk minimization, where the regularization terms take the
form of a non-local perimeters of interest in their own right. We discussed an asymptotic
expansion for smooth decision boundaries to show that for small adversarial budgets these
38probabilisticperimetersinducethesameregularizationeffectastheoriginaladversarialtrain-
ingmodel. Forbinaryclassificationweprovedexistenceofoptimalhardclassifiersandofvery
general classes of soft classifiers including neural networks in both the original and modified
PRL settings. This was done through novel relaxation techniques taking advantage of the
structure of our functionals. Finally, through rigurous Î“-convergence analysis we provided
a detailed discussion on the relation between adversarial training, risk minimization, and all
the PRL models, highlighting that the original PRL model fails to interpolate between risk
minimization and adversarial training, contrary to claims in previous works. For general
(not necessarily binary) problems we showed that the natural loss function to choose is the
sample-wise maximum of the standard loss and conditional value at risk (CVaR).
One limitation of PRL is that it does not completely solve the accuracy vs. robustness
trade-off, which remains a challenging problem. Furthermore, while the formal limit of PRL
aspâ†’0is the worst-case adversarial problem, the algorithms for solving PRL exhibit
limitations for very small values of p(in the computation of CVaR p). Still, the results for
moderately large values of pare encouraging and future work should focus on understanding
of this trade-off better.
The rich mathematical theory developed in this paper opens up new avenues for research,
such as the explicit design of probabilistic regularizers for algorithms and exploring the
variational convergence of the probabilistic perimeter and its implications for adversarial
robustness.
Acknowledgment
This material is based upon work supported by the National Science Foundation under
Grant Number DMS 1641020 and was started during the summer of 2022 as part of the
AMS-MRC program Data Science at the Crossroads of Analysis, Geometry, and Topology .
NGT was supported by the NSF grants DMS-2005797 and DMS-2236447. MJ was supported
by NSF grant DMS-2400641.
References
[1] Maksym Andriushchenko and Nicolas Flammarion. â€œUnderstanding and improving fast
adversarialtrainingâ€.In: Advances in Neural Information Processing Systems 33(2020),
pp. 16048â€“16059.
[2] Pranjal Awasthi, Natalie S Frank, and Mehryar Mohri. â€œOn the existence of the ad-
versarial Bayes classifierâ€. In: Advances in Neural Information Processing Systems 34
(2021), pp. 2978â€“2990.
[3] Pranjal Awasthi, Natalie S Frank, and Mehryar Mohri. â€œOn the Existence of the Ad-
versarial Bayes Classifier (Extended Version)â€. In: arXiv preprint arXiv:2112.01694
(2021).
[4] Andrea Braides. Gamma-Convergence for Beginners . Oxford University Press, July
2002. isbn: 9780198507840.
[5] Andrea Braides and Lev Truskinovsky. â€œAsymptotic Expansions by Î“-convergenceâ€.
In:Continuum Mechanics and Thermodynamics 20.1 (Apr. 2008), pp. 21â€“62. issn:
0935-1175, 1432-0959.
39[6] Leon Bungert, NicolÃ¡s GarcÃ­a Trillos, and Ryan Murray. â€œThe geometry of adversarial
training in binary classificationâ€. In: Information and Inference: A Journal of the IMA
12.2 (June 2023), pp. 921â€“968. issn: 2049-8772.
[7] Leon Bungert, Tim Laux, and Kerrek Stinson. A mean curvature flow arising in ad-
versarial training . 2024. arXiv: 2404.14402 [math.AP] .
[8] LeonBungertandKerrekStinson.â€œGamma-convergenceofanonlocalperimeterarising
in adversarial machine learningâ€. In: Calculus of Variations and Partial Differential
Equations 63.5 (2024), p. 114.
[9] HanQin Cai et al. â€œA zeroth-order block coordinate descent algorithm for huge-scale
black-box optimizationâ€. In: International Conference on Machine Learning . PMLR.
2021, pp. 1193â€“1203.
[10] Antonin Chambolle, Alessandro Giacomini, and Luca Lussardi. â€œContinuous limits of
discrete perimetersâ€. In: ESAIM: Mathematical Modelling and Numerical Analysis 44.2
(2010), pp. 207â€“230.
[11] Antonin Chambolle, Massimiliano Morini, and Marcello Ponsiglione. â€œNonlocal curva-
ture flowsâ€. In: Archive for Rational Mechanics and Analysis 218 (2015), pp. 1263â€“
1329.
[12] Pin-Yu Chen et al. â€œZOO: Zeroth order optimization based black-box attacks to deep
neural networks without training substitute modelsâ€. In: Proceedings of the 10th ACM
workshop on artificial intelligence and security . 2017, pp. 15â€“26.
[13] Jeremy Cohen, Elan Rosenfeld, and Zico Kolter. â€œCertified adversarial robustness via
randomized smoothingâ€. In: international conference on machine learning . PMLR.
2019, pp. 1310â€“1320.
[14] Gianni Dal Maso. An Introduction to Î“-Convergence . BirkhÃ¤user Boston, 1993. isbn:
9781461203278.
[15] Nelson Dunford and Jacob T Schwartz. Linear Operators: General theory . Linear Op-
erators. Interscience Publishers, 1958. isbn: 9780470226056.
[16] NatalieSFrankandJonathanNiles-Weed.â€œExistenceandminimaxtheoremsforadver-
sarialsurrogaterisksinbinaryclassificationâ€.In: Journal of Machine Learning Research
25.58 (2024), pp. 1â€“41.
[17] Natalie S Frank and Jonathan Niles-Weed. â€œThe Consistency of Adversarial Training
for Binary Classificationâ€. In: arXiv preprint arXiv:2206.09099 (2022).
[18] NicolÃ¡s GarcÃ­a Trillos, Matt Jacobs, and Jakwang Kim. â€œOn the existence of solutions
to adversarial training in multiclass classificationâ€. In: arXiv preprint arXiv:2305.00075
(2023).
[19] NicolÃ¡s GarcÃ­a Trillos and Ryan Murray. â€œAdversarial Classification: Necessary Condi-
tions and Geometric Flowsâ€. In: Journal of Machine Learning Research 23.187 (2022),
pp. 1â€“38.
[20] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. â€œExplaining and harnessing
adversarial examplesâ€. In: arXiv preprint arXiv:1412.6572 (2014).
[21] Kaiming He et al. â€œDeep residual learning for image recognitionâ€. In: Proceedings of the
IEEE conference on computer vision and pattern recognition . 2016, pp. 770â€“778.
[22] Dan Hendrycks et al. â€œThe many faces of robustness: A critical analysis of out-of-
distributiongeneralizationâ€.In: Proceedings of the IEEE/CVF International Conference
on Computer Vision . 2021, pp. 8340â€“8349.
40[23] Aleksander Madry et al. â€œTowards deep learning models resistant to adversarial at-
tacksâ€. In: arXiv preprint arXiv:1706.06083 (2017).
[24] JosÃ© M MazÃ³n, Marcos Solera, and JuliÃ¡n Toledo. â€œThe total variation flow in metric
random walk spacesâ€. In: Calculus of Variations and Partial Differential Equations 59
(2020), pp. 1â€“64.
[25] Rachel Morris and Ryan Murray. Uniform Convergence of Adversarially Robust Clas-
sifiers. 2024. arXiv: 2406.14682 [math.AP] .
[26] Muni Sreenivas Pydi and Varun Jog. â€œThe many faces of adversarial riskâ€. In: Advances
in Neural Information Processing Systems 34 (2021), pp. 10000â€“10012.
[27] Yao Qin et al. â€œImperceptible, robust, and targeted adversarial examples for automatic
speech recognitionâ€. In: International conference on machine learning . PMLR. 2019,
pp. 5231â€“5240.
[28] Joaquin QuinoÃ±ero-Candela et al. Dataset shift in machine learning . Mit Press, 2008.
[29] Vinod Raman, Unique Subedi, and Ambuj Tewari. â€œOn Proper Learnability between
Average- and Worst-case Robustnessâ€. In: arXiv preprint arXiv:2211.05656 (2023).
[30] Alexander Robey et al. â€œProbabilistically Robust Learning: Balancing Average and
Worst-case Performanceâ€. In: International Conference on Machine Learning . PMLR.
2022, pp. 18667â€“18686.
[31] R Tyrrell Rockafellar, Stanislav Uryasev, et al. â€œOptimization of conditional value-at-
riskâ€. In: Journal of risk 2 (2000), pp. 21â€“42.
[32] LeoSchwinnetal.â€œIdentifyinguntrustworthypredictionsinneuralnetworksbygeomet-
ric gradient analysisâ€. In: Uncertainty in Artificial Intelligence . PMLR. 2021, pp. 854â€“
864.
[33] Leo Schwinn et al. â€œImproving Robustness against Real-World and Worst-Case Dis-
tribution Shifts through Decision Region Quantificationâ€. In: International Conference
on Machine Learning . PMLR. 2022, pp. 19434â€“19449.
[34] Ali Shafahi et al. â€œAdversarial training for free!â€ In: Advances in Neural Information
Processing Systems 32 (2019).
[35] Dimitris Tsipras et al. â€œRobustness may be at odds with accuracyâ€. In: arXiv preprint
arXiv:1805.12152 (2018).
[36] Vladimir Vapnik. The nature of statistical learning theory . Springer science & business
media, 1999.
[37] Bao Wang et al. â€œEnResNet: ResNets Ensemble via the Feynmanâ€“Kac Formalism for
Adversarial Defense and Beyondâ€. In: SIAM Journal on Mathematics of Data Science
2.3 (2020), pp. 559â€“582.
[38] Lukas Weigand, Tim Roith, and Martin Burger. Adversarial flows: A gradient flow
characterization of adversarial attacks . 2024. arXiv: 2406.05376 [cs.LG] .
[39] Eric Wong, Leslie Rice, and J Zico Kolter. â€œFast is better than free: Revisiting adver-
sarial trainingâ€. In: arXiv preprint arXiv:2001.03994 (2020).
[40] Matthew D Zeiler. â€œAdadelta: an adaptive learning rate methodâ€. In: arXiv preprint
arXiv:1212.5701 (2012).
[41] Hongyang Zhang et al. â€œTheoretically principled trade-off between robustness and ac-
curacyâ€. In: International conference on machine learning . PMLR. 2019, pp. 7472â€“
7482.
41Appendix A.Pathological points in the modified PRL model
Contrary to the situation presented in Figure 1, where we describe unintuitive features
of a solution of the original PRL model, the modified PRL model possesses an interesting
stability property that prevents their minimizers from having pathological points (recall
the discussion in Section 6.2). This property is independent of any specifics of the family
{mx}xâˆˆXand for example holds in the Euclidean setting when we set mxto be the uniform
measure over the ball BÎµ(x).
Proposition 11. IfAis a minimizer of ProbR Î¨0withÎ¨0(t) =1t>0, then for Ï0-a.e. xâˆˆ X
we have: 1A(x) = 1implies mx-ess sup 1A= 1. Likewise, for Ï1-a.e. xâˆˆ X,1Ac(x) = 1
implies mx-ess sup 1Ac= 1.
Proof.We first observe that if Aminimizes ProbR Î¨0, then it also minimizes RÎ¨0. To see
this, let ProbRâˆ—
Î¨0andRâˆ—
Î¨0be the infima of ProbR Î¨0andRÎ¨0, respectively. We then observe
that for any given measurable ËœAwe have
RÎ¨0(ËœA)â‰¥Râˆ—
Î¨0= ProbRâˆ—
Î¨0= ProbR Î¨0(A)â‰¥RÎ¨0(A),
where the second equality follows from Theorem 6 and the last inequality from Proposi-
tion 10. This proves that Ais indeed a minimizer of RÎ¨0. From the proof of Proposition 10
we had already observed that for every xâˆˆ X
1Ac(x)Â·mx-ess sup 1A+1A(x)â‰¥mx-ess sup 1A,
as well as
1A(x)Â·mx-ess sup 1Ac+1Ac(x)â‰¥mx-ess sup 1Ac.
But since we also have
RÎ¨0(A) = ProbR Î¨0(A)â‰¥Z
X(1Ac(x)Â·mx-ess sup 1A+1A(x)) dÏ0(x)
+Z
X(1A(x)Â·mx-ess sup 1Ac+1Ac(x)) dÏ1(x)
â‰¥Z
Xmx-ess sup 1AdÏ0(x) +Z
Xmx-ess sup 1AcdÏ1(x)
= R Î¨0(A),
we deduce that for Ï0-a.e. xâˆˆ X
1Ac(x)Â·mx-ess sup 1A+1A(x) =mx-ess sup 1A
and for Ï1-a.e. xâˆˆ X
1A(x)Â·mx-ess sup 1Ac+1Ac(x) =mx-ess sup 1Ac.
The desired implications now follow. â–¡
42Appendix B.Computational aspects of PRL
B.1.Pseudocode for geometric probabilistically robust learning. In Algorithm 1
we provide a pseudocode for parametrized classifiers fâ‰¡fÎ¸:X â†’ Y based on stochastic
gradient descent with batch size B. Furthermore, it involves a sample size of Msamples from
a distribution mxaround an input xâˆˆ X, a learning rate Î·Î±for the inner optimization in
CVaR, and a learning rate Î·for the parameter updates. The pseudocode is a straightforward
generalization of [30, Algorithm 1] and we implemented it in their code framework.2The
code which can be used to reproduce our results is part of the supplementary material of
this paper.
Algorithm 1 Proposed algorithm for solving (38) for pâˆˆ(0,1).
1:forminibatch (xj, yj)B
j=1do
2:forTstepsdo â–·Approximate solution of inner problem
3: Draw xâ€²
kâˆ¼mxj,k= 1, . . . , M
4: gÎ±jâ†1âˆ’1
pMMX
k=11â„“(fÎ¸(xâ€²
k), yj)â‰¥Î±j
5: Î±jâ†Î±jâˆ’Î·Î±gÎ±j
6:end for
7: Sjâ†Î±j+1
pMMX
k=1(â„“(fÎ¸(xâ€²
k), yj)âˆ’Î±j)+â–·Approximate value of CVaR p
8:ifSj> â„“(fÎ¸(xj), yj))then â–·IfCVaR pkicks in
9: gjâ†1
pMMX
k=1âˆ‡Î¸(â„“(fÎ¸(xâ€²
k), yj)âˆ’Î±j)+
10:else â–·If it doesnâ€™t
11: gjâ† âˆ‡ Î¸â„“(fÎ¸(xj), yj)
12:end if
13: gâ†1
BBX
j=1gj â–·Compute full Î¸-gradient
14: vâ†optimizer( g) â–·AdaDelta or SGD(+M)
15: Î¸â†Î¸âˆ’Î·v â–·Update parameters
16:end for
B.2.Training details. Hyperparameter values specific to Algorithm 1 used in training are
presented in Table 2. Following [30], we use AdaDelta [40] for MNIST experiments and
SGD with momentum for CIFAR-10 experiments. The MNIST experiments use a CNN
architecture with two convolutional layers (32 and 64 filters, size 3x3), two dropout layers
(dropout probabilities 0.25, 0.5), and two fully connected layers (dimensions 9216 to 128 and
128 to 10). A ResNet-18 [21] is used in the CIFAR-10 experiments. The hyperparameter
valuesusedforthesealgorithmsarecontainedin hparams_registry.py intheaccompanying
code.
2https://github.com/arobey1/advbench
43Table 2. Hyperparameters used for training. The probability distribution
mxis always taken to be the uniform distribution over the ball BÎµ(x). Note
that pis called betain the code. For consistency we always used the same
hyperparameter values for the â€œGeometricâ€ and â€œOriginalâ€ versions.
Data p Îµ Î· Î±M TMNIST0.01 0 .3 0 .1 20 5
0.1 0 .3 1 .0 20 5
0.3 0 .3 1 .0 20 5
0.5 0 .3 1 .0 20 5CIFAR-100.01 8 /255 0 .1 20 5
0.1 8 /255 1 .0 20 5
0.3 8 /255 1 .0 20 5
0.5 8 /255 1 .0 20 5
B.3.Computational resources used. We performed the majority of the prototyping and
someexperimentationonaLambdaLabsVectorworkstationequippedwith3NVIDIAA6000
GPUs. We estimate that we used approximately 500 GPU-hours on this machine. We
supplemented this with 550 GPU-hours of cloud computeâ€”using the Lambda GPU cloudâ€”
predominately on instances equipped with a single A10 GPU.
44B.4.Further numerical experiments. In Figures 4 to 6 we provide further numerical
experiments on pathological points with parameters p= 0.1,0.3, and 0.5
0 20 40 60 80 100
Percentage of perturbations yielding correct classification102103Number of  Incorrectly Classified Images0 25 50 75 100102
(a)p= 0.1, train, original PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification101102103Number of  Incorrectly Classified Images0 25 50 75 100102 (b)p= 0.1, train, m-PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification100101102103Number of  Incorrectly Classified Images0 25 50 75 100100101102
(c)p= 0.1, test, original PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification100101102103Number of  Incorrectly Classified Images0 25 50 75 100100101102 (d)p= 0.1, test, m-PRL
Figure 4. Histograms showing the distribution of percentages of correctly
classified perturbations among misclassified images for both original and m-
PRL with parameter p= 0.1.
450 20 40 60 80 100
Percentage of perturbations yielding correct classification101102103Number of  Incorrectly Classified Images0 25 50 75 100101102(a)p= 0.3, train, original PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification101102103Number of  Incorrectly Classified Images0 25 50 75 100101102 (b)p= 0.3, train, m-PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification100101102Number of  Incorrectly Classified Images0 25 50 75 100100101102
(c)p= 0.3, test, original PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification100101102Number of  Incorrectly Classified Images0 25 50 75 100100101102 (d)p= 0.3, test, m-PRL
Figure 5. Histograms showing the distribution of percentages of correctly
classified perturbations among misclassified images for both original and m-
PRL with parameter p= 0.3.
460 20 40 60 80 100
Percentage of perturbations yielding correct classification101102103Number of  Incorrectly Classified Images0 25 50 75 100102(a)p= 0.5, train, original PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification101102103Number of  Incorrectly Classified Images0 25 50 75 100101102 (b)p= 0.5, train, m-PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification101102Number of  Incorrectly Classified Images0 25 50 75 100101
(c)p= 0.5, test, original PRL
0 20 40 60 80 100
Percentage of perturbations yielding correct classification100101102Number of  Incorrectly Classified Images0 25 50 75 100100101102 (d)p= 0.5, test, m-PRL
Figure 6. Histograms showing the distribution of percentages of correctly
classified perturbations among misclassified images for both original and m-
PRL with parameter p= 0.5.
47Institute of Mathematics & Center for Artifical Intelligence and Data Science (CAIDAS),
University of WÃ¼rzburg, Germany
Email address :leon.bungert@uni-wuerzburg.de
Department of Statistics, University of Wisconsin-Madison, US
Email address :garciatrillo@wisc.edu
Department of Mathematics, University of California Santa Barbara, US
Email address :majaco@ucsb.edu
Department of Applied Mathematics and Statistics, Colorado School of Mines, US
Email address :dmckenzie@mines.edu
Department of Mathematics, University of California Santa Barbara, US
Email address :nikolic@math.ucsb.edu
Department of Mathematics, University of Utah, US
Email address :qswang@math.utah.edu
48