RASTI 000, 1–10 (0000) Preprint 10 February 2023 Compiled using rasti L ATEX style ﬁle v3.0
Practical Guidance for Bayesian Inference in Astronomy
Gwendolyn M. Eadie12★, Joshua S. Speagle,123Jessi Cisewski-Kehe,4Daniel Foreman-Mackey,5
Daniela Huppenkothen,6David E. Jones,7Aaron Springford8and Hyungsuk Tak91011
1University of Toronto, David A. Dunlap Department of Astronomy & Astrophysics, Toronto, M5S 3H4, Canada
2University of Toronto, Department of Statistical Sciences, Toronto, M5S 3G3, Canada
3University of Toronto, Dunlap Institute for Astronomy & Astrophysics, Toronto, M5S 3H4, Canada
4University of Wisconsin-Madison, Department of Statistics, Madison, WI, 53706, USA
5Center for Computational Astrophysics, Flatiron Institute, 160 5th Ave, New York, NY 10010, USA
6SRON Netherlands Institute for Space Research, Niels Bohrlaan 4, 2333 CA Leiden, Netherlands
7Texas A&M University, Department of Statistics, College Station, TX 77843, USA
8Cytel, Toronto, Ontario, Canada
9Pennsylvania State University, Department of Statistics, University Park, PA 16802, USA
10Pennsylvania State University, Department of Astronomy & Astrophysics, University Park, PA 16802, USA
11Pennsylvania State University, Institute for Computational and Data Sciences, University Park, PA 16802, USA
10 February 2023
ABSTRACT
Inthelasttwodecades,Bayesianinferencehasbecomecommonplaceinastronomy.Atthesametime,thechoiceofalgorithms,
terminology, notation, and interpretation of Bayesian inference varies from one sub-ﬁeld of astronomy to the next, which can
lead to confusion to both those learning and those familiar with Bayesian statistics. Moreover, the choice varies between the
astronomy and statistics literature, too. In this paper, our goal is two-fold: (1) provide a reference that consolidates and clariﬁes
terminologyandnotationacrossdisciplines,and(2)outlinepracticalguidanceforBayesianinferenceinastronomy.Highlighting
boththeastronomyandstatisticsliterature,wecovertopicssuchasnotation,speciﬁcationofthelikelihoodandpriordistributions,
inferenceusingtheposteriordistribution,andposteriorpredictivechecking.Itisnotourintentiontointroducetheentireﬁeldof
Bayesiandataanalysis–rather,wepresentaseriesofusefulpracticesforastronomerswhoalreadyhaveanunderstandingofthe
Bayesian"nutsandbolts"andwishtoincreasetheirexpertiseandextendtheirknowledge.Moreover,astheﬁeldofastrostatistics
and astroinformatics continues to grow, we hope this paper will serve as both a helpful reference and as a jumping oﬀ point for
deeper dives into the statistics and astrostatistics literature.
Key words: astrostatistics – computational methods – parallax
1 INTRODUCTION
Over the past two decades, Bayesian inference has become increas-
ingly popular in astronomy. On NASA’s Astrophysics Data Sys-
tem (ADS), a search using “keyword:statistical” and “abs:bayesian”
yields2377refereedpapers,andshowsexponentialgrowthsincethe
year 2000, with over 237 papers in 2021.
Bayesian analyses have become popular in astronomy due to sev-
eral key advantages over traditional methods. First, an estimate of
theposteriordistributionofmodelparametersprovidesamorecom-
plete picture of parameter uncertainty, joint parameter uncertainty,
and parameter relationships given the model, data, and prior as-
sumptions than traditional methods. Second, the interpretation of
Bayesian probability intervals is often closer to what scientists de-
sire, and is an appealing alternative to point estimates with conﬁ-
dence intervals which often rely on the sampling distribution of the
estimator.Third,Bayesiananalysiseasilyallowsformarginalization
over nuisance parameters, incorporation of measurement uncertain-
tiesthroughmeasurementerrormodels,andinclusionofincomplete
★E-mail: gwen.eadie@utoronto.cadata such as missing and censored data. Fourth, astronomers of-
ten have prior knowledge about allowable and realistic ranges of
parameter values (e.g., through physical theories and previous ob-
servations/experiments) which can naturally be included in prior
distributions and thereby improve the ﬁnal inference.
Importantly, in addition to the aforementioned advantages of the
Bayesian approach, eﬃcient and increased computing power, along
witheasy-to-useorout-of-the-boxalgorithms,havebroughtBayesian
methodologytoastronomersinconvenientpracticalforms(e.g., em-
cee(Foreman-Mackey et al. 2013), Rstan(Stan Development Team
2020),PyStan(Riddell et al. 2017), PyMC3(Salvatier et al. 2016),
BUGS (Lunn et al. 2000), NIMBLE (de Valpine et al. 2017), and
JAGS (Plummer et al. 2003)).
Interestingly, the surge in popularity of Bayesian statistics comes
in spite of the fact that Bayesian methods are rarely taught in un-
dergraduate astronomy and physics programs, and has only recently
beenintroducedatabasiclevelinastronomygraduatecourses(Eadie
et al. 2019b,a). Some challenges faced by both new and seasoned
users of Bayesian inference are the varied notation, terminology, in-
terpretation,andchoiceofalgorithmsavailableintheastronomyand
statistics literature.
©0000 The AuthorsarXiv:2302.04703v1  [astro-ph.IM]  9 Feb 20232G.M. Eadie et al.
Beingwell-versedinbestpracticesandcommonpitfallsassociated
withtheBayesianframeworkisimportantifthesemethodsaretobe
used to advance the ﬁeld of astronomy. Here, users of Bayesian
inferenceinastronomyfacechallengestoo,sinceundergraduateand
graduate program training is still catching up to the state-of-the-art
Bayesian inference methods.
The goal of this paper is two-fold. Our ﬁrst goal is to provide a
“translation” between terminology and notation used for Bayesian
inference across the ﬁelds of astronomy and statistics. Our second
goalistoillustrateusefulpracticesfortheBayesianinferenceprocess
which we hope will be a valuable contribution to astronomers who
arefamiliarwithand/oruseBayesianstatisticsinresearch.Toachieve
these goals, we deal with the following topics in the main body of
the paper: notation (Section 2.1), interpreting and determining the
likelihood (Section 2.2), choosing and assessing prior distributions
(Section 2.3), evaluating and making inference from the posterior
distribution(Section2.4),andperformingposteriorpredictivechecks
(Section 2.5).
This work is not meant to be a comprehensive introduction to
Bayesian inference, but rather an unveiling of Bayesian statistics as
both an extensive topic and an active research area. We focus our
eﬀorts on identifying common mistakes and misunderstandings re-
lated to Bayesian inference, and use these as jumping oﬀ points for
highlighting important topics for further study. Indeed, many valu-
able topics and subtopics arise which we do not cover, but we make
a point of providing key references. For example, throughout the
paper we touch on areas such as Bayesian design, posterior pre-
dictivechecking,hierarchicalmodeling,andBayesiancomputations
(Craiu&Rosenthal2014;Robert2014),andalsorecommendbooks
on Bayesian data analysis from statistics and astrostatistics (Gelman
et al. 2013; Carlin & Louis 2008; Hilbe et al. 2017).
Tohelpthenarrative,weusearunningexampleattheendofeach
section — inferring the distance to a star through its parallax mea-
surement.Thespeciﬁcproblemofdistanceestimationfromparallax
in the Bayesian context is explored closely in other studies (Bailer-
Jones 2015; Astraatmadja & Bailer-Jones 2016a,b) and applied to
theGaiaseconddatarelease( GaiaDR2)(Lindegren,L.etal.2018;
Bailer-Jones et al. 2018; Schönrich et al. 2019), and we refer the
reader to these papers for a deep exploration on this topic. Here,
we employ this example because of its generality, because it pro-
videssomeinterestingchallengesandpotentialpitfalls,andbecause
itprovidesaniceframeworktoillustratesoundpracticesinBayesian
analysis. Along the way, we also identify how our advice applies to
other areas in astronomy.
2 SPECIFYING A BAYESIAN MODEL
2.1 Notation & Bayes Theorem
A number of diﬀerent notation practices for Bayesian inference are
used in both the astronomy and statistics literature. This section is
meant to clarify some of these diﬀerences, while also providing a
“translation” so that astronomers can more easily follow statistics
papers (e.g., recognize notation for random variables, probability
distribution functions, etc.).
We use 𝒚(vectorized form) to represent the observed data of a
random variable 𝑌, and 𝜽to represent the parameter(s) of interest.
The posterior distribution is deﬁned by Bayes’ theorem as
𝑝¹𝜽j𝒚º=𝑝¹𝒚j𝜽º𝑝¹𝜽º
𝑝¹𝒚º(1)
where𝑝¹𝒚j𝜽ºis thesampling distribution for𝒚given 𝜽(Section2.2),𝑝¹𝜽ºis theprior density (Section 2.3), and 𝑝¹𝒚ºis theprior
predictivedensity (Schervish1995).Withthedata 𝒚inhand,𝑝¹𝒚j𝜽º
isoftenviewedasafunctionof 𝜽calledthe likelihoodfunction (which
isnotaprobabilitydensity),and 𝑝¹𝒚ºisanormalizingconstantthat
does not depend on 𝜽(which is often referred to in astronomy as
the model evidence). In the probability and Bayesian computation
literature, the posterior probability distribution of interest is usually
denoted and referred to as the target distribution with the notation
𝜋. There are also diﬀerences in notation for the likelihood across
disciplines, which we discuss in Section 2.2.
For smooth translation between sub-disciplines of astronomy and
statistics, it is beneﬁcial to use explicit statements about model
choices and parameter deﬁnitions. For example, a list of all model
parameters, notation, and their associated prior probability distribu-
tions in the form of a table is very useful to the reader. Moreover,
we stress the importance of fully specifying any Bayesian model in
paperstoincreasereproducibility(e.g.,viaadetailedappendix,open
code). In this spirit, we provide the full Bayesian model for our run-
ningexampleinTable1,explicitlydeﬁnenotationnext,andprovide
our open source code1.
2.1.1 Parallax Example: Deﬁning Notation
For the running example in this paper, we infer the distance to a star
from a parallax measurement. The true but unknown distance 𝑑in
kiloparsecs (kpc) is related to the true but unknown parallax 𝜛in
milliarcseconds (mas) through
𝑑»kpc¼=1
𝜛»mas¼ (2)
Ourdata𝑦isameasurementoftheparallax,andhassomeﬁxedun-
certainty𝜎thatwetreatasknown.Thus,intheBayesianframework,
wewishtoinfertheparameter 𝑑giventhedata 𝑦,andweseektoﬁnd
the posterior distribution,
𝑝¹𝑑j𝑦º/𝑝¹𝑦j𝑑º𝑝¹𝑑º (3)
In Section 2.4.2, we extend this example to infer the distance to a
star cluster from the parallax measurements of many stars within
the cluster. The true but unknown distance to the cluster, 𝑑cluster,
is related to the true but unknown parallax of the cluster through
Equation2,too.Inthiscase,weexpressthecorrespondingposterior
density as follows:
𝑝¹𝑑clusterj𝒚º/𝑝¹𝒚j𝑑clusterº𝑝¹𝑑clusterº (4)
where 𝒚represents a vector of parallax measurements of its stars.
Table 1 summarizes this model speciﬁcation.
2.2 Likelihood function
Diﬀerences in notation and language between statistics and astron-
omy can lead to confusions regarding the likelihood. In Bayesian
statistics, the capital letters 𝑌andΘoften denote random variables .
Forexample,bothGelmanetal.(2013)intheirappliedstatisticstext
and Schervish (1995) in his statistics theory text ﬁrst write down
ajointprobability density 𝑝¹Θ𝑌º, and then specify the likelihood
functionas𝑝¹𝑌=𝒚j𝜽º(sometimeswritten L¹𝜽ºelsewhere),where
𝒚istheﬁxed,observedvalueof 𝑌(i.e.,thedata),and 𝜽istheargument
ofthelikelihoodfunction.Thatis,thelikelihoodisafunctionofthe
parameters 𝜽,giventhedata 𝒚(Gelmanetal.2013;Schervish1995;
1https://github.com/joshspeagle/nrp_astrobayes
RASTI 000, 1–10 (0000)Bayesian inference in Astronomy 3
Table 1.Bayesianmodelsforinferring(1)astar’sdistanceparameter 𝑑fromitsparallaxmeasurement 𝑦,assumingaGaussiandistributionforitstrueparallax
𝜛(top panel), and (2) a star cluster’s distance parameter 𝑑clusterfrom the parallax measurement of 𝑛stars𝒚(bottom panel).
Inferring a single star’s distance parameter 𝑑
Sampling density / likelihood (parallax) 𝑝¹𝑦j𝑑º=𝑁¹𝑦j1𝑑𝜎2º, where𝜛=1𝑑
Prior (distance) 𝑝¹𝑑º/(
𝑑2𝑒 𝑑𝐿if𝑑min𝑑𝑑 maxwith a constant 𝐿
0 otherwise
Posterior on distance 𝑝¹𝑑j𝑦𝜎 𝜛º/𝑑2exph
 𝑑
𝐿 ¹𝑦 1𝑑º2
2𝜎2i
Inferring a star cluster’s distance parameter 𝑑cluster
Sampling density / likelihood ( 𝑛parallax measurements) 𝑝¹𝒚j𝑑clusterº=Î𝑛
𝑖=1𝑁¹𝒚j1𝑑cluster𝜎2
𝑖º
Prior (on parallax of cluster) 𝑝¹𝜛clusterº=𝑁¹𝜛clusterj𝜇𝜛𝜎𝜛º
Posterior on distance to cluster 𝑝¹𝑑clusterj𝒚º/𝑝¹𝑑clusterºexp
 ¹𝑦𝑒 𝑓 𝑓 1𝑑clusterº2
2𝜏2
2In both the upper and lower box, 𝜎and𝜎𝑖:𝑖=12𝑛are assumed to be known. Throughout 𝑁¹𝑦j𝑎𝑏ºdenotes the Gaussian density function of 𝑦
with mean𝑎and variance𝑏.
Carlin & Louis 2008; Berger & Wolpert 1988; Casella & Berger
2002). However, in astronomy, it is not unusual to see phrases such
as “the likelihood function of the data given the model parameters”,
whichmightbemisconstruedastreatingthelikelihoodfunctionasa
function of data. Finally, we note that the likelihood function of 𝜽is
not a probability density function of 𝜽.
In Table 2, we summarize common notation for the likelihood
found in both the statistics and astronomy literature, which ranges
from being very explicit (e.g., 𝑓𝑌¹𝒚j𝜽º) to quite simpliﬁed (e.g.,
𝑃¹𝒚j𝑀º). We note that a subtlety sometimes missed in astronomy
is the diﬀerence between 𝑝and𝑃. In statistics, 𝑓and𝑝are often
used for probability density functions (pdf) of continuous random
variables, and 𝑃or𝑃𝑟are used to denote probabilities of discrete
events (probability mass functions (pmf) are an exception, and are
often denoted using 𝑓,𝑝, or𝑃). A capital𝐹is usually reserved for
the cumulative distribution function (cdf).
Determining what the likelihood function should be in a given
astronomy problem can be challenging, and care must be taken to
choose an appropriate sampling distribution. The likelihood is of-
ten taken to be a product of independent and identically distributed
(i.i.d.) Gaussian random variables with known variance. While this
choice is sometimes plausible, there are also many cases in which it
isinappropriate,andhasamaterialeﬀectoninference.Forinstance,
when describing the brightness of a high energy source, a discrete
distribution such as the Poisson distribution is usually more appro-
priate than a Gaussian. In other cases, uncertainty in the variance
of the data might lead us to use a likelihood function based on the
𝑡-distribution or another non-Gaussian parametric family. A further
consideration is whether the data being modeled are collected as a
functionofspaceortime,inwhichcasetheassumptionofexchange-
ability –that data can be reordered without aﬀecting the likelihood
– is generally unwarranted. In these cases, an expanded model that
includes correlation among observations should be considered.
Best practice includes all non-negligible contributors to the mea-
surementprocessinthelikelihoodfunction.Forexample,itisimpor-
tant to account for substantial truncation and censoring issues when
present, because these can strongly inﬂuence parameter inference in
some cases (Rubin 1976; Eadie et al. 2021). Other common issues
tocheckforandaddressaremeasurementuncertainty,correlateder-
rors, measurement bias, sampling bias, and missing data. There area number of valuable references in the statistics literature on these
topics (Rubin 1976; Little & Rubin 2019). We recommend writing
down enough mathematical details to uniquely determine the like-
lihood by deﬁning (algebraically) not only the physical process of
interest but also the sampling/measurement process that generated
the data.
2.2.1 Parallax Example: the likelihood function
TheGaiaspacecraft has measured parallaxes for over a billion stars
(Gaia et al. 2018; Collaboration et al. 2018). These parallaxes have
been shown empirically, through simulations (Holl et al. 2012; Lin-
degren et al. 2012), to follow a normal distribution with mean equal
to the true underlying parallax 𝜛so that
𝑝¹𝑦j𝜛º=1p
2𝜋𝜎2exp
 ¹𝑦 𝜛º2
2𝜎2
or equivalently, (5)
𝑦j𝜛𝜎𝑁¹𝜛 𝜎2º (6)
where𝑦is the measured parallax and 𝜎is the associated (assumed
known) measurement uncertainty (Hogg 2018). The parameter of
interest is the distance 𝑑, so we rewrite Equation 6 as
𝑝¹𝑦j𝑑º=1p
2𝜋𝜎2exp
 ¹𝑦 1𝑑º2
2𝜎2
or equivalently, (7)
𝑦j𝑑𝜎𝑁¹1𝑑 𝜎2º (8)
We note that a similar Gaussian model assumption is widely ap-
plicable to various sub-ﬁelds in observational astronomy such as
detecting exoplanets by RV (Danby 1988; Mayor et al. 2011; Pepe
et al. 2011; Fischer et al. 2013; Butler et al. 2017) or by transit
(Konacki et al. 2003; Alonso et al. 2004; Dragomir et al. 2019), in-
ferringthetruebrightnessofasource(Taketal.2017),orestimating
the Hubble constant (Hubble 1929). This is because the statistical
details are analogous; the observation is measured with Gaussian
measurement error, estimated measurement error uncertainty 𝜎is
treated as a known constant, and the mean model can be written as
adeterministicfunctionofotherparameters,e.g., 𝜛=1𝑑inEqua-
tion 6. On the other hand, as mentioned already, in each new setting
itisimportanttocarefullyconsiderwhichmodelismostappropriate;
RASTI 000, 1–10 (0000)4G.M. Eadie et al.
[t!]
Table 2.Likelihood notation found in diﬀerent contexts.
Notation Description Context
𝑓𝑌¹𝒚j𝜽ºdistribution function of the random variable 𝑌, statistics
but viewed as a function of 𝜽, with 𝒚ﬁxed
𝑝¹𝒚j𝜽º format used in this paper (common) statistics and astronomy
L¹𝜽;𝒚ºorL¹𝜽ºexplicit notation for the likelihood with speciﬁc statistics topics, e.g.,
argument 𝜽 maximum likelihood estimation
𝑃¹𝑫j𝜽º𝐷represents the data astronomy
𝑃¹𝒚j𝑀º𝑀represents the model assumption, astronomy, model selection
implicitly suggests parameters
𝑃𝑟¹𝒚j𝜽𝐻º𝐻represents a particular proposed model astronomy, model selection
Gaussian-based models are (i) sometimes misused, (ii) overused, or
(iii) sometimes inappropriate.
2.3 Prior Distributions
The prior probability distribution, or the prior, captures our initial
knowledgeaboutthemodelparametersbeforewehaveseenthedata.
Priors may assign higher probability (or density) to some values of
the model parameters over others. Priors are often categorized into
twoclasses: informative andnon-informative .Theformertypesum-
marizesknowledgegainedfrompreviousstudies,theoreticalpredic-
tions,and/orscientiﬁcintuition.Thelattertypeattemptstoincludeas
little information as possible about the model parameters. Informa-
tive priors can be conjugate (Diaconis & Ylvisaker 1979), mixtures
ofconjugatepriors(Dalal&Hall1983),scientiﬁcallymotivated(Tak
etal.2018;Lemoine2019),basedonpreviousdata,orinthecaseof
empirical Bayes, based on the data at hand (often called data-driven
priors) (Carlin & Louis 2000; Maritz 2018). Non-informative priors
can be improper or “ﬂat”, weakly-informative, Jeﬀrey’s priors (Tuyl
et al. 2008), or other reference distributions. Conjugate priors are
sometimes deﬁned to be non-informative.
One popular choice for a non-informative prior is an improper
prior—apriorthatisnotaprobabilitydistributionandinparticular
does not integrate to one. Good introductions to improper priors are
available in the statistics literature (Gelman et al. 2013, 2017). An
example of an improper prior is a ﬂat prior on an unbounded range,
e.g., Unif(0,1) or Unif( 1,1). When an improper prior has been
adopted,itisimperativetocheckwhethertheresultingposteriorisa
properprobabilitydistributionbeforemakinganyinference.Without
posterior propriety the analysis has no probability interpretation.
Empirical checks may not be suﬃcient; posterior samples may not
reveal any evidence of posterior impropriety, forming a seemingly
reasonabledistributionevenwhentheposteriorisactuallyimproper
(Hobert & Casella 1996; Tak et al. 2018).
Researchonquantifyingpriorimpactisactive(e.g.,eﬀectiveprior
samplesizeClarke1996;Reimherretal.2014;Jonesetal.2020)as
is the discussion on choosing a prior in the context of the likelihood
(Reimherr et al. 2014; Gelman et al. 2017; Jones et al. 2020).
In astronomy, there is a tendency for scientists to adopt non-
informative prior distributions, perhaps because informative priors
are perceived as too subjective or because there is a lack of easily
quantiﬁableinformationabouttheparametersinquestion.However,
all priors provide someinformation about the likely values of the
modelparameter(s),evena“ﬂat”prior.Notably,aﬂatpriorisnon-ﬂatafter a transformation. For instance, in our example (Section 2.3.1)
a “non-informative” uniform prior distribution on the parallax of a
star is actually quite informative in terms of distance (third panel,
Figure 1). Thus, we recommend carefully considering what direct
or indirect information is available about the value of a parameter
before resorting to default or non-informative priors; in astronomy,
we usually have at least a little information about the range of al-
lowedorphysicallyreasonablevalues.Evenwhenanon-informative
priordoesseemappropriate,checkingthatthechosendistributionis
consistent with known physical constraints is essential.
Complete descriptions and mathematical forms of prior distribu-
tions, including the values of hyperparameters deﬁning these dis-
tributions, help promote reproducibility and open science. Unfortu-
nately, a recent meta-analysis of the astronomical literature showed
that prior deﬁnitions are often incomplete or unstated (Tak et al.
2018), making it diﬃcult for others to interpret results.
To summarize, good practices in the context of priors are: (1)
choosing informative priors when existing knowledge is available,
(2) choosing priors with caution if there is no prior knowledge,
(3) testing the inﬂuence of alternative priors (see the discussion of
sensitivity analyses in Section 2.4), and (4) explicitly specifying the
chosen prior distributions for clarity and reproducibility.
2.3.1 Parallax Example: choosing a prior
A naive choice of prior on the true parallax 𝜛is𝑝¹𝜛º/constant,
an improper prior that assigns equal density to all values of 𝜛from
¹0¸1º. A straightforward way to be more informative and proper
is to instead deﬁne a truncated uniform prior, where 𝜛is uniformly
distributed between 𝜛=¹𝜛min𝜛maxºso that
𝑝¹𝜛º/(
constant𝜛min𝜛 𝜛 max
0 otherwise (9)
or equivalently,
𝜛Unif¹𝜛min𝜛maxº (10)
Here,𝜛minand𝜛maxare hyperparameters set by the scientist (e.g.,
using some physically-motivated cutoﬀ for 𝜛minand the minimum
realistic distance to the star for 𝜛max). Thus the prior in Equation 9
canberegardedasweakly-informativebecausesomephysicalknowl-
edge is reﬂected in the bounds. Similarly, we could instead deﬁne a
RASTI 000, 1–10 (0000)Bayesian inference in Astronomy 5
uniform prior on distance:
𝑝¹𝑑º/(
constant𝑑min𝑑 𝑑 max
0 otherwise (11)
or equivalently,
𝑑Unif¹𝑑min𝑑maxº (12)
where𝑑min=1𝜛maxand𝑑max=1𝜛min. Like Equation 9, this
prior can also be regarded as weakly-informative. However, both
display drastically diﬀerent behavior as a function of 𝑑(see Fig-
ure 1), which highlights how the interpretation of non-informative
(or weakly-informative) priors may change depending on the choice
of parameterization.
While the prior in Equation 11 may appear non-informative (in
a sense that it is uniform), it actually encodes a strong assumption
aboutthenumberdensityofstars 𝜌asafunctionofdistance.Theprior
implies that we are just as likely to observe stars at large distances
as we are at smaller distances. However, as we look out into space,
the area of the solid angle deﬁned by the distance 𝑑increases, and
thisinturnimpliesthatthestellarnumberdensityisdecreasingwith
distance.Thus,Equation11,whichsaysthatalldistancesareequally
likely,impliesthattherearefewerstarspervolumeatlargedistances
than stars per volume at small distances.
Bailer-Jonesetal.(2018)introducedabetterpriorfortheparallax
inference problem, which we outline brieﬂy and reproduce here.
The physical volume d𝑉probed by an inﬁnitesimal solid angle on
the sky dΩat a given distance 𝑑scales as the size of a shell so that
dΩ/𝑑2.Thismeansthat,assumingaconstantstellarnumberdensity
𝜌everywhere, a prior behaving as 𝑝¹𝑑º/𝑑2is more appropriate.
However, we can go one step further — we know that our Sun sits
in the disk of the Galaxy, and that the actual stellar density 𝜌as
we go radially outward in the disk should decrease as a function
of distance. Assuming we are looking outward, and that the stellar
density decreases exponentially with a length scale 𝐿(so that for a
given distance we have 𝑝¹𝜌j𝑑º/𝑒 𝑑𝐿) the prior on distance is
𝑝¹𝑑º/(
𝑑2𝑒 𝑑𝐿𝑑min𝑑 𝑑 max
0 otherwise (13)
which is the density function of a truncated Gamma( 3𝐿) distri-
bution. The scientist using Equation 13 would need to choose and
deﬁne the three hyperparameters 𝑑min𝑑maxand𝐿. Equation 13 is
the exponentially decreasing space density prior of previously pre-
sentedinBailer-Jonesetal.(2018).Figure1illustratesallthreepriors
discussed here.
2.4 Posterior distributions
The posterior distribution of Equation 1 is the focus of Bayesian
inference. Once the prior distribution(s) and the likelihood function
are speciﬁed, the posterior distribution is uniquely determined. Of-
ten, the denominator quantity 𝑝¹𝒚ºis not available analytically. In
this case,𝑝¹𝒚ºcan be estimated by numerical integration. Samples
drawn from 𝑝¹𝜽j𝒚ºcan be used to estimate properties of the pos-
terior. A popular approach for obtaining samples is to construct a
MarkovChainwhosestationarydistributionisdesignedtomatchthe
target distribution 𝑝¹𝜽j𝒚º, which is known as Markov chain Monte
Carlo(MCMC).ThecanonicalexampleistheMetropolis-Hastingal-
gorithm(Metropolis&Ulam1949;Metropolisetal.1953;Hastings
1970; Gelman et al. 2013), but there are many variations, some of
which are designed to address speciﬁc challenges such as samplinghigh-dimensional or multi-modal target distributions; see Brooks
et al. (2011) for details.
The posterior distribution enables inference of model parameters
or of quantities that can be derived from model parameters. For
example, the posterior mean 𝐸¹𝜃j𝑦ºis a point summary for 𝜃. The
posterior distribution can also be used to deﬁne credible intervals
for parameters that provide a range of probable values. We stress
that credible intervals are not conﬁdence intervals; a 95% credible
interval suggests that there is a 95% probability that the parameter
lieswithinthespeciﬁedrangegivenourpriorbeliefs,themodel,and
the data, whereas a 95% conﬁdence interval suggests that if similar
intervals are properly constructed for multiple datasets then 95% of
them are expected to contain the true (ﬁxed) parameter value.
Depending on the characteristics of the posterior distribution, we
emphasize that point summaries and intervals may not provide a
complete description of uncertainty (e.g., for multi-modal posteri-
ors). Here, visualizations of the posterior can provide a more com-
prehensivepicture(seeFigure2).Recommendationsandopensource
softwarepackagescontainingvisualizationtoolsforBayesiananaly-
sis can be found in the statistics literature (Gabry et al. 2019; Gabry
& Mahr 2019; Kumar et al. 2019; Vehtari et al. 2020). Projections
of the joint posterior distribution into two parameter dimensions —
also colloquially referred to as a corner plot in astronomy literature
—isthemostcommonvisualizationtool.Drawingcredibleregions
orcontoursonthesetypesofvisualizationsarealsohelpful,although
defaulting to a “1-sigma” credible region is not always appropriate
(i.e., when the distributions are non-Gaussian).
Theposteriordistributionalsoprovidesausefulwaytoobtaines-
timatesandcredibleintervalsforotherquantitiesofphysicalinterest.
For example, if a model has parameters 𝜽=¹𝛼𝛽𝜅ºand there is
somephysicalquantitydescribedbye.g., 𝛾=𝛽2𝛼𝑒𝜅,thenforevery
sampleof 𝜽,asampleof 𝛾canbecalculated.Thus,a distribution of
the physically interesting quantity 𝛾is obtained, which can also be
usedtoobtainpointestimatesandcredibleintervals.Inotherwords,
intheBayesianparadigm,uncertaintiesineachmodelparameterare
naturally propagated to uncertainties in derived physical quantities
in a coherent way.
Posterior distributions can be complicated in shape (e.g., asym-
metric, with multiple modes). This can create computational chal-
lengesincaseswheretheposteriorcannotbederivedinclosedform.
Fortunately, many algorithms have been developed for approximat-
ing the posterior distribution. Diﬀerent algorithms perform well for
diﬀerent characteristics of the posterior, and therefore prior knowl-
edge of what we might expect the posterior to look like, as well
preliminary explorations, are often valuable in practice. In addition
to the MCMC sampling algorithms already mentioned, a number
of other techniques have been developed. For example, integrated
nested Laplace approximations (Rue et al. 2009) approximates pos-
terior distributions, variational Bayes methods (Jordan et al. 1999;
Blei et al. 2003; Hoﬀman et al. 2013), and approximate Bayesian
computation(Beaumontetal.2009;Marinetal.2012;Weyantetal.
2013;Akeretetal.2015;Ishidaetal.2015;Beaumont2019)arepos-
sible alternatives when the likelihood functions are too complicated
or expensive to be evaluated.
2.4.1 Parallax Example: inferring the distance to a star
Inourrunningexample,weareinterestedininferringtheparameter
for the distance 𝑑=1𝜛given the measured parallax 𝑦and its
associated measurement uncertainty 𝜎(which we treat as known).
RASTI 000, 1–10 (0000)6G.M. Eadie et al.
Parallax [mas] Distance [kpc]Likelihood
Observed 
units
(𝜛)Physical 
units
(d=1/𝜛)Prior
Uniform (parallax)
Uniform (distance)Physically -motivatedPosterior
Distance [kpc] Distance [kpc]
∝ ×
GaussianNon-
Gaussian
Figure 1. Bayesianinferenceofthedistance 𝑑=1𝜛toastarbasedonthemeasuredparallax 𝑦.Farleft:Thelikelihoodforparallax 𝜛isnormalwithvariance
assumed known. Center left: A transformation of parameters from 𝜛to𝑑gives a non-normal PDF. Note that a non-negativity constraint was applied to the
distributionof 𝑑.Centerright: Wehighlightthreepossiblepriors 𝑝¹𝑑ºoverthedistance:uniforminparallax 𝜛=1𝑑(blue),uniformindistance 𝑑(red),and
a physically-motivated prior (Bailer-Jones et al. 2018) (orange). Far right: The posteriors that correspond to each of the three priors.
Distance [kpc]
Probability [normalized]Mode
Median
90% Credible Interval
Figure 2. ThethreeposteriordistributionscorrespondingtoeachpriordistributionshowninFigure1:uniforminparallaxprior(bluecurve),uniformindistance
prior(redcurve),andphysically-motivatedprior(orangecurve).Alsoshownareonesummarystatisticforeachposterior:themode(bluedottedline),themedian
(red dotted-dashed line), and the 90% credible interval (orange dashed lines and shaded region).
From Bayes’ theorem, the posterior is
𝑝¹𝑑j𝑦º/𝑝¹𝑦j𝑑º𝑝¹𝑑º (14)
For the three priors discussed previously, this corresponds to the
following posteriors:
Equation 9)𝑝¹𝑑j𝑦º/1
𝑑2exp
 ¹𝑦 1𝑑º2
2𝜎2
(15)
Equation 11)𝑝¹𝑑j𝑦º/exp
 ¹𝑦 1𝑑º2
2𝜎2
(16)
Equation 13)𝑝¹𝑑j𝑦º/𝑑2exp
 𝑑
𝐿 ¹𝑦 1𝑑º2
2𝜎2
(17)for𝑑min𝑑 𝑑 max(and 0otherwise).Whilenoneofthesehavean-
alytic solutions for point estimates or credible intervals, they can be
computedusingcomputationaltechniques.Approximationstothese
threeposteriordistributionsareshowinFigures1and2.Inthisillus-
tration, though each resulting posterior distribution is right-skewed,
the shape is notably diﬀerent for each considered prior distribution.
2.4.2 Extended Example: inferring the distance to a clusterof stars
We now extend our example to infer the distance to a cluster of
stars, based on the collection of parallax measurements of each in-
dividual star. Assuming that there are 𝑛stars located at approxi-
mately the same distance 𝑑clusterand that the measured parallaxes
RASTI 000, 1–10 (0000)Bayesian inference in Astronomy 7
𝒚=f𝑦1𝑦2𝑦𝑛gto each star are independent given 𝑑cluster, our
combined likelihood is the product of the individual likelihoods
𝑝¹𝑦1𝑦2𝑦𝑛j1𝑑clusterº=𝑛Ö
𝑖=1𝑝¹𝑦𝑖j1𝑑clusterº (18)
where the individual likelihoods are deﬁned following Equation 6.
We assume that the measurement uncertainties 𝜎𝑖are known con-
stants. Our posterior is
𝑝¹𝑑clusterj𝒚º/𝑝¹𝑑clusterº𝑛Ö
𝑖=1𝑝¹𝑦𝑖j1𝑑clusterº (19)
Theproductof 𝑛independentGaussiandensitieswithknownvari-
ancesisaGaussiandensitywithprecisionparameter 𝜏 2=Í𝑛
𝑖=1𝜎 2
𝑖
andmeanparameter 1𝑑cluster.Theobservedparallaxescanbecom-
binedtoobtainaneﬀectiveparallax 𝑦eﬀ=𝜏2Í𝑛
𝑖=1𝑦𝑖𝜎2
𝑖,andthus,
𝑝¹𝑑clusterj𝒚º/𝑝¹𝑑clusterºexp
 ¹𝑦eﬀ 1𝑑clusterº2
2𝜏2
 (20)
The estimated posterior distribution over 𝜛cluster=1𝑑clusterfor
anearbyclusterofstars(M67)usingdatafrom GaiaDR2,andusing
a conjugate Gaussian prior for 𝜛cluster, is shown in Figure 3. The
top panel of Figure 3 shows the individual parallax measurements
of stars in M67, sorted by their signal-to-noise values. The bottom
panel shows the assumed prior distribution (narrow left panel) and
the (estimated) posterior distribution for the cluster’s parallax, as
more and better data are added to the analysis.
Note:A prior over 𝑝¹𝑑clusterº, which governs the distribution of
clustersofstars,isnotthesameasapriorover 𝑝¹𝑑º,whichgoverns
the distribution of individual stars. While it might be reasonable to
assumethesearesimilar,theyarenotinterchangeablequantitiesand
may indeed follow diﬀerent distributions. Realizing the diﬀerences
in priors between various scenarios such as these is key to building
good models and subsequently making good inferences.
2.5 Posterior Predictive Checking
Afterobtainingtheposteriordistribution,itisrecommendedtoassess
theadequacyofthemodelusing posteriorpredictivechecks (Gelman
et al. 1996), which compare the empirical distribution of the data
to the distribution described by the Bayesian model. The posterior
predictive distribution is the posterior distribution of hypothetical
future data ( ˜𝒚) under the chosen model and given the previously
collected data:
𝑝¹˜𝒚j𝒚º=∫
𝑝¹˜𝒚𝜽j𝒚º𝑑𝜽 (21)
Weﬁndthatposteriorpredictivecheckingisunderusedinastronomy
but can be very useful. Posterior predictive checks not only assess
thetheadequacyofthemodelbutalsosimultaneouslycheckanyap-
proximationstotheposterior.Theyareavaluabletoolfordiagnosing
issues with computational sampling methods.
Inmostcases,theposteriorpredictivedistributionisnotavailable
in closed form. However, it is possible to generate simulated obser-
vations from theposterior predictive distribution andcompare these
totheoriginaldata.Forexample,foreachoftheposteriorsamplesof
𝜽,drawarandomsampleof ˜𝒚andcomparethesesamplestothereal
data. Signiﬁcant or systematic diﬀerences between the distributions
oftherealandsimulateddatamaysuggestaproblemwiththemodel.
It is good practice to perform quantitative and/or graphical com-
parison between the simulated data and the real data. For graphicalcomparison, an overlaid density plot could be used (top panel of
Figure4),butingeneralthisisapoorchoicebecauseitisdiﬃcultto
judge diﬀerences between the overlaid densities visually. For graph-
ical comparison, we recommend instead using a quantile-quantile
(Q-Q)plottocharacterizeanydiﬀerences(bottompanelofFigure4).
To construct a Q-Qplot, it suﬃces to compute the quantiles from
the original data and from the posterior predictive distribution (or
from data simulated from the posterior predictive distribution), and
toplotthepairsoneagainsttheother(bottompanel,Figure4).Ifthe
empiricaldistributionandtheposteriorpredictivedistributionmatch,
then their quantiles should lie along a 1:1 line. Functions to display
Q-Qplots are common in statistical computing software languages.
Inourparallaxexample,parallaxvaluesinthetailsofthesimulated
and real data distributions show some disagreement (Figure 4). The
Q-Qplot shows this more explicitly that the density plot, as the
quantiles do not follow the 1:1 line in the tails of the distribution
(below10th percentile and above 70th percentile). Diﬀerences
ineitherendofa Q-Qplotcanbeduetochance,butstrongdeviations
from the 1:1 line are usually worth investigating.
There are also other valuable approaches for checking a Bayesian
modelandthequalityofapproximationstotheposteriordistribution.
For example, one may set a portion of the data aside, or obtain ad-
ditional data, and then compare the resulting inference to that from
the original data. One may also use multiple methods for approxi-
matingtheposteriordistribution,andcompareresults.Thiscanhelp
diagnose situations where one or more sampling algorithms did not
explore the full parameter space, and consequently fail to include
high-probability regions in the posterior samples.
Inadditiontomodelandposteriorchecking,itisimportanttocon-
sider the inﬂuence of the prior distribution(s). The rightmost panel
of Figure 1 shows three posteriors: each one used one of the three
priors discussed in Section 2.3.1. While the posteriors are vaguely
similarinshape(e.g.,right-skewed),theinferredsummarystatistics
can be quite diﬀerent (Figure 2).
Moregenerally,investigatinghowtheanalysiscomparesforseveral
diﬀerentpriordistributionsisanimportanttechnique,oftenreferred
to as asensitivity analysis . A sensitivity analysis directly assesses
the impact of the prior distribution on the posterior, and for this
reason we recommend them — particularly when the information
availabletoconstructapriorislimited.Ontheotherhand,sensitivity
analyses can be somewhat ad hoc (e.g., which priors are tried, how
theyarecompared)makingitdiﬃculttosummarizeandcomparethe
priorimpactacrossmultipleanalyses,instruments,andmodels.More
principledapproachesmaythereforebepreferredorcomplementary
in some scenarios. One such method is to quantify the eﬀective
prior sample size (EPSS), i.e., the number of data points that the
information provided by the prior distribution corresponds to.
The EPSS is simple to compute for conjugate models. For exam-
ple, if we have the data 𝑦𝑖𝑖𝑖𝑑𝑁¹𝜇𝜎2º, for𝑖=1𝑛, and the
conjugatepriordistribution 𝜇𝑁¹𝜇0𝜎2𝑚º,withknown 𝜎2,then
the posterior distribution of 𝜇has variance 𝜎2¹𝑛¸𝑚º. Thus, the
eﬀectofthepriorisequivalenttothatof 𝑚samples,andwesaythat
the EPSS is𝑚. The statistics literature includes proposals of several
methods for extending this idea beyond conjugate models (Clarke
1996; Morita et al. 2008; Reimherr et al. 2014; Jones et al. 2020)
and how to additionally account for location discrepancies, e.g., the
valueofj¯𝑦 𝜇0jintheprecedingexample.Clarke(1996)andMorita
et al. (2008) use EPSS to quantify the information in the prior in
isolationfromthedata,whileReimherretal.(2014)andJonesetal.
(2020)concentrateontheimpactoftheprioronthespeciﬁcanalysis
RASTI 000, 1–10 (0000)8G.M. Eadie et al.
Number of ObjectsMeasured
LikelihoodPosteriorPriorParallax [mas]
ClusterCombine
More informationInferredParallax [mas]
Individual 
Measurements
Figure 3. Extended Example for Open Cluster M67. An extension of the example shown in Figure 1 illustrating how to infer the distance to an open cluster
(M67)basedonparallaxmeasurementsofmanystars. Top:Parallaxmeasurements(gray)forlikelyclustermembers(basedonpropermotions),sortedbytheir
observedsignal-to-noseratio 𝜛obs𝜎𝜛.Bottom:Thejointlikelihood(gray)andposterior(blue)fortheclusterparallax 𝜛cluster=1𝑑clusterasmoreandmore
starsareaddedtoouranalysis.The(Gaussian)priordistributiononthecluster’sparallaxisillustratedinthenarrowleftpanel.Whenthereisonlyasmallnumber
of stars, the location of the prior has a substantial impact on the posterior. However, as more stars are added, the information from the data dominates.
performed. The latteris typically more relevant inscience and more
closely coincides with sensitivity analyses.
Good practices outlined in this section can be summarized as (1)
using multiple ways to summarize the posterior inference, (2) quan-
titatively and graphically checking the posterior distribution (e.g.,
usingposteriorpredictivechecks, Q-Qplots),and(3)providingevi-
dence that diagnostic checks were completed.
2.5.1 Extended Example: posterior predictive checks
We investigate the validity of our model for the distance to a cluster
of stars by computing the posterior predictive distribution for the
observedstellarparallaxes.Whileinthiscasetheposteriorpredictive
canbewritteninclosedform(sinceitisaGaussiandistribution),we
alsoapproximateitbysimulatingvaluesof 𝑑clusterfromtheposterior
and then subsequently simulating values for the predicted parallax
measurements 𝜛pred𝑖given𝑑cluster.
In Figure 4, we compare both the distribution and quantiles esti-
matedforthesimulateddatasetandtheobserveddatasetviaadensity
andQ-Qplot respectively. While there are diﬀerences, especially in
thetailsofthedistribution,overalltheclustermodelreproducesmost
of the observed properties of the data. It would be worth investigat-
ing whether these diﬀerences persist under diﬀerent models – for
example, a model in which the distance to each star is not assumed
to be identical, or a model in which measurement uncertainty is not
assumed to be known exactly.2.6 Conclusion
Wehopethatthisarticlehasidentiﬁed,clariﬁed,andilluminatedfun-
damentalBayesianinferencenotationandtechniquesfromthestatis-
tics literature, and in particular, has made a case for fully specifying
the model, posterior predictive checking, and the use of underused
aidssuchasthe Q-Qplot.Insummary,wehighlightsoundpractices
for conducting Bayesian inference in astronomy as follows:
Beexplicitaboutnotation,anduseappropriateterminologyfor
the interpretation of concepts such as the likelihood and credible
intervals, which will help interdisciplinary collaboration and repro-
ducibility.
Describe the likelihood as a function of the parameters, given
the data.
Use informative priors whenever possible and justiﬁed. Care-
fully consider what direct or indirect information is available about
the parameters.
Usenon-informativepriorscarefully,andassesstheirproperties
under parameter transformations.
Testthesensitivityoftheposteriordistributiontodiﬀerentprior
distributions.
Fully specify the Bayesian model in terms of the likelihood,
prior, and posterior, and provide open-source code whenever possi-
ble.
Performposteriorpredictivechecksofthemodel,usingvisual-
izations such as Q-Qplots where appropriate.
Strivetoincludeallnon-negligiblecontributorstothemeasure-
ment process.
We hope that there is a continued growth of interdisciplinary col-
laborationsbetweenastronomersandstatisticiansinthefuture.Data
RASTI 000, 1–10 (0000)Bayesian inference in Astronomy 9
Predicted Parallax [mas]Measured Parallax [mas] Probability [normalized]DataPosterior
Posterior 
Predictive
1%5%20%50%80%95%99%
Figure 4. Quantile-Quantile ( Q-Q) Plot.This ﬁgure demonstrates a way
to perform posterior predictive checking for the model shown in Figure 3.
Top:The distribution of parallax measurements from the data (gray) and
simulated values from the posterior predictive (light blue). The posterior
mean is indicated using the dashed dark blue line. The distributions appear
relatively consistent with each other by eye, but a quantile-quantile ( Q-Q)
plotismoreinformativeandsuggestsotherwise. Bottom:TheQ-Qplotofthe
quantiles from the posterior predictive simulated parallax data ( 𝑥-axis) and
of the observed parallaxes ( 𝑦-axis). If the real and simulated data followed
the same distribution, then the quantiles would lie on the one-to-one line.
However, strong discrepancies are apparent below 10th percentile and
above70th percentile.
from cutting-edge telescopes such as the Vera Rubin Observatory,
the James Webb Space Telescope, and many others, have the poten-
tial to drive the ﬁeld of astronomy, but this new information is best
understood in the context of existing knowledge and careful statisti-
calinference.Bayesianinferenceprovidesaframeworkinwhichthis
type of analysis and discovery can occur. Areas of astronomy where
prior information and non-Gaussian based likelihoods are common
canespeciallybeneﬁtfromBayesianmethods,forexampleX-rayand
gamma-ray astronomy.
Bayesian inference is a broad topic, and many subtopics were
not covered in this article. Ultimately, we hope that this article not
only serves as a useful resource, but will also be the inception for a
series of more speciﬁc papers on Bayesian methods and techniques
in astronomy and physics.ACKNOWLEDGEMENTS
GMEacknowledgesthesupportofaDiscoveryGrantfromtheNatu-
ralSciencesandEngineeringResearchCouncilofCanada(NSERC,
RGPIN-2020-04554). JCK gratefully acknowledges support from
NSF under Grant Numbers AST 2009528 and DMS 2038556. DH
issupportedbytheWomenInScienceExcel(WISE)programmeof
the Netherlands Organisation for Scientiﬁc Research (NWO).
DATA AVAILABILITY
Data used in the running example is provided with permission and
courtesyofPhillCargile(CenterforAstrophysics jHarvard&Smith-
sonian).
REFERENCES
Akeret J., Refregier A., Amara A., Seehars S., Hasner C., 2015, Journal of
Cosmology and Astroparticle Physics, 2015, 043
Alonso R., et al., 2004, The Astrophysical Journal Letters, 613, L153
Astraatmadja T. L., Bailer-Jones C. A. L., 2016a, ApJ, 832, 137
Astraatmadja T. L., Bailer-Jones C. A. L., 2016b, ApJ, 833, 119
Bailer-Jones C. A. L., 2015, PASP, 127, 994
Bailer-Jones C. A. L., Rybizki J., Fouesneau M., Mantelet G., Andrae R.,
2018, AJ, 156, 58
BeaumontM.A.,2019,Annualreviewofstatisticsanditsapplication,6,379
BeaumontM.A.,CornuetJ.-M.,MarinJ.-M.,RobertC.P.,2009,Biometrika,
96, 983
Berger J. O., Wolpert R. L., 1988, The likelihood principle. IMS Lecture
Notes-Monograph Series Vol. 6, Institute of Mathematical Statistics
Blei D. M., Ng A. Y., Jordan M. I., 2003, Journal of machine Learning
research, 3, 993
Brooks S., Gelman A., Jones G., Meng X.-L., 2011, Handbook of Markov
chain Monte carlo. CRC press
Butler R. P., et al., 2017, The Astronomical Journal, 153, 208
Carlin B. P., Louis T. A., 2000, Bayes and empirical Bayes methods for data
analysis.TextsinStatisticalScienceVol.88,Chapman&Hall/CRCBoca
Raton
Carlin B. P., Louis T. A., 2008, Bayesian methods for data analysis. CRC
Press
Casella G., Berger R. L., 2002, Statistical inference, second edn. Duxbury
Paciﬁc Grove, CA
Clarke B., 1996, Journal of the American Statistical Association, 91, 173
Collaboration G., et al., 2018, yCat, pp I–345
CraiuR.V.,RosenthalJ.S.,2014,AnnualReviewofStatisticsandItsAppli-
cation, 1, 179
Dalal S., Hall W., 1983, Journal of the Royal Statistical Society: Series B
(Methodological), 45, 278
Danby J., 1988, Willmann-Bell, 1988. 2nd ed., rev. & enl.
Diaconis P., Ylvisaker D., 1979, The Annals of statistics, pp 269–281
Dragomir D., et al., 2019, The Astrophysical Journal Letters, 875, L7
Eadie G., et al., 2019a, in Bulletin of the American Astronomical Society.
p. 233 ( arXiv:1909.11714 )
Eadie G., et al., 2019b, in Canadian Long Range Plan for As-
tronony and Astrophysics White Papers. p. 10 ( arXiv:1910.08857 ),
doi:10.5281/zenodo.3756019
Eadie G. M., Webb J. J., Rosenthal J. S., 2021, arXiv e-prints, p.
arXiv:2108.13491
Fischer D. A., Marcy G. W., Spronck J. F., 2013, The Astrophysical Journal
Supplement Series, 210, 5
Foreman-MackeyD.,HoggD.W.,LangD.,GoodmanJ.,2013,Publications
of the Astronomical Society of the Paciﬁc, 125, 306
Gabry J., Mahr T., 2019, bayesplot: Plotting for Bayesian Models, https:
//mc-stan.org/bayesplot
RASTI 000, 1–10 (0000)10G.M. Eadie et al.
Gabry J., Simpson D., Vehtari A., Betancourt M., Gelman A., 2019, J. R.
Stat. Soc. A, 182, 389
Gaia C., et al., 2018, Astronomy & Astrophysics, 616
Gelman A., Meng X.-L., Stern H., 1996, Statistica Sinica, 6, 733
GelmanA.,CarlinJ.B.,SternH.S.,DunsonD.B.,VehtariA.,RubinD.B.,
2013, Bayesian data analysis. CRC press
Gelman A., Simpson D., Betancourt M., 2017, Entropy, 19, 555
Hastings W. K., 1970, Biometrika, 57, 97
Hilbe J. M., De Souza R. S., Ishida E. E., 2017, Bayesian models for astro-
physical data: using R, JAGS, Python, and Stan. Cambridge University
Press
HobertJ.P.,CasellaG.,1996,JournaloftheAmericanStatisticalAssociation,
91, 1461
HoﬀmanM.D.,BleiD.M.,WangC.,PaisleyJ.,2013,TheJournalofMachine
Learning Research, 14, 1303
Hogg D. W., 2018, A likelihood function for the Gaia Data
(arXiv:1804.07766 )
Holl B., Lindegren L., Hobbs D., 2012, A&A, 543, A15
Hubble E., 1929, Proceedings of the National Academy of Science, 15, 168
Ishida E. E., et al., 2015, Astronomy and Computing, 13, 1
JonesD.E.,TrangucciR.N.,ChenY.,2020,arXivpreprintarXiv:2001.10664
Jordan M. I., Ghahramani Z., Jaakkola T. S., Saul L. K., 1999, Machine
learning, 37, 183
Konacki M., Torres G., Jha S., Sasselov D. D., 2003, Nature, 421, 507
Kumar R., Carroll C., Hartikainen A., Martin O. A., 2019, The Journal of
Open Source Software
Lemoine N. P., 2019, Oikos, 128, 912
Lindegren, L. et al., 2018, A&A, 616, A2
LindegrenL.,LammersU.,HobbsD.,O’MullaneW.,BastianU.,Hernández
J., 2012, A&A, 538, A78
Little R. J., Rubin D. B., 2019, Statistical analysis with missing data, third
edn. John Wiley & Sons
Lunn D. J., Thomas A., Best N., Spiegelhalter D., 2000, Statistics and com-
puting, 10, 325
Marin J.-M., Pudlo P., Robert C. P., Ryder R. J., 2012, Statistics and Com-
puting, 22, 1167
Maritz J. S., 2018, Empirical Bayes methods with applications. CRC Press
Mayor M., et al., 2011, arXiv preprint arXiv:1109.2497
MetropolisN.,UlamS.,1949,JournaloftheAmericanstatisticalassociation,
44, 335
Metropolis N., Rosenbluth A. W., Rosenbluth M. N., Teller A. H., Teller E.,
1953, The journal of chemical physics, 21, 1087
Morita S., Thall P. F., Müller P., 2008, Biometrics, 64, 595
Pepe F., et al., 2011, Astronomy & Astrophysics, 534, A58
Plummer M., et al., 2003, in Proceedings of the 3rd international workshop
on distributed statistical computing. pp 1–10
Reimherr M., Meng X.-L., Nicolae D. L., 2014, arXiv preprint
arXiv:1406.5958
Riddell A., et al., 2017, stan-dev/pystan: v2.17.0.0,
doi:10.5281/zenodo.1003176, https://doi.org/10.5281/zenodo.
1003176
Robert C. P., 2014, Annual Review of Statistics and Its Application, 1, 153
Rubin D. B., 1976, Biometrika, 63, 581
Rue H., Martino S., Chopin N., 2009, Journal of the royal statistical society:
Series b (statistical methodology), 71, 319
Salvatier J., Wiecki T. V., Fonnesbeck C., 2016, PeerJ Computer Science, 2,
e55
Schervish M. J., 1995, Theory of statistics. Springer Series in Statistics,
Springer
Schönrich R., McMillan P., Eyer L., 2019, Monthly Notices of the Royal
Astronomical Society, 487, 3568
Stan Development Team 2020, RStan: the R interface to Stan, http://
mc-stan.org/
Tak H., Mandel K., van Dyk D. A., Kashyap V. L., Meng X.-L., Siemigi-
nowska A., 2017, The Annals of Applied Statistics, 11, 1309
Tak H., Ghosh S. K., Ellis J. A., 2018, Monthly Notices of the Royal Astro-
nomical Society, 481, 277
Tuyl F., Gerlach R., Mengersen K., 2008, The American Statistician, 62, 40Vehtari A., Gelman A., Simpson D., Carpenter B., Bürkner P.-C., 2020,
Bayesian Analysis, 16, 667
WeyantA.,SchaferC.,Wood-VaseyW.M.,2013,TheAstrophysicalJournal,
764, 116
de Valpine P., Turek D., Paciorek C. J., Anderson-Bergman C., Lang D. T.,
Bodik R., 2017, Journal of Computational and Graphical Statistics, 26,
403
This paper has been typeset from a T EX/LATEX ﬁle prepared by the author.
RASTI 000, 1–10 (0000)