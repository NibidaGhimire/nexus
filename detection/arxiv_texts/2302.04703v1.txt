RASTI 000, 1â€“10 (0000) Preprint 10 February 2023 Compiled using rasti L ATEX style ï¬le v3.0
Practical Guidance for Bayesian Inference in Astronomy
Gwendolyn M. Eadie1Â–2â˜…, Joshua S. Speagle,1Â–2Â–3Jessi Cisewski-Kehe,4Daniel Foreman-Mackey,5
Daniela Huppenkothen,6David E. Jones,7Aaron Springford8and Hyungsuk Tak9Â–10Â–11
1University of Toronto, David A. Dunlap Department of Astronomy & Astrophysics, Toronto, M5S 3H4, Canada
2University of Toronto, Department of Statistical Sciences, Toronto, M5S 3G3, Canada
3University of Toronto, Dunlap Institute for Astronomy & Astrophysics, Toronto, M5S 3H4, Canada
4University of Wisconsin-Madison, Department of Statistics, Madison, WI, 53706, USA
5Center for Computational Astrophysics, Flatiron Institute, 160 5th Ave, New York, NY 10010, USA
6SRON Netherlands Institute for Space Research, Niels Bohrlaan 4, 2333 CA Leiden, Netherlands
7Texas A&M University, Department of Statistics, College Station, TX 77843, USA
8Cytel, Toronto, Ontario, Canada
9Pennsylvania State University, Department of Statistics, University Park, PA 16802, USA
10Pennsylvania State University, Department of Astronomy & Astrophysics, University Park, PA 16802, USA
11Pennsylvania State University, Institute for Computational and Data Sciences, University Park, PA 16802, USA
10 February 2023
ABSTRACT
Inthelasttwodecades,Bayesianinferencehasbecomecommonplaceinastronomy.Atthesametime,thechoiceofalgorithms,
terminology, notation, and interpretation of Bayesian inference varies from one sub-ï¬eld of astronomy to the next, which can
lead to confusion to both those learning and those familiar with Bayesian statistics. Moreover, the choice varies between the
astronomy and statistics literature, too. In this paper, our goal is two-fold: (1) provide a reference that consolidates and clariï¬es
terminologyandnotationacrossdisciplines,and(2)outlinepracticalguidanceforBayesianinferenceinastronomy.Highlighting
boththeastronomyandstatisticsliterature,wecovertopicssuchasnotation,speciï¬cationofthelikelihoodandpriordistributions,
inferenceusingtheposteriordistribution,andposteriorpredictivechecking.Itisnotourintentiontointroducetheentireï¬eldof
Bayesiandataanalysisâ€“rather,wepresentaseriesofusefulpracticesforastronomerswhoalreadyhaveanunderstandingofthe
Bayesian"nutsandbolts"andwishtoincreasetheirexpertiseandextendtheirknowledge.Moreover,astheï¬eldofastrostatistics
and astroinformatics continues to grow, we hope this paper will serve as both a helpful reference and as a jumping oï¬€ point for
deeper dives into the statistics and astrostatistics literature.
Key words: astrostatistics â€“ computational methods â€“ parallax
1 INTRODUCTION
Over the past two decades, Bayesian inference has become increas-
ingly popular in astronomy. On NASAâ€™s Astrophysics Data Sys-
tem (ADS), a search using â€œkeyword:statisticalâ€ and â€œabs:bayesianâ€
yields2377refereedpapers,andshowsexponentialgrowthsincethe
year 2000, with over 237 papers in 2021.
Bayesian analyses have become popular in astronomy due to sev-
eral key advantages over traditional methods. First, an estimate of
theposteriordistributionofmodelparametersprovidesamorecom-
plete picture of parameter uncertainty, joint parameter uncertainty,
and parameter relationships given the model, data, and prior as-
sumptions than traditional methods. Second, the interpretation of
Bayesian probability intervals is often closer to what scientists de-
sire, and is an appealing alternative to point estimates with conï¬-
dence intervals which often rely on the sampling distribution of the
estimator.Third,Bayesiananalysiseasilyallowsformarginalization
over nuisance parameters, incorporation of measurement uncertain-
tiesthroughmeasurementerrormodels,andinclusionofincomplete
â˜…E-mail: gwen.eadie@utoronto.cadata such as missing and censored data. Fourth, astronomers of-
ten have prior knowledge about allowable and realistic ranges of
parameter values (e.g., through physical theories and previous ob-
servations/experiments) which can naturally be included in prior
distributions and thereby improve the ï¬nal inference.
Importantly, in addition to the aforementioned advantages of the
Bayesian approach, eï¬ƒcient and increased computing power, along
witheasy-to-useorout-of-the-boxalgorithms,havebroughtBayesian
methodologytoastronomersinconvenientpracticalforms(e.g., em-
cee(Foreman-Mackey et al. 2013), Rstan(Stan Development Team
2020),PyStan(Riddell et al. 2017), PyMC3(Salvatier et al. 2016),
BUGS (Lunn et al. 2000), NIMBLE (de Valpine et al. 2017), and
JAGS (Plummer et al. 2003)).
Interestingly, the surge in popularity of Bayesian statistics comes
in spite of the fact that Bayesian methods are rarely taught in un-
dergraduate astronomy and physics programs, and has only recently
beenintroducedatabasiclevelinastronomygraduatecourses(Eadie
et al. 2019b,a). Some challenges faced by both new and seasoned
users of Bayesian inference are the varied notation, terminology, in-
terpretation,andchoiceofalgorithmsavailableintheastronomyand
statistics literature.
Â©0000 The AuthorsarXiv:2302.04703v1  [astro-ph.IM]  9 Feb 20232G.M. Eadie et al.
Beingwell-versedinbestpracticesandcommonpitfallsassociated
withtheBayesianframeworkisimportantifthesemethodsaretobe
used to advance the ï¬eld of astronomy. Here, users of Bayesian
inferenceinastronomyfacechallengestoo,sinceundergraduateand
graduate program training is still catching up to the state-of-the-art
Bayesian inference methods.
The goal of this paper is two-fold. Our ï¬rst goal is to provide a
â€œtranslationâ€ between terminology and notation used for Bayesian
inference across the ï¬elds of astronomy and statistics. Our second
goalistoillustrateusefulpracticesfortheBayesianinferenceprocess
which we hope will be a valuable contribution to astronomers who
arefamiliarwithand/oruseBayesianstatisticsinresearch.Toachieve
these goals, we deal with the following topics in the main body of
the paper: notation (Section 2.1), interpreting and determining the
likelihood (Section 2.2), choosing and assessing prior distributions
(Section 2.3), evaluating and making inference from the posterior
distribution(Section2.4),andperformingposteriorpredictivechecks
(Section 2.5).
This work is not meant to be a comprehensive introduction to
Bayesian inference, but rather an unveiling of Bayesian statistics as
both an extensive topic and an active research area. We focus our
eï¬€orts on identifying common mistakes and misunderstandings re-
lated to Bayesian inference, and use these as jumping oï¬€ points for
highlighting important topics for further study. Indeed, many valu-
able topics and subtopics arise which we do not cover, but we make
a point of providing key references. For example, throughout the
paper we touch on areas such as Bayesian design, posterior pre-
dictivechecking,hierarchicalmodeling,andBayesiancomputations
(Craiu&Rosenthal2014;Robert2014),andalsorecommendbooks
on Bayesian data analysis from statistics and astrostatistics (Gelman
et al. 2013; Carlin & Louis 2008; Hilbe et al. 2017).
Tohelpthenarrative,weusearunningexampleattheendofeach
section â€” inferring the distance to a star through its parallax mea-
surement.Thespeciï¬cproblemofdistanceestimationfromparallax
in the Bayesian context is explored closely in other studies (Bailer-
Jones 2015; Astraatmadja & Bailer-Jones 2016a,b) and applied to
theGaiaseconddatarelease( GaiaDR2)(Lindegren,L.etal.2018;
Bailer-Jones et al. 2018; SchÃ¶nrich et al. 2019), and we refer the
reader to these papers for a deep exploration on this topic. Here,
we employ this example because of its generality, because it pro-
videssomeinterestingchallengesandpotentialpitfalls,andbecause
itprovidesaniceframeworktoillustratesoundpracticesinBayesian
analysis. Along the way, we also identify how our advice applies to
other areas in astronomy.
2 SPECIFYING A BAYESIAN MODEL
2.1 Notation & Bayes Theorem
A number of diï¬€erent notation practices for Bayesian inference are
used in both the astronomy and statistics literature. This section is
meant to clarify some of these diï¬€erences, while also providing a
â€œtranslationâ€ so that astronomers can more easily follow statistics
papers (e.g., recognize notation for random variables, probability
distribution functions, etc.).
We use ğ’š(vectorized form) to represent the observed data of a
random variable ğ‘Œ, and ğœ½to represent the parameter(s) of interest.
The posterior distribution is deï¬ned by Bayesâ€™ theorem as
ğ‘Â¹ğœ½jğ’šÂº=ğ‘Â¹ğ’šjğœ½Âºğ‘Â¹ğœ½Âº
ğ‘Â¹ğ’šÂº(1)
whereğ‘Â¹ğ’šjğœ½Âºis thesampling distribution forğ’šgiven ğœ½(Section2.2),ğ‘Â¹ğœ½Âºis theprior density (Section 2.3), and ğ‘Â¹ğ’šÂºis theprior
predictivedensity (Schervish1995).Withthedata ğ’šinhand,ğ‘Â¹ğ’šjğœ½Âº
isoftenviewedasafunctionof ğœ½calledthe likelihoodfunction (which
isnotaprobabilitydensity),and ğ‘Â¹ğ’šÂºisanormalizingconstantthat
does not depend on ğœ½(which is often referred to in astronomy as
the model evidence). In the probability and Bayesian computation
literature, the posterior probability distribution of interest is usually
denoted and referred to as the target distribution with the notation
ğœ‹. There are also diï¬€erences in notation for the likelihood across
disciplines, which we discuss in Section 2.2.
For smooth translation between sub-disciplines of astronomy and
statistics, it is beneï¬cial to use explicit statements about model
choices and parameter deï¬nitions. For example, a list of all model
parameters, notation, and their associated prior probability distribu-
tions in the form of a table is very useful to the reader. Moreover,
we stress the importance of fully specifying any Bayesian model in
paperstoincreasereproducibility(e.g.,viaadetailedappendix,open
code). In this spirit, we provide the full Bayesian model for our run-
ningexampleinTable1,explicitlydeï¬nenotationnext,andprovide
our open source code1.
2.1.1 Parallax Example: Deï¬ning Notation
For the running example in this paper, we infer the distance to a star
from a parallax measurement. The true but unknown distance ğ‘‘in
kiloparsecs (kpc) is related to the true but unknown parallax ğœ›in
milliarcseconds (mas) through
ğ‘‘Â»kpcÂ¼=1
ğœ›Â»masÂ¼Â• (2)
Ourdatağ‘¦isameasurementoftheparallax,andhassomeï¬xedun-
certaintyğœthatwetreatasknown.Thus,intheBayesianframework,
wewishtoinfertheparameter ğ‘‘giventhedata ğ‘¦,andweseektoï¬nd
the posterior distribution,
ğ‘Â¹ğ‘‘jğ‘¦Âº/ğ‘Â¹ğ‘¦jğ‘‘Âºğ‘Â¹ğ‘‘ÂºÂ• (3)
In Section 2.4.2, we extend this example to infer the distance to a
star cluster from the parallax measurements of many stars within
the cluster. The true but unknown distance to the cluster, ğ‘‘cluster,
is related to the true but unknown parallax of the cluster through
Equation2,too.Inthiscase,weexpressthecorrespondingposterior
density as follows:
ğ‘Â¹ğ‘‘clusterjğ’šÂº/ğ‘Â¹ğ’šjğ‘‘clusterÂºğ‘Â¹ğ‘‘clusterÂºÂ– (4)
where ğ’šrepresents a vector of parallax measurements of its stars.
Table 1 summarizes this model speciï¬cation.
2.2 Likelihood function
Diï¬€erences in notation and language between statistics and astron-
omy can lead to confusions regarding the likelihood. In Bayesian
statistics, the capital letters ğ‘ŒandÎ˜often denote random variables .
Forexample,bothGelmanetal.(2013)intheirappliedstatisticstext
and Schervish (1995) in his statistics theory text ï¬rst write down
ajointprobability density ğ‘Â¹Î˜Â–ğ‘ŒÂº, and then specify the likelihood
functionasğ‘Â¹ğ‘Œ=ğ’šjğœ½Âº(sometimeswritten LÂ¹ğœ½Âºelsewhere),where
ğ’šistheï¬xed,observedvalueof ğ‘Œ(i.e.,thedata),and ğœ½istheargument
ofthelikelihoodfunction.Thatis,thelikelihoodisafunctionofthe
parameters ğœ½,giventhedata ğ’š(Gelmanetal.2013;Schervish1995;
1https://github.com/joshspeagle/nrp_astrobayes
RASTI 000, 1â€“10 (0000)Bayesian inference in Astronomy 3
Table 1.Bayesianmodelsforinferring(1)astarâ€™sdistanceparameter ğ‘‘fromitsparallaxmeasurement ğ‘¦,assumingaGaussiandistributionforitstrueparallax
ğœ›(top panel), and (2) a star clusterâ€™s distance parameter ğ‘‘clusterfrom the parallax measurement of ğ‘›starsğ’š(bottom panel).
Inferring a single starâ€™s distance parameter ğ‘‘
Sampling density / likelihood (parallax) ğ‘Â¹ğ‘¦jğ‘‘Âº=ğ‘Â¹ğ‘¦j1Âğ‘‘Â–ğœ2Âº, whereğœ›=1Âğ‘‘
Prior (distance) ğ‘Â¹ğ‘‘Âº/(
ğ‘‘2ğ‘’ ğ‘‘Âğ¿ifğ‘‘minÂŸğ‘‘ÂŸğ‘‘ maxwith a constant ğ¿
0 otherwise
Posterior on distance ğ‘Â¹ğ‘‘jğ‘¦Â–ğœ ğœ›Âº/ğ‘‘2exph
 ğ‘‘
ğ¿ Â¹ğ‘¦ 1Âğ‘‘Âº2
2ğœ2i
Inferring a star clusterâ€™s distance parameter ğ‘‘cluster
Sampling density / likelihood ( ğ‘›parallax measurements) ğ‘Â¹ğ’šjğ‘‘clusterÂº=Ãğ‘›
ğ‘–=1ğ‘Â¹ğ’šj1Âğ‘‘clusterÂ–ğœ2
ğ‘–Âº
Prior (on parallax of cluster) ğ‘Â¹ğœ›clusterÂº=ğ‘Â¹ğœ›clusterjğœ‡ğœ›Â–ğœğœ›Âº
Posterior on distance to cluster ğ‘Â¹ğ‘‘clusterjğ’šÂº/ğ‘Â¹ğ‘‘clusterÂºexp
 Â¹ğ‘¦ğ‘’ ğ‘“ ğ‘“ 1Âğ‘‘clusterÂº2
2ğœ2
2In both the upper and lower box, ğœandğœğ‘–:ğ‘–=1Â–2Â–Â•Â•Â•Â–ğ‘›are assumed to be known. Throughout ğ‘Â¹ğ‘¦jğ‘Â–ğ‘Âºdenotes the Gaussian density function of ğ‘¦
with meanğ‘and varianceğ‘.
Carlin & Louis 2008; Berger & Wolpert 1988; Casella & Berger
2002). However, in astronomy, it is not unusual to see phrases such
as â€œthe likelihood function of the data given the model parametersâ€,
whichmightbemisconstruedastreatingthelikelihoodfunctionasa
function of data. Finally, we note that the likelihood function of ğœ½is
not a probability density function of ğœ½.
In Table 2, we summarize common notation for the likelihood
found in both the statistics and astronomy literature, which ranges
from being very explicit (e.g., ğ‘“ğ‘ŒÂ¹ğ’šjğœ½Âº) to quite simpliï¬ed (e.g.,
ğ‘ƒÂ¹ğ’šjğ‘€Âº). We note that a subtlety sometimes missed in astronomy
is the diï¬€erence between ğ‘andğ‘ƒ. In statistics, ğ‘“andğ‘are often
used for probability density functions (pdf) of continuous random
variables, and ğ‘ƒorğ‘ƒğ‘Ÿare used to denote probabilities of discrete
events (probability mass functions (pmf) are an exception, and are
often denoted using ğ‘“,ğ‘, orğ‘ƒ). A capitalğ¹is usually reserved for
the cumulative distribution function (cdf).
Determining what the likelihood function should be in a given
astronomy problem can be challenging, and care must be taken to
choose an appropriate sampling distribution. The likelihood is of-
ten taken to be a product of independent and identically distributed
(i.i.d.) Gaussian random variables with known variance. While this
choice is sometimes plausible, there are also many cases in which it
isinappropriate,andhasamaterialeï¬€ectoninference.Forinstance,
when describing the brightness of a high energy source, a discrete
distribution such as the Poisson distribution is usually more appro-
priate than a Gaussian. In other cases, uncertainty in the variance
of the data might lead us to use a likelihood function based on the
ğ‘¡-distribution or another non-Gaussian parametric family. A further
consideration is whether the data being modeled are collected as a
functionofspaceortime,inwhichcasetheassumptionofexchange-
ability â€“that data can be reordered without aï¬€ecting the likelihood
â€“ is generally unwarranted. In these cases, an expanded model that
includes correlation among observations should be considered.
Best practice includes all non-negligible contributors to the mea-
surementprocessinthelikelihoodfunction.Forexample,itisimpor-
tant to account for substantial truncation and censoring issues when
present, because these can strongly inï¬‚uence parameter inference in
some cases (Rubin 1976; Eadie et al. 2021). Other common issues
tocheckforandaddressaremeasurementuncertainty,correlateder-
rors, measurement bias, sampling bias, and missing data. There area number of valuable references in the statistics literature on these
topics (Rubin 1976; Little & Rubin 2019). We recommend writing
down enough mathematical details to uniquely determine the like-
lihood by deï¬ning (algebraically) not only the physical process of
interest but also the sampling/measurement process that generated
the data.
2.2.1 Parallax Example: the likelihood function
TheGaiaspacecraft has measured parallaxes for over a billion stars
(Gaia et al. 2018; Collaboration et al. 2018). These parallaxes have
been shown empirically, through simulations (Holl et al. 2012; Lin-
degren et al. 2012), to follow a normal distribution with mean equal
to the true underlying parallax ğœ›so that
ğ‘Â¹ğ‘¦jğœ›Âº=1p
2ğœ‹ğœ2exp
 Â¹ğ‘¦ ğœ›Âº2
2ğœ2
or equivalently, (5)
ğ‘¦jğœ›Â–ğœğ‘Â¹ğœ›Â– ğœ2Âº (6)
whereğ‘¦is the measured parallax and ğœis the associated (assumed
known) measurement uncertainty (Hogg 2018). The parameter of
interest is the distance ğ‘‘, so we rewrite Equation 6 as
ğ‘Â¹ğ‘¦jğ‘‘Âº=1p
2ğœ‹ğœ2exp
 Â¹ğ‘¦ 1Âğ‘‘Âº2
2ğœ2
or equivalently, (7)
ğ‘¦jğ‘‘Â–ğœğ‘Â¹1Âğ‘‘Â– ğœ2ÂºÂ• (8)
We note that a similar Gaussian model assumption is widely ap-
plicable to various sub-ï¬elds in observational astronomy such as
detecting exoplanets by RV (Danby 1988; Mayor et al. 2011; Pepe
et al. 2011; Fischer et al. 2013; Butler et al. 2017) or by transit
(Konacki et al. 2003; Alonso et al. 2004; Dragomir et al. 2019), in-
ferringthetruebrightnessofasource(Taketal.2017),orestimating
the Hubble constant (Hubble 1929). This is because the statistical
details are analogous; the observation is measured with Gaussian
measurement error, estimated measurement error uncertainty ğœis
treated as a known constant, and the mean model can be written as
adeterministicfunctionofotherparameters,e.g., ğœ›=1Âğ‘‘inEqua-
tion 6. On the other hand, as mentioned already, in each new setting
itisimportanttocarefullyconsiderwhichmodelismostappropriate;
RASTI 000, 1â€“10 (0000)4G.M. Eadie et al.
[t!]
Table 2.Likelihood notation found in diï¬€erent contexts.
Notation Description Context
ğ‘“ğ‘ŒÂ¹ğ’šjğœ½Âºdistribution function of the random variable ğ‘Œ, statistics
but viewed as a function of ğœ½, with ğ’šï¬xed
ğ‘Â¹ğ’šjğœ½Âº format used in this paper (common) statistics and astronomy
LÂ¹ğœ½;ğ’šÂºorLÂ¹ğœ½Âºexplicit notation for the likelihood with speciï¬c statistics topics, e.g.,
argument ğœ½ maximum likelihood estimation
ğ‘ƒÂ¹ğ‘«jğœ½Âºğ·represents the data astronomy
ğ‘ƒÂ¹ğ’šjğ‘€Âºğ‘€represents the model assumption, astronomy, model selection
implicitly suggests parameters
ğ‘ƒğ‘ŸÂ¹ğ’šjğœ½Â–ğ»Âºğ»represents a particular proposed model astronomy, model selection
Gaussian-based models are (i) sometimes misused, (ii) overused, or
(iii) sometimes inappropriate.
2.3 Prior Distributions
The prior probability distribution, or the prior, captures our initial
knowledgeaboutthemodelparametersbeforewehaveseenthedata.
Priors may assign higher probability (or density) to some values of
the model parameters over others. Priors are often categorized into
twoclasses: informative andnon-informative .Theformertypesum-
marizesknowledgegainedfrompreviousstudies,theoreticalpredic-
tions,and/orscientiï¬cintuition.Thelattertypeattemptstoincludeas
little information as possible about the model parameters. Informa-
tive priors can be conjugate (Diaconis & Ylvisaker 1979), mixtures
ofconjugatepriors(Dalal&Hall1983),scientiï¬callymotivated(Tak
etal.2018;Lemoine2019),basedonpreviousdata,orinthecaseof
empirical Bayes, based on the data at hand (often called data-driven
priors) (Carlin & Louis 2000; Maritz 2018). Non-informative priors
can be improper or â€œï¬‚atâ€, weakly-informative, Jeï¬€reyâ€™s priors (Tuyl
et al. 2008), or other reference distributions. Conjugate priors are
sometimes deï¬ned to be non-informative.
One popular choice for a non-informative prior is an improper
priorâ€”apriorthatisnotaprobabilitydistributionandinparticular
does not integrate to one. Good introductions to improper priors are
available in the statistics literature (Gelman et al. 2013, 2017). An
example of an improper prior is a ï¬‚at prior on an unbounded range,
e.g., Unif(0,1) or Unif( 1,1). When an improper prior has been
adopted,itisimperativetocheckwhethertheresultingposteriorisa
properprobabilitydistributionbeforemakinganyinference.Without
posterior propriety the analysis has no probability interpretation.
Empirical checks may not be suï¬ƒcient; posterior samples may not
reveal any evidence of posterior impropriety, forming a seemingly
reasonabledistributionevenwhentheposteriorisactuallyimproper
(Hobert & Casella 1996; Tak et al. 2018).
Researchonquantifyingpriorimpactisactive(e.g.,eï¬€ectiveprior
samplesizeClarke1996;Reimherretal.2014;Jonesetal.2020)as
is the discussion on choosing a prior in the context of the likelihood
(Reimherr et al. 2014; Gelman et al. 2017; Jones et al. 2020).
In astronomy, there is a tendency for scientists to adopt non-
informative prior distributions, perhaps because informative priors
are perceived as too subjective or because there is a lack of easily
quantiï¬ableinformationabouttheparametersinquestion.However,
all priors provide someinformation about the likely values of the
modelparameter(s),evenaâ€œï¬‚atâ€prior.Notably,aï¬‚atpriorisnon-ï¬‚atafter a transformation. For instance, in our example (Section 2.3.1)
a â€œnon-informativeâ€ uniform prior distribution on the parallax of a
star is actually quite informative in terms of distance (third panel,
Figure 1). Thus, we recommend carefully considering what direct
or indirect information is available about the value of a parameter
before resorting to default or non-informative priors; in astronomy,
we usually have at least a little information about the range of al-
lowedorphysicallyreasonablevalues.Evenwhenanon-informative
priordoesseemappropriate,checkingthatthechosendistributionis
consistent with known physical constraints is essential.
Complete descriptions and mathematical forms of prior distribu-
tions, including the values of hyperparameters deï¬ning these dis-
tributions, help promote reproducibility and open science. Unfortu-
nately, a recent meta-analysis of the astronomical literature showed
that prior deï¬nitions are often incomplete or unstated (Tak et al.
2018), making it diï¬ƒcult for others to interpret results.
To summarize, good practices in the context of priors are: (1)
choosing informative priors when existing knowledge is available,
(2) choosing priors with caution if there is no prior knowledge,
(3) testing the inï¬‚uence of alternative priors (see the discussion of
sensitivity analyses in Section 2.4), and (4) explicitly specifying the
chosen prior distributions for clarity and reproducibility.
2.3.1 Parallax Example: choosing a prior
A naive choice of prior on the true parallax ğœ›isğ‘Â¹ğœ›Âº/constant,
an improper prior that assigns equal density to all values of ğœ›from
Â¹0Â–Â¸1Âº. A straightforward way to be more informative and proper
is to instead deï¬ne a truncated uniform prior, where ğœ›is uniformly
distributed between ğœ›=Â¹ğœ›minÂ–ğœ›maxÂºso that
ğ‘Â¹ğœ›Âº/(
constantğœ›minÂŸğœ› ÂŸğœ› max
0 otherwiseÂ– (9)
or equivalently,
ğœ›UnifÂ¹ğœ›minÂ–ğœ›maxÂº (10)
Here,ğœ›minandğœ›maxare hyperparameters set by the scientist (e.g.,
using some physically-motivated cutoï¬€ for ğœ›minand the minimum
realistic distance to the star for ğœ›max). Thus the prior in Equation 9
canberegardedasweakly-informativebecausesomephysicalknowl-
edge is reï¬‚ected in the bounds. Similarly, we could instead deï¬ne a
RASTI 000, 1â€“10 (0000)Bayesian inference in Astronomy 5
uniform prior on distance:
ğ‘Â¹ğ‘‘Âº/(
constantğ‘‘minÂŸğ‘‘ ÂŸğ‘‘ max
0 otherwiseÂ– (11)
or equivalently,
ğ‘‘UnifÂ¹ğ‘‘minÂ–ğ‘‘maxÂº (12)
whereğ‘‘min=1Âğœ›maxandğ‘‘max=1Âğœ›min. Like Equation 9, this
prior can also be regarded as weakly-informative. However, both
display drastically diï¬€erent behavior as a function of ğ‘‘(see Fig-
ure 1), which highlights how the interpretation of non-informative
(or weakly-informative) priors may change depending on the choice
of parameterization.
While the prior in Equation 11 may appear non-informative (in
a sense that it is uniform), it actually encodes a strong assumption
aboutthenumberdensityofstars ğœŒasafunctionofdistance.Theprior
implies that we are just as likely to observe stars at large distances
as we are at smaller distances. However, as we look out into space,
the area of the solid angle deï¬ned by the distance ğ‘‘increases, and
thisinturnimpliesthatthestellarnumberdensityisdecreasingwith
distance.Thus,Equation11,whichsaysthatalldistancesareequally
likely,impliesthattherearefewerstarspervolumeatlargedistances
than stars per volume at small distances.
Bailer-Jonesetal.(2018)introducedabetterpriorfortheparallax
inference problem, which we outline brieï¬‚y and reproduce here.
The physical volume dğ‘‰probed by an inï¬nitesimal solid angle on
the sky dÎ©at a given distance ğ‘‘scales as the size of a shell so that
dÎ©/ğ‘‘2.Thismeansthat,assumingaconstantstellarnumberdensity
ğœŒeverywhere, a prior behaving as ğ‘Â¹ğ‘‘Âº/ğ‘‘2is more appropriate.
However, we can go one step further â€” we know that our Sun sits
in the disk of the Galaxy, and that the actual stellar density ğœŒas
we go radially outward in the disk should decrease as a function
of distance. Assuming we are looking outward, and that the stellar
density decreases exponentially with a length scale ğ¿(so that for a
given distance we have ğ‘Â¹ğœŒjğ‘‘Âº/ğ‘’ ğ‘‘Âğ¿) the prior on distance is
ğ‘Â¹ğ‘‘Âº/(
ğ‘‘2ğ‘’ ğ‘‘Âğ¿ğ‘‘minÂŸğ‘‘ ÂŸğ‘‘ max
0 otherwiseÂ– (13)
which is the density function of a truncated Gamma( 3Â–ğ¿) distri-
bution. The scientist using Equation 13 would need to choose and
deï¬ne the three hyperparameters ğ‘‘minÂ–ğ‘‘maxÂ–andğ¿. Equation 13 is
the exponentially decreasing space density prior of previously pre-
sentedinBailer-Jonesetal.(2018).Figure1illustratesallthreepriors
discussed here.
2.4 Posterior distributions
The posterior distribution of Equation 1 is the focus of Bayesian
inference. Once the prior distribution(s) and the likelihood function
are speciï¬ed, the posterior distribution is uniquely determined. Of-
ten, the denominator quantity ğ‘Â¹ğ’šÂºis not available analytically. In
this case,ğ‘Â¹ğ’šÂºcan be estimated by numerical integration. Samples
drawn from ğ‘Â¹ğœ½jğ’šÂºcan be used to estimate properties of the pos-
terior. A popular approach for obtaining samples is to construct a
MarkovChainwhosestationarydistributionisdesignedtomatchthe
target distribution ğ‘Â¹ğœ½jğ’šÂº, which is known as Markov chain Monte
Carlo(MCMC).ThecanonicalexampleistheMetropolis-Hastingal-
gorithm(Metropolis&Ulam1949;Metropolisetal.1953;Hastings
1970; Gelman et al. 2013), but there are many variations, some of
which are designed to address speciï¬c challenges such as samplinghigh-dimensional or multi-modal target distributions; see Brooks
et al. (2011) for details.
The posterior distribution enables inference of model parameters
or of quantities that can be derived from model parameters. For
example, the posterior mean ğ¸Â¹ğœƒjğ‘¦Âºis a point summary for ğœƒ. The
posterior distribution can also be used to deï¬ne credible intervals
for parameters that provide a range of probable values. We stress
that credible intervals are not conï¬dence intervals; a 95% credible
interval suggests that there is a 95% probability that the parameter
lieswithinthespeciï¬edrangegivenourpriorbeliefs,themodel,and
the data, whereas a 95% conï¬dence interval suggests that if similar
intervals are properly constructed for multiple datasets then 95% of
them are expected to contain the true (ï¬xed) parameter value.
Depending on the characteristics of the posterior distribution, we
emphasize that point summaries and intervals may not provide a
complete description of uncertainty (e.g., for multi-modal posteri-
ors). Here, visualizations of the posterior can provide a more com-
prehensivepicture(seeFigure2).Recommendationsandopensource
softwarepackagescontainingvisualizationtoolsforBayesiananaly-
sis can be found in the statistics literature (Gabry et al. 2019; Gabry
& Mahr 2019; Kumar et al. 2019; Vehtari et al. 2020). Projections
of the joint posterior distribution into two parameter dimensions â€”
also colloquially referred to as a corner plot in astronomy literature
â€”isthemostcommonvisualizationtool.Drawingcredibleregions
orcontoursonthesetypesofvisualizationsarealsohelpful,although
defaulting to a â€œ1-sigmaâ€ credible region is not always appropriate
(i.e., when the distributions are non-Gaussian).
Theposteriordistributionalsoprovidesausefulwaytoobtaines-
timatesandcredibleintervalsforotherquantitiesofphysicalinterest.
For example, if a model has parameters ğœ½=Â¹ğ›¼Â–ğ›½Â–ğœ…Âºand there is
somephysicalquantitydescribedbye.g., ğ›¾=ğ›½2Âğ›¼ğ‘’ğœ…,thenforevery
sampleof ğœ½,asampleof ğ›¾canbecalculated.Thus,a distribution of
the physically interesting quantity ğ›¾is obtained, which can also be
usedtoobtainpointestimatesandcredibleintervals.Inotherwords,
intheBayesianparadigm,uncertaintiesineachmodelparameterare
naturally propagated to uncertainties in derived physical quantities
in a coherent way.
Posterior distributions can be complicated in shape (e.g., asym-
metric, with multiple modes). This can create computational chal-
lengesincaseswheretheposteriorcannotbederivedinclosedform.
Fortunately, many algorithms have been developed for approximat-
ing the posterior distribution. Diï¬€erent algorithms perform well for
diï¬€erent characteristics of the posterior, and therefore prior knowl-
edge of what we might expect the posterior to look like, as well
preliminary explorations, are often valuable in practice. In addition
to the MCMC sampling algorithms already mentioned, a number
of other techniques have been developed. For example, integrated
nested Laplace approximations (Rue et al. 2009) approximates pos-
terior distributions, variational Bayes methods (Jordan et al. 1999;
Blei et al. 2003; Hoï¬€man et al. 2013), and approximate Bayesian
computation(Beaumontetal.2009;Marinetal.2012;Weyantetal.
2013;Akeretetal.2015;Ishidaetal.2015;Beaumont2019)arepos-
sible alternatives when the likelihood functions are too complicated
or expensive to be evaluated.
2.4.1 Parallax Example: inferring the distance to a star
Inourrunningexample,weareinterestedininferringtheparameter
for the distance ğ‘‘=1Âğœ›given the measured parallax ğ‘¦and its
associated measurement uncertainty ğœ(which we treat as known).
RASTI 000, 1â€“10 (0000)6G.M. Eadie et al.
Parallax [mas] Distance [kpc]Likelihood
Observed 
units
(ğœ›)Physical 
units
(d=1/ğœ›)Prior
Uniform (parallax)
Uniform (distance)Physically -motivatedPosterior
Distance [kpc] Distance [kpc]
âˆ Ã—
GaussianNon-
Gaussian
Figure 1. Bayesianinferenceofthedistance ğ‘‘=1Âğœ›toastarbasedonthemeasuredparallax ğ‘¦.Farleft:Thelikelihoodforparallax ğœ›isnormalwithvariance
assumed known. Center left: A transformation of parameters from ğœ›toğ‘‘gives a non-normal PDF. Note that a non-negativity constraint was applied to the
distributionof ğ‘‘.Centerright: Wehighlightthreepossiblepriors ğ‘Â¹ğ‘‘Âºoverthedistance:uniforminparallax ğœ›=1Âğ‘‘(blue),uniformindistance ğ‘‘(red),and
a physically-motivated prior (Bailer-Jones et al. 2018) (orange). Far right: The posteriors that correspond to each of the three priors.
Distance [kpc]
Probability [normalized]Mode
Median
90% Credible Interval
Figure 2. ThethreeposteriordistributionscorrespondingtoeachpriordistributionshowninFigure1:uniforminparallaxprior(bluecurve),uniformindistance
prior(redcurve),andphysically-motivatedprior(orangecurve).Alsoshownareonesummarystatisticforeachposterior:themode(bluedottedline),themedian
(red dotted-dashed line), and the 90% credible interval (orange dashed lines and shaded region).
From Bayesâ€™ theorem, the posterior is
ğ‘Â¹ğ‘‘jğ‘¦Âº/ğ‘Â¹ğ‘¦jğ‘‘Âºğ‘Â¹ğ‘‘ÂºÂ• (14)
For the three priors discussed previously, this corresponds to the
following posteriors:
Equation 9)ğ‘Â¹ğ‘‘jğ‘¦Âº/1
ğ‘‘2exp
 Â¹ğ‘¦ 1Âğ‘‘Âº2
2ğœ2
(15)
Equation 11)ğ‘Â¹ğ‘‘jğ‘¦Âº/exp
 Â¹ğ‘¦ 1Âğ‘‘Âº2
2ğœ2
(16)
Equation 13)ğ‘Â¹ğ‘‘jğ‘¦Âº/ğ‘‘2exp
 ğ‘‘
ğ¿ Â¹ğ‘¦ 1Âğ‘‘Âº2
2ğœ2
Â–(17)forğ‘‘minÂŸğ‘‘ ÂŸğ‘‘ max(and 0otherwise).Whilenoneofthesehavean-
alytic solutions for point estimates or credible intervals, they can be
computedusingcomputationaltechniques.Approximationstothese
threeposteriordistributionsareshowinFigures1and2.Inthisillus-
tration, though each resulting posterior distribution is right-skewed,
the shape is notably diï¬€erent for each considered prior distribution.
2.4.2 Extended Example: inferring the distance to a clusterof stars
We now extend our example to infer the distance to a cluster of
stars, based on the collection of parallax measurements of each in-
dividual star. Assuming that there are ğ‘›stars located at approxi-
mately the same distance ğ‘‘clusterand that the measured parallaxes
RASTI 000, 1â€“10 (0000)Bayesian inference in Astronomy 7
ğ’š=fğ‘¦1Â–ğ‘¦2Â–Â•Â•Â•Â–ğ‘¦ğ‘›gto each star are independent given ğ‘‘cluster, our
combined likelihood is the product of the individual likelihoods
ğ‘Â¹ğ‘¦1Â–ğ‘¦2Â–Â•Â•Â•Â–ğ‘¦ğ‘›j1Âğ‘‘clusterÂº=ğ‘›Ã–
ğ‘–=1ğ‘Â¹ğ‘¦ğ‘–j1Âğ‘‘clusterÂºÂ– (18)
where the individual likelihoods are deï¬ned following Equation 6.
We assume that the measurement uncertainties ğœğ‘–are known con-
stants. Our posterior is
ğ‘Â¹ğ‘‘clusterjğ’šÂº/ğ‘Â¹ğ‘‘clusterÂºğ‘›Ã–
ğ‘–=1ğ‘Â¹ğ‘¦ğ‘–j1Âğ‘‘clusterÂºÂ• (19)
Theproductof ğ‘›independentGaussiandensitieswithknownvari-
ancesisaGaussiandensitywithprecisionparameter ğœ 2=Ãğ‘›
ğ‘–=1ğœ 2
ğ‘–
andmeanparameter 1Âğ‘‘cluster.Theobservedparallaxescanbecom-
binedtoobtainaneï¬€ectiveparallax ğ‘¦eï¬€=ğœ2Ãğ‘›
ğ‘–=1ğ‘¦ğ‘–Âğœ2
ğ‘–,andthus,
ğ‘Â¹ğ‘‘clusterjğ’šÂº/ğ‘Â¹ğ‘‘clusterÂºexp
 Â¹ğ‘¦eï¬€ 1Âğ‘‘clusterÂº2
2ğœ2
Â• (20)
The estimated posterior distribution over ğœ›cluster=1Âğ‘‘clusterfor
anearbyclusterofstars(M67)usingdatafrom GaiaDR2,andusing
a conjugate Gaussian prior for ğœ›cluster, is shown in Figure 3. The
top panel of Figure 3 shows the individual parallax measurements
of stars in M67, sorted by their signal-to-noise values. The bottom
panel shows the assumed prior distribution (narrow left panel) and
the (estimated) posterior distribution for the clusterâ€™s parallax, as
more and better data are added to the analysis.
Note:A prior over ğ‘Â¹ğ‘‘clusterÂº, which governs the distribution of
clustersofstars,isnotthesameasapriorover ğ‘Â¹ğ‘‘Âº,whichgoverns
the distribution of individual stars. While it might be reasonable to
assumethesearesimilar,theyarenotinterchangeablequantitiesand
may indeed follow diï¬€erent distributions. Realizing the diï¬€erences
in priors between various scenarios such as these is key to building
good models and subsequently making good inferences.
2.5 Posterior Predictive Checking
Afterobtainingtheposteriordistribution,itisrecommendedtoassess
theadequacyofthemodelusing posteriorpredictivechecks (Gelman
et al. 1996), which compare the empirical distribution of the data
to the distribution described by the Bayesian model. The posterior
predictive distribution is the posterior distribution of hypothetical
future data ( Ëœğ’š) under the chosen model and given the previously
collected data:
ğ‘Â¹Ëœğ’šjğ’šÂº=âˆ«
ğ‘Â¹Ëœğ’šÂ–ğœ½jğ’šÂºğ‘‘ğœ½Â• (21)
Weï¬ndthatposteriorpredictivecheckingisunderusedinastronomy
but can be very useful. Posterior predictive checks not only assess
thetheadequacyofthemodelbutalsosimultaneouslycheckanyap-
proximationstotheposterior.Theyareavaluabletoolfordiagnosing
issues with computational sampling methods.
Inmostcases,theposteriorpredictivedistributionisnotavailable
in closed form. However, it is possible to generate simulated obser-
vations from theposterior predictive distribution andcompare these
totheoriginaldata.Forexample,foreachoftheposteriorsamplesof
ğœ½,drawarandomsampleof Ëœğ’šandcomparethesesamplestothereal
data. Signiï¬cant or systematic diï¬€erences between the distributions
oftherealandsimulateddatamaysuggestaproblemwiththemodel.
It is good practice to perform quantitative and/or graphical com-
parison between the simulated data and the real data. For graphicalcomparison, an overlaid density plot could be used (top panel of
Figure4),butingeneralthisisapoorchoicebecauseitisdiï¬ƒcultto
judge diï¬€erences between the overlaid densities visually. For graph-
ical comparison, we recommend instead using a quantile-quantile
(Q-Q)plottocharacterizeanydiï¬€erences(bottompanelofFigure4).
To construct a Q-Qplot, it suï¬ƒces to compute the quantiles from
the original data and from the posterior predictive distribution (or
from data simulated from the posterior predictive distribution), and
toplotthepairsoneagainsttheother(bottompanel,Figure4).Ifthe
empiricaldistributionandtheposteriorpredictivedistributionmatch,
then their quantiles should lie along a 1:1 line. Functions to display
Q-Qplots are common in statistical computing software languages.
Inourparallaxexample,parallaxvaluesinthetailsofthesimulated
and real data distributions show some disagreement (Figure 4). The
Q-Qplot shows this more explicitly that the density plot, as the
quantiles do not follow the 1:1 line in the tails of the distribution
(below10th percentile and above 70th percentile). Diï¬€erences
ineitherendofa Q-Qplotcanbeduetochance,butstrongdeviations
from the 1:1 line are usually worth investigating.
There are also other valuable approaches for checking a Bayesian
modelandthequalityofapproximationstotheposteriordistribution.
For example, one may set a portion of the data aside, or obtain ad-
ditional data, and then compare the resulting inference to that from
the original data. One may also use multiple methods for approxi-
matingtheposteriordistribution,andcompareresults.Thiscanhelp
diagnose situations where one or more sampling algorithms did not
explore the full parameter space, and consequently fail to include
high-probability regions in the posterior samples.
Inadditiontomodelandposteriorchecking,itisimportanttocon-
sider the inï¬‚uence of the prior distribution(s). The rightmost panel
of Figure 1 shows three posteriors: each one used one of the three
priors discussed in Section 2.3.1. While the posteriors are vaguely
similarinshape(e.g.,right-skewed),theinferredsummarystatistics
can be quite diï¬€erent (Figure 2).
Moregenerally,investigatinghowtheanalysiscomparesforseveral
diï¬€erentpriordistributionsisanimportanttechnique,oftenreferred
to as asensitivity analysis . A sensitivity analysis directly assesses
the impact of the prior distribution on the posterior, and for this
reason we recommend them â€” particularly when the information
availabletoconstructapriorislimited.Ontheotherhand,sensitivity
analyses can be somewhat ad hoc (e.g., which priors are tried, how
theyarecompared)makingitdiï¬ƒculttosummarizeandcomparethe
priorimpactacrossmultipleanalyses,instruments,andmodels.More
principledapproachesmaythereforebepreferredorcomplementary
in some scenarios. One such method is to quantify the eï¬€ective
prior sample size (EPSS), i.e., the number of data points that the
information provided by the prior distribution corresponds to.
The EPSS is simple to compute for conjugate models. For exam-
ple, if we have the data ğ‘¦ğ‘–ğ‘–ğ‘–ğ‘‘ğ‘Â¹ğœ‡Â–ğœ2Âº, forğ‘–=1Â–Â•Â•Â•Â–ğ‘›, and the
conjugatepriordistribution ğœ‡ğ‘Â¹ğœ‡0Â–ğœ2Âğ‘šÂº,withknown ğœ2,then
the posterior distribution of ğœ‡has variance ğœ2ÂÂ¹ğ‘›Â¸ğ‘šÂº. Thus, the
eï¬€ectofthepriorisequivalenttothatof ğ‘šsamples,andwesaythat
the EPSS isğ‘š. The statistics literature includes proposals of several
methods for extending this idea beyond conjugate models (Clarke
1996; Morita et al. 2008; Reimherr et al. 2014; Jones et al. 2020)
and how to additionally account for location discrepancies, e.g., the
valueofjÂ¯ğ‘¦ ğœ‡0jintheprecedingexample.Clarke(1996)andMorita
et al. (2008) use EPSS to quantify the information in the prior in
isolationfromthedata,whileReimherretal.(2014)andJonesetal.
(2020)concentrateontheimpactoftheprioronthespeciï¬canalysis
RASTI 000, 1â€“10 (0000)8G.M. Eadie et al.
Number of ObjectsMeasured
LikelihoodPosteriorPriorParallax [mas]
ClusterCombine
More informationInferredParallax [mas]
Individual 
Measurements
Figure 3. Extended Example for Open Cluster M67. An extension of the example shown in Figure 1 illustrating how to infer the distance to an open cluster
(M67)basedonparallaxmeasurementsofmanystars. Top:Parallaxmeasurements(gray)forlikelyclustermembers(basedonpropermotions),sortedbytheir
observedsignal-to-noseratio ğœ›obsÂğœğœ›.Bottom:Thejointlikelihood(gray)andposterior(blue)fortheclusterparallax ğœ›cluster=1Âğ‘‘clusterasmoreandmore
starsareaddedtoouranalysis.The(Gaussian)priordistributionontheclusterâ€™sparallaxisillustratedinthenarrowleftpanel.Whenthereisonlyasmallnumber
of stars, the location of the prior has a substantial impact on the posterior. However, as more stars are added, the information from the data dominates.
performed. The latteris typically more relevant inscience and more
closely coincides with sensitivity analyses.
Good practices outlined in this section can be summarized as (1)
using multiple ways to summarize the posterior inference, (2) quan-
titatively and graphically checking the posterior distribution (e.g.,
usingposteriorpredictivechecks, Q-Qplots),and(3)providingevi-
dence that diagnostic checks were completed.
2.5.1 Extended Example: posterior predictive checks
We investigate the validity of our model for the distance to a cluster
of stars by computing the posterior predictive distribution for the
observedstellarparallaxes.Whileinthiscasetheposteriorpredictive
canbewritteninclosedform(sinceitisaGaussiandistribution),we
alsoapproximateitbysimulatingvaluesof ğ‘‘clusterfromtheposterior
and then subsequently simulating values for the predicted parallax
measurements ğœ›predÂ–ğ‘–givenğ‘‘cluster.
In Figure 4, we compare both the distribution and quantiles esti-
matedforthesimulateddatasetandtheobserveddatasetviaadensity
andQ-Qplot respectively. While there are diï¬€erences, especially in
thetailsofthedistribution,overalltheclustermodelreproducesmost
of the observed properties of the data. It would be worth investigat-
ing whether these diï¬€erences persist under diï¬€erent models â€“ for
example, a model in which the distance to each star is not assumed
to be identical, or a model in which measurement uncertainty is not
assumed to be known exactly.2.6 Conclusion
Wehopethatthisarticlehasidentiï¬ed,clariï¬ed,andilluminatedfun-
damentalBayesianinferencenotationandtechniquesfromthestatis-
tics literature, and in particular, has made a case for fully specifying
the model, posterior predictive checking, and the use of underused
aidssuchasthe Q-Qplot.Insummary,wehighlightsoundpractices
for conducting Bayesian inference in astronomy as follows:
Beexplicitaboutnotation,anduseappropriateterminologyfor
the interpretation of concepts such as the likelihood and credible
intervals, which will help interdisciplinary collaboration and repro-
ducibility.
Describe the likelihood as a function of the parameters, given
the data.
Use informative priors whenever possible and justiï¬ed. Care-
fully consider what direct or indirect information is available about
the parameters.
Usenon-informativepriorscarefully,andassesstheirproperties
under parameter transformations.
Testthesensitivityoftheposteriordistributiontodiï¬€erentprior
distributions.
Fully specify the Bayesian model in terms of the likelihood,
prior, and posterior, and provide open-source code whenever possi-
ble.
Performposteriorpredictivechecksofthemodel,usingvisual-
izations such as Q-Qplots where appropriate.
Strivetoincludeallnon-negligiblecontributorstothemeasure-
ment process.
We hope that there is a continued growth of interdisciplinary col-
laborationsbetweenastronomersandstatisticiansinthefuture.Data
RASTI 000, 1â€“10 (0000)Bayesian inference in Astronomy 9
Predicted Parallax [mas]Measured Parallax [mas] Probability [normalized]DataPosterior
Posterior 
Predictive
1%5%20%50%80%95%99%
Figure 4. Quantile-Quantile ( Q-Q) Plot.This ï¬gure demonstrates a way
to perform posterior predictive checking for the model shown in Figure 3.
Top:The distribution of parallax measurements from the data (gray) and
simulated values from the posterior predictive (light blue). The posterior
mean is indicated using the dashed dark blue line. The distributions appear
relatively consistent with each other by eye, but a quantile-quantile ( Q-Q)
plotismoreinformativeandsuggestsotherwise. Bottom:TheQ-Qplotofthe
quantiles from the posterior predictive simulated parallax data ( ğ‘¥-axis) and
of the observed parallaxes ( ğ‘¦-axis). If the real and simulated data followed
the same distribution, then the quantiles would lie on the one-to-one line.
However, strong discrepancies are apparent below 10th percentile and
above70th percentile.
from cutting-edge telescopes such as the Vera Rubin Observatory,
the James Webb Space Telescope, and many others, have the poten-
tial to drive the ï¬eld of astronomy, but this new information is best
understood in the context of existing knowledge and careful statisti-
calinference.Bayesianinferenceprovidesaframeworkinwhichthis
type of analysis and discovery can occur. Areas of astronomy where
prior information and non-Gaussian based likelihoods are common
canespeciallybeneï¬tfromBayesianmethods,forexampleX-rayand
gamma-ray astronomy.
Bayesian inference is a broad topic, and many subtopics were
not covered in this article. Ultimately, we hope that this article not
only serves as a useful resource, but will also be the inception for a
series of more speciï¬c papers on Bayesian methods and techniques
in astronomy and physics.ACKNOWLEDGEMENTS
GMEacknowledgesthesupportofaDiscoveryGrantfromtheNatu-
ralSciencesandEngineeringResearchCouncilofCanada(NSERC,
RGPIN-2020-04554). JCK gratefully acknowledges support from
NSF under Grant Numbers AST 2009528 and DMS 2038556. DH
issupportedbytheWomenInScienceExcel(WISE)programmeof
the Netherlands Organisation for Scientiï¬c Research (NWO).
DATA AVAILABILITY
Data used in the running example is provided with permission and
courtesyofPhillCargile(CenterforAstrophysics jHarvard&Smith-
sonian).
REFERENCES
Akeret J., Refregier A., Amara A., Seehars S., Hasner C., 2015, Journal of
Cosmology and Astroparticle Physics, 2015, 043
Alonso R., et al., 2004, The Astrophysical Journal Letters, 613, L153
Astraatmadja T. L., Bailer-Jones C. A. L., 2016a, ApJ, 832, 137
Astraatmadja T. L., Bailer-Jones C. A. L., 2016b, ApJ, 833, 119
Bailer-Jones C. A. L., 2015, PASP, 127, 994
Bailer-Jones C. A. L., Rybizki J., Fouesneau M., Mantelet G., Andrae R.,
2018, AJ, 156, 58
BeaumontM.A.,2019,Annualreviewofstatisticsanditsapplication,6,379
BeaumontM.A.,CornuetJ.-M.,MarinJ.-M.,RobertC.P.,2009,Biometrika,
96, 983
Berger J. O., Wolpert R. L., 1988, The likelihood principle. IMS Lecture
Notes-Monograph Series Vol. 6, Institute of Mathematical Statistics
Blei D. M., Ng A. Y., Jordan M. I., 2003, Journal of machine Learning
research, 3, 993
Brooks S., Gelman A., Jones G., Meng X.-L., 2011, Handbook of Markov
chain Monte carlo. CRC press
Butler R. P., et al., 2017, The Astronomical Journal, 153, 208
Carlin B. P., Louis T. A., 2000, Bayes and empirical Bayes methods for data
analysis.TextsinStatisticalScienceVol.88,Chapman&Hall/CRCBoca
Raton
Carlin B. P., Louis T. A., 2008, Bayesian methods for data analysis. CRC
Press
Casella G., Berger R. L., 2002, Statistical inference, second edn. Duxbury
Paciï¬c Grove, CA
Clarke B., 1996, Journal of the American Statistical Association, 91, 173
Collaboration G., et al., 2018, yCat, pp Iâ€“345
CraiuR.V.,RosenthalJ.S.,2014,AnnualReviewofStatisticsandItsAppli-
cation, 1, 179
Dalal S., Hall W., 1983, Journal of the Royal Statistical Society: Series B
(Methodological), 45, 278
Danby J., 1988, Willmann-Bell, 1988. 2nd ed., rev. & enl.
Diaconis P., Ylvisaker D., 1979, The Annals of statistics, pp 269â€“281
Dragomir D., et al., 2019, The Astrophysical Journal Letters, 875, L7
Eadie G., et al., 2019a, in Bulletin of the American Astronomical Society.
p. 233 ( arXiv:1909.11714 )
Eadie G., et al., 2019b, in Canadian Long Range Plan for As-
tronony and Astrophysics White Papers. p. 10 ( arXiv:1910.08857 ),
doi:10.5281/zenodo.3756019
Eadie G. M., Webb J. J., Rosenthal J. S., 2021, arXiv e-prints, p.
arXiv:2108.13491
Fischer D. A., Marcy G. W., Spronck J. F., 2013, The Astrophysical Journal
Supplement Series, 210, 5
Foreman-MackeyD.,HoggD.W.,LangD.,GoodmanJ.,2013,Publications
of the Astronomical Society of the Paciï¬c, 125, 306
Gabry J., Mahr T., 2019, bayesplot: Plotting for Bayesian Models, https:
//mc-stan.org/bayesplot
RASTI 000, 1â€“10 (0000)10G.M. Eadie et al.
Gabry J., Simpson D., Vehtari A., Betancourt M., Gelman A., 2019, J. R.
Stat. Soc. A, 182, 389
Gaia C., et al., 2018, Astronomy & Astrophysics, 616
Gelman A., Meng X.-L., Stern H., 1996, Statistica Sinica, 6, 733
GelmanA.,CarlinJ.B.,SternH.S.,DunsonD.B.,VehtariA.,RubinD.B.,
2013, Bayesian data analysis. CRC press
Gelman A., Simpson D., Betancourt M., 2017, Entropy, 19, 555
Hastings W. K., 1970, Biometrika, 57, 97
Hilbe J. M., De Souza R. S., Ishida E. E., 2017, Bayesian models for astro-
physical data: using R, JAGS, Python, and Stan. Cambridge University
Press
HobertJ.P.,CasellaG.,1996,JournaloftheAmericanStatisticalAssociation,
91, 1461
Hoï¬€manM.D.,BleiD.M.,WangC.,PaisleyJ.,2013,TheJournalofMachine
Learning Research, 14, 1303
Hogg D. W., 2018, A likelihood function for the Gaia Data
(arXiv:1804.07766 )
Holl B., Lindegren L., Hobbs D., 2012, A&A, 543, A15
Hubble E., 1929, Proceedings of the National Academy of Science, 15, 168
Ishida E. E., et al., 2015, Astronomy and Computing, 13, 1
JonesD.E.,TrangucciR.N.,ChenY.,2020,arXivpreprintarXiv:2001.10664
Jordan M. I., Ghahramani Z., Jaakkola T. S., Saul L. K., 1999, Machine
learning, 37, 183
Konacki M., Torres G., Jha S., Sasselov D. D., 2003, Nature, 421, 507
Kumar R., Carroll C., Hartikainen A., Martin O. A., 2019, The Journal of
Open Source Software
Lemoine N. P., 2019, Oikos, 128, 912
Lindegren, L. et al., 2018, A&A, 616, A2
LindegrenL.,LammersU.,HobbsD.,Oâ€™MullaneW.,BastianU.,HernÃ¡ndez
J., 2012, A&A, 538, A78
Little R. J., Rubin D. B., 2019, Statistical analysis with missing data, third
edn. John Wiley & Sons
Lunn D. J., Thomas A., Best N., Spiegelhalter D., 2000, Statistics and com-
puting, 10, 325
Marin J.-M., Pudlo P., Robert C. P., Ryder R. J., 2012, Statistics and Com-
puting, 22, 1167
Maritz J. S., 2018, Empirical Bayes methods with applications. CRC Press
Mayor M., et al., 2011, arXiv preprint arXiv:1109.2497
MetropolisN.,UlamS.,1949,JournaloftheAmericanstatisticalassociation,
44, 335
Metropolis N., Rosenbluth A. W., Rosenbluth M. N., Teller A. H., Teller E.,
1953, The journal of chemical physics, 21, 1087
Morita S., Thall P. F., MÃ¼ller P., 2008, Biometrics, 64, 595
Pepe F., et al., 2011, Astronomy & Astrophysics, 534, A58
Plummer M., et al., 2003, in Proceedings of the 3rd international workshop
on distributed statistical computing. pp 1â€“10
Reimherr M., Meng X.-L., Nicolae D. L., 2014, arXiv preprint
arXiv:1406.5958
Riddell A., et al., 2017, stan-dev/pystan: v2.17.0.0,
doi:10.5281/zenodo.1003176, https://doi.org/10.5281/zenodo.
1003176
Robert C. P., 2014, Annual Review of Statistics and Its Application, 1, 153
Rubin D. B., 1976, Biometrika, 63, 581
Rue H., Martino S., Chopin N., 2009, Journal of the royal statistical society:
Series b (statistical methodology), 71, 319
Salvatier J., Wiecki T. V., Fonnesbeck C., 2016, PeerJ Computer Science, 2,
e55
Schervish M. J., 1995, Theory of statistics. Springer Series in Statistics,
Springer
SchÃ¶nrich R., McMillan P., Eyer L., 2019, Monthly Notices of the Royal
Astronomical Society, 487, 3568
Stan Development Team 2020, RStan: the R interface to Stan, http://
mc-stan.org/
Tak H., Mandel K., van Dyk D. A., Kashyap V. L., Meng X.-L., Siemigi-
nowska A., 2017, The Annals of Applied Statistics, 11, 1309
Tak H., Ghosh S. K., Ellis J. A., 2018, Monthly Notices of the Royal Astro-
nomical Society, 481, 277
Tuyl F., Gerlach R., Mengersen K., 2008, The American Statistician, 62, 40Vehtari A., Gelman A., Simpson D., Carpenter B., BÃ¼rkner P.-C., 2020,
Bayesian Analysis, 16, 667
WeyantA.,SchaferC.,Wood-VaseyW.M.,2013,TheAstrophysicalJournal,
764, 116
de Valpine P., Turek D., Paciorek C. J., Anderson-Bergman C., Lang D. T.,
Bodik R., 2017, Journal of Computational and Graphical Statistics, 26,
403
This paper has been typeset from a T EX/LATEX ï¬le prepared by the author.
RASTI 000, 1â€“10 (0000)