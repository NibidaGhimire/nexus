Cycle-guided Denoising Diffusion Probability M odel for 
3D Cross-modality  MRI Synthesis  
Shaoyan Pan1,2, Chih -Wei Chang, Junbo Peng1, Jiahan Zhang1, Richard L.J. Qiu1,  
Tonghe Wang3, Justin Roper1, Tian Liu4, Hui Mao5 and Xiaofeng Yang1,2* 
1Department of Radiation Oncology and Winship Cancer Institute, Emory University, Atlanta, 
GA 30322, USA  
2Department of Biomedical Informatics, Emory University, Atlanta, GA 30322, USA  
3Medical Physics, Memorial Sloan Kettering Cancer Center , New York, NY 10065, USA  
4Radiation Oncology, Icahn School of Medicine at Mount Sinai, New York, NY 10029, USA  
5Department of Radiology and Imaging Sciences and Winship Cancer Institute, Atlanta, 
GA 30308  
 
*Corresponding to: xiaofeng.yang@emory.edu  
Abstract  This study aims  to develop a novel Cycle -guided Denoising Diffusion 
Probability Model (CG -DDPM) for  cross -modality MRI synthesis. The CG -
DDPM deploys two DDPMs that condition each other to generate synthetic im-
ages from two different MRI  pulse sequences . The two DDPMs exchange ran-
dom latent noise in the reverse processes , which helps  to regularize both DDPMs 
and generate matching images in two modalities . This  improv es image -to-image 
translation accuracy. We evaluated t he CG -DDPM quantita tively using mean ab-
solute error (MAE), multi -scale structural similarity index measure ( MSSIM), 
and peak signal -to-noise ratio (PSNR) , as well as the network synthesis con-
sistency,  on the B raTS2020 dataset . Our proposed method showed high accuracy 
and reliable consistency  for MRI synthesis. In addition, we compared the CG -
DDPM with several other state -of-the-art networks and demonstrated statistically 
significant improvements in the image quality of synthetic MRIs. The proposed 
method enhances the capabili ty of current multimodal MRI synthesis  approaches, 
which could contribute to more accurate diagnosis and better treatment planning 
for patients by synthesizing additional MRI modalities.  
Keywords:  3D denoising  diffusion probabilistic model, 3D MRI synthesi s. 
1 Introduction  
Magnetic Resonance Imaging (MRI) is widely deployed in the clinic for diagnosis, 
prognosis, and treatment planning for radiotherapy  [1-5]. MRI is featured in providing 
anatomical and functi onal information, allowing physicians to accurately identify le-
sion regions, malignan cy types, and metastasis status. For instance, T1 -weighted (T1) 
MRI scans offer clear contrast resolution between white and gray matter to reveal the 
tissue boundary in di agnosing brain lesions. T2 -weighted (T2) MRI scans are used to 
identify craniospinal fluid (CSF) in the brain, and the fluid -attenuated inversion 2 
recovery (FLAIR) technique can suppress fluid signals to enable lesion detection in 
proximity to CSF. Combinin g the strengths of each modality enables a more compre-
hensive examination of the underlying anatomy and physiology, facilitating disease di-
agnosis and treatment. However, MRI scanning is time -consuming due to fundamental 
imag ing physics. The time dilation between different MRI scanning sequences can 
cause motion artifacts, compromising the image quality. For patients allergic to MRI 
contrast, the diagnosis accuracy may be compromised without using contrast . 
Deep learning as a universal approximator  [6-12] has been explored for MRI syn-
thesis via various model hierarchies  [13, 14] . Generative adversarial networks (GAN) 
[15-19] have  been  demonstrated  to be effective in  generat ing high-quality medical im-
ages across different modalities . Recently, denoising diffusion probability models 
(DDPM) [20, 21]  have gained attraction for image synthesis since DDPM addresses the 
issues of GAN , such as  mode collapse when  learning multimodal distribution. How-
ever, DDPM requires Markov chain denoising processes, which root in uncertainty for 
image synthesis [22]. Numerous efforts and studies have been conducted to enhance 
the performance of DDPM  [23, 24]  and applied the DDPM into medical image synthe-
sis [25]. In radiotherapy , the investigation of three -dimensional (3D) DDPM’s  uncer-
tainty  on MRI synthesis  is still in its infancy, and such a development is essential to 
ensure patient safety and benefits.  
This work proposes a cycle -guided denoising diffusion probability model (C G-
DDPM), a cross -modality MRI synthesis algorithm that generates comprehensive MRI 
modalities based on available inputs. To the authors' best knowledge, the proposed 
model  is the first capable of leveraging the 3D MRI data to ensure the consistency of 
patient anatomy. In conventional DDPMs, the reverse denoising process is entirely ran-
dom, leading to inconsistent synthetic results across multiple runs and potentially caus-
ing the model to generate MRIs in the target signal sequences that can mismatch those 
in the source signal sequences. In contrast, we propose a cycle -guided reverse latent 
process to regularize DDPM to conserve the patient anatomy and improve image trans-
lation accuracy. To demonstrate the robustness and accuracy of the CG -DDPM, we 
investigat e its performance  with other state -of-the-art MRI cross -modality translation 
methods in BraTS2020  dataset  [26-28]. The originality of the proposed CG -DDPM , the 
first 3D D DPM -based model for MRI synthesis,  can be summarized in two aspects.  
(The code will be released after acceptance from Journal)  
• The proposed 3D CG-DDPM can stably preserve patient anatomy and reproduce 
reverse noise pattern when synthesizing MRI images. This feature is essential for pa-
tient safety regarding lesion diagnosis and prognosis.  
• The proposed 3D CG-DDPM can improve accuracy  compared to other state -of-the-
art GAN and DDPM methods. This outcome is essential  for potential MRI -based treat-
ment planning.  
2 Method : Cycle -Guided Denoising Diffusion Probability Model  
The proposed CG -DDPM consists of two identical denoising  neural networks  run in 
three processes  (Figure 1). Firstly, a forward diffusion process adds a small amount of 3 
Gaussian noise to the high-quality, scanner -acquired  target  MRI 𝑋0 and the source  MRI 
𝑌0 at 𝑁 successive time step, resulting in two sequence s of noisy images [𝑋1,…,𝑋𝑁] 
and [𝑌1,…,𝑌𝑁]. Next , a reverse diffusion process trains two neural network s 𝑓𝑋, under 
the guidance of the source MRI 𝑌0, and 𝑓𝑌, under the guidance of the target MRI 𝑋0, 
to denoise the MRI 𝑋𝑛 to 𝑋𝑛−1,  and 𝑌𝑛 to 𝑌𝑛−1 at any timestep 𝑛, respectively . In ad-
dition , the reverse latent noise 𝜖𝑁𝑋 obtained between  the 𝑋𝑛 and 𝑋𝑛−1 is used in the gen-
eration of 𝑌𝑛−1, and vice versa , to control the denoising direction . Thirdly,  in an  infer-
ence process , the fine -trained source reverse process 𝑝𝑓𝑌 generate s a sequence of reverse 
latent code [𝑧𝑁,𝑧𝑁−1,…,𝑧1] from [𝑌0,…,𝑌𝑁]. The latent codes are  then applied to 𝑓𝑋 
to convert a Gaussian noise 𝑋𝑁 to the target  MRI 𝑋𝑛𝑒𝑤 paired to 𝑌0. In the following 
sections, we use target image synthesis to illust rate the forward and reverse process es. 
2.1 Forward diffusion process  
The forward diffusion defines the noisy image generation as a Gaussian Markov pro-
cess 𝒩(𝑋𝑛;√1−𝛽𝑛𝑋𝑛−1,𝛽𝑛𝐼), with pre -determined mean of √1−𝛽𝑛 and standard 
deviation of 𝛽𝑛 at timest ep 𝑛. Following  [21], we can efficiently generate a noisy image 
at any arbitrary timestep 𝑛 by the clean image 𝑋0 of the source or target modality : 
 𝑋𝑛= √ ∏ 𝛼𝑖𝑛
𝑖=1 𝑋0+√1− ∏ 𝛼𝑖𝑛
𝑖=1 𝜖𝑋 (1) 
where 𝛼𝑖≔1−𝛽𝑖, 𝜖𝑋~𝒩(0,𝐼) is a noise sampled from a normal di stribution.   
 
Figure 1:  Proposed CG -DDPM: In addition to the forward and reverse diffusion in the traditional 
DDPM, the generation direction is controlled using a cycle -guided latent noise regularization 
technique. The ground truth target and source MRIs 𝑋1,…,𝑁 and 𝑌1,…,𝑁 are used to generate the 
deterministic latent noise 𝜖1,…,𝑁𝑋 and 𝜖1,…,𝑁𝑌. Then we mutually employ the latent noise to generate 
synthetic MRIs 𝑋1,…,𝑁𝑒𝑠𝑡 and 𝑌1,…,𝑁𝑒𝑠𝑡 from two modalities . 
2. 2 Reverse diffusion process  
The reverse  diffusion process  is defined as another Gaussian process 
𝑝𝑋(𝑋𝑛−1|𝑋𝑛)~𝒩(𝑋𝑛;𝜇𝑋,Σ𝑋), where 𝜇𝑋 and Σ𝑋 are unknown. We use a neural net-
work 𝑓𝑋, condition ed on the clean source image 𝑌0, to estimate them:  
𝑝𝑓𝑋(𝑋𝑛−1|𝑋𝑛,𝑌0,𝑛)=𝒩(𝑋𝑛−1;𝜇𝑓𝑋(𝑋𝑛,𝑌0,𝑛),Σ𝑓𝑋(𝑋𝑛,𝑌0,𝑛))      (2) 
4 
Following Nicol et al.’s formulation  [23], a denoising network is trained to estimate 
noise 𝜖𝑓𝑋 and the variance  coefficient  𝑣𝑋. The network is optimized as:  
 argmin  
𝑓𝑋𝐿𝐷𝐷𝑃𝑀𝑋= 𝑀𝐴𝐸 (𝜖𝑋,𝜖𝑓𝑋(𝑋𝑛,𝑌0,𝑛))+γ∗LVLB(Σ𝑋,Σ𝑓𝑋(𝑋𝑛,𝑌0,𝑛),𝑛)  (3) 
where 𝑀𝐴𝐸  is the mean absolute error,  𝐿𝑉𝐿𝐵 is the variational lower bound loss, and:  
Σ𝑓𝑋(𝑋𝑛,𝑌0,𝑛)=exp (𝑣𝑋(𝑋𝑛,𝑌0,𝑛)∗log𝛽𝑛+(1−𝑣𝑋(𝑋𝑛,𝑌0,𝑛))∗
log(1−∏ 𝛼𝑖𝑛−1
𝑖=1
1−∏ 𝛼𝑖𝑛
𝑖=1𝛽𝑛))  (4) 
Then the estimated mean 𝜇𝑓𝑋 can be obtained from:  
 𝜇𝑓𝑋(𝑋𝑛,𝑌0,𝑛)=1
√ 𝛼𝑛(𝑋𝑛−𝛽𝑛
√1− 𝛼𝑛𝜖𝑓𝑋(𝑋𝑛,𝑌0,𝑛))  (5) 
where 𝛾 is empirically set to 0.05.  Full optimization details are in the Appendix. B.  
2.3 Applying the cycle -guided latent code regularization  
With an accurately  estimated mean and variance, using the reparameterization trick, we 
can sample  estimated  𝑋𝑛−1𝑒𝑠𝑡 from 𝑋𝑛, and 𝑌𝑛−1𝑒𝑠𝑡 from 𝑌𝑛 at any timestep 𝑛: 
 𝑋𝑛−1𝑒𝑠𝑡=𝜇𝑓𝑋(𝑋𝑛,𝑌0,𝑛)+Σ𝑓𝑋(𝑋𝑛,𝑌0,𝑛)∗𝜖𝑛𝑋 (7) 
 𝑌𝑛−1𝑒𝑠𝑡=𝜇𝑓𝑌(𝑌𝑛,𝑋0,𝑛)+Σ𝑓𝑌(𝑌𝑛,𝑋0,𝑛)∗𝜖𝑛𝑌 (8) 
where 𝜖𝑛𝑋,𝑌~𝒩(0,𝐼). Previous research [29] suggests that a fixed sequence of random 
latent codes can produce similar images consistently using two diffusion models. Based 
on this, our proposed approach is to use the same fixed latent code for both the source 
and target DDPMs to generate paired MRI. We introduce an additional step in model 
training, where the network is optimized to generate matching MRI by using the latent 
code from the reverse process of the source MRI. Formally , the source latent cod e is: 
 𝑧𝑛=𝜖𝑛𝑌=𝑌𝑛−1−𝜇𝑓𝑌(𝑌𝑛,𝑋0,𝑛)
Σ𝑓𝑌(𝑌𝑛,𝑋0,𝑛) (9) 
Then the matching MRI on the target domain is generated as:  
 𝑋𝑛−1𝑒𝑠𝑡=𝜇𝑓𝑋(𝑋𝑛,𝑌0,𝑛)+Σ𝑓𝑋(𝑋𝑛,𝑌0,𝑛)∗𝑧𝑛 (20) 
By applying the same process to source domain reverse process , we jointly optimize 
the source and target network by the cycle -guided loss 𝐿𝑐𝑦𝑐, which consists of two 
𝑀𝐴𝐸  losses between the synthetic images and ground truth images : 
 argmin  
𝑓𝑋,𝑓𝑌Lcyc=𝑀𝐴𝐸 (𝑋𝑛−1𝑒𝑠𝑡,𝑋𝑛−1)+ 𝑀𝐴𝐸 (𝑌𝑛−1𝑒𝑠𝑡,𝑌𝑛−1)   (31) 
Finally, the CG -DDPM is optimized with a cycle -guided strength 𝜆 (empirically =1): 5 
 𝐿𝐶𝐺−𝐷𝐷𝑃𝑀 =𝐿𝐷𝐷𝑃𝑀𝑋+ 𝐿𝐷𝐷𝑃𝑀𝑌+𝜆𝐿cyc (42) 
2.4 Sampling  
To generate a target image matching the given condition image, we firstly  generate  a 
sequence of  noisy image [𝑌1,…,𝑌𝑁] based on Eq. ( 2). Taking t he 𝑌𝑁 as a starting point 
for the target image sampling , we denote 𝑋𝑁=𝑌𝑁. Then we can obtain the corre spond-
ing clean target image 𝑋0𝑒𝑠𝑡: 
 𝑋0𝑒𝑠𝑡=𝑋𝑛− √1− ∏ 𝛼𝑖𝑁
𝑖=1𝜖𝑓𝑋(𝑋𝑁,𝑌0,𝑁)
√ ∏ 𝛼𝑛𝑁
𝑖=1𝑋0 (53) 
Then the 𝑋0𝑒𝑠𝑡 can be used for obtaining the first source reverse code  at timestep 𝑡: 
 𝑧𝑛=𝜖𝑁𝑌=𝑌𝑁−1−𝜇𝑓𝑌(𝑌𝑁,𝑋0𝑒𝑠𝑡,𝑁)
Σ𝑓𝑌(𝑌𝑁,𝑋0𝑒𝑠𝑡,𝑁) (64) 
And we can obtain the less noisy target image 𝑋𝑁−1𝑒𝑠𝑡: 
 𝑋𝑁−1𝑒𝑠𝑡=𝜇𝑓𝑋(𝑋𝑁,𝑌0,𝑁)+Σ𝑓𝑋(𝑋𝑁,𝑌0,𝑁)∗𝑧𝑛 (75) 
By repeating the above operation N times,  the target DDPM can iteratively generate a 
less noisy image and eventually obtain a target MRI  𝑋𝑛𝑒𝑤 matching the  source MRI 𝑌0. 
2.5 Denoising network  
The denoising networks in the CG -DDPM are 3D U -shaped neural netwo rks consisting 
of convolution layers defined in [30] and Swin -transformer layers defined in [31]. The 
full architecture is presented in Appendix A.  
 
Figure 2. Ground truth MRIs and synthetic MRIs for T1→T2, T2→T1, T1→FLAIR, 
FLAIR→T1  synthesis. Synthetic MRIs from the proposed CG -DDPM (column #1), IDDPM 
(column #2), IDDIM (column #3), and MRI -cGAN  (column #4) are presented column -wise. The 
difference maps between the truth and synthetic MRIs are shown below.  
6 
3 Experiments  
3.1 BraTS 2020 dataset  
The B raTS 2020 dataset  [26-28] is a collection of  multi -instituti onal multimodal brain 
MRI scans . For this experiment, we utilized the first 178 scans for training, 2 for vali-
dation, and 18 for testing. We resampled each MRI scan into a voxel spacing of 1x1x6 
mm, then centered and padded the boundaries, resulting in ima ge grid dimensions of 
256x256x32. Each MRI scan is normalized to the intensity interval [ -1,1] in both the 
training and inference phases. During each training iteration, we randomly selected two 
patches with a size of 64x64x16 from each MRI scan to train t he denoising model. 
During inference, we used a sliding window approach to generate the full MRI scan 
with a window size equal to the patch size. We set the overlap between windows to 
50% of the patch size and applied Gaussian weighting to the edges of the  windows. No 
augmentation or registration techniques were used.  
3.2 Experiment design  
The proposed CG -DDPM was applied for four MRI cross -modality translation tasks 
using the BraTS 2020 dataset: one model for T1 -T2 (T1 -to-T2 and T2 -to-T1), and one 
for T1 -FLAIR (T1 -to- FLAIR and FLAIR -to-T1). Each CG -DDPM was trained with 
N=4000 forward diffusion steps, and 50 reverse diffusion steps were used to sample 
synthetic images. The CG -DDPM denois ing networks were trained with an AdamW  
[32] optimizer (initial learning rate of 0.00004 and weight decay rate of 0.001) with a 
batch size of four. The T1 -to-T2 CG -DDPM was trained for 1000 epochs, and the T1 -
to-FLAIR CG -DDPM was trained for 850 epochs. The source and target denoising net-
works w ere trained individually, under Eq. (5), for the first 500 epochs and jointly 
trained using cycle -guided latent code regularization for the remaining epochs, as de-
scribed in Eq. (12).  
Table 1.  Quantitative and statistical analysis of the synthetic MRIs for  CG-DDPM vs. IDDPM, 
IDDIM, and MRI -cGAN . MAE is calculated by the normalized images ([ -1,1]).  
  CG-DDPM  IDDPM  IDDIM  MRI -cGAN  
T1 
 
T2 MSSIM  0.968  0.914* 0.882* 0.875* 
MAE  0.011  0.013* 0.020* 0.025* 
PSNR(dB)  28.6 28.8 27.4 25.2* 
T2 
 
T1 MSSIM  0.971  0.945* 0.878* 0.924* 
MAE  0.012  0.024* 0.024* 0.018* 
PSNR(dB)  28.7 24.1* 25.1* 26.5* 
T1 
 
FLAIR  MSSIM  0.966  0.958* 0.881* 0.882* 
MAE  0.011  0.012  0.022* 0.028* 
PSNR(dB)  28.8 28.2 25.6* 23.0* 
FLAIR  
 
T1 MSSIM  0.971  0.957* 0.875* 0.875* 
MAE  0.013  0.014  0.025* 0.025* 
PSNR(dB)  27.7 28.1 25.2 25.2* 
*Statistically significant difference to CG -DDPM ( p-value < 0.05)  
We evaluated the performance  of CG -DDPM using three evaluation metrics: multi -
scale structural similarity measure (MSSIM) [33], peak signal -to-noise ratio (PSNR ), 7 
and mean absolute error (MAE). The proposed model was also compared to other deep 
learning models , including improved DDPM (IDDPM)  [23], improved denoising dif-
fusion implicit model (IDDIM) [23], and MRI conditional GAN ( MRI -cGAN ) [34]. 
IDDPM and IDDIM were trained for 4000 steps and sampled MRIs for 256 steps based 
on the settings  defined in [23]. Due to the randomness in diffusion -based deep learning 
models, we used Monte Carlo -based (MC -based) sampling  [22] to generate a converged 
synthetic MRI. We sampled MRIs in five runs and took the average result as the final 
synthetic MRI for each patient.  
3.3 Quantitative and qualitative results for accuracy of CG -DDPM   
Figure 2 and 3  shows  the visualization of synthetic MRIs from various methods. The 
CG-DDPM and DDPM -based methods exhibit good visual appearance, but the DDPM -
based methods display slight patchy artifacts due to the patch -based inference strategy. 
The computational requiremen ts for full image inference were overwhelming in their 
hardware setting (48 GB NVIDIA RTX 6000 GPU) , therefore patch -based inference is 
needed . Higher overlapping ratios of the patch -based inference could mitigate the 
patchy artifacts. Table 1 summarizes t he quantitative accuracy of diffusion -based deep 
learning models and MRI -cGAN . The proposed CG -DDPM can achieve optimal results 
regarding MAE and PSNR  for most of the translation tasks . Although IDDPM shows 
better PSNR values than CG -DDPM for T1 to T2, and  FLAIR to T1 MRI synthesis, the 
statistical  p-value tests indicate no significant difference in PSNR results. CG -DDPM 
achieves the optimal MSSIM for all types of MRI image generation. Figure 2 confirms 
the results that CG -DDPM can generate the most similar  images as the ground truth 
regarding difference and resolution comparisons via MSSIM .  
 
Figure 3. Ground truth MRIs, synthetic MRIs from five different runs and their average of the 
MC-based sampling of the DDPM models are presented column -wise. We present the proposed 
CG-DDPM in the first row, IDDPM in the second row, and IDDIM in the third row. More ex-
amples are shown in the Appendix. C.  
8 
3.4 Qualitative and q uantitative results for consistency  of CG -DDPM  
We assessed the consistency of the synthetic result of the DDPM -based methods.  Fig-
ure 3 shows that the synthetic results from five runs of the MC -based sampling  and 
their average among the five runs . The proposed CG -DDPM shows higher consistency 
compared to the IDDPM and IDDIM  among different  runs. We further calculated the 
mean standard deviation of image intensities from the five runs as the uncertainty of 
DDPM -based deep learning models. In Fig ure 5, the CG -DDPM achieves the minimum 
uncertainties in all ta sks, indicating superior  consistency  compared to other methods .  
In addition, w e ran the DDPM -based models for 𝑛 times  to sample synthetic MRIs  
and denoted them as MC -n, where  n ranges from one to five.  We calculated the MSSIM 
of the average results of al l MC -𝑛. Then, we normalized MSSIM (N -MSSIM) using 
the maximum SSIM value across all MC -𝑛. This allowed us to observe how the quality 
of synthetic images changed with different numbers of runs in MC -based sampling.  A 
slower convergence could indicate that  more MC runs are needed to obtain the con-
verged synthetic MRIs. In Fig ure 4, the N-MSSIM of CG -DDPM is converged with 
run times of one or two, which is faster than IDDPM and IDDIM.  The standard devia-
tions of N-MSSIM from different MC -𝑛 results define  the inconsistency. Figure 5 
shows the inconsistency of diffusion -based models. CG -DDPM achieves the minimum 
inconsistency, indicating that the optimal and stable synthetic MRI can be obtained with 
minimum sampling runs.  
 
Figure 4 . Sampling stabilit y of the DDPM -based methods from four MRI translation tasks. MC-
𝑛 indicates the MC -based sampling averaged result using 𝑛 runs. Notice that the N -MSSIM does 
not represent the absolute quantitative performance  (e.g., CG -DDPM’s “1” is much higher than 
IDDI M’s “1”) , but a trend of the performance under different numbers of runs in the MC -based 
sampling.  
 
Figure 5. The quantitative robustness of the DDPM -based methods in four MRI translation tasks 
is presented through black  and blue bars that represent sampling uncertainty and inconsistency, 
respectively, with corresponding values shown above the bars.  
3.5 Discussion  
The CG -DDPM network performed the best in terms of image quality, achieving the 
lowest MAE and highest MSSIM, as well as the second -best PSNR among all compet-
ing networks in all translation tasks. Compared to the IDDIM and MRI -cGAN  net-
works, the CG -DDPM d emonstrated statistically significant improvements (with p -val-
ues < 0.05) in reducing cumulative errors (lower MAE), improving accuracy of ana-
tomical intensity, structure, and tissue contrast across multiple resolutions (higher 
9 
MSSIM), and reducing peak er rors of synthetic MRI (smaller PSNR). Even compared 
to the IDDPM network, while the CG -DDPM had slightly worse PSNR, it showed bet-
ter MAE and significantly better MSSIM, indicating its superior performance in syn-
thesizing anatomical intensity, structure, a nd contrasts with smaller cumulative errors.  
In terms of consistency , the CG -DDPM converges faster  (Fig. 4)  than the IDDPM 
and IDDIM to its optimal synthesis  in the MC -based sampling . In addition , the CG-
DDPM showed the lowest  sampling  uncertainty  and inconsistency  in all translation 
tasks . The CG -DDPM can  generate accurate and stable  synthetic MRIs with fewer sam-
pling runs compared to other DDPM -based methods.  
4 Conclusion  
This work introduces a cycle-guided denoising diffusion probabili ty model (CG -
DDPM) , which is the first 3D DDPM -based method  for generating high -quality MRIs 
of a target modality using MRIs from a different modality. It uses two DDPMs to gen-
erate MRIs for each modality, and the random reverse latent noise from one DDPM is 
used to guide the other, which helps to generate matching MRIs in both modalities. The 
CG-DDPM can generate accurate MRIs from the target modality, and achieve state -of-
the-art quantitative performance compared to the other networks.  The CG -DDPM also 
reduce uncertainties  in the synthetic MRIs compared to the other DDPM -based meth-
ods. As a result, t he CG -DDPM can serve as a reliable tool for generat ing high-quality 
MRIs of a target modality given by MRIs from another modality , to facilitate MRI 
medical ap plications.  
 
 
Acknowledgments  
This research is supported in part by the National Institutes of Health under Award 
Number R01CA215718, R56EB033332,  and R01EB032680 . 
  10 
References  
[1] A. Hoffmann, B. Oborn, M. Moteabbed  et al. , “MR -guided proton therapy: a review 
and a preview,” Radiation Oncology , 15(1), 129 (2020).  
[2] K. Goudschaal, F. Beeksma, M. Boon  et al. , “Accuracy of an MR -only workflow for 
prostate radiotherapy using semi -automatically burned -in fiducial markers,” Radia tion 
Oncology , 16(1), 37 (2021).  
[3] C.-W. Chang, R. Marants, Y. Gao  et al. , “Multimodal imaging -based material mass 
density estimation for proton therapy using physics -constrained deep learning,” arXiv 
preprint arXiv:2207.13150, (2022).  
[4] Y. Li, J. Wang , C.-W. Chang  et al. , "Multi -Parametric MRI radiomics analysis with 
ensemble learning for prostate lesion classification." 12468, 49 -54. 
[5] Y. Li, B. Zhou, J. Wang  et al. , "Ultrasound -based dominant intraprostatic lesion 
classification with Swin Transform er." 12470, 146 -151. 
[6] K. Hornik, M. Stinchcombe, and H. White, “Multilayer feedforward networks are 
universal approximators,” Neural Networks , 2(5), 359 -366 (1989).  
[7] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” Nature , 521(7553), 436 -444 
(2015). 
[8] C.-W. Chang, and N. T. Dinh, “Classification of machine learning frameworks for 
data-driven thermal fluid models,” International Journal of Thermal Sciences , 135, 
559-579 (2019).  
[9] M. Hu, J. Wang, C. -w. Chang  et al. , [Ultrasound breast tumor dete ction based on vision 
graph neural network] SPIE, MI (2023).  
[10] M. Hu, J. Wang, C. -W. Chang  et al. , [End -to-end brain tumor detection using a graph -
feature -based classifier] SPIE, MI (2023).  
[11] M. Hu, J. Wang, J. Wynne  et al. , [A vision -GNN framework f or retinopathy 
classification using optical coherence tomography] SPIE, MI (2023).  
[12] L. Yuheng, W. Jing, H. Mingzhe  et al. , "Prostate gleason score prediction via MRI 
using capsule network." 12465, 1246523.  
[13] L. Sun, X. Hu, Y. Liu  et al. , “Image Feat ures of Magnetic Resonance Imaging under 
the Deep Learning Algorithm in the Diagnosis and Nursing of Malignant Tumors,” 
Contrast Media & Molecular Imaging , 2021, 1104611 (2021).  
[14] E. Moya -Sáez, Ó. Peña -Nogales, R. d. Luis -García  et al. , “A deep learning  approach 
for synthetic MRI based on two routine sequences and training with synthetic data,” 
Computer Methods and Programs in Biomedicine , 210, 106371 (2021).  
[15] X. Dai, Y. Lei, Y. Fu  et al. , “Multimodal MRI synthesis using unified generative 
adversaria l networks,” Medical Physics , 47(12), 6343 -6354 (2020).  
[16] X. Hu, R. Shen, D. Luo  et al. , "AutoGAN -Synthesizer: Neural Architecture Search 
for Cross -Modality MRI Synthesis." 397 -409. 
[17] Z. Yu, Y. Zhai, X. Han  et al. , "MouseGAN: GAN -Based Multiple MRI M odalities 
Synthesis and Segmentation for Mouse Brain Structures." 442 -450. 
[18] I. Goodfellow, J. Pouget -Abadie, M. Mirza  et al. , “Generative adversarial networks,” 
Communications of the ACM , 63(11), 139 -144 (2020).  
[19] S. Pan, J. Flores, C. T. Lin  et al. , [Generative adversarial networks and radiomics 
supervision for lung lesion synthesis] SPIE, MI (2021).  11 
[20] J. Song, C. Meng, and S. Ermon, “Denoising diffusion implicit models,” arXiv preprint 
arXiv:2010.02502, (2020).  
[21] J. Ho, A. Jain, and P.  Abbeel, “Denoising diffusion probabilistic models,” Advances 
in Neural Information Processing Systems , 33, 6840 -6851 (2020).  
[22] Q. Lyu, and G. Wang, “Conversion Between CT and MRI Images Using Diffusion and 
Score -Matching Models,” arXiv preprint arXiv:2 209.12104, (2022).  
[23] A. Q. Nichol, and P. Dhariwal, [Improved Denoising Diffusion Probabilistic Models] 
PMLR, Proceedings of Machine Learning Research(2021).  
[24] P. Dhariwal, and A. Nichol, “Diffusion models beat gans on image synthesis,” 
Advances in N eural Information Processing Systems , 34, 8780 -8794 (2021).  
[25] J. Peng, R. L. Qiu, J. F. Wynne  et al. , “CBCT -Based Synthetic CT Image Generation 
Using Conditional Denoising Diffusion Probabilistic Model,” arXiv preprint 
arXiv:2303.02649, (2023).  
[26] S. Bakas, M. Reyes, A. Jakab  et al. , “Identifying the best machine learning algorithms 
for brain tumor segmentation, progression assessment, and overall survival prediction 
in the BRATS challenge,” arXiv preprint arXiv:1811.02629, (2018).  
[27] B. H. Menze, A.  Jakab, S. Bauer  et al. , “The Multimodal Brain Tumor Image 
Segmentation Benchmark (BRATS),” IEEE Transactions on Medical Imaging , 34(10), 
1993 -2024 (2015).  
[28] S. Bakas, H. Akbari, A. Sotiras  et al. , “Advancing The Cancer Genome Atlas glioma 
MRI collectio ns with expert segmentation labels and radiomic features,” Scientific 
Data , 4(1), 170117 (2017).  
[29] C. H. Wu, and F. De la Torre, “Unifying Diffusion Models' Latent Space, with 
Applications to CycleDiffusion and Guidance,” arXiv preprint arXiv:2210.05559 , 
(2022).  
[30] S. Pan, C. -W. Chang, T. Wang  et al. , “Abdomen CT multi -organ segmentation using 
token -based MLP -Mixer,” Medical Physics , n/a(n/a).  
[31] Z. Liu, Y. Lin, Y. Cao  et al. , "Swin transformer: Hierarchical vision transformer using 
shifted windows."  10012 -10022.  
[32] I. Loshchilov, and F. Hutter, “Decoupled weight decay regularization,” arXiv preprint 
arXiv:1711.05101, (2017).  
[33] Z. Wang, E. P. Simoncelli, and A. C. Bovik, "Multiscale structural similarity for image 
quality assessment." 2, 1398 -1402 Vol.2.  
[34] Q. Yang, N. Li, Z. Zhao  et al. , “MRI Cross -Modality Image -to-Image Translation,” 
Scientific Reports , 10(1), 3753 (2020).  
 