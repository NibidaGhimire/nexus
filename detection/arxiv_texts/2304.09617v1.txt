Towards Autonomous Selective Harvesting: A Review
of Robot Perception, Robot Design, Motion Planning
and Control
Vishnu Rajendran S
University of Lincoln, UK
25451641@students.lincoln.ac.ukBappaditya Debnath
Kings College London, UK
b.debnath2017@gmail.com
Sariah Mghames
University of Lincoln, UK
SMghames@lincoln.ac.ukWillow Mandil
University of Lincoln, UK
18710370@lincoln.ac.ukSoran Parsa
University of Hudderseld, UK
sparsa@lincoln.ac.uk
Simon Parsons
University of Lincoln, UK
sParsons@lincoln.ac.ukAmir Ghalamzan-E.y
University of Lincoln, UK
aghalamzanesfahani@lincoln.ac.uk
Abstract
This paper provides an overview of the current state-of-the-art in selective harvesting robots
(SHRs) and their potential for addressing the challenges of global food production. SHRs
have the potential to increase productivity, reduce labour costs, and minimise food waste
by selectively harvesting only ripe fruits and vegetables. The paper discusses the main
components of SHRs, including perception, grasping, cutting, motion planning, and control.
It also highlights the challenges in developing SHR technologies, particularly in the areas of
robot design, motion planning and control. The paper also discusses the potential benets
of integrating AI and soft robots and data-driven methods to enhance the performance and
robustness of SHR systems. Finally, the paper identies several open research questions in
the eld and highlights the need for further research and development eorts to advance
SHR technologies to meet the challenges of global food production. Overall, this paper
provides a starting point for researchers and practitioners interested in developing SHRs
and highlights the need for more research in this eld.
keywords: Selective harvesting; Robotics; Computer vision; Motion control, Motion planning; Precision
farming; Agriculture
1 Introduction
Human activities are driving global warming, and current projections indicate that warming of 1.5 Â°C is
likely to occur between 2030 and 2050 if emissions continue at their current rates (IPCC, 2018). However,
limiting global warming to just 1.5 Â°C requires rapid changes in multiple sectors, including agriculture. As
These authors equally contributed to this work.
yTo whom the correspondence should be made.arXiv:2304.09617v1  [cs.RO]  19 Apr 2023Sensing
systems
Precision
agriculture
machinery/robots
data
processing unit
Precision AgricultureSelective Harvesting RobotsSpraying  robots  (pesticide, herbicide,
chemicals).
Weeding  and hoving  robots
Sensing RobotsSensors on end-
effectorOff-board sensors
network
Sensors on
manipulatorSensors on
manipulatorFruit detection, localization,
weght/quality estimation
Navigation Obstacle map
Manipulator(s) End-ef fector(s)
Mobile robot Collection moduleControl unitOn-board
computer(s)HMI module
Selective
Harvesting RobotsAgir-robotsFigure 1: Precision agriculture (left); robotic systems for precision agriculture (middle); and a general
conguration of SHRs.
of 2015, the global food system accounted for 34% of all greenhouse gas (GHG) emissions, with 71% of
these emissions coming from agriculture and land use (Crippa et al., 2021). Moreover, feeding the growing
global population with current agricultural and food production practices will be a signicant challenge by
2100, as the population is expected to grow by 27% (Nations, 2019). Therefore, developing sustainable
and innovative practices that reduce GHG emissions from agriculture and ensure food security for future
generations is critical. A drastic change in agricultural practises and in the usage of land and other required
resources is required to mitigate these.
Precision agriculture is a promising approach for optimizing the use of agricultural resources. By utilizing
a range of techniques to enhance the eciency of agricultural production, precision agriculture can increase
yields and reduce waste (Pierce and Nowak, 1999). Furthermore, it enables sustainable intensication by
improving yield without compromising ecosystem services (Milder et al., 2019). Precision agriculture has
been developing since the 1980s, with the adoption of technologies such as sensing technologies and GPS
(Mulla and Khosla, 2016). A key aspect of precision agriculture is the acquisition of data from a variety of
sensing technologies, including in-situ data collection and remote data collection from above, which enables
the assessment of spatial and temporal variability across a farm. Robotics plays an important role in precision
agriculture, with current technologies enabling the deployment of mobile grounded and aerial robots for a
variety of tasks, including agricultural monitoring, watering, harvesting, and weeding (see Fig. 1).
Selective harvesting is a critical and labour-intensive task in high-value crop production, as crops do not
ripen simultaneously. As a result, careful crop selection is required, making the task complex and demanding
skilled pickers. Unfortunately, this tedious job often causes disorders and health damage to labourers (M lotek
et al., 2015; Manninen et al., 1995). Selective harvesting is a signicant factor in high-value crops, such as
strawberries, that can put growers' investments at risk as it accounts for over 25% of total production costs.
Additionally, growers may face signicant nancial losses if planned picking labourers are unavailable, putting
immense pressure and stress on businesses. To address these challenges, robotic automation is increasingly
being adopted as a solution to labourer shortages in harvesting. Recent developments in selective harvesting
robots ( SHRs ) have shown promising results for harvesting high-value crops in greenhouses, orchards,
and indoor-outdoor environments. SHRs are complex systems that include various hardware and software
components. Figure 1 (right) presents the schematic of the SHR system. In general, SHR hardware includes
(1) manipulator arm(s) tted with a dedicated end eector on a (2) mobile platform traversing through
the crop environment, (3) on-board sensors, (4) computers and control units, and (5) collection units. The
collection unit may be a conveyor system that assists in handling harvested fruits to reach a designated
collection point. These components work together to enable the SHR to accurately identify and pick only
the ripe fruits while avoiding damaging the plant and leaving unripe fruits for future harvesting.Autonomous navigation, fruit perception, motion planning, and control are among the key software com-
ponents of SHR. The harvesting process begins with the vision system detecting ripe fruit using various
perception algorithms. These algorithms aim to enhance the intelligence and eciency of SHR by automat-
ing the detection, localisation, orientation, and grading of fruits. However, challenges such as illumination,
occlusion, and fruit clustering can make it dicult to localise individual fruits and their picking points. Fur-
thermore, a wide range of fruit attributes, including colour, shape, size, and texture, can pose challenges for
automated fruit grading. Once the fruit is detected and the picking point is identied, the motion planner
drives the manipulator unit to the picking point to perform the harvest.
In this paper, we provide an extensive review of the latest advancements in robotic systems and algorithms
employed for selective harvesting, with a focus on (i) selective harvesting hardware, (ii) perception, (iii)
motion planning, and (iv) control. Additionally, we highlight several key challenges that need to be addressed
to develop a reliable and robust SHR system.
2 Selective Harvesting Robot Hardware
This section provides a comprehensive discussion on the hardware components that are crucial for a successful
SHR system, including manipulator arm(s), end eector(s), mobile platform, fruit transport system, onboard
sensors, actuator drives, onboard computers/controllers, and power sources. We present a detailed overview
of the state-of-the-art SHRs, highlighting the key features and advantages of each hardware unit.
2.1 Manipulator Arm(s)
Robotic manipulators are the key components of SHRs that interact with crops during harvesting. These
manipulators are equipped with specialised end eectors or tools for selectively picking the target crop.
The congurations of selective harvesting manipulators vary, including Cartesian, spherical, cylindrical, or
articulated serial arms. Depending on the specic harvesting requirements, they may be arranged in a single,
dual, or multiple-arm conguration.
Selective harvesting tasks have been performed using both o-the-shelf and custom-made robotic manipu-
lators. While o-the-shelf manipulators oer reliable functionality, custom-made manipulators are gaining
greater emphasis due to their ability to meet specic harvesting requirements. Table 1 provides details of
the robotic manipulators used in various harvesting robotic systems. Among o-the-shelf manipulators, 6
degrees of freedom (DOF) manipulators have been widely used. These manipulators can have additional
DOFs added or removed to meet the selective harvesting requirements. For example, Xiong et al. (2019)
used a 6-DOF o-the-shelf manipulator to harvest strawberries, xing one DOF during operation to meet
the selective harvesting orientation requirements.
Multiple-arm robots have been developed to address the complexity of selective harvesting. In particular,
dual-arm manipulators have been employed to work collaboratively or as stand-alone units. (Sep uLveda
et al., 2020) used a dual robotic arm to harvest eggplants cooperatively, with successful results in managing
occluded fruit conditions. (Zhao et al., 2016b) used a dual-arm robot for tomato harvesting, in which
one arm detaches a tomato from its stem while the other arm grips it. (Davidson et al., 2017) utilised
a dual-arm mechanism for an apple harvesting robot in which a 6-DOFs apple picker was assisted by a
2-DOFs catching mechanism, reducing the harvesting cycle time. Other dual-arm congurations were also
presented in (Armada et al., 2005; Plebe and Grasso, 2001; Ceres et al., 1998; Xiong et al., 2020b) to speed
up the harvesting cycle. The autonomous kiwi-harvesting robot (Scarfe et al., 2009) uses four robots in
parallel; some of these arms and congurations are shown in Figure 2. Table 1 shows an overview of dierent
manipulators used for selective harvesting.
To eectively harvest crops, the manipulator needs to travel to dierent heights or depths for individual crops.(a)
 (b)
 (c)
(d)
 (e)
Figure 2: Dierent congurations of manipulators: (a). articulated arm(Qingchun et al., 2012) (b). Cylin-
drical arm(Hayashi et al., 2010) (c). Cartesian arm(Reed et al., 2001) (d). Dual-articulated arm(Ling et al.,
2019) (e). Multiple articulated arm(Scarfe et al., 2009)
Therefore, manipulators are usually mounted on a mobile base with provisions such as vertical slides (Zhao
et al., 2016b; Lehnert et al., 2017), horizontal slides (Davidson et al., 2017; Silwal et al., 2017; Van Henten
et al., 2002), slanting slides (Armada et al., 2005), and scissor lift mechanisms (Arad et al., 2020; Feng et al.,
2018) to enhance the manipulator's reach. In some cases, manipulators are mounted on forklift vehicles for
orchard harvesting (Lee and Rosa, 2006). Figure 3 illustrates the workspace enhancement arrangements used
in various SHR systems. In addition to conventional rigid mechanisms, soft and continuum mechanisms have
been explored for manipulation tasks in harvesting. For instance, researchers have developed an elephant
trunk-inspired mechanism (Tiefeng et al., 2015) and a combination of rigid and soft mechanisms (Chowdhary
et al., 2019). These approaches have the potential to overcome the limitations in the dexterity of rigid
mechanisms when used for harvesting.Table 1: Manipulator mechanism used for selective harvesting. O/Name - o-the-shelf manipulator/Model, C - Custom manipulator, DOF - degree of
freedom, AC-Articulated/Jointed arm conguration, CY- Cylindrical arm conguration, CR- Cartesian arm conguration, SP- Spherical arm conguration, DA-
Dual arm mechanism, MA(#n)- Multiple arm conguration and the value in the bracket shows the number of arms, '-' - Not evident from the source, '?'-
Uncertainty on the information from a source, E-Electric, P-Pneumatic, H-Hydraulic.
Crop Manipulator Arm Total Arm Arm Ref
DOFs conguration actuation
Pepper O/Fanuc LR Mate 200iD 7 AC E (Arad et al., 2020)
O/Universal Robotics - UR5 7 AC E (Lehnert et al., 2017)
C 9 AC E (Bac et al., 2017)(Baur et al., 2012)
Custom - - E (Kitamura and Oka, 2005)
Eggplant O/- 5 AC E (Hayashi et al., 2002)(Shigehiko et al., 2001)
O/Kinova Mico 6+6 (DA) AC E (Sep uLveda et al., 2020)
Tomato O/Universal Robotics - UR5 6 AC E (Yaguchi et al., 2016)
- 4 AC E (Lili et al., 2017)
- 4 AC E (Qingchun et al., 2014)(Feng et al., 2015)
O/Denso VS-6556G 8 AC E (Feng et al., 2018)
C 3+3 (DA) CR E (Zhao et al., 2016b)(Ling et al., 2019)
O/- 6 AC E (Yasukawa et al., 2017)
Strawberry C 3 CY E (Hayashi et al., 2010)(Shiigi et al., 2008)(Rajendra et al., 2009)
C 3 CY E (Hayashi et al., 2014)
C 4 CR E (Han et al., 2012)
O/Denso VS-6556G 6 AC E (Feng et al., 2012)(Qingchun et al., 2012)
C 4 CR E (Arima et al., 2004)
O/Mitsubishi RV-2AJ 6 AC E (Xiong et al., 2019b)(Xiong et al., 2018b)
C 3+3 (DA) CR E (Xiong et al., 2020b)
O/- - AC E (Yamamoto et al., 2014)(Yamamoto et al., 2007)
C 4 CR E? (Cui et al., 2013)(Feng et al., 2008)
C 5 SP E? (Kondo et al., 1998)
C 6 AC E (Yu et al., 2020)
Apple C 5 AC E (De-An et al., 2011)
C 7 AC E (Silwal et al., 2017)
C (8+2) (DA) AC E (Davidson et al., 2017)
O/Panasonic VR006L 7 AC E (Baeten et al., 2008)
Cucumber O/Mitsubishi RV-E2 7 AC E (Van Henten et al., 2002)(Van Henten et al., 2006)(Van Henten et al., 2003b)
C 6 AC E (Tang et al., 2009)
C? 7 SP E? (Arima, 1999)
Litchi O/- 7 AC E (Li et al., 2020)
O/- 6 AC E (Xiong et al., 2018a)
Mushroom C 3 CR E (Reed et al., 2001)
Grapes C 5 SP E? (Monta et al., 1995)
Kiwi C 3? (MA#4) AC E (Scarfe et al., 2009)
Palm C? 5 AC H? (Jayaselan et al., 2012)
Orange C 4 CR P+H (Lee and Rosa, 2006)
C 3(DA) CR P+E (Armada et al., 2005)
C 3(DA) Telescopic? E (Plebe and Grasso, 2001)
C 4(DA) AC E (Ceres et al., 1998)
C 3 SP H (Harrell et al., 1990)
O/Robotics Research Model 1207 7 AC E (Hannan and Burks, 2004)(a)
 (b)
 (c)
(d)
 (e)
Figure 3: Work envelope enhancing arrangements: (a). Vertical slide(Lehnert et al., 2017) (b). Slanting
slide(Armada et al., 2005) (c). Horizontal slide(Van Henten et al., 2002) (d). Scissor mechanism(Arad et al.,
2020) (e). Fork lift(Lee and Rosa, 2006).
2.2 End eector(s)
An end eector ( EE) is a tool attached to the wrist of a robotic manipulator to harvest the fruit, either
by grasping or gripping the fruit or its peduncle (attachment), detaching it from the parent plant, and
eventually delivering it to storage.
Various actions performed by the EEs and the corresponding technologies used for executing them are pre-
sented in Table 2. These EEs perform individual actions either simultaneously (e.g., gripping and detaching)
or sequentially (gripping/grasping followed by detaching) to accomplish a successful harvesting operation.
The attachment function involves gripping or grasping the fruit or its peduncle, where gripping is a 1-DOF
action performed using a vacuum or an open-close mechanism while grasping uses multiple DOFs mecha-
nisms to adapt to the shape of the fruit to be handled (Davidson et al., 2020). When nger mechanisms
made of hard materials are used for gripping or grasping operations, the surface of the ngers in contact
with the fruit is cushioned with a soft layer, such as urethane, to prevent any damage or bruising (Hayashi
et al., 2010; Hayashi et al., 2014; Feng et al., 2012; Silwal et al., 2017).
Blades are the primary means of cutting the peduncle during harvesting. The robot may use dierent
blade congurations and movements, such as scissors, parallel, oscillating, or rotatory motion to perform
the cutting action. In addition to blade-based cutting, twisting or pulling actions can also detach the fruit
from its peduncles. Thermal cutting has also been employed for detaching action, which utilises a heated
wire to cut the peduncle (Van Henten et al., 2002). Thermal-based cutting can stop the spread of infection(a)
 (b)
 (c)
 (d)
(e)
 (f)
 (g)
(h)
 (i)
 (j)
 (k)
(l)
 (m)
 (n)
Figure 4: end eector technology and fruit transport methods: (a) Gripping with vacuum cup, (b) Gripping
using air-oat (Feng et al., 2015), (c) Gripping by mechanical ngers (Xiong et al., 2018a), (d) Grasping
by soft mechanical ngers (Hayashi et al., 2002), (e) Thermal-based cutting (Van Henten et al., 2002), (f)
Cutting by oscillating blade (Lehnert et al., 2017), (g) Cutting by scissor action of blade (Bac et al., 2017),
(h) Cutting with parallel blades (Hayashi et al., 2010), (i) Cutting with rotary blade (Zhao et al., 2016b),
(j) Detachment by spinning action of wrist (Yaguchi et al., 2016), (k) Fruit catching ngers (Arad et al.,
2020), (l) Fruit catching cup with provision for fruit transfer through tube (Davidson et al., 2017), (m) End
eector with storage provision (Xiong et al., 2020b); (n) Robofruits' end eector with 2.5 DOF for cluster
manipulation (Parsa et al., 2023).across dierent plants (Feng et al., 2012) and improve the shelf life of the fruit (Van Henten et al., 2002).
Certain EE mechanisms were designed to swallow the target fruit during detaching (Xiong et al., 2019b;
Xiong et al., 2020b; Qingchun et al., 2014; Arima et al., 2004; Kondo et al., 1998), which helps the robot
deal with uncertainty regarding the orientation of the fruits during harvesting.
Manipulator units with multiple arms operate collaboratively or as stand-alone units. In a dual-arm manip-
ulator for tomato harvesting, as reported by (Ling et al., 2019; Zhao et al., 2016b), the cutter and gripping
end eectors were placed separately on each arm for the collaborative harvesting approach. However, in the
case of multiple-arm robots that are supposed to operate in non-collaborative ways, they have independent
end eectors attached to the arm for simultaneous harvesting actions (Armada et al., 2005; Scarfe et al.,
2009).
Once the detaching operation is completed, the end eector holds the fruit until it is intentionally dropped
or safely placed at a designated location. Certain end eectors feature nger arrangements to facilitate the
catching of the fruit when it is dropped after detachment. For example, (Arad et al., 2020) designed an end
eector for a sweet pepper-harvesting robot with a soft plastic-coated six-nger metallic arrangement imme-
diately below the cutting blade assembly that receives the fruit after detachment. (Davidson et al., 2017)
proposed a catching mechanism for an apple-harvesting robot to handle harvested apples. This approach
uses a two-degree-of-freedom secondary mechanism with a funnel-like catching end eector that moves to the
dropping position to catch the apple as when the primary picking manipulator drops the harvested apple.
This pick-and-catch approach was shown to be superior to conventional pick-and-place approaches, resulting
in a 50% reduction in harvesting cycle time. Representative images of end eectors demonstrating various
types of fruit attachment and detachment methodologies are shown in gure 4(a)-(j).
When the robot harvests crops that grow in clusters (such as strawberries), it must manipulate the clusters to
reach the target fruit. The Robofruits' EE has 1 DOF mechanism for pushing away the occluding strawberries
away from ripe strawberries to be picked (Parsa et al., 2023) (gure 4 (n)). Other end eectors have also
been reported to perform cluster manipulation. One end eector uses a direct pushing and parting action
with its body to deect the neighbouring/adjoining fruits around the targeted fruit (Xiong et al., 2020a).
The other uses a set of air nozzles that ush air streams to deect adjoining fruits (Yamamoto et al., 2014).
2.3 Fruit Collection System
After detaching the fruits, various methodologies have been reported for fruit transfer. For example, the
robot places the fruit in a bin on a mobile robot (Arad et al., 2020; Qingchun et al., 2014; Hayashi et al.,
2010). In some cases, it uses a conveyor system to move the harvested fruit to the storage area(Armada et al.,
2005; Reed et al., 2001) from the drop location and also to circulate the empty tray to the drop location once
the current tray lls up (Hayashi et al., 2010; Hayashi et al., 2014). Flexible tubing was also used in addition
to the conveyor system. This exible tube can be an integral attachment to the end eector, through which
the detached fruit directly falls into the storage chamber (Arima et al., 2004). Sometimes, with a certain
manipulation eort, the end eector drops the fruits into the specied dropping location from where the
fruit enters the opening of the tubing (De-An et al., 2011). In addition to these transport mechanisms, end
eectors were provided with storage bins as direct attachments. The end eector proposed by (Xiong et al.,
2020b) for a strawberry harvesting robot has provisions for attaching the market punnet to it so that the
harvested strawberry falls directly into the punnet. These fruit transport methods are shown in gure 4
(k)-(m).
2.4 Mobile Platform
Harvesting robots must be mobile to reach crops grown in various patterns in their growth environment. The
mobile platforms used for this purpose have employed dierent locomotion methods such as four-wheeled
dierential drive (Lehnert et al., 2017; Feng et al., 2012), four-wheel independent drive and steering (XiongTable 2: end eector functionalities; (P - pneumatic actuation, E - Electric actuation, NA - not applicable,
? - uncertainty on information from source)
Functions Action Technique Actuation Document
Attachment Grip Suction P(Hayashi et al., 2010)(Feng et al., 2012)(Arima et al., 2004)
(Yamamoto et al., 2014)(Baeten et al., 2008)(Reed et al., 2001)
(Zhao et al., 2016b)(Lehnert et al., 2017)
(Bac et al., 2017)(Hayashi et al., 2002)(Van Henten et al., 2002)
Mechanical ngers E (Yaguchi et al., 2016)(Han et al., 2012)(Xiong et al., 2018a)
P (Hayashi et al., 2010)(Feng et al., 2012)(Hannan and Burks, 2004)
Air oats P (Feng et al., 2015)
Grasp Mechanical ngers E (Silwal et al., 2017)
P (Bac et al., 2017)(Hayashi et al., 2002)
Detachment Cutting Thermal cutting E- heated wire (Feng et al., 2012)(Van Henten et al., 2002)
Oscillating blade motion E (Arad et al., 2020)(Lehnert et al., 2017)
Scissor type blade motion E (Xiong et al., 2019b)(Kitamura and Oka, 2005)(Han et al., 2012)
P(Armada et al., 2005)(Bac et al., 2017)?
(Hayashi et al., 2002)(Feng et al., 2018)
(Feng et al., 2008)(Lee and Rosa, 2006)
Parallel blade motion E (Yu et al., 2020)?
P (Hayashi et al., 2010)(Hayashi et al., 2014)
Rotary/spinning blade motion E (Zhao et al., 2016b)(Arima et al., 2004)(Xiong et al., 2018a)(De-An et al., 2011)
end eector or arm spin/
deection (without blades)E(Davidson et al., 2017)(Yaguchi et al., 2016)(Feng et al., 2015)
(Silwal et al., 2017; Baeten et al., 2008)
Fruit transport Catching Mechanical ngers NA (Arad et al., 2020)
Cup NA (Davidson et al., 2017)
Storage Provisions for attaching punnets NA (Xiong et al., 2020b)
Provisions for fruit
transport to storageNA (Davidson et al., 2017)(Arima et al., 2004)
Cluster
manipulationPushing and partingDirect contact on fruits
with the EENA (Xiong et al., 2020a)
DeectingDirect contact on fruits
with an attachment on EEE (Parsa et al., 2023)
Pushing Air nozzles P (Yamamoto et al., 2014)
et al., 2019b; Lili et al., 2017), crawler type (Hayashi et al., 2002; De-An et al., 2011; Monta et al., 1995),
or rail carriages (Zhao et al., 2016b; Feng et al., 2015; Parsa et al., 2023; Feng et al., 2018; Yasukawa
et al., 2017; Hayashi et al., 2010) utilising heating pipes running through the rows of greenhouses. In
orchards, mobile platforms can also include human-driven vehicles such as tractors, forklifts, and other
utility vehicles (Armada et al., 2005; Silwal et al., 2017; Baeten et al., 2008; Jayaselan et al., 2012; Lee and
Rosa, 2006). These mobile platforms are either o-the-shelf or custom-made according to specic needs.
However, when the mobile platform positions itself for the harvesting process, the varying dynamic load
acting on it due to manipulation can aect its stability on the ground. As a result, certain stabilising
mechanisms have been reported as an integral part of this mobile platforms (Baeten et al., 2008; Van Henten
et al., 2002). O-the-shelf mobile platforms like Thorvald II (Xiong et al., 2019b; Xiong et al., 2020b; Xiong
et al., 2018b), and Qii-Drive AGV (Arad et al., 2020) have also been used for this purpose.
Arima et al. (Arima et al., 2004) developed a unique sliding system that moves a suspended manipulator
under the strawberry planting bed for harvesting the strawberries. For indoor-grown crops such as mush-
rooms, a Cartesian conguration is used where the robotic system covers the entire length and width of the
mushroom growing bed for harvesting(Reed et al., 2001). In contrast to using a mobile robot, (Yamamoto
et al., 2014) investigated a stationary manipulator unit, where the crop table moves on rails in front of the
manipulator during the harvesting operation. Some of the mobile platforms mentioned in this section are
shown in gure 5.
2.5 Sensors
The sensory system of SHR incorporates both external and internal sensors. External sensors are primarily
used for fruit identication, localisation, and environment perception to facilitate robot navigation. On
the other hand, internal sensors monitor the performance of individual subsystems like manipulators, end(a)
 (b)
Panda 
Robot Arm
containerPicking Head
 (c)
(d)
 (e)
(f)
Figure 5: Mobile base type: (a) Four-wheeled dierential drive platform (Qingchun et al., 2012); (b) four-
wheeled independent drive and steering platform (Xiong et al., 2019b); (c) railed platform (Parsa et al.,
2023); (d) crawler platform (De-An et al., 2011); (e) electric human-driven platform (Silwal et al., 2017); (f)
Robot mounted on planting bench (Arima et al., 2004).
eectors, and mobile platforms. However, during our review of various SHRs, we observed that less attention
was given to reporting the other sensors that support manipulation, navigation, and other functions, besides
the integrated vision systems and the sensors mounted on end eectors. In order to position and orient its
end eector for successful attachment and detachment of fruit, a manipulator's integrated vision system must
primarily detect the spatial description of ripe fruit on the plant. This is a challenging task, particularly
when ripe fruits are occluded by leaves, stems, or clusters of fruits. Additionally, factors such as color,
size, and shape vary from fruit to fruit, and the vision system and algorithm must be calibrated and tuned
accordingly. Peduncle detection and position-orientation mapping are also necessary. Tang et al. (Tang(a)
 (b)
 (c)
(d)
 (e)
Figure 6: Camera placements: (a). On end eector(Hayashi et al., 2002) (b). On manipulator el-
bow(Qingchun et al., 2012) (c). On vertical frame(Xiong et al., 2019b) (d). On a horizontal slider(Van Henten
et al., 2002) (e). On a vertical slider(Qingchun et al., 2014)
et al., 2020) have reported that harvesting robots use binocular vision, laser vision, Kinect, multi-spectral,
or other visual sensors for detecting and localizing fruits. In the robots we reviewed, single or multiple vision
sensors were used to scan the scene and detect ripe fruits. The camera(s) were generally placed on or near
the end eector (Arad et al., 2020; Bac et al., 2017; Hayashi et al., 2002; Hayashi et al., 2010; Han et al.,
2012; Yu et al., 2020; Xiong et al., 2018a; Monta et al., 1995), on the manipulator links (Lili et al., 2017;
Feng et al., 2018; Feng et al., 2012), or in elevated positions (Xiong et al., 2019b; Zhao et al., 2016b; Xiong
et al., 2020b; Feng et al., 2015; Xiong et al., 2018b; Yamamoto et al., 2014; Li et al., 2020). Some robots use
a combination of these camera congurations (Cui et al., 2013). In some cases, the primary or additional
cameras were equipped with a separate motion mechanism to increase their scanning freedom (Bac et al.,
2017; Kitamura and Oka, 2005; Van Henten et al., 2002). Fig. 6 shows various camera placements for SHR.
However, other than the integrated vision systems and the sensors mounted on end eectors reports we
reviewed do not well present other sensors that support manipulation, navigation, and other functionalities
in the SHRs.
In order to achieve eective scanning and detection, external illumination sources such as LED units (Arad
et al., 2020; Hayashi et al., 2010; Hayashi et al., 2014; Yamamoto et al., 2014), uorescent units (Cui et al.,
2013), or combinations of LED and halogen units (Bac et al., 2017) have been utilised to properly illuminate
the scene. While conventional cameras have been commonly used for fruit identication and localisation,
Ceres R et al. (Ceres et al., 1998) used a laser range nder to locate ripe fruit on trees based on human
input. In certain cases, ultrasound sensors have been employed in conjunction with cameras to obtain
distance information of the target fruit(Jayaselan et al., 2012; Harrell et al., 1990; Hannan and Burks, 2004).
Apart from vision-based sensors, end eectors were also equipped with various other sensors such as pho-toelectric sensors, IR sensors, micro-switches, pressure/vacuum sensors, or their combinations to improve
harvesting accuracy. Table 3 provides a summary of the dierent sensory units used in the reviewed robots.
2.6 Other Hardware
Most manipulator mechanisms employed in selective harvesting utilise electric actuation systems, as shown
in Table 1. However, in cases where harvesting operations are performed at higher levels and must handle
heavier payloads, uid power (Jayaselan et al., 2012)(Lee and Rosa, 2006) or a combination of uid power
and electric actuation (Armada et al., 2005) were utilised. O-the-shelf manipulators commonly used servo
AC/DC motor systems in harvesting operations (Xiong et al., 2019b; Van Henten et al., 2002; Hannan
and Burks, 2004), while custom-built manipulators used servo motors (Baur et al., 2012; Yu et al., 2020;
Silwal et al., 2017), stepper motors (Scarfe et al., 2009), and cylinders for actuation (Jayaselan et al., 2012;
Lee and Rosa, 2006). For end eectors (as shown in Table 2), electric motors and pneumatic actuators
were primarily used for various grip, grasp, and cutting mechanisms. The articles reviewed did not provide
detailed specications for the actuators used. Other necessary hardware includes drives, electronic circuitry,
hardware interfaces, onboard computers/controllers, HMIs, and power sources. While the articles reviewed
did not emphasise these details, a representative general outline is presented.
In order to handle the computational demands of perception, motion planning, and control, onboard com-
puters were commonly used as controllers in robotic harvesting systems (Xiong et al., 2020b; Arad et al.,
2020)(Hayashi et al., 2002; Lili et al., 2017; Yasukawa et al., 2017; Xiong et al., 2018b; Li et al., 2020).
To perform low-level control functions, separate controllers were sometimes used (Arad et al., 2020; Ling
et al., 2019). Several harvesting systems included dedicated GUI or HMI interfaces to allow operators to
interact with the system (Lili et al., 2017; Ling et al., 2019; Han et al., 2012; Baeten et al., 2008; Jayaselan
et al., 2012). In terms of powering the various hardware units, robotic systems were reported to use battery
power (Arad et al., 2020; Lehnert et al., 2017), generators (Silwal et al., 2017; Baeten et al., 2008; Harrell
et al., 1990), and AC power lines (Van Henten et al., 2002).
3 Fruit Perception
In this study, two major categories of articles have been reviewed: 1) fruit detection and localisation, and
2) fruit grading. The reviewed works are presented in Table 4 and Table 5, highlighting their contributions,
novelties, and shortcomings related to fruit detection and fruit quality estimation.
Various approaches have been proposed for fruit detection and localisation using vision sensing. These
range from classical morphological operations to state-of-the-art Convolutional Neural Networks (CNNs).
Classical methods include morphology, colour-based, thresholding, and geometrical approaches. In recent
years, Deep Learning (DL)-based approaches have been used to achieve state-of-the-art results. For instance,
pre-trained CNN networks have been used for fruit detection, while mask R-CNNs have been used for pixel-
wise segmentation of fruit pixels, leading to high accuracy in fruit detection and localisation. Additionally,
some researchers have used information extracted from RCNN for better estimation of picking points. In
this section, we rst analyse the classical approaches and then review the DL-based approaches.Table 3: Sensory Unit; (Model name of the sensors are included wherever available and written after a '/', (#n) along with a sensor represents the
number of such sensors used, '-' means information unavailable from the source, '?' - uncertainty on the information from source)
Crop Sensors for fruit detection Navigation Sensors on end eector for eective Other sensors Ref
and localisation sensors fruit attachment and detachment
Pepper RGB-D camera/Fotonic F80 - - - (Arad et al., 2020)
Pepper RGB-D camera/Intel Realsense SR300 Laser scanner Pressure sensor - (Lehnert et al., 2017)
Pepper Colour camera/VRmMS-12, Position sensor Encoder &,
Mini ToF camera/Camoard nano; - Vacuum sensor Limit switch (per arm joints) (Bac et al., 2017)(Baur et al., 2012)
Color camera(#2)/Prossilica GC2450C,
ToF camera/SR4000
Pepper CCD camera(#2)/RF Systems - - Potentiometer (Kitamura and Oka, 2005)
Eggplant CCD camera - Microswitch - (Hayashi et al., 2002)(Shigehiko et al., 2001)
Photoelectric sensor
Eggplant Color camera/Prossilica GC2450C, - - - (Sep uLveda et al., 2020)
ToF Camera/SR4000
Tomato PlayStation camera - - - (Yaguchi et al., 2016)
Tomato Stereo Vision camera/GS3 U3-15S5C Laser scanner/LMS151 - - (Lili et al., 2017)
Tomato CCD camera/FL3-U3-13S2C-CS - - Encoder (Qingchun et al., 2014)(Feng et al., 2015)
with laser generator
Tomato Stereo vision camera with laser generator - - - (Feng et al., 2018)
Tomato Stereo vision camera/Bumblebee2 - - - (Zhao et al., 2016b)(Ling et al., 2019)
Tomato Kinect V2, USB camera - - - (Yasukawa et al., 2017)
Strawberry CCD camera(#3) - Photoelectric sensor - (Hayashi et al., 2010)(Shiigi et al., 2008)(Rajendra et al., 2009)
Strawberry CCD camera(#3) - Photoelectric sensor - (Hayashi et al., 2014)
Strawberry CCD camera(#3)/STC-620 - - - (Han et al., 2012)
with laser range nder/S80L-Y
Strawberry Binocular camera/Bumblebee2 Sonar sensor, Camera - - (Feng et al., 2012)(Qingchun et al., 2012)
Strawberry CCD camera - Photo-interrupter (#3 pairs) - (Arima et al., 2004)
Limit switch
Strawberry RGB-D camera/Intel R200 - IR sensor(#3)/TRCT5000 - (Xiong et al., 2019b)(Xiong et al., 2018b)
Strawberry RGB-D camera/Intel R200 LIDAR/Hokuyo IR sensor(#3)/TRCT5000 Proximity sensor/PL-05N/2 (Xiong et al., 2020b)
IMU/Xsens Mti-30
Strawberry Position & Colour measurement unit/? - Air pressure sensor - (Yamamoto et al., 2014)(Yamamoto et al., 2007)
Strawberry CCD camera/Sony DXC-151A - Fiber optic sensor - (Cui et al., 2013)(Feng et al., 2008)
CCD camera/ELM O EC-202 II Limit switch
Strawberry CCD camera - Photo-interrupters(#3 pairs) Tacho-generator & (Kondo et al., 1998)
Encoder (per arm joints)
Strawberry USB camera - Laser sensor(#1 pair) - (Yu et al., 2020)
Apple CCD camera GPS Collision sensor(#1 pair) Hall eect sensor(#8)
Photo-electric position sensor(#2 pairs) Micro-switches(#5) (De-An et al., 2011)
Pressure sensor
Apple CCD camera/Prosilica GC1290C, - - - (Silwal et al., 2017)
ToF camera/Camcube 3.0
Apple CCD camera/Prosilica GC1290C? - - - (Davidson et al., 2017)
ToF camera/Camcube 3.0?
Apple Camera/UI2230-C uEye - - Level sensors(#2) (Baeten et al., 2008)
Cucumber CCD camera(#2) - - Encoder (per arm joints) (Van Henten et al., 2002)(Van Henten et al., 2006)(Van Henten et al., 2003b)
Cucumber - - - Limit sensor(#12) (Tang et al., 2009)
Cucumber Custom 2-wavelength visual sensor - - - (Arima, 1999)
Litchi Kinect V2.0 - - - (Li et al., 2020)
Litchi CCD camera(#2)/DH HV3100FC - - - (Xiong et al., 2018a)
Mushroom Panasonic camera CD 20B - - Linear encoder (Reed et al., 2001)
Grape Camera/- - - - (Monta et al., 1995)
Kiwi Webcam(#8) - - - (Scarfe et al., 2009)
Palm Webcam with ultrasound sensor - - - (Jayaselan et al., 2012)
Orange Camera/- GPS, Encoders Proximity switch - (Armada et al., 2005)
Orange Stereo vision camera(#2)? - - - (Plebe and Grasso, 2001)
Orange Laser telemetry - Pressure sensor Encoder (Ceres et al., 1998)
IR sensor(#2) Limit switch
Orange CCD video camera - - Potentiometer & (Harrell et al., 1990)
with ultrasound sensor Tachogenerator (per arm joints)
Orange Camera/Sony FCB-EX780S - - - (Hannan and Burks, 2004)
with ultrasound sensor(#1 pair)Table 4: Summary of fruit detection and localisation methods, Type Keys: C: Colour-based, G: Geometry-based, CV: Classic Computer Vision-based,
DL: Deep Learning-based, ML: Machine Learning-based.
Type Contribution Sensor Novelty Shortcoming Ref
DL, C Spherical fruit localisation Stereo camera colour clustering, edge detection, Neural mapping Stereo matchingFruit radius calculated may not work for other
varieties(Plebe and Grasso, 2001)
C, G Strawberry Peduncle recognition Stereo cameraStereo image based depth calculation, Colour-based maturity,
geometry based peduncle localisationPeduncle detection threshold- based,
Fails in many scenarios(Rajendra et al., 2009)
C, G Evaluation of strawberry picking robot CCD colour Colour-based detection, geometry-based localisationGeometric assumption of peduncle inclination
may not work in cluster scenario(Hayashi et al., 2010)
C, CVRecognition and localisation
of ripen tomatoRGB CameraRemoving background in RGB colour space; extract using combination
of RGB, HSI, YIQ spaces; morphological processing for localisationMorphological operation prone to
background noise, illumination(Are et al., 2011)
ML, CRecognition and localisation
of ripe appleCCD colour cameraVector median lter and colour based feature representation; SVM
based classication algorithm; Colour based feature extracted
through histogram and thresholdingColour based method prone to noise,
illumination(De-An et al., 2011)
CV Localisation of LitchiTwo CCD RGB Xian
MicrovisionEdge-detection and Hough transformation-based localisation;
Alabel template-based matching algorithm was proposed for
unstructured environmentsSingle template with thresholding may not be
generalisable(Wang et al., 2016)
CV Fruit DetectionTwo AVTManta cameras;
1292x964Watershed Based Segmentation;Tinocular Stereo Triangulation
Based Segmentation; Cascade classier model using AdaBoost
with local binary patternsCannot outline the berry for ripping, cluster
separation can be improved(Puttemans et al., 2016)
DL Fruit detection RGB and NIR Bounding box detection using FRCNN and RGB, IR image fusion No Harvesting (Sa et al., 2016)
DL Fruit Counting Synthetic ImagesModied Inception-ResNet for training on synthetic images;
Inference on real imagesNo harvesting (Rahnemoonfar and Sheppard, 2017)
C, G, ML 3D localisation of apple for picking Kinect V2novel 3d colour and geometric feature-based descriptor to
extract feature from point cloud and classify through GA-SVMOccluded apples could not be grasped (Tao and Zhou, 2017)
C, G, CV Strawberry Picking point detection ColourMorphology/Colour based detection,geometry-based picking
point localisationDetection method prone to noise,
background illumination(Huang et al., 2017)
CV Fruit image segmentation Colour Wavelet decomposition, Retinex- based image segmentation Fruit segmentation contains holes (Wang et al., 2017a)
C, CVStrawberry esh and calyx
segmentationBasleravA1900-50g RGB
1920 x 1080Colour-based segmentation, CCL algorithmColour segmentation prone to background
noise and illumination(Durand-Petiteville et al., 2017)
CV Detection and Localisation of Apple CCD Colour cameraCircular Hough Transformation for clearly visible apples and Blob
Analysis in iterative fashion to detect occluded applesObstacle detection not included (Silwal et al., 2017)
C, CVSweet pepper detection and
localisationRGB-D sr300Colour-based segmentation and 3D parametric model-tting
for localisationLower detachment rate with dierent cultivar (Lehnert et al., 2017)
ML, G Dynamic Litchi cluster detection 2 CCD cameraFuzzy clustering method based segmentation, geometry-based
Litchi ttingError in Depth Perception can be improved
DLCNN-based strawberry detection
systemRGB 1080x1920CNN optimisation through input compression, image tiling,
color masking, network compressionCNN network used us very basic (Xiong et al., 2018a)
DLCitrus picking using RCNN/YOLO
basedBB2-08S2M/08S2C60
binocularLabelling of leaves, branches and other occlusions help
increase accuracyNo harvesting method presented (Liu et al., 2018b)
DL, CV Robust fruit counting RGBCNN + Hungarian Algorithm + SfM- based method to calculate
relative 3d location ; count correction based on3D
localisation + size distribution estimatesNo harvesting method presented (Liu et al., 2018a)
DL Apple detection during 3 growth stage RGB; 3000x4000 Improved YOLO-V3 network processed by DenseNet method No harvesting method presented (Tian et al., 2019)
MLFruit detection using mobile
laser scannerLiDAR; 3D point cloud Reectance, DBSCAN + k-means based counting algorithm Holes in segmentation with DBSCAN (Gen e-Mola et al., 2019a)
DL, C Picking point localisation RGB; 30 cm Geometrical algorithm to calculate picking point from M-RCNN Ripeness based on discrete colours (Yu et al., 2019)
DL, CVStrawberry localisation and
environment perceptionRGB-DRCNN output based localisation through coordinate transformation,
density base point clustering and the proposed location approximation
method; safe region classication through Hough Transform based
algorithmImproper detection of unripe fruit (Ge et al., 2019b)
G, CVSegment strawberry instances;
classify ripenessReal-Sense200; 50 cm
to 70 cmdetect occluded fruit and recover actual sizes using
width to height ratioStrawberry assumed symmetric (Ge et al., 2019a)
DLMulti-modal Fuji Apple
detection and datasetKinect V2; 1m and 3m range 5-channel R-CNN based multi-modal fruit detection Performance drops under sunlight (Gen e-Mola et al., 2019b)
CV Picking point localisation RGB 640 * 480; 30-100 cmIterative retinex algorithms for illumination adjustment,
Otsu thresholding, Harris corner detector-based localisationMorphological operations prone to noise (Zhuang et al., 2019)
CV, DL Mango Fruit Load EstimationBasleracA2440-75um; Goyo
(GM10HR30518MCN)lensKalman Filter + Hungarian Algorithm + Mango Yolo;
lower complexity and cost solutionTested only with articial lighting (Wang et al., 2019)Type Contribution Sensor Novelty Shortcoming Ref
DL Tomato classication 2D cameraData visualisation using T-SNE; Data augmentation;
CNN-based classicationCNN architecture is very basic (Zhang et al., 2018)
DL Cucumber detection is greenhouse Canon EOS 760D Logical Green operator improves Mask RCNN performance Central point location may be improved (Liu et al., 2019)
DL RCNN-based RGB Camera RGB + HSV image input to RCNN improves performance No harvesting or picking point localisation (Ganesh et al., 2019)
DLRCNN-base strawberry
instance segmentationSamsung Galaxy S7
4032x30248000 annotated images, RCNN based segmentation Tested only with black background (P erez-Borrero et al., 2020)
CV, MLDetection of Litchi,Background
and twigKinectDeep-lab v3 based segmentation, morphological operation
for twig detection, RDBSCAN clustering and pca line-ttingSegmentation contains holes (Li et al., 2020)
DL Detection and 3D locationSfM point cloud;
2D imagesCombines 2D instance segmentation and SfM; Mask RCNN
detection projected onto 3D point clouds based on SfMCannot process in real-time (Gen e-Mola et al., 2020)
ML Strawberry classication Real-Sense D435Corrects deformed point clouds by fruit feature and depth
data integrationModel-tting method not clear (Ge et al., 2020b)
C, CVStrawberry detection and
localisationIntel R200 RGB-D Light intensity modelling and adaptive colour thresholding Prone to noise, background illumination (Xiong et al., 2020b)
DL, GStrawberry picking point
localisationUSB 640*480 RGBGeometry based picking point localisation based on YOLO
bounding boxNo cluster negotiation (Yu et al., 2020)
Table 5: Summary of fruit quality estimation methods. Type Keys: C: Colour-based, G: Geometry-based, CV: Classic Computer Vision-based, DL:
Deep Learning-based, ML: Machine Learning-based
Type Contribution Sensor Novelty Shortcoming Document
CV, CStem detection, ripeness
and fruit quality judgementTwo RGB camerasStrawberry detection with Blob algorithm, HSI
colour-based ripeness estimationColour-based method prone to illumination
and background noise(Feng et al., 2008)
CV, ML Strawberry grading system RGBShape extraction through Outs algorithm and
sharing line method, K-means clustering for gradationMorphological operations prone to noise,
k-means clustering has drawbacks(Liming and Yanchao, 2010)
CV, GStrawberry shape,size
estimation;classicationRGBKite properties, morphology and geometry-based
algorithm for gradingMorphological algorithm may not be robust (Oo and Aung, 2018)
MLRipeness evaluation of
strawberryRGBSpectral and texture features fusion for SVM
classicationMid-ripe samples miss-classied (Guo et al., 2016)
CV3d strawberry shape
completionRGBCompletion of partial 3D points based on optimal
hypothetical planeStrawberry assumed symmetric (Ge et al., 2020a)
C, CV On-tree fruit size estimation RGBAlgorithm involving Cascade detection with HoG,
Otsu's method, colour thresholding; fruit lineal
dimension calculation with depth information,
fruit image size and thin lens formulaColour thresholding not robust (Wang et al., 2017b)
CV, ML Mango grading RGBRFE-SVM maturity prediction, size in defect image
processing, Multi-Attribute decision systemThresholding not generalise-able (Nandi et al., 2014)
ML, DL Tomato quality evaluation RGBCombined statistical and texture feature based
classicationANN used is very basic (Arakeri et al., 2016)
DL Strawberry ripeness Spectral Camera Spectral feature selection with CNN for classication CNN architecture used is very basic (Gao et al., 2020)
C, CV Ripeness of strawberry ColourSegmentation algorithm using ellipsoid Hough
transform, HSV colour models and histogram
based features for classicationColour-based method prone to illumination
and background noise(Cho et al., 2019)
DLPear bruise detection
and classicationThermalThermal image and LeNet for classication;
eect of hot air on thermal image analysedCNN architecture is very old and basic (Zeng et al., 2020)
C, GStrawberry shape and
size estimationPanasonic WV-CP470Colour-based segmentation,Geometry-based
size estimationColour-based method prone to noise,
background illumination(Htet et al., 2020)3.1 Colour-based approaches
Fruits exhibit a variety of colours, which can be exploited for detecting them in an image. Classic approaches
for fruit detection have included colour-based segmentation, morphology, thresholding, and geometrical
techniques. For instance, Rajendra et al. (Rajendra et al., 2009) manually set the threshold for ripe
strawberries by converting the colour from RGB to HSI colour space, which separates intensity from colour,
making the approach more robust to illumination. However, manual thresholding can make the model
more prone to background noise. To overcome this, automatic thresholding algorithms, such as Otsu's
thresholding, can be used, as demonstrated by Zhuang et al. (Zhuang et al., 2019). Are et al. (Are et al.,
2011) used a combination of RGB, HSI, and YIQ colour spaces for colour-based segmentation to remove the
background and keep the fruit blob. In addition to colour, other features can be combined for a more robust
approach. Tao et al. (Tao and Zhou, 2017) used colour with geometric features for apple classication with
GA-SVM, while Lehnert et al. (Lehnert et al., 2017) used colour-based segmentation with 3D parametric
model-tting for localisation of sweet peppers. Zhuang et al. (Zhuang et al., 2019) attempted to improve
colour-based segmentation through an iterative Retinex algorithm followed by Otsu's thresholding. They
argue that this strategy enhances the lightness of litchi regions in weakly illuminated images while leaving
the lightness information unchanged in well-illuminated images.
3.2 Classic computer vision-based approaches
Morphological operations, which are a set of non-linear operations (e.g., erosion and dilation), are often
used to extract the shape or morphology of the fruit for harvesting. Morphological operations are normally
conducted on a binary image. The binary image is extracted from colour-based segmentation. Morphological
operations conducted on binary images result in a more rened extraction of the original fruit morphology.
Are et al. (Are et al., 2011) used the well-known watershed algorithm to extract the morphology of
tomatoes from binary images extracted through colour thresholding. In the watershed algorithm, the image
is rst binarized followed by erosion and dilation operations. The erosion operation helps to identify sure-
shot foreground pixels, whereas the dilation operation helps to identify sure-shot background pixels. This is
followed by distance transformation and thresholding, which identies the core of the fruits, separated from
other fruits. Then, with the help of a connected component algorithm, the boundary areas are established,
which helps to segment and image fruits. The connected component algorithm is used to identify similar
regions in an image and is also used for blob detection. Durand et al. (Durand-Petiteville et al., 2017) used
the connected component algorithm to identify strawberry blobs. Huang et al. (Huang et al., 2017) used
erosion and dilation operations to rene strawberries from the colour-segmented binary mask. Li et al. Li et
al. (Li et al., 2020) implemented morphological operations for twig detection to prune fruitless twigs for litchi
harvesting. First, images were segmented into berries and twigs with Deeplab v3 (Chen et al., 2018). This
provided twig pixels in grey but with holes, i.e., the twig pixels were not continuous. This was converted
into a grey-scale image, and a MATLAB-based morphology algorithm was used to extract the twigs.
In addition to fruit morphology, morphological operations can also be used for twig detection to prune
fruitless twigs for harvesting. For instance, Li et al. (Li et al., 2020) implemented morphological operations
for twig detection in litchi harvesting. First, they segmented images into berries and twigs with Deeplab
v3 (Chen et al., 2018), which provided twig pixels in grey but with holes, meaning the twig pixels were not
continuous. They then converted this to a grey-scale image and used a Matlab-based morphology algorithm
to extract the twigs.
3.3 Geometry-based approaches
In addition to fruit detection for selective harvesting, it is highly desirable to locate the stem and identify
other relevant parts for eective harvesting. One approach taken by existing research is to use the geometric
properties of fruits. Rajendra et al. (Rajendra et al., 2009) proposed diameter thresholding for peduncle
detection. However, a simple thresholding approach may be hard to generalise. Hayashi et al. (Hayashiet al., 2010) used the geometry of strawberries to calculate the peduncle angle with respect to the vertical
line for picking point localisation. Tao et al. (Tao and Zhou, 2017) used a parameterised query of the spatial
dierences between a point and its adjacent area to form a Fast Point Feature Histogram (FPFH) descriptor.
The FPFH descriptor formed a multidimensional histogram to describe the geometric properties within the
kneighbourhood of a point. According to Tao et al., this oered the advantages of rotation invariance and
good robustness under dierent sampling densities and adjacent noise levels. Xiong et al. (Xiong et al.,
2018a) considered Litchi clusters as a single large fruit, and the fruit area was marked with a minimum
bounding rectangle (MBR). The picking point was calculated as one-third above the top of the MBR and
in the centre third of the width, based on statistics of Litchi cluster geometry. Yu et al. (Yu et al., 2019)
rst used a Mask R-CNN to segment strawberry images and then used geometrical calculations to localise
the picking point. The authors used the two extreme points of a strawberry pixel to draw a horizontal line.
Then the fruit axis was calculated based on the similarity of regions that would be dividing the fruit axis.
The picking point was localised on the fruit axis based on statistics of strawberry shape.
3.4 Statistical approaches
Various statistical algorithms, including but not limited to SVM and AdaBoost, have been used for fruit
recognition and grading. These algorithms are not only used for classication or regression but also for tasks
such as dimensionality reduction and model tting. For instance, De et al. (De-An et al., 2011) showed that
the SVM method with radial basis function (RBF) kernel function based on both colour features and shape
features was found to be the best for apple recognition. Puttemans et al. (Puttemans et al., 2016) used a
cascade classier model using the AdaBoost algorithm with local binary patterns as feature descriptors. The
authors focused on gradient information by comparing regions of pixel intensities in the grey-scale image and
used histogram equalisation to account for varying lighting conditions. Tao et al. (Tao and Zhou, 2017) used
SVM classier with RBF kernel for Apple detection. They utilised a Genetic Algorithm (GA) for tuning the
SVM hyper-parameters. SVM has also been used for fruit grading, as in (Guo et al., 2016) where a fusion of
spectral and texture features was used to determine the ripeness of strawberries. Nandi et al. (Nandi et al.,
2014) used RFE-SVM for maturity prediction and defect processing of mangoes, and similarly, Lamb et al.
(Lamb and Chuah, 2018) used SVM for strawberry grading, where vision-based feature descriptors such as
SIFT, SURB, and ORB were extracted and used for classication.
3.5 Stochastic approaches
Stochastic algorithms are also used in selective harvesting. Plebe et al. (Plebe and Grasso, 2001) used
neural mapping for stereo matching. However, for selective harvesting, CNN and RCNN have primarily
been used for the detection and localisation of strawberries and other fruits. Lamb et al. (Lamb and Chuah,
2018) utilised CNN for strawberry detection, and optimised the network through techniques such as input
compression, image tiling, colour masking, and network compression. Liu et al. (Liu et al., 2018a) combined
CNN with depth data to calculate the relative 3D location of fruit. Zhang et al. (Zhang et al., 2018) used
CNN for tomato classication. For strawberry quality or ripeness detection, Gao et al. (Gao et al., 2020)
used spectral features with CNN, and for pear bruise detection based on thermal images, Zeng et al. (Zeng
et al., 2020) used a CNN architecture. However, it should be noted that the CNN architectures used in (Gao
et al., 2020) and (Zeng et al., 2020) were basic and outdated.
While Convolutional Neural Networks (CNNs) are eective in image-specic tasks like classication, they may
not perform well in pixel-wise image understanding, which requires semantic segmentation. Regional CNNs,
on the other hand, have shown to be more successful in this regard. For fruit detection and localisation,
Sa et al. (Sa et al., 2016) utilised bounding box detection through the fusion of Faster R-CNN, RGB, and
Infrared (IR) images. Faster RCNN is an optimised version of RCNNs that enables real-time segmentation.
Liu et al. (Liu et al., 2018b) used Mask RCNN and YOLOv3 (You Only Look Once, Version 3) for bounding
box detection in citrus fruit harvesting. Mask RCNN relied on ResNet-52 and ResNet-150 as the backbone,
and ResNet-150 provided the best performance. Yu et al. (Yu et al., 2019) used Mask RCNN to determinethe strawberry shapes and then utilised a geometrical algorithm to localise the picking point. Ge. et
al. (Ge et al., 2019b) used Mask RCNN to extract strawberry pixels and combined this with depth data,
density-based clustering, and Hough transformation to develop a more robust scene understanding. Perez
et al. (P erez-Borrero et al., 2020) utilised Mask RCNN for strawberry segmentation for harvesting. Other
studies have used RCNN in combination with other methods to improve overall accuracy. For instance, Liu
et al. (Liu et al., 2019) used Mask RCNN with the logical green operator to improve the overall performance
of cucumber detection. Ganesh et al. (Ganesh et al., 2019) employed a combination of HSV and RGB
images to improve the overall performance of Mask RCNN for orange detection. In a recent study, Tafuro
and colleagues (Tafuro et al., 2022a) applied Detectron 2 a Mask-RCNN architecture to detect/estimate
strawberry picking point, ripeness, and weight and presented two novel datasets for strawberry picking.
The authors used two novel datasets specically designed for strawberry picking, which included various
illumination conditions and fruit orientations.
4 Motion Planning for Selective Harvesting
Motion planning is a fundamental problem in robotics that involves nding a feasible path from a start
conguration to a goal conguration, subject to environmental and robot constraints. In the context of
selective harvesting, mobile manipulators equipped with robotic arms have been developed to address the
global challenge of labour shortage in agriculture (Bolda et al., 2016). However, the success of a robotic
fruit picker heavily relies on the reliability and speed of its motion planner (Xiong et al., 2019a). To better
understand the challenges facing selective harvesting, it is important to explore the specic requirements of
the motion planner, including the need for both reliability and speed.
For a selective harvesting system to be successful, its motion planning component must be able to cope
with imprecise perception and environmental interactions. However, agri-robotic motion planning poses
signicant challenges such as (i) the diculty of picking soft fruits in clusters where targets are occluded
by unripe fruits, stems, and foliage; (ii) inaccurate fruit localisation; (iii) incorrect inertial properties and
Coriolis-centrifugal terms used in robot modelling; (iv) unknown interaction dynamics of objects in the
cluster; (v) the need for short-term planning to meet the high-speed requirements of fresh crop production.
These challenges can lead to low success rates and slower picking performance.
The advancements in robotic harvesting methodologies have led to signicant progress in the eld of selective
harvesting for both isolated and cluster-grown crops. Schuetz et al. (Schuetz et al., 2015) proposed an optimal
control approach to generate a trajectory for a 9-DoF CROPS manipulator for sweet pepper harvesting,
minimising collision and dynamical costs. In (Luo et al., 2018), an articial potential eld approach combined
with energy optimisation was presented for collision-free path planning in grape harvesting with a 6-DoF
robot. The potential eld method generated a path that avoided obstacles while guiding the harvesting
point towards the grape clusters. For grape harvesting, the authors of (Jin et al., 2022) introduced a far-near
combined strategy for picking-point positioning, which involved rst detecting and roughly locating the grape
clusters in a far view and then guiding the robot to a near-view point to accurately position the peduncle.
These approaches demonstrate the potential for intelligent motion planning methodologies to overcome the
challenges in selective harvesting, leading to ecient and accurate harvesting performance.
In recent works such as (Xiong et al., 2019a; Xiong et al., 2021), active obstacle-separation path planning
strategies have been proposed to pick fruits in clusters, inspired by human pickers who use their hands to
push and separate surrounding dynamic obstacles during picking. The authors use a customised cup-shaped
end eector with opening blades to push away surrounding fruits and swallow a target fruit. They calculate
the entry direction of the end eector into the cluster (Fig. 7 (b)), move the head straight towards the centre
of the target while actuating the ngers, and inducing pushing actions on the surrounding obstacles before
reaching the target. However, the bulky picking end eector damages the fruits using this heuristic motion
planning. On the other hand, (Yamamoto et al., 2014) proposed an air-blowing mechanism to separate the
target from its adjoining fruits, as seen in gure 7a, which relies on two nozzles: vertical and horizontal.(a)
 (b)
 (c)
Figure 7: Strategies for motion planning in dense fruit clusters: (a) Blowing strategy for neighbourhood sep-
aration (Yamamoto et al., 2014), (b) Gripper nger actuation to push bottom obstacles along a straight line
trajectory towards the target point (Xiong et al., 2020b), (c) Interactive probabilistic movement primitives
(Mghames et al., 2020).
Bac et al. (Bac et al., 2016) addressed the problem of collision-free motion planning for a 9-DoFs sweet-
pepper harvesting robot using bi-directional rapidly exploring random trees (bi-RRT). This approach is less
aected by the number of degrees of freedom compared to other planners like CHOMP. After generating the
path, a path-smoothing algorithm is applied due to the tortuous nature of sampling-based techniques. The
authors place particular emphasis on selecting the azimuth angle of the end eector, where the optimal pose
minimises the dierence between the fruit azimuth angle (with respect to the stem, in the horizontal plane)
and the end eector azimuth angle (with respect to the fruit, in the horizontal plane).
Mghames et al. (Mghames et al., 2020) proposed an Interactive Movement Primitives framework to quickly
plan simple quasi-static pushing movements given the occluding strawberries. The proposed motion planning
can readily generalise to dierent congurations of fruits and clusters. This approach uses the orientation of
single occluding objects (including unripe fruits and stems) for generating systematic pushing actions. This
was the rst attempt to make motion planning interactive which is needed for fruit picking. An optimisation
version of this approach allows the robot to nd a solution for avoiding non-pushable obstacles (Shyam et al.,
2019). Shaym et al. (Shyam et al., 2019) proposed a probabilistic primitive-based optimisation technique
to generate smooth and fast trajectories based on the Covariant Hamiltonian Optimisation framework for
motion planning for harvesting tomatoes regardless of occlusions. Zhong et al. (Zhong et al., 2021) proposed
a fruit grasp planning for litchi picking based on YOLACT.
Selective harvesting of fruit such as apples involves fewer challenges for motion planning as it has less cluttered
fruits. Davison et al. (Davidson et al., 2016) considered that the region between the trellis wires is collision-
free for an under-actuated end eector to reach a target. On the side of grasp planning, (Wang et al., 2022)
proposes an end-to-end network architecture-based RGB-D data for grasping an occluded target. In this
work, a modied PointNet, embedding features of both target and non-target objects, is used for geometry-
aware grasping estimation. On the other hand, cucumber harvesting was tackled in (Van Henten et al.,
2003a) with the A(a shortest-path nding algorithm from a specied source to a specied goal) algorithm
for collision-free planning. The authors motivate their selection with their need for algorithm completeness.
In principle, a complete algorithm will nd the solution or stop using a clearly dened stopping criterion if
a solution cannot be found.
Learning from demonstration (LfD) is another popular approach for planning the picking actions. For
example, Tafuro et al. (Tafuro et al., 2022b) proposed a method called Deep Probabilistic Motion Planning
(d-PMP) (which is based on Deep Movement Primitives (d-MP) (Sanni et al., 2022)). Using an auto-
encoder and fully connected layers, d-PMP maps visual sensory readings to the weight of robot movements.
d-MP extends the deterministic nature of d-MP and enables a robot to generate a distribution of possible
trajectories for tasks such as picking strawberries (Tafuro et al., 2022b).Table 6: Summary on the motion planning strategies developed over the literature for robotic selective
harvesting
Activity Fruit DoFs Structure Motion Planning Technique Document
Strawberries 7 Serial Probabilistic (Tafuro et al., 2022b)
Strawberries 7 Serial CHOMP (Parsa et al., 2023)
Strawberries 3 SerialCluster entrance angle
calculation with active ngers(Xiong et al., 2019a),
(Xiong et al., 2021)
Strawberries 3 Serial IMP (Mghames et al., 2020)
Strawberries 7 Serial Air blowing (Yamamoto et al., 2014)
Grape 6 SerialMinimum Energy + Articial
Potential Field(Luo et al., 2018)
Harvesting Apple 6 Serial Trapezoidal velocity proles (Davidson et al., 2016)
Cucumber 6 Serial A* (Van Henten et al., 2003a)
Tomato 7 Serial CHOMP (Shyam et al., 2019)
Strawberries 7 Serial CHOMP (Mghames and Hanheide, 2022)
Sweet Pepper 9 Serial Bi-RRT (Bac et al., 2016)
Sweet Pepper 9 Serial iLQG (Schuetz et al., 2015)
(a)
 (b)
 (c)
Figure 8: Strategies for planning fruit harvesting from less dense clusters or distributed environment: (a)
Heuristic method for initialising an optimal problem (sweet-pepper) (Schuetz et al., 2015), (b) Minimal
energy approach for harvesting sequence and articial potential eld for harvesting path generation (Luo
et al., 2018), (c) Sampling-based technique (bi-directional RRT) with a desired end eector azimuth angle
with respect to the target (Bac et al., 2016).
Mobility Systems Shoudhary et al. (Choudhary et al., 2021) present a planning framework for nonholo-
nomic mobile robots navigating through narrow pathways in agricultural applications. They use an RRT*
algorithm to generate a global trajectory that considers the kinematic constraints of the robot with non-
holonomic constraints. The E-band local planner is then used to generate a sub-trajectory by connecting
the centre points of the band using various heuristics. The Reeds-Shepp curve generates the curve with the
combination of curve and straight line to the sub-goal. The E-band planner drives the mobile robot towards
the trajectory generated by the Reeds-Shepp curve, and the Reeds-Shepp model is implemented to navigate
the robot in forward and backward directions.
Binch et al. (Binch et al., 2020) propose a genetic framework for optimising navigation parameters in dierent
spatial contexts. They consider navigation algorithms as a black box and use an iterative optimisation
approach to nd suitable parameters for the Thorvald robot in simulated environments. The global planner
used is navfn, and the Dynamic-Window Approach (DWA) algorithm is used as the local planner, as they
are commonly used congurations for the ROS navigation stack. The authors use the eaMuPlusLambda
evolutionary strategy from the distributed evolutionary algorithms in Python (DEAP) library to generate(a)
 (b)
 (c)
 (d)
Figure 9: Strategies for planning to reach an object in a 2-D cluttered environment: (a) Physics-based
planner with uncertainties awareness and an inverted planning-execution timeline (Dogar and Srinivasa,
2012), (b) optimisation-based planning (Kitaev et al., 2015), (c) Whole arm trajectory planning (King et al.,
2015), (d) Deep reinforcement learning (Yuan et al., 2018).
suitable candidate parameter sets.
Methods potentially useful for planning selective harvesting motions: State-of-the-art motion
planning techniques in robotic selective harvesting include: (i) Sampling-based techniques, such as RRT
and its variants (Elbanhawi and Simic, 2014), (Yang et al., 2019), which involve sampling the conguration
space of the robot and nding feasible connectivity between samples. This technique oers fast generation
of a solution in high-dimensionality space, but the solution found may not be optimal. Sampling-based
planners ensure a weaker notion of completeness known as probabilistic completeness, but they are not
guaranteed to nd a solution if one exists. (ii) Learning from demonstrations (LfD), e.g. imitation learning
(IL) (Hussein et al., 2017), dynamic movement primitives (DMP) (Schaal, 2006), multi-layered LfD (Paxton
et al., 2015), (Ghalamzan and Ragaglia, 2018), and deep (probabilistic) movement primitives (Sanni et al.,
2022), (Tafuro et al., 2022b). LfD learns a task model from demonstrations. The model maps the state
or sensory observation to action policy picking movements. (iii) Optimisation methods, such as CHOMP
(Ratli et al., 2009), TrajOpt (Schulman et al., 2014), and STOMP (Kalakrishnan et al., 2011) frameworks,
which are computationally more expensive by using the constraints representation, such as obstacles. (iv)
Polynomial-based path generation, used for parameterising the time of a path generated with a heuristic
planner in harvesting applications, such as the one presented in (Schuetz et al., 2015).
Challenges and opportunities: Occlusion is a major challenge for motion planning. Yamamoto et al.
(Yamamoto et al., 2014) use two external nozzles, which may not be eective in dense clutter where a nozzle
targeting one fruit may be obstructed by another. Additionally, Interactive Movement Primitives (Mghames
et al., 2020) does not take this into consideration. On the other hand, reaching an object in the clutter in 2-D
cases, such as in a fridge or shelves, handles occlusions to some extent (Dogar and Srinivasa, 2012), (Agboh
and Dogar, 2018b), (Kitaev et al., 2015), (King et al., 2015). Dogar et al. (Dogar and Srinivasa, 2012)
propose a physics-based manipulation framework that employs non-prehensile manipulation techniques, such
as pushing, pulling, and toggling, to reach for an object in the clutter with a level of uncertainty in object
position (Figure 9 (a)). The planner moves the penetrated objects ahead in the execution process to make
the planned grasp feasible. Kitaev et al. (Kitaev et al., 2015) use a baseline planner that samples a number of
straight-line trajectories at dierent approach angles to the target (Figure 9 (b)). They then use sequential
quadratic programming (SQP) to minimise static obstacle cost and velocity cost using MuJoCo. King et
al. (King et al., 2015) employ the entire robotic arm to rearrange the scene and move an object to a target
pose (e.g., Fig. 9 (c), the whole arm trajectory planning pushes away the red can, blue box, and grey bowl
while ensuring the green box reaches the target). Their technique embeds a physics-based model into theFigure 10: Simple grow environment of greenhouse-grown cucumbers. (Van Henten et al., 2002)
core of a randomised planner, such as RRT.
In terms of computational eciency, the approach presented in (Dogar and Srinivasa, 2012) is suitable
for cases without uncertainty. On the other hand, computationally expensive techniques such as physics-
based trajectory optimisation have been applied successfully in examples (Agboh and Dogar, 2018b; Kitaev
et al., 2015; King et al., 2015). However, to minimise planning time, robot learning from demonstration
(LfD) approaches such as those described in (Ghalamzan and Ragaglia, 2018) have been developed. Dy-
namic Movement Primitives (DMP) can be used to generate and adapt robot trajectories in real-time while
avoiding collisions (Schaal, 2006). Probabilistic Movement Primitives (ProMP) is another LfD approach
with useful properties that enable online adaptation of learned tasks to new, unseen features in the robot
workspace (Paraschos et al., 2018). Although many works deal with pushing occlusions away to reach a tar-
get fruit in a cluster, few address the challenge of generating fast motion in a scene with initially connected
objects. Table 6 provides an overview of motion planning approaches relevant to selective harvesting.
5 Motion Control for Selective Harvesting
In this section, we focus on the motion control aspect of selective harvesting, which aims to ensure that
the end eector reaches the desired grasping pose (position and orientation) of the target fruit. While the
kinematic control of bespoke harvesting robots is often mentioned in the literature, we do not cover it here.
The complexity of motion control arises from the accessibility of the target fruit, which depends on various
factors, such as the fruit type and the end eector design. To facilitate our discussion, we categorise the
complexity into several key areas. In some rare cases, selective harvesting tasks involve fruits with low control
requirements that are well presented to the robot, such as greenhouse-grown cucumbers shown in gure 10
and reported in (Van Henten et al., 2002).
The typical approach to motion control is to generate an initial trajectory oine for the given scenario,
which is then adapted or rened to ensure that the goal state is achieved. However, the adaptation process
can be challenging, especially in complex scenarios where the target fruit is occluded by other objects or the
environment is highly dynamic. Various techniques have been proposed in the literature to address these
challenges, which we review in the following subsections.
One common approach in many research papers and projects is to simplify the environment by removing sur-
rounding fruit and foliage to expose the ripe fruit, which provides a less complex version of the environment.
This simplication makes the target fruit's position more stable and reduces occlusion and surrounding ob-
stacles. By doing so, robot motion and control, as well as machine vision, can produce more accurate results
without dealing with some of the more complex aspects of selective harvesting. This method is commonly
used in most selective harvesting projects and is illustrated in gure 11, which depicts a commercially grown
sweet pepper crop, and then the simplied version with the obstacles removed from the environment (AradFigure 11: Complexity dierence between commercial and modied sweet pepper crop. (Arad et al., 2020)
et al., 2020). These simplied scenarios are often used as benchmark test cases for harvesting systems.
Although the simplied test cases provide a good milestone for other aspects of robotic harvesters, in reality,
the requirements of the control system are not tested in these settings. (Jun et al., 2021) state that `Because of
unknown and unstructured environments, such as the presence of clusters of fruits and canopies, manipulation
is considered one of the major challenges in the development of harvesting robots' citing (Silwal et al., 2017).
In this more `realistic' dense environment, there is often reduced accuracy from the machine vision system,
with inaccurate pose estimations, open-loop control produces high failure rates. Attaching sensors to the
robot's end eector allows for closed-loop visual servo control, which is applied to increase the system's
robustness to inaccurate soft fruit pose estimations (Zhao et al., 2016a).
In a variety of crops, obstacles exist in the environment that must be avoided. These can be other fruits
(especially delicate crops such as mushrooms that damage very easily), foliage, or grow equipment. In these
cases, there is often a likelihood of occlusion, which also further reduces the accuracy of machine vision
systems. A good example of this challenge can be seen in gure 12 middle and further increases the control
requirements.
In many unstructured and object-dense environments, obstacle avoidance is not possible as stated by (Jun
et al., 2021): `Harvesting from clusters is dicult because surrounding fruits, leaves, stems, and other
obstacles are dicult to isolate from the target during detection and manipulation'. In some crops, obstacle
interaction is required to move objects out of the way to reach the target fruit, such as the environment as
seen in gure 12 right.
A common representation of this problem is when attempting to harvest from a cluster of soft fruit, where
the requirements of the control system are to push occluding fruit out of the way without bruising them and
reach the target fruit. In this setting, a target fruit's position is highly unstable due to the interactions of
the robot with the cluster.
Open loop visual Control: Open-loop visual control is a popular technique used in projects with simple
environments where heuristic control approaches can be implemented. Despite its simplicity, it remains
one of the most commonly used control approaches in the literature due to its ease of implementation and
success in simplied test cases. (Zhao et al., 2016a) provides a review of open-loop visual control techniques
used in robotic harvesting. Initial techniques relied on accurate machine vision to increase the probability(a)
 (b)
 (c)
Figure 12: (a) Simple tomato test environment with increasing occlusion requiring open-loop visual control
(Jun et al., 2021). (b) Image of the typical obstacles found in sweet pepper grow environments that require
visual servo control and obstacle avoidance. (Bac et al., 2013), (c) Examples of dense soft fruit clusters
(Xiong et al., 2020b) requiring obstacle interaction
of reaching the target fruit. For instance, (Inoue et al., 1996) used multiple visual sensors, (Hayashi et al.,
2010) used a three-camera system, where the centre camera was used to calculate inclination and the other
two were used for stereo vision, and (Han et al., 2012) added the use of a laser device to improve accuracy.
Other methods relied on simple heuristic approaches. For example, (Kondo et al., 1996) sent the end eector
to target the centre of a fruit cluster, and if there was no contact, the end eector was moved forward by
50mm, repeating this process until the target fruit was grasped.
With the advent of modern RGBD cameras and machine learning techniques to produce highly accurate
pose estimations, open-loop control is still used. (Jun et al., 2021) used this technique to drive a 6-DOF ma-
nipulator in lab conditions to harvest 1 to 4 tomato clusters. Evaluation: 1T = 100% 2T=91.7% 3T=58.3%
4T=41.7%. The key challenges cited about the open-loop control policy were the obstruction to target
tomatoes caused inaccurate pose estimations, which the control policy was not able to adjust to. Incorrect
path planning further impacted the system's performance.
Overall the use of open-loop control has many issues resulting in the reduced performance of the developed
harvesting system. Complete reliance on the machine vision system's accuracy, calibration, and assembly
(Yau and Wang, 1996) leads to inevitable issues with harvester performance. As such, in cluttered and
realistic harvesting environments open-loop control policies are unreliable, so testing is generally performed
in controlled laboratory conditions (Font et al., 2014) (Jun et al., 2021) (Zou et al., 2012) where the crop
is clearly presented. When tested in realistic environments, even conditions such as wind can result in the
fruit position changing, in these cases, the `eciency of open-loop visual control for robotic harvesting is
very low' (Zhao et al., 2016a).
Closed loop control In order to increase the accuracy of open-loop control systems many robotic selective
harvesting projects have used a visual control feedback loop (Corke and Hager, 1998). A review of visual servo
control algorithms used in robotic harvesting is presented in (Zhao et al., 2016a). Visual servoing techniques
have remained the same since, and we have not found novel applications of new control techniques beyond
those presented in (Zhao et al., 2016a). However, the testing of these control algorithms has developed into
progressively more realistic environments.
More recently, Arad et al. (Arad et al., 2020) used open-loop control to arrive at a location close to the target
fruit, they then used a simple visual servo algorithm based on keeping the centre of the fruit in the centreof the in-hand camera (RGBD). The contribution of this paper was extensive testing of the system in a
real growing environment. Performance was measured in the percentage of sweet peppers reached: Modied
scene single row=89% double row=91%, unmodied single row=64% double row=55%. Where unmodied
means the realistic harvesting environment. Visual servo control was cited as successful, however, they
suggest better error handling would increase system accuracy as if the sight of the fruit was lost, the visual
servo algorithm would fail to reach the target state. Richard et al. (Ringdahl et al., 2019) also state that
visual servo control is not as robust in certain fruit/grow types as if the view of the fruit is lost during the
process then the system will fail. This is most common in fruits that grow in clusters or in highly occluded
growing environments such as sweet peppers.
Obstacle Avoidance: Arad et al. (Arad et al., 2020) applied a visual servo control to sweet pepper
harvesting with a 6-DOF manipulator tested in eld conditions. Obstacle avoidance motion control was
applied to allow the manipulator to plan a trajectory to the target fruit without bruising or disturbing the
surrounding environment. They used ROS MoveIt OMPL's lazy PRM* and TRAC-IK kinematic solvers
to create target kinematic congurations. As shown in the paper above, in selective harvesting, obstacle
avoidance has been performed in an open-loop manner and as such may have issues relating to environmental
change during the actions, however, this has not yet been cited as an issue.
6 Discussion
The results presented in this paper demonstrate the challenges and advancements in selective harvesting
robotics. The complexity of the selective harvesting task is evident from the range of approaches and
techniques presented in the literature. This paper has highlighted the dierent areas of selective harvesting
robotics, including dierent hardware designs, sensing and perception, motion planning and motion control.
One of the key challenges in selective harvesting is dealing with the variability of the fruit and the envi-
ronment. This variability makes it dicult to develop a single solution that can be applied across dierent
picking scenarios. As a result, many of the papers focus on specic crops or environments. This narrow
focus allows for a more tailored solution, but it also limits the generalisability of the approach.
The review of sensing and perception techniques highlights the importance of accurate and reliable sensing
for selective harvesting. Machine vision and sensor fusion are commonly used approaches to obtain accurate
fruit detection and pose estimation. However, these techniques can be aected by variability in lighting
conditions and the presence of other objects in the scene. The use of depth cameras and other RGBD
sensors has shown promise in improving the accuracy of pose estimation, but further research is needed to
evaluate their eectiveness in real-world scenarios.
Motion planning andcontrol are critical components of any selective harvesting system. The reviewed
papers demonstrate the range of approaches used to generate and execute trajectories for the robot end
eector. Trajectory optimisation and learning from demonstrations are commonly used techniques for gen-
erating trajectories, while open-loop and closed-loop control policies are used for execution. End eector
design is also an important consideration, with grippers and suction cups being the most commonly used
tools for harvesting each come with its specications and capabilities.
SHRs (selective harvesting robots) still struggle to perform as well as humans in dealing with complex and
dense fruit clusters. Humans benet from bi-manual manipulation with active perception (moving visual
sensors) and interactive perception (moving parts in a cluster to improve perception performance). A similar
approach could be adopted to help SHRs eectively deal with clusters, by using a bi-manual mechanism that
works cooperatively with the vision system. One arm could move occluding parts away in clusters with
tactile-enabled nger mechanisms, allowing the perception system to look at the target fruit. Then, the
vision system can capture sensory information, estimate the ripeness of the fruit, and localise it. The second
arm can then approach the ripe fruit and pick it. A bi-manual SHR, as demonstrated in (Sep uLveda et al.,2020), showed improved eectiveness in picking eggplants occluded by leaves. Such a mechanism can also
perform simultaneous harvesting with both arms in the case of detecting two isolated fruits. Incorporating
bi-manual manipulation in SHRs may lead to better performance in complex harvesting scenarios, and should
be considered as a potential solution for future research.
A more eective design forrobotic picking end eector is another domain of research in SHRs. Parsa
et al. (Parsa et al., 2023) proposed a novel strawberry-picking end eector which to some extent handles
the problem of occlusion in a cluster. According to the results in (Bac et al., 2016), reducing end eector
dimensions and widening stem spacing are promising research directions because they signicantly improved
goal conguration success, from 63% to 84%. SHR research has explored the area of Continuum mechanisms
less than rigid mechanisms for the manipulator. Continuum robots combine the benets of soft and rigid
mechanisms. A continuum mechanism can oer the exibility and compliance to position the end eector in
cluttered picking scenarios (Chowdhary et al., 2019). A more extensive study may demonstrate its potential
benets for SHRs.
After picking the fruits, they are transferred to storage bins either by a pick-and-place sequence, transferred
through exible tubes, or directly stored in a punnet held by the end eector. A pick-and-place sequence
after every harvesting action increases harvesting cycle time, while the transfer through exible tubes can
cause damage to some fruits, especially those having a soft fruit body. At the same time, carrying the
harvested fruits on the end eector itself can aect the dynamics of the arm/end eector while operating on
fast cycles. Studies on fruit transfer methodologies would help preserve fruit quality without compromising
the cycle time or picking speed. There is also room to study solar power for SHRs.
Our overview of the available perception methods for SHRs indicates that many more publicly available
datasets (with necessary annotations, e.g. weight, picking point, key points, ripeness, and quality) are
needed. We also need to use other sensing modalities such as hyper-spectral imaging to improve the perfor-
mance of the vision system. Moreover, active and interactive perception is required to deal with complex
perception problems where a partial or a full occlusion exists.
We also observed that data-driven and learning approaches can help us to build motion planning learned
from human demonstrations. This helps generalise the picking action across several dierent picking scenarios
(e.g strawberries, tomatoes, mushrooms) rather than engineering a solution for a single growing condition,
e.g. (Tafuro et al., 2022b). In this regard, Imitation Learning and Deep Reinforcement Learning (Yuan et al.,
2018) (gure 9 (d)) and (Bejjani et al., 2019) are very useful. For instance, Yuan et al. (Yuan et al., 2018)
rely on visual feedback to train a deep Q-network to rearrange objects on a tabletop. The latter technique
is used to overcome the need to model the physical properties of the environment precisely.
Though some crops are more sparsely grown (e.g. apples, sweet peppers), they are still occluded by foliage
and/or stems. Motion planning and control for removing occluding elements are crucial for the accurate
detection of the target fruit. This can happen by pushing/pulling away occlusions and re-planning a path to
the target fruit using, e.g., a receding-horizon controller. Planning SHR actions for active andinteractive
perception is also an open research challenge. Moreover, quick computational approaches for this planning
are an open research challenge as SHRs need to perform comparably to the human picking rate. In 3-D
real-world examples where these pushing/pulling actions are required, a forward model is needed to plan
or control pushing actions for eective cluster manipulation. Modelling the plants (i.e. making a forward
model) with many loose interconnections imposes a highly nonlinear and complex problem. Another open
research challenge is data-driven approaches that can predict the movements of cluster parts conditioned by
a robot action. Hence, the robot can o-line optimise its actions and consequently implement the mission.
Closed-loop control systems are also complex and required by SHRs. Environments with fruit clusters
provide a major challenge in motion control for selective harvesting. Clusters are commonly found in various
crops such as strawberries, tomatoes, mushrooms and kiwis (to give a few examples). Initially, clusters
provide a complex challenge for machine vision systems to locate the obscured soft fruits accurately, so
often, the control algorithm must be able to handle unreliable or inaccurate target pose estimations. XiongFigure 13: Grasping in a cluttered workspace, exampling pushing obstacles out of the way to reach the target
object. (Agboh and Dogar, 2018a)
et al. (Xiong et al., 2019b) used visual servo control to show that the highest cause of failure was when
harvesting in clusters `where both detection and picking struggles to separate strawberries'. They suggest
that advanced path planning and control should be used to `control the gripper to avoid or even push the
surrounding obstacles for cluster picking'. (Hayashi et al., 2010) used visual servo control and cited that
one area of issue for the control system was that `the tip of the gripper sometimes pushed adjacent fruits,
causing the target fruits to move'. A control algorithm capable of reacting to the unforeseen eects of the
end eector interacting with the cluster would further increase yield.
Our observations suggest a research gap in the area of closed-loop motion control for obstacle manipulation
in selective harvesting. While some initial research has been conducted on trajectory generation for this
task (Mghames et al., 2020; Xiong et al., 2019a), there is a lack of focus on closed-loop control. While there
exist methods of pushing actions with robotic manipulators in other domains, such as bin picking, applying
these techniques to the selective harvesting of soft fruit clusters presents unique challenges. While the idea
of pushing obstacles out of the way with robotic manipulators is a well-established eld of research, most of
the work has focused on simpler scenarios with static 2D objects, as shown in gure 14. A comprehensive
introduction to this eld is presented in (Yu et al., 2016), where estimations of friction coecients are made
to create models for frictional pushing tasks. However, these methods may not be directly applicable to the
complex and dynamic soft fruit cluster manipulation problem.
In (Agboh and Dogar, 2018a), the authors addressed tasks such as pushing a target object into a goal region
and grasping an object in a cluttered workspace as a Markov decision process with stochasticity (Figure 13).
They used a trajectory optimiser to feed promising trajectories to the MDP, and their approach focused on
grasp speed while maintaining high success rates. Although pushing actions have been widely studied in
robotics (Tekden et al., 2021), the scenarios tested are typically far simpler than those encountered in soft
fruit cluster manipulation. We suggest investigating closed-loop control for manipulating dense and complex
soft fruit clusters to address this research gap, possibly using the MDP framework.
The application of action-conditioned model predictive control can enable robotic pushing within
the complex clustered environments discussed above. The prediction model can be applied within a model
predictive control (MPC) algorithm to react to and adjust the robot's trajectory to ensure that the `pushing'
actions of the robot will move the obstacles to their target positions. The best representation for the
harvesting environment is not known, and this is the rst area of research that should be considered; similar
research into more simplied robot-pushing tasks to nd the best representations were carried out in (Ye et al.,
2020), which showed that an object-centric representation `better captures the interaction among objects
and the robot' and thus improved the performance of their model predictive control system. However, this
environment shown in gure 14 is simple and the authors' representation made the assumption that their
environment is a `collection of distinct objects, where each object can be described via its location and the
visual descriptor'. Tests should be carried out to see if this representation contains enough features about a
soft fruit cluster/ growing environment to produce accurate predictions on the robot-to-cluster interactions.(a)
 (b)
 (c)
Figure 14: Examples of modern robot pushing task environments presented in (Tekden et al., 2021) (a),
(Finn et al., 2016) (b) and (Ye et al., 2020) (c)
Figure 15: Strawberry clusters simulated in (Mghames et al., 2020)
Vision-based representations for deep model predictive control have been applied to the most similar problems
we could nd. The problem presented in (Finn et al., 2016), and their subsequent variations and editions to
their work in (Babaeizadeh et al., 2017) and (Finn and Levine, 2017), focused on using a video prediction
model trained on unlabelled data for use in a model predictive control system that would push objects to
desired locations in a cluster.
Thevideo prediction system (Finn and Levine, 2017) is a deep learning model that takes as input a
trajectory of the robot's end eector in task space and context video frames of the environment, and outputs
a sequence of future video frames. The original video prediction model was trained on a dataset of 1.5 million
video frames showing robot-to-cluster interactions, with the objects in the cluster being static household
objects on a at surface (as shown in Figure 14 middle) (Finn and Levine, 2017). The resulting control system
was capable of pushing objects to desired locations and orientations. However, in a harvesting environment,
the objects in a cluster exhibit dynamic qualities, which may require additional features beyond RGBD
data to accurately predict future frames. Incorporating tactile data during the interaction could provide the
predictive model with information about the forces involved, allowing for more accurate predictions.
Thetactile prediction has been exhibited, rst, in research showing tactile sensation can be predicted
in an obstacle manipulation setting (Nazari et al., 2021), (Mandil et al., 2022). These styles of models
were then introduced within a control scenario for slip prediction and control (Nazari et al., 2023b). In
preliminary research, the use of tactile predictive control for soft fruit cluster manipulation was shown in
(Nazari et al., 2023a). Knowing if objects within occluded scenes are slipping and using tactile predictive
control to maintain strong contact and manipulation control with an obstacle is an essential requirement
for obstacle manipulation in the highly occluded soft fruit cluster scenes shown in strawberry harvesting.
Fusing video and tactile for video prediction showed a signicantly improved performance compared to
video alone prediction (Mandil and Ghalamzan, 2022). This opens up more research opportunities in sensor
fusion for tactile and video prediction to be used for predictive control.Tactile sensors are also not studied well enough for SHRs. This sensing modality is vital for cases where
visual sensing is no longer eective as either manipulator or other objects create occlusions for a xed eye
on SHRs, or the eye-in-hand is too close to provide meaningful information. Tactile sensing on the end
eector can help better manipulator control as it provides contact force information during the harvesting of
fruits. Fusing the information from the vision system and tactile sensors enables an SHR to eectively push
unripe fruits, leaves, and foliage away to help the vision system view or the manipulator to reach a target
fruit. Moreover, tactile sensors, in the end, eectors help to control the forces applied on delicate fruits like
strawberries during the harvesting action. Specic studies are available that measured the required force
to handle strawberries during harvesting (Dimeas et al., 2013; Rajendran et al., 2022). Understanding the
need for tactile sensing in end eectors handling soft fruits, we are developing a low-cost tactile skin that
can easily be added to existing end eectors (Rajendran S et al., 2023) and (Nazari et al., 2023a).
If generating real data sets large enough to produce accurate predictions is not possible, simulating the
harvesting environment may be required. This would enable the generation of large data sets for pre-
training predictive models and the use of reinforcement learning techniques. Soft fruit clusters have been
simulated for initial trajectory generation (Mghames et al., 2020). However, as shown in gure 15, the
simulated environment is extremely simplied. Beyond this study, there has been no further research into
soft fruit clusters/dense harvesting environments. This is another signicant gap in the community, and
we recommend research in this area to enable research into reinforcement learning methods. Due to the
complexity of simulating these dense harvesting environments, we believe that a focus on model predictive
control is most likely to be successful.
Although these reviews and discussions are based on various SHR technologies reported in the literature,
there are several other SHRs that are brought out by many start-ups . Some of them includes: Dogtooth
Technologies1(Strawberry harvester), Saga Robotics2(Strawberry harvester), Traptic3(Strawberry har-
vester), AvL Motion4(Asparagus harvester), Tevel Tech5(Soft fruit harvester), Four Growers6(Tomato
harvester), iSaron7(Saron harvester), GROBOMAC8(Cotton harvester). Since the reports on them lack
much technical details, we haven't discussed them in this article.
7 Conclusion
In conclusion, the potential benets of selective harvesting robots in addressing the challenges of global food
production are immense. However, as we have discussed in this paper, there are signicant gaps and chal-
lenges that need to be addressed in the development of SHR technologies. Currently, the state-of-the-art in
SHR technologies is unevenly distributed, with more advanced hardware and perception technologies com-
pared to motion planning and control. This highlights the need for greater focus and research eorts in the
areas of motion planning and control, particularly in the context of realistic and unstructured environments.
Additionally, the current research landscape for SHRs has primarily focused on simplied harvesting en-
vironments, and there is a need for more realistic, dense cluster environments to be considered. This will
require the development of more robust and ecient motion planning and control algorithms to support
SHRs in such environments. The integration of AI and soft robots, as well as data-driven methods, can fur-
ther enhance the performance and robustness of SHR systems. Active and interactive perception techniques
can provide SHRs with a better understanding of their environment and the ability to interact with objects
in it, while data-driven methods can enable the ecient and accurate handling of large datasets generated
1https://dogtooth.tech/
2https://sagarobotics.com/
3https://www.traptic.com/
4https://www.avlmotion.com/nl/
5https://www.tevel-tech.com/
6https://fourgrowers.com/
7https://www.isaron.life/
8https://www.grobomac.com/by SHR sensors.
We also identied several open research questions that need to be addressed to advance SHR technologies
further. These include developing more robust grasping and cutting techniques, improving the accuracy
and speed of sensing and perception systems, developing ecient and robust motion planning and control
algorithms, and integrating SHR technologies with precision agriculture systems. To meet these challenges, a
concerted eort is needed from researchers and practitioners in the eld of robotics, agriculture, and related
disciplines. Collaborative eorts and open sharing of data and knowledge can accelerate the development of
SHR technologies, which can ultimately help address the challenges of global food production.
Overall, this paper provides a comprehensive overview of the current state-of-the-art in SHR technologies
and highlights the need for further research and development eorts to meet the challenges of global food
production. We hope this paper serves as a starting point for researchers and practitioners interested in
developing SHRs and contributes to the advancement of this important eld.
8 Acknowledgement
This work was partially supported by the Centre for Doctoral Training, United Kingdom (CDT) in Agri-
Food Robotics (AgriFoRwArdS) Grant reference: EP/S023917/1; Lincoln Agri-Robotics (LAR) funded by
Research England.
References
Agboh, W. C. and Dogar, M. R. (2018a). Pushing fast and slow: Task-adaptive planning for non-prehensile
manipulation under uncertainty. In International Workshop on the Algorithmic Foundations of Robotics ,
pages 160{176. Springer.
Agboh, W. C. and Dogar, M. R. (2018b). Real-time online re-planning for grasping under clutter and
uncertainty. In 2018 IEEE-RAS 18th International Conference on Humanoid Robots (Humanoids) ,
pages 1{8. IEEE.
Arad, B., Balendonck, J., Barth, R., Ben-Shahar, O., Edan, Y., Hellstr om, T., Hemming, J., Kurtser, P.,
Ringdahl, O., Tielen, T., et al. (2020). Development of a sweet pepper harvesting robot. Journal of
Field Robotics , 37(6):1027{1039.
Arakeri, M. P. et al. (2016). Computer vision based fruit grading system for quality evaluation of tomato in
agriculture industry. Procedia Computer Science , 79:426{433.
Are, A., Motlagh, A. M., Mollazade, K., Teimourlou, R. F., et al. (2011). Recognition and localization of
ripen tomato based on machine vision. Australian Journal of Crop Science , 5(10):1144.
Arima, S. (1999). Cucumber harvesting robot and plant training system. Journal of Robotics and Mecha-
tronics , 11(3):208{212.
Arima, S., Kondo, N., and Monta, M. (2004). Strawberry harvesting robot on table-top culture. In 2004
ASAE Annual Meeting , page 1. American Society of Agricultural and Biological Engineers.
Armada, M. A., Muscato, G., Prestilippo, M., Abbate, N., and Rizzuto, I. (2005). A prototype of an orange
picking robot: past history, the new robot and experimental results. Industrial Robot: An International
Journal .
Babaeizadeh, M., Finn, C., Erhan, D., Campbell, R. H., and Levine, S. (2017). Stochastic variational video
prediction. arXiv preprint arXiv:1710.11252 .Bac, C., Hemming, J., and Van Henten, E. (2013). Robust pixel-based classication of obstacles for robotic
harvesting of sweet-pepper. Computers and electronics in agriculture , 96:148{162.
Bac, C. W., Hemming, J., Van Tuijl, B., Barth, R., Wais, E., and van Henten, E. J. (2017). Performance
evaluation of a harvesting robot for sweet pepper. Journal of Field Robotics , 34(6):1123{1139.
Bac, C. W., Roorda, T., Reshef, R., Berman, S., Hemming, J., and van Henten, E. J. (2016). Analysis of
a motion planning problem for sweet-pepper harvesting in a dense obstacle environment. Biosystems
Engineering , 146:85{97.
Baeten, J., Donn e, K., Boedrij, S., Beckers, W., and Claesen, E. (2008). Autonomous fruit picking machine:
A robotic apple harvester. In Field and service robotics , pages 531{539. Springer.
Baur, J., Pfa, J., Ulbrich, H., and Villgrattner, T. (2012). Design and development of a redundant modular
multipurpose agricultural manipulator. In 2012 IEEE/ASME International Conference on Advanced
Intelligent Mechatronics (AIM) , pages 823{830. IEEE.
Bejjani, W., Dogar, M. R., and Leonetti, M. (2019). Learning physics-based manipulation in clutter: Combin-
ing image-based generalization and look-ahead planning. In 2019 IEEE/RSJ International Conference
on Intelligent Robots and Systems (IROS) , pages 6562{6569. IEEE.
Binch, A., Das, G. P., Pulido Fentanes, J., and Hanheide, M. (2020). Context dependant iterative parameter
optimisation for robust robot navigation. In 2020 IEEE International Conference on Robotics and
Automation (ICRA) , pages 3937{3943.
Bolda, M., Tourte, L., Murdock, J., and Sumner, D. A. (2016). Sample costs to produce and harvest
strawberries. Accessed: 23-02-2020.
Ceres, R., Pons, J. L., Jimenez, A., Martin, J., and Calderon, L. (1998). Design and implementation of an
aided fruit-harvesting robot (agribot). Industrial Robot: An International Journal .
Chen, L.-C., Zhu, Y., Papandreou, G., Schro, F., and Adam, H. (2018). Encoder-decoder with atrous
separable convolution for semantic image segmentation. In ECCV .
Cho, W., Na, M., Kim, S., and Jeon, W. (2019). Automatic prediction of brix and acidity in stages of ripeness
of strawberries using image processing techniques. In 2019 34th International Technical Conference on
Circuits/Systems, Computers and Communications (ITC-CSCC) , pages 1{4. IEEE.
Choudhary, A., Kobayashi, Y., Arjonilla, F. J., Nagasaka, S., and Koike, M. (2021). Evaluation of map-
ping and path planning for non-holonomic mobile robot navigation in narrow pathway for agricultural
application. In 2021 IEEE/SICE International Symposium on System Integration (SII) , pages 17{22.
Chowdhary, G., Gazzola, M., Krishnan, G., Soman, C., and Lovell, S. (2019). Soft robotics as an enabling
technology for agroforestry practice and research. Sustainability , 11(23):6751.
Corke, P. I. and Hager, G. D. (1998). Vision-based robot control. In Control Problems in Robotics and
Automation , pages 177{192. Springer.
Crippa, M., Solazzo, E., Guizzardi, D., Monforti-Ferrario, F., Tubiello, F., and Leip, A. (2021). Food systems
are responsible for a third of global anthropogenic ghg emissions. Nature Food , 2(3):198{209.
Cui, Y., Gejima, Y., Kobayashi, T., Hiyoshi, K., and Nagata, M. (2013). Study on cartesian-type strawberry-
harvesting robot. Sensor Letters , 11(6-7):1223{1228.
Davidson, J., Bhusal, S., Mo, C., Karkee, M., and Zhang, Q. (2020). Robotic manipulation for specialty
crop harvesting: A review of manipulator and end-eector technologies. Global Journal of Agricultural
and Allied Sciences , 2(1):25{41.
Davidson, J. R., Hohimer, C. J., Mo, C., and Karkee, M. (2017). Dual robot coordination for apple harvesting.
In2017 ASABE annual international meeting , page 1. American Society of Agricultural and Biological
Engineers.Davidson, J. R., Silwal, A., Hohimer, C. J., Karkee, M., Mo, C., and Zhang, Q. (2016). Proof-of-concept
of a robotic apple harvester. In 2016 IEEE/RSJ International Conference on Intelligent Robots and
Systems (IROS) , pages 634{639. IEEE.
De-An, Z., Jidong, L., Wei, J., Ying, Z., and Yu, C. (2011). Design and control of an apple harvesting robot.
Biosystems engineering , 110(2):112{122.
Dimeas, F., Sako, D. V., Moulianitis, V. C., and Aspragathos, N. (2013). Towards designing a robot gripper
for ecient strawberry harvesting. In Proceedings of 22nd International Workshop on Robotics in Alpe-
Adria-Danube Region{RAAD, Portoroz, Slovenia , pages 220{226.
Dogar, M. R. and Srinivasa, S. S. (2012). A planning framework for non-prehensile manipulation under
clutter and uncertainty. Autonomous Robots , 33(3):217{236.
Durand-Petiteville, A., Vougioukas, S., and Slaughter, D. C. (2017). Real-time segmentation of strawberry
esh and calyx from images of singulated strawberries during postharvest processing. Computers and
electronics in agriculture , 142:298{313.
Elbanhawi, M. and Simic, M. (2014). Sampling-based robot motion planning: A review. IEEE Access ,
2:56{77.
Feng, G., Qixin, C., and Masateru, N. (2008). Fruit detachment and classication method for strawberry
harvesting robot. International Journal of Advanced Robotic Systems , 5(1):4.
Feng, Q., Wang, X., Wang, G., and Li, Z. (2015). Design and test of tomatoes harvesting robot. In 2015
IEEE International Conference on Information and Automation , pages 949{952. IEEE.
Feng, Q., Wang, X., Zheng, W., Qiu, Q., and Jiang, K. (2012). New strawberry harvesting robot for
elevated-trough culture. International Journal of Agricultural and Biological Engineering , 5(2):1{8.
Feng, Q., Zou, W., Fan, P., Zhang, C., and Wang, X. (2018). Design and test of robotic harvesting system
for cherry tomato. International Journal of Agricultural and Biological Engineering , 11(1):96{100.
Finn, C., Goodfellow, I., and Levine, S. (2016). Unsupervised learning for physical interaction through video
prediction. arXiv preprint arXiv:1605.07157 .
Finn, C. and Levine, S. (2017). Deep visual foresight for planning robot motion. In 2017 IEEE International
Conference on Robotics and Automation (ICRA) , pages 2786{2793. IEEE.
Font, D., Pallej a, T., Tresanchez, M., Runcan, D., Moreno, J., Mart nez, D., Teixid o, M., and Palac n, J.
(2014). A proposal for automatic fruit harvesting by combining a low cost stereovision camera and a
robotic arm. Sensors , 14(7):11557{11579.
Ganesh, P., Volle, K., Burks, T., and Mehta, S. (2019). Deep orange: Mask r-cnn based orange detection
and segmentation. IFAC-PapersOnLine , 52(30):70{75.
Gao, Z., Shao, Y., Xuan, G., Wang, Y., Liu, Y., and Han, X. (2020). Real-time hyperspectral imaging for
the in-eld estimation of strawberry ripeness with deep learning. Articial Intelligence in Agriculture .
Ge, Y., Xiong, Y., and From, P. J. (2019a). Instance segmentation and localization of strawberries in farm
conditions for automatic fruit harvesting. IFAC-PapersOnLine , 52(30):294{299.
Ge, Y., Xiong, Y., and From, P. J. (2020a). Symmetry-based 3d shape completion for fruit localisation for
harvesting robots. Biosystems Engineering , 197:188{202.
Ge, Y., Xiong, Y., Tenorio, G. L., and From, P. J. (2019b). Fruit localization and environment perception
for strawberry harvesting robots. IEEE Access , 7:147642{147652.
Ge, Y., Ya, X., and From, P. J. (2020b). Classication of pickable and unpickable strawberries under farm
conditions. CASE , 145:39{51.Gen e-Mola, J., Gregorio, E., Guevara, J., Auat, F., Sanz-Cortiella, R., Escol a, A., Llorens, J., Morros, J.-R.,
Ruiz-Hidalgo, J., Vilaplana, V., et al. (2019a). Fruit detection in an apple orchard using a mobile
terrestrial laser scanner. Biosystems engineering , 187:171{184.
Gen e-Mola, J., Sanz-Cortiella, R., Rosell-Polo, J. R., Morros, J.-R., Ruiz-Hidalgo, J., Vilaplana, V., and
Gregorio, E. (2020). Fruit detection and 3d location using instance segmentation neural networks and
structure-from-motion photogrammetry. Computers and Electronics in Agriculture , 169:105165.
Gen e-Mola, J., Vilaplana, V., Rosell-Polo, J. R., Morros, J.-R., Ruiz-Hidalgo, J., and Gregorio, E. (2019b).
Multi-modal deep learning for fuji apple detection using rgb-d cameras and their radiometric capabilities.
Computers and electronics in agriculture , 162:689{698.
Ghalamzan, A. and Ragaglia, M. (2018). Robot learning from demonstrations: Emulation learning in
environments with moving obstacles. Robotics and Autonomous Systems , 101:45{56.
Guo, C., Liu, F., Kong, W., He, Y., Lou, B., et al. (2016). Hyperspectral imaging analysis for ripeness
evaluation of strawberry with support vector machine. Journal of Food Engineering , 179:11{18.
Han, K.-S., Kim, S.-C., Lee, Y.-B., Kim, S.-C., Im, D.-H., Choi, H.-K., and Hwang, H. (2012). Strawberry
harvesting robot for bench-type cultivation. Journal of Biosystems Engineering , 37(1):65{74.
Hannan, M. W. and Burks, T. F. (2004). Current developments in automated citrus harvesting. In 2004
ASAE Annual Meeting , page 1. American Society of Agricultural and Biological Engineers.
Harrell, R., Adsit, P. D., Munilla, R., and Slaughter, D. (1990). Robotic picking of citrus. Robotica ,
8(4):269{278.
Hayashi, S., Ganno, K., Ishii, Y., and Tanaka, I. (2002). Robotic harvesting system for eggplants. Japan
Agricultural Research Quarterly: JARQ , 36(3):163{168.
Hayashi, S., Shigematsu, K., Yamamoto, S., Kobayashi, K., Kohno, Y., Kamata, J., and Kurita, M. (2010).
Evaluation of a strawberry-harvesting robot in a eld test. Biosystems engineering , 105(2):160{171.
Hayashi, S., Yamamoto, S., Saito, S., Ochiai, Y., Kamata, J., Kurita, M., and Yamamoto, K. (2014). Field
operation of a movable strawberry-harvesting robot using a travel platform. Japan Agricultural Research
Quarterly: JARQ , 48(3):307{316.
Htet, H. T. M., Thu, T. T., Win, A. K., and Shibata, Y. (2020). Vision-based automatic strawberry shape
and size estimation and classication using raspberry pi. In 2020 59th Annual Conference of the Society
of Instrument and Control Engineers of Japan (SICE) , pages 360{365. IEEE.
Huang, Z., Wane, S., and Parsons, S. (2017). Towards automated strawberry harvesting: Identifying the
picking point. In Annual Conference Towards Autonomous Robotic Systems , pages 222{236. Springer.
Hussein, A., Gaber, M. M., Elyan, E., and Jayne, C. (2017). Imitation learning: A survey of learning
methods. ACM Computing Surveys (CSUR) , 50(2):1{35.
Inoue, S., Ojika, T., Harayama, M., Kobayashi, T., and Imai, T. (1996). Cooperated operation of plural
hand-robots for automatic harvest system. Mathematics and computers in simulation , 41(3-4):357{365.
IPCC, I. (2018). Summary for policymakers" in global warming of 1.5 Â°c. an ipcc special report on the
impacts of global warming of 1.5 Â°c above pre-industrial levels and related global greenhouse gas emission
pathways, in the context of strengthening the global response to the threat of climate change, sustainable
development, and eorts to eradicate poverty.
Jayaselan, H. A. J., Ismail, W. I. W., and Ahmad, D. (2012). Manipulator automation for fresh fruit bunch
(b) harvester. International Journal of Agricultural and Biological Engineering , 5(1):7{12.
Jin, Y., Liu, J., Wang, J., Xu, Z., and Yuan, Y. (2022). Far-near combined positioning of picking-point based
on depth data features for horizontal-trellis cultivated grape. Computers and Electronics in Agriculture ,
194:106791.Jun, J., Kim, J., Seol, J., Kim, J., and Son, H. I. (2021). Towards an ecient tomato harvesting robot: 3d
perception, manipulation, and end-eector. IEEE Access , 9:17631{17640.
Kalakrishnan, M., Chitta, S., Theodorou, E., Pastor, P., and Schaal, S. (2011). Stomp: Stochastic trajectory
optimization for motion planning. In 2011 IEEE international conference on robotics and automation ,
pages 4569{4574. IEEE.
King, J. E., Haustein, J. A., Srinivasa, S. S., and Asfour, T. (2015). Nonprehensile whole arm rearrangement
planning on physics manifolds. In 2015 IEEE International Conference on Robotics and Automation
(ICRA) , pages 2508{2515. IEEE.
Kitaev, N., Mordatch, I., Patil, S., and Abbeel, P. (2015). Physics-based trajectory optimization for grasping
in cluttered environments. In 2015 IEEE International Conference on Robotics and Automation (ICRA) ,
pages 3102{3109. IEEE.
Kitamura, S. and Oka, K. (2005). Recognition and cutting system of sweet pepper for picking robot in green-
house horticulture. In IEEE International Conference Mechatronics and Automation, 2005 , volume 4,
pages 1807{1812. IEEE.
Kondo, N., Monta, M., and Arima, S. (1998). Strawberry harvesting robot on hydroponic system. IFAC
Proceedings Volumes , 31(5):181{185.
Kondo, N., Nishitsuji, Y., Ling, P. P., and Ting, K. C. (1996). Visual feedback guided robotic cherry tomato
harvesting. Transactions of the ASAE , 39(6):2331{2338.
Lamb, N. and Chuah, M. C. (2018). A strawberry detection system using convolutional neural networks. In
2018 IEEE International Conference on Big Data (Big Data) , pages 2515{2520. IEEE.
Lee, B. and Rosa, U. (2006). Development of a canopy volume reduction technique for easy assessment and
harvesting of valencia citrus fruits. Transactions of the ASABE , 49(6):1695{1703.
Lehnert, C., English, A., McCool, C., Tow, A. W., and Perez, T. (2017). Autonomous sweet pepper
harvesting for protected cropping systems. IEEE Robotics and Automation Letters , 2(2):872{879.
Li, J., Tang, Y., Zou, X., Lin, G., and Wang, H. (2020). Detection of fruit-bearing branches and localization
of litchi clusters for vision-based harvesting robots. IEEE Access , 8:117746{117758.
Lili, W., Bo, Z., Jinwei, F., Xiaoan, H., Shu, W., Yashuo, L., Zhou, Q., and Chongfeng, W. (2017). De-
velopment of a tomato harvesting robot used in greenhouse. International Journal of Agricultural and
Biological Engineering , 10(4):140{149.
Liming, X. and Yanchao, Z. (2010). Automated strawberry grading system based on image processing.
Computers and Electronics in Agriculture , 71:S32{S39.
Ling, X., Zhao, Y., Gong, L., Liu, C., and Wang, T. (2019). Dual-arm cooperation and implementing for
robotic harvesting tomato using binocular vision. Robotics and Autonomous Systems , 114:134{143.
Liu, X., Chen, S. W., Aditya, S., Sivakumar, N., Dcunha, S., Qu, C., Taylor, C. J., Das, J., and Kumar,
V. (2018a). Robust fruit counting: Combining deep learning, tracking, and structure from motion. In
2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) , pages 1045{1052.
IEEE.
Liu, X., Zhao, D., Jia, W., Ji, W., Ruan, C., and Sun, Y. (2019). Cucumber fruits detection in greenhouses
based on instance segmentation. IEEE Access , 7:139635{139642.
Liu, Y.-P., Yang, C.-H., Ling, H., Mabu, S., and Kuremoto, T. (2018b). A visual system of citrus pick-
ing robot using convolutional neural networks. In 2018 5th international conference on systems and
informatics (ICSAI) , pages 344{349. IEEE.Luo, L., Wen, H., Lu, Q., Huang, H., Chen, W., Zou, X., and Wang, C. (2018). Collision-free path-planning
for six-dof serial harvesting robot based on energy optimal and articial potential eld. Complexity ,
2018.
Mandil, W. and Ghalamzan, A. (2022). Combining vision and tactile sensation for video prediction. preprint
arXiv:2205.09430 .
Mandil, W., Nazari, K., and Ghalamzan, A. (2022). Action conditioned tactile prediction: a case study on
slip prediction. Robotics: Science and Systems .
Manninen, P., Riihim aki, H., and Heli ovaara, M. (1995). Incidence and risk factors of low-back pain in
middle-aged farmers. Occupational medicine , 45(3):141{146.
Mghames, S. and Hanheide, M. (2022). Environment-aware interactive movement primitives for object
reaching in clutter. In 2022 IEEE 18th International Conference on Automation Science and Engineering
(CASE) , pages 493{498. IEEE.
Mghames, S., Hanheide, M., and Ghalamzan E., A. (2020). Interactive movement primitives: Planning
to push occluding pieces for fruit picking. In 2020 IEEE/RSJ International Conference on Intelligent
Robots and Systems (IROS) , pages 2616{2623.
Milder, J. C., Garbach, K., DeClerck, F. A., Driscoll, L., and Montenegro, M. (2019). An assessment of the
multi-functionality of agroecological intensication. Gates Open Res , 3(279):279.
M lotek, M., Kuta,  L., Stopa, R., and Komarnicki, P. (2015). The eect of manual harvesting of fruit on the
health of workers and the quality of the obtained produce. Procedia Manufacturing , 3:1712{1719.
Monta, M., Kondo, N., and Shibano, Y. (1995). Agricultural robot in grape production system. In Proceedings
of the 1995 IEEE International Conference on Robotics and Automation. Part 1 (of 3) , pages 2504{2509.
IEEE.
Mulla, D. and Khosla, R. (2016). Historical evolution and recent advances in precision farming. Soil-specic
farming precision agriculture , pages 1{35.
Nandi, C. S., Tudu, B., and Koley, C. (2014). Computer vision based mango fruit grading system. In
International Conference on Innovative Engineering Technologies (ICIET 2014) Dec , pages 28{29.
Nations, U. (2019). World population prospects 2019. Vol (ST/ESA/SE. A/424) Department of Economic
and Social Aairs: Population Division .
Nazari, K., Gandol, G., Talebpour, Z., Rajendran, V., Rocco, P., et al. (2023a). Deep functional predictive
control for strawberry cluster manipulation using tactile prediction. arXiv preprint arXiv:2303.05393 .
Nazari, K., Mandil, W., and Esfahani, A. M. G. (2023b). Proactive slip control by learned slip model and
trajectory adaptation. In Conference on Robot Learning , pages 751{761. PMLR.
Nazari, K., Mandill, W., Hanheide, M., and Esfahani, A. G. (2021). Tactile dynamic behaviour prediction
based on robot action. In Towards Autonomous Robotic Systems: 22nd Annual Conference, TAROS
2021, Lincoln, UK, September 8{10, 2021, Proceedings 22 , pages 284{293. Springer.
Oo, L. M. and Aung, N. Z. (2018). A simple and ecient method for automatic strawberry shape and size
estimation and classication. Biosystems engineering , 170:96{107.
Paraschos, A., Daniel, C., Peters, J., and Neumann, G. (2018). Using probabilistic movement primitives in
robotics. Autonomous Robots , 42(3):529{551.
Parsa, S., Debnath, B., Khan, M. A., et al. (2023). Autonomous strawberry picking robotic system
(robofruit). Journal of Field Robotics (preprint arXiv:2301.03947) .Paxton, C., Hager, G. D., Bascetta, L., et al. (2015). An incremental approach to learning generalizable robot
tasks from human demonstration. In 2015 IEEE international conference on robotics and automation
(ICRA) , pages 5616{5621. IEEE.
P erez-Borrero, I., Mar n-Santos, D., Geg undez-Arias, M. E., and Cort es-Ancos, E. (2020). A fast and
accurate deep learning method for strawberry instance segmentation. Computers and Electronics in
Agriculture , 178:105736.
Pierce, F. J. and Nowak, P. (1999). Aspects of precision agriculture. Advances in agronomy , 67:1{85.
Plebe, A. and Grasso, G. (2001). Localization of spherical fruits for robotic harvesting. Machine Vision and
Applications , 13(2):70{79.
Puttemans, S., Vanbrabant, Y., Tits, L., and Goedem e, T. (2016). Automated visual fruit detection for
harvest estimation and robotic harvesting. In 2016 sixth international conference on image processing
theory, tools and applications (IPTA) , pages 1{6. IEEE.
Qingchun, F., Wei, C., Jianjun, Z., and Xiu, W. (2014). Design of structured-light vision system for tomato
harvesting robot. International Journal of Agricultural and Biological Engineering , 7(2):19{26.
Qingchun, F., Wengang, Z., Quan, Q., Kai, J., and Rui, G. (2012). Study on strawberry robotic harvesting
system. In 2012 IEEE International Conference on Computer Science and Automation Engineering
(CSAE) , volume 1, pages 320{324. IEEE.
Rahnemoonfar, M. and Sheppard, C. (2017). Deep count: fruit counting based on deep simulated learning.
Sensors , 17(4):905.
Rajendra, P., Kondo, N., Ninomiya, K., Kamata, J., Kurita, M., Shiigi, T., Hayashi, S., Yoshida, H., and
Kohno, Y. (2009). Machine vision algorithm for robots to harvest strawberries in tabletop culture
greenhouses. Engineering in Agriculture, Environment and Food , 2(1):24{30.
Rajendran, V., Parsa, S., Parsons, S., and E, A. G. (2022). Peduncle gripping and cutting force for strawberry
harvesting robotic end-eector design. In 2022 4th International Conference on Control and Robotics
(ICCR) , pages 59{64.
Rajendran S, V. et al. (2023). Acoustic soft tactile skin (ast skin). arXiv preprint arXiv:2303.17355 .
Ratli, N., Zucker, M., Bagnell, J. A., and Srinivasa, S. (2009). Chomp: Gradient optimization techniques
for ecient motion planning. In 2009 IEEE international conference on robotics and automation , pages
489{494. IEEE.
Reed, J., Miles, S., Butler, J., Baldwin, M., and Noble, R. (2001). Ae|automation and emerging tech-
nologies: Automatic mushroom harvester development. Journal of Agricultural Engineering Research ,
78(1):15{23.
Ringdahl, O., Kurtser, P., and Edan, Y. (2019). Evaluation of approach strategies for harvesting robots:
Case study of sweet pepper harvesting. Journal of Intelligent & Robotic Systems , 95(1):149{164.
Sa, I., Ge, Z., Dayoub, F., Upcroft, B., Perez, T., and McCool, C. (2016). Deepfruits: A fruit detection
system using deep neural networks. Sensors , 16(8):1222.
Sanni, O., Bonvicini, G., Khan, M. A., L opez-Custodio, P. C., Nazari, K., et al. (2022). Deep movement
primitives: toward breast cancer examination robot. In Proceedings of the AAAI Conference on Articial
Intelligence , volume 36, pages 12126{12134.
Scarfe, A. J., Flemmer, R. C., Bakker, H., and Flemmer, C. L. (2009). Development of an autonomous
kiwifruit picking robot. In 2009 4th International Conference on Autonomous Robots and Agents , pages
380{384. IEEE.Schaal, S. (2006). Dynamic movement primitives-a framework for motor control in humans and humanoid
robotics. In Adaptive motion of animals and machines , pages 261{280. Springer.
Schuetz, C., Baur, J., Pfa, J., Buschmann, T., and Ulbrich, H. (2015). Evaluation of a direct optimiza-
tion method for trajectory planning of a 9-dof redundant fruit-picking manipulator. In 2015 IEEE
International Conference on Robotics and Automation (ICRA) , pages 2660{2666. IEEE.
Schulman, J., Duan, Y., Ho, J., Lee, A., Awwal, I., Bradlow, H., Pan, J., Patil, S., Goldberg, K., and
Abbeel, P. (2014). Motion planning with sequential convex optimization and convex collision checking.
The International Journal of Robotics Research , 33(9):1251{1270.
Sep uLveda, D., Fern andez, R., Navas, E., Armada, M., and Gonz alez-De-Santos, P. (2020). Robotic
aubergine harvesting using dual-arm manipulation. IEEE Access , 8:121889{121904.
Shigehiko, H., Katsunobu, G., Yukitsugu, I., and Itsuo, T. (2001). Development of a harvesting end-eector
for eggplants. Journal of Society of High technology in Agriculture , 13(2):97{103.
Shiigi, T., Kurita, M., Kondo, N., Ninomiya, K., Rajendra, P., Kamata, J., Hayashi, S., Kobayashi, K.,
Shigematsu, K., and Kohno, Y. (2008). Strawberry harvesting robot for fruits grown on table top culture.
In2008 Providence, Rhode Island, June 29{July 2, 2008 , page 1. American Society of Agricultural and
Biological Engineers.
Shyam, R. A., Lightbody, P., Das, G., Liu, P., Gomez-Gonzalez, S., and Neumann, G. (2019). Improving
local trajectory optimisation using probabilistic movement primitives. In 2019 IEEE/RSJ International
Conference on Intelligent Robots and Systems (IROS) , pages 2666{2671. IEEE.
Silwal, A., Davidson, J. R., Karkee, M., Mo, C., Zhang, Q., and Lewis, K. (2017). Design, integration, and
eld evaluation of a robotic apple harvester. Journal of Field Robotics , 34(6):1140{1159.
Tafuro, A., Adewumi, A., Parsa, S., Amir, G. E., and Debnath, B. (2022a). Strawberry picking point local-
ization ripeness and weight estimation. In 2022 International Conference on Robotics and Automation
(ICRA) , pages 2295{2302. IEEE.
Tafuro, A., Debnath, B., Zanchettin, A. M., and Ghalamzan, E. A. (2022b). dpmp-deep probabilistic
motion planning: A use case in strawberry picking robot. In 2022 IEEE/RSJ International Conference
on Intelligent Robots and Systems (IROS) , pages 8675{8681. IEEE.
Tang, X., Zhang, T., Liu, L., Xiao, D., and Chen, Y. (2009). A new robot system for harvesting cucumber.
In2009 Reno, Nevada, June 21-June 24, 2009 , page 1. American Society of Agricultural and Biological
Engineers.
Tang, Y.-C., Wang, C., Luo, L., Zou, X., et al. (2020). Recognition and localization methods for vision-based
fruit picking robots: a review. Frontiers in Plant Science , 11:510.
Tao, Y. and Zhou, J. (2017). Automatic apple recognition based on the fusion of color and 3d feature for
robotic fruit picking. Computers and electronics in agriculture , 142:388{396.
Tekden, A. E., Erdem, A., Erdem, E., Asfour, T., and Ugur, E. (2021). Object and relation centric repre-
sentations for push eect prediction. arXiv preprint arXiv:2102.02100 .
Tian, Y., Yang, G., Wang, Z., Wang, H., Li, E., and Liang, Z. (2019). Apple detection during dierent
growth stages in orchards using the improved yolo-v3 model. Computers and electronics in agriculture ,
157:417{426.
Tiefeng, S., Mingyu, D., Guanjun, B., Libin, Z., and Qinghua, Y. (2015). Fruit harvesting continuum ma-
nipulator inspired by elephant trunk. International Journal of Agricultural and Biological Engineering ,
8(1):57{63.
Van Henten, E., Hemming, J., Van Tuijl, B., Kornet, J., and Bontsema, J. (2003a). Collision-free motion
planning for a cucumber picking robot. Biosystems Engineering , 86(2):135{144.Van Henten, E., Van Tuijl, B. v., Hemming, J., Kornet, J., Bontsema, J., and Van Os, E. (2003b). Field
test of an autonomous cucumber picking robot. Biosystems engineering , 86(3):305{313.
Van Henten, E., Van't Slot, D., Hol, C., and Van Willigenburg, L. (2006). Optimal design of a cucumber
harvesting robot. In Proceedings of CIGR EurAgEng/VDI-MEG, FAO World Congress .
Van Henten, E. J., Hemming, J., Van Tuijl, B., Kornet, J., Meuleman, J., Bontsema, J., and Van Os, E.
(2002). An autonomous robot for harvesting cucumbers in greenhouses. Autonomous robots , 13(3):241{
258.
Wang, C., Tang, Y., Zou, X., SiTu, W., and Feng, W. (2017a). A robust fruit image segmentation algorithm
against varying illumination for vision system of fruit harvesting robot. Optik , 131:626{631.
Wang, C., Zou, X., Tang, Y., Luo, L., and Feng, W. (2016). Localisation of litchi in an unstructured
environment using binocular stereo vision. Biosystems Engineering , 145:39{51.
Wang, X., Kang, H., Zhou, H., Au, W., and Chen, C. (2022). Geometry-aware fruit grasping estimation for
robotic harvesting in apple orchards. Computers and Electronics in Agriculture , 193:106716.
Wang, Z., Walsh, K., and Koirala, A. (2019). Mango fruit load estimation using a video based mango
yolo|kalman lter|hungarian algorithm method. Sensors , 19(12):2742.
Wang, Z., Walsh, K. B., and Verma, B. (2017b). On-tree mango fruit size estimation using rgb-d images.
Sensors , 17(12):2738.
Xiong, J., He, Z., Lin, R., Liu, Z., Bu, R., Yang, Z., Peng, H., and Zou, X. (2018a). Visual positioning
technology of picking robots for dynamic litchi clusters with disturbance. Computers and electronics in
agriculture , 151:226{237.
Xiong, Y., From, P. J., and Isler, V. (2018b). Design and evaluation of a novel cable-driven gripper with per-
ception capabilities for strawberry picking robots. In 2018 IEEE International Conference on Robotics
and Automation (ICRA) , pages 7384{7391. IEEE.
Xiong, Y., Ge, Y., and From, P. J. (2020a). An obstacle separation method for robotic picking of fruits in
clusters. Computers and Electronics in Agriculture , 175:105397.
Xiong, Y., Ge, Y., and From, P. J. (2021). An improved obstacle separation method using deep learning for
object detection and tracking in a hybrid visual control loop for fruit picking in clusters. Computers
and Electronics in Agriculture , 191:106508.
Xiong, Y., Ge, Y., Grimstad, L., and From, P. J. (2019a). An autonomous strawberry-harvesting robot:
Design, development, integration, and eld evaluation. Journal of Field Robotics .
Xiong, Y., Ge, Y., Grimstad, L., and From, P. J. (2020b). An autonomous strawberry-harvesting robot:
Design, development, integration, and eld evaluation. Journal of Field Robotics , 37(2):202{224.
Xiong, Y., Peng, C., Grimstad, L., From, P. J., and Isler, V. (2019b). Development and eld evaluation of
a strawberry harvesting robot with a cable-driven gripper. Computers and electronics in agriculture ,
157:392{402.
Yaguchi, H., Nagahama, K., Hasegawa, T., and Inaba, M. (2016). Development of an autonomous tomato
harvesting robot with rotational plucking gripper. In 2016 IEEE/RSJ International Conference on
Intelligent Robots and Systems (IROS) , pages 652{657. IEEE.
Yamamoto, S., Hayashi, S., Yoshida, H., and Kobayashi, K. (2014). Development of a stationary robotic
strawberry harvester with a picking mechanism that approaches the target fruit from below. Japan
Agricultural Research Quarterly: JARQ , 48(3):261{269.
Yamamoto, S., Hayashi, S., Yoshida, H., Kobayashi, K., and Shigematsu, K. (2007). Development of an
end eector for a strawberry-harvesting robot. In International Symposium on High Technology for
Greenhouse System Management: Greensys2007 801 , pages 565{572.Yang, Y., Pan, J., and Wan, W. (2019). Survey of optimal motion planning. IET Cyber-systems and Robotics ,
1(1):13{19.
Yasukawa, S., Li, B., Sonoda, T., and Ishii, K. (2017). Development of a tomato harvesting robot. In
Proceedings of the 2017 International Conference on Articial Life and Robotics, Miyazaki, Japan ,
pages 19{22.
Yau, W.-Y. and Wang, H. (1996). Robust hand-eye coordination. Advanced Robotics , 11(1):57{73.
Ye, Y., Gandhi, D., Gupta, A., and Tulsiani, S. (2020). Object-centric forward modeling for model predictive
control. In Conference on Robot Learning , pages 100{109. PMLR.
Yu, K.-T., Bauza, M., Fazeli, N., and Rodriguez, A. (2016). More than a million ways to be pushed. a
high-delity experimental dataset of planar pushing. In 2016 IEEE/RSJ international conference on
intelligent robots and systems (IROS) , pages 30{37. IEEE.
Yu, Y., Zhang, K., Liu, H., Yang, L., and Zhang, D. (2020). Real-time visual localization of the picking
points for a ridge-planting strawberry harvesting robot. IEEE Access , 8:116556{116568.
Yu, Y., Zhang, K., Yang, L., and Zhang, D. (2019). Fruit detection for strawberry harvesting robot in non-
structural environment based on mask-rcnn. Computers and Electronics in Agriculture , 163:104846.
Yuan, W., Stork, J. A., Kragic, D., Wang, M. Y., and Hang, K. (2018). Rearrangement with nonprehensile
manipulation using deep reinforcement learning. In 2018 IEEE International Conference on Robotics
and Automation (ICRA) , pages 270{277. IEEE.
Zeng, X., Miao, Y., Ubaid, S., Gao, X., and Zhuang, S. (2020). Detection and classication of bruises of
pears based on thermal images. Postharvest Biology and Technology , 161:111090.
Zhang, L., Jia, J., Gui, G., Hao, X., Gao, W., and Wang, M. (2018). Deep learning based improved
classication system for designing tomato harvesting robot. IEEE Access , 6:67940{67950.
Zhao, Y., Gong, L., Huang, Y., and Liu, C. (2016a). A review of key techniques of vision-based control for
harvesting robot. Computers and Electronics in Agriculture , 127:311{323.
Zhao, Y., Gong, L., Liu, C., and Huang, Y. (2016b). Dual-arm robot design and testing for harvesting
tomato in greenhouse. IFAC-PapersOnLine , 49(16):161{165.
Zhong, Z., Xiong, J., Zheng, Z., Liu, B., Liao, S., Huo, Z., and Yang, Z. (2021). A method for litchi picking
points calculation in natural environment based on main fruit bearing branch detection. Computers and
Electronics in Agriculture , 189:106398.
Zhuang, J., Hou, C., Tang, Y., He, Y., Guo, Q., Zhong, Z., and Luo, S. (2019). Computer vision-based
localisation of picking points for automatic litchi harvesting applications towards natural scenarios.
Biosystems Engineering , 187:1{20.
Zou, X., Zou, H., and Lu, J. (2012). Virtual manipulator-based binocular stereo vision positioning system
and errors modelling. Machine Vision and Applications , 23(1):43{63.