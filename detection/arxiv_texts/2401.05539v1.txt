A Bilevel Optimization Method for Inverse Mean-Field Games∗
Jiajia Yu†Quan Xiao‡Tianyi Chen§Rongjie Lai¶
Abstract
In this paper, we introduce a bilevel optimization framework for addressing inverse mean-field games,
alongside an exploration of numerical methods tailored for this bilevel problem. The primary benefit
of our bilevel formulation lies in maintaining the convexity of the objective function and the linearity
of constraints in the forward problem. Our paper focuses on inverse mean-field games characterized by
unknown obstacles and metrics. We show numerical stability for these two types of inverse problems.
More importantly, we, for the first time, establish the identifiability of the inverse mean-field game with
unknown obstacles via the solution of the resultant bilevel problem. The bilevel approach enables us to
employ an alternating gradient-based optimization algorithm with a provable convergence guarantee. To
validate the effectiveness of our methods in solving the inverse problems, we have designed comprehensive
numerical experiments, providing empirical evidence of its efficacy.
1 Introduction
Mean-field games study the Nash Equilibrium in a non-cooperative game with infinitely many agents. In
the game, each agent aims to minimize a combination of dynamic cost, interaction cost, and terminal cost
by controlling its own state trajectory. At the Nash Equilibrium, the agents cannot unilaterally reduce their
costs. The theory is proposed in [20, 11, 10] and has attracted increasing attention since then.
In most existing works, knowing the cost functions is required to solve mean-field games. However, in
practice, these cost functions are not always easy to obtain. In contrast, the state distribution, the strategies
of agents, and sometimes the value function at the Nash Equilibrium can be observed. Thus, a natural
question arises: Can we learn the cost functions from the Nash Equilibrium? We refer to this as the inverse
mean-field game problem, and to the original one as the forward problem.
Unlike the forward problem, relatively few studies focus on inverse mean-field games. [14] derives two
traffic flow models as the solutions of non-viscous mean-field games. [7] reconstructs the underlying metric
in the dynamic cost and the kernel in the non-local interaction cost from the possibly noisy observation
of agent distribution and strategy. [6] learns the running cost from population density and strategy on a
given boundary. [22, 23, 24, 27] establish the theoretical unique identifiability result for a general class of
mean-field games, mean-field game boundary problems and multipopulation mean-field games, where infinite
pairs of training data are required in the proof. Following [17], a series of works [15, 16, 18, 19, 12] study
the stability and uniqueness of inverse mean-field game through Carleman estimates.
In this paper, we study a typical class of forward problems, the potential mean-field games. Applications
like crowd motion [28] and generative models [21] have the formulations of potential mean-field games. In a
potential mean-field game, the Nash Equilibrium is a pair of agent distribution ρand strategy mminimizing
a cost Lwhich consists of the dynamic cost L, the interaction cost FIand the terminal cost FT, under a
constraint C(µ0) for density and strategy evolution dynamics:
(ρ∗,m∗) := argmin
ρ,m∈C(µ0)L(ρ,m;L,FI,FT). (1)
∗This work is suppoted in part by NSF DMS-2134168.
†J. Yu (jiajia.yu@duke.edu) is with the Department of Mathematics, Duke University.
‡Q. Xiao (xiaoq5@rpi.edu) is with the Department of Electrical, Computer, and Systems Engineering, Rensselaer Polytechnic
Institute.
§T. Chen (chent18@rpi.edu) is with the Department of Electrical, Computer, and Systems Engineering, Rensselaer Poly-
technic Institute.
¶R Lai (lairj@purdue.edu) is with the Department of Mathematics, Purdue University.
1arXiv:2401.05539v1  [math.OC]  10 Jan 2024The inverse problem is to identify L,FIorFTgiven ( ρ∗,m∗). Typical choices of L,FIandFTmake (1) a
(strongly) convex optimization problem with linear constraint. Taking Lunknown and FI,FTknown as an
example, we thus consider the following bilevel optimization problem
min
LD((ρ∗,m∗),(ρ(L),m(L))) +R(L)
s.t. (ρ(L),m(L)) := argmin
ρ,m∈C(µ0)L(ρ,m;L,FI,FT).(2)
HereDis a fidelity term and Ris a regularity term. Existing works [7, 6] use the nonlinear and nonconvex
PDE optimality conditions as constraints. Consequently, achieving a theoretical convergence guarantee
is challenging. In contrast, we propose a bilevel formulation for inverse mean-field games, which directly
incorporates the forward problem as the constraint. This bilevel formulation maintains the desirable convex-
linear structure of the forward problem (the lower-level problem) and enables us to adopt a gradient-based
bilevel optimization algorithm [5, 29, 13, 9, 30] to address the inverse problem (2). Moreover, leveraging this
convex-linear structure, we have developed a convergence result, demonstrating that our algorithm converges
to the stationary point of the bilevel problem.
A common question in inverse mean-field games concerns the stability and unique identifiability of the
unknown parameter or function relative to the data. In our setting, we ask whether it is possible to uniquely
recover the cost functions from a single pair of observations ( ρ∗,m∗) and whether the recovered cost func-
tion continuously depends on these observations. This setup differs significantly from the theoretical work
discussed in [22, 23]. In those studies, the authors demonstrate that if the interaction and terminal costs are
local, holomorphic in ρ(x, t), and meet zero admissibility conditions, then it is possible to uniquely recover
them from infinitely many observations either throughout the full domain or on its boundary. However,
in our case, the cost function for a crowd motion model typically does not satisfy the zero admissibility
condition. Moreover, obtaining infinitely many observations is not feasible in practice. In this work, we
establish stability results for a general model and unique identifiability results for crowd motion models at
a discrete level. Specifically, for a general model, we prove that our model can achieve a close solution to
the ground truth with noisy observation, and for the crowd motion model, we prove that only one pair of
complete observation ( ρ∗,m∗) is sufficient to uniquely recover the obstacle function, up to a constant. Thus,
compared to the requirement of infinitely many observations in [22], our result is more practical and offers
insights into what constitutes an effective observation for accurately recovering the ground truth.
Contribution: We summarize our contributions as follows.
1. We propose a bilevel optimization framework for modeling inverse mean-field games.
2. We study a general model of mean-field games and show that the unknown cost parameters continuously
depend on the observation of the Nash Equilibrium.
3. For the crowd motion model, we prove that up to a constant, the ground truth obstacle function is the
unique minimizer to the bilevel optimization problem of the inverse mean-field game.
4. We apply an alternating gradient-based bilevel optimization algorithm to solve inverse mean-field games
and prove the algorithm converges to the stationary point of the bilevel problem.
5. We implement the algorithm and illustrate the effectiveness of our model and algorithm with compre-
hensive numerical experiments.
Organization: The paper is organized as follows. In section 2, we briefly review the potential mean-
field games and provide two examples of forward mean-field game models whose inverse problem will be
addressed in this paper. In section 3, we provide the bilevel optimization model for inverse mean-field games
and discretize the model. We also state the stability of both models and the unique identifiability of the
inverse crowd motion model and prove them in section 5. In section 4, we present the algorithm to solve
our bilevel model for inverse mean-field games and prove the convergence in section 5. In section 6, we
demonstrate our model and algorithm with experiments. Finally, we conclude our work in section 7.
22 A Review of Potential Mean-Field Games
In this section, we first review potential mean-field games and their optimality conditions [20, 11, 10]. Then
we present two example problems that we would like to solve in the inverse problem setup.
Consider a problem defined spatially on Ω ⊂Rdand temporally on [0 ,1].ρ: Ω×[0,1]→Ris the state
density. v: Ω×[0,1]→Rdrepresents the velocity (control) field of the agents and m:=ρvthe flux. A
potential mean-field game typically has the following formulation:
min
(ρ,m)∈C(µ0)L(ρ,m) :=Z1
0Z
Ωρ(x, t)L
x,m(x, t)
ρ(x, t)
dxdt+Z1
0FI(ρ(·, t))dt+FT(ρ(·,1)) (3)
with the constraint set being
C(µ0) :={(ρ,m) :∂tρ+∇ ·m= 0, ρ(·,0) = µ0,m·n= 0 for x∈∂Ω, ρ(·,·)≥0}. (4)
where nis the normal direction on the boundary ∂Ω. It is clear to see that any pair of ( ρ,m)∈ C(µ0)
satisfies mass conservation and zero boundary flux condition with the initial density of ρbeing µ0. In this
objective function, L: Ω×Rd→Rmodels the dynamic cost, FI:P(Ω)→Rthe interaction cost and
FT:P(Ω)→Rthe terminal cost.
To derive the optimality condition of (3), we introduce the Lagrangian multiplier ϕand formulate the
Lagrangian
A(ρ,m, ϕ) :=L(ρ,m)−Z1
0Z
Ωϕ(x, t) (∂tρ(x, t) +∇ ·m(x, t)) dxdt
=L(ρ,m) +Z1
0Z
Ωρ(x, t)∂tϕ(x, t)dxdt+Z1
0Z
Ωm(x, t)· ∇ϕ(x, t)dxdt
−Z
Ωϕ(x,1)ρ(x,1)dx+Z
Ωϕ(x,0)µ0(x)dx,(5)
where the second equality is due to integration by part. The optimal solution solves the saddle point problem
min
ρ≥0,mmax
ϕA(ρ,m, ϕ). (6)
When L(x,v) is convex in v, let the Legendre transformation of Lbe
H: Ω×Rd→R,(x,p)7→sup
v{−⟨p,v⟩ −L(x,v)}. (7)
Then if ρ >0, the optimality condition of (3) is


−∂tϕ(x, t) +H(x,∇ϕ(x, t)) =δFI(ρ)
δρ(x), ϕ(x,1) =δFT(ρ)
δρ(x),
∂tρ(x, t)− ∇ · (ρ(x, t)∂pH(x,∇ϕ(x, t))) = 0 , ρ(·,0) = µ0.(8)
We use this forward-backward PDE system to explore the properties of the inverse problem later.
In this paper, we focus on the following two problems.
Problem 2.1 (Crowd motion with obstacle) .A common example comes from crowd motion [28], whose
formulation is
min
(ρ,m)∈C(µ0)L(ρ,m;b) :=Z1
0Z
Ω∥m(x, t)∥2
2
2ρ(x, t)dxdt+Z1
0Z
Ωρ(x, t)b(x)dxdt
+γIZ1
0Z
Ωρ(x, t) logρ(x, t)dxdt+γTZ
Ωρ(x, t) (log ρ(x, t)−logµ1(x)) dx.(9)
Here the terminal cost is the KL divergence FT(ρ(·,1)) =R
Ωρ(x, t) (log ρ(x, t)−logµ1(x)) dxwhich aims
to match the terminal density ρ(·,1) to the desired density µ1. The interaction cost contains two parts.
3The entropy termR
Ωρ(x, t) logρ(x, t)dxpenalizes the aggregation of the density. And the obstacle termR
Ωρ(x, t)b(x)dxpenalizes the mass going through the obstacle xwith larger value of b(x). With the same
initial density µ0, different obstacle functions lead to different Nash Equilibrium. Assuming that we know
everything in the objective function (9) except the obstacle function b, we aim to recover bfrom observations
of the equilibrium ( ρ,m).
Problem 2.2 (Non-Euclidean metric) .It is also common to consider mean-field games on spaces with non-
Euclidean metrics. If at each x∈Ω,Ω⊂Rd, there is a positive definite matrix g(x)∈Sd
++indicating the
metric, then the mean-field game problem takes the form
min
(ρ,m)∈C(µ0)L(ρ,m;g) :=Z1
0Z
Ωm(x, t)⊤g(x)m(x, t)
2ρ(x, t)dxdt
+γIZ1
0Z
Ωρ(x, t) logρ(x, t)dxdt+γTZ
Ωρ(x, t) (log ρ(x, t)−logµ1(x)) dx.(10)
We also work on solving the metric gfrom the observations of the equilibrium ( ρ,m), assuming other terms
in (10) are known.
In summary, we are interested in the mean-field game problem with the objective function
L(ρ,m;g, b) :=Z1
0Z
Ωm(x, t)⊤g(x)m(x, t)
2ρ(x, t)dxdt+Z1
0Z
Ωρ(x, t)b(x)dxdt
+γIZ1
0Z
Ωρ(x, t) logρ(x, t)dxdt+γTZ
Ωρ(x,1) (log ρ(x,1)−logµ1(x)) dx.(11)
We write L(ρ,m;g) when b≡0 and L(ρ,m;b) when g≡Id. With ρ >0, the optimality condition for the
problem
min
(ρ,m)∈C(µ0)L(ρ,m;g, b), (12)
is

−∂tϕ(x, t) +1
2(∇ϕ(x, t))⊤(g(x))−1∇ϕ(x, t) =γI(logρ(x, t) + 1) + b(x),
ϕ(x,1) = γT(logρ(x, t)−logµ1(x) + 1) ,
∂tρ(x, t)− ∇ · 
ρ(x, t)(g(x))−1∇ϕ(x, t)
= 0, ρ(·,0) = µ0.(13)
We call the potential mean-field games (3), as well as (9),(10), the forward problem. In this paper, we aim
to learn the unknown variables b, gfrom one or a set of observations of the Nash Equilibrium {(eρn,emn)}N
n=1
that solve the forward problems, and we name this the inverse problem. Note that the forward problem has
a convex objective function and linear constraint, while the optimality condition is nonlinear and nonconvex.
To preserve the nice convex-linear structure of the forward problem, we formulate the inverse mean-field
game as a bilevel optimization problem and treat the forward problem as the constraint.
3 A Bilevel Formulation of Inverse Mean-Field Games
In this section, we first review the general formulation of a bilevel optimization problem, then provide the
bilevel formulation of inverse mean-field games, as well as two concrete inverse problems that we would like
to solve in this work. After that, we discretize the model for numerical implementation.
3.1 Bilevel Formulation
The general formulation of a bilevel optimization problem is
min
ξ∈Ξu(ξ) :=U(η∗(ξ);ξ)
where η∗(ξ) = argmin
η∈HL(η;ξ).(14)
4Here we consider linear constraint set H={η|Aη=c}and convex set Ξ, where A∈Rdc×dη, c∈Rdc.
dc< dη. The optimization problem over Uis referred to as the upper-level problem and that over Las the
lower-level problem. We formulate our inverse problems as bilevel optimization problems, with the upper-
level objective being a combination of fidelity Dρ,Dmand regularity R, and the lower-level problem being
the forward problem.
min
L∈CL,FI∈CFIU((ρ,m),(eρ,em);L,FI) := (Dρ(ρ,eρ) +Dm(m,em)) +R(L,FI)
s.t. (ρ,m) := argmin
(ρ,m)∈C(µ0)L(ρ,m;L,FI).
The dynamic cost Land interaction cost functional FIare the upper-level variables and the density-flux
pair ( ρ,m) is the lower-level variable. For convenience, we choose Dρ(ρ,eρ) =1
2R1
0R
Ω(ρ(x, t)−eρ(x, t))2dxdt
andDρ(m,em) =1
2R1
0R
Ω∥m(x, t)−em(x, t)∥2
2dxdt
We formulate the inverse problems of problem 2.1 and 2.2 as follows.
Problem 3.1 (The inverse problem of crowd motion (problem 2.1)) .Let the regularity be R(b) = 0. The
inverse problem of (11) is
min
b∈CbDρ(ρ,eρ) +Dm(m,em)
s.t. (ρ,m) := argmin
(ρ,m)∈C(µ0)L(ρ,m;b).(15)
Here (eρ,em) = argmin(ρ,m)∈C(µ0)L(ρ,m;eb) are the observed data with ground truth eb. Notice that for any
constant c∈R, if (eρ,em) minimizes L(ρ,m;eb), then ( eρ,em) also minimizes L(ρ,m;eb+c). To remove the
ambiguity, we restrict our focus to obstacle functions with zero integral, i.e.
Cb:=
b:Z
Ωb(x)dx= 0
. (16)
Ideally, we expect projCb(eb) to be the unique minimizer of the bilevel problem (15). We prove this unique
identifiability property for the discretization of (15) in section 5.
Problem 3.2 (The inverse problem of unknown metric (problem 2.2)) .Similarly, we have the bilevel for-
mulation to recover the metric egfrom the data ( eρ,em) = argmin
(ρ,m)∈C(µ0)L(ρ,m;eg).
min
g∈CgDρ(ρ,eρ) +Dm(m,em) +R(g)
s.t. (ρ,m) := argmin
(ρ,m)∈C(µ0)L(ρ,m;g).(17)
To make sure that ginduces a metric on Ω, we set the constraint of gas
Cg:={g: Ω→Sd
++:g(x) are positive definite matrices ,∀x∈Ω}. (18)
For one observation, if the density is zero in an open set, it means almost no players pass the region and it
is impossible to obtain the exact information in that region. However multiple observations may complement
the missing information, and therefore it is meaningful to consider the following inverse MFG with multiple
observations.
Problem 3.3 (The inverse problem of unknown metric (problem 2.2) with multiple observations) .Suppose
that we have multiple observations of the Nash Equilibrium with a given egfrom different initial densities
µn
0, n= 1,···, N, i.e. (eρn,emn) = argmin
(ρ,m)∈C(µn
0)L(ρ,m;eg) for n= 1,2,···, N. Then we can solve the following
bilevel optimization problem to recover the true metric.
min
g∈CgNX
n=1(Dρ(ρn,eρn) +Dm(mn,emn)) +R(g)
s.t.{(ρn,mn)}N
n=1:= argmin
(ρn,mn)∈C(µn
0)NX
n=1L(ρn,mn;g).(19)
5The lower-level is equivalent to a concatenation of Nforward problems since ( ρn,mn) are independent.
3.2 Discretization
We conduct numerical experiments on Rdwith d= 1,2. Taking d= 2 as an example, we let Ω = [0 ,1]×[0,1]
and the space-time joint domain be [0 ,1]3, and we write m= (mx, my). We follow the discretization in
[31], with which the discrete optimizer is consistent with the continuous optimizer under certain regularity
conditions. To be precise, we equally divide [0 ,1] into nx, ny, ntparts, and each cube is of size ∆ x∆y∆t, with
∆x=1
nx,∆y=1
ny,∆t=1
nt.Letxi= (i−1
2)∆x, yi= (i−1
2)∆y, ti= (i−1
2)∆t, and ( f)ixiyitapproximates
function fon points ( xix, yiy, tit). Similarly, ( f)ix,iy≈f(xix, yiy). We define Gρ,GmxandGmyas the sets
of grid point indices on t-,x- and y-staggered grids, respectively, where
Gρ:={(ix, iy, it+1
2) :ix= 1,···, nx, iy= 1,···, ny, it= 1,···, nt},
Gmx:={(ix+1
2, iy, it) :ix= 1,···, nx−1, iy= 1,···, ny, it= 1,···, nt},
Gmy:={(ix, iy+1
2, it) :ix= 1,···, nx, iy= 1,···, ny−1, it= 1,···, nt}.
Then we approximate the function ρ, mxandmyont-,x- and y-staggered grids by ρGρ, mx
Gmxandmy
Gmy, re-
spectively, i.e. ρGρ:={(ρ)i}i∈Gρ∈Rnxnynt,mx
Gmx={(mx)i}i∈Gmx∈R(nx−1)nyntandmy
Gmy={(my)i}i∈Gmy∈
Rnx(ny−1)nt. We denote Gm:=Gmx× Gmyas the concatenation of Gmx,GmyandmGm:={mx
Gmx, my
Gmy}
as the concatenation of mx
Gmx, my
Gmy. We will omit the under scripts of grids wherever there is no ambiguity
according to context. The left part of Figure 1 illustrates the staggered grids and the corresponding ρ, mx
ford= 1.
We define the inner products on the staggered grids as
⟨ρ1, ρ2⟩Gρ:= ∆x∆y∆tX
i∈Gρ(ρ1)i(ρ2)i,
⟨mx
1, mx
2⟩Gmx:= ∆x∆y∆tX
i∈Gmx(mx
1)i(mx
2)i,
⟨my
1, my
2⟩Gmy:= ∆x∆y∆tX
i∈Gmy(my
1)i(my
2)i,
and denote their induced norm as ∥·∥Gρ,∥·∥Gmxand∥·∥Gmy. Based on these, we approximate the discrepancy
between lower-level minimizer and observed data Dρ,Dmby the sum of element-wise differences on grids
DGρ,DGm,
DGρ(ρ,eρ) :=1
2∥ρ−eρ∥2
Gρ
DGm(m,em) :=1
2∥mx−emx∥2
Gmx+1
2∥my−emy∥2
Gmy.(20)
To compute the objective function, we consider the central grid (see the right plot in Figure 1)
Gϕ:={(ix, iy, it) :ix= 1,···, nx, iy= 1,···, ny, it= 1,···, nt}.
We define the inner product and induced norm on the central grid similarly and denote them as ⟨·,·⟩Gϕand
∥·∥Gϕ. With the interpolation operators, ρ=It(ρ;µ0),mx=Ix(mx),my=Iy(my) meet on the central grid
points:
(ρ)ixiyit= (It(ρ;µ0))ixiyit:=

1
2
(µ0)ix,iy+ (ρ)ix,iy,it+1
2
, i t= 1,
1
2
(ρ)ix,iy,it−1
2+ (ρ)ix,iy,it+1
2
, it= 2,···, nt.
(mx)ixiyit= (Ix(mx))ixiyit:=

1
2(mx)ix+1
2,iy,it, i x= 1,
1
2
(mx)ix−1
2,iy,it+ (mx)ix+1
2,iy,it
, ix= 2,···, nx−1,
1
2(mx)ix−1
2,iy,it, i x=nx.
6Figure 1: Illustrations of the staggered (left) and central (right) grids.
(my)ixiyit= (Iy(my))ixiyit:=

1
2(my)ix,iy+1
2,it, i y= 1,
1
2
(my)ix,iy−1
2,it+ (my)ix,iy+1
2,it
, iy= 2,···, ny−1,
1
2(my)ix,iy−1
2,it, i y=ny.
Here, the definition of mxonix= 1, nxandmyoniy= 1, nyare consistent with the zero-flux bound-
ary condition in the continuous setting. The objective functions of the forward problem can therefore be
approximated by
LG(ρ,m;g, b) := ∆ x∆y∆tX
i∈Gϕ 
(m)⊤
i(g)ix,iy(m)i
2 (ρ)i+γI(ρ)ilog((ρ)i)!
+ ∆x∆y∆tX
i∈Gρ(ρ)i(b)ix,iy
+γT∆x∆ynxX
ix=1nyX
iy=1(ρ)ix,iy,nt+1
2
log(ρ)ix,iy,nt+1
2−log(µ1)ix,iy
.(21)
where m={mx, my}, (m)⊤
ixiyit:= (( mx)ixiyit,(my)ixiyit) and the subscript of LGindicates the cost is
defined on the discrete space. Similar to the continuous notation, we write LG(ρ,m;g) when b=0and
LG(ρ,m;b) when g≡1 (d= 1) or g≡I2(d= 2).
With this discretization, LG(ρ,m;g, b) preserves the following properties on ( ρ,m) from the continuous
setting.
Lemma 3.4. ForLG(ρ,m;g, b)defined on (ρGρ, mx
Gmx, my
Gmy)∈Rnxnynt×R(nx−1)nynt×Rnx(ny−1)ntwith
min
i∈Gρ(ρ)i>0, the following statements hold:
1. If γI, γT≥0andgix,iyis positive definite for all ix, iy, then LG(ρ,m;g, b)is convex in ρ,m.
2. In addition to 1, if we restrict the domain to ρwith min
i∈Gρ(ρ)i≥cρ>0,mxwith max
i∈Gmx(|mx
i|)≤cm, and
mywith max
i∈Gmy(|my
i|)≤cm, then LG(ρ,m;g, b)is Lipschitz smooth in ρ,m.
3. In addition to 1,2, if we further restrict the domain to ρ∈Rnxnyntwith max
i∈Gρ(ρ)i≤cρ, then for any
γI, γT>0,LG(ρ,m;g, b)is strongly convex in ρ,m.
We postpone the proof of the lemma in section 5 for better readability. The Lipschitz smoothness and
strong convexity of the lower-level objective are important to guarantee the convergence of our alternating
gradient algorithm, as detailed later in section 4.
7Following the nature of the staggered grid, we choose a central difference scheme to approximate the
differential operators.
(Dt(ρ;µ0))ixiyit:=

1
∆t
(ρ)ix,iy,it+1
2−(µ0)ix,iy
, i t= 1,
1
∆t
(ρ)ix,iy,it+1
2−(ρ)ix,iy,it−1
2
, it= 2,···, nt.
(Dx(mx))ixiyit:=

1
∆x(mx)ix+1
2,iy,it, i x= 1,
1
∆x
(mx)ix+1
2,iy,it−(mx)ix−1
2,iy,it
, ix= 2,···, nx−1,
−1
∆x(mx)ix−1
2,iy,it, i x=nx.
(Dy(my))ixiyit:=

1
∆y(my)ix,iy+1
2,it, i y= 1,
1
∆y
(my)ix,iy+1
2,it−(my)ix,iy−1
2,it
, iy= 2,···, ny−1,
−1
∆y(my)ix,iy−1
2,it, i y=ny.
Again, the definitions of Dx, Dyonix= 1, nx, iy= 1, ny, respectively, are consistent with the zero-flux
boundary condition. The discrete constraint set is
CG(µ0) :={(ρ,m) :Dt(ρ;µ0) +Dx(mx) +Dy(my) =0}. (22)
Based on the above notations, we restate the inverse problems 3.1 and 3.2 in the discretized space. We
intentionally write down the problems for more general cases with multiple pairs of training data as they
will reduce to the case with a single pair data by chosing N= 1.
Problem 3.5 (The discretization of the inverse crowd motion problem 3.1) .The discretization of (15) has
the following formulation
min
b∈CG,bNX
n=1(DGρ(ρn,eρn) +DGm(mn,emn))
s.t. (ρn,mn) := argmin
(ρ,m)∈CG(µn
0)LG(ρ,m;b), n= 1,2,···, N,(23)
where ( eρn,emn) = argmin(ρ,m)∈CG(µn
0)LG(ρ,m;eb) are the observed data and
CG,b:=

b:nx,nyX
ix,iy(b)ix,iy= 0

. (24)
Problem 3.6 (The discretization of the inverse metric problem 3.2) .Similarly, given the data ( eρn,emn) =
argmin
(ρ,m)∈C(µn
0)L(ρ,m;eg), we implement algorithms to solve
min
g∈CG,gNX
n=1(DGρ(ρn,eρn) +DGm(mn,emn)) +RG(g)
s.t. (ρn,mn) := argmin
(ρ,m)∈CG(µn
0)LG(ρ,m;g), n= 1,2,···, N,(25)
with the constraint of gbeing
CG,g:={g: (g)ix,iy∈Rd×dare positive definite matrices , ix= 1,···, nx, iy= 1,···, ny}. (26)
3.3 Regularity and Unique Identifiability of the Inverse Problems
At the end of this section, we state the regularity of the inverse problem 3.5 and 3.6 and the unique
identifiability of the inverse crowd motion problem 3.5.
8The regularity and unique identifiability of the inverse problem rely on the KKT system of the discretized
forward problem
min
(ρ,m)∈C(µ0)LG(ρ,m;g, b).(27)
To write the KKT system in a concise way, we define the adjoint operators of Ix, Iy, Itfor any ϕ=ϕGϕon
the central grid as
(I∗
t(ϕ))ix,iy,it+1
2:=(
1
2 
(ϕ)ixiyit+ (ϕ)ix,iy,it+1
, it= 1,···, nt−1,
1
2(ϕ)ixiyit, i t=nt.
(I∗
x(ϕ))ix+1
2,iy,it:=1
2 
(ϕ)ixiyit+ (ϕ)ix+1,iy,it
, ix= 1,···, nx−1.
(I∗
y(ϕ))ix,iy+1
2,it:=1
2 
(ϕ)ixiyit+ (ϕ)ix,iy+1,it
, iy= 1,···, ny−1.
and the adjoint operators of Dx, Dy, Dtas
(D∗
t(ϕ))ix,iy,it+1
2:=(
−1
∆t 
(ϕ)ix,iy,it+1−(ϕ)ixiyit
, it= 1,···, nt−1
1
∆t(ϕ)ixiyit, i t=nt.
(D∗
x(ϕ))ix+1
2,iy,it:=1
∆x 
(ϕ)ix+1,iy,it−(ϕ)ixiyit
, ix= 1,···, nx−1
(D∗
y(ϕ))ix,iy+1
2,it:=1
∆y 
(my)ix,iy+1,it−(my)ixiyit
, iy= 1,···, ny−1.
The adjoint relation in the discretized space holds based on the definitions. To be precise, for the interpolation
operators, we have
⟨It(ρ;µ0), ϕ⟩Gϕ=⟨ρ, I∗
t(ϕ)⟩Gρ+1
2nxX
ix=1nyX
iy=1(µ0)ix,iy(ϕ)ix,iy,1.
⟨Ix(mx), ϕ⟩Gϕ=⟨mx, I∗
x(ϕ),⟩Gmx.
⟨Iy(my), ϕ⟩Gmy=⟨my, I∗
y(ϕ),⟩Gmy.
and for differential operators, we have
⟨Dt(ρ;µ0), ϕ⟩Gϕ=⟨ρ, D∗
t(ϕ)⟩Gρ−1
∆tnxX
ix=1nyX
iy=1(µ0)ix,iy(ϕ)ix,iy,1.
⟨Dx(mx), ϕ⟩Gϕ=⟨mx, D∗
x(ϕ)⟩Gmx.
⟨Dy(my), ϕ⟩Gϕ=⟨my, D∗
y(ϕ)⟩Gmy.
With the adjoint operators, we define the Yoperators as following to describe the optimality condition
for the forward problem,


i∈ Gρ, it= 1,···, nt−1,
(Yρ(ρ,m, ϕ;g, b))i:=−(D∗
t(ϕ))i+
I∗
t
−(m)⊤gm
2ρ2+γI(log(ρ) + 1)
i+bix,iy,
i∈ Gρ,=nt,
(Yρ(ρ,m, ϕ;g, b))i:=−(D∗
t(ϕ))i+
I∗
t
−(m)⊤gm
2ρ2+γI(log(ρ) + 1)
i+bix,iy
+γT
∆t(log(ρi)−log((µ1)ix,iy) + 1) ,
i∈ Gmx,(Ymx(ρ,m, ϕ;g, b))i:=−(D∗
x(ϕ))i+
I∗
xgxxmx+gxymy
ρ
i,
i∈ Gmy,(Ymy(ρ,m, ϕ;g, b))i:=− 
D∗
y(ϕ)
i+
I∗
ygxymx+gyymy
ρ
i,
i∈ Gϕ,(Yϕ(ρ,m, ϕ;g, b))i:= (Dt(ρ;µ0) +Dx(mx) +Dy(my))i.(28)
9Yρ,Yx
m,Yy
m,Yϕare obtained by taking gradients on the Lagrangian of the forward problem (27). By viewing
ρ,m, ϕ, b andYρ,Yx
m,Yy
m,Yϕas long vectors and denoting Y:= (Yρ,Ymx,Ymy,Yϕ)⊤, we define a function
Y:Rdl×Rdu→Rdlwith du= (d(d+1)
2+ 1)nxnycorresponding to the dimension of ( g, b) and dl=
nxnynt+ (nx−1)nynt+nx(ny−1)nt+nxnyntto the dimension of ρ, mx, my, ϕ. Since the constraint is
linear, the optimizer of (27) satisfies the KKT condition. The formal statement is the following.
Lemma 3.7. If(eρ,em)∈ C(µ0)is a minimizer of LG(ρ,m;eg,eb), and min
i∈Gρ{eρi}>0, then there exists eϕ∈
Rnxnyntsuch that
Y(eρ,em,eϕ;eg,eb) =0. (29)
With the discrete PDE description of the Nash Equilibrium, we state the regularity result for the inverse
problem 3.5 and 3.6.
Theorem 3.8 (Regularity) .Assume that (eρ,em)is the Nash Equilibrium given the metric eg, obstacle function
ebandγI>0, γT>0, i.e. (27) holds, and that min
i∈Gρeρi>0, then there exists ru>0and a radius ruopen ball
Bru(eg,eb)centered at (eg,eb), and a mapping Tdefined on Bru(eg,eb)satisfying the following
•For any (g, b)∈Bru(eg,eb), there exist a unique (ρ,m, ϕ) =T(g, b)∈Brl(eρ,em,eϕ), a radius rlopen ball
centered at (eρ,em,eϕ), such that (ρ,m, ϕ)solves the forward problem with LG(ρ,m;g, b).
•T(eg,eb) = (eρ,em,eϕ),Tis of class C1and
DT(g, b) =−(Dρ,m,ϕY(T(g, b);g, b)))−1(DbY(T(g, b);g, b)),for all (g, b)∈Bru(eg,eb). (30)
In addition, we have the unique identifiability of the inverse crowd motion problem because the lower-
level objective has a simple dependence on the obstacle b. To be concrete, by solving the inverse crowd
motion problem 3.5, we uniquely recover the ground truth obstacle ebup to a constant from only one good
observation of the Nash Equilibrium.
Theorem 3.9 (Unique identifiability) .Assume that (eρ,em)is the Nash Equilibrium given the obstacle func-
tioneb, i.e.
(eρ,em) := argmin
(ρ,m)∈CG(µ0)LG(ρ,m;eb), (31)
and that min
i∈Gρeρi>0, then any minimizer bof the bilevel minimization problem
min
bDGρ(ρ,eρ) +DGm(m,em)
s.t.(ρ,m) := argmin
(ρ,m)∈CG(µ0)LG(ρ,m;b),(32)
has the form b=eb+cwhere c∈Ris a constant. This implies that ebis the unique minimizer of the bilevel
minimization problem (32) up to a constant.
The proofs are postponed to section 5. We close this section with some remarks on the theorems.
Remark 3.10 (Numerical stability) .While the unique identifiability Theorem 3.9 holds without the entropy
term and the regularity Theorem 3.8, we emphasize that the entropy term and regularity theorem are
meaningful for studying the numerical stability of the inverse problem. In fact, the entropy term guarantees
the strong convexity of the objective function and thus the uniqueness of the forward problem. And it is
important for the regularity Theorem 3.8 to hold. The regularity argument states the differentiability of the
forward optimizer with respect to the metric gand the obstacle band reveals the rate of change. According
to Theorem 3.9, if the smallest singular value of DT(g, b) is large, then a small perturbation to ( eρ,em) can
still give a reasonable approximation of the ground truth eg,eb. It is also worth noting that when min ieρiis
close to 0, the condition number of the Jacobian matrix Dρ,m,ϕY(eρ,em,eϕ;b) in (30) can be extremely large.
Therefore the Jacobian matrix Db(ρ,m, ϕ) is close to singular, and the observation error may cause a failure
to recover the ground truth obstacle.
10Remark 3.11 (Unique identifiability in the function space) .Theorem 3.9 establishes the unique identifiability
of the obstacle bG∈Rnxnyin the discretized finite-dimensional space. To prove the parallel result for the
obstacle function b: Ω→Rin the infinite-dimension space, it is subtle to choose the function space for
b, ρ,m, and ϕ. The function space is expected to be large enough to guarantee the existence of the lower-level
optimizers ρ∗(b),m∗(b) for different b, and to guarantee the existence of the bilevel problem optimizer b∗.
Meanwhile, the functions in the space require enough regularity for ρ∗(b),m∗(b) to be differentiable with
respect to b. This is out of the scope of this paper. We refer interested readers to [22, 23, 27] for efforts
in studying the unique identifiability in the infinite-dimensional space, where infinity many pairs of training
data are required.
Remark 3.12 (Unique identifiability of the unknown metric) .To establish the local unique identifiability of
the metric as a corollary of the stability Theorem 3.8, we need DgY(eρ,em,eϕ;g) to have full rank. However, for
1D metric, the rank of DgY(eρ,em,eϕ;g) depends on the data eρ,em,eϕ, which is different from DbY(eρ,em,eϕ;b)
being a constant. Therefore, we may not uniquely recover the metric from the data. Besides the degenerated
rank, while uniquely identifying grequires the knowledge of eϕ, we do not have eϕin our problem setting and
this can also cause non-uniqueness of the inverse problem. By experiments in [7], the lack of information on
eϕcan be overcome by giving partial true information on the metric and incorporating regularity terms in the
upper-level objective. For 2D metric, if we view gxx, gxy, gyyas independent variables, then DgY(eρ,em,eϕ;g)
is not a full-rank matrix and theoretically there is no hope to uniquely recover the ground truth metric. If
the metric gi∈S2
++has intrinsic structures such that the number of variables to determine the metric is
nxnyinstead of 3 nxny, numerically we recover the ground truth with a low error as shown by the numerical
experiment in section 6.5. The numerical experiment in section 6.2.2 also shows that another way to resolve
the ambiguity is to have multiple observations for more complete information in the region.
4 Alternating Gradient Method
In this section, we present the alternating gradient method (AGM) to solve the general bilevel optimization
problem (14), as well as two inverse mean-field game problems 3.5 and 3.6.
4.1 Preliminary on AGM for Bilevel Optimization
The idea of the AGM is iteratively conducting gradient descent on the lower-level variable and the upper-level
variable. To illustrate our algorithm, we first consider the following unconstrained bilevel problem
min
ξ∈Rduu(ξ) :=U(η∗(ξ);ξ)
where η∗(ξ) = argmin
η∈RdlL(η;ξ).(33)
The computation of the lower-level gradient is straightforward. To obtain the upper-level gradient, we assume
thatU,Lare differentiable and denote the gradient operator with respect to their first and second entries as
∇η,∇ξ. If for any given ξ, there exists a unique η∗(ξ) solving the lower-level optimization problem and the
function mapping ξto its corresponding minimizer η∗(ξ) is differentiable, then by chain rule, we have
∇u(ξ) =∇ξη∗(ξ)⊤∇ηU(η∗(ξ);ξ) +∇ξU(η∗(ξ);ξ), (34)
with∇ξη∗(ξ) = ( ∂ξ1η∗(ξ), . . . , ∂ ξduη∗(ξ))∈Rdl×dubeing the Jacobian matrix of η∗. We clarify that here
∇ξU(η∗(ξ);ξ) is the gradient of Uwith respect to its second entry evaluated at ( η∗(ξ);ξ) without considering
the dependence of η∗onξ. Therefore ∇ηU(η∗(ξ);ξ) and ∇ξU(η∗(ξ);ξ) in (34) are easy to compute.
When the exact lower-level solution η∗(ξ) is unavailable, the upper-level gradient ∇u(ξ) is inaccessible.
However, we can approximate η∗(ξ) and therefore approximate ∇ξu(ξ). Specifically, for ξkuat the ku-th
iteration, we run Kl-step gradient descent of lower-level with stepsize τlto approximate η∗(ξku), i.e.


ηku,1=ηku;
ηku,kl+1=ηku,kl−τl∇ηL 
ηku,kl;ξku
, kl= 1,···, Kl;
ηku+1=ηku,Kl+1.(35)
11It is easy to see that ηku,kl+1=ηku,kl+1(ξku)(kl= 1,···, Kl) and ηku+1=ηku+1(ξku) are functions of ξku.
We drop the dependence for notation conciseness and estimate the upper-level gradient ∇u(ξku) by
b∇u(ξku) := 
∇ξkuηku+1⊤∇ηU 
ηku+1;ξku
+∇ξU 
ηku+1;ξku
, (36)
where the ηkuis a lower-level estimator of the lower-level optimizer η∗(ξku), and ( ∇ξkuηku+1)ij=∂ξku
jηku+1
i
estimates ∇ξη∗(ξku) by unrolling the lower-level iterates through the chain rule. With the estimator in (36),
we then update the upper-level variable by gradient descent with stepsize τu, i.e.
ξku+1=ξku−τub∇u(ξku). (37)
We summarize the algorithm in Algorithm 1
Algorithm 1 General AGM for unconstrained bilevel optimization problem (33)
Initialization: ξ1, η1, stepsizes {τu, τl}
forku= 1,2,···, Kudo
Initialize lower-level update by ηku,1=ηku.
forkl= 1,2···, Kldo
lower-level gradient descent
ηku,kl+1=ηku,kl−τl∇ηL(ηku,kl;ξku). (38)
end for
Let the lower-level estimator be ηku+1=ηku,Kl+1and compute b∇u(ξku) by (36).
Conduct upper-level gradient descent
ξku+1=ξku−τub∇u(ξku). (39)
end for
Remark 4.1 (Error of unrolled differentiation) .(34) gives the exact value of the upper-level gradient. To
obtain the unknown ∇ξη∗(ξ) in (34), we refer to the first-order optimality condition from the lower-level
problem ∇ηL(η∗(ξ);ξ) =0. We view ∇ηL(η∗(ξ);ξ) as a vector-valued function of ξ, and its Jacobian matrix
gives
∇ξη∗(ξ)⊤∇ηηL(η∗(ξ);ξ) +∇ξηL(η∗(ξ);ξ) =0, (40)
where ( ∇ξηL)ij(η, ξ) =∂ξi∂ηjL(η, ξ) and ( ∇ηηL)ij(η, ξ) =∂ηi∂ηjL(η, ξ) are blocks of the Hessian matrix of
L. Therefore
∇ξη∗(ξ)⊤=−∇ξηL(η∗(ξ);ξ) (∇ηηL(η∗(ξ);ξ))−1. (41)
Plugging (41) into (34) gives the upper-level gradient
∇u(ξ) =b∇ξU(η∗(ξ);ξ), (42)
where
b∇ξU(η;ξ) =∇ξU(η;ξ)− ∇ ξηL(η;ξ) (∇ηηL(η;ξ))−1∇ηU(η;ξ). (43)
The gradient estimator (36) approximate the true gradient by approximating η∗byηku+1and approximating
(∇ηηL(η;ξ))−1by unrolling differentiation. A key to the convergence of the AGM algorithm is to control the
error of unrolling differentiation. For unconstrained problems, [8, 13] proved that under sufficient smoothness
assumptions, the errors of the approximations decrease as klincreases. In Lemma 5.3 of this paper, we study
and prove the error can also be bounded for linear equality constrained lower-level problems.
12Algorithm 2 General AGM for (14)
Initialization: ξ1, η1, stepsizes {τu, τl}
forku= 1,2,···, Kudo
Initialize lower-level update by ηku,1=ηku.
forkl= 1,2···, Kldo
lower-level gradient descent
ηku,kl+1= proj
H 
ηku,kl−τl∇ηL(ηku,kl;ξku)
. (44)
end for
Let the lower-level estimator be ηku+1=ηku,Kl+1and compute b∇u(ξku) by (36).
Conduct upper-level projected gradient descent
ξku+1= proj
Ξ
ξku−τub∇u(ξku)
(45)
end for
4.2 AGM for Inverse Mean-Field Games
Building upon Algorithm 1 for unconstrained bilevel optimization problems (33), we propose Algorithm 2
to solve the constrained bilevel optimization problem (14) and its special cases in inverse mean-field game
problems 3.1 and 3.2.
Algorithm 2 applies the projected gradient descent to estimate the lower-level optimizer and to update
the upper-level optimizer at each iteration. Precisely, by denoting the matrix form of the constraint (22) as
Aη=c, the projection to H={η|Aη=c}is
proj
H(η) = (I−A†A)η+η0,
where A†is the Moore-Penrose inverse and η0is a fixed solution to Aη=c. The projection operator is
invariant to the lower-level objective and the number of iterations. As discussed in [31], the main cost of
the lower-level projected gradient descent is to compute the inverse of the discretized Laplacian operator
(AA⊤)−1, which can be solved efficiently using the fast cosine transform. We refer to section 3.2 in [31]
for all detailed discussions. Since each step in projected gradient descent is explicit, it is possible to unroll
the differentiation to estimate the upper-level gradient and thus conduct AGM for the constrained bilevel
optimization problem. It is worth emphasizing that the proximal gradient solver for the lower-level problem
[31] makes it easy and efficient to unroll the differentiation and estimate the upper-level gradient. This is not
the case for other popular lower-level solvers, for example, augmented Lagrangian [2, 3]and primal-dual [26,
25] because the implicit updates in these methods make unrolling the differentiation prohibitively complicated
and expensive. Meanwhile, although it is widely acknowledged in unconstrained bilevel optimization [8, 13]
that the error arising from unrolling differentiation is controllable, rigorously adapting this approach to
incorporate lower-level linear constraints is, to the best of our knowledge, unexplored. Lemma 5.3 in this
paper investigates the error of this approximation, indicating that the gradient estimation error can be
effectively bounded by the accuracy of the lower-level solution.
The complexity of resolving the upper-level constraint is similar to a single-level optimization problem.
In our cases, for the inverse crowd motion problem 3.5, the upper-level constraint set Ξ = CG,bas defined in
(24) is the set of matrices of size nx×nywith entry sum zero. And the projection is simply projCG,b(b) =˜b,
where ( ˜b)ix,iy= (b)ix,iy−1
nxnyPnx,ny
ix,iy(b)ix,iy. And for the inverse metric problem 3.6, Ξ = CG,g, where CG,g
is defined in (26). We compute the projection ˜ g:= projCG,g(g) pointwisely. To be specific, for ( g)ix,iy, we first
compute its eigenvalue decomposition ( g)ix,iy=QΛQ−1where Λ = diag( λ1, λ2) and let (˜ g)ix,iy:=Q˜ΛQ−1
where ˜Λ = diag(max( λ1, ϵ),max( λ2, ϵ)) with a pre-selected small positive value ϵ.
Different from our bilevel formulation and AGM algorithm, [6, 7] treat the forward MFG PDE system
as the constraint of their optimization problem and apply primal-dual algorithm [4] to solve it. However,
13the nonlinear and nonconvex constraint makes it challenging to prove the algorithm convergence. On the
contrary, our bilevel formulation takes advantage of the convex-linear structure of the forward MFG and we
establish the following convergence theorem of our Algorithm 2.
If the upper-level and lower-level objective functions satisfy the following regularity assumptions,
Assumption 1.Assume that U,∇U,∇L,∇2Lis Lipschitz continuous with ℓu,0, ℓu,1, ℓl,1, ℓl,2, respectively.
Assumption 2.For any fixed ξ, assume that L(η;ξ) isµl-strongly convex with respect to η.
Assumption 3.Ξ is a linear constraint set Ξ = {ξ|Bξ=e}, and Hand Ξ are nonempty.
then we have the following theorem.
Theorem 4.2. Under Assumption 1–3, let τl≤1
2ℓl,1, Kl=O(logKu)andτu=O(1), then the iterates of
Algorithm 2 satisfy
1
KuKuX
ku=1∥ξku−proj
Ξ(ξku− ∇u(ξku))∥2=O1
Ku
(46)
where Oomits the logdependency.
Let us define ϵstationary point as ∥ξ−projΞ(ξ− ∇u(ξ))∥2≤ϵ, then Theorem 4.2 states that Algorithm
2 achieves ϵstationary point by O(ϵ−1) iterations. This matches the iteration complexity of the single-level
projected gradient descent method. We postpone the proof in section 5.
Lemma 3.4 states that when ρ,mare bounded, and when the entropy in the objective function is non-zero
(λ >0), then our inverse problems 3.5 and 3.6 satisfy assumptions 1 and 2. Moreover, since the upper-level
constraint set of the inverse crowd motion problem 3.5 is linear, assumption 3 is satisfied and Theorem 4.2
guarantees the algorithm convergence when solving problem 3.5. For the inverse metric problem 3.6 where
the upper-level constraint set is a convex cone, the convergence of the algorithm can be established similarly.
However, the convergence rate is possibly different. We leave the study of the convergence rate for general
upper-level constraints set to future research.
At the end of this section, we discuss how to unroll differentiation in practice.
Remark 4.3 (Unroll differentiation in practice) .Recall that in our problem, the lower-level variable η=
(ρGρ,mGm) and the upper-level variable ξ= (gG, bG) are of size O(d2ntnxny). To obtain the upper-level
gradient estimator (36), the computation of ∇ξU 
ηku+1;ξku
is straightforward. But it is not practicable
to directly formulate ∇ξkuηku+1since the size of the Jacobian matrix is O(dntnxny)× O(d2ntnxny) and
the sparsity structure of the Jacobian matrix is not straightforward. Denote the gradient descent mapping
M(η;ξ) :=η−τl∇ηL(η;ξ). Then the Jacobian of M,∇M= (∇ηM,∇ξM) = (I−τ∇ηηL,−τ∇ηξL) is sparse
because the number of non-zero entries of ∇ηηLand∇ηξLisO(dntnxny). In practice, we avoid formulating
the matrix ∇ξkuηku+1by chain rule and the sparsity structure of ∇M. Specifically, let P:=I−A†A
be the projection matrix, ∇ηku,klU 
ηku+1;ξku
be the gradient of U 
ηku+1;ξku
with respect to ηku,kl,
and∇ξkuηku,klbe the Jacobian of ηku,klwith respect to ξku, then we have the following relation by back-
propagation
(∇ηku,Kl+1U 
ηku+1;ξku
=∇ηU 
ηku+1;ξku
,
∇ηku,klU 
ηku+1;ξku
= 
∇ηM(ηku,kl;ξku)⊤P∇ηku,kl+1U 
ηku;ξku
, k l= 1,···, Kl.(47)
14Consequently, the upper-level gradient estimator is
b∇u(ξku) = 
∇ξkuηku,Kl+1⊤∇ηku,Kl+1U 
ηku+1;ξku
+∇ξU 
ηku+1;ξku
= 
∇ηM(ηku,Kl;ξku)∇ξkuηku,Kl⊤P∇ηku,Kl+1U 
ηku+1;ξku
+ 
∇ξM(ηku,Kl;ξku)⊤P∇ηku,Kl+1U 
ηku+1;ξku
+∇ξU 
ηku+1;ξku
by (47)= 
∇ξkuηku,Kl⊤∇ηku,KlU 
ηku+1;ξku
+ 
∇ξM(ηku,Kl;ξku)⊤P∇ηku,Kl+1U 
ηku+1;ξku
+∇ξU 
ηku+1;ξku
= 
∇ηM(ηku,Kl−1;ξku)∇ξkuηku,Kl−1⊤P∇ηku,KlU 
ηku+1;ξku
+ 
∇ξM(ηku,Kl−1;ξku)⊤P∇ηku,KlU 
ηku+1;ξku
+ 
∇ξM(ηku,Kl;ξku)⊤P∇ηku,Kl+1U 
ηku+1;ξku
+∇ξU 
ηku+1;ξku
by (47)= 
∇ξkuηku,Kl−1⊤∇ηku,Kl−1 
ηku+1;ξku
+KlX
i=Kl−1 
∇ξM(ηku,i;ξku)⊤P∇ηku,i+1U 
ηku+1;ξku
+∇ξU 
ηku+1;ξku
=···
(a)=KlX
i=1 
∇ξM(ηku,i;ξku)⊤P∇ηku,i+1U 
ηku+1;ξku
+∇ξU 
ηku+1;ξku(48)
where ( a) is because that ηku,1is independent of ξku. In this way, each term in the estimator can be computed
by sparse matrix and vector multiplication.
5 Proofs of Main Theorems
In this section, we provide the proofs of main theorems. Theorem 3.8 shows that the observations of the
Nash Equilibrium continuously depend on the unknown parameters. Theorem 3.9 states that with only
one good observation of the Nash Equilibrium, we can uniquely recover the obstacle bup to a constant by
solving the bilevel problem (23). This illustrates the effectiveness of our model. Lemma 3.4 and Theorem
4.2 together guarantee that Algorithm 2 converges to a stationary point to the bilevel problem (23) if the
forward problem has enough regularity. This illustrates the effectiveness of our algorithm.
5.1 Proof of Theorem 3.8 and 3.9
Recall that Y(ρ,m, ϕ;g, b) =0gives the optimality condition. Denote the Jacobian matrix of Yas∇Y=
((∇ρ,m,ϕY)dl×dl,(∇g,bY)dl×du). The proof of the regularity Theorem 3.8 is based on the implicit function
theorem and the key is to show that the matrix ∇ρ,m,ϕYis invertible at a good observation ( eρ,em,eϕ;eg,eb).
Lemma 5.1. IfγI>0,γT>0andmin i∈Gρ{eρi}>0, then ∇ρ,m,ϕY(eρ,em,eϕ;eg,eb)is invertible.
Proof. To prove the lemma is equivalent to showing that
∇ρ,m,ϕY(eρ,em,eϕ;eg,eb)(δρ, δm, δϕ) =0, (49)
if and only if ( δρ, δm, δϕ) =0. Here δm:={δmx, δmy}. By definition,
∇ρ,m,ϕY(eρ,em,eϕ;eg,eb)(δρ, δm, δϕ) = lim
ϵ→01
ϵ
Y(eρ+ϵδρ,em+ϵδm,eϕ+ϵδϕ;eg,eb)− Y(eρ,em,eϕ;eg,eb)
(50)
15Therefore (49) is equivalent to


i∈ Gρ, it= 1,···, nt−1,
−(D∗
t(δϕ))i+ 
I∗
t 
−gxxemx+gxyemy
eρ2δmx−gxyemx+gyyemy
eρ2δmy
+(em)⊤gem
eρ3δρ+γI
eρδρ!!
i= 0,
i∈ Gρ,=nt,
−(D∗
t(δϕ))i+ 
I∗
t 
−gxxemx+gxyemy
eρ2δmx−gxyemx+gyyemy
eρ2δmy
+(em)⊤gem
eρ3δρ+γI
eρδρ!!
i+γT
∆t(eρ)i(δρ)i= 0,
i∈ Gmx,−(D∗
x(δϕ))i+ 
I∗
x 
gxx
eρδmx+gxy
eρδmy−gxxemx+gxyemy
eρ2δρ!!
i= 0,
i∈ Gmy,−(D∗
y(δϕ))i+ 
I∗
y 
gxy
eρδmx+gyy
eρδmy−gxyemx+gyyemy
eρ2δρ!!
i= 0,
i∈ Gϕ,(Dt(δρ;0) +Dx(δmx) +Dy(δmy))i= 0.(51)
Note that eρ,em,eϕare viewed as constants with respect to ( δρ, δm, δϕ) in the system. It clear that the system
51 is linear in ( δρ, δm, δϕ) and therefore (49) holds if ( δρ, δm, δϕ) =0. If both ( δρ, δm, δϕ) and ( δ′
ρ, δ′
m, δ′
ϕ)
satisfy (49), then by plugging them into (51) and subtracting, we have


i∈ Gρ, it= 1,···, nt−1,
−(D∗
t(δϕ−δ′
ϕ))i+ 
I∗
t 
−gxxemx+gxyemy
eρ2(δmx−δ′
mx)
−gxyemx+gyyemy
eρ2(δmy−δ′
my)
+(em)⊤gem
eρ3(δρ−δ′ρ) +γI
eρ(δρ−δ′ρ)!!
i= 0,
i∈ Gρ,=nt,
−(D∗
t(δϕ−δ′
ϕ))i+ 
I∗
t 
−gxxemx+gxyemy
eρ2(δmx−δ′
mx)
−gxyemx+gyyemy
eρ2(δmy−δ′
my)
+(em)⊤gem
eρ3(δρ−δ′ρ) +γI
eρ(δρ−δ′ρ)!!
i+γT
∆t(eρ)i(δρ−δ′
ρ)i= 0,(52)
16

i∈ Gmx,−(D∗
x(δϕ−δ′
ϕ))i+ 
I∗
x 
gxx
eρ(δmx−δ′
mx) +gxy
eρ(δmy−δ′
my)
−gxxemx+gxyemy
eρ2(δρ−δ′ρ)!!
i= 0,
i∈ Gmy,−(D∗
y(δϕ−δ′
ϕ))i+ 
I∗
y 
gxy
eρ(δmx−δ′
mx) +gyy
eρ(δmy−δ′
my)
−gxyemx+gyyemy
eρ2(δρ−δ′ρ)!!
i= 0,(53)
and
i∈ Gϕ,(Dt(δρ−δ′
ρ;0) +Dx(δmx−δ′
mx) +Dy(δmy−δ′
my))i= 0. (54)
Pointwisely multiplying (52) with ( δρ−δ′
ρ) and summing over Gρgives us
−
δρ−δ′
ρ, D∗
t(δϕ−δ′
ϕ)
Gρ
−*
δρ−δ′
ρ, I∗
t 
gxxemx+gxyemy
eρ2(δmx−δ′
mx)!+
Gρ−*
δρ−δ′
ρ, I∗
t 
gxyemx+gyyemy
eρ2(δmy−δ′
my)!+
Gρ
+*
δρ−δ′
ρ, I∗
t 
(em)⊤gem
eρ3(δρ−δ′ρ)!+
Gρ+
δρ−δ′
ρ, I∗
tγI
eρ(δρ−δ′ρ)
Gρ
+ ∆x∆ynxX
nx=1nyX
ny=1γT
(eρ)ix,iy,nt(δρ−δ′
ρ)2
ix,iy,nt= 0.
(55)
Similarly (53) and (54) imply
−
δmx−δ′
mx, D∗
x(δϕ−δ′
ϕ)
Gmx
+
δmx−δ′
mx, I∗
xgxx
eρ(δmx−δ′
mx) +gxy
eρ(δmy−δ′
my)
Gmx
−*
δmx−δ′
mx, I∗
x 
gxxemx+gxyemy
eρ2(δρ−δ′ρ)!+
Gmx= 0,(56)
and
−
δmy−δ′
my, D∗
y(δϕ−δ′
ϕ)
Gmy
+
δmy−δ′
my, I∗
ygxy
eρ(δmx−δ′
mx) +gyy
eρ(δmy−δ′
my)
Gmy
−*
δmy−δ′
my, I∗
y 
gxyemx+gyyemy
eρ2(δρ−δ′ρ)!+
Gmy= 0,(57)
and

δϕ−δ′
ϕ, Dt(δρ−δ′
ρ;0)
Gϕ+
δϕ−δ′
ϕ, Dx(δmx−δ′
mx)
Gϕ+
δϕ−δ′
ϕ, Dy(δmy−δ′
my)
Gϕ= 0. (58)
Next, we add (55)-(58) and combine terms with the same components in groups. The first group is
−
δρ−δ′
ρ, D∗
t(δϕ−δ′
ϕ)
Gρ−
δmx−δ′
mx, D∗
x(δϕ−δ′
ϕ)
Gmx−
δmy−δ′
my, D∗
y(δϕ−δ′
ϕ)
Gmy

δϕ−δ′
ϕ, Dt(δρ−δ′
ρ;0)
Gϕ+
δϕ−δ′
ϕ, Dx(δmx−δ′
mx)
Gϕ+
δϕ−δ′
ϕ, Dy(δmy−δ′
my)
Gϕ,(59)
and by the adjoint relation between Dt, D∗
t, this group sums to 0. The second group consists of

δρ−δ′
ρ, I∗
tγI
eρ(δρ−δ′ρ)
Gρ+∆x∆ynxX
nx=1nyX
ny=1γT
(eρ)ix,iy,nt(δρ−δ′
ρ)2
ix,iy,nt. (60)
17and the sum is equal to γIδρ−δ′ρ
eρ1/22
Gϕ+ ∆x∆ynxX
nx=1nyX
ny=1γT
(eρ)ix,iy,nt(δρ−δ′
ρ)2
ix,iy,nt. The rest terms form
the last group and sum toX
i∈Gϕ1
eρ3
i
(δρ−δ′ρ)em−eρ(δm−δ′m)
i2
gi, (61)
where ∥vi∥2
gi= (v)⊤
igivi. Overall, adding (55)-(58) gives
γIδρ−δ′ρ
eρ1/22
Gϕ+ ∆x∆ynxX
nx=1nyX
ny=1γT
(eρ)ix,iy,nt(δρ−δ′
ρ)2
ix,iy,nt
+X
i∈Gϕ1
eρ3
i
(δρ−δ′ρ)em−eρ(δm−δ′m)
i2
gi= 0.(62)
We conclude that each term in (62) is zero since they are non-negative and sum to zero. Combining
(δρ)ix,iy,nt= (δ′
ρ)ix,iy,ntandδρ=δ′ρgives δρ=δ′
ρ. Consequently, δmx=δ′
mxandδmy=δ′
my. Because Ix, Iy
are full rank linear operators, δmx=δ′
mxandδmy=δ′
my. Based on δρ=δ′
ρ, δm=δ′
m, (52) and (53) lead to
δϕ=δ′
ϕ. Therefore (49) has unique solution ( ρ,m, ϕ) =0, i.e.∇ρ,m,ϕY(eρ,em,eϕ;eb) is invertible.
With Lemma 5.1, we apply implicit function theorem to Yat (eρ,em,eϕ;eg,eb) and then the regularity
Theorem 3.8 is true.
Next, we prove the unique identifiability Theorem 3.9 for inverse obstacle problem 3.5.
Proof of Theorem 3.9. Since the upper-level objective is non-negative and equals 0 when b=eb, any minimizer
bof the bilevel minimization problem satisfies
(eρ,em) = argmin
(ρ,m)∈CG(µ0)LG(ρ,m;b), (63)
and by Lemma 3.7, there exists ϕsuch that Y(eρ,em, ϕ;b) =0. Assume that b′is a minimizer, b′̸=eb, and
Y(eρ,em,eϕ;eb) =Y(eρ,em, ϕ′;b′) =0,
then
Y(eρ,em,eϕ;eb)− Y(eρ,em, ϕ′;b′) =0,
which is equivalent to

i∈ Gρ,−
D∗
t(ϕ′−eϕ)
i+ ((b′)ix,iy−(eb)ix,iy) = 0 ,
i∈ Gmx,
D∗
x(ϕ′−eϕ)
i= 0,
i∈ Gmy,
D∗
y(ϕ′−eϕ)
i= 0.(64)
The equation on Gρgives ( ϕ′−eϕ)ixiyit= (nt−it+ 1)( b′−eb)ix,iy. Plugging in equations on Gmx,Gmy, we
have ( b′−eb)ix,iy=cwhere cis a constant for different ix, iy.
5.2 Proof of Theorem 4.2 and Lemma 3.4
In this section, we provide the nonasymptotic analysis for AGM on general constrained bilevel optimization
(14). We follow conventional notations in bilevel optimization by using commas to separate lower-level and
upper-level variables, i.e., L(η, ξ) =L(η;ξ),U(η, ξ) =U(η;ξ)
18Recall that the lower level constraint is H={η|Aη=c}. Denote the singular value decomposition of
AasA=UΣV⊤, where
Σ =Σ10
0 0
∈Rdc×dη,
U= [U1U2],V= [V1V2],U∈Rdc×dc, V∈Rdη×dηare orthogonal matrix and U1∈Rdc×r, V1∈Rdη×r
are the submatrix corresponds to full rank diagonal submatrix Σ 1∈Rr×r. Then V2is the orthogonal basis
of Ker( A) :={η|Aη= 0}. Let η0∈Hbe a feasible lower-level solution, then the lower-level update is
equivalent to
ηku,1=ηku;ηku,kl+1=V2V⊤
2 
ηku,kl−τl∇ηL(ηku,kl, ξku)
+η0;ηku+1=ηku,Kl+1. (65)
With ηku+1approximating η∗(ξku), we approximate the lower-level gradient with
b∇u(ξku) :=∇ξU(ηku+1, ξku) + (∇ξkuηku+1)⊤∇ηU(ηku+1, ξku) (66)
and∇ξkuηku+1is obtained by unrolling the lower-level iterates


∇ξkuηku,1=0,
∇ξkuηku,kl+1=V2V⊤
2∇ξkuηku,kl−τlV2V⊤
2 
∇ηξL(ηku,kl, ξku) +∇ηηL(ηku,kl, ξku)∇ξkuηku,kl
=V2V⊤
2 
I−τl∇ηηL(ηku,kl, ξku)
∇ξkuηku,kl−τlV2V⊤
2∇ηξL(ηku,kl, ξku), kl= 1,···, Kl.
(67)
To prove the convergence, we first present the regularity of the lower-level optimizer established in [30].
To be self-contained, we also provide its proof.
Lemma 5.2 (The regularity of lower-level optimizer) .Under Assumption 1–2, η∗(ξ)is differentiable with
respect to ξwith the following gradient
∇η∗(ξ) =−V2(V⊤
2∇ηηL(η∗(ξ), ξ)V2)−1V⊤
2∇ηξL(η∗(ξ), ξ).
where V2is the orthogonal basis of Ker(A). Therefore, η∗(ξ)isLη-Lipschitz continuous and and Lηξsmooth
with
Lη:=ℓl,1
µl=O(κ), L ηξ:=ℓl,2(1 +ℓl,1
µl)2
µl=O(κ3).
Proof. First, we prove the differentiability and compute the Jacobian matrix. We choose a fixed η0satisfying
Aη0=c. Using the aforementioned SVD of A, the constraint set H={η0+V2z|z∈Rdη−r}. Letting
Lz(z, ξ) :=L(η0+V2z, ξ) and z∗(ξ) = arg min zLz(z, ξ), we have η∗(ξ) =η0+V2z∗(ξ). By optimality
condition, z∗(ξ) satisfies
∇zLz(z∗(ξ), ξ) =V⊤
2∇ηL(η0+V2z∗(ξ), ξ) = 0 , (68)
Since
∇zzLz(z∗(ξ), ξ) =V⊤
2∇ηηL(η0+V2z∗(ξ), ξ)V2 (69)
and by strong convexity of Lwith respect to η,∇zzLz(z∗(ξ), ξ) is invertible. By implicit function theorem,
z∗(ξ) is differentiable with respect to ξ. As a consequence, η∗(ξ) is differentiable with respect to ξ. Taking
the gradient with respect to ξon both sides of (68) gives us
0 =∇ξηL(η0+V2z∗(ξ), ξ)V2+ 
∇ξz∗(ξ)⊤V⊤
2
∇ηηL(η0+V2z∗(ξ), ξ)V2
=∇ξηL(η0+V2z∗(ξ), ξ)V2+∇ξz∗(ξ)⊤V⊤
2∇ηηL(η0+V2z∗(ξ), ξ)V2.
Then, we have (cf. ∇ηηL(η∗(ξ), ξ) =∇ηηL(η0+V2z∗(ξ), ξ))
∇z∗(ξ) =− 
V⊤
2∇ηηL(η∗(ξ), ξ)V2−1V⊤
2∇ηξL(η∗(ξ), ξ) (70)
19and as a result,
∇η∗(ξ) =V2∇z∗(ξ)
=−V2 
V⊤
2∇ηηL(η∗(ξ), ξ)V2−1V⊤
2∇ηξL(η∗(ξ), ξ).
Next, utilizing the fact that V2is the orthogonal matrix, we know µlI⪯V⊤
2∇ηηL(η, ξ)V2. Therefore, we
have for any ξ, η,
V2 
V⊤
2∇ηηL(η, ξ)V2−1V⊤
2⪯1
µlI. (71)
As a result, ∇η∗(ξ) is bounded by
∥∇η∗(ξ)∥ ≤ ∥ V2 
V⊤
2∇ηηL(η∗(ξ), ξ)V2−1V⊤
2∥∥∇ ηξL(η∗(ξ), ξ)∥ ≤ℓl,1
µl=Lη
which implies η∗(ξ) isLηLipschitz continuous.
Finally, we aim to prove the smoothness of η∗(ξ). For any ξ1andξ2, we have
∥∇η∗(ξ1)− ∇η∗(ξ2)∥
=∥V2 
V⊤
2∇ηηL(η∗(ξ1), ξ1)V2−1V⊤
2∇ηξL(η∗(ξ1), ξ1)
−V2 
V⊤
2∇ηηL(η∗(ξ2), ξ2)V2−1V⊤
2∇ηξL(η∗(ξ2), ξ2)∥
≤ ∥V2B−1
1V⊤
2∥∥∇ ηξL(η∗(ξ1), ξ1)− ∇ ηξL(η∗(ξ2), ξ2))∥
+∥V2(B−1
1−B−1
2)V⊤
2∥∥∇ ηξL(η∗(ξ2), ξ2)∥
(a)
≤1
µl∥∇ηξL(η∗(ξ1), ξ1)− ∇ ηξL(η∗(ξ2), ξ2)∥
+ℓl,1
µ2
l∥∇ηηL(η∗(ξ1), ξ1)− ∇ ηηL(η∗(ξ2), ξ2)∥
(b)
≤ℓl,2(1 +ℓl,1
µl)2
µl∥ξ1−ξ2∥ (72)
where B1=V⊤
2∇ηηL(η∗(ξ1), ξ1)V2andB2=V⊤
2∇ηηL(η∗(ξ2), ξ2)V2, (a) comes from (71) and the following
fact:
V2 
B−1
1−B−1
2
V⊤
2
=V2B−1
1(B2−B1)B−1
2V⊤
2
=V2B−1
1  
V⊤
2∇ηηL(η∗(ξ2), ξ2)V2
− 
V⊤
2∇ηηL(η∗(ξ1), ξ1)V2
B−1
2V⊤
2
=V2B−1
1V⊤
2(∇ηηL(η∗(ξ2), ξ2)− ∇ ηηL(η∗(ξ1), ξ1))V2B−1
2V⊤
2
and (b) comes from
∥∇2L(η∗(ξ1), ξ1)− ∇2L(η∗(ξ2), ξ2)∥ ≤ℓl,2[∥ξ1−ξ2∥+∥η∗(ξ1)−η∗(ξ2)∥]
≤ℓl,2
1 +ℓl,1
µl
∥ξ1−ξ2∥.
In Algorithm 2, we approximate ∇η∗(ξ) by unrolling the differentiation. The following lemma investigates
the error of this approximation in constrained bilevel problems for the first time, indicating that the gradient
estimation error can be effectively bounded by the accuracy of the lower-level solution.
20Lemma 5.3 (Error of unrolling differentiation) .Suppose that Assumption 1–3 hold and choose τl≤1
2ℓl,1,
the error of implicit gradient estimator can be bounded by
∥∇η∗(ξku)− ∇ ξkuηku+1∥2≤2 (1−τlµl)2Kl+2+ 2CKlC2
l∥η∗(ξku)−ηku∥2
where C2
l:=
1 +ℓl,1
µl
ℓ2
l,2
2
µ2
l+3
2ℓ2
l,1
andCKlis the upper bound of Kl(1−τlµl)Kl−1and is finite.
Proof. According to (67), we know that ∇ξkuηku,1= 0 and
∇ξkuηku,kl+1=V2V⊤
2 
I−τl∇ηηL(ηku,kl, ξku)
∇ξkuηku,kl−τlV2V⊤
2∇ηξL(ηku,kl, ξku).
For any given ξku, we can define an auxiliary sequence {wkl}∞
kl=0andw∗:= lim Kl→∞wKl, where w1= 0
and
wkl+1=V2V⊤
2 
I−τl∇ηηL(η∗(ξku), ξku)
wkl−τlV2V⊤
2∇ηξL(η∗(ξku), ξku). (73)
We can see that (67) and (73) only differ in η∗(ξku) and ηku,kl. For the sequence wkl, we can calculate the
explicit form of wKl+1as
wKl+1=KlX
s=0 
V2V⊤
2−τlV2V⊤
2∇ηηL(η∗(ξku), ξku)s 
−τlV2V⊤
2∇ηξL(η∗(ξku), ξku)
=KlX
s=0 
V2V⊤
2−τlV2V⊤
2∇ηηL(η∗(ξku), ξku)V2V⊤
2s 
−τl∇ηξL(η∗(ξku), ξku)
=KlX
s=0 
V2 
I−τlV⊤
2∇ηηL(η∗(ξku), ξku)V2
V⊤
2s 
−τl∇ηξL(η∗(ξku), ξku)
=KlX
s=0V2 
I−τlV⊤
2∇ηηL(η∗(ξku), ξku)V2sV⊤
2 
−τl∇ηξL(η∗(ξku), ξku)
=V2 KlX
s=0 
I−τlV⊤
2∇ηηL(η∗(ξku), ξku)V2s!
V⊤
2 
−τl∇ηξL(η∗(ξku), ξku)
(74)
where the first equality comes from unrolling (73), the second and the fourth equality are due to ( V2V⊤
2)s=
V2V⊤
2. Let D:=I−τlV⊤
2∇ηηL(η∗(ξku), ξku)V2. When τl<2
ℓl,1, the operator norm of Dsatisfies ∥D∥<1,
the limitP+∞
s=0Ds:= lim Kl→+∞PKl
s=0Ds= (I−D)−1= (τlV⊤
2∇ηηL(η∗(ξku), ξku)V2)−1.Therefore, the
limit point of wklis equal to ∇η∗(ξku) since
w∗:= lim
Kl→∞wKl=V2 ∞X
s=0 
I−τlV⊤
2∇ηηL(η∗(ξku), ξku)V2s!
V⊤
2 
−τl∇ηξL(η∗(ξku), ξku)
=V2 
τlV⊤
2∇ηηL(η∗(ξku), ξku)V2−1V⊤
2 
−τl∇ηξL(η∗(ξku), ξku)
=−V2 
V⊤
2∇ηηL(η∗(ξku), ξku)V2−1V⊤
2∇ηξL(η∗(ξku), ξku) =∇η∗(ξku) (75)
Moreover, the error by finite-step approximation can be bounded by
(I−D)−1−KlX
s=0Ds=∞X
s=Kl+1Ds≤∞X
s=Kl+1∥D∥s=∥D∥Kl+1
1− ∥D∥
Since (1 −τlℓl,1)I⪯D=I−τlV⊤
2∇ηηL(η∗(ξku), ξku)V2⪯(1−τlµl)Iand according to (75) and (74), we
know that if τl≤1
2ℓl,1,
∥wKl+1− ∇η∗(ξku)∥ ≤τlℓl,1(1−τlµl)Kl+1
1−τlℓl,1≤(1−τlµl)Kl+1. (76)
21Next, we aim to bound the distance between ∇ξkuηku,kland the auxiliary sequence wkl. For any kl,
according to (67) and (73), we have
∥∇ξkuηku,kl+1−wkl+1∥2=∥ 
V2V⊤
2−τlV2V⊤
2∇ηηL(ηku,kl, ξku)
∇ξkuηku,kl−τlV2V⊤
2∇ηξL(ηku,kl, ξku)
− 
V2V⊤
2−τlV2V⊤
2∇ηηL(η∗(ξku), ξku)
wkl+τlV2V⊤
2∇ηξL(η∗(ξku), ξku)∥2
≤(1 +γ)∥ 
V2V⊤
2−τlV2V⊤
2∇ηηL(ηku,kl, ξku)
(∇ξkuηku,kl−wkl)∥2+
+ 2
1 +1
γ
∥τlV2V⊤
2(∇ηηL(ηku,kl, ξku)− ∇ ηηL 
η∗(ξku), ξku
wkl∥2
+ 2
1 +1
γ
∥τlV2V⊤
2(∇ηξL(ηku,kl, ξku)− ∇ ηξL 
η∗(ξku), ξku
∥2
≤(1 +γ) (1−τlµl)2∥∇ξkuηku,kl−wkl∥2
+
1 +1
γ
τ2
lℓ2
l,2∥η∗(ξku)−ηku,kl∥2 
2 + 2∥wkl∥2
(77)
where the first inequality is derived from ∥a+b+c∥2
2≤(1 +γ)∥a∥2
2+ (2 +2
γ)∥b∥2
2+ (2 +2
γ)∥c∥2
2and the
second inequality is due to Assumption 1–2. On the one hand, ∥wkl∥ ≤ ∥∇ η∗(ξku)∥+∥wkl− ∇η∗(ξku)∥ ≤
ℓl,1
1
µl+τl
is bounded according to Lemma 5.2 and (76). Thus, if τl≤1
2ℓl,1and letting γ=τlµl, (77)
becomes
∥∇ξkuηku,kl+1−wk+1∥2≤(1−τlµl)∥∇ξkuηku,kl−wkl∥2+
1 +1
τlµl
τ2
lℓ2
l,2 
4ℓ2
l,1
µ2
l+ 3!
∥η∗(ξku)−ηku,kl∥2
≤(1−τlµl)∥∇ξkuηku,kl−wkl∥2+C2
l∥η∗(ξku)−ηku,kl∥2(78)
where C2
l:=
1 +ℓl,1
µl
ℓ2
l,2
2
µ2
l+3
2ℓ2
l,1
.
On the other hand, we know that projected gradient descent is a contraction according to [30], i.e.
∥ηku,kl+1−η∗(ξku)∥2≤(1−τlµl)∥ηku,kl−η∗(ξku)∥2(79)
for 0≤τl≤1
ℓl,1. By induction, we have
∥ηku,kl+1−η∗(ξku)∥2≤(1−τlµl)kl∥ηku−η∗(ξku)∥2(80)
Then (78) becomes
∥∇ξkuηku,kl+1−wkl+1∥2≤(1−τlµl)∥∇ξkuηku,kl−wkl∥2+C2
l(1−τlµl)kl−1∥ηku−η∗(ξku)∥2.(81)
Then by induction and w1=∇ξkuηku,1= 0, ηku+1=ηku,Kl+1, we obtain that
∥∇ξkuηku+1−wKl+1∥2≤Kl(1−τlµl)Kl−1C2
l∥η∗(ξku)−ηku∥2. (82)
Combining (82) with (76) and setting τl≤1
2ℓl,1, we know that
∥∇ξkuηku+1− ∇η∗(ξku)∥2≤2 (1−τlµl)2Kl+2+ 2Kl(1−τlµl)Kl−1C2
l∥η∗(ξku)−ηku∥2. (83)
Then given τland let f(Kl) =Kl(1−τlµl)Kl−1, we know log( f(Kl)) = log Kl+ (Kl−1) log(1 −τlµl).
Taking the gradient of log( f(Kl)), we get 1 /Kl+ log(1 −τlµl). As log(1 −τlµl)<0, we know log( f(Kl))
first increases and then decreases and thus, log( f(Kl)) and f(Kl) have a finite upper bound. Let us denote
the upper bound of Kl(1−τlµl)Kl−1asCKl=O(1). Then (83) becomes
∥∇ξkuηku+1− ∇η∗(ξku)∥2≤2 (1−τlµl)2Kl+2+ 2CKlC2
l∥η∗(ξku)−ηku∥2. (84)
which yields the conclusion.
22Besides, we have the lower-level contraction and error.
Lemma 5.4 (Lower-level error) .Suppose that Assumption 1–3 hold and τl≤1
ℓl,1, then for any γ >0, we
have
∥ηku+1−η∗(ξku)∥2≤(1−τlµl)Kl∥ηku−η∗(ξku)∥2(85a)
∥ηku+1−η∗(ξku+1)∥2≤(1 +γ)∥ηku+1−η∗(ξku)∥2+L2
η
1 +1
γ
∥ξku−ProjΞ(ξku−τub∇u(ξku))∥2(85b)
Proof. (85a) comes from (80) when setting kl=Kl. Moreover,
∥ηku+1−η∗(ξku+1)∥2=∥ηku+1−η∗(ξku) +η∗(ξku)−η∗(ξku+1)∥2
(a)
≤(1 +γ)∥ηku+1−η∗(ξku)∥2+
1 +1
γ
∥η∗(ξku)−η∗(ξku+1)∥2
(b)
≤(1 +γ)∥ηku+1−η∗(ξku)∥2+L2
η
1 +1
γ
∥ξku−ξku+1∥2
= (1 + γ)∥ηku+1−η∗(ξku)∥2+L2
η
1 +1
γ
∥ξku−ProjΞ(ξku−τub∇u(ξku))∥2
where (a) is due to ∥a+b∥2
2≤(1 +γ)∥a∥2
2+ (1 +1
γ)∥b∥2
2for any γ >0, and (b) comes from the Lipschitz
continuity of η∗(ξ) in Lemma 5.2.
Lemma 5.5 (Upper-level error) .Under Suppose that Assumption 1–3 hold and τl≤1
2ℓl,1, then it holds that
u(ξku+1)−u(ξku)≤ −τu
2∥ξku−ProjΞ(ξku− ∇u(ξku))∥2−1
2τu−Lu
2
∥ξku−ProjΞ(ξku−b∇u(ξku))∥2
+τu 
ℓu,1(1 +Lη) + 2ℓu,0CKlC2
l2∥η∗(ξku)−ηku∥2+ 2τu(1−τlµl)4Kl+4
Proof. According to Lemma 5.2, we know u(ξ) =U(η∗(ξ), ξ) is Lipschitz smooth and
∇u(ξ) =∇ξU(η∗(ξ), ξ) +∇⊤
ξη∗(ξ)∇ηU(η∗(ξ), ξ)
and for any ξ1, ξ2, we have
∥∇u(ξ1)− ∇u(ξ2)∥=∥∇ξU(η∗(ξ1), ξ1) +∇⊤
ξη∗(ξ1)∇ηU(η∗(ξ1), ξ1)− ∇ ξU(η∗(ξ2), ξ2)− ∇⊤
ξη∗(ξ2)∇ηU(η∗(ξ2), ξ2)∥
≤ ∥∇ ξU(η∗(ξ1), ξ1)− ∇ ξU(η∗(ξ2), ξ2)∥+∥∇⊤
ξη∗(ξ1)∥∥∇ ηU(η∗(ξ1), ξ1)− ∇ ηU(η∗(ξ2), ξ2)∥
+∥∇ηU(η∗(ξ2), ξ2)∥∥∇ ξη∗(ξ1)− ∇ ξη∗(ξ2)∥
≤ℓu,1(∥η∗(ξ1)−η∗(ξ2)∥+∥ξ1−ξ2∥) +Lηℓu,1(∥η∗(ξ1)−η∗(ξ2)∥+∥ξ1−ξ2∥) +ℓu,0Lηξ∥ξ1−ξ2∥
≤(ℓu,1(1 +Lη)2+ℓu,0Lηξ)∥ξ1−ξ2∥.
By denoting the smoothness constant of u(ξ) asLu:=ℓu,1(1+Lη)2+ℓu,0Lηξ, we have the following expansion
u(ξku+1)≤u(ξku) +⟨∇u(ξku), ξku+1−ξku⟩+Lu
2∥ξku+1−ξku∥2
=u(ξku)− ⟨∇ u(ξku), ξku−ProjΞ(ξku−τub∇u(ξku))⟩+Lu
2∥ξku−ProjΞ(ξku−τub∇u(ξku))∥2
(a)=u(ξku)−1
τu⟨ξku−ProjΞ(ξku−τu∇u(ξku)), ξku−ProjΞ(ξku−τub∇u(ξku))⟩
+Lu
2∥ξku−ProjΞ(ξku−τub∇u(ξku))∥2
23(b)=u(ξku)−1
2τu∥ξku−ProjΞ(ξku−τu∇u(ξku))∥2
+1
2τu∥ProjΞ(ξku−τu∇u(ξku))−ProjΞ(ξku−τub∇u(ξku))∥2
−1
2τu−Lu
2
∥ξku−ProjΞ(ξku−τub∇u(ξku))∥2
(c)
≤u(ξku)−τu
2∥ξku−ProjΞ(ξku− ∇u(ξku))∥2+τu
2∥∇u(ξku)−b∇u(ξku)∥2
−1
2τu−Lu
2
∥ξku−ProjΞ(ξku−τub∇u(ξku))∥2(86)
where (a) comes from ξku= ProjΞ(ξku) and the fact that ProjΞonto a linear equality constraint set is a
linear operator, (b) is derived from 2 a⊤b=∥a∥2+∥b∥2−∥a−b∥2and (c) is because ProjΞis a linear operator
and∥Proj( A)−Proj( B)∥ ≤ ∥ A−B∥. Besides, we can decompose the gradient bias term as follows
∥∇u(ξku)−b∇u(ξku)∥=∥∇ξU(η∗(ξku), ξku)− ∇η∗(ξku)⊤∇ηU(η∗(ξku), ξku)
− ∇ ξU(ηku+1, ξku) +∇⊤
ξkuηku+1∇ηU(ηku+1, ξku)∥
≤ ∥∇ ξU(η∗(ξku), ξku)− ∇ ξU(ηku+1, ξku)∥
+∥∇η∗(ξku)∥∥∇ ηU(η∗(ξku), ξku)− ∇ ηU(ηku+1, ξku)∥
+∥∇ηU(ηku+1, ξku)∥∥∇η∗(ξku)− ∇ ξkuηku+1∥
≤ℓu,1(1 +Lη)∥η∗(ξku)−ηku+1∥+ℓu,0∥∇η∗(ξku)− ∇ ξkuηku+1∥
(a)
≤ 
ℓu,1(1 +Lη) + 2ℓu,0CKlC2
l
∥η∗(ξku)−ηku∥+ 2 (1 −τlµl)2Kl+2(87)
where (a) comes from lower-level contraction (80). Thus, plugging (87) to (86), we get that
u(ξku+1)−u(ξku)≤ −τu
2∥ξku−ProjΞ(ξku− ∇u(ξku))∥2−1
2τu−Lu
2
∥ξku−ProjΞ(ξku−b∇u(ξku))∥2
+τu
2 
ℓu,1(1 +Lη) + 2ℓu,0CKlC2
l
∥η∗(ξku)−ηku∥+ 2 (1 −τlµl)2K+22
≤ −τu
2∥ξku−ProjΞ(ξku− ∇u(ξku))∥2−1
2τu−Lu
2
∥ξku−ProjΞ(ξku−b∇u(ξku))∥2
+τu 
ℓu,1(1 +Lη) + 2ℓu,0CKlC2
l2∥η∗(ξku)−ηku∥2+ 2τu(1−τlµl)4Kl+4
With Lemma 5.2, 5.3, 5.4 and 5.5, we restate the convergence Theorem 4.2 in a more formal way and
prove the theorem as follows.
Theorem 5.6. Under Assumption 1–3, let τl≤1
2ℓl,1, Kl=O(logKu)andτu=O(1)satisfies
τu≤min1
2Lu(1 + 2 Lη),τlLuµl
Lη((ℓu,1(1 +Lη) + 2ℓu,0CKlC2
l)2+ 4L2u)
,
then the iterates of Algorithm 2 satisfy
1
KuKuX
ku=1∥ξku−ProjΞ(ξku− ∇u(ξku))∥2=O1
Ku
(88)
where Oomits the logdependency.
Proof. We can define Lyapunov function as
Vku=u(ξku) +Lu
Lη∥η∗(ξku)−ηku∥2
24On the one hand, plugging (85a) to (85b), we get
∥ηku+1−η∗(ξku+1)∥2≤(1 +γ) (1−τlµl)∥ηku−η∗(ξku)∥2+L2
η
1 +1
γ
∥ξku−ProjΞ(ξku−τub∇u(ξku))∥2.
(89)
On the other hand, according to Lemma 5.5 and (89), it holds that
Vku+1−Vku≤ −τu
2∥ξku−ProjΞ(ξku− ∇u(ξku))∥2−1
2τu−Lu
2
∥ξku−ProjΞ(ξku−b∇u(ξku))∥2
+τu 
ℓu,1(1 +Lη) + 2ℓu,0CKlC2
l2∥η∗(ξku)−ηku∥2+ 2τu(1−τlµl)4K+4
+Lu
Lη[(1 + γ) (1−τlµl)−1]∥ηku−η∗(ξku)∥2+LuLη
1 +1
γ
∥ξku−ProjΞ(ξku−τub∇u(ξku))∥2
(a)
≤ −τu
2∥ξku−ProjΞ(ξku− ∇u(ξku))∥2−1
4τu−Lu
2−LuLη
∥ξku−ProjΞ(ξku−τub∇u(ξku))∥2
−τlLuµl
Lη−τu 
(ℓu,1(1 +Lη) + 2ℓu,0CKlC2
l)2+ 4L2
u
∥η∗(ξku)−ηku∥2+ 2τu(1−τlµl)4Kl+4
(b)
≤ −τu
2∥ξku−ProjΞ(ξku− ∇u(ξku))∥2+ 2τu(1−τlµl)4Kl+4(90)
where (a) is earned by setting γ= 4LuLητuand (b) comes from the conditions
1
4τu−Lu
2−LuLη≥0,andτlLuµl
Lη−τu 
(ℓu,1(1 +Lη) + 2ℓu,0CKlC2
l)2+ 4L2
u
≥0. (91)
The sufficient conditions for (91) are
τu≤min1
2Lu(1 + 2 Lη),τlLuµl
Lη((ℓu,1(1 +Lη) + 2ℓu,0CKlC2
l)2+ 4L2u)
.
Rearranging terms and telescoping (90) yield
1
KuKuX
ku=1ξku−ProjΞ(ξku− ∇u(ξku))2≤2(V1−VKu+1)
τuKu+ 4(1−τlµl)4Kl+4
≤2(V1−infξu(ξ))
τuKu+ 4(1−τlµl)4Kl+4.
Then by choosing Kl=O(log(Ku)), the convergence rate of Algorithm 2 is O
1
Ku
.
The above theorem guarantees the Algorithm 2 converges to an ϵstationary point given that assumptions
1–3 are satisfied. And Lemma 3.4 states the convexity and Lipschitz smoothness of the lower-level objective
functions LG(ρ,m;g, b) in (21) and shows that our problem setting satisfies the assumptions.
Since the interpolation operators Ix, Iy, Itare linear and positive definite, to prove Lemma 3.4, it is
sufficient to prove the (strong) convexity and the Lipschitz smoothness of LG,γ:R+×Rd→R,(α,β)7→
β⊤Gβ
2α+γαlog(α).
Lemma 5.7. LetGbe ad×dsymmetric positive definite matrix and LG,γ:R+×Rd→R,(α,β)7→β⊤Gβ
2α+
γαlog(α). For any γ≥0,LG,γis convex in R+×Rdand Lipschitz smooth in {α∈R:α≥cρ>0} × {β∈
Rd:∥β∥ ≤cm}(cm>0). And for any γ >0,LG,γis strongly convex in {α∈R:cρ≥α≥cρ>0} ×Rd.
Proof. Since Gis symmetric and positive definite, we write the singular value decomposition of GasG=
UΣGU⊤, with UU⊤=U⊤U=I, ΣG= diag( σG,d, σG,d−1,···, σG,1), (σG,d≥σG,d−1≥ ··· ≥ σG,1).
25And σG,i, i= 1,···, dare the singular values of G. Denote Σ1
2
G:= diag(√σG,d,√σG,d−1,···,√σG,1) and
S= Σ1
2
GU⊤. Then G=S⊤Sand the singular values of SareσS,i=√σG,i.
Obviously, LG,γis twice differentiable in R+×Rdand
∇2LG,γ(α,β) =1
α3
β⊤Gβ−αβ⊤G⊤
−αGβ α2G
=1
α31
S⊤
(Sβ)⊤Sβ+γα2−α(Sβ)⊤
−αSβ α2I
1
S
=1
α31
S⊤
∇2LI,γ(α, Sβ)1
S
.(92)
We denote the minimal and maximal singular values of ∇2LG,γ(α,β) asσG,γ
min(α,β) and σG,γ
max(α,β). Then
we have
σG,γ
min(α,β)≥min(1 , σG,1)
α3σI,γ
min(α, Sβ), σG,γ
max(α,β)≤max(1 , σG,d)
α3σI,γ
max(α, Sβ). (93)
By computation, the eigenvalues λI,γ(α,β) of∇2LI,γ(α,β) satisfy
 
λ2− 
∥β∥2+ (γ+ 1)α2
λ+γα4
(λ−α2)d−1= 0. (94)
Therefore λI,γ(α,β)≥0 and

σI,γ
min(α,β)≥γα4
∥β∥2+ (γ+ 1)α2≥0,
σI,γ
max(α,β)≤ ∥β∥2+ (γ+ 1)α2(95)
Forγ≥0,σG,γ
min(α,β)≥0 hold for any α >0,β∈Rd, which implies Lγis convex. For γ≥0, α≥cρ,∥β∥ ≤
cm,σG,γ
max(α,β)≤max(1 , σG,d)
σG,dc2
m+(γ+1)c2
ρ
c3
ρ
hold for any α≥cρ,∥β∥ ≤cm, which implies LG,γis Lip-
schitz smooth. And for γ >0,cρ≥α≥cρ,σG,γ
min(α,β)≥min(1 , σG,1) min
γcρ
σG,dc2
m+(γ+1)c2
ρ,γcρ
σG,dc2
m+(γ+1)c2
ρ
.
6 Numerical Experiments
6.1 Experiment Settings
This section presents several numerical experiments to illustrate the effectiveness of our model and algorithm.
We generate the data by solving the forward problem using the projected gradient descent algorithm proposed
in [31] based on the FISTA algorithm [1]. In each experiment, we report the relative error versus the number
of iterations for recovering the obstacle and the metric. The relative error for recovering the obstacle is
vuutPnx
ix=1Pny
iy=1((bKu)ix,iy−(eb)ix,iy)2
Pnx
ix=1Pny
iy=1(eb)2
ix,iy, (96)
and the relative errors for the metrics are
(1D)sPnx
ix=1((gKu)ix−(eg)ix)2
Pnx
ix=1(eg)2
ix, (2D)vuutPnx
ix=1Pny
iy=1∥(gKu)ix,iy−(eg)ix,iy∥2
FPnx
ix=1Pny
iy=1∥(eg)ix,iy∥2
F, (97)
where bKu, gKuare the numerical results after Kuupper-level updates and eb,egare the ground truth. We
implement all of our numerical experiments in Matlab on a PC with an Intel(R) i7-8550U 1.80GHz CPU
and 16 GB memory.
266.2 Theoretical arguments verification
6.2.1 Algorithm convergence and obstacle unique identifiability
The first experiment aims to numerically verify the stability Theorem 3.8, the unique identifiability Theorem
3.9 and convergence analysis in Theorem 4.2 of the bilevel algorithm with lower and upper-level constraints.
We discretize the space with nt= 16 , nx=ny= 64. Denote pg(x, y;µx, µy, σx, σy) as the probabil-
ity density function of Gaussian distribution with mean ( µx, µy) and covariance matrix diag( σ2
x, σ2
y). We
feed the model with one pair of observations, i.e. N= 1, with µ0=pg(·,·;−0.25,0,0.08,0.08),µ1=
pg(·,·; 0.25,0,0.08,0.08) and γI= 0.1, γT= 5. We choose the obstacle function as b(x, y) =γbpg(x, y; 0,0,0.08,0.1).
With different values of γb, the agents avoid the center of the obstacle to different degrees. Higher values of
γblead to lower density values at ( x, y) = (0 ,0). According to remark 3.10, low-density values in the data
result in difficulties in accurately reconstructing the obstacle.
5101520
5101520
51015202530
5101520253035
00.20.40.60.8
00.511.5
0246
0246810
0 2000 4000 6000
UL iteration051015UL objectiveUL Objective
0 2000 4000 6000
UL iteration0102030UL objectiveUL Objective
0 2000 4000 6000
UL iteration0204060UL objectiveUL Objective
0 2000 4000 6000
UL iteration020406080UL objectiveUL Objective
0 2000 4000 6000
UL iteration00.51obs relative error
0 2000 4000 6000
UL iteration00.51obs relative error
0 2000 4000 6000
UL iteration0.20.40.60.81obs relative error
0 2000 4000 6000
UL iteration0.20.40.60.81obs relative error
Figure 2: Convergence test of the inverse crowd motion problem. Top to bottom: the snapshot of eρat
t= 0.5, recovered bwith smallest relative error, upper-level objective value versus the number of iterations,
relative error of bversus the number of iterations. Left to right: γb= 0.05,0.1,0.5,1.
Figure 2 and Table 1 compare the results with γb= 0.05,0.1,0.5,5. For a fair comparison, we initialize
the algorithm with obstacle b0=0so that the initial relative errors all start from 1 for different γb. We run
each inner loop for 5 iterations and run the outer loop for 6000 iterations.
The first row in Figure 2 plots training data eρ(·,·,0.5) and em(·,·,0.5). In the first column of table 1, we
report the density value eρ(·,·,0.5) at the center, reflecting the value of min eρ. It is clear to see that more
agents avoid the center of the obstacle as γbgrows larger, thus the density value in the center decreases.
The third row of Figure 2 presents the progression of upper-level objective values across upper-level
iterations, while Table 1, Column 2, details the final upper-level objective values. To enhance the precision
27Table 1: Convergence test of the inverse crowd motion problem.
γbeρ(0,0,0.5)upper-level
objective valuerelative error
(best)relative error
(terminial)time elapsed
(second)
0.05 0.7831 1.1792 0.0139 0.0148 1570.1611
0.1 0.0293 2.2504 0.0134 0.0161 1537.9703
0.5 0.0079 6.2426 0.2186 0.3500 1565.9526
1 0.0054 8.5889 0.3326 0.4354 1549.7152
of the upper-level objective calculation, we execute the forward solver to convergence every 10 upper-level
iterations. This approach yields a refined approximation of ( ρ∗(b(k)),m∗(b(k))), thereby providing a more
accurate estimation of the upper-level objective values. Theorem 4.2 implies that convergence is achieved
when min eρ >0. Supporting this, Table 1, Column 1, indicates that min eρ >0 for all considered γbvalues.
Furthermore, Figure 2, Row 3, demonstrates numerical convergence for each γbselection. This verifies the
algorithm convergence Theorem 4.2.
We qualitatively show the numerical solutions of the obstacle in the second row of Figure 2, while we
report the relative error in the fourth row of Figure 2 and list the best relative error and terminal step relative
error in the third and fourth column of Table 1, respectively. Given that min eρ >0, Theorem 3.9 suggests
the possibility of uniquely recovering the ground truth obstacle, up to a constant, for all γbvalues of 0.05,
0.1, 0.5, and 1. Numerically, this unique recovery is observed for γb= 0.05 and 0 .1. However, for higher
γbvalues of 0.5 and 1, the reconstructed bdoes not align perfectly with the ground truth eb, as one might
expect. This deviation is accounted for by Remark 3.10, which discusses the robustness of the reconstruction.
Specifically, when γbis set to 0.5 or 1, the lower bound of the data eρdecreases. According to Remark 3.10,
a smaller eρlower bound leads to less robust solutions, making them more susceptible to distortions from
small perturbations in the ground truth. In our experiments, since the forward solver typically produces
an approximation of the exact minimizer after a finite number of iterations, the data represents a slight
deviation from the ground truth. Consequently, This causes the reconstructed obstacle to differ from the
exact obstacle and the discrepancy is more obvious when γb= 0.5,1.
6.2.2 Improving results with multiple data
We conduct an experiment to show that multiple training data help to enhance reconstruction results for
the inverse metric problem.
The example is defined on space domain [ −0.5,0.5] and time domain [0 ,1]. We discretize the space
domain [ −0.5,0.5] with nx= 64 and the time domain [0 ,1] with nt= 16. The ground truth metric is
eg(x) = 0 .7−0.3 cos(2 πx). The parameters in the forward problem are γI= 0.01, γT= 0.5. Then we obtain
the first pair of data with µ0(x) = 1 .25−0.25 cos(4 πx), µ1= 1.25 + 0 .25 cos(2 πx) and the second pair with
µ0(x) =pg(x; 0,0.1), µ1= 1.
We solve the inverse problem with the first pair of data ( N= 1) or both data ( N= 2). When solving
the inverse problem, we take the information on the left end Gk={ix:ix= 1}as known and fix it. We
choose R(g) :=1
2γRR
∥∇g(x)∥2
2dxto regularize the smoothness of the metric. The discretization is therefore
RG(g) :=1
2γR∆xPnx−1
ix=1((g)ix+1−(g)ix)2.
We run the Algorithm 2 for 5000 iterations with 5 iterations per each inner loop. The initialization on
ix= 1 is set as the true value and the initialization on other points is 0.7. Figure 3 shows the comparison
of numerical results and ground truth (row 1) and the relative error of the metric versus the number of
upper-level iterations. Table 2 reports the weight of regularization γR, relative error, and running time of
the algorithm. For one comparison, we choose no regularization ( γR= 0) in the model. The results with
the first data ( N= 1) are presented in row 1 and the results with both data ( N= 2) are in row 2. Then
we tune the regularization parameter and report the best results with the first data in row 3 and with both
data in row 4. It is easy to see that when using both data, our model captures the ground truth metric
better and achieves lower relative error. It is worth noting that when using both data to solve the inverse
problem, our model captures the shape of the ground truth metric even without smoothness regularization.
However, when using the first data, the model fails to learn the information in the center and on both ends.
28-0.5 0 0.50.40.60.81
true
num
-0.5 0 0.50.40.60.81
true
num
-0.5 0 0.50.40.60.81
true
num
-0.5 0 0.50.40.60.81
true
num
0 1000 2000 3000 4000 50000.150.20.250.3
0 1000 2000 3000 4000 50000.050.10.150.20.250.3
0 1000 2000 3000 4000 50000.10.150.20.250.3
0 1000 2000 3000 4000 500000.10.20.3Figure 3: Improving results with multiple data. Top to bottom: comparison of numerical gand the ground
trutheg, the relative error of gversus the number of iterations. Left to right: ( N= 1, γR= 0), ( N= 2, γR=
0), (N= 1, γR= 10−5), (N= 2, γR= 10−4).
Table 2: Improving results with multiple data.
N γR relative error time elapsed (seconds)
1 0 0.1700 60.0653
2 0 0.0673 128.5328
1 1×10−50.1073 67.3291
2 1×10−40.0145 118.9042
6.3 Robustness with respect to data
6.3.1 Unknown obstacles
To test the robustness of our method for noisy input as discussed in Remark 3.10 , we design the following
numerical experiment.
We discretize the space [ −0.5,0.5]2with nx=ny= 64 and choose nt= 16. We let the obsta-
cle function be b(x, y) =(
0.5, x < 0,0.05< y < 0.1,orx >0,−0.1< y < −0.05,
0, otherwise.. Assume there is one
pair of observations, with initial density µ0=pg(·,·;−0.3,0.3,0.1,0.1), preferred terminal density µ1=
pg(·,·; 0.3,−0.3,0.1,0.1) and γI= 0.1, γT= 1. We use the perturbed observation eρ+γnnρ,em+γnnmto
solve the inverse problem, where γn= 0,0.25,0.5,0.75 and noise nρ, nmare generated by pointwise i.i.d
sampling from the uniform distribution U[−0.5,0.5]. To avoid numerical instability caused by zero value or
negative density values, we threshold the perturbed density by 0.01. All experiments initialize with the same
random choice of b. Every inner loop contains 5 iterations and 5000 outer iterations have been conducted.
In addition, we do not add any regularizer in this experiment. From Figure 4 and Table 3, we observe that
with larger noise, the relative errors between numerical results and the ground truth are larger. Overall, the
numerical results capture the shape of the ground truth and the algorithm converges to a close result to the
ground truth ebwith reasonably low relative errors.
6.3.2 Unknown 1D metric
This is a 1D example on [ −0.5,0.5]×[0,1]. We discretize the space domain [ −0.5,0.5] with nx= 64 and
the time domain [0 ,1] with nt= 16. The ground truth metric is eg(x) = 8 x(x−0.375)( x+ 0.375) + 1. The
data is obtained by taking µ0(x) =pg(x; 0,0.1), µ1= 1 and γI= 0.01, γT= 0.5. We test the robustness
of the model by perturbing the observation eρ,em. The noises nρ, nmshare the same size with eρ,emand are
pointwise i.i.d samples from U[−0.5,0.5]. We use the perturbed data eρ+γnnρ,em+γnnmto solve the inverse
2900.10.20.30.4
00.10.20.30.40.5
00.10.20.30.40.5
-0.100.10.20.30.40.5
-2024610-3
-0.08-0.06-0.04-0.0200.020.04
-0.15-0.1-0.0500.05
-0.2-0.100.1
0 1000 2000 3000 4000 5000
UL iteration0123obs relative error
0 1000 2000 3000 4000 5000
UL iteration0123obs relative error
0 1000 2000 3000 4000 5000
UL iteration0123obs relative error
0 1000 2000 3000 4000 5000
UL iteration11.522.53obs relative errorFigure 4: Robustness test of the inverse crowd motion problem. Top to bottom: numerical b, the difference
between the numerical results and the ground truth b−eb, the relative error of bversus the number of
iterations. Left to right: noise level γn= 0,0.25,0.5,0.75.
Table 3: Robustness test of the inverse crowd motion problem.
γn relative error (last) time elapsed (second)
0 0.0081 1437.0926
0.25 0.0897 1343.8082
0.5 0.3771 1397.4578
0.75 0.7035 1379.7269
problem, where γn= 0,0.1,0.2,0.3. Row 1-2 of figure 5 illustrate the perturbed data.
When solving the inverse problem, we take the information on the left end Gk={ix:ix= 1}as known
and fix it. Same as section 6.2.2, we choose R(g) :=1
2γRR
∥∇g(x)∥2
2dxto regularize the smoothness of the
metric. The regularization weight γRtakes different values for different γnand the values are in Table 4.
We run Algorithm 2 for 5000 iterations with 5 iterations per each inner loop. The initialization of gtakes
value 1 everywhere. Figure 5 and table 4 compare the result with different γn.
From the comparison in Figure 5 and the relative error in Table 4, we observe that as the noise level
increases, the recovered metric deviates more from the ground truth. However, it is crucial to highlight that,
on the whole, our model adeptly captures the underlying shape of the metric with reasonable fidelity, and
the associated relative error remains consistently small. This robust performance underscores the resilience
of our model in the presence of added noise to the data.
6.4 Robustness with respect to unknowns
We present more numerical results to show that our method effectively recovers various types of obstacles
and metrics.
30-0.5 0 0.50.511.5
true
num
-0.5 0 0.50.511.5
true
num
-0.5 0 0.50.511.5
true
num
-0.5 0 0.50.511.5
true
num
0 1000 2000 3000 4000 50000.050.10.15
0 1000 2000 3000 4000 50000.050.10.15
0 1000 2000 3000 4000 50000.060.080.10.120.140.16
0 1000 2000 3000 4000 50000.080.10.120.14Figure 5: Robustness test of the inverse metric problem. Left to right: γn= 0,0.1,0.2,0.3. Top to bottom:
perturbed data eρ+γnnρ, perturbed data em+γnnm, comparison of numerical gand the ground truth eg, the
relative error of gversus the number of iterations.
6.4.1 Unknown obstacles
Besides the obstacle of the Gaussian type and of a “two-bar” shape, we conduct experiments on obstacles
with more irregular shapes. We plot examples of “the segmented ring” and “clover” in figure 6. In both
experiments, only one pair of data is used to recover the unknown obstacle. The figure shows that our
algorithm produces consistently good results when recovering various obstacles. Our model and algorithm
recover the shape of the obstacle and achieve very low relative errors.
6.4.2 Unknown 1D metric
Apart from the experiments in sections 6.2.2 and 6.3.2, we conduct experiments on more different metrics
and plot the results in Figure 7. In both experiments, we use only one pair of data and the ground truth
information on the left end. The figure shows that our model and algorithm consistently recover the ground
Table 4: Robustness test of the inverse metric problem.
γn γR relative error (last) time elapsed (second)
0 1×10−50.0358 63.4809
0.1 3×10−40.0380 63.2121
0.2 1×10−30.0645 61.5193
0.3 3×10−30.0815 60.7215
3100.10.20.30.4
00.20.40.60.8
00.10.20.30.40.5
0 1000 2000 3000 4000 5000
UL iteration00.511.52obs relative error
00.10.20.30.4
-0.100.10.20.30.40.5
-0.100.10.20.3
0 1000 2000 3000 4000 5000
UL iteration00.511.52obs relative errorFigure 6: Robustness test of the inverse obstacle problem with respect to the obstacle. Mesh grid size:
nt= 16, nx=ny= 64. Left to right: ground truths, numerical results, the difference between ground truths
and numerical results, the relative error of the obstacle versus the number of iterations. Top to bottom:
relative error=0.3837, 0.1935, time elapsed=4103s, 3247s.
truth metric and achieve low relative errors.
-0.5 0 0.52.533.544.55
true
num
0 1000 2000 3000 4000 500000.10.20.30.40.5
-0.5 0 0.511.522.5
true
num
0 1000 2000 3000 4000 500000.10.20.30.40.5
Figure 7: Robustness test of the inverse metric problem with respect to the metric. Mesh grid size: nt=
16, nx=ny= 64. Columns 1,3: comparison of numerical gand the ground truth eg, columns 2,4: the
relative error of gversus the number of iterations. Column 1,2: λ= 10−5, relative error=0.0172, time
elapsed=62.8513s, column 3,4: λ= 10−5, relative error=0.0172, time elapsed=63.0395s.
6.5 Unknown 2D metric
The last example is a 2D inverse metric problem on [ −0.5,0.5]2×[0,1]. We take nx=ny= 64 and
nt= 16. The ground truth metric is eg(x, y) =g0(x, y) + 4 g0(x, y) + 2
g0(x, y) + 2 g0(x, y) + 1
with g0(x, y) = 0 .75 +
0.5 sin(2 πx) cos(2 πy−0.5π). The data is obtained by taking γI= 0.1, γT= 1. We take N= 4, i.e.
4 observations, in this example. The initial densities are µ0=pg(·,·;ax, ay,0.1,0.1) with ( ax, ay) =
(−0.3,−0.3),(−0.3,0),(−0.3,0.3),(0,0.3),and the terminal densities are µ1(x, y) =pg(·,·;ax, ay,0.1,0.1)
with ( ax, ay) = (0 .3,0.3),(0.3,0),(0.3,−0.3),(0,−0.3). We solve the inverse problem with the weights of
smoothness regularizers γR= 10−4. The algorithm initiates from gxx= 4, gxy= 2 and gyy= 1. Each inner
loop takes 5 iterations and each outer loop takes 5000 iterations. Columns 1-3 of Figure 8 shows the ground
truth, the recovered metric, and the difference between the numerical result and ground truth. Our model
and algorithm capture the symmetricity of the ground truth metric and achieve a relative error of value
0.0260.
324.44.64.855.2
4.24.44.64.855.2
-0.200.2
2.42.62.833.2
2.22.42.62.833.2
-0.2-0.100.10.2
1.41.61.822.2
1.21.41.61.822.2
-0.100.10.2Figure 8: Solving an inverse problem with an unknown metric in 2D. Mesh grid size: nt= 16, nx=ny= 64.
Left to right: ground truths, numerical results, the difference between ground truths and numerical results.
Top to bottom: gxx, gxy, gyy. Relative error=0.0260, time elapsed=4327.5671s.
7 Conclusion
In conclusion, this paper introduces a novel bilevel optimization framework to tackle inverse mean-field games
for learning metrics and obstacles. We also design an alternating gradient descent algorithm to solve the
proposed bilevel problems. The primary advantage of our proposed formulation is its ability to retain the
convexity of the objective function and the linearity of constraints in the forward problem. Focusing on the
inverse mean-field games involving unknown obstacles and metrics, we have achieved numerical stability in
these setups. A significant contribution of our research is establishing unique identifiability in the inverse
crowd motion model with unknown obstacles based on one pair of input and revealing when the solution of the
bilevel problem is stable to the noisy data. Employing an alternating gradient-based optimization algorithm
within our bilevel approach, we ensure its convergence and illustrate its effectiveness through comprehensive
numerical experiments. These experiments serve as robust validation, underscoring the practical applicability
and reliability of our algorithm in resolving inverse problems. Our model and techniques offer a new approach
to understanding and further explorations and application of inverse mean-field games.
References
[1] Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse
problems. SIAM journal on imaging sciences , 2(1):183–202, 2009.
[2] Jean-David Benamou and Guillaume Carlier. Augmented lagrangian methods for transport optimiza-
tion, mean-field games and degenerate pdes. 2014.
[3] Jean-David Benamou and Guillaume Carlier. Augmented lagrangian methods for transport optimiza-
tion, mean field games and degenerate elliptic equations. Journal of Optimization Theory and Applica-
tions, 167(1):1–26, 2015.
33[4] Antonin Chambolle and Thomas Pock. A first-order primal-dual algorithm for convex problems with
applications to imaging. Journal of mathematical imaging and vision , 40:120–145, 2011.
[5] Tianyi Chen, Yuejiao Sun, and Wotao Yin. Closing the gap: Tighter analysis of alternating stochastic
gradient methods for bilevel problems. Advances in Neural Information Processing Systems , 34:25294–
25307, 2021.
[6] Yat Tin Chow, Samy Wu Fung, Siting Liu, Levon Nurbekyan, and Stanley Osher. A numerical algorithm
for inverse problem from partial boundary measurement arising from mean field game problem. Inverse
Problems , 39(1):014001, 2022.
[7] Lisang Ding, Wuchen Li, Stanley Osher, and Wotao Yin. A mean field game inverse problem. Journal
of Scientific Computing , 92(1):7, 2022.
[8] Riccardo Grazzi, Luca Franceschi, Massimiliano Pontil, and Saverio Salzo. On the iteration complexity
of hypergradient computation. In International Conference on Machine Learning , pages 3748–3758.
PMLR, 2020.
[9] Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang. A two-timescale stochastic algorithm
framework for bilevel optimization: Complexity analysis and application to actor-critic. SIAM Journal
on Optimization , 33(1):147–180, 2023.
[10] Minyi Huang, Peter E Caines, and Roland P Malham´ e. Large-population cost-coupled lqg problems with
nonuniform agents: individual-mass behavior and decentralized ε-nash equilibria. IEEE transactions
on automatic control , 52(9):1560–1571, 2007.
[11] Minyi Huang, Roland P Malham´ e, Peter E Caines, et al. Large population stochastic dynamic games:
closed-loop mckean-vlasov systems and the nash certainty equivalence principle. Communications in
Information & Systems , 6(3):221–252, 2006.
[12] Oleg Imanuvilov, Hongyu Liu, and Masahiro Yamamoto. Lipschitz stability for determination of states
and inverse source problem for the mean field game equations, 2023.
[13] Kaiyi Ji, Junjie Yang, and Yingbin Liang. Bilevel optimization: Convergence analysis and enhanced
design. In International conference on machine learning , pages 4882–4892. PMLR, 2021.
[14] Pushkin Kachroo, Shaurya Agarwal, and Shankar Sastry. Inverse problem for non-viscous mean field
control: Example from traffic. IEEE Transactions on Automatic Control , 61(11):3412–3421, 2015.
[15] Michael V Klibanov. Lipschitz stability estimate and uniqueness for a problem for the mean field games
system. arXiv preprint arXiv:2303.03928 , 2023.
[16] Michael V. Klibanov. The mean field games system: Carleman estimates, lipschitz stability and unique-
ness, 2023.
[17] Michael V Klibanov and Yurii Averboukh. Lipschitz stability estimate and uniqueness in the retrospec-
tive analysis for the mean field games system via two carleman estimates, 2023.
[18] Michael V Klibanov and Jingzhi Li. The mean field games system with the lateral cauchy data via
carleman estimates, 2023.
[19] Michael V Klibanov, Jingzhi Li, and Hongyu Liu. Holder stability and uniqueness for the mean field
games system via carleman estimates, 2023.
[20] Jean-Michel Lasry and Pierre-Louis Lions. Mean field games. Japanese journal of mathematics ,
2(1):229–260, 2007.
[21] Alex Tong Lin, Samy Wu Fung, Wuchen Li, Levon Nurbekyan, and Stanley J Osher. Apac-net: Alter-
nating the population and agent control via two neural networks to solve high-dimensional stochastic
mean field games. Proc. Natl. Acad. Sci. U.S.A. , 118(31), 2021. e2024713118.
34[22] Hongyu Liu, Chenchen Mou, and Shen Zhang. Inverse problems for mean field games, 2022.
[23] Hongyu Liu and Shen Zhang. On an inverse boundary problem for mean field games, 2022.
[24] Hongyu Liu and Shen Zhang. Simultaneously recovering running cost and hamiltonian in mean field
games system, 2023.
[25] Nicolas Papadakis. Optimal transport for image processing . PhD thesis, 2015.
[26] Nicolas Papadakis, Gabriel Peyr´ e, and Edouard Oudet. Optimal transport with proximal splitting.
SIAM Journal on Imaging Sciences , 7(1):212–238, 2014.
[27] Kui Ren, Nathan Soedjak, and Kewei Wang. Unique determination of cost functions in a multipopulation
mean field game model, 2023.
[28] Lars Ruthotto, Stanley J Osher, Wuchen Li, Levon Nurbekyan, and Samy Wu Fung. A machine learning
framework for solving high-dimensional mean field game and mean field control problems. Proceedings
of the National Academy of Sciences , 117(17):9183–9193, 2020.
[29] Paul Vicol, Jonathan P Lorraine, Fabian Pedregosa, David Duvenaud, and Roger B Grosse. On implicit
bias in overparameterized bilevel optimization. In International Conference on Machine Learning , pages
22234–22259. PMLR, 2022.
[30] Quan Xiao, Han Shen, Wotao Yin, and Tianyi Chen. Alternating projected sgd for equality-constrained
bilevel optimization. In International Conference on Artificial Intelligence and Statistics , pages 987–
1023. PMLR, 2023.
[31] Jiajia Yu, Rongjie Lai, Wuchen Li, and Stanley Osher. A fast proximal gradient method and convergence
analysis for dynamic mean field planning, 2023.
35