A Bilevel Optimization Method for Inverse Mean-Field Gamesâˆ—
Jiajia Yuâ€ Quan Xiaoâ€¡Tianyi ChenÂ§Rongjie LaiÂ¶
Abstract
In this paper, we introduce a bilevel optimization framework for addressing inverse mean-field games,
alongside an exploration of numerical methods tailored for this bilevel problem. The primary benefit
of our bilevel formulation lies in maintaining the convexity of the objective function and the linearity
of constraints in the forward problem. Our paper focuses on inverse mean-field games characterized by
unknown obstacles and metrics. We show numerical stability for these two types of inverse problems.
More importantly, we, for the first time, establish the identifiability of the inverse mean-field game with
unknown obstacles via the solution of the resultant bilevel problem. The bilevel approach enables us to
employ an alternating gradient-based optimization algorithm with a provable convergence guarantee. To
validate the effectiveness of our methods in solving the inverse problems, we have designed comprehensive
numerical experiments, providing empirical evidence of its efficacy.
1 Introduction
Mean-field games study the Nash Equilibrium in a non-cooperative game with infinitely many agents. In
the game, each agent aims to minimize a combination of dynamic cost, interaction cost, and terminal cost
by controlling its own state trajectory. At the Nash Equilibrium, the agents cannot unilaterally reduce their
costs. The theory is proposed in [20, 11, 10] and has attracted increasing attention since then.
In most existing works, knowing the cost functions is required to solve mean-field games. However, in
practice, these cost functions are not always easy to obtain. In contrast, the state distribution, the strategies
of agents, and sometimes the value function at the Nash Equilibrium can be observed. Thus, a natural
question arises: Can we learn the cost functions from the Nash Equilibrium? We refer to this as the inverse
mean-field game problem, and to the original one as the forward problem.
Unlike the forward problem, relatively few studies focus on inverse mean-field games. [14] derives two
traffic flow models as the solutions of non-viscous mean-field games. [7] reconstructs the underlying metric
in the dynamic cost and the kernel in the non-local interaction cost from the possibly noisy observation
of agent distribution and strategy. [6] learns the running cost from population density and strategy on a
given boundary. [22, 23, 24, 27] establish the theoretical unique identifiability result for a general class of
mean-field games, mean-field game boundary problems and multipopulation mean-field games, where infinite
pairs of training data are required in the proof. Following [17], a series of works [15, 16, 18, 19, 12] study
the stability and uniqueness of inverse mean-field game through Carleman estimates.
In this paper, we study a typical class of forward problems, the potential mean-field games. Applications
like crowd motion [28] and generative models [21] have the formulations of potential mean-field games. In a
potential mean-field game, the Nash Equilibrium is a pair of agent distribution Ïand strategy mminimizing
a cost Lwhich consists of the dynamic cost L, the interaction cost FIand the terminal cost FT, under a
constraint C(Âµ0) for density and strategy evolution dynamics:
(Ïâˆ—,mâˆ—) := argmin
Ï,mâˆˆC(Âµ0)L(Ï,m;L,FI,FT). (1)
âˆ—This work is suppoted in part by NSF DMS-2134168.
â€ J. Yu (jiajia.yu@duke.edu) is with the Department of Mathematics, Duke University.
â€¡Q. Xiao (xiaoq5@rpi.edu) is with the Department of Electrical, Computer, and Systems Engineering, Rensselaer Polytechnic
Institute.
Â§T. Chen (chent18@rpi.edu) is with the Department of Electrical, Computer, and Systems Engineering, Rensselaer Poly-
technic Institute.
Â¶R Lai (lairj@purdue.edu) is with the Department of Mathematics, Purdue University.
1arXiv:2401.05539v1  [math.OC]  10 Jan 2024The inverse problem is to identify L,FIorFTgiven ( Ïâˆ—,mâˆ—). Typical choices of L,FIandFTmake (1) a
(strongly) convex optimization problem with linear constraint. Taking Lunknown and FI,FTknown as an
example, we thus consider the following bilevel optimization problem
min
LD((Ïâˆ—,mâˆ—),(Ï(L),m(L))) +R(L)
s.t. (Ï(L),m(L)) := argmin
Ï,mâˆˆC(Âµ0)L(Ï,m;L,FI,FT).(2)
HereDis a fidelity term and Ris a regularity term. Existing works [7, 6] use the nonlinear and nonconvex
PDE optimality conditions as constraints. Consequently, achieving a theoretical convergence guarantee
is challenging. In contrast, we propose a bilevel formulation for inverse mean-field games, which directly
incorporates the forward problem as the constraint. This bilevel formulation maintains the desirable convex-
linear structure of the forward problem (the lower-level problem) and enables us to adopt a gradient-based
bilevel optimization algorithm [5, 29, 13, 9, 30] to address the inverse problem (2). Moreover, leveraging this
convex-linear structure, we have developed a convergence result, demonstrating that our algorithm converges
to the stationary point of the bilevel problem.
A common question in inverse mean-field games concerns the stability and unique identifiability of the
unknown parameter or function relative to the data. In our setting, we ask whether it is possible to uniquely
recover the cost functions from a single pair of observations ( Ïâˆ—,mâˆ—) and whether the recovered cost func-
tion continuously depends on these observations. This setup differs significantly from the theoretical work
discussed in [22, 23]. In those studies, the authors demonstrate that if the interaction and terminal costs are
local, holomorphic in Ï(x, t), and meet zero admissibility conditions, then it is possible to uniquely recover
them from infinitely many observations either throughout the full domain or on its boundary. However,
in our case, the cost function for a crowd motion model typically does not satisfy the zero admissibility
condition. Moreover, obtaining infinitely many observations is not feasible in practice. In this work, we
establish stability results for a general model and unique identifiability results for crowd motion models at
a discrete level. Specifically, for a general model, we prove that our model can achieve a close solution to
the ground truth with noisy observation, and for the crowd motion model, we prove that only one pair of
complete observation ( Ïâˆ—,mâˆ—) is sufficient to uniquely recover the obstacle function, up to a constant. Thus,
compared to the requirement of infinitely many observations in [22], our result is more practical and offers
insights into what constitutes an effective observation for accurately recovering the ground truth.
Contribution: We summarize our contributions as follows.
1. We propose a bilevel optimization framework for modeling inverse mean-field games.
2. We study a general model of mean-field games and show that the unknown cost parameters continuously
depend on the observation of the Nash Equilibrium.
3. For the crowd motion model, we prove that up to a constant, the ground truth obstacle function is the
unique minimizer to the bilevel optimization problem of the inverse mean-field game.
4. We apply an alternating gradient-based bilevel optimization algorithm to solve inverse mean-field games
and prove the algorithm converges to the stationary point of the bilevel problem.
5. We implement the algorithm and illustrate the effectiveness of our model and algorithm with compre-
hensive numerical experiments.
Organization: The paper is organized as follows. In section 2, we briefly review the potential mean-
field games and provide two examples of forward mean-field game models whose inverse problem will be
addressed in this paper. In section 3, we provide the bilevel optimization model for inverse mean-field games
and discretize the model. We also state the stability of both models and the unique identifiability of the
inverse crowd motion model and prove them in section 5. In section 4, we present the algorithm to solve
our bilevel model for inverse mean-field games and prove the convergence in section 5. In section 6, we
demonstrate our model and algorithm with experiments. Finally, we conclude our work in section 7.
22 A Review of Potential Mean-Field Games
In this section, we first review potential mean-field games and their optimality conditions [20, 11, 10]. Then
we present two example problems that we would like to solve in the inverse problem setup.
Consider a problem defined spatially on â„¦ âŠ‚Rdand temporally on [0 ,1].Ï: â„¦Ã—[0,1]â†’Ris the state
density. v: â„¦Ã—[0,1]â†’Rdrepresents the velocity (control) field of the agents and m:=Ïvthe flux. A
potential mean-field game typically has the following formulation:
min
(Ï,m)âˆˆC(Âµ0)L(Ï,m) :=Z1
0Z
â„¦Ï(x, t)L
x,m(x, t)
Ï(x, t)
dxdt+Z1
0FI(Ï(Â·, t))dt+FT(Ï(Â·,1)) (3)
with the constraint set being
C(Âµ0) :={(Ï,m) :âˆ‚tÏ+âˆ‡ Â·m= 0, Ï(Â·,0) = Âµ0,mÂ·n= 0 for xâˆˆâˆ‚â„¦, Ï(Â·,Â·)â‰¥0}. (4)
where nis the normal direction on the boundary âˆ‚â„¦. It is clear to see that any pair of ( Ï,m)âˆˆ C(Âµ0)
satisfies mass conservation and zero boundary flux condition with the initial density of Ïbeing Âµ0. In this
objective function, L: â„¦Ã—Rdâ†’Rmodels the dynamic cost, FI:P(â„¦)â†’Rthe interaction cost and
FT:P(â„¦)â†’Rthe terminal cost.
To derive the optimality condition of (3), we introduce the Lagrangian multiplier Ï•and formulate the
Lagrangian
A(Ï,m, Ï•) :=L(Ï,m)âˆ’Z1
0Z
â„¦Ï•(x, t) (âˆ‚tÏ(x, t) +âˆ‡ Â·m(x, t)) dxdt
=L(Ï,m) +Z1
0Z
â„¦Ï(x, t)âˆ‚tÏ•(x, t)dxdt+Z1
0Z
â„¦m(x, t)Â· âˆ‡Ï•(x, t)dxdt
âˆ’Z
â„¦Ï•(x,1)Ï(x,1)dx+Z
â„¦Ï•(x,0)Âµ0(x)dx,(5)
where the second equality is due to integration by part. The optimal solution solves the saddle point problem
min
Ïâ‰¥0,mmax
Ï•A(Ï,m, Ï•). (6)
When L(x,v) is convex in v, let the Legendre transformation of Lbe
H: â„¦Ã—Rdâ†’R,(x,p)7â†’sup
v{âˆ’âŸ¨p,vâŸ© âˆ’L(x,v)}. (7)
Then if Ï >0, the optimality condition of (3) is
ï£±
ï£²
ï£³âˆ’âˆ‚tÏ•(x, t) +H(x,âˆ‡Ï•(x, t)) =Î´FI(Ï)
Î´Ï(x), Ï•(x,1) =Î´FT(Ï)
Î´Ï(x),
âˆ‚tÏ(x, t)âˆ’ âˆ‡ Â· (Ï(x, t)âˆ‚pH(x,âˆ‡Ï•(x, t))) = 0 , Ï(Â·,0) = Âµ0.(8)
We use this forward-backward PDE system to explore the properties of the inverse problem later.
In this paper, we focus on the following two problems.
Problem 2.1 (Crowd motion with obstacle) .A common example comes from crowd motion [28], whose
formulation is
min
(Ï,m)âˆˆC(Âµ0)L(Ï,m;b) :=Z1
0Z
â„¦âˆ¥m(x, t)âˆ¥2
2
2Ï(x, t)dxdt+Z1
0Z
â„¦Ï(x, t)b(x)dxdt
+Î³IZ1
0Z
â„¦Ï(x, t) logÏ(x, t)dxdt+Î³TZ
â„¦Ï(x, t) (log Ï(x, t)âˆ’logÂµ1(x)) dx.(9)
Here the terminal cost is the KL divergence FT(Ï(Â·,1)) =R
â„¦Ï(x, t) (log Ï(x, t)âˆ’logÂµ1(x)) dxwhich aims
to match the terminal density Ï(Â·,1) to the desired density Âµ1. The interaction cost contains two parts.
3The entropy termR
â„¦Ï(x, t) logÏ(x, t)dxpenalizes the aggregation of the density. And the obstacle termR
â„¦Ï(x, t)b(x)dxpenalizes the mass going through the obstacle xwith larger value of b(x). With the same
initial density Âµ0, different obstacle functions lead to different Nash Equilibrium. Assuming that we know
everything in the objective function (9) except the obstacle function b, we aim to recover bfrom observations
of the equilibrium ( Ï,m).
Problem 2.2 (Non-Euclidean metric) .It is also common to consider mean-field games on spaces with non-
Euclidean metrics. If at each xâˆˆâ„¦,â„¦âŠ‚Rd, there is a positive definite matrix g(x)âˆˆSd
++indicating the
metric, then the mean-field game problem takes the form
min
(Ï,m)âˆˆC(Âµ0)L(Ï,m;g) :=Z1
0Z
â„¦m(x, t)âŠ¤g(x)m(x, t)
2Ï(x, t)dxdt
+Î³IZ1
0Z
â„¦Ï(x, t) logÏ(x, t)dxdt+Î³TZ
â„¦Ï(x, t) (log Ï(x, t)âˆ’logÂµ1(x)) dx.(10)
We also work on solving the metric gfrom the observations of the equilibrium ( Ï,m), assuming other terms
in (10) are known.
In summary, we are interested in the mean-field game problem with the objective function
L(Ï,m;g, b) :=Z1
0Z
â„¦m(x, t)âŠ¤g(x)m(x, t)
2Ï(x, t)dxdt+Z1
0Z
â„¦Ï(x, t)b(x)dxdt
+Î³IZ1
0Z
â„¦Ï(x, t) logÏ(x, t)dxdt+Î³TZ
â„¦Ï(x,1) (log Ï(x,1)âˆ’logÂµ1(x)) dx.(11)
We write L(Ï,m;g) when bâ‰¡0 and L(Ï,m;b) when gâ‰¡Id. With Ï >0, the optimality condition for the
problem
min
(Ï,m)âˆˆC(Âµ0)L(Ï,m;g, b), (12)
isï£±
ï£´ï£´ï£²
ï£´ï£´ï£³âˆ’âˆ‚tÏ•(x, t) +1
2(âˆ‡Ï•(x, t))âŠ¤(g(x))âˆ’1âˆ‡Ï•(x, t) =Î³I(logÏ(x, t) + 1) + b(x),
Ï•(x,1) = Î³T(logÏ(x, t)âˆ’logÂµ1(x) + 1) ,
âˆ‚tÏ(x, t)âˆ’ âˆ‡ Â· 
Ï(x, t)(g(x))âˆ’1âˆ‡Ï•(x, t)
= 0, Ï(Â·,0) = Âµ0.(13)
We call the potential mean-field games (3), as well as (9),(10), the forward problem. In this paper, we aim
to learn the unknown variables b, gfrom one or a set of observations of the Nash Equilibrium {(eÏn,emn)}N
n=1
that solve the forward problems, and we name this the inverse problem. Note that the forward problem has
a convex objective function and linear constraint, while the optimality condition is nonlinear and nonconvex.
To preserve the nice convex-linear structure of the forward problem, we formulate the inverse mean-field
game as a bilevel optimization problem and treat the forward problem as the constraint.
3 A Bilevel Formulation of Inverse Mean-Field Games
In this section, we first review the general formulation of a bilevel optimization problem, then provide the
bilevel formulation of inverse mean-field games, as well as two concrete inverse problems that we would like
to solve in this work. After that, we discretize the model for numerical implementation.
3.1 Bilevel Formulation
The general formulation of a bilevel optimization problem is
min
Î¾âˆˆÎu(Î¾) :=U(Î·âˆ—(Î¾);Î¾)
where Î·âˆ—(Î¾) = argmin
Î·âˆˆHL(Î·;Î¾).(14)
4Here we consider linear constraint set H={Î·|AÎ·=c}and convex set Î, where AâˆˆRdcÃ—dÎ·, câˆˆRdc.
dc< dÎ·. The optimization problem over Uis referred to as the upper-level problem and that over Las the
lower-level problem. We formulate our inverse problems as bilevel optimization problems, with the upper-
level objective being a combination of fidelity DÏ,Dmand regularity R, and the lower-level problem being
the forward problem.
min
LâˆˆCL,FIâˆˆCFIU((Ï,m),(eÏ,em);L,FI) := (DÏ(Ï,eÏ) +Dm(m,em)) +R(L,FI)
s.t. (Ï,m) := argmin
(Ï,m)âˆˆC(Âµ0)L(Ï,m;L,FI).
The dynamic cost Land interaction cost functional FIare the upper-level variables and the density-flux
pair ( Ï,m) is the lower-level variable. For convenience, we choose DÏ(Ï,eÏ) =1
2R1
0R
â„¦(Ï(x, t)âˆ’eÏ(x, t))2dxdt
andDÏ(m,em) =1
2R1
0R
â„¦âˆ¥m(x, t)âˆ’em(x, t)âˆ¥2
2dxdt
We formulate the inverse problems of problem 2.1 and 2.2 as follows.
Problem 3.1 (The inverse problem of crowd motion (problem 2.1)) .Let the regularity be R(b) = 0. The
inverse problem of (11) is
min
bâˆˆCbDÏ(Ï,eÏ) +Dm(m,em)
s.t. (Ï,m) := argmin
(Ï,m)âˆˆC(Âµ0)L(Ï,m;b).(15)
Here (eÏ,em) = argmin(Ï,m)âˆˆC(Âµ0)L(Ï,m;eb) are the observed data with ground truth eb. Notice that for any
constant câˆˆR, if (eÏ,em) minimizes L(Ï,m;eb), then ( eÏ,em) also minimizes L(Ï,m;eb+c). To remove the
ambiguity, we restrict our focus to obstacle functions with zero integral, i.e.
Cb:=
b:Z
â„¦b(x)dx= 0
. (16)
Ideally, we expect projCb(eb) to be the unique minimizer of the bilevel problem (15). We prove this unique
identifiability property for the discretization of (15) in section 5.
Problem 3.2 (The inverse problem of unknown metric (problem 2.2)) .Similarly, we have the bilevel for-
mulation to recover the metric egfrom the data ( eÏ,em) = argmin
(Ï,m)âˆˆC(Âµ0)L(Ï,m;eg).
min
gâˆˆCgDÏ(Ï,eÏ) +Dm(m,em) +R(g)
s.t. (Ï,m) := argmin
(Ï,m)âˆˆC(Âµ0)L(Ï,m;g).(17)
To make sure that ginduces a metric on â„¦, we set the constraint of gas
Cg:={g: â„¦â†’Sd
++:g(x) are positive definite matrices ,âˆ€xâˆˆâ„¦}. (18)
For one observation, if the density is zero in an open set, it means almost no players pass the region and it
is impossible to obtain the exact information in that region. However multiple observations may complement
the missing information, and therefore it is meaningful to consider the following inverse MFG with multiple
observations.
Problem 3.3 (The inverse problem of unknown metric (problem 2.2) with multiple observations) .Suppose
that we have multiple observations of the Nash Equilibrium with a given egfrom different initial densities
Âµn
0, n= 1,Â·Â·Â·, N, i.e. (eÏn,emn) = argmin
(Ï,m)âˆˆC(Âµn
0)L(Ï,m;eg) for n= 1,2,Â·Â·Â·, N. Then we can solve the following
bilevel optimization problem to recover the true metric.
min
gâˆˆCgNX
n=1(DÏ(Ïn,eÏn) +Dm(mn,emn)) +R(g)
s.t.{(Ïn,mn)}N
n=1:= argmin
(Ïn,mn)âˆˆC(Âµn
0)NX
n=1L(Ïn,mn;g).(19)
5The lower-level is equivalent to a concatenation of Nforward problems since ( Ïn,mn) are independent.
3.2 Discretization
We conduct numerical experiments on Rdwith d= 1,2. Taking d= 2 as an example, we let â„¦ = [0 ,1]Ã—[0,1]
and the space-time joint domain be [0 ,1]3, and we write m= (mx, my). We follow the discretization in
[31], with which the discrete optimizer is consistent with the continuous optimizer under certain regularity
conditions. To be precise, we equally divide [0 ,1] into nx, ny, ntparts, and each cube is of size âˆ† xâˆ†yâˆ†t, with
âˆ†x=1
nx,âˆ†y=1
ny,âˆ†t=1
nt.Letxi= (iâˆ’1
2)âˆ†x, yi= (iâˆ’1
2)âˆ†y, ti= (iâˆ’1
2)âˆ†t, and ( f)ixiyitapproximates
function fon points ( xix, yiy, tit). Similarly, ( f)ix,iyâ‰ˆf(xix, yiy). We define GÏ,GmxandGmyas the sets
of grid point indices on t-,x- and y-staggered grids, respectively, where
GÏ:={(ix, iy, it+1
2) :ix= 1,Â·Â·Â·, nx, iy= 1,Â·Â·Â·, ny, it= 1,Â·Â·Â·, nt},
Gmx:={(ix+1
2, iy, it) :ix= 1,Â·Â·Â·, nxâˆ’1, iy= 1,Â·Â·Â·, ny, it= 1,Â·Â·Â·, nt},
Gmy:={(ix, iy+1
2, it) :ix= 1,Â·Â·Â·, nx, iy= 1,Â·Â·Â·, nyâˆ’1, it= 1,Â·Â·Â·, nt}.
Then we approximate the function Ï, mxandmyont-,x- and y-staggered grids by ÏGÏ, mx
Gmxandmy
Gmy, re-
spectively, i.e. ÏGÏ:={(Ï)i}iâˆˆGÏâˆˆRnxnynt,mx
Gmx={(mx)i}iâˆˆGmxâˆˆR(nxâˆ’1)nyntandmy
Gmy={(my)i}iâˆˆGmyâˆˆ
Rnx(nyâˆ’1)nt. We denote Gm:=GmxÃ— Gmyas the concatenation of Gmx,GmyandmGm:={mx
Gmx, my
Gmy}
as the concatenation of mx
Gmx, my
Gmy. We will omit the under scripts of grids wherever there is no ambiguity
according to context. The left part of Figure 1 illustrates the staggered grids and the corresponding Ï, mx
ford= 1.
We define the inner products on the staggered grids as
âŸ¨Ï1, Ï2âŸ©GÏ:= âˆ†xâˆ†yâˆ†tX
iâˆˆGÏ(Ï1)i(Ï2)i,
âŸ¨mx
1, mx
2âŸ©Gmx:= âˆ†xâˆ†yâˆ†tX
iâˆˆGmx(mx
1)i(mx
2)i,
âŸ¨my
1, my
2âŸ©Gmy:= âˆ†xâˆ†yâˆ†tX
iâˆˆGmy(my
1)i(my
2)i,
and denote their induced norm as âˆ¥Â·âˆ¥GÏ,âˆ¥Â·âˆ¥Gmxandâˆ¥Â·âˆ¥Gmy. Based on these, we approximate the discrepancy
between lower-level minimizer and observed data DÏ,Dmby the sum of element-wise differences on grids
DGÏ,DGm,
DGÏ(Ï,eÏ) :=1
2âˆ¥Ïâˆ’eÏâˆ¥2
GÏ
DGm(m,em) :=1
2âˆ¥mxâˆ’emxâˆ¥2
Gmx+1
2âˆ¥myâˆ’emyâˆ¥2
Gmy.(20)
To compute the objective function, we consider the central grid (see the right plot in Figure 1)
GÏ•:={(ix, iy, it) :ix= 1,Â·Â·Â·, nx, iy= 1,Â·Â·Â·, ny, it= 1,Â·Â·Â·, nt}.
We define the inner product and induced norm on the central grid similarly and denote them as âŸ¨Â·,Â·âŸ©GÏ•and
âˆ¥Â·âˆ¥GÏ•. With the interpolation operators, Ï=It(Ï;Âµ0),mx=Ix(mx),my=Iy(my) meet on the central grid
points:
(Ï)ixiyit= (It(Ï;Âµ0))ixiyit:=ï£±
ï£²
ï£³1
2
(Âµ0)ix,iy+ (Ï)ix,iy,it+1
2
, i t= 1,
1
2
(Ï)ix,iy,itâˆ’1
2+ (Ï)ix,iy,it+1
2
, it= 2,Â·Â·Â·, nt.
(mx)ixiyit= (Ix(mx))ixiyit:=ï£±
ï£´ï£´ï£²
ï£´ï£´ï£³1
2(mx)ix+1
2,iy,it, i x= 1,
1
2
(mx)ixâˆ’1
2,iy,it+ (mx)ix+1
2,iy,it
, ix= 2,Â·Â·Â·, nxâˆ’1,
1
2(mx)ixâˆ’1
2,iy,it, i x=nx.
6Figure 1: Illustrations of the staggered (left) and central (right) grids.
(my)ixiyit= (Iy(my))ixiyit:=ï£±
ï£´ï£´ï£²
ï£´ï£´ï£³1
2(my)ix,iy+1
2,it, i y= 1,
1
2
(my)ix,iyâˆ’1
2,it+ (my)ix,iy+1
2,it
, iy= 2,Â·Â·Â·, nyâˆ’1,
1
2(my)ix,iyâˆ’1
2,it, i y=ny.
Here, the definition of mxonix= 1, nxandmyoniy= 1, nyare consistent with the zero-flux bound-
ary condition in the continuous setting. The objective functions of the forward problem can therefore be
approximated by
LG(Ï,m;g, b) := âˆ† xâˆ†yâˆ†tX
iâˆˆGÏ• 
(m)âŠ¤
i(g)ix,iy(m)i
2 (Ï)i+Î³I(Ï)ilog((Ï)i)!
+ âˆ†xâˆ†yâˆ†tX
iâˆˆGÏ(Ï)i(b)ix,iy
+Î³Tâˆ†xâˆ†ynxX
ix=1nyX
iy=1(Ï)ix,iy,nt+1
2
log(Ï)ix,iy,nt+1
2âˆ’log(Âµ1)ix,iy
.(21)
where m={mx, my}, (m)âŠ¤
ixiyit:= (( mx)ixiyit,(my)ixiyit) and the subscript of LGindicates the cost is
defined on the discrete space. Similar to the continuous notation, we write LG(Ï,m;g) when b=0and
LG(Ï,m;b) when gâ‰¡1 (d= 1) or gâ‰¡I2(d= 2).
With this discretization, LG(Ï,m;g, b) preserves the following properties on ( Ï,m) from the continuous
setting.
Lemma 3.4. ForLG(Ï,m;g, b)defined on (ÏGÏ, mx
Gmx, my
Gmy)âˆˆRnxnyntÃ—R(nxâˆ’1)nyntÃ—Rnx(nyâˆ’1)ntwith
min
iâˆˆGÏ(Ï)i>0, the following statements hold:
1. If Î³I, Î³Tâ‰¥0andgix,iyis positive definite for all ix, iy, then LG(Ï,m;g, b)is convex in Ï,m.
2. In addition to 1, if we restrict the domain to Ïwith min
iâˆˆGÏ(Ï)iâ‰¥cÏ>0,mxwith max
iâˆˆGmx(|mx
i|)â‰¤cm, and
mywith max
iâˆˆGmy(|my
i|)â‰¤cm, then LG(Ï,m;g, b)is Lipschitz smooth in Ï,m.
3. In addition to 1,2, if we further restrict the domain to ÏâˆˆRnxnyntwith max
iâˆˆGÏ(Ï)iâ‰¤cÏ, then for any
Î³I, Î³T>0,LG(Ï,m;g, b)is strongly convex in Ï,m.
We postpone the proof of the lemma in section 5 for better readability. The Lipschitz smoothness and
strong convexity of the lower-level objective are important to guarantee the convergence of our alternating
gradient algorithm, as detailed later in section 4.
7Following the nature of the staggered grid, we choose a central difference scheme to approximate the
differential operators.
(Dt(Ï;Âµ0))ixiyit:=ï£±
ï£²
ï£³1
âˆ†t
(Ï)ix,iy,it+1
2âˆ’(Âµ0)ix,iy
, i t= 1,
1
âˆ†t
(Ï)ix,iy,it+1
2âˆ’(Ï)ix,iy,itâˆ’1
2
, it= 2,Â·Â·Â·, nt.
(Dx(mx))ixiyit:=ï£±
ï£´ï£´ï£²
ï£´ï£´ï£³1
âˆ†x(mx)ix+1
2,iy,it, i x= 1,
1
âˆ†x
(mx)ix+1
2,iy,itâˆ’(mx)ixâˆ’1
2,iy,it
, ix= 2,Â·Â·Â·, nxâˆ’1,
âˆ’1
âˆ†x(mx)ixâˆ’1
2,iy,it, i x=nx.
(Dy(my))ixiyit:=ï£±
ï£´ï£´ï£²
ï£´ï£´ï£³1
âˆ†y(my)ix,iy+1
2,it, i y= 1,
1
âˆ†y
(my)ix,iy+1
2,itâˆ’(my)ix,iyâˆ’1
2,it
, iy= 2,Â·Â·Â·, nyâˆ’1,
âˆ’1
âˆ†y(my)ix,iyâˆ’1
2,it, i y=ny.
Again, the definitions of Dx, Dyonix= 1, nx, iy= 1, ny, respectively, are consistent with the zero-flux
boundary condition. The discrete constraint set is
CG(Âµ0) :={(Ï,m) :Dt(Ï;Âµ0) +Dx(mx) +Dy(my) =0}. (22)
Based on the above notations, we restate the inverse problems 3.1 and 3.2 in the discretized space. We
intentionally write down the problems for more general cases with multiple pairs of training data as they
will reduce to the case with a single pair data by chosing N= 1.
Problem 3.5 (The discretization of the inverse crowd motion problem 3.1) .The discretization of (15) has
the following formulation
min
bâˆˆCG,bNX
n=1(DGÏ(Ïn,eÏn) +DGm(mn,emn))
s.t. (Ïn,mn) := argmin
(Ï,m)âˆˆCG(Âµn
0)LG(Ï,m;b), n= 1,2,Â·Â·Â·, N,(23)
where ( eÏn,emn) = argmin(Ï,m)âˆˆCG(Âµn
0)LG(Ï,m;eb) are the observed data and
CG,b:=ï£±
ï£²
ï£³b:nx,nyX
ix,iy(b)ix,iy= 0ï£¼
ï£½
ï£¾. (24)
Problem 3.6 (The discretization of the inverse metric problem 3.2) .Similarly, given the data ( eÏn,emn) =
argmin
(Ï,m)âˆˆC(Âµn
0)L(Ï,m;eg), we implement algorithms to solve
min
gâˆˆCG,gNX
n=1(DGÏ(Ïn,eÏn) +DGm(mn,emn)) +RG(g)
s.t. (Ïn,mn) := argmin
(Ï,m)âˆˆCG(Âµn
0)LG(Ï,m;g), n= 1,2,Â·Â·Â·, N,(25)
with the constraint of gbeing
CG,g:={g: (g)ix,iyâˆˆRdÃ—dare positive definite matrices , ix= 1,Â·Â·Â·, nx, iy= 1,Â·Â·Â·, ny}. (26)
3.3 Regularity and Unique Identifiability of the Inverse Problems
At the end of this section, we state the regularity of the inverse problem 3.5 and 3.6 and the unique
identifiability of the inverse crowd motion problem 3.5.
8The regularity and unique identifiability of the inverse problem rely on the KKT system of the discretized
forward problem
min
(Ï,m)âˆˆC(Âµ0)LG(Ï,m;g, b).(27)
To write the KKT system in a concise way, we define the adjoint operators of Ix, Iy, Itfor any Ï•=Ï•GÏ•on
the central grid as
(Iâˆ—
t(Ï•))ix,iy,it+1
2:=(
1
2 
(Ï•)ixiyit+ (Ï•)ix,iy,it+1
, it= 1,Â·Â·Â·, ntâˆ’1,
1
2(Ï•)ixiyit, i t=nt.
(Iâˆ—
x(Ï•))ix+1
2,iy,it:=1
2 
(Ï•)ixiyit+ (Ï•)ix+1,iy,it
, ix= 1,Â·Â·Â·, nxâˆ’1.
(Iâˆ—
y(Ï•))ix,iy+1
2,it:=1
2 
(Ï•)ixiyit+ (Ï•)ix,iy+1,it
, iy= 1,Â·Â·Â·, nyâˆ’1.
and the adjoint operators of Dx, Dy, Dtas
(Dâˆ—
t(Ï•))ix,iy,it+1
2:=(
âˆ’1
âˆ†t 
(Ï•)ix,iy,it+1âˆ’(Ï•)ixiyit
, it= 1,Â·Â·Â·, ntâˆ’1
1
âˆ†t(Ï•)ixiyit, i t=nt.
(Dâˆ—
x(Ï•))ix+1
2,iy,it:=1
âˆ†x 
(Ï•)ix+1,iy,itâˆ’(Ï•)ixiyit
, ix= 1,Â·Â·Â·, nxâˆ’1
(Dâˆ—
y(Ï•))ix,iy+1
2,it:=1
âˆ†y 
(my)ix,iy+1,itâˆ’(my)ixiyit
, iy= 1,Â·Â·Â·, nyâˆ’1.
The adjoint relation in the discretized space holds based on the definitions. To be precise, for the interpolation
operators, we have
âŸ¨It(Ï;Âµ0), Ï•âŸ©GÏ•=âŸ¨Ï, Iâˆ—
t(Ï•)âŸ©GÏ+1
2nxX
ix=1nyX
iy=1(Âµ0)ix,iy(Ï•)ix,iy,1.
âŸ¨Ix(mx), Ï•âŸ©GÏ•=âŸ¨mx, Iâˆ—
x(Ï•),âŸ©Gmx.
âŸ¨Iy(my), Ï•âŸ©Gmy=âŸ¨my, Iâˆ—
y(Ï•),âŸ©Gmy.
and for differential operators, we have
âŸ¨Dt(Ï;Âµ0), Ï•âŸ©GÏ•=âŸ¨Ï, Dâˆ—
t(Ï•)âŸ©GÏâˆ’1
âˆ†tnxX
ix=1nyX
iy=1(Âµ0)ix,iy(Ï•)ix,iy,1.
âŸ¨Dx(mx), Ï•âŸ©GÏ•=âŸ¨mx, Dâˆ—
x(Ï•)âŸ©Gmx.
âŸ¨Dy(my), Ï•âŸ©GÏ•=âŸ¨my, Dâˆ—
y(Ï•)âŸ©Gmy.
With the adjoint operators, we define the Yoperators as following to describe the optimality condition
for the forward problem,
ï£±
ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£³iâˆˆ GÏ, it= 1,Â·Â·Â·, ntâˆ’1,
(YÏ(Ï,m, Ï•;g, b))i:=âˆ’(Dâˆ—
t(Ï•))i+
Iâˆ—
t
âˆ’(m)âŠ¤gm
2Ï2+Î³I(log(Ï) + 1)
i+bix,iy,
iâˆˆ GÏ,=nt,
(YÏ(Ï,m, Ï•;g, b))i:=âˆ’(Dâˆ—
t(Ï•))i+
Iâˆ—
t
âˆ’(m)âŠ¤gm
2Ï2+Î³I(log(Ï) + 1)
i+bix,iy
+Î³T
âˆ†t(log(Ïi)âˆ’log((Âµ1)ix,iy) + 1) ,
iâˆˆ Gmx,(Ymx(Ï,m, Ï•;g, b))i:=âˆ’(Dâˆ—
x(Ï•))i+
Iâˆ—
xgxxmx+gxymy
Ï
i,
iâˆˆ Gmy,(Ymy(Ï,m, Ï•;g, b))i:=âˆ’ 
Dâˆ—
y(Ï•)
i+
Iâˆ—
ygxymx+gyymy
Ï
i,
iâˆˆ GÏ•,(YÏ•(Ï,m, Ï•;g, b))i:= (Dt(Ï;Âµ0) +Dx(mx) +Dy(my))i.(28)
9YÏ,Yx
m,Yy
m,YÏ•are obtained by taking gradients on the Lagrangian of the forward problem (27). By viewing
Ï,m, Ï•, b andYÏ,Yx
m,Yy
m,YÏ•as long vectors and denoting Y:= (YÏ,Ymx,Ymy,YÏ•)âŠ¤, we define a function
Y:RdlÃ—Rduâ†’Rdlwith du= (d(d+1)
2+ 1)nxnycorresponding to the dimension of ( g, b) and dl=
nxnynt+ (nxâˆ’1)nynt+nx(nyâˆ’1)nt+nxnyntto the dimension of Ï, mx, my, Ï•. Since the constraint is
linear, the optimizer of (27) satisfies the KKT condition. The formal statement is the following.
Lemma 3.7. If(eÏ,em)âˆˆ C(Âµ0)is a minimizer of LG(Ï,m;eg,eb), and min
iâˆˆGÏ{eÏi}>0, then there exists eÏ•âˆˆ
Rnxnyntsuch that
Y(eÏ,em,eÏ•;eg,eb) =0. (29)
With the discrete PDE description of the Nash Equilibrium, we state the regularity result for the inverse
problem 3.5 and 3.6.
Theorem 3.8 (Regularity) .Assume that (eÏ,em)is the Nash Equilibrium given the metric eg, obstacle function
ebandÎ³I>0, Î³T>0, i.e. (27) holds, and that min
iâˆˆGÏeÏi>0, then there exists ru>0and a radius ruopen ball
Bru(eg,eb)centered at (eg,eb), and a mapping Tdefined on Bru(eg,eb)satisfying the following
â€¢For any (g, b)âˆˆBru(eg,eb), there exist a unique (Ï,m, Ï•) =T(g, b)âˆˆBrl(eÏ,em,eÏ•), a radius rlopen ball
centered at (eÏ,em,eÏ•), such that (Ï,m, Ï•)solves the forward problem with LG(Ï,m;g, b).
â€¢T(eg,eb) = (eÏ,em,eÏ•),Tis of class C1and
DT(g, b) =âˆ’(DÏ,m,Ï•Y(T(g, b);g, b)))âˆ’1(DbY(T(g, b);g, b)),for all (g, b)âˆˆBru(eg,eb). (30)
In addition, we have the unique identifiability of the inverse crowd motion problem because the lower-
level objective has a simple dependence on the obstacle b. To be concrete, by solving the inverse crowd
motion problem 3.5, we uniquely recover the ground truth obstacle ebup to a constant from only one good
observation of the Nash Equilibrium.
Theorem 3.9 (Unique identifiability) .Assume that (eÏ,em)is the Nash Equilibrium given the obstacle func-
tioneb, i.e.
(eÏ,em) := argmin
(Ï,m)âˆˆCG(Âµ0)LG(Ï,m;eb), (31)
and that min
iâˆˆGÏeÏi>0, then any minimizer bof the bilevel minimization problem
min
bDGÏ(Ï,eÏ) +DGm(m,em)
s.t.(Ï,m) := argmin
(Ï,m)âˆˆCG(Âµ0)LG(Ï,m;b),(32)
has the form b=eb+cwhere câˆˆRis a constant. This implies that ebis the unique minimizer of the bilevel
minimization problem (32) up to a constant.
The proofs are postponed to section 5. We close this section with some remarks on the theorems.
Remark 3.10 (Numerical stability) .While the unique identifiability Theorem 3.9 holds without the entropy
term and the regularity Theorem 3.8, we emphasize that the entropy term and regularity theorem are
meaningful for studying the numerical stability of the inverse problem. In fact, the entropy term guarantees
the strong convexity of the objective function and thus the uniqueness of the forward problem. And it is
important for the regularity Theorem 3.8 to hold. The regularity argument states the differentiability of the
forward optimizer with respect to the metric gand the obstacle band reveals the rate of change. According
to Theorem 3.9, if the smallest singular value of DT(g, b) is large, then a small perturbation to ( eÏ,em) can
still give a reasonable approximation of the ground truth eg,eb. It is also worth noting that when min ieÏiis
close to 0, the condition number of the Jacobian matrix DÏ,m,Ï•Y(eÏ,em,eÏ•;b) in (30) can be extremely large.
Therefore the Jacobian matrix Db(Ï,m, Ï•) is close to singular, and the observation error may cause a failure
to recover the ground truth obstacle.
10Remark 3.11 (Unique identifiability in the function space) .Theorem 3.9 establishes the unique identifiability
of the obstacle bGâˆˆRnxnyin the discretized finite-dimensional space. To prove the parallel result for the
obstacle function b: â„¦â†’Rin the infinite-dimension space, it is subtle to choose the function space for
b, Ï,m, and Ï•. The function space is expected to be large enough to guarantee the existence of the lower-level
optimizers Ïâˆ—(b),mâˆ—(b) for different b, and to guarantee the existence of the bilevel problem optimizer bâˆ—.
Meanwhile, the functions in the space require enough regularity for Ïâˆ—(b),mâˆ—(b) to be differentiable with
respect to b. This is out of the scope of this paper. We refer interested readers to [22, 23, 27] for efforts
in studying the unique identifiability in the infinite-dimensional space, where infinity many pairs of training
data are required.
Remark 3.12 (Unique identifiability of the unknown metric) .To establish the local unique identifiability of
the metric as a corollary of the stability Theorem 3.8, we need DgY(eÏ,em,eÏ•;g) to have full rank. However, for
1D metric, the rank of DgY(eÏ,em,eÏ•;g) depends on the data eÏ,em,eÏ•, which is different from DbY(eÏ,em,eÏ•;b)
being a constant. Therefore, we may not uniquely recover the metric from the data. Besides the degenerated
rank, while uniquely identifying grequires the knowledge of eÏ•, we do not have eÏ•in our problem setting and
this can also cause non-uniqueness of the inverse problem. By experiments in [7], the lack of information on
eÏ•can be overcome by giving partial true information on the metric and incorporating regularity terms in the
upper-level objective. For 2D metric, if we view gxx, gxy, gyyas independent variables, then DgY(eÏ,em,eÏ•;g)
is not a full-rank matrix and theoretically there is no hope to uniquely recover the ground truth metric. If
the metric giâˆˆS2
++has intrinsic structures such that the number of variables to determine the metric is
nxnyinstead of 3 nxny, numerically we recover the ground truth with a low error as shown by the numerical
experiment in section 6.5. The numerical experiment in section 6.2.2 also shows that another way to resolve
the ambiguity is to have multiple observations for more complete information in the region.
4 Alternating Gradient Method
In this section, we present the alternating gradient method (AGM) to solve the general bilevel optimization
problem (14), as well as two inverse mean-field game problems 3.5 and 3.6.
4.1 Preliminary on AGM for Bilevel Optimization
The idea of the AGM is iteratively conducting gradient descent on the lower-level variable and the upper-level
variable. To illustrate our algorithm, we first consider the following unconstrained bilevel problem
min
Î¾âˆˆRduu(Î¾) :=U(Î·âˆ—(Î¾);Î¾)
where Î·âˆ—(Î¾) = argmin
Î·âˆˆRdlL(Î·;Î¾).(33)
The computation of the lower-level gradient is straightforward. To obtain the upper-level gradient, we assume
thatU,Lare differentiable and denote the gradient operator with respect to their first and second entries as
âˆ‡Î·,âˆ‡Î¾. If for any given Î¾, there exists a unique Î·âˆ—(Î¾) solving the lower-level optimization problem and the
function mapping Î¾to its corresponding minimizer Î·âˆ—(Î¾) is differentiable, then by chain rule, we have
âˆ‡u(Î¾) =âˆ‡Î¾Î·âˆ—(Î¾)âŠ¤âˆ‡Î·U(Î·âˆ—(Î¾);Î¾) +âˆ‡Î¾U(Î·âˆ—(Î¾);Î¾), (34)
withâˆ‡Î¾Î·âˆ—(Î¾) = ( âˆ‚Î¾1Î·âˆ—(Î¾), . . . , âˆ‚ Î¾duÎ·âˆ—(Î¾))âˆˆRdlÃ—dubeing the Jacobian matrix of Î·âˆ—. We clarify that here
âˆ‡Î¾U(Î·âˆ—(Î¾);Î¾) is the gradient of Uwith respect to its second entry evaluated at ( Î·âˆ—(Î¾);Î¾) without considering
the dependence of Î·âˆ—onÎ¾. Therefore âˆ‡Î·U(Î·âˆ—(Î¾);Î¾) and âˆ‡Î¾U(Î·âˆ—(Î¾);Î¾) in (34) are easy to compute.
When the exact lower-level solution Î·âˆ—(Î¾) is unavailable, the upper-level gradient âˆ‡u(Î¾) is inaccessible.
However, we can approximate Î·âˆ—(Î¾) and therefore approximate âˆ‡Î¾u(Î¾). Specifically, for Î¾kuat the ku-th
iteration, we run Kl-step gradient descent of lower-level with stepsize Ï„lto approximate Î·âˆ—(Î¾ku), i.e.
ï£±
ï£´ï£²
ï£´ï£³Î·ku,1=Î·ku;
Î·ku,kl+1=Î·ku,klâˆ’Ï„lâˆ‡Î·L 
Î·ku,kl;Î¾ku
, kl= 1,Â·Â·Â·, Kl;
Î·ku+1=Î·ku,Kl+1.(35)
11It is easy to see that Î·ku,kl+1=Î·ku,kl+1(Î¾ku)(kl= 1,Â·Â·Â·, Kl) and Î·ku+1=Î·ku+1(Î¾ku) are functions of Î¾ku.
We drop the dependence for notation conciseness and estimate the upper-level gradient âˆ‡u(Î¾ku) by
bâˆ‡u(Î¾ku) := 
âˆ‡Î¾kuÎ·ku+1âŠ¤âˆ‡Î·U 
Î·ku+1;Î¾ku
+âˆ‡Î¾U 
Î·ku+1;Î¾ku
, (36)
where the Î·kuis a lower-level estimator of the lower-level optimizer Î·âˆ—(Î¾ku), and ( âˆ‡Î¾kuÎ·ku+1)ij=âˆ‚Î¾ku
jÎ·ku+1
i
estimates âˆ‡Î¾Î·âˆ—(Î¾ku) by unrolling the lower-level iterates through the chain rule. With the estimator in (36),
we then update the upper-level variable by gradient descent with stepsize Ï„u, i.e.
Î¾ku+1=Î¾kuâˆ’Ï„ubâˆ‡u(Î¾ku). (37)
We summarize the algorithm in Algorithm 1
Algorithm 1 General AGM for unconstrained bilevel optimization problem (33)
Initialization: Î¾1, Î·1, stepsizes {Ï„u, Ï„l}
forku= 1,2,Â·Â·Â·, Kudo
Initialize lower-level update by Î·ku,1=Î·ku.
forkl= 1,2Â·Â·Â·, Kldo
lower-level gradient descent
Î·ku,kl+1=Î·ku,klâˆ’Ï„lâˆ‡Î·L(Î·ku,kl;Î¾ku). (38)
end for
Let the lower-level estimator be Î·ku+1=Î·ku,Kl+1and compute bâˆ‡u(Î¾ku) by (36).
Conduct upper-level gradient descent
Î¾ku+1=Î¾kuâˆ’Ï„ubâˆ‡u(Î¾ku). (39)
end for
Remark 4.1 (Error of unrolled differentiation) .(34) gives the exact value of the upper-level gradient. To
obtain the unknown âˆ‡Î¾Î·âˆ—(Î¾) in (34), we refer to the first-order optimality condition from the lower-level
problem âˆ‡Î·L(Î·âˆ—(Î¾);Î¾) =0. We view âˆ‡Î·L(Î·âˆ—(Î¾);Î¾) as a vector-valued function of Î¾, and its Jacobian matrix
gives
âˆ‡Î¾Î·âˆ—(Î¾)âŠ¤âˆ‡Î·Î·L(Î·âˆ—(Î¾);Î¾) +âˆ‡Î¾Î·L(Î·âˆ—(Î¾);Î¾) =0, (40)
where ( âˆ‡Î¾Î·L)ij(Î·, Î¾) =âˆ‚Î¾iâˆ‚Î·jL(Î·, Î¾) and ( âˆ‡Î·Î·L)ij(Î·, Î¾) =âˆ‚Î·iâˆ‚Î·jL(Î·, Î¾) are blocks of the Hessian matrix of
L. Therefore
âˆ‡Î¾Î·âˆ—(Î¾)âŠ¤=âˆ’âˆ‡Î¾Î·L(Î·âˆ—(Î¾);Î¾) (âˆ‡Î·Î·L(Î·âˆ—(Î¾);Î¾))âˆ’1. (41)
Plugging (41) into (34) gives the upper-level gradient
âˆ‡u(Î¾) =bâˆ‡Î¾U(Î·âˆ—(Î¾);Î¾), (42)
where
bâˆ‡Î¾U(Î·;Î¾) =âˆ‡Î¾U(Î·;Î¾)âˆ’ âˆ‡ Î¾Î·L(Î·;Î¾) (âˆ‡Î·Î·L(Î·;Î¾))âˆ’1âˆ‡Î·U(Î·;Î¾). (43)
The gradient estimator (36) approximate the true gradient by approximating Î·âˆ—byÎ·ku+1and approximating
(âˆ‡Î·Î·L(Î·;Î¾))âˆ’1by unrolling differentiation. A key to the convergence of the AGM algorithm is to control the
error of unrolling differentiation. For unconstrained problems, [8, 13] proved that under sufficient smoothness
assumptions, the errors of the approximations decrease as klincreases. In Lemma 5.3 of this paper, we study
and prove the error can also be bounded for linear equality constrained lower-level problems.
12Algorithm 2 General AGM for (14)
Initialization: Î¾1, Î·1, stepsizes {Ï„u, Ï„l}
forku= 1,2,Â·Â·Â·, Kudo
Initialize lower-level update by Î·ku,1=Î·ku.
forkl= 1,2Â·Â·Â·, Kldo
lower-level gradient descent
Î·ku,kl+1= proj
H 
Î·ku,klâˆ’Ï„lâˆ‡Î·L(Î·ku,kl;Î¾ku)
. (44)
end for
Let the lower-level estimator be Î·ku+1=Î·ku,Kl+1and compute bâˆ‡u(Î¾ku) by (36).
Conduct upper-level projected gradient descent
Î¾ku+1= proj
Î
Î¾kuâˆ’Ï„ubâˆ‡u(Î¾ku)
(45)
end for
4.2 AGM for Inverse Mean-Field Games
Building upon Algorithm 1 for unconstrained bilevel optimization problems (33), we propose Algorithm 2
to solve the constrained bilevel optimization problem (14) and its special cases in inverse mean-field game
problems 3.1 and 3.2.
Algorithm 2 applies the projected gradient descent to estimate the lower-level optimizer and to update
the upper-level optimizer at each iteration. Precisely, by denoting the matrix form of the constraint (22) as
AÎ·=c, the projection to H={Î·|AÎ·=c}is
proj
H(Î·) = (Iâˆ’Aâ€ A)Î·+Î·0,
where Aâ€ is the Moore-Penrose inverse and Î·0is a fixed solution to AÎ·=c. The projection operator is
invariant to the lower-level objective and the number of iterations. As discussed in [31], the main cost of
the lower-level projected gradient descent is to compute the inverse of the discretized Laplacian operator
(AAâŠ¤)âˆ’1, which can be solved efficiently using the fast cosine transform. We refer to section 3.2 in [31]
for all detailed discussions. Since each step in projected gradient descent is explicit, it is possible to unroll
the differentiation to estimate the upper-level gradient and thus conduct AGM for the constrained bilevel
optimization problem. It is worth emphasizing that the proximal gradient solver for the lower-level problem
[31] makes it easy and efficient to unroll the differentiation and estimate the upper-level gradient. This is not
the case for other popular lower-level solvers, for example, augmented Lagrangian [2, 3]and primal-dual [26,
25] because the implicit updates in these methods make unrolling the differentiation prohibitively complicated
and expensive. Meanwhile, although it is widely acknowledged in unconstrained bilevel optimization [8, 13]
that the error arising from unrolling differentiation is controllable, rigorously adapting this approach to
incorporate lower-level linear constraints is, to the best of our knowledge, unexplored. Lemma 5.3 in this
paper investigates the error of this approximation, indicating that the gradient estimation error can be
effectively bounded by the accuracy of the lower-level solution.
The complexity of resolving the upper-level constraint is similar to a single-level optimization problem.
In our cases, for the inverse crowd motion problem 3.5, the upper-level constraint set Î = CG,bas defined in
(24) is the set of matrices of size nxÃ—nywith entry sum zero. And the projection is simply projCG,b(b) =Ëœb,
where ( Ëœb)ix,iy= (b)ix,iyâˆ’1
nxnyPnx,ny
ix,iy(b)ix,iy. And for the inverse metric problem 3.6, Î = CG,g, where CG,g
is defined in (26). We compute the projection Ëœ g:= projCG,g(g) pointwisely. To be specific, for ( g)ix,iy, we first
compute its eigenvalue decomposition ( g)ix,iy=QÎ›Qâˆ’1where Î› = diag( Î»1, Î»2) and let (Ëœ g)ix,iy:=QËœÎ›Qâˆ’1
where ËœÎ› = diag(max( Î»1, Ïµ),max( Î»2, Ïµ)) with a pre-selected small positive value Ïµ.
Different from our bilevel formulation and AGM algorithm, [6, 7] treat the forward MFG PDE system
as the constraint of their optimization problem and apply primal-dual algorithm [4] to solve it. However,
13the nonlinear and nonconvex constraint makes it challenging to prove the algorithm convergence. On the
contrary, our bilevel formulation takes advantage of the convex-linear structure of the forward MFG and we
establish the following convergence theorem of our Algorithm 2.
If the upper-level and lower-level objective functions satisfy the following regularity assumptions,
Assumption 1.Assume that U,âˆ‡U,âˆ‡L,âˆ‡2Lis Lipschitz continuous with â„“u,0, â„“u,1, â„“l,1, â„“l,2, respectively.
Assumption 2.For any fixed Î¾, assume that L(Î·;Î¾) isÂµl-strongly convex with respect to Î·.
Assumption 3.Î is a linear constraint set Î = {Î¾|BÎ¾=e}, and Hand Î are nonempty.
then we have the following theorem.
Theorem 4.2. Under Assumption 1â€“3, let Ï„lâ‰¤1
2â„“l,1, Kl=O(logKu)andÏ„u=O(1), then the iterates of
Algorithm 2 satisfy
1
KuKuX
ku=1âˆ¥Î¾kuâˆ’proj
Î(Î¾kuâˆ’ âˆ‡u(Î¾ku))âˆ¥2=O1
Ku
(46)
where Oomits the logdependency.
Let us define Ïµstationary point as âˆ¥Î¾âˆ’projÎ(Î¾âˆ’ âˆ‡u(Î¾))âˆ¥2â‰¤Ïµ, then Theorem 4.2 states that Algorithm
2 achieves Ïµstationary point by O(Ïµâˆ’1) iterations. This matches the iteration complexity of the single-level
projected gradient descent method. We postpone the proof in section 5.
Lemma 3.4 states that when Ï,mare bounded, and when the entropy in the objective function is non-zero
(Î» >0), then our inverse problems 3.5 and 3.6 satisfy assumptions 1 and 2. Moreover, since the upper-level
constraint set of the inverse crowd motion problem 3.5 is linear, assumption 3 is satisfied and Theorem 4.2
guarantees the algorithm convergence when solving problem 3.5. For the inverse metric problem 3.6 where
the upper-level constraint set is a convex cone, the convergence of the algorithm can be established similarly.
However, the convergence rate is possibly different. We leave the study of the convergence rate for general
upper-level constraints set to future research.
At the end of this section, we discuss how to unroll differentiation in practice.
Remark 4.3 (Unroll differentiation in practice) .Recall that in our problem, the lower-level variable Î·=
(ÏGÏ,mGm) and the upper-level variable Î¾= (gG, bG) are of size O(d2ntnxny). To obtain the upper-level
gradient estimator (36), the computation of âˆ‡Î¾U 
Î·ku+1;Î¾ku
is straightforward. But it is not practicable
to directly formulate âˆ‡Î¾kuÎ·ku+1since the size of the Jacobian matrix is O(dntnxny)Ã— O(d2ntnxny) and
the sparsity structure of the Jacobian matrix is not straightforward. Denote the gradient descent mapping
M(Î·;Î¾) :=Î·âˆ’Ï„lâˆ‡Î·L(Î·;Î¾). Then the Jacobian of M,âˆ‡M= (âˆ‡Î·M,âˆ‡Î¾M) = (Iâˆ’Ï„âˆ‡Î·Î·L,âˆ’Ï„âˆ‡Î·Î¾L) is sparse
because the number of non-zero entries of âˆ‡Î·Î·Landâˆ‡Î·Î¾LisO(dntnxny). In practice, we avoid formulating
the matrix âˆ‡Î¾kuÎ·ku+1by chain rule and the sparsity structure of âˆ‡M. Specifically, let P:=Iâˆ’Aâ€ A
be the projection matrix, âˆ‡Î·ku,klU 
Î·ku+1;Î¾ku
be the gradient of U 
Î·ku+1;Î¾ku
with respect to Î·ku,kl,
andâˆ‡Î¾kuÎ·ku,klbe the Jacobian of Î·ku,klwith respect to Î¾ku, then we have the following relation by back-
propagation
(âˆ‡Î·ku,Kl+1U 
Î·ku+1;Î¾ku
=âˆ‡Î·U 
Î·ku+1;Î¾ku
,
âˆ‡Î·ku,klU 
Î·ku+1;Î¾ku
= 
âˆ‡Î·M(Î·ku,kl;Î¾ku)âŠ¤Pâˆ‡Î·ku,kl+1U 
Î·ku;Î¾ku
, k l= 1,Â·Â·Â·, Kl.(47)
14Consequently, the upper-level gradient estimator is
bâˆ‡u(Î¾ku) = 
âˆ‡Î¾kuÎ·ku,Kl+1âŠ¤âˆ‡Î·ku,Kl+1U 
Î·ku+1;Î¾ku
+âˆ‡Î¾U 
Î·ku+1;Î¾ku
= 
âˆ‡Î·M(Î·ku,Kl;Î¾ku)âˆ‡Î¾kuÎ·ku,KlâŠ¤Pâˆ‡Î·ku,Kl+1U 
Î·ku+1;Î¾ku
+ 
âˆ‡Î¾M(Î·ku,Kl;Î¾ku)âŠ¤Pâˆ‡Î·ku,Kl+1U 
Î·ku+1;Î¾ku
+âˆ‡Î¾U 
Î·ku+1;Î¾ku
by (47)= 
âˆ‡Î¾kuÎ·ku,KlâŠ¤âˆ‡Î·ku,KlU 
Î·ku+1;Î¾ku
+ 
âˆ‡Î¾M(Î·ku,Kl;Î¾ku)âŠ¤Pâˆ‡Î·ku,Kl+1U 
Î·ku+1;Î¾ku
+âˆ‡Î¾U 
Î·ku+1;Î¾ku
= 
âˆ‡Î·M(Î·ku,Klâˆ’1;Î¾ku)âˆ‡Î¾kuÎ·ku,Klâˆ’1âŠ¤Pâˆ‡Î·ku,KlU 
Î·ku+1;Î¾ku
+ 
âˆ‡Î¾M(Î·ku,Klâˆ’1;Î¾ku)âŠ¤Pâˆ‡Î·ku,KlU 
Î·ku+1;Î¾ku
+ 
âˆ‡Î¾M(Î·ku,Kl;Î¾ku)âŠ¤Pâˆ‡Î·ku,Kl+1U 
Î·ku+1;Î¾ku
+âˆ‡Î¾U 
Î·ku+1;Î¾ku
by (47)= 
âˆ‡Î¾kuÎ·ku,Klâˆ’1âŠ¤âˆ‡Î·ku,Klâˆ’1 
Î·ku+1;Î¾ku
+KlX
i=Klâˆ’1 
âˆ‡Î¾M(Î·ku,i;Î¾ku)âŠ¤Pâˆ‡Î·ku,i+1U 
Î·ku+1;Î¾ku
+âˆ‡Î¾U 
Î·ku+1;Î¾ku
=Â·Â·Â·
(a)=KlX
i=1 
âˆ‡Î¾M(Î·ku,i;Î¾ku)âŠ¤Pâˆ‡Î·ku,i+1U 
Î·ku+1;Î¾ku
+âˆ‡Î¾U 
Î·ku+1;Î¾ku(48)
where ( a) is because that Î·ku,1is independent of Î¾ku. In this way, each term in the estimator can be computed
by sparse matrix and vector multiplication.
5 Proofs of Main Theorems
In this section, we provide the proofs of main theorems. Theorem 3.8 shows that the observations of the
Nash Equilibrium continuously depend on the unknown parameters. Theorem 3.9 states that with only
one good observation of the Nash Equilibrium, we can uniquely recover the obstacle bup to a constant by
solving the bilevel problem (23). This illustrates the effectiveness of our model. Lemma 3.4 and Theorem
4.2 together guarantee that Algorithm 2 converges to a stationary point to the bilevel problem (23) if the
forward problem has enough regularity. This illustrates the effectiveness of our algorithm.
5.1 Proof of Theorem 3.8 and 3.9
Recall that Y(Ï,m, Ï•;g, b) =0gives the optimality condition. Denote the Jacobian matrix of Yasâˆ‡Y=
((âˆ‡Ï,m,Ï•Y)dlÃ—dl,(âˆ‡g,bY)dlÃ—du). The proof of the regularity Theorem 3.8 is based on the implicit function
theorem and the key is to show that the matrix âˆ‡Ï,m,Ï•Yis invertible at a good observation ( eÏ,em,eÏ•;eg,eb).
Lemma 5.1. IfÎ³I>0,Î³T>0andmin iâˆˆGÏ{eÏi}>0, then âˆ‡Ï,m,Ï•Y(eÏ,em,eÏ•;eg,eb)is invertible.
Proof. To prove the lemma is equivalent to showing that
âˆ‡Ï,m,Ï•Y(eÏ,em,eÏ•;eg,eb)(Î´Ï, Î´m, Î´Ï•) =0, (49)
if and only if ( Î´Ï, Î´m, Î´Ï•) =0. Here Î´m:={Î´mx, Î´my}. By definition,
âˆ‡Ï,m,Ï•Y(eÏ,em,eÏ•;eg,eb)(Î´Ï, Î´m, Î´Ï•) = lim
Ïµâ†’01
Ïµ
Y(eÏ+ÏµÎ´Ï,em+ÏµÎ´m,eÏ•+ÏµÎ´Ï•;eg,eb)âˆ’ Y(eÏ,em,eÏ•;eg,eb)
(50)
15Therefore (49) is equivalent to
ï£±
ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£³iâˆˆ GÏ, it= 1,Â·Â·Â·, ntâˆ’1,
âˆ’(Dâˆ—
t(Î´Ï•))i+ 
Iâˆ—
t 
âˆ’gxxemx+gxyemy
eÏ2Î´mxâˆ’gxyemx+gyyemy
eÏ2Î´my
+(em)âŠ¤gem
eÏ3Î´Ï+Î³I
eÏÎ´Ï!!
i= 0,
iâˆˆ GÏ,=nt,
âˆ’(Dâˆ—
t(Î´Ï•))i+ 
Iâˆ—
t 
âˆ’gxxemx+gxyemy
eÏ2Î´mxâˆ’gxyemx+gyyemy
eÏ2Î´my
+(em)âŠ¤gem
eÏ3Î´Ï+Î³I
eÏÎ´Ï!!
i+Î³T
âˆ†t(eÏ)i(Î´Ï)i= 0,
iâˆˆ Gmx,âˆ’(Dâˆ—
x(Î´Ï•))i+ 
Iâˆ—
x 
gxx
eÏÎ´mx+gxy
eÏÎ´myâˆ’gxxemx+gxyemy
eÏ2Î´Ï!!
i= 0,
iâˆˆ Gmy,âˆ’(Dâˆ—
y(Î´Ï•))i+ 
Iâˆ—
y 
gxy
eÏÎ´mx+gyy
eÏÎ´myâˆ’gxyemx+gyyemy
eÏ2Î´Ï!!
i= 0,
iâˆˆ GÏ•,(Dt(Î´Ï;0) +Dx(Î´mx) +Dy(Î´my))i= 0.(51)
Note that eÏ,em,eÏ•are viewed as constants with respect to ( Î´Ï, Î´m, Î´Ï•) in the system. It clear that the system
51 is linear in ( Î´Ï, Î´m, Î´Ï•) and therefore (49) holds if ( Î´Ï, Î´m, Î´Ï•) =0. If both ( Î´Ï, Î´m, Î´Ï•) and ( Î´â€²
Ï, Î´â€²
m, Î´â€²
Ï•)
satisfy (49), then by plugging them into (51) and subtracting, we have
ï£±
ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£³iâˆˆ GÏ, it= 1,Â·Â·Â·, ntâˆ’1,
âˆ’(Dâˆ—
t(Î´Ï•âˆ’Î´â€²
Ï•))i+ 
Iâˆ—
t 
âˆ’gxxemx+gxyemy
eÏ2(Î´mxâˆ’Î´â€²
mx)
âˆ’gxyemx+gyyemy
eÏ2(Î´myâˆ’Î´â€²
my)
+(em)âŠ¤gem
eÏ3(Î´Ïâˆ’Î´â€²Ï) +Î³I
eÏ(Î´Ïâˆ’Î´â€²Ï)!!
i= 0,
iâˆˆ GÏ,=nt,
âˆ’(Dâˆ—
t(Î´Ï•âˆ’Î´â€²
Ï•))i+ 
Iâˆ—
t 
âˆ’gxxemx+gxyemy
eÏ2(Î´mxâˆ’Î´â€²
mx)
âˆ’gxyemx+gyyemy
eÏ2(Î´myâˆ’Î´â€²
my)
+(em)âŠ¤gem
eÏ3(Î´Ïâˆ’Î´â€²Ï) +Î³I
eÏ(Î´Ïâˆ’Î´â€²Ï)!!
i+Î³T
âˆ†t(eÏ)i(Î´Ïâˆ’Î´â€²
Ï)i= 0,(52)
16ï£±
ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£³iâˆˆ Gmx,âˆ’(Dâˆ—
x(Î´Ï•âˆ’Î´â€²
Ï•))i+ 
Iâˆ—
x 
gxx
eÏ(Î´mxâˆ’Î´â€²
mx) +gxy
eÏ(Î´myâˆ’Î´â€²
my)
âˆ’gxxemx+gxyemy
eÏ2(Î´Ïâˆ’Î´â€²Ï)!!
i= 0,
iâˆˆ Gmy,âˆ’(Dâˆ—
y(Î´Ï•âˆ’Î´â€²
Ï•))i+ 
Iâˆ—
y 
gxy
eÏ(Î´mxâˆ’Î´â€²
mx) +gyy
eÏ(Î´myâˆ’Î´â€²
my)
âˆ’gxyemx+gyyemy
eÏ2(Î´Ïâˆ’Î´â€²Ï)!!
i= 0,(53)
and
iâˆˆ GÏ•,(Dt(Î´Ïâˆ’Î´â€²
Ï;0) +Dx(Î´mxâˆ’Î´â€²
mx) +Dy(Î´myâˆ’Î´â€²
my))i= 0. (54)
Pointwisely multiplying (52) with ( Î´Ïâˆ’Î´â€²
Ï) and summing over GÏgives us
âˆ’
Î´Ïâˆ’Î´â€²
Ï, Dâˆ—
t(Î´Ï•âˆ’Î´â€²
Ï•)
GÏ
âˆ’*
Î´Ïâˆ’Î´â€²
Ï, Iâˆ—
t 
gxxemx+gxyemy
eÏ2(Î´mxâˆ’Î´â€²
mx)!+
GÏâˆ’*
Î´Ïâˆ’Î´â€²
Ï, Iâˆ—
t 
gxyemx+gyyemy
eÏ2(Î´myâˆ’Î´â€²
my)!+
GÏ
+*
Î´Ïâˆ’Î´â€²
Ï, Iâˆ—
t 
(em)âŠ¤gem
eÏ3(Î´Ïâˆ’Î´â€²Ï)!+
GÏ+
Î´Ïâˆ’Î´â€²
Ï, Iâˆ—
tÎ³I
eÏ(Î´Ïâˆ’Î´â€²Ï)
GÏ
+ âˆ†xâˆ†ynxX
nx=1nyX
ny=1Î³T
(eÏ)ix,iy,nt(Î´Ïâˆ’Î´â€²
Ï)2
ix,iy,nt= 0.
(55)
Similarly (53) and (54) imply
âˆ’
Î´mxâˆ’Î´â€²
mx, Dâˆ—
x(Î´Ï•âˆ’Î´â€²
Ï•)
Gmx
+
Î´mxâˆ’Î´â€²
mx, Iâˆ—
xgxx
eÏ(Î´mxâˆ’Î´â€²
mx) +gxy
eÏ(Î´myâˆ’Î´â€²
my)
Gmx
âˆ’*
Î´mxâˆ’Î´â€²
mx, Iâˆ—
x 
gxxemx+gxyemy
eÏ2(Î´Ïâˆ’Î´â€²Ï)!+
Gmx= 0,(56)
and
âˆ’
Î´myâˆ’Î´â€²
my, Dâˆ—
y(Î´Ï•âˆ’Î´â€²
Ï•)
Gmy
+
Î´myâˆ’Î´â€²
my, Iâˆ—
ygxy
eÏ(Î´mxâˆ’Î´â€²
mx) +gyy
eÏ(Î´myâˆ’Î´â€²
my)
Gmy
âˆ’*
Î´myâˆ’Î´â€²
my, Iâˆ—
y 
gxyemx+gyyemy
eÏ2(Î´Ïâˆ’Î´â€²Ï)!+
Gmy= 0,(57)
and

Î´Ï•âˆ’Î´â€²
Ï•, Dt(Î´Ïâˆ’Î´â€²
Ï;0)
GÏ•+
Î´Ï•âˆ’Î´â€²
Ï•, Dx(Î´mxâˆ’Î´â€²
mx)
GÏ•+
Î´Ï•âˆ’Î´â€²
Ï•, Dy(Î´myâˆ’Î´â€²
my)
GÏ•= 0. (58)
Next, we add (55)-(58) and combine terms with the same components in groups. The first group is
âˆ’
Î´Ïâˆ’Î´â€²
Ï, Dâˆ—
t(Î´Ï•âˆ’Î´â€²
Ï•)
GÏâˆ’
Î´mxâˆ’Î´â€²
mx, Dâˆ—
x(Î´Ï•âˆ’Î´â€²
Ï•)
Gmxâˆ’
Î´myâˆ’Î´â€²
my, Dâˆ—
y(Î´Ï•âˆ’Î´â€²
Ï•)
Gmy

Î´Ï•âˆ’Î´â€²
Ï•, Dt(Î´Ïâˆ’Î´â€²
Ï;0)
GÏ•+
Î´Ï•âˆ’Î´â€²
Ï•, Dx(Î´mxâˆ’Î´â€²
mx)
GÏ•+
Î´Ï•âˆ’Î´â€²
Ï•, Dy(Î´myâˆ’Î´â€²
my)
GÏ•,(59)
and by the adjoint relation between Dt, Dâˆ—
t, this group sums to 0. The second group consists of

Î´Ïâˆ’Î´â€²
Ï, Iâˆ—
tÎ³I
eÏ(Î´Ïâˆ’Î´â€²Ï)
GÏ+âˆ†xâˆ†ynxX
nx=1nyX
ny=1Î³T
(eÏ)ix,iy,nt(Î´Ïâˆ’Î´â€²
Ï)2
ix,iy,nt. (60)
17and the sum is equal to Î³IÎ´Ïâˆ’Î´â€²Ï
eÏ1/22
GÏ•+ âˆ†xâˆ†ynxX
nx=1nyX
ny=1Î³T
(eÏ)ix,iy,nt(Î´Ïâˆ’Î´â€²
Ï)2
ix,iy,nt. The rest terms form
the last group and sum toX
iâˆˆGÏ•1
eÏ3
i
(Î´Ïâˆ’Î´â€²Ï)emâˆ’eÏ(Î´mâˆ’Î´â€²m)
i2
gi, (61)
where âˆ¥viâˆ¥2
gi= (v)âŠ¤
igivi. Overall, adding (55)-(58) gives
Î³IÎ´Ïâˆ’Î´â€²Ï
eÏ1/22
GÏ•+ âˆ†xâˆ†ynxX
nx=1nyX
ny=1Î³T
(eÏ)ix,iy,nt(Î´Ïâˆ’Î´â€²
Ï)2
ix,iy,nt
+X
iâˆˆGÏ•1
eÏ3
i
(Î´Ïâˆ’Î´â€²Ï)emâˆ’eÏ(Î´mâˆ’Î´â€²m)
i2
gi= 0.(62)
We conclude that each term in (62) is zero since they are non-negative and sum to zero. Combining
(Î´Ï)ix,iy,nt= (Î´â€²
Ï)ix,iy,ntandÎ´Ï=Î´â€²Ïgives Î´Ï=Î´â€²
Ï. Consequently, Î´mx=Î´â€²
mxandÎ´my=Î´â€²
my. Because Ix, Iy
are full rank linear operators, Î´mx=Î´â€²
mxandÎ´my=Î´â€²
my. Based on Î´Ï=Î´â€²
Ï, Î´m=Î´â€²
m, (52) and (53) lead to
Î´Ï•=Î´â€²
Ï•. Therefore (49) has unique solution ( Ï,m, Ï•) =0, i.e.âˆ‡Ï,m,Ï•Y(eÏ,em,eÏ•;eb) is invertible.
With Lemma 5.1, we apply implicit function theorem to Yat (eÏ,em,eÏ•;eg,eb) and then the regularity
Theorem 3.8 is true.
Next, we prove the unique identifiability Theorem 3.9 for inverse obstacle problem 3.5.
Proof of Theorem 3.9. Since the upper-level objective is non-negative and equals 0 when b=eb, any minimizer
bof the bilevel minimization problem satisfies
(eÏ,em) = argmin
(Ï,m)âˆˆCG(Âµ0)LG(Ï,m;b), (63)
and by Lemma 3.7, there exists Ï•such that Y(eÏ,em, Ï•;b) =0. Assume that bâ€²is a minimizer, bâ€²Ì¸=eb, and
Y(eÏ,em,eÏ•;eb) =Y(eÏ,em, Ï•â€²;bâ€²) =0,
then
Y(eÏ,em,eÏ•;eb)âˆ’ Y(eÏ,em, Ï•â€²;bâ€²) =0,
which is equivalent toï£±
ï£´ï£´ï£´ï£´ï£²
ï£´ï£´ï£´ï£´ï£³iâˆˆ GÏ,âˆ’
Dâˆ—
t(Ï•â€²âˆ’eÏ•)
i+ ((bâ€²)ix,iyâˆ’(eb)ix,iy) = 0 ,
iâˆˆ Gmx,
Dâˆ—
x(Ï•â€²âˆ’eÏ•)
i= 0,
iâˆˆ Gmy,
Dâˆ—
y(Ï•â€²âˆ’eÏ•)
i= 0.(64)
The equation on GÏgives ( Ï•â€²âˆ’eÏ•)ixiyit= (ntâˆ’it+ 1)( bâ€²âˆ’eb)ix,iy. Plugging in equations on Gmx,Gmy, we
have ( bâ€²âˆ’eb)ix,iy=cwhere cis a constant for different ix, iy.
5.2 Proof of Theorem 4.2 and Lemma 3.4
In this section, we provide the nonasymptotic analysis for AGM on general constrained bilevel optimization
(14). We follow conventional notations in bilevel optimization by using commas to separate lower-level and
upper-level variables, i.e., L(Î·, Î¾) =L(Î·;Î¾),U(Î·, Î¾) =U(Î·;Î¾)
18Recall that the lower level constraint is H={Î·|AÎ·=c}. Denote the singular value decomposition of
AasA=UÎ£VâŠ¤, where
Î£ =Î£10
0 0
âˆˆRdcÃ—dÎ·,
U= [U1U2],V= [V1V2],UâˆˆRdcÃ—dc, VâˆˆRdÎ·Ã—dÎ·are orthogonal matrix and U1âˆˆRdcÃ—r, V1âˆˆRdÎ·Ã—r
are the submatrix corresponds to full rank diagonal submatrix Î£ 1âˆˆRrÃ—r. Then V2is the orthogonal basis
of Ker( A) :={Î·|AÎ·= 0}. Let Î·0âˆˆHbe a feasible lower-level solution, then the lower-level update is
equivalent to
Î·ku,1=Î·ku;Î·ku,kl+1=V2VâŠ¤
2 
Î·ku,klâˆ’Ï„lâˆ‡Î·L(Î·ku,kl, Î¾ku)
+Î·0;Î·ku+1=Î·ku,Kl+1. (65)
With Î·ku+1approximating Î·âˆ—(Î¾ku), we approximate the lower-level gradient with
bâˆ‡u(Î¾ku) :=âˆ‡Î¾U(Î·ku+1, Î¾ku) + (âˆ‡Î¾kuÎ·ku+1)âŠ¤âˆ‡Î·U(Î·ku+1, Î¾ku) (66)
andâˆ‡Î¾kuÎ·ku+1is obtained by unrolling the lower-level iterates
ï£±
ï£´ï£²
ï£´ï£³âˆ‡Î¾kuÎ·ku,1=0,
âˆ‡Î¾kuÎ·ku,kl+1=V2VâŠ¤
2âˆ‡Î¾kuÎ·ku,klâˆ’Ï„lV2VâŠ¤
2 
âˆ‡Î·Î¾L(Î·ku,kl, Î¾ku) +âˆ‡Î·Î·L(Î·ku,kl, Î¾ku)âˆ‡Î¾kuÎ·ku,kl
=V2VâŠ¤
2 
Iâˆ’Ï„lâˆ‡Î·Î·L(Î·ku,kl, Î¾ku)
âˆ‡Î¾kuÎ·ku,klâˆ’Ï„lV2VâŠ¤
2âˆ‡Î·Î¾L(Î·ku,kl, Î¾ku), kl= 1,Â·Â·Â·, Kl.
(67)
To prove the convergence, we first present the regularity of the lower-level optimizer established in [30].
To be self-contained, we also provide its proof.
Lemma 5.2 (The regularity of lower-level optimizer) .Under Assumption 1â€“2, Î·âˆ—(Î¾)is differentiable with
respect to Î¾with the following gradient
âˆ‡Î·âˆ—(Î¾) =âˆ’V2(VâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾), Î¾)V2)âˆ’1VâŠ¤
2âˆ‡Î·Î¾L(Î·âˆ—(Î¾), Î¾).
where V2is the orthogonal basis of Ker(A). Therefore, Î·âˆ—(Î¾)isLÎ·-Lipschitz continuous and and LÎ·Î¾smooth
with
LÎ·:=â„“l,1
Âµl=O(Îº), L Î·Î¾:=â„“l,2(1 +â„“l,1
Âµl)2
Âµl=O(Îº3).
Proof. First, we prove the differentiability and compute the Jacobian matrix. We choose a fixed Î·0satisfying
AÎ·0=c. Using the aforementioned SVD of A, the constraint set H={Î·0+V2z|zâˆˆRdÎ·âˆ’r}. Letting
Lz(z, Î¾) :=L(Î·0+V2z, Î¾) and zâˆ—(Î¾) = arg min zLz(z, Î¾), we have Î·âˆ—(Î¾) =Î·0+V2zâˆ—(Î¾). By optimality
condition, zâˆ—(Î¾) satisfies
âˆ‡zLz(zâˆ—(Î¾), Î¾) =VâŠ¤
2âˆ‡Î·L(Î·0+V2zâˆ—(Î¾), Î¾) = 0 , (68)
Since
âˆ‡zzLz(zâˆ—(Î¾), Î¾) =VâŠ¤
2âˆ‡Î·Î·L(Î·0+V2zâˆ—(Î¾), Î¾)V2 (69)
and by strong convexity of Lwith respect to Î·,âˆ‡zzLz(zâˆ—(Î¾), Î¾) is invertible. By implicit function theorem,
zâˆ—(Î¾) is differentiable with respect to Î¾. As a consequence, Î·âˆ—(Î¾) is differentiable with respect to Î¾. Taking
the gradient with respect to Î¾on both sides of (68) gives us
0 =âˆ‡Î¾Î·L(Î·0+V2zâˆ—(Î¾), Î¾)V2+ 
âˆ‡Î¾zâˆ—(Î¾)âŠ¤VâŠ¤
2
âˆ‡Î·Î·L(Î·0+V2zâˆ—(Î¾), Î¾)V2
=âˆ‡Î¾Î·L(Î·0+V2zâˆ—(Î¾), Î¾)V2+âˆ‡Î¾zâˆ—(Î¾)âŠ¤VâŠ¤
2âˆ‡Î·Î·L(Î·0+V2zâˆ—(Î¾), Î¾)V2.
Then, we have (cf. âˆ‡Î·Î·L(Î·âˆ—(Î¾), Î¾) =âˆ‡Î·Î·L(Î·0+V2zâˆ—(Î¾), Î¾))
âˆ‡zâˆ—(Î¾) =âˆ’ 
VâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾), Î¾)V2âˆ’1VâŠ¤
2âˆ‡Î·Î¾L(Î·âˆ—(Î¾), Î¾) (70)
19and as a result,
âˆ‡Î·âˆ—(Î¾) =V2âˆ‡zâˆ—(Î¾)
=âˆ’V2 
VâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾), Î¾)V2âˆ’1VâŠ¤
2âˆ‡Î·Î¾L(Î·âˆ—(Î¾), Î¾).
Next, utilizing the fact that V2is the orthogonal matrix, we know ÂµlIâª¯VâŠ¤
2âˆ‡Î·Î·L(Î·, Î¾)V2. Therefore, we
have for any Î¾, Î·,
V2 
VâŠ¤
2âˆ‡Î·Î·L(Î·, Î¾)V2âˆ’1VâŠ¤
2âª¯1
ÂµlI. (71)
As a result, âˆ‡Î·âˆ—(Î¾) is bounded by
âˆ¥âˆ‡Î·âˆ—(Î¾)âˆ¥ â‰¤ âˆ¥ V2 
VâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾), Î¾)V2âˆ’1VâŠ¤
2âˆ¥âˆ¥âˆ‡ Î·Î¾L(Î·âˆ—(Î¾), Î¾)âˆ¥ â‰¤â„“l,1
Âµl=LÎ·
which implies Î·âˆ—(Î¾) isLÎ·Lipschitz continuous.
Finally, we aim to prove the smoothness of Î·âˆ—(Î¾). For any Î¾1andÎ¾2, we have
âˆ¥âˆ‡Î·âˆ—(Î¾1)âˆ’ âˆ‡Î·âˆ—(Î¾2)âˆ¥
=âˆ¥V2 
VâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾1), Î¾1)V2âˆ’1VâŠ¤
2âˆ‡Î·Î¾L(Î·âˆ—(Î¾1), Î¾1)
âˆ’V2 
VâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾2), Î¾2)V2âˆ’1VâŠ¤
2âˆ‡Î·Î¾L(Î·âˆ—(Î¾2), Î¾2)âˆ¥
â‰¤ âˆ¥V2Bâˆ’1
1VâŠ¤
2âˆ¥âˆ¥âˆ‡ Î·Î¾L(Î·âˆ—(Î¾1), Î¾1)âˆ’ âˆ‡ Î·Î¾L(Î·âˆ—(Î¾2), Î¾2))âˆ¥
+âˆ¥V2(Bâˆ’1
1âˆ’Bâˆ’1
2)VâŠ¤
2âˆ¥âˆ¥âˆ‡ Î·Î¾L(Î·âˆ—(Î¾2), Î¾2)âˆ¥
(a)
â‰¤1
Âµlâˆ¥âˆ‡Î·Î¾L(Î·âˆ—(Î¾1), Î¾1)âˆ’ âˆ‡ Î·Î¾L(Î·âˆ—(Î¾2), Î¾2)âˆ¥
+â„“l,1
Âµ2
lâˆ¥âˆ‡Î·Î·L(Î·âˆ—(Î¾1), Î¾1)âˆ’ âˆ‡ Î·Î·L(Î·âˆ—(Î¾2), Î¾2)âˆ¥
(b)
â‰¤â„“l,2(1 +â„“l,1
Âµl)2
Âµlâˆ¥Î¾1âˆ’Î¾2âˆ¥ (72)
where B1=VâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾1), Î¾1)V2andB2=VâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾2), Î¾2)V2, (a) comes from (71) and the following
fact:
V2 
Bâˆ’1
1âˆ’Bâˆ’1
2
VâŠ¤
2
=V2Bâˆ’1
1(B2âˆ’B1)Bâˆ’1
2VâŠ¤
2
=V2Bâˆ’1
1  
VâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾2), Î¾2)V2
âˆ’ 
VâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾1), Î¾1)V2
Bâˆ’1
2VâŠ¤
2
=V2Bâˆ’1
1VâŠ¤
2(âˆ‡Î·Î·L(Î·âˆ—(Î¾2), Î¾2)âˆ’ âˆ‡ Î·Î·L(Î·âˆ—(Î¾1), Î¾1))V2Bâˆ’1
2VâŠ¤
2
and (b) comes from
âˆ¥âˆ‡2L(Î·âˆ—(Î¾1), Î¾1)âˆ’ âˆ‡2L(Î·âˆ—(Î¾2), Î¾2)âˆ¥ â‰¤â„“l,2[âˆ¥Î¾1âˆ’Î¾2âˆ¥+âˆ¥Î·âˆ—(Î¾1)âˆ’Î·âˆ—(Î¾2)âˆ¥]
â‰¤â„“l,2
1 +â„“l,1
Âµl
âˆ¥Î¾1âˆ’Î¾2âˆ¥.
In Algorithm 2, we approximate âˆ‡Î·âˆ—(Î¾) by unrolling the differentiation. The following lemma investigates
the error of this approximation in constrained bilevel problems for the first time, indicating that the gradient
estimation error can be effectively bounded by the accuracy of the lower-level solution.
20Lemma 5.3 (Error of unrolling differentiation) .Suppose that Assumption 1â€“3 hold and choose Ï„lâ‰¤1
2â„“l,1,
the error of implicit gradient estimator can be bounded by
âˆ¥âˆ‡Î·âˆ—(Î¾ku)âˆ’ âˆ‡ Î¾kuÎ·ku+1âˆ¥2â‰¤2 (1âˆ’Ï„lÂµl)2Kl+2+ 2CKlC2
lâˆ¥Î·âˆ—(Î¾ku)âˆ’Î·kuâˆ¥2
where C2
l:=
1 +â„“l,1
Âµl
â„“2
l,2
2
Âµ2
l+3
2â„“2
l,1
andCKlis the upper bound of Kl(1âˆ’Ï„lÂµl)Klâˆ’1and is finite.
Proof. According to (67), we know that âˆ‡Î¾kuÎ·ku,1= 0 and
âˆ‡Î¾kuÎ·ku,kl+1=V2VâŠ¤
2 
Iâˆ’Ï„lâˆ‡Î·Î·L(Î·ku,kl, Î¾ku)
âˆ‡Î¾kuÎ·ku,klâˆ’Ï„lV2VâŠ¤
2âˆ‡Î·Î¾L(Î·ku,kl, Î¾ku).
For any given Î¾ku, we can define an auxiliary sequence {wkl}âˆ
kl=0andwâˆ—:= lim Klâ†’âˆwKl, where w1= 0
and
wkl+1=V2VâŠ¤
2 
Iâˆ’Ï„lâˆ‡Î·Î·L(Î·âˆ—(Î¾ku), Î¾ku)
wklâˆ’Ï„lV2VâŠ¤
2âˆ‡Î·Î¾L(Î·âˆ—(Î¾ku), Î¾ku). (73)
We can see that (67) and (73) only differ in Î·âˆ—(Î¾ku) and Î·ku,kl. For the sequence wkl, we can calculate the
explicit form of wKl+1as
wKl+1=KlX
s=0 
V2VâŠ¤
2âˆ’Ï„lV2VâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾ku), Î¾ku)s 
âˆ’Ï„lV2VâŠ¤
2âˆ‡Î·Î¾L(Î·âˆ—(Î¾ku), Î¾ku)
=KlX
s=0 
V2VâŠ¤
2âˆ’Ï„lV2VâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾ku), Î¾ku)V2VâŠ¤
2s 
âˆ’Ï„lâˆ‡Î·Î¾L(Î·âˆ—(Î¾ku), Î¾ku)
=KlX
s=0 
V2 
Iâˆ’Ï„lVâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾ku), Î¾ku)V2
VâŠ¤
2s 
âˆ’Ï„lâˆ‡Î·Î¾L(Î·âˆ—(Î¾ku), Î¾ku)
=KlX
s=0V2 
Iâˆ’Ï„lVâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾ku), Î¾ku)V2sVâŠ¤
2 
âˆ’Ï„lâˆ‡Î·Î¾L(Î·âˆ—(Î¾ku), Î¾ku)
=V2 KlX
s=0 
Iâˆ’Ï„lVâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾ku), Î¾ku)V2s!
VâŠ¤
2 
âˆ’Ï„lâˆ‡Î·Î¾L(Î·âˆ—(Î¾ku), Î¾ku)
(74)
where the first equality comes from unrolling (73), the second and the fourth equality are due to ( V2VâŠ¤
2)s=
V2VâŠ¤
2. Let D:=Iâˆ’Ï„lVâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾ku), Î¾ku)V2. When Ï„l<2
â„“l,1, the operator norm of Dsatisfies âˆ¥Dâˆ¥<1,
the limitP+âˆ
s=0Ds:= lim Klâ†’+âˆPKl
s=0Ds= (Iâˆ’D)âˆ’1= (Ï„lVâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾ku), Î¾ku)V2)âˆ’1.Therefore, the
limit point of wklis equal to âˆ‡Î·âˆ—(Î¾ku) since
wâˆ—:= lim
Klâ†’âˆwKl=V2 âˆX
s=0 
Iâˆ’Ï„lVâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾ku), Î¾ku)V2s!
VâŠ¤
2 
âˆ’Ï„lâˆ‡Î·Î¾L(Î·âˆ—(Î¾ku), Î¾ku)
=V2 
Ï„lVâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾ku), Î¾ku)V2âˆ’1VâŠ¤
2 
âˆ’Ï„lâˆ‡Î·Î¾L(Î·âˆ—(Î¾ku), Î¾ku)
=âˆ’V2 
VâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾ku), Î¾ku)V2âˆ’1VâŠ¤
2âˆ‡Î·Î¾L(Î·âˆ—(Î¾ku), Î¾ku) =âˆ‡Î·âˆ—(Î¾ku) (75)
Moreover, the error by finite-step approximation can be bounded by
(Iâˆ’D)âˆ’1âˆ’KlX
s=0Ds=âˆX
s=Kl+1Dsâ‰¤âˆX
s=Kl+1âˆ¥Dâˆ¥s=âˆ¥Dâˆ¥Kl+1
1âˆ’ âˆ¥Dâˆ¥
Since (1 âˆ’Ï„lâ„“l,1)Iâª¯D=Iâˆ’Ï„lVâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾ku), Î¾ku)V2âª¯(1âˆ’Ï„lÂµl)Iand according to (75) and (74), we
know that if Ï„lâ‰¤1
2â„“l,1,
âˆ¥wKl+1âˆ’ âˆ‡Î·âˆ—(Î¾ku)âˆ¥ â‰¤Ï„lâ„“l,1(1âˆ’Ï„lÂµl)Kl+1
1âˆ’Ï„lâ„“l,1â‰¤(1âˆ’Ï„lÂµl)Kl+1. (76)
21Next, we aim to bound the distance between âˆ‡Î¾kuÎ·ku,kland the auxiliary sequence wkl. For any kl,
according to (67) and (73), we have
âˆ¥âˆ‡Î¾kuÎ·ku,kl+1âˆ’wkl+1âˆ¥2=âˆ¥ 
V2VâŠ¤
2âˆ’Ï„lV2VâŠ¤
2âˆ‡Î·Î·L(Î·ku,kl, Î¾ku)
âˆ‡Î¾kuÎ·ku,klâˆ’Ï„lV2VâŠ¤
2âˆ‡Î·Î¾L(Î·ku,kl, Î¾ku)
âˆ’ 
V2VâŠ¤
2âˆ’Ï„lV2VâŠ¤
2âˆ‡Î·Î·L(Î·âˆ—(Î¾ku), Î¾ku)
wkl+Ï„lV2VâŠ¤
2âˆ‡Î·Î¾L(Î·âˆ—(Î¾ku), Î¾ku)âˆ¥2
â‰¤(1 +Î³)âˆ¥ 
V2VâŠ¤
2âˆ’Ï„lV2VâŠ¤
2âˆ‡Î·Î·L(Î·ku,kl, Î¾ku)
(âˆ‡Î¾kuÎ·ku,klâˆ’wkl)âˆ¥2+
+ 2
1 +1
Î³
âˆ¥Ï„lV2VâŠ¤
2(âˆ‡Î·Î·L(Î·ku,kl, Î¾ku)âˆ’ âˆ‡ Î·Î·L 
Î·âˆ—(Î¾ku), Î¾ku
wklâˆ¥2
+ 2
1 +1
Î³
âˆ¥Ï„lV2VâŠ¤
2(âˆ‡Î·Î¾L(Î·ku,kl, Î¾ku)âˆ’ âˆ‡ Î·Î¾L 
Î·âˆ—(Î¾ku), Î¾ku
âˆ¥2
â‰¤(1 +Î³) (1âˆ’Ï„lÂµl)2âˆ¥âˆ‡Î¾kuÎ·ku,klâˆ’wklâˆ¥2
+
1 +1
Î³
Ï„2
lâ„“2
l,2âˆ¥Î·âˆ—(Î¾ku)âˆ’Î·ku,klâˆ¥2 
2 + 2âˆ¥wklâˆ¥2
(77)
where the first inequality is derived from âˆ¥a+b+câˆ¥2
2â‰¤(1 +Î³)âˆ¥aâˆ¥2
2+ (2 +2
Î³)âˆ¥bâˆ¥2
2+ (2 +2
Î³)âˆ¥câˆ¥2
2and the
second inequality is due to Assumption 1â€“2. On the one hand, âˆ¥wklâˆ¥ â‰¤ âˆ¥âˆ‡ Î·âˆ—(Î¾ku)âˆ¥+âˆ¥wklâˆ’ âˆ‡Î·âˆ—(Î¾ku)âˆ¥ â‰¤
â„“l,1
1
Âµl+Ï„l
is bounded according to Lemma 5.2 and (76). Thus, if Ï„lâ‰¤1
2â„“l,1and letting Î³=Ï„lÂµl, (77)
becomes
âˆ¥âˆ‡Î¾kuÎ·ku,kl+1âˆ’wk+1âˆ¥2â‰¤(1âˆ’Ï„lÂµl)âˆ¥âˆ‡Î¾kuÎ·ku,klâˆ’wklâˆ¥2+
1 +1
Ï„lÂµl
Ï„2
lâ„“2
l,2 
4â„“2
l,1
Âµ2
l+ 3!
âˆ¥Î·âˆ—(Î¾ku)âˆ’Î·ku,klâˆ¥2
â‰¤(1âˆ’Ï„lÂµl)âˆ¥âˆ‡Î¾kuÎ·ku,klâˆ’wklâˆ¥2+C2
lâˆ¥Î·âˆ—(Î¾ku)âˆ’Î·ku,klâˆ¥2(78)
where C2
l:=
1 +â„“l,1
Âµl
â„“2
l,2
2
Âµ2
l+3
2â„“2
l,1
.
On the other hand, we know that projected gradient descent is a contraction according to [30], i.e.
âˆ¥Î·ku,kl+1âˆ’Î·âˆ—(Î¾ku)âˆ¥2â‰¤(1âˆ’Ï„lÂµl)âˆ¥Î·ku,klâˆ’Î·âˆ—(Î¾ku)âˆ¥2(79)
for 0â‰¤Ï„lâ‰¤1
â„“l,1. By induction, we have
âˆ¥Î·ku,kl+1âˆ’Î·âˆ—(Î¾ku)âˆ¥2â‰¤(1âˆ’Ï„lÂµl)klâˆ¥Î·kuâˆ’Î·âˆ—(Î¾ku)âˆ¥2(80)
Then (78) becomes
âˆ¥âˆ‡Î¾kuÎ·ku,kl+1âˆ’wkl+1âˆ¥2â‰¤(1âˆ’Ï„lÂµl)âˆ¥âˆ‡Î¾kuÎ·ku,klâˆ’wklâˆ¥2+C2
l(1âˆ’Ï„lÂµl)klâˆ’1âˆ¥Î·kuâˆ’Î·âˆ—(Î¾ku)âˆ¥2.(81)
Then by induction and w1=âˆ‡Î¾kuÎ·ku,1= 0, Î·ku+1=Î·ku,Kl+1, we obtain that
âˆ¥âˆ‡Î¾kuÎ·ku+1âˆ’wKl+1âˆ¥2â‰¤Kl(1âˆ’Ï„lÂµl)Klâˆ’1C2
lâˆ¥Î·âˆ—(Î¾ku)âˆ’Î·kuâˆ¥2. (82)
Combining (82) with (76) and setting Ï„lâ‰¤1
2â„“l,1, we know that
âˆ¥âˆ‡Î¾kuÎ·ku+1âˆ’ âˆ‡Î·âˆ—(Î¾ku)âˆ¥2â‰¤2 (1âˆ’Ï„lÂµl)2Kl+2+ 2Kl(1âˆ’Ï„lÂµl)Klâˆ’1C2
lâˆ¥Î·âˆ—(Î¾ku)âˆ’Î·kuâˆ¥2. (83)
Then given Ï„land let f(Kl) =Kl(1âˆ’Ï„lÂµl)Klâˆ’1, we know log( f(Kl)) = log Kl+ (Klâˆ’1) log(1 âˆ’Ï„lÂµl).
Taking the gradient of log( f(Kl)), we get 1 /Kl+ log(1 âˆ’Ï„lÂµl). As log(1 âˆ’Ï„lÂµl)<0, we know log( f(Kl))
first increases and then decreases and thus, log( f(Kl)) and f(Kl) have a finite upper bound. Let us denote
the upper bound of Kl(1âˆ’Ï„lÂµl)Klâˆ’1asCKl=O(1). Then (83) becomes
âˆ¥âˆ‡Î¾kuÎ·ku+1âˆ’ âˆ‡Î·âˆ—(Î¾ku)âˆ¥2â‰¤2 (1âˆ’Ï„lÂµl)2Kl+2+ 2CKlC2
lâˆ¥Î·âˆ—(Î¾ku)âˆ’Î·kuâˆ¥2. (84)
which yields the conclusion.
22Besides, we have the lower-level contraction and error.
Lemma 5.4 (Lower-level error) .Suppose that Assumption 1â€“3 hold and Ï„lâ‰¤1
â„“l,1, then for any Î³ >0, we
have
âˆ¥Î·ku+1âˆ’Î·âˆ—(Î¾ku)âˆ¥2â‰¤(1âˆ’Ï„lÂµl)Klâˆ¥Î·kuâˆ’Î·âˆ—(Î¾ku)âˆ¥2(85a)
âˆ¥Î·ku+1âˆ’Î·âˆ—(Î¾ku+1)âˆ¥2â‰¤(1 +Î³)âˆ¥Î·ku+1âˆ’Î·âˆ—(Î¾ku)âˆ¥2+L2
Î·
1 +1
Î³
âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’Ï„ubâˆ‡u(Î¾ku))âˆ¥2(85b)
Proof. (85a) comes from (80) when setting kl=Kl. Moreover,
âˆ¥Î·ku+1âˆ’Î·âˆ—(Î¾ku+1)âˆ¥2=âˆ¥Î·ku+1âˆ’Î·âˆ—(Î¾ku) +Î·âˆ—(Î¾ku)âˆ’Î·âˆ—(Î¾ku+1)âˆ¥2
(a)
â‰¤(1 +Î³)âˆ¥Î·ku+1âˆ’Î·âˆ—(Î¾ku)âˆ¥2+
1 +1
Î³
âˆ¥Î·âˆ—(Î¾ku)âˆ’Î·âˆ—(Î¾ku+1)âˆ¥2
(b)
â‰¤(1 +Î³)âˆ¥Î·ku+1âˆ’Î·âˆ—(Î¾ku)âˆ¥2+L2
Î·
1 +1
Î³
âˆ¥Î¾kuâˆ’Î¾ku+1âˆ¥2
= (1 + Î³)âˆ¥Î·ku+1âˆ’Î·âˆ—(Î¾ku)âˆ¥2+L2
Î·
1 +1
Î³
âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’Ï„ubâˆ‡u(Î¾ku))âˆ¥2
where (a) is due to âˆ¥a+bâˆ¥2
2â‰¤(1 +Î³)âˆ¥aâˆ¥2
2+ (1 +1
Î³)âˆ¥bâˆ¥2
2for any Î³ >0, and (b) comes from the Lipschitz
continuity of Î·âˆ—(Î¾) in Lemma 5.2.
Lemma 5.5 (Upper-level error) .Under Suppose that Assumption 1â€“3 hold and Ï„lâ‰¤1
2â„“l,1, then it holds that
u(Î¾ku+1)âˆ’u(Î¾ku)â‰¤ âˆ’Ï„u
2âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’ âˆ‡u(Î¾ku))âˆ¥2âˆ’1
2Ï„uâˆ’Lu
2
âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’bâˆ‡u(Î¾ku))âˆ¥2
+Ï„u 
â„“u,1(1 +LÎ·) + 2â„“u,0CKlC2
l2âˆ¥Î·âˆ—(Î¾ku)âˆ’Î·kuâˆ¥2+ 2Ï„u(1âˆ’Ï„lÂµl)4Kl+4
Proof. According to Lemma 5.2, we know u(Î¾) =U(Î·âˆ—(Î¾), Î¾) is Lipschitz smooth and
âˆ‡u(Î¾) =âˆ‡Î¾U(Î·âˆ—(Î¾), Î¾) +âˆ‡âŠ¤
Î¾Î·âˆ—(Î¾)âˆ‡Î·U(Î·âˆ—(Î¾), Î¾)
and for any Î¾1, Î¾2, we have
âˆ¥âˆ‡u(Î¾1)âˆ’ âˆ‡u(Î¾2)âˆ¥=âˆ¥âˆ‡Î¾U(Î·âˆ—(Î¾1), Î¾1) +âˆ‡âŠ¤
Î¾Î·âˆ—(Î¾1)âˆ‡Î·U(Î·âˆ—(Î¾1), Î¾1)âˆ’ âˆ‡ Î¾U(Î·âˆ—(Î¾2), Î¾2)âˆ’ âˆ‡âŠ¤
Î¾Î·âˆ—(Î¾2)âˆ‡Î·U(Î·âˆ—(Î¾2), Î¾2)âˆ¥
â‰¤ âˆ¥âˆ‡ Î¾U(Î·âˆ—(Î¾1), Î¾1)âˆ’ âˆ‡ Î¾U(Î·âˆ—(Î¾2), Î¾2)âˆ¥+âˆ¥âˆ‡âŠ¤
Î¾Î·âˆ—(Î¾1)âˆ¥âˆ¥âˆ‡ Î·U(Î·âˆ—(Î¾1), Î¾1)âˆ’ âˆ‡ Î·U(Î·âˆ—(Î¾2), Î¾2)âˆ¥
+âˆ¥âˆ‡Î·U(Î·âˆ—(Î¾2), Î¾2)âˆ¥âˆ¥âˆ‡ Î¾Î·âˆ—(Î¾1)âˆ’ âˆ‡ Î¾Î·âˆ—(Î¾2)âˆ¥
â‰¤â„“u,1(âˆ¥Î·âˆ—(Î¾1)âˆ’Î·âˆ—(Î¾2)âˆ¥+âˆ¥Î¾1âˆ’Î¾2âˆ¥) +LÎ·â„“u,1(âˆ¥Î·âˆ—(Î¾1)âˆ’Î·âˆ—(Î¾2)âˆ¥+âˆ¥Î¾1âˆ’Î¾2âˆ¥) +â„“u,0LÎ·Î¾âˆ¥Î¾1âˆ’Î¾2âˆ¥
â‰¤(â„“u,1(1 +LÎ·)2+â„“u,0LÎ·Î¾)âˆ¥Î¾1âˆ’Î¾2âˆ¥.
By denoting the smoothness constant of u(Î¾) asLu:=â„“u,1(1+LÎ·)2+â„“u,0LÎ·Î¾, we have the following expansion
u(Î¾ku+1)â‰¤u(Î¾ku) +âŸ¨âˆ‡u(Î¾ku), Î¾ku+1âˆ’Î¾kuâŸ©+Lu
2âˆ¥Î¾ku+1âˆ’Î¾kuâˆ¥2
=u(Î¾ku)âˆ’ âŸ¨âˆ‡ u(Î¾ku), Î¾kuâˆ’ProjÎ(Î¾kuâˆ’Ï„ubâˆ‡u(Î¾ku))âŸ©+Lu
2âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’Ï„ubâˆ‡u(Î¾ku))âˆ¥2
(a)=u(Î¾ku)âˆ’1
Ï„uâŸ¨Î¾kuâˆ’ProjÎ(Î¾kuâˆ’Ï„uâˆ‡u(Î¾ku)), Î¾kuâˆ’ProjÎ(Î¾kuâˆ’Ï„ubâˆ‡u(Î¾ku))âŸ©
+Lu
2âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’Ï„ubâˆ‡u(Î¾ku))âˆ¥2
23(b)=u(Î¾ku)âˆ’1
2Ï„uâˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’Ï„uâˆ‡u(Î¾ku))âˆ¥2
+1
2Ï„uâˆ¥ProjÎ(Î¾kuâˆ’Ï„uâˆ‡u(Î¾ku))âˆ’ProjÎ(Î¾kuâˆ’Ï„ubâˆ‡u(Î¾ku))âˆ¥2
âˆ’1
2Ï„uâˆ’Lu
2
âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’Ï„ubâˆ‡u(Î¾ku))âˆ¥2
(c)
â‰¤u(Î¾ku)âˆ’Ï„u
2âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’ âˆ‡u(Î¾ku))âˆ¥2+Ï„u
2âˆ¥âˆ‡u(Î¾ku)âˆ’bâˆ‡u(Î¾ku)âˆ¥2
âˆ’1
2Ï„uâˆ’Lu
2
âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’Ï„ubâˆ‡u(Î¾ku))âˆ¥2(86)
where (a) comes from Î¾ku= ProjÎ(Î¾ku) and the fact that ProjÎonto a linear equality constraint set is a
linear operator, (b) is derived from 2 aâŠ¤b=âˆ¥aâˆ¥2+âˆ¥bâˆ¥2âˆ’âˆ¥aâˆ’bâˆ¥2and (c) is because ProjÎis a linear operator
andâˆ¥Proj( A)âˆ’Proj( B)âˆ¥ â‰¤ âˆ¥ Aâˆ’Bâˆ¥. Besides, we can decompose the gradient bias term as follows
âˆ¥âˆ‡u(Î¾ku)âˆ’bâˆ‡u(Î¾ku)âˆ¥=âˆ¥âˆ‡Î¾U(Î·âˆ—(Î¾ku), Î¾ku)âˆ’ âˆ‡Î·âˆ—(Î¾ku)âŠ¤âˆ‡Î·U(Î·âˆ—(Î¾ku), Î¾ku)
âˆ’ âˆ‡ Î¾U(Î·ku+1, Î¾ku) +âˆ‡âŠ¤
Î¾kuÎ·ku+1âˆ‡Î·U(Î·ku+1, Î¾ku)âˆ¥
â‰¤ âˆ¥âˆ‡ Î¾U(Î·âˆ—(Î¾ku), Î¾ku)âˆ’ âˆ‡ Î¾U(Î·ku+1, Î¾ku)âˆ¥
+âˆ¥âˆ‡Î·âˆ—(Î¾ku)âˆ¥âˆ¥âˆ‡ Î·U(Î·âˆ—(Î¾ku), Î¾ku)âˆ’ âˆ‡ Î·U(Î·ku+1, Î¾ku)âˆ¥
+âˆ¥âˆ‡Î·U(Î·ku+1, Î¾ku)âˆ¥âˆ¥âˆ‡Î·âˆ—(Î¾ku)âˆ’ âˆ‡ Î¾kuÎ·ku+1âˆ¥
â‰¤â„“u,1(1 +LÎ·)âˆ¥Î·âˆ—(Î¾ku)âˆ’Î·ku+1âˆ¥+â„“u,0âˆ¥âˆ‡Î·âˆ—(Î¾ku)âˆ’ âˆ‡ Î¾kuÎ·ku+1âˆ¥
(a)
â‰¤ 
â„“u,1(1 +LÎ·) + 2â„“u,0CKlC2
l
âˆ¥Î·âˆ—(Î¾ku)âˆ’Î·kuâˆ¥+ 2 (1 âˆ’Ï„lÂµl)2Kl+2(87)
where (a) comes from lower-level contraction (80). Thus, plugging (87) to (86), we get that
u(Î¾ku+1)âˆ’u(Î¾ku)â‰¤ âˆ’Ï„u
2âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’ âˆ‡u(Î¾ku))âˆ¥2âˆ’1
2Ï„uâˆ’Lu
2
âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’bâˆ‡u(Î¾ku))âˆ¥2
+Ï„u
2 
â„“u,1(1 +LÎ·) + 2â„“u,0CKlC2
l
âˆ¥Î·âˆ—(Î¾ku)âˆ’Î·kuâˆ¥+ 2 (1 âˆ’Ï„lÂµl)2K+22
â‰¤ âˆ’Ï„u
2âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’ âˆ‡u(Î¾ku))âˆ¥2âˆ’1
2Ï„uâˆ’Lu
2
âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’bâˆ‡u(Î¾ku))âˆ¥2
+Ï„u 
â„“u,1(1 +LÎ·) + 2â„“u,0CKlC2
l2âˆ¥Î·âˆ—(Î¾ku)âˆ’Î·kuâˆ¥2+ 2Ï„u(1âˆ’Ï„lÂµl)4Kl+4
With Lemma 5.2, 5.3, 5.4 and 5.5, we restate the convergence Theorem 4.2 in a more formal way and
prove the theorem as follows.
Theorem 5.6. Under Assumption 1â€“3, let Ï„lâ‰¤1
2â„“l,1, Kl=O(logKu)andÏ„u=O(1)satisfies
Ï„uâ‰¤min1
2Lu(1 + 2 LÎ·),Ï„lLuÂµl
LÎ·((â„“u,1(1 +LÎ·) + 2â„“u,0CKlC2
l)2+ 4L2u)
,
then the iterates of Algorithm 2 satisfy
1
KuKuX
ku=1âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’ âˆ‡u(Î¾ku))âˆ¥2=O1
Ku
(88)
where Oomits the logdependency.
Proof. We can define Lyapunov function as
Vku=u(Î¾ku) +Lu
LÎ·âˆ¥Î·âˆ—(Î¾ku)âˆ’Î·kuâˆ¥2
24On the one hand, plugging (85a) to (85b), we get
âˆ¥Î·ku+1âˆ’Î·âˆ—(Î¾ku+1)âˆ¥2â‰¤(1 +Î³) (1âˆ’Ï„lÂµl)âˆ¥Î·kuâˆ’Î·âˆ—(Î¾ku)âˆ¥2+L2
Î·
1 +1
Î³
âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’Ï„ubâˆ‡u(Î¾ku))âˆ¥2.
(89)
On the other hand, according to Lemma 5.5 and (89), it holds that
Vku+1âˆ’Vkuâ‰¤ âˆ’Ï„u
2âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’ âˆ‡u(Î¾ku))âˆ¥2âˆ’1
2Ï„uâˆ’Lu
2
âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’bâˆ‡u(Î¾ku))âˆ¥2
+Ï„u 
â„“u,1(1 +LÎ·) + 2â„“u,0CKlC2
l2âˆ¥Î·âˆ—(Î¾ku)âˆ’Î·kuâˆ¥2+ 2Ï„u(1âˆ’Ï„lÂµl)4K+4
+Lu
LÎ·[(1 + Î³) (1âˆ’Ï„lÂµl)âˆ’1]âˆ¥Î·kuâˆ’Î·âˆ—(Î¾ku)âˆ¥2+LuLÎ·
1 +1
Î³
âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’Ï„ubâˆ‡u(Î¾ku))âˆ¥2
(a)
â‰¤ âˆ’Ï„u
2âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’ âˆ‡u(Î¾ku))âˆ¥2âˆ’1
4Ï„uâˆ’Lu
2âˆ’LuLÎ·
âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’Ï„ubâˆ‡u(Î¾ku))âˆ¥2
âˆ’Ï„lLuÂµl
LÎ·âˆ’Ï„u 
(â„“u,1(1 +LÎ·) + 2â„“u,0CKlC2
l)2+ 4L2
u
âˆ¥Î·âˆ—(Î¾ku)âˆ’Î·kuâˆ¥2+ 2Ï„u(1âˆ’Ï„lÂµl)4Kl+4
(b)
â‰¤ âˆ’Ï„u
2âˆ¥Î¾kuâˆ’ProjÎ(Î¾kuâˆ’ âˆ‡u(Î¾ku))âˆ¥2+ 2Ï„u(1âˆ’Ï„lÂµl)4Kl+4(90)
where (a) is earned by setting Î³= 4LuLÎ·Ï„uand (b) comes from the conditions
1
4Ï„uâˆ’Lu
2âˆ’LuLÎ·â‰¥0,andÏ„lLuÂµl
LÎ·âˆ’Ï„u 
(â„“u,1(1 +LÎ·) + 2â„“u,0CKlC2
l)2+ 4L2
u
â‰¥0. (91)
The sufficient conditions for (91) are
Ï„uâ‰¤min1
2Lu(1 + 2 LÎ·),Ï„lLuÂµl
LÎ·((â„“u,1(1 +LÎ·) + 2â„“u,0CKlC2
l)2+ 4L2u)
.
Rearranging terms and telescoping (90) yield
1
KuKuX
ku=1Î¾kuâˆ’ProjÎ(Î¾kuâˆ’ âˆ‡u(Î¾ku))2â‰¤2(V1âˆ’VKu+1)
Ï„uKu+ 4(1âˆ’Ï„lÂµl)4Kl+4
â‰¤2(V1âˆ’infÎ¾u(Î¾))
Ï„uKu+ 4(1âˆ’Ï„lÂµl)4Kl+4.
Then by choosing Kl=O(log(Ku)), the convergence rate of Algorithm 2 is O
1
Ku
.
The above theorem guarantees the Algorithm 2 converges to an Ïµstationary point given that assumptions
1â€“3 are satisfied. And Lemma 3.4 states the convexity and Lipschitz smoothness of the lower-level objective
functions LG(Ï,m;g, b) in (21) and shows that our problem setting satisfies the assumptions.
Since the interpolation operators Ix, Iy, Itare linear and positive definite, to prove Lemma 3.4, it is
sufficient to prove the (strong) convexity and the Lipschitz smoothness of LG,Î³:R+Ã—Rdâ†’R,(Î±,Î²)7â†’
Î²âŠ¤GÎ²
2Î±+Î³Î±log(Î±).
Lemma 5.7. LetGbe adÃ—dsymmetric positive definite matrix and LG,Î³:R+Ã—Rdâ†’R,(Î±,Î²)7â†’Î²âŠ¤GÎ²
2Î±+
Î³Î±log(Î±). For any Î³â‰¥0,LG,Î³is convex in R+Ã—Rdand Lipschitz smooth in {Î±âˆˆR:Î±â‰¥cÏ>0} Ã— {Î²âˆˆ
Rd:âˆ¥Î²âˆ¥ â‰¤cm}(cm>0). And for any Î³ >0,LG,Î³is strongly convex in {Î±âˆˆR:cÏâ‰¥Î±â‰¥cÏ>0} Ã—Rd.
Proof. Since Gis symmetric and positive definite, we write the singular value decomposition of GasG=
UÎ£GUâŠ¤, with UUâŠ¤=UâŠ¤U=I, Î£G= diag( ÏƒG,d, ÏƒG,dâˆ’1,Â·Â·Â·, ÏƒG,1), (ÏƒG,dâ‰¥ÏƒG,dâˆ’1â‰¥ Â·Â·Â· â‰¥ ÏƒG,1).
25And ÏƒG,i, i= 1,Â·Â·Â·, dare the singular values of G. Denote Î£1
2
G:= diag(âˆšÏƒG,d,âˆšÏƒG,dâˆ’1,Â·Â·Â·,âˆšÏƒG,1) and
S= Î£1
2
GUâŠ¤. Then G=SâŠ¤Sand the singular values of SareÏƒS,i=âˆšÏƒG,i.
Obviously, LG,Î³is twice differentiable in R+Ã—Rdand
âˆ‡2LG,Î³(Î±,Î²) =1
Î±3
Î²âŠ¤GÎ²âˆ’Î±Î²âŠ¤GâŠ¤
âˆ’Î±GÎ² Î±2G
=1
Î±31
SâŠ¤
(SÎ²)âŠ¤SÎ²+Î³Î±2âˆ’Î±(SÎ²)âŠ¤
âˆ’Î±SÎ² Î±2I
1
S
=1
Î±31
SâŠ¤
âˆ‡2LI,Î³(Î±, SÎ²)1
S
.(92)
We denote the minimal and maximal singular values of âˆ‡2LG,Î³(Î±,Î²) asÏƒG,Î³
min(Î±,Î²) and ÏƒG,Î³
max(Î±,Î²). Then
we have
ÏƒG,Î³
min(Î±,Î²)â‰¥min(1 , ÏƒG,1)
Î±3ÏƒI,Î³
min(Î±, SÎ²), ÏƒG,Î³
max(Î±,Î²)â‰¤max(1 , ÏƒG,d)
Î±3ÏƒI,Î³
max(Î±, SÎ²). (93)
By computation, the eigenvalues Î»I,Î³(Î±,Î²) ofâˆ‡2LI,Î³(Î±,Î²) satisfy
 
Î»2âˆ’ 
âˆ¥Î²âˆ¥2+ (Î³+ 1)Î±2
Î»+Î³Î±4
(Î»âˆ’Î±2)dâˆ’1= 0. (94)
Therefore Î»I,Î³(Î±,Î²)â‰¥0 andï£±
ï£´ï£²
ï£´ï£³ÏƒI,Î³
min(Î±,Î²)â‰¥Î³Î±4
âˆ¥Î²âˆ¥2+ (Î³+ 1)Î±2â‰¥0,
ÏƒI,Î³
max(Î±,Î²)â‰¤ âˆ¥Î²âˆ¥2+ (Î³+ 1)Î±2(95)
ForÎ³â‰¥0,ÏƒG,Î³
min(Î±,Î²)â‰¥0 hold for any Î± >0,Î²âˆˆRd, which implies LÎ³is convex. For Î³â‰¥0, Î±â‰¥cÏ,âˆ¥Î²âˆ¥ â‰¤
cm,ÏƒG,Î³
max(Î±,Î²)â‰¤max(1 , ÏƒG,d)
ÏƒG,dc2
m+(Î³+1)c2
Ï
c3
Ï
hold for any Î±â‰¥cÏ,âˆ¥Î²âˆ¥ â‰¤cm, which implies LG,Î³is Lip-
schitz smooth. And for Î³ >0,cÏâ‰¥Î±â‰¥cÏ,ÏƒG,Î³
min(Î±,Î²)â‰¥min(1 , ÏƒG,1) min
Î³cÏ
ÏƒG,dc2
m+(Î³+1)c2
Ï,Î³cÏ
ÏƒG,dc2
m+(Î³+1)c2
Ï
.
6 Numerical Experiments
6.1 Experiment Settings
This section presents several numerical experiments to illustrate the effectiveness of our model and algorithm.
We generate the data by solving the forward problem using the projected gradient descent algorithm proposed
in [31] based on the FISTA algorithm [1]. In each experiment, we report the relative error versus the number
of iterations for recovering the obstacle and the metric. The relative error for recovering the obstacle is
vuutPnx
ix=1Pny
iy=1((bKu)ix,iyâˆ’(eb)ix,iy)2
Pnx
ix=1Pny
iy=1(eb)2
ix,iy, (96)
and the relative errors for the metrics are
(1D)sPnx
ix=1((gKu)ixâˆ’(eg)ix)2
Pnx
ix=1(eg)2
ix, (2D)vuutPnx
ix=1Pny
iy=1âˆ¥(gKu)ix,iyâˆ’(eg)ix,iyâˆ¥2
FPnx
ix=1Pny
iy=1âˆ¥(eg)ix,iyâˆ¥2
F, (97)
where bKu, gKuare the numerical results after Kuupper-level updates and eb,egare the ground truth. We
implement all of our numerical experiments in Matlab on a PC with an Intel(R) i7-8550U 1.80GHz CPU
and 16 GB memory.
266.2 Theoretical arguments verification
6.2.1 Algorithm convergence and obstacle unique identifiability
The first experiment aims to numerically verify the stability Theorem 3.8, the unique identifiability Theorem
3.9 and convergence analysis in Theorem 4.2 of the bilevel algorithm with lower and upper-level constraints.
We discretize the space with nt= 16 , nx=ny= 64. Denote pg(x, y;Âµx, Âµy, Ïƒx, Ïƒy) as the probabil-
ity density function of Gaussian distribution with mean ( Âµx, Âµy) and covariance matrix diag( Ïƒ2
x, Ïƒ2
y). We
feed the model with one pair of observations, i.e. N= 1, with Âµ0=pg(Â·,Â·;âˆ’0.25,0,0.08,0.08),Âµ1=
pg(Â·,Â·; 0.25,0,0.08,0.08) and Î³I= 0.1, Î³T= 5. We choose the obstacle function as b(x, y) =Î³bpg(x, y; 0,0,0.08,0.1).
With different values of Î³b, the agents avoid the center of the obstacle to different degrees. Higher values of
Î³blead to lower density values at ( x, y) = (0 ,0). According to remark 3.10, low-density values in the data
result in difficulties in accurately reconstructing the obstacle.
5101520
5101520
51015202530
5101520253035
00.20.40.60.8
00.511.5
0246
0246810
0 2000 4000 6000
UL iteration051015UL objectiveUL Objective
0 2000 4000 6000
UL iteration0102030UL objectiveUL Objective
0 2000 4000 6000
UL iteration0204060UL objectiveUL Objective
0 2000 4000 6000
UL iteration020406080UL objectiveUL Objective
0 2000 4000 6000
UL iteration00.51obs relative error
0 2000 4000 6000
UL iteration00.51obs relative error
0 2000 4000 6000
UL iteration0.20.40.60.81obs relative error
0 2000 4000 6000
UL iteration0.20.40.60.81obs relative error
Figure 2: Convergence test of the inverse crowd motion problem. Top to bottom: the snapshot of eÏat
t= 0.5, recovered bwith smallest relative error, upper-level objective value versus the number of iterations,
relative error of bversus the number of iterations. Left to right: Î³b= 0.05,0.1,0.5,1.
Figure 2 and Table 1 compare the results with Î³b= 0.05,0.1,0.5,5. For a fair comparison, we initialize
the algorithm with obstacle b0=0so that the initial relative errors all start from 1 for different Î³b. We run
each inner loop for 5 iterations and run the outer loop for 6000 iterations.
The first row in Figure 2 plots training data eÏ(Â·,Â·,0.5) and em(Â·,Â·,0.5). In the first column of table 1, we
report the density value eÏ(Â·,Â·,0.5) at the center, reflecting the value of min eÏ. It is clear to see that more
agents avoid the center of the obstacle as Î³bgrows larger, thus the density value in the center decreases.
The third row of Figure 2 presents the progression of upper-level objective values across upper-level
iterations, while Table 1, Column 2, details the final upper-level objective values. To enhance the precision
27Table 1: Convergence test of the inverse crowd motion problem.
Î³beÏ(0,0,0.5)upper-level
objective valuerelative error
(best)relative error
(terminial)time elapsed
(second)
0.05 0.7831 1.1792 0.0139 0.0148 1570.1611
0.1 0.0293 2.2504 0.0134 0.0161 1537.9703
0.5 0.0079 6.2426 0.2186 0.3500 1565.9526
1 0.0054 8.5889 0.3326 0.4354 1549.7152
of the upper-level objective calculation, we execute the forward solver to convergence every 10 upper-level
iterations. This approach yields a refined approximation of ( Ïâˆ—(b(k)),mâˆ—(b(k))), thereby providing a more
accurate estimation of the upper-level objective values. Theorem 4.2 implies that convergence is achieved
when min eÏ >0. Supporting this, Table 1, Column 1, indicates that min eÏ >0 for all considered Î³bvalues.
Furthermore, Figure 2, Row 3, demonstrates numerical convergence for each Î³bselection. This verifies the
algorithm convergence Theorem 4.2.
We qualitatively show the numerical solutions of the obstacle in the second row of Figure 2, while we
report the relative error in the fourth row of Figure 2 and list the best relative error and terminal step relative
error in the third and fourth column of Table 1, respectively. Given that min eÏ >0, Theorem 3.9 suggests
the possibility of uniquely recovering the ground truth obstacle, up to a constant, for all Î³bvalues of 0.05,
0.1, 0.5, and 1. Numerically, this unique recovery is observed for Î³b= 0.05 and 0 .1. However, for higher
Î³bvalues of 0.5 and 1, the reconstructed bdoes not align perfectly with the ground truth eb, as one might
expect. This deviation is accounted for by Remark 3.10, which discusses the robustness of the reconstruction.
Specifically, when Î³bis set to 0.5 or 1, the lower bound of the data eÏdecreases. According to Remark 3.10,
a smaller eÏlower bound leads to less robust solutions, making them more susceptible to distortions from
small perturbations in the ground truth. In our experiments, since the forward solver typically produces
an approximation of the exact minimizer after a finite number of iterations, the data represents a slight
deviation from the ground truth. Consequently, This causes the reconstructed obstacle to differ from the
exact obstacle and the discrepancy is more obvious when Î³b= 0.5,1.
6.2.2 Improving results with multiple data
We conduct an experiment to show that multiple training data help to enhance reconstruction results for
the inverse metric problem.
The example is defined on space domain [ âˆ’0.5,0.5] and time domain [0 ,1]. We discretize the space
domain [ âˆ’0.5,0.5] with nx= 64 and the time domain [0 ,1] with nt= 16. The ground truth metric is
eg(x) = 0 .7âˆ’0.3 cos(2 Ï€x). The parameters in the forward problem are Î³I= 0.01, Î³T= 0.5. Then we obtain
the first pair of data with Âµ0(x) = 1 .25âˆ’0.25 cos(4 Ï€x), Âµ1= 1.25 + 0 .25 cos(2 Ï€x) and the second pair with
Âµ0(x) =pg(x; 0,0.1), Âµ1= 1.
We solve the inverse problem with the first pair of data ( N= 1) or both data ( N= 2). When solving
the inverse problem, we take the information on the left end Gk={ix:ix= 1}as known and fix it. We
choose R(g) :=1
2Î³RR
âˆ¥âˆ‡g(x)âˆ¥2
2dxto regularize the smoothness of the metric. The discretization is therefore
RG(g) :=1
2Î³Râˆ†xPnxâˆ’1
ix=1((g)ix+1âˆ’(g)ix)2.
We run the Algorithm 2 for 5000 iterations with 5 iterations per each inner loop. The initialization on
ix= 1 is set as the true value and the initialization on other points is 0.7. Figure 3 shows the comparison
of numerical results and ground truth (row 1) and the relative error of the metric versus the number of
upper-level iterations. Table 2 reports the weight of regularization Î³R, relative error, and running time of
the algorithm. For one comparison, we choose no regularization ( Î³R= 0) in the model. The results with
the first data ( N= 1) are presented in row 1 and the results with both data ( N= 2) are in row 2. Then
we tune the regularization parameter and report the best results with the first data in row 3 and with both
data in row 4. It is easy to see that when using both data, our model captures the ground truth metric
better and achieves lower relative error. It is worth noting that when using both data to solve the inverse
problem, our model captures the shape of the ground truth metric even without smoothness regularization.
However, when using the first data, the model fails to learn the information in the center and on both ends.
28-0.5 0 0.50.40.60.81
true
num
-0.5 0 0.50.40.60.81
true
num
-0.5 0 0.50.40.60.81
true
num
-0.5 0 0.50.40.60.81
true
num
0 1000 2000 3000 4000 50000.150.20.250.3
0 1000 2000 3000 4000 50000.050.10.150.20.250.3
0 1000 2000 3000 4000 50000.10.150.20.250.3
0 1000 2000 3000 4000 500000.10.20.3Figure 3: Improving results with multiple data. Top to bottom: comparison of numerical gand the ground
trutheg, the relative error of gversus the number of iterations. Left to right: ( N= 1, Î³R= 0), ( N= 2, Î³R=
0), (N= 1, Î³R= 10âˆ’5), (N= 2, Î³R= 10âˆ’4).
Table 2: Improving results with multiple data.
N Î³R relative error time elapsed (seconds)
1 0 0.1700 60.0653
2 0 0.0673 128.5328
1 1Ã—10âˆ’50.1073 67.3291
2 1Ã—10âˆ’40.0145 118.9042
6.3 Robustness with respect to data
6.3.1 Unknown obstacles
To test the robustness of our method for noisy input as discussed in Remark 3.10 , we design the following
numerical experiment.
We discretize the space [ âˆ’0.5,0.5]2with nx=ny= 64 and choose nt= 16. We let the obsta-
cle function be b(x, y) =(
0.5, x < 0,0.05< y < 0.1,orx >0,âˆ’0.1< y < âˆ’0.05,
0, otherwise.. Assume there is one
pair of observations, with initial density Âµ0=pg(Â·,Â·;âˆ’0.3,0.3,0.1,0.1), preferred terminal density Âµ1=
pg(Â·,Â·; 0.3,âˆ’0.3,0.1,0.1) and Î³I= 0.1, Î³T= 1. We use the perturbed observation eÏ+Î³nnÏ,em+Î³nnmto
solve the inverse problem, where Î³n= 0,0.25,0.5,0.75 and noise nÏ, nmare generated by pointwise i.i.d
sampling from the uniform distribution U[âˆ’0.5,0.5]. To avoid numerical instability caused by zero value or
negative density values, we threshold the perturbed density by 0.01. All experiments initialize with the same
random choice of b. Every inner loop contains 5 iterations and 5000 outer iterations have been conducted.
In addition, we do not add any regularizer in this experiment. From Figure 4 and Table 3, we observe that
with larger noise, the relative errors between numerical results and the ground truth are larger. Overall, the
numerical results capture the shape of the ground truth and the algorithm converges to a close result to the
ground truth ebwith reasonably low relative errors.
6.3.2 Unknown 1D metric
This is a 1D example on [ âˆ’0.5,0.5]Ã—[0,1]. We discretize the space domain [ âˆ’0.5,0.5] with nx= 64 and
the time domain [0 ,1] with nt= 16. The ground truth metric is eg(x) = 8 x(xâˆ’0.375)( x+ 0.375) + 1. The
data is obtained by taking Âµ0(x) =pg(x; 0,0.1), Âµ1= 1 and Î³I= 0.01, Î³T= 0.5. We test the robustness
of the model by perturbing the observation eÏ,em. The noises nÏ, nmshare the same size with eÏ,emand are
pointwise i.i.d samples from U[âˆ’0.5,0.5]. We use the perturbed data eÏ+Î³nnÏ,em+Î³nnmto solve the inverse
2900.10.20.30.4
00.10.20.30.40.5
00.10.20.30.40.5
-0.100.10.20.30.40.5
-2024610-3
-0.08-0.06-0.04-0.0200.020.04
-0.15-0.1-0.0500.05
-0.2-0.100.1
0 1000 2000 3000 4000 5000
UL iteration0123obs relative error
0 1000 2000 3000 4000 5000
UL iteration0123obs relative error
0 1000 2000 3000 4000 5000
UL iteration0123obs relative error
0 1000 2000 3000 4000 5000
UL iteration11.522.53obs relative errorFigure 4: Robustness test of the inverse crowd motion problem. Top to bottom: numerical b, the difference
between the numerical results and the ground truth bâˆ’eb, the relative error of bversus the number of
iterations. Left to right: noise level Î³n= 0,0.25,0.5,0.75.
Table 3: Robustness test of the inverse crowd motion problem.
Î³n relative error (last) time elapsed (second)
0 0.0081 1437.0926
0.25 0.0897 1343.8082
0.5 0.3771 1397.4578
0.75 0.7035 1379.7269
problem, where Î³n= 0,0.1,0.2,0.3. Row 1-2 of figure 5 illustrate the perturbed data.
When solving the inverse problem, we take the information on the left end Gk={ix:ix= 1}as known
and fix it. Same as section 6.2.2, we choose R(g) :=1
2Î³RR
âˆ¥âˆ‡g(x)âˆ¥2
2dxto regularize the smoothness of the
metric. The regularization weight Î³Rtakes different values for different Î³nand the values are in Table 4.
We run Algorithm 2 for 5000 iterations with 5 iterations per each inner loop. The initialization of gtakes
value 1 everywhere. Figure 5 and table 4 compare the result with different Î³n.
From the comparison in Figure 5 and the relative error in Table 4, we observe that as the noise level
increases, the recovered metric deviates more from the ground truth. However, it is crucial to highlight that,
on the whole, our model adeptly captures the underlying shape of the metric with reasonable fidelity, and
the associated relative error remains consistently small. This robust performance underscores the resilience
of our model in the presence of added noise to the data.
6.4 Robustness with respect to unknowns
We present more numerical results to show that our method effectively recovers various types of obstacles
and metrics.
30-0.5 0 0.50.511.5
true
num
-0.5 0 0.50.511.5
true
num
-0.5 0 0.50.511.5
true
num
-0.5 0 0.50.511.5
true
num
0 1000 2000 3000 4000 50000.050.10.15
0 1000 2000 3000 4000 50000.050.10.15
0 1000 2000 3000 4000 50000.060.080.10.120.140.16
0 1000 2000 3000 4000 50000.080.10.120.14Figure 5: Robustness test of the inverse metric problem. Left to right: Î³n= 0,0.1,0.2,0.3. Top to bottom:
perturbed data eÏ+Î³nnÏ, perturbed data em+Î³nnm, comparison of numerical gand the ground truth eg, the
relative error of gversus the number of iterations.
6.4.1 Unknown obstacles
Besides the obstacle of the Gaussian type and of a â€œtwo-barâ€ shape, we conduct experiments on obstacles
with more irregular shapes. We plot examples of â€œthe segmented ringâ€ and â€œcloverâ€ in figure 6. In both
experiments, only one pair of data is used to recover the unknown obstacle. The figure shows that our
algorithm produces consistently good results when recovering various obstacles. Our model and algorithm
recover the shape of the obstacle and achieve very low relative errors.
6.4.2 Unknown 1D metric
Apart from the experiments in sections 6.2.2 and 6.3.2, we conduct experiments on more different metrics
and plot the results in Figure 7. In both experiments, we use only one pair of data and the ground truth
information on the left end. The figure shows that our model and algorithm consistently recover the ground
Table 4: Robustness test of the inverse metric problem.
Î³n Î³R relative error (last) time elapsed (second)
0 1Ã—10âˆ’50.0358 63.4809
0.1 3Ã—10âˆ’40.0380 63.2121
0.2 1Ã—10âˆ’30.0645 61.5193
0.3 3Ã—10âˆ’30.0815 60.7215
3100.10.20.30.4
00.20.40.60.8
00.10.20.30.40.5
0 1000 2000 3000 4000 5000
UL iteration00.511.52obs relative error
00.10.20.30.4
-0.100.10.20.30.40.5
-0.100.10.20.3
0 1000 2000 3000 4000 5000
UL iteration00.511.52obs relative errorFigure 6: Robustness test of the inverse obstacle problem with respect to the obstacle. Mesh grid size:
nt= 16, nx=ny= 64. Left to right: ground truths, numerical results, the difference between ground truths
and numerical results, the relative error of the obstacle versus the number of iterations. Top to bottom:
relative error=0.3837, 0.1935, time elapsed=4103s, 3247s.
truth metric and achieve low relative errors.
-0.5 0 0.52.533.544.55
true
num
0 1000 2000 3000 4000 500000.10.20.30.40.5
-0.5 0 0.511.522.5
true
num
0 1000 2000 3000 4000 500000.10.20.30.40.5
Figure 7: Robustness test of the inverse metric problem with respect to the metric. Mesh grid size: nt=
16, nx=ny= 64. Columns 1,3: comparison of numerical gand the ground truth eg, columns 2,4: the
relative error of gversus the number of iterations. Column 1,2: Î»= 10âˆ’5, relative error=0.0172, time
elapsed=62.8513s, column 3,4: Î»= 10âˆ’5, relative error=0.0172, time elapsed=63.0395s.
6.5 Unknown 2D metric
The last example is a 2D inverse metric problem on [ âˆ’0.5,0.5]2Ã—[0,1]. We take nx=ny= 64 and
nt= 16. The ground truth metric is eg(x, y) =g0(x, y) + 4 g0(x, y) + 2
g0(x, y) + 2 g0(x, y) + 1
with g0(x, y) = 0 .75 +
0.5 sin(2 Ï€x) cos(2 Ï€yâˆ’0.5Ï€). The data is obtained by taking Î³I= 0.1, Î³T= 1. We take N= 4, i.e.
4 observations, in this example. The initial densities are Âµ0=pg(Â·,Â·;ax, ay,0.1,0.1) with ( ax, ay) =
(âˆ’0.3,âˆ’0.3),(âˆ’0.3,0),(âˆ’0.3,0.3),(0,0.3),and the terminal densities are Âµ1(x, y) =pg(Â·,Â·;ax, ay,0.1,0.1)
with ( ax, ay) = (0 .3,0.3),(0.3,0),(0.3,âˆ’0.3),(0,âˆ’0.3). We solve the inverse problem with the weights of
smoothness regularizers Î³R= 10âˆ’4. The algorithm initiates from gxx= 4, gxy= 2 and gyy= 1. Each inner
loop takes 5 iterations and each outer loop takes 5000 iterations. Columns 1-3 of Figure 8 shows the ground
truth, the recovered metric, and the difference between the numerical result and ground truth. Our model
and algorithm capture the symmetricity of the ground truth metric and achieve a relative error of value
0.0260.
324.44.64.855.2
4.24.44.64.855.2
-0.200.2
2.42.62.833.2
2.22.42.62.833.2
-0.2-0.100.10.2
1.41.61.822.2
1.21.41.61.822.2
-0.100.10.2Figure 8: Solving an inverse problem with an unknown metric in 2D. Mesh grid size: nt= 16, nx=ny= 64.
Left to right: ground truths, numerical results, the difference between ground truths and numerical results.
Top to bottom: gxx, gxy, gyy. Relative error=0.0260, time elapsed=4327.5671s.
7 Conclusion
In conclusion, this paper introduces a novel bilevel optimization framework to tackle inverse mean-field games
for learning metrics and obstacles. We also design an alternating gradient descent algorithm to solve the
proposed bilevel problems. The primary advantage of our proposed formulation is its ability to retain the
convexity of the objective function and the linearity of constraints in the forward problem. Focusing on the
inverse mean-field games involving unknown obstacles and metrics, we have achieved numerical stability in
these setups. A significant contribution of our research is establishing unique identifiability in the inverse
crowd motion model with unknown obstacles based on one pair of input and revealing when the solution of the
bilevel problem is stable to the noisy data. Employing an alternating gradient-based optimization algorithm
within our bilevel approach, we ensure its convergence and illustrate its effectiveness through comprehensive
numerical experiments. These experiments serve as robust validation, underscoring the practical applicability
and reliability of our algorithm in resolving inverse problems. Our model and techniques offer a new approach
to understanding and further explorations and application of inverse mean-field games.
References
[1] Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse
problems. SIAM journal on imaging sciences , 2(1):183â€“202, 2009.
[2] Jean-David Benamou and Guillaume Carlier. Augmented lagrangian methods for transport optimiza-
tion, mean-field games and degenerate pdes. 2014.
[3] Jean-David Benamou and Guillaume Carlier. Augmented lagrangian methods for transport optimiza-
tion, mean field games and degenerate elliptic equations. Journal of Optimization Theory and Applica-
tions, 167(1):1â€“26, 2015.
33[4] Antonin Chambolle and Thomas Pock. A first-order primal-dual algorithm for convex problems with
applications to imaging. Journal of mathematical imaging and vision , 40:120â€“145, 2011.
[5] Tianyi Chen, Yuejiao Sun, and Wotao Yin. Closing the gap: Tighter analysis of alternating stochastic
gradient methods for bilevel problems. Advances in Neural Information Processing Systems , 34:25294â€“
25307, 2021.
[6] Yat Tin Chow, Samy Wu Fung, Siting Liu, Levon Nurbekyan, and Stanley Osher. A numerical algorithm
for inverse problem from partial boundary measurement arising from mean field game problem. Inverse
Problems , 39(1):014001, 2022.
[7] Lisang Ding, Wuchen Li, Stanley Osher, and Wotao Yin. A mean field game inverse problem. Journal
of Scientific Computing , 92(1):7, 2022.
[8] Riccardo Grazzi, Luca Franceschi, Massimiliano Pontil, and Saverio Salzo. On the iteration complexity
of hypergradient computation. In International Conference on Machine Learning , pages 3748â€“3758.
PMLR, 2020.
[9] Mingyi Hong, Hoi-To Wai, Zhaoran Wang, and Zhuoran Yang. A two-timescale stochastic algorithm
framework for bilevel optimization: Complexity analysis and application to actor-critic. SIAM Journal
on Optimization , 33(1):147â€“180, 2023.
[10] Minyi Huang, Peter E Caines, and Roland P MalhamÂ´ e. Large-population cost-coupled lqg problems with
nonuniform agents: individual-mass behavior and decentralized Îµ-nash equilibria. IEEE transactions
on automatic control , 52(9):1560â€“1571, 2007.
[11] Minyi Huang, Roland P MalhamÂ´ e, Peter E Caines, et al. Large population stochastic dynamic games:
closed-loop mckean-vlasov systems and the nash certainty equivalence principle. Communications in
Information & Systems , 6(3):221â€“252, 2006.
[12] Oleg Imanuvilov, Hongyu Liu, and Masahiro Yamamoto. Lipschitz stability for determination of states
and inverse source problem for the mean field game equations, 2023.
[13] Kaiyi Ji, Junjie Yang, and Yingbin Liang. Bilevel optimization: Convergence analysis and enhanced
design. In International conference on machine learning , pages 4882â€“4892. PMLR, 2021.
[14] Pushkin Kachroo, Shaurya Agarwal, and Shankar Sastry. Inverse problem for non-viscous mean field
control: Example from traffic. IEEE Transactions on Automatic Control , 61(11):3412â€“3421, 2015.
[15] Michael V Klibanov. Lipschitz stability estimate and uniqueness for a problem for the mean field games
system. arXiv preprint arXiv:2303.03928 , 2023.
[16] Michael V. Klibanov. The mean field games system: Carleman estimates, lipschitz stability and unique-
ness, 2023.
[17] Michael V Klibanov and Yurii Averboukh. Lipschitz stability estimate and uniqueness in the retrospec-
tive analysis for the mean field games system via two carleman estimates, 2023.
[18] Michael V Klibanov and Jingzhi Li. The mean field games system with the lateral cauchy data via
carleman estimates, 2023.
[19] Michael V Klibanov, Jingzhi Li, and Hongyu Liu. Holder stability and uniqueness for the mean field
games system via carleman estimates, 2023.
[20] Jean-Michel Lasry and Pierre-Louis Lions. Mean field games. Japanese journal of mathematics ,
2(1):229â€“260, 2007.
[21] Alex Tong Lin, Samy Wu Fung, Wuchen Li, Levon Nurbekyan, and Stanley J Osher. Apac-net: Alter-
nating the population and agent control via two neural networks to solve high-dimensional stochastic
mean field games. Proc. Natl. Acad. Sci. U.S.A. , 118(31), 2021. e2024713118.
34[22] Hongyu Liu, Chenchen Mou, and Shen Zhang. Inverse problems for mean field games, 2022.
[23] Hongyu Liu and Shen Zhang. On an inverse boundary problem for mean field games, 2022.
[24] Hongyu Liu and Shen Zhang. Simultaneously recovering running cost and hamiltonian in mean field
games system, 2023.
[25] Nicolas Papadakis. Optimal transport for image processing . PhD thesis, 2015.
[26] Nicolas Papadakis, Gabriel PeyrÂ´ e, and Edouard Oudet. Optimal transport with proximal splitting.
SIAM Journal on Imaging Sciences , 7(1):212â€“238, 2014.
[27] Kui Ren, Nathan Soedjak, and Kewei Wang. Unique determination of cost functions in a multipopulation
mean field game model, 2023.
[28] Lars Ruthotto, Stanley J Osher, Wuchen Li, Levon Nurbekyan, and Samy Wu Fung. A machine learning
framework for solving high-dimensional mean field game and mean field control problems. Proceedings
of the National Academy of Sciences , 117(17):9183â€“9193, 2020.
[29] Paul Vicol, Jonathan P Lorraine, Fabian Pedregosa, David Duvenaud, and Roger B Grosse. On implicit
bias in overparameterized bilevel optimization. In International Conference on Machine Learning , pages
22234â€“22259. PMLR, 2022.
[30] Quan Xiao, Han Shen, Wotao Yin, and Tianyi Chen. Alternating projected sgd for equality-constrained
bilevel optimization. In International Conference on Artificial Intelligence and Statistics , pages 987â€“
1023. PMLR, 2023.
[31] Jiajia Yu, Rongjie Lai, Wuchen Li, and Stanley Osher. A fast proximal gradient method and convergence
analysis for dynamic mean field planning, 2023.
35