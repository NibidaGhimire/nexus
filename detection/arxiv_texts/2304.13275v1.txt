FEDERATED LEARNING WITH UNCERTAINTY -BASED CLIENT
CLUSTERING FOR FLEET -WIDEFAULT DIAGNOSIS
Hao Lu
Department of Electrical Engineering
Iowa State University
Ames, IA 50011
hlu1@iastate.edu
Adam Thelen
Department of Mechanical Engineering
Iowa State University
Ames, IA 50011
acthelen@iastate.edu
Olga Fink
Intelligent Maintenance and Operations Systems
EPFL
Lausanne, Switzerland 12309
olga.fink@epfl.ch
Chao Huy
Department of Mechanical Engineering
University of Connecticut
Storrs, CT 01776
chao.hu@uconn.edu
Simon Laﬂamme
Department of Civil, Environmental, and Construction Engineering
Iowa State University
Ames, IA 50011
laflamme@iastate.edu
yIndicates corresponding author. Email: chao.hu@uconn.edu.
ABSTRACT
Operators from various industries have been pushing the adoption of wireless sensing nodes for
industrial monitoring, and such efforts have produced sizeable condition monitoring datasets that
can be used to build diagnosis algorithms capable of warning maintenance engineers of impending
failure or identifying current system health conditions. However, single operators may not have
sufﬁciently large ﬂeets of systems or component units to collect sufﬁcient data to develop data-
driven algorithms. Collecting a satisfactory quantity of fault patterns for safety-critical systems is
particularly difﬁcult due to the rarity of faults. One potential solution to overcome the challenge of
having limited or not sufﬁciently representative datasets is to merge datasets from multiple operators
with the same type of assets. This could provide a feasible approach to ensure datasets are large
enough and representative enough. However, directly sharing data across the company’s borders
yields privacy concerns. Federated learning (FL) has emerged as a promising solution to leverage
datasets from multiple operators to train a decentralized asset fault diagnosis model while maintaining
data conﬁdentiality. However, there are still considerable obstacles to overcome when it comes to
optimizing the federation strategy without leaking sensitive data and addressing the issue of client
dataset heterogeneity. This is particularly prevalent in fault diagnosis applications due to the high
diversity of operating conditions and system conﬁgurations. To address these two challenges, we
propose a novel clustering-based FL algorithm where clients are clustered for federating based on
dataset similarity. To quantify dataset similarity between clients without explicitly sharing data,
each client sets aside a local test dataset and evaluates the other clients’ model prediction accuracy
and uncertainty on this test dataset. Clients are then clustered for FL based on relative prediction
accuracy and uncertainty. Experiments on three bearing fault datasets, two publicly available and
one newly collected for this work, show that our algorithm signiﬁcantly outperforms FedAvg and a
cosine similarity-based algorithm by 5:1%and30:7%on average over the three datasets. Further,arXiv:2304.13275v1  [cs.LG]  26 Apr 2023Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
using a probabilistic classiﬁcation model has the additional advantage of accurately quantifying its
prediction uncertainty, which we show it does exceptionally well.
Keywords federated learningfault diagnosisdeep learninguncertainty quantiﬁcation model bearings
1 Introduction
The increased availability of sensor data from ﬂeets of cloud-connected assets, such as vehicles and manufacturing
facilities, has been driving a transformation in system health monitoring for fault diagnosis. Plant operators and process
engineers are interested in leveraging their data to proactively diagnose faulty equipment and notify maintenance
personnel of impending potential failures so they can schedule accordingly, improving reliability and reducing downtime
costs in the process [ 1,2]. To facilitate this effort, numerous data-driven diagnosis algorithms have been developed,
enabling real-time detection and accurate classiﬁcation of system faults [ 3,4]. Data-driven fault diagnosis methods
rely on machine learning and deep learning models to effectively classify condition monitoring signals that indicate
the system’s health status. Numerous fault diagnosis models have been proposed previously, including artiﬁcial
neural networks [ 5,6,7], random forests [ 8,9], and support vector machines [ 10,11]. In general, the performance
of data-driven diagnosis models is directly related to the quality and quantity of available training data [ 1]. However,
the fault patterns that data-driven models are trained to recognize are often unique to the speciﬁc system they were
collected from and are highly inﬂuenced by the operating conditions. This presents a signiﬁcant challenge to model
development since collecting training data under all possible working conditions is time-consuming and costly, which
impedes the deployment of data-driven diagnosis models to the ﬁeld [ 12]. A potential solution to tackle the challenges
posed by fault rarity and high variability in operating conditions could be to compile data from multiple clients into a
central database for training. Most clients are hesitant to do so because of data privacy concerns and legal regulations
[13]. In turn, there is a great need to develop decentralized machine learning algorithms that maintain data privacy
while providing greater fault classiﬁcation accuracy than asset operators can achieve individually [14].
In 2017, McMahan et al. [ 15] developed the ﬁrst federated learning (FL) strategy for training a centralized deep learning
model to serve multiple clients without explicitly requiring them to share their data, thus preserving privacy. In this
method, each client trains a model locally with its own data and uploads its model parameters to a server. Then, the
server takes a weighted average of each client’s model parameters, where the weights are determined by the size of
the client’s training dataset. This method of model aggregation on the server has since been referred to as federated
averaging (FedAvg). Several researchers have effectively applied FedAvg and similar methods to train fault diagnosis
models [ 16,17,18,19]. Notably, Zhang et al. [ 18] demonstrated a dynamic validation and self-supervised FedAvg
algorithm where the server evaluated local models using a validation dataset to determine which models to neglect
during federation. A follow-up work by Zhang et al. [ 19] introduced blockchain technology to improve the security
of model parameter sharing. While FedAvg has shown promise in cross-client fault diagnosis, challenges arise when
clients’ data are heterogeneous or non-independent and identically distributed (non-IID) [20, 21, 22].
The performance of FL algorithms can be affected by two types of statistical data heterogeneity. The ﬁrst, known
asdomain shift , occurs when clients’ data do not share a similar distribution due to differences in system operating
conditions or system conﬁgurations. The second, referred to as label heterogeneity , occurs when clients’ datasets
have different quantities and types of system faults [ 23]. In most real-world scenarios, clients’ data generally do not
exhibit similar distributions, fault types, and fault prevalence due to the diverse environmental conditions experienced
by systems or components in the ﬁeld (e.g., run-time, load, temperature, and humidity) [ 14]. Unfortunately, large
variations between clients’ datasets have been shown to reduce the training speed and overall accuracy of the FedAvg
algorithm [ 21,24]. One potential solution to deal with domain shift among client’s datasets is to develop a personalized
feature extractor network that extracts fault-related features that are invariant to the different operating conditions and
fault types of the clients (see Fig. 1b) [ 25,26,27]. This approach, referred to as adaptation-based transfer learning,
mitigates the data domain shift using unique model architectures that extract features that are indistinguishable between
different clients. Another approach to deal with domain shift is to group clients for training based on their dataset
similarity, where each group builds a different global model (see Fig. 1c) [ 28,29,30,31]. The key to this approach lies
in the clustering strategy used to group the clients since directly comparing clients’ datasets would violate data privacy.
For example, Tian et al. [ 31] utilized the cosine similarity between each pair of client model parameters to infer the
similarity of client dataset distributions. While both transfer learning and clustering are effective approaches to deal
with client data heterogeneity, numerous distinct challenges speciﬁc to system fault diagnosis must be resolved.
Manuscript submitted to Mechanical Systems and Signal Processing
2Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
Firstly, due to the differences in operating settings and monitoring policies, the frequency of fault types presented in
clients’ datasets can be signiﬁcantly heterogeneous, and some fault types may be completely missing. Few studies have
addressed the challenge of training a model algorithm that can accurately differentiate all labels in scenarios where
speciﬁc labels are missed in certain clients. Second, most studies adopt a deterministic model for machinery health
monitoring. The deterministic models used in those studies are capable of addressing data heterogeneity challenges
under the assumption that the test data follows a similar distribution as the training data. However, in a real-world
application, models may be faced with out-of-distribution samples. Considering that scenario, it is desirable to use
a probabilistic model that can accurately represent its prediction uncertainty and conﬁdence in the prediction results.
Considering the aforementioned requirements, building a cross-client fault diagnosis model that can be deployed
in practice is undoubtedly difﬁcult. To meet the needs of the industry, it is important to use a FL strategy that can
effectively train a fault diagnosis model even when many clients are missing one or more fault types. Furthermore,
the ﬁnal global model distributed to each client should output accurate uncertainty estimates with its fault diagnosis
predictions so that maintenance personnel can appropriately gauge the severity of the situation.
In this work, we develop a dynamic clustering FL algorithm for training an accurate fault diagnosis model even when
clients’ datasets exhibit signiﬁcant label heterogeneity and domain shifts. Different from existing algorithms that use
model parameters or prediction errors to cluster clients, we use a probabilistic deep learning model and leverage its
prediction uncertainty estimates to cluster clients based on inferred dataset similarity. We demonstrate the ability of our
uncertainty-based clustering strategy to assign clients with similar data distributions to the same cluster for training.
We benchmark the fault classiﬁcation performance of our federated learning algorithm (FedSNGP) against FedAvg
and a cosine similarity-based clustering algorithm (FedCos) using two publicly-available bearing fault datasets and
one new bearing fault dataset collected speciﬁcally for this work. In cases where clients’ datasets are heterogeneous in
fault type and exhibit signiﬁcant domain shift (Scenario 2), our FedSNGP algorithm outperforms FedAvg and FedCos.
Further, in cases where clients’ datasets exhibit domain shift and are heterogeneous in fault type as well as the sample
size (Scenario 3), our FedSNGP algorithm demonstrates its prowess, achieving signiﬁcantly higher accuracy than
both FedAvg and FedCos. This ﬁnal scenario highlights the advantage of our self-supervised and uncertainty-aware
clustering algorithm for FL, as it achieves excellent fault classiﬁcation accuracy, even in the most extreme scenarios.
Further, using a probabilistic classiﬁcation model has the added beneﬁt of quantifying its prediction uncertainty to
detect out-of-distribution samples, which we show it does exceptionally well.
2 Preliminaries on FL
2.1 Basics of FL
This study targets industrial scenarios where each operator has its own dataset and shares the same diagnosis task. To
stay consistent with existing literature on federated learning, we refer to operators as clients. FL is a distributed machine
learning approach for training a model using decentralized data from multiple clients without sharing or aggregating
the clients’ datasets on a central server. We begin by deﬁning notations used to describe FL strategies. We denote the
number of clients as Nand denote the ithclient’s local training dataset as: Di= 
xi
j;yi
j	ni
j=1, where each client
hasniinput and output training data pairs, denoted as xi
jandyi
j, respectively. In the traditional centralized model
training approach, the ﬁrst involves aggregating all the client’s data on a single server, followed by optimizing each
client’s model parameters ito minimize the global lossNP
i=1niP
j=1Loss 
i;xi
j;yi
j
. Here,Loss 
i;xi
j;yi
j
represents
the prediction loss of the model for a given input-output pair 
xi
j;yi
j
with respect to the model parameters i.
One simplistic approach is to allow the server to aggregate all of the client datasets and optimize the model parameters
by computing the gradient of the global loss. This implies that the server has complete access to all of the clients’
datasets. However, aggregating sensitive client data on a central server presents privacy and legal concerns and should
be avoided. Instead, FL strategies aim to train a global model or models without sharing data between clients. To
perform FL, as illustrated in Fig. 1a, each client independently optimizes their local model using their own dataset (Step
1) and transmits their model parameters to the server (Step 2). On the server side, model parameters are aggregated
to create one or more global models (Step 3), which are subsequently disseminated to the clients (Step 4). A single
instance of this four-step process is often called a communication round , as it involves the clients communicating with
the server to facilitate training.
The most important step in any FL strategy is the model aggregation (Step 3 in Fig. 1a). Model aggregation leverages
non-sensitive client information (e.g., model parameters and other information the client is willing to share) as part of
an algorithm to update the global model. The model aggregation algorithm directly affects the amount of information
transferred from each client to the ﬁnal model and is crucial to the model’s overall accuracy. The ﬁrst model aggregation
3Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
Figure 1: An illustration of FL ( a) and two FL strategies ( b,c).a, The four-step process of FL is common to nearly all
FL approaches. b, An overview of an adaptation-based approach to FL that uses a global classiﬁer to accommodate
client-speciﬁc feature extractors. c, An overview of a clustering-based approach to FL that groups clients for training
based on non-private comparison criteria.
strategy, proposed by McMahan et al. [ 15], was the FedAvg strategy. The FedAvg method of model aggregation
combines the client’s models by performing a weighted average of model parameters, where the weights are determined
based on the number of training samples each client has. The weighted average model aggregation is deﬁned as follows:
t+1=PN
i=1nii
tPN
i=1ni(1)
The weighted averaging approach to model aggregation used in FedAvg allows clients to employ a collaborative
prediction model that contains additional information beyond what each client had separately. This is because each
client’s model can be regarded as a condensed representation of their data, and constructing a global model by
incorporating the weights of all clients enables the global model to learn each client’s information indirectly. As a result,
this yields an exceptionally accurate model for the clients.
2.2 FL for Non-IID Datasets
Though FedAvg yields decent performance in most scenarios, a major challenge of the FedAvg approach is that its
performance decreases signiﬁcantly when the clients’ data are vastly different from one another, i.e., non-IID and
heterogeneous in fault types [ 12,21]. Large differences in local dataset distributions (often referred to as domain
shifts) cause some clients’ model parameters to deviate signiﬁcantly from those of the group. Including information
models from clients with signiﬁcantly different dataset distributions can negatively impact the global model aggregation
process, causing the ﬁnal global model to serve neither the majority of clients with similar data nor the minority clients
with outlier data well. Numerous algorithms have been developed to tackle the challenge of data heterogeneity when
deploying a FL strategy for a ﬂeet of system or component units. This section introduces two of the most common
methods for dealing with non-IID datasets and highlights notable research in this area.
2.2.1 Adaptation-based Approaches to FL
The challenge of data domain shift has been widely recognized in the ﬁeld of deep learning [ 32]. One common method
of dealing with data domain shift in traditional deep learning settings is known as adaptation-based learning [ 33,23].
There are different domain adaptation approaches. One way is to train a feature extractor that extracts domain-invariant
features from the input data. Then, feed the domain invariant features to a classiﬁer for prediction.
The same domain adaptation approach can be applied to the FL problem. In adaptation-based FL, shown in Fig.
1b, theithclient’s model is divided into a personalized feature extractor 'iand a shared global classiﬁer hi[27,23].
The personalized feature extractor learns to map the raw input data into a low-dimensional feature space such that
the learned mapping is invariant to the system’s operating conditions. Then, the shared classiﬁer takes the extracted
4Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
domain-invariant features as input to diagnose the system’s health. Mathematically, this optimization process can be
written as follows:
argmin
'1;'2;:::;' N;hgNX
i=1niX
j=1Loss 
'ihg;Xi
j;yi
j
+NX
i=1NX
j=1;j6=iDis(zi;zj) (2)
whereLoss 
'ihg;Xi
j;yi
j
denotes theithmodel’s prediction loss towards the local training dataset, zidenotes the
clienti’s extracted features, and Dis()is the metric of discrepancy of two distributions.
Training a personalized feature extractor can be achieved by introducing a domain classiﬁer into the model architecture
[27] or introducing the maximum mean discrepancy distance into the loss function [ 34]. In the context of an FL
framework where new clients may join, researchers in [ 34] developed a dynamic weighted averaging algorithm. In
the model aggregation step, the algorithm evaluates the maximum mean discrepancy between features extracted from
source domain models and the target domain model. A smaller discrepancy implies that there is less domain discrepancy
between two clients and should contribute more to the training of the target domain model. The algorithm alleviates
domain discrepancy by assigning higher weights to models that can extract similar features in the source and target
domains.
While domain adaptation algorithms are a popular solution for dealing with data domain shifts, their main limitation is
their lack of ﬂexibility to changes in future operating conditions. Domain adaptation algorithms build personalized
feature extractors for each client (target domain) and assume that the data distribution and operating conditions will not
change with time. If any aspect of the system changes, the input data will shift, and the personalized feature extractor
cannot be trusted to accurately map the new inputs into domain-invariant features. To alleviate this challenge, test-time
adaptation algorithms have been developed. Regardless, domain adaptation algorithms remain promising to deal with
domain shifts in FL environments.
2.2.2 Clustering-based Approaches to FL
Research conducted in [ 13,18] has highlighted that in non-IID FL scenarios, certain clients should be disregarded
or assigned lower weights during model aggregation to prevent the transfer of low-quality knowledge to the global
model. During each training communication round of clustering-based FL, the server performs client clustering that
assigns clients with comparable data distributions to the same cluster, whereby the clients in the same cluster share the
same model parameters. The optimization target of the clustering strategy and model parameter optimization can be
formulated as:
minimize
C1;C2;:::C k1
NKX
k=1NX
i=1ri;kniX
j=1Loss 
Ck;Xi
j;yi
j
subject tori;k=argmin
ri;k1
NKX
k=1NX
i=1ri;kDi 
k(3)
WhereCkdenotes the model parameters of the clients in kthcluster,ri;kdenotes the resulting client clustering with
ri;k= 1if clienti2clusterk, otherwiseri;k= 0. TheDidenotes client dataset distribution, and 
krepresents the
data distribution center for cluster k. It is important to note that in order to maintain data privacy, the server must
indirectly deduce dataset similarity ( kDi 
kk).
The key to clustering-based FL algorithms is to estimate the dataset similarity between each pair of clients without
accessing the client’s dataset. Researchers in [ 31] developed a similarity-based clustering approach that used the cosine
distance between models’ parameters to estimate their dataset similarity and determine if they should be clustered
together for training. In this approach, clients with identical or highly similar dataset distributions are clustered together
for each FL communication round. In a similar line of research, Li et al. [29] proposed a soft clustering algorithm that
can assign clients to overlapped clusters. In this way, each client’s information is fully utilized.
There is currently limited research that focuses on employing clustering-based algorithms for FL in the context of
system fault diagnosis. Researchers in [ 35] developed a clustering-based algorithm where each client performs a
GridSearchCV method to tune their model hyperparameters. Then during model aggregation, the clients that share
similar hyperparameters are clustered into the same group to get updated models. Researchers in [ 28] proposed a
multi-center clustering-based FL algorithm. They used a k-means-based algorithm to cluster clients. However, the
drawback of this approach is that it requires specifying the number of clusters in advance, which can signiﬁcantly affect
performance.
5Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
For clustering-based FL algorithms, the clustering strategy plays a crucial role in determining the algorithm’s perfor-
mance. If a client is allocated to an unsuitable cluster, the resulting global model may perform worse than the more
basic algorithms, like FedAvg, that incorporate all models in the federation process regardless of data domain shift and
label heterogeneity. Altogether, domain-adaptation and clustering-based approaches have been shown to be effective
solutions to the challenge of domain shift and label heterogeneity in FL. However, little work has been done to apply
these methods in the ﬁeld of system fault diagnosis.
3 Proposed FL Method
Our approach to FL differs from existing clustering-based FL approaches in two important ways: Firstly, we incorporate
a distance-aware model into the FL framework, which enables us to use the prediction uncertainty to infer the dataset
similarity and group clients into clusters. The distance-aware model we employ in the proposed FL approach has a
unique capability of detecting out-of-distribution input samples, thus preventing the model from making overconﬁdent
predictions. Secondly, we use a clustering algorithm that can determine the number of clusters without requiring
user-deﬁned parameters. The number of clusters is dynamically adjusted by the clustering algorithm during each
communication round based on the dataset similarity inferred by the distance-aware model. This ensures that the client
grouping is optimized to achieve the maximum information transfer to the global model without the need for predeﬁning
the number of clusters. Our algorithm is designed to work well under a wide range of dataset conditions with various
levels of domain shift and missing fault types.
Shown in Fig. 2, our FL training strategy consists of four steps:
1.Local model training: each client trains its own model using its dataset and uploads model parameters to the
server.
2.Estimation of dataset similarity: each client downloads the models of other clients from the server and estimates
the prediction uncertainty of downloaded models towards its dataset to infer distribution similarity between
each pair of client datasets.
3.Model clustering and aggregation: the server forms a similarity matrix based on the estimated dataset similarity,
uses an unsupervised clustering algorithm to group the clients into clusters, and performs model aggregation
within each cluster.
4.Model dissemination to the clients: the server sends the updated global model back to the clients for further
local training.
Figure 2: An illustration of the FedSNGP training process. Each training communication round has four key steps: 1)
local model training, 2) dataset similarity estimation, 3) local model clustering for training, and 4) model dissemination
to the clients.
In what follows, we describe our uncertainty-aware deep learning model and our dynamic clustering algorithm for FL.
6Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
3.1 Uncertainty-Aware Model Training at Local Clients
Deploying a deep learning model in the ﬁeld requires building conﬁdence among operators and maintenance personnel
regarding the model’s diagnostic accuracy. At a minimum, the model should indicate higher predictive uncertainty
to operators when it lacks conﬁdence in a prediction. This is particularly important for safety-critical equipment, as
an incorrect diagnosis can result in catastrophic failures, putting people and equipment at risk. For this reason, it is
essential to build a fault diagnosis model that can accurately estimate its prediction uncertainty. Moreover, we believe
that the uncertainty estimates can be leveraged to improve the performance of our FL approach.
Real-world fault diagnosis is prone to challenges such as domain shifts caused by changes in environmental or operating
conditions or other factors. With a slight shift in input distribution, a vanilla machine learning model may yield
overconﬁdent prediction results for these samples, misleading operators and wasting time. To tackle this problem, it is
desirable to develop an algorithm that can infer when new data exhibit domain shift or unknown fault type with respect
to the training dataset. The larger the discrepancy between the new sample and the model’s training data, the higher the
model’s prediction uncertainty should be. To accomplish this, we employ a distinctive model architecture that enables
the model to identify input samples that differ signiﬁcantly from the data it was trained on and consequently increase its
uncertainty estimate.
The ability of the model to detect the difference between new samples and the training dataset is referred to as ‘distance
awareness’ [ 36]. Given a deep learning model logit (x) =gh(x), wheregrepresents the model output layer and
h()denotes the mapping function that maps the raw input into a hidden representation space, a deep learning model is
input distance aware if it follows two conditions:
1.The model’s mapping function is distance-preserving. Considering the distance in the data manifoldx x0
X, the distance in the hidden spaceh(x) h
x0
Hneeds to satisfy the following bi-Lipschitz
condition:
L1x x0
Xh(x) h
x0
HL2x x0
X;0<L 1<L 2 (4)
2.The model’s output layer is distance aware. The output layer gshould output an uncertainty metric that reﬂects
distance in the hidden spaceh(x) h
x0
H. The standard Gaussian process machine learning model
exhibits this property. However, Gaussian processes are unsuitable for high-dimensional problems and large
datasets because the inference is extremely computationally expensive (O(n3))[37].
To address the above-mentioned conditions, Liu et. al [ 36] proposed a model architecture known as the Spectral-
normalized Neural Gaussian Process (SNGP). The SNGP is formed by residual blocks equipped with spectral normal-
ization to ensure that the hidden mapping h()is distance preserving. For the model’s output layer, the dense layer is
replaced with an approximate Gaussian process conditioned on the learned hidden representations of the model. The
SNGP adopts random feature expansion to convert the inﬁnite-dimensional Gaussian process into a featured Bayesian
linear model and uses Laplace approximation to approximate the posterior. The output layer is designed with ﬁxed
hidden weights wLand trainable output weights , given as:
g(h) =r
2
DLcos( wLh+bL)|;with prior DL1N(0;IDLDL) (5)
where hdenotes the output features of the penultimate layer with dimension DL 1,wLis a ﬁxed weight matrix with
dimensionDLDL 1whose entries are sampled i.i.d. from N(0;1).bLis a ﬁxed bias term with dimension
DL1whose entries are sampled i.i.d. from Uniform (0;). Conditional on h,is the only trainable variable in the
output layer. For K-class classiﬁcation, the Laplace method is applied to approximate the posterior for each class as
[36]:
p(kjD)MVN
^k;^k=^Hk 1
;where ^Hk=NX
i=1pi;k(1 pi;k) i|
i+I (6)
and^kis the model’s maximum a posteriori probability estimate conditioned on the random Fourier hidden representa-
tion,pi;k= 1=(1 +e |
i^k), and i=q
2
DLcos( wLh(xi) +bL).
Training the SNGP model can be performed using stochastic gradient descent:
 logp
;fwl;blgL 1
l=1jD
= logp
Dj;fwl;blgL 1
l=1
+1
2kk2(7)
7Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
where logp
Dj;fwl;blgL 1
l=1
is the cross-entropy loss for the classiﬁcation task. The pseudo-code of the
training and test procedure of the SNGP model is summarized in Algorithms 1 and 2 . Each client trains a local model
using the local dataset and uploads the model to the server.
Algorithm 1 Local training of SNGP
1:Inputs:
Local training dataset Di=/braceleftig/parenleftig
xi
j, yi
j/parenrightig/bracerightigni
j=1
2:Initialize:
ˆΣk=I,wL∼N(0,1),bL∼U(0,2π)
3:forNumber training = 1 to Max iteration do
4: SGD update β,{wl}L−1
l=1,{bl}L−1
l=1
5: iffinal epoch then
6: Update precision matrix ˆH
7: end if
8:end for
9:Compute posterior covariance ˆH−1
Algorithm 2 SNGP prediction
1:Inputs:
Test sample x
2:Initialize:
SNGP model/braceleftig
β,{wl,bl}L−1
l=1,ˆH−1/bracerightig
3:Compute Features:
ΦDL×1=/radicalig
2
DL∗cos(−wLh(xi) +bL)
4:Compute Posterior Mean:
logit(x)= Φ⊺β
5:Compute posterior variance:
var(x)= Φ⊺ˆH−1Φ
6:Evaluate predictive posterior distribution:
Softmax/parenleftbigg
Φ⊺β√
1+λ∗Φ⊺ˆH−1Φ/parenrightbigg
1
Figure 3: Pseudo-code of the training and prediction process of the SNGP model
3.2 Dataset Similarity Estimation for Federated Clustering
When dealing with client datasets that are heterogeneous, the typical methods of FL strategies may result in suboptimal
performance. One way to alleviate the negative impact caused by data heterogeneity is to cluster clients [ 38]. Clustering-
based FL algorithms group clients into clusters based on their dataset similarity. The SNGP model is capable of
inferring the distance between the training dataset and test samples. Therefore, SNGP model can be adopted to infer
the similarity between the datasets of two clients. The FedSNGP algorithm involves uploading the locally trained
model from each client to the server after training. Following this, the clients work together to estimate the similarities
between their datasets.
As the SNGP model is distance aware, the model’s prediction result reﬂects the similarity between the test sample
and the training datasets. To infer client dataset similarity, each client downloads other clients’ models and evaluates
other models’ prediction results against the local training dataset. The SNGP modeln
;fwl;blgL 1
l=1;^H 1o
maps the
inputxinto random Fourier feature  =q
2
DLcos(wLh(x) +bL), and the output posterior predictive probability
for each class follows MVN
|k;|^H 1
k
, the expectation of the probability can be approximated by using the
8Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
mean-ﬁeld method:
E(p(x))Softmax0
@|kq
1 +|^Hk 11
A (8)
whereis a scaling factor that is commonly set to =8[36,39]. Then, in this study, the predicted variance is used to
infer model uncertainty:
Pvar1
niniX
i=1var(p(xi)) =1
niniX
i=1E 
p 
x2
i
 (E(p(xi)))2(9)
The predicted variance reﬂects the distance between a model’s training and test datasets, where higher variance indicates
a higher difference between two datasets. In the proposed FedSNGP approach, each client downloads all the local
models and evaluates those models using its local training dataset. Then, the predicted variance results are uploaded
to the server and are used for clustering. The predicted variance is used to form a 2D matrix, where the entry in ith
row,jthcolumn is the predicted variance from evaluating the jthmodel using the ithclient’s dataset. After performing
column-wise normalization, the results form a prediction uncertainty matrix with the range [0;1], with dimension
NclientNclient , denoted as MU.
In the next step, the afﬁnity propagation algorithm [ 40] is used to automatically determine the number of clusters.
Unlike the k-means clustering algorithm, afﬁnity propagation does not require the user to specify the number of clusters
in advance. Instead, it automatically determines a suitable number of clusters. We create a similarity matrix MSimby
calculating 1 MU. The similarity matrix represents the similarity between clients’ datasets, where values close to 0
indicate high prediction uncertainty and suggest that the jthclient’s dataset differs signiﬁcantly from the ithclient’s
dataset, and the clients would not beneﬁt from federating together. The afﬁnity propagation takes the similarity matrix
as input and outputs the clustering strategy for model aggregation. The clustering strategy takes place remotely on the
central server. The algorithm describing this process is summarized in Algorithm 3 .
Algorithm 3 FedSNGP
1:Initialize:
Model parameters for all clients∼
θ0
2:forCommunication round t= 1 to Max number of training round do
3: Initialize prediction variance matrix M sim=Zeros (n, n)
4: Receive local updates:∼
θ1
t,∼
θ2
t, . . . ,∼
θn
t
5: forLocal client i∈ {1,2, . . . , n }do
6: forLocal dataset j∈ {1,2, . . . , n }do
7: Modelj←∼
θj
t
8: Calculate M sim(i, j) by using Modelj’s predictive
9: uncertainty towards Di
10: Clustering List=AffinityPropagation( Msim)
11: end for
12: end for
13: Aggregate mode based on the Clustering List
14: Update local model parameters∼
θ1
t+1,∼
θ2
t+1, . . . ,∼
θn
t+1
15:end for
2
Figure 4: Pseudo-code of FedSNGP algorithm
4 Training and Test Conﬁguration
4.1 Selected Datasets
We evaluate the performance of the proposed algorithm on three bearing fault diagnosis case studies to demonstrate
the effectiveness of the FedSNGP algorithm. A summary of three case studies is given in Table 1. Each bearing
dataset contains vibration signals collected from rolling element bearings with distinct health conditions under various
operating conditions. To simulate the FL scenario, the dataset is partitioned into 12 subsets, and each subset is allocated
9Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
to a client. The objective of each client is to train a fault diagnosis model capable of accurately identifying the health
condition of bearings. The selected bearing datasets chosen for this task are as follows:
1.Case Western Reserve University (CWRU) dataset [ 41]: Case study 1 uses the Case Western Reserve University
(CWRU) bearing dataset, which is widely used as a standard reference in the bearing diagnosis ﬁeld. The data was
collected with a 12 kHz sampling frequency under four working conditions. The bearing faults were introduced by
using electro-discharge machining. Three manual fault sizes were created, with diameters of 0.007, 0.014, and 0.021
inches. Considering that outer race and inner race faults are more frequently appeared in accelerated degradation
tests, we use the healthy, inner race fault, and outer race fault bearings. For each type of fault, the bearings with fault
diameters of 0.007 and 0.014 inches are selected.
2.Paderborn University (PU) dataset [ 42]: Case study 2 uses an experimental dataset collected by the KAT data center
in Paderborn University (PU). The PU dataset contains high-resolution vibration data, which are collected from six
healthy bearings and 26 damaged bearings under four working conditions. The sampling frequency is 64kHz. Out of
the 26 damaged bearing sets, 12 bearings were artiﬁcially damaged, and the other 14 were damaged by accelerated
lifetime test. Bearings that undergo accelerated lifetime testing are selected in this case study. In total, bearings with
three different health conditions (healthy, inner race fault, and outer race fault) are included, with three bearings for
each health condition.
3.Iowa State University (ISU) dataset: An experimental dataset is collected from a machinery fault simulator in our
lab at Iowa State University, denoted as the ISU dataset. The ISU dataset was collected with a 25.6 kHz sampling
frequency from four bearings under four working conditions. The bearing faults were introduced by electrical
discharge machining, where the size of each fault is approximately 1.5 mm ×1.0 mm ×0.1 mm. Four health
conditions are considered: healthy, inner race fault, outer race fault, and a combination of faults.
Table 1: Summary of selected bearing datasets
Name Bearing health conditionsCause of
bearing faultSampling
frequencyNotes
CWRUWorking condition
IDShaft
speedBearing fault
diameter
Healthy, Inner race fault,
Outer race faultElectric
engraver12 kHz1 1797 rpm 0.007"
2 1797 rpm 0.014"
3 1772 rpm 0.007"
4 1772 rpm 0.014"
5 1730 rpm 0.007"
6 1730 rpm 0.014"
PUWorking condition
IDShaft
speedLoad
torqueRadial
force
Healthy, Inner race fault,
Outer race faultAccelerated
degradation64 kHz1 1500 rpm 0.7 Nm 1000 N
2 900 rpm 0.7 Nm 1000 N
3 1500 rpm 0.1 Nm 1000 N
4 1500 rpm 0.7 Nm 400 N
ISUWorking condition
IDShaft
speedRadial
force
Healthy, Inner race fault,
Outer race fault,
Combination of bearing faultsElectric
engraver25.6 kHz1 2100 rpm 0
2 2100 rpm 25 N
3 1500 rpm 0
4 1500 rpm 25 N
The above-mentioned datasets were collected under different sampling rates and different sampling times. We ﬁrst
resample vibration signals with sampling frequency = 12.8 kHz. Then split each signal into multiple vibration samples.
The length of each sample is equal to 1024 points and is equivalent to 0.08 seconds of data. Frequency domain analysis
has been widely applied in vibration-based bearing diagnosis [ 6,43]. In this study, we apply the fast Fourier transform
to acquire the single-sided output of the signal power spectrum. After signal processing, each time domain signal is
converted into a frequency domain feature, with length = 512. After dataset processing, 80 % of the total dataset is used
to form training datasets, while the remainder is used for testing.
4.2 Design of the FL Scenarios
To demonstrate the impact of dataset heterogeneity, we considered three FL scenarios in which each client’s dataset is
collected under different working conditions. Moreover, due to the rareness of faults in complex industrial equipment,
10Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
each client may not be able to observe every possible fault under all possible operating conditions. In the domain
adaptation problem, the partial domain adaptation (DA) scenario was deﬁned by making the source domain have all
classes of data and the target domain cover only a subset of those classes [ 44]. We extend this deﬁnition to FL scenarios
where certain clients’ datasets contain a subset of all classes. For consistency and simpliﬁcation, such scenarios are
also denoted as partial DA. The training datasets under scenarios 1 and 2 are deﬁned using the partial DA setting with
domain shift. Speciﬁcally for Scenario 3, we drastically varied the number of samples in each client’s dataset to make
the problem more difﬁcult.
Figure 5: An illustration of the three test conditions examined in this paper.
Fig. 5 shows the three FL scenarios considered in this work. In scenario 1, client datasets are collected under different
working conditions, and differences exist in each client’s label space (partial DA setting). For example, some clients
might only have healthy and inner race fault samples, while other clients might have healthy and outer race fault
samples. Under Scenario 1, each client’s evaluation dataset follows a similar distribution as the training dataset (the
types of test data are identical to the training dataset).
The training datasets in scenario 2 are identical to the settings in scenario 1. However, different from scenario 1, the
test datasets are label-balanced datasets, which means clients need to collaborate to train a model that is capable of
identifying unknown fault types.
Finally, for scenario 3, in addition to the feature distribution shift caused by different working conditions, the clients’
datasets follow the partial DA setting with data quantity heterogeneity. The prediction difﬁculties are increased from
scenario 1 to scenario 3.
Three test scenarios are designed for each case study. We ﬁrst divide each dataset into several subsets, where each
subset contains data collected under the same operating condition. Then for each subset, we further divide the subset
dataset into several client local datasets. Table 2 shows how the client training datasets are designed for each dataset
case study.
For the CWRU dataset, we deﬁne six operating conditions, and 62 = 12 client datasets are created, each containing
data related to two particular health conditions. Under this setting, the clients need to work together to train a model
that is capable of classifying three health conditions. For the PU dataset, 43 = 12 client datasets are created. Clients
1,4,7 and 10 contain three types of training samples, while others only own two types of samples. The ISU dataset is
also divided into 12 client datasets.
11Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
In scenarios 1 and 2, all the training datasets are utilized to generate client training datasets, and in scenario 3, some
clients are assigned a portion of the total data to create the client-wise quantiﬁed discrepancy. The detailed description
of the dataset design is listed in the appendix tables 6 and 6.
Table 2: Design of each client dataset for scenarios 1 and 2
Dataset Number of samples
CWRUClient ID Operating condition HealthyInner race
faultOuter race
fault
1 Shaft speed = 1797 rpm
Fault diameter = 0.007”80 80 0
2 80 0 80
3 Shaft speed = 1797 rpm
Fault diameter = 0.014”80 80 0
4 80 0 80
5 Shaft speed = 1772 rpm
Fault diameter = 0.007”80 80 0
6 80 0 80
7 Shaft speed = 1772 rpm
Fault diameter = 0.014”80 80 0
8 80 0 80
9 Shaft speed = 1730 rpm
Fault diameter = 0.007”80 80 0
10 80 0 80
11 Shaft speed = 1730 rpm
Fault diameter = 0.014”80 80 0
12 80 0 80
PUClient ID Operating condition HealthyInner race
faultOuter race
fault
1 Shaft speed = 1500 rpm
Load torque = 0.7 Nm
Radial force = 1000 N1200 1200 1200
2 1200 1200 0
3 1200 0 1200
4 Shaft speed = 900 rpm
Load torque = 0.7 Nm
Radial force = 1000 N1200 1200 1200
5 1200 1200 0
6 1200 0 1200
7 Shaft speed = 1500 rpm
Load torque = 0.1 Nm
Radial force = 1000 N1200 1200 1200
8 1200 1200 0
9 1200 0 1200
10 Shaft speed = 1500 rpm
Load torque = 0.7 Nm
Radial force = 400N1200 1200 1200
11 1200 1200 0
12 1200 0 1200
ISUClient ID Operating condition HealthyInner race
faultOuter race
faultCombination
of faults
1Shaft speed = 2100 rpm
Radial force = 02000 2000 0 0
2 2000 0 2000 0
3 2000 0 0 2000
4Shaft speed = 2100 rpm
Radial force = 25 N2000 2000 0 0
5 2000 0 2000 0
6 2000 0 0 2000
7Shaft speed = 1500 rpm
Radial force = 02000 2000 0 0
8 2000 0 2000 0
9 2000 0 0 2000
10Shaft speed = 1500 rpm
Radial force = 25 N2000 2000 0 0
11 2000 0 2000 0
12 2000 0 0 2000
4.3 Alternative FL Algorithms Used for Comparison
The FedAvg [ 15] and a cosine-similarity-based clustering algorithm are included as comparison models. In section 5,
we compare the performance of the proposed FedSNGP against those two algorithms.
12Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
aStandard Locally-Trained Fault Diagnosis Models To highlight the beneﬁt of performing FL, we include the
algorithm where each client updates their respective model parameters without FL. In the local training algorithm,
each client trains the model for 250 epochs with a learning rate of 0.005.
bFederated Averaging We use the federated averaging algorithm as a baseline model. As a widely recognized FL
algorithm, FedAvg performs weighted averaging to aggregate all the client’s parameters. The training procedure of
FedAvg is given in Fig 1 a.
cFederated Clustering Using Cosine Similarity The cosine similarity has been widely utilized in clustering-based
FL [31,23]. This study includs a clustering-based algorithm as a comparison model, denoted as FedCos. The
FedCos algorithm differs from the FedSNGP in that it determines the clustering strategy by evaluating the cosine
similarity between the parameters of local models instead of utilizing prediction uncertainty results. Given two local
model parameters iandj, the cosine similarity between the two models is deﬁned as:
Sim Cos(i;j) =ij
kikkjk(10)
The cosine similarity metric measures the angle between iandj, a smaller angle indicates a higher similarity
between iandj. Similar to the FedSNGP algorithm, each communication round of the FedCos algorithm is
composed of four steps:
(a) Each client trains a local model individually and uploads the model to the server.
(b)The server evaluates the cosine similarity between the parameters of local models and generates a similarity
matrixMSim.
(c)The afﬁnity propagation algorithm is applied to determine the clustering strategy and generate an updated
global model for each cluster by using Eqn. 1.
(d) Each client downloads the updated global model from the server.
The key difference between FedAvg, FedCos, and FedSNGP is the server’s model aggregation algorithm. Therefore, in
this study, all the clients utilize the same SNGP model architecture for their models, and the processed features are a 1D
array with a length of 512. The SNGP model is designed with three residual blocks, and each residual block contains
one fully connected layer with 64 units. The models in this study are trained using FL algorithms for a total of 50
communication rounds. In each communication round, each client performs local model updates for a period of ﬁve
epochs with a ﬁxed learning rate of 0.005.
5 Results and Discussion
5.1 Evaluation Results
Each of the 12 clients in the FL process undertakes their own diagnostic task, resulting in a total of 12 tasks for each test
scenario. To evaluate the performance of the algorithms, we begin by examining the average test accuracy across all 12
clients. The average test accuracies are summarized in Table 3, and the detailed results are listed in Appendix. Table 6
In scenario 1, each client’s training and test data follow a similar distribution. The model training and test are conducted
using samples that have the same types of bearing faults. The performance of FedAvg is worse than the other three
methods, which is caused by the heterogeneity of the dataset. Still, all four algorithms achieved a test accuracy of more
than 95% for all three case studies.
Table 3: Summarization of average test accuracy for each case study
MethodsScenario 1 Scenario 2 Scenario 3
CWRU PU ISU CWRU PU ISU CWRU PU ISU
Local training 99.58 99.93 100.00 75.69 77.72 50.11 70.56 71.33 45.76
FedAvg 99.37 98.31 98.80 99.16 98.14 98.20 89.17 97.67 92.80
FedCos 99.79 99.47 99.92 99.72 80.06 50.00 72.63 80.39 49.98
FedSNGP 99.58 99.90 100.00 99.44 99.92 100.00 95.56 99.81 99.66
Compared to scenario 1, scenarios 2 and 3 are more challenging, several clients have unbalanced training datasets, and
the test dataset covers all the fault types. Clients need to acquire diagnosis knowledge from each other. Otherwise, it can
not identify unknown fault types. Therefore, the performance of the local training algorithm experienced a signiﬁcant
decline. The following two subsections discuss the algorithms’ performance in scenarios 2 and 3.
13Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
5.1.1 Scenario 2 Case Studies
Figure 6: The prediction results for scenario 2 case studies. The bar charts show the average test accuracy of each
algorithm, and the radar chart shows the algorithms’ prediction accuracy for each client.
Figure 6 shows the prediction results for scenario 2. The top half of the ﬁgure summarizes the average test accuracy.
And the bottom half of the ﬁgure shows the speciﬁc diagnosis accuracy for each client.
As a benchmark bearing dataset, the fault pattern of the CWRU dataset is obvious, the change in working conditions
does not lead to a signiﬁcant domain shift, and the fault patterns can be identiﬁed easily. Considering that the feature
distribution discrepancy is not severe in scenario 2, the FL algorithms successfully utilize the client’s information, and
both FedAvg, FedCos, and FedSNGP achieved a test accuracy of more than 95%. As a comparison, the locally trained
client models can not identify unknown fault types. Resulting in an accuracy of around 75%.
For the PU dataset case study, the local datasets of clients 1, 4, 7, and 10 contain all the health conditions. That
information is sufﬁcient to train highly accurate diagnosis models. Therefore, the local training algorithm achieves
a testing accuracy of around 100% for those four clients. On the other hand, the remaining eight client datasets
were restricted to only one health and one faulty condition, preventing the client from training an accurate model
independently without the knowledge of the missing fault types. As a result, the locally trained models for those eight
clients were unable to effectively diagnose fault types that were not present in their respective training datasets. As a
benchmark FL algorithm, FedAvg aggregates all the client’s information by performing weighted averages to local
models’ parameters. Most of the models trained by FedAvg achieve an accuracy of more than 95%, and clients 4,5,6
yield a 94.00 % accuracy. This decline in performance is attributed to the domain discrepancy among clients, primarily
due to the variance in working conditions. The average accuracy of FedCos is 80.1%, which is slightly higher than the
one of the local training method (77.7%). Based on the radar chart analysis, the performance of FedCos models was
inferior to that of FedAvg models. The models trained by FedCos yield 100% accuracy on clients 1 and 7, and for other
clients, the model’s accuracy is around 2=3. This is mainly because FedCos is not able to accurately cluster the clients.
The FedSNGP models achieved almost 100% accuracy for all the clients. Finally, the ISU dataset case study shows that
the proposed FedSNGP outperforms the other three methods.
14Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
5.1.2 Scenario 3 Case Studies
Figure 7: The prediction results for scenario 3 case studies. The bar charts show the average test accuracy of each
algorithm, and the radar chart shows the algorithms’ prediction accuracy for each client.
In addition to domain shifts and partial DA setting, scenario 3 also considers differences in the number of training
samples. In this scenario, some clients may possess a larger number of samples, while others may have only a limited
number of samples. Previous studies have indicated that unbalanced training sample quantities can have a signiﬁcant
impact on the performance of the FedAvg algorithm [ 23]. The evaluation results for scenario 3 case studies are
summarized in Fig 6. The feature distribution and sample quantity discrepancy make diagnosis tasks more challenging
than scenario 2. As a result of the varying numbers of training samples held by each client, the training dataset exhibits
more pronounced Non-IID properties, resulting in the performance decline of FedAvg and FedCos models. However,
the introduction of training sample number discrepancy does not affect the performance of the proposed FedSNGP. In
all three case studies within scenario 3, models trained using FedSNGP outperformed those trained using other methods,
achieving average prediction accuracies higher than 95%.
5.2 Analysis of the Clustering Strategy
Unlike FedAvg, which creates a single global model for all the clients, clustering-based FL algorithms assign clients
to multiple clusters. Then, the clients in each cluster are federated together to train a global model. Several cosine
similarity-based clustering FL algorithms have been developed [ 31,29]. This study considers both domain shift and
partial DA setup. It is surprising that the FedCos algorithm does not show any improvement compared to FedAvg. In
this section, we use the PU case study (scenario 2) to compare the clustering strategy of FedSNGP and FedCos and
analyze why FedCos performs worse than FedSNGP.
The PU dataset was collected under four working conditions, with each working condition forming a subset. Fig 8
visualizes the distribution of the average amplitude of the samples. It has been acknowledged that the shaft speed affects
the bearing fault characteristic frequencies, and the change of shaft speed affects the vibration amplitude a lot. The
subset B data (marked by blue shade) was collected under 900 rpm, which is signiﬁcantly different from the other three
subsets. The kernel density estimation results also infer that the feature distribution of subset B is signiﬁcantly different
from the other three subsets. For the remaining three subsets, their healthy samples seem to follow a similar distribution.
The feature distributions of outer race and inner race fault samples suggest that data in subset D differs slightly from
the other two subsets. Based on the kernel density estimation analysis, it appears that subsets A and C have similar
data distributions, while subset D has some differences from subsets A and C. Subset B, on the other hand, is notably
different from the other subsets. A desired clustering strategy needs to make sure that: a) the clients in the same subset
(which means the client datasets were collected under the same working condition) should be grouped together; and
b) if two subset features share similar distribution, then those two subsets should be grouped together. Following this
15Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
Figure 8: Kernel density estimations of datasets by calculating the average amplitude of input features (sorted by
different labels)
assumption, the optimal clustering result for the PU case study should result in three clusters: client 1, client 2, client 3,
client 7, client 8, client 9,client 3, client 4, client 5, and client 10, client 11, client 12.
Fig. 9. shows the dynamic changes in clustering results provided by FedCos and FedSNGP in the different communica-
tion rounds. In the ﬁrst communication round, since the models are still in the early training stage, both FedCos and
FedSNGP can not group clients correctly. As the number of communication rounds increased, each client model started
to capture the distribution of its training dataset. FedSNGP assigns clients into three clusters. The subsets A and C form
one cluster, while B and subset D clients form two clusters. On the contrary, the FedCos fails to group clients from the
same subset into the same cluster. The incorrect clustering strategy employed by FedCos resulted in a decrease in the
model’s performance.
Fig 10 shows the dynamic changes of the similarity matrix provided by FedCos and FedSNGP in each communication
round. Each entry shows the calculated similarities between the two models. The darker blue indicates a higher similarity
between the two clients. It should be noted that while FedCos and FedSNGP utilize the same model architecture, they
use different metrics to infer data distribution similarity. FedCos estimates the similarity by comparing the model
parameters. In the initial communication round, since each client model is initialized with the same parameters and
has undergone only ﬁve local training epochs, the cosine similarity matrix between each pair of clients exhibits large
values. After the second communication round, it is still difﬁcult to determine if any two local models are signiﬁcantly
different. After the communication round 10, the results start to indicate high similarities between certain client models.
However, due to the severe distribution discrepancy among clients, some clients are optimized in different directions.
More importantly, within each communication round, the server clusters clients based on the model parameters, and the
model aggregation process affects the updated model parameters. In case a client is assigned to an inappropriate cluster,
it becomes challenging for the algorithm to rectify the mistake and assign the client to the correct cluster. As a result, the
MSimgenerated by FedCos does not necessarily reﬂect the dataset similarity, and the algorithm does not assign clients
of the same subset to the same cluster. For example, we expect the models of clients 1, 2, 3, 7, 8, and 9 to show a higher
similarity because those three clients collect data under the same working condition (subset A). However, according to
the entries of the ﬁrst row, the normalized cosine similarity between clients 1 and 7 is signiﬁcantly larger than other
entries, while the cosine similarity between 1 and 2 is relatively low. Finally, only clients 1 and 7 are clustered together.
Unlike FedCos, which uses cosine similarity to cluster clients, the FedSNGP uses model prediction uncertainty as a
driving force for clustering. FedSNGP generates a similarity matrix ( MSim) that is non-symmetric, indicating that the
similarity between two datasets is not necessarily the same in both directions. By considering prediction uncertainty, the
FedSNGP is better equipped to estimate dataset similarity, making it more effective than FedCos in clustering clients
for FL.
16Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
Figure 9: Clustering results provided by FedCos and FedSNGP
While after the ﬁrst communication, the FedCos indicates that all the models are similar (with cosine similarity being
more than 0.8 for each pair of clients), FedSNGP starts to indicate that certain client datasets are signiﬁcantly different
from others. For example, the second row indicates that dataset 2 is signiﬁcantly different from dataset 4 and 5 (the
similarity values are around 0). It is worth noting that a single client’s estimation results can be unreliable. For instance,
if we consider the perspective of client 3 (the third row), its data distribution is signiﬁcantly different from that of clients
1 and 2. This is due to the fact that the training dataset of client 3 only covers healthy and outer race fault samples,
unlike client 1,which has all the classes of training datasets. Consequently, the similarity estimations from client 3 may
not be as dependable as those from client 1. While both the ﬁrst row and second row indicate that clients 1,2,3,6,7 and
12 have similar data distributions, the third row suggests that the dataset of client 3 differs signiﬁcantly from all the
other clients. And afﬁnity propagation clustering considers all clients’ information and creates client clusters in an
adaptive manner. Notably, after round 10 of communication, the FedSNGP algorithm formed three clusters: the ﬁrst
cluster included clients 1,2,3,5,6, and 7, the second cluster grouped clients 3,4,5, and the third cluster included clients
10,11,12.
Figures 9 and 10 illustrate how clients are clustered using FedCos and FedSNGP, respectively. Fig. 9 analyzes the
training datasets by examining the average amplitude. To validate the accuracy of the clustering strategy, we conducted
the following test.
(a) We divide the whole dataset into four subsets based on the working conditions. We then use each subset to train
an individual SNGP model. The total number of training epochs is 20. After every ﬁve epochs, we record the model
parameters. Finally, we use the principal component analysis algorithm to map the parameters of each model onto a 2D
plot.
(b) In the context of the PU dataset (scenario 2 setting), we utilized 12 client datasets to train 12 models. The number of
training epochs is 20. Again, model parameters are recorded at every ﬁve epochs. Finally, we use principal component
analysis to map the parameters of the 12 models onto a 2D plot. As shown in Fig11a, the shift of model parameters
indicates that models trained on subset A or C are being optimized in a comparable direction, suggesting that the data
distribution of subset A is similar to subset C. According to our kernel density feature distribution analysis, subsets B and
D should be trained independently without utilizing information from other subsets. This is further supported by Figure
11b, which demonstrates that the client models generally form three clusters. However, for clients with imbalanced
training datasets, such as clients 11 and 12, their optimization directions exhibit slight divergence from the desired
direction, especially during the initial stages. This divergence may potentially mislead the cosine-similarity-based FL
approach. Therefore, these ﬁndings suggest that at the early stages of local model training, the similarity of model
parameters may not necessarily reﬂect the similarity or discrepancy of the data.
17Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
Figure 10: Compare the similarity matrix generated by FedCos and FedSNGP at communication round 1, 2, and 10
Figure 11: Change of model parameters. The model parameters are mapped into 2D plots, and the arrow connects each
adjacent model point to show the optimization direction of each model.
5.3 Handling Out-of-Cluster-Distribution Samples
One limitation of clustering-based FL is that the trained model is only applicable to the data distribution within the same
cluster. In the context of bearing diagnosis, if the testing data falls outside the distribution of the client’s training dataset,
the client may generate inaccurate predictions which can have a substantial impact on availability and maintenance
costs. This limitation poses a challenge to the practical application of the diagnosis algorithm in industrial settings.
However, unlike conventional clustering algorithms, the FedSNGP incorporates prediction uncertainty into the FL
framework, which can help clients in avoiding overconﬁdent predictions for out-of-distribution samples. This property
18Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
of uncertainty quantiﬁcation could potentially enhance the reliability and practicality of the FedSNGP algorithm for
industrial applications.
In this section, we show how FedSNGP deals with out-of-distribution samples. If an SNGP model is tested with
out-of-distribution samples, the prediction uncertainty increases signiﬁcantly higher compared to the uncertainty towards
the training dataset. To mitigate this issue, a prediction uncertainty threshold is deﬁned based on the model’s training
dataset predicted variance. In this study, we set the threshold to ten times the training dataset predicted variance. If the
predicted variance for a test dataset exceeds this threshold, it suggests that the prediction is unreliable, and clients seek
help from other clients.
To do this, the client downloads other client clusters’ models from the server and tests them with the test dataset. The
client selects the model that yields the least predicted variance. Fig 12 provides a numerical example using client 1 in
the PU dataset case study (scenario 2). The client ﬁrst evaluates the test dataset using model 1, with a test predicted
variance of 0:272, which is signiﬁcantly larger than its predicted variance towards its training dataset. The client then
seeks help from the server.
On the server side, it is known that clients form three clusters. The server shares the other two clusters’ models ( 4and
10) with client 1. The model 4yields the least predicted variance, and that value is within the threshold. Therefore,
model 4’s result is more reliable. The confusion matrix listed in Fig 12 b demonstrates that 4yields the highest
accuracy. The predicted variance-guided model selection strategy can fully utilize the information provided by all the
clients.
Figure 12: An example of predicted variance-guided model selection: a. the model’s predicted variance results. b. the
confusion matrix of prediction results
6 Conclusion
This study proposes an uncertainty-based dynamic clustering federated algorithm, called FedSNGP, for fault diagnosis
on ﬂeets of system or component units, considering partial DA setting and feature shift. The proposed FedSNGP clusters
clients based on inferred dataset similarity and clients within the same cluster federate to train a model applicable to
its own data distribution. FedSNGP has two desirable features: (1) it uses predicted variance results instead of model
parameter similarity to infer dataset similarity and does not require deﬁning the number of clusters, and (2) it detects
out-of-distribution samples and prevents overconﬁdent predictions.
Experimental results using three datasets and three FL scenarios demonstrate that FedSNGP outperforms FedAvg and
FedCos, achieving over 99% accuracy for all clients. The proposed model is applicable to severe partial DA scenarios,
and by analyzing the distribution of client datasets and model parameter changes during training, it accurately deﬁnes
clusters and yields the highest prediction accuracy.
19Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
However, there are still limitations that need future research. Speciﬁcally, estimating data similarity requires clients to
download multiple models from the server, resulting in increased computational resources and training time compared
to FedAvg. A potential strategy to mitigate this limitation is to reduce data transmission volume between the server and
clients by encoding model parameters. Additionally, our strategy requires each client to have access to the other clients’
models, which may lead to privacy concerns. One way to mitigate this issue is to shufﬂe the order of client models and
hide the models’ client IDs when a client downloads other models. This makes it more challenging for each client to
reconstruct other clients’ training datasets.
Acknowledgements
This work was supported in part by the U.S. National Science Foundation under Grant IIP-1919265. Any opinions,
ﬁndings, or conclusions in this paper are those of the authors and do not necessarily reﬂect the sponsor’s views.
References
[1]Mariela Cerrada, René-Vinicio Sánchez, Chuan Li, Fannia Pacheco, Diego Cabrera, José Valente de Oliveira, and
Rafael E Vásquez. A review on data-driven fault severity assessment in rolling bearings. Mechanical Systems and
Signal Processing , 99:169–196, 2018. ISSN 0888-3270.
[2]Jay Lee, Fangji Wu, Wenyu Zhao, Masoud Ghaffari, Linxia Liao, and David Siegel. Prognostics and health
management design for rotary machinery systems—reviews, methodology and applications. Mechanical systems
and signal processing , 42(1-2):314–334, 2014.
[3]Yuekai Liu, Liang Guo, Hongli Gao, Zhichao You, Yunguang Ye, and Bin Zhang. Machine vision based condition
monitoring and fault diagnosis of machine tools using information from machined surface texture: A review.
Mechanical Systems and Signal Processing , 164:108068, 2022.
[4]Xiang Rao, Chenxing Sheng, Zhiwei Guo, and Chengqing Yuan. A review of online condition monitoring and
maintenance strategy for cylinder liner-piston rings of diesel engines. Mechanical Systems and Signal Processing ,
165:108385, 2022.
[5]Ying Lin, Maohua Xiao, Huijia Liu, Zhuolong Li, Shuang Zhou, Xiaomei Xu, and Dicheng Wang. Gear fault
diagnosis based on cs-improved variational mode decomposition and probabilistic neural network. Measurement ,
192:110913, 2022.
[6]Sheng Shen, Hao Lu, Mohammadkazem Sadoughi, Chao Hu, Venkat Nemani, Adam Thelen, Keith Webster,
Matthew Darr, Jeff Sidon, and Shawn Kenny. A physics-informed deep learning approach for bearing fault
detection. Engineering Applications of Artiﬁcial Intelligence , 103:104295, 2021. ISSN 0952-1976.
[7]Qin Wang, Gabriel Michau, and Olga Fink. Missing-class-robust domain adaptation by unilateral alignment. IEEE
Transactions on Industrial Electronics , 68(1):663–671, 2020. ISSN 0278-0046.
[8]Qin Hu, Xiao-Sheng Si, Qing-Hua Zhang, and Ai-Song Qin. A rotating machinery fault diagnosis method based
on multi-scale dimensionless indicators and random forests. Mechanical systems and signal processing , 139:
106609, 2020. ISSN 0888-3270.
[9]Suliang Ma, Mingxuan Chen, Jianwen Wu, Yuhao Wang, Bowen Jia, and Yuan Jiang. High-voltage circuit breaker
fault diagnosis using a hybrid feature transformation approach based on random forest and stacked autoencoder.
IEEE Transactions on Industrial Electronics , 66(12):9777–9788, 2018.
[10] XiaoLi Zhang, BaoJian Wang, and XueFeng Chen. Intelligent fault diagnosis of roller bearings with multivariable
ensemble-based incremental support vector machine. Knowledge-Based Systems , 89:56–85, 2015. ISSN 0950-
7051.
[11] Zhenya Wang, Ligang Yao, and Yongwu Cai. Rolling bearing fault diagnosis using generalized reﬁned composite
multiscale sample entropy and optimized support vector machine. Measurement , 156:107574, 2020.
[12] Olga Fink, Qin Wang, Markus Svensen, Pierre Dersin, Wan-Jui Lee, and Melanie Ducoffe. Potential, chal-
lenges and future directions for deep learning in prognostics and health management applications. Engineering
Applications of Artiﬁcial Intelligence , 92:103678, 2020.
[13] Junbin Chen, Jipu Li, Ruyi Huang, Ke Yue, Zhuyun Chen, and Weihua Li. Federated learning for bearing fault
diagnosis with dynamic weighted averaging. In 2021 International Conference on Sensing, Measurement & Data
Analytics in the era of Artiﬁcial Intelligence (ICSMD) , pages 1–6. IEEE, 2021. ISBN 1665427477.
[14] Olga Fink, Torbjørn Netland, and Stefan Feuerriegelc. Artiﬁcial intelligence across company borders. Communi-
cations of the ACM , 65(1):34–36, 2021. ISSN 0001-0782.
20Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
[15] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-
efﬁcient learning of deep networks from decentralized data. In Artiﬁcial intelligence and statistics , pages
1273–1282. PMLR, 2017. ISBN 2640-3498.
[16] Zehui Zhang, Cong Guan, Hui Chen, Xiangguo Yang, Wenfeng Gong, and Ansheng Yang. Adaptive privacy-
preserving federated learning for fault diagnosis in internet of ships. IEEE Internet of Things Journal , 9(9):
6844–6854, 2021.
[17] Xue Ma, Chenglin Wen, and Tao Wen. An asynchronous and real-time update paradigm of federated learning for
fault diagnosis. IEEE Transactions on Industrial Informatics , 17(12):8531–8540, 2021. ISSN 1551-3203.
[18] Wei Zhang, Xiang Li, Hui Ma, Zhong Luo, and Xu Li. Federated learning for machinery fault diagnosis with
dynamic validation and self-supervision. Knowledge-Based Systems , 213:106679, 2021. ISSN 0950-7051.
[19] Wei Zhang, Ziwei Wang, and Xiang Li. Blockchain-based decentralized federated transfer learning methodology
for collaborative machinery fault diagnosis. Reliability Engineering & System Safety , page 108885, 2022. ISSN
0951-8320.
[20] Solmaz Niknam, Harpreet S Dhillon, and Jeffrey H Reed. Federated learning for wireless communications:
Motivation, opportunities, and challenges. IEEE Communications Magazine , 58(6):46–51, 2020. ISSN 0163-
6804.
[21] Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang. On the convergence of fedavg on
non-iid data. arXiv preprint arXiv:1907.02189 , 2019.
[22] Hangyu Zhu, Jinjin Xu, Shiqing Liu, and Yaochu Jin. Federated learning on non-iid data: A survey. Neurocomput-
ing, 465:371–390, 2021. ISSN 0925-2312.
[23] Guogang Zhu, Xuefeng Liu, Shaojie Tang, and Jianwei Niu. Aligning before aggregating: Enabling cross-domain
federated learning via consistent feature extraction. In 2022 IEEE 42nd International Conference on Distributed
Computing Systems (ICDCS) , pages 809–819. IEEE, 2022.
[24] Hongda Wu and Ping Wang. Node selection toward faster convergence for federated learning on non-iid data.
IEEE Transactions on Network Science and Engineering , 9(5):3099–3111, 2022. ISSN 2327-4697.
[25] I Kevin, Kai Wang, Xiaokang Zhou, Wei Liang, Zheng Yan, and Jinhua She. Federated transfer learning based
cross-domain prediction for smart manufacturing. IEEE Transactions on Industrial Informatics , 18(6):4088–4096,
2021. ISSN 1551-3203.
[26] Yaxin Luopan, Rui Han, Qinglong Zhang, Chi Harold Liu, and Guoren Wang. Fedknow: Federated continual
learning with signature task knowledge integration at edge. arXiv preprint arXiv:2212.01738 , 2022.
[27] Yanxin Wang, Jing Yan, Zhou Yang, Yuannan Dai, Jianhua Wang, and Yingsan Geng. A novel federated transfer
learning framework for intelligent diagnosis of insulation defects in gas-insulated switchgear. IEEE Transactions
on Instrumentation and Measurement , 71:1–11, 2022. ISSN 0018-9456.
[28] Weihua Li, Wansheng Yang, Gang Jin, Junbin Chen, Jipu Li, Ruyi Huang, and Zhuyun Chen. Clustering federated
learning for bearing fault diagnosis in aerospace applications with a self-attention mechanism. Aerospace , 9(9):
516, 2022. ISSN 2226-4310.
[29] Chengxi Li, Gang Li, and Pramod K Varshney. Federated learning with soft clustering. IEEE Internet of Things
Journal , 9(10):7773–7782, 2021. ISSN 2327-4662.
[30] Dong Wang, Naifu Zhang, and Meixia Tao. Adaptive clustering-based model aggregation for federated learning
with imbalanced data. In 2021 IEEE 22nd International Workshop on Signal Processing Advances in Wireless
Communications (SPAWC) , pages 591–595. IEEE, 2021.
[31] Pu Tian, Weixian Liao, Wei Yu, and Erik Blasch. Wscc: A weight similarity based client clustering approach for
non-iid federated learning. IEEE Internet of Things Journal , 2022. ISSN 2327-4662.
[32] Weihua Li, Ruyi Huang, Jipu Li, Yixiao Liao, Zhuyun Chen, Guolin He, Ruqiang Yan, and Konstantinos Gryllias.
A perspective survey on deep transfer learning for fault diagnosis in industrial scenarios: Theories, applications
and challenges. Mechanical Systems and Signal Processing , 167:108487, 2022.
[33] Alysa Ziying Tan, Han Yu, Lizhen Cui, and Qiang Yang. Towards personalized federated learning. IEEE
Transactions on Neural Networks and Learning Systems , 2022.
[34] Junbin Chen, Jipu Li, Ruyi Huang, Ke Yue, Zhuyun Chen, and Weihua Li. Federated transfer learning for bearing
fault diagnosis with discrepancy-based weighted federated averaging. IEEE Transactions on Instrumentation and
Measurement , 2022. ISSN 0018-9456.
[35] Nastaran Gholizadeh and Petr Musilek. Federated learning with hyperparameter-based clustering for electrical
load forecasting. Internet of Things , 17:100470, 2022. ISSN 2542-6605.
21Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
[36] Jeremiah Liu, Zi Lin, Shreyas Padhy, Dustin Tran, Tania Bedrax Weiss, and Balaji Lakshminarayanan. Simple and
principled uncertainty estimation with deterministic deep learning via distance awareness. Advances in Neural
Information Processing Systems , 33:7498–7512, 2020.
[37] Jacob Gardner, Geoff Pleiss, Kilian Q Weinberger, David Bindel, and Andrew G Wilson. Gpytorch: Blackbox
matrix-matrix gaussian process inference with gpu acceleration. Advances in neural information processing
systems , 31, 2018.
[38] Xuming HAN, Minghan GAO, Limin WANG, Zaobo HE, and Yanze WANG. A survey of federated learning on
non-iid data iid data. ZTE COMMUNICATIONS , 20(3), 2022.
[39] Zhiyun Lu, Eugene Ie, and Fei Sha. Mean-ﬁeld approximation to gaussian-softmax integral with application to
uncertainty estimation. arXiv preprint arXiv:2006.07584 , 2020.
[40] Brendan J Frey and Delbert Dueck. Clustering by passing messages between data points. science , 315(5814):
972–976, 2007. ISSN 0036-8075.
[41] Case western reserve university bearing dataset, Aug 2021. URL https://engineering.case.edu/
bearingdatacenter/download-data-file .
[42] Christian Lessmeier, James Kuria Kimotho, Detmar Zimmer, and Walter Sextro. Condition monitoring of bearing
damage in electromechanical drive systems by using motor current signals of electric motors: A benchmark data
set for data-driven classiﬁcation. In PHM Society European Conference , volume 3, 2016.
[43] Gabriel Michau and Olga Fink. Unsupervised transfer learning for anomaly detection: Application to complemen-
tary operating condition transfer. Knowledge-Based Systems , 216:106816, 2021.
[44] Katharina Rombach, Gabriel Michau, and Olga Fink. Controlled generation of unseen faults for partial and
open-partial domain adaptation. Reliability Engineering & System Safety , 230:108857, 2023.
Code Availability
The dataset and related codes are provided at https://github.com/SalieriLu/FL_fault_diagnosis
Appendix
Design of the training datasets
To create data sample heterogeneity, in scenario 3, some clients only use a portion of the training dataset to train the
model. The design of the training dataset for scenario 3 is listed as follows:
CWRU dataset case study PU dataset case study ISU dataset case study
Client ID HealthyInner race
faultOuter race
faultHealthyInner race
faultOuter race
faultHealthyInner race
faultOuter race
faultCombination
of faults
1 64 64 0 480 480 480 1200 1200 0 0
2 64 0 64 480 480 0 1200 0 1200 0
3 64 64 0 480 0 480 1200 0 0 1200
4 56 0 56 1200 1200 1200 1800 1800 0 0
5 56 56 0 1200 1200 0 1800 0 1800 0
6 56 0 56 1200 0 1200 1800 0 0 1800
7 64 64 0 600 600 600 800 800 0 0
8 64 0 64 600 600 0 800 0 800 0
9 64 64 0 600 0 600 800 0 0 800
10 72 0 72 720 720 720 1600 1600 0 0
11 72 72 0 720 720 0 1600 0 1600 0
12 72 0 72 720 0 720 1600 0 0 1600
Design of the test datasets
The design of test datasets is summarized in the following table:
22Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
Dataset Scenario 1 test dataset Scenario 2 and 3 test dataset
CWRUClient ID Operating condition HealthyInner race
faultOuter race
faultHealthyInner race
faultOuter race
fault
1 Shaft speed = 1797 rpm
Fault diameter = 0.007”20 20 0 20 20 20
2 20 0 20 20 20 20
3 Shaft speed = 1797 rpm
Fault diameter = 0.014”20 20 0 20 20 20
4 20 0 20 20 20 20
5 Shaft speed = 1772 rpm
Fault diameter = 0.007”20 20 0 20 20 20
6 20 0 20 20 20 20
7 Shaft speed = 1772 rpm
Fault diameter = 0.014”20 20 0 20 20 20
8 20 0 20 20 20 20
9 Shaft speed = 1730 rpm
Fault diameter = 0.007”20 20 0 20 20 20
10 20 0 20 20 20 20
11 Shaft speed = 1730 rpm
Fault diameter = 0.014”20 80 0 20 20 20
12 20 0 20 20 20 20
PUClient ID Operating condition HealthyInner race
faultOuter race
faultHealthyInner race
faultOuter race
fault
1 Shaft speed = 1500 rpm
Load torque = 0.7 Nm
Radial force = 1000 N300 300 300 300 300 300
2 300 300 0 300 300 300
3 300 0 300 300 300 300
4 Shaft speed = 900 rpm
Load torque = 0.7 Nm
Radial force = 1000 N300 300 300 300 300 300
5 300 300 0 300 300 300
6 300 0 300 300 300 300
7 Shaft speed = 1500 rpm
Load torque = 0.1 Nm
Radial force = 1000 N300 300 300 300 300 300
8 300 300 0 300 300 300
9 300 0 300 300 300 300
10 Shaft speed = 1500 rpm
Load torque = 0.7 Nm
Radial force = 400N300 300 300 300 300 300
11 300 300 0 300 300 300
12 300 0 300 300 300 300
ISUClient ID Operating condition HealthyInner race
faultOuter race
faultCombination
of faultsHealthyInner race
faultOuter race
faultCombination
of faults
1Shaft speed = 2100 rpm
Radial force = 0500 500 0 0 500 500 500 500
2 500 0 500 0 500 500 500 500
3 500 0 0 500 500 500 500 500
4Shaft speed = 2100 rpm
Radial force = 25 N500 500 0 0 500 500 500 500
5 500 0 500 0 500 500 500 500
6 500 0 0 500 500 500 500 500
7Shaft speed = 1500 rpm
Radial force = 0500 500 0 0 500 500 500 500
8 500 0 500 0 500 500 500 500
9 500 0 0 500 500 500 500 500
10Shaft speed = 1500 rpm
Radial force = 25 N500 500 0 0 500 500 500 500
11 500 0 500 0 500 500 500 500
12 500 0 0 500 500 500 500 500
Note that scenario 2 and 3 uses the same test dataset setting.
23Federated Learning with Uncertainty-Based Client Clustering for Fleet-Wide Fault Diagnosis
Results for each of the three test conditions
CWRU
Scenario 1 Scenario 2 Scenario 3
Local training FedAvg FedCos FedSNGP Local training FedAvg FedCos FedSNGP Local training FedAvg FedCos FedSNGP
1 100.00 100.00 100.00 100.00 81.67 100.00 100.00 100.00 78.33 93.33 71.67 96.67
2 95.00 97.50 100.00 97.50 73.33 98.33 100.00 98.33 65.00 95.00 66.67 98.33
3 100.00 100.00 100.00 100.00 75.00 100.00 100.00 100.00 75.00 93.33 66.67 96.67
4 100.00 100.00 100.00 100.00 85.00 98.33 100.00 98.33 75.00 95.00 66.67 98.33
5 100.00 100.00 100.00 100.00 76.67 100.00 100.00 100.00 73.33 93.33 100.00 100.00
6 100.00 100.00 100.00 97.50 75.00 98.33 98.33 98.33 58.33 80.00 66.67 85.00
7 100.00 100.00 100.00 100.00 71.67 100.00 100.00 100.00 58.33 93.33 100.00 100.00
8 100.00 97.50 97.50 100.00 73.33 98.33 98.33 98.33 71.67 80.00 66.67 85.00
9 100.00 100.00 100.00 100.00 71.67 100.00 100.00 100.00 70.00 90.00 66.67 98.33
10 100.00 100.00 100.00 100.00 78.33 98.33 100.00 100.00 76.67 83.33 66.67 95.00
11 100.00 100.00 100.00 100.00 76.67 100.00 100.00 100.00 68.33 90.00 66.67 98.33
12 100.00 97.50 100.00 100.00 70.00 98.33 100.00 100.00 76.67 83.33 66.67 95.00
PU
Scenario 1 Scenario 2 Scenario 3
Local training FedAvg FedCos FedSNGP Local training FedAvg FedCos FedSNGP Local training FedAvg FedCos FedSNGP
1 99.89 99.78 100.00 100.00 99.89 99.78 100.00 100.00 100.00 97.56 99.56 99.89
2 100.00 99.65 100.00 100.00 66.67 99.78 66.67 100.00 51.00 97.56 66.89 99.89
3 100.00 100.00 100.00 100.00 66.67 99.78 66.56 100.00 35.11 97.56 66.67 99.89
4 99.56 94.00 99.11 99.67 99.56 94.00 99.11 99.67 99.56 98.44 99.67 99.56
5 100.00 97.21 100.00 100.00 66.67 94.00 99.11 99.67 66.67 98.44 99.67 99.56
6 99.66 92.33 95.40 99.15 66.56 94.00 63.67 99.67 66.44 98.44 66.22 99.56
7 100.00 100.00 100.00 100.00 100.00 100.00 100.00 100.00 99.89 97.22 99.67 99.78
8 100.00 99.83 100.00 100.00 66.67 100.00 66.67 100.00 66.67 97.22 66.67 99.78
9 100.00 100.00 100.00 100.00 66.67 100.00 66.44 100.00 67.22 97.22 66.67 99.78
10 100.00 98.78 99.22 100.00 100.00 98.78 99.22 100.00 100.00 97.44 99.56 100.00
11 100.00 100.00 100.00 100.00 66.67 98.78 66.67 100.00 66.78 97.44 66.67 100.00
12 100.00 98.26 100.00 100.00 66.67 98.78 66.67 100.00 36.67 97.44 66.89 100.00
ISU
Scenario 1 Scenario 2 Scenario 3
Local training FedAvg FedCos FedSNGP Local training FedAvg FedCos FedSNGP Local training FedAvg FedCos FedSNGP
1 100.00 98.00 100.00 100.00 50.00 98.30 50.00 100.00 52.35 90.85 50.00 100.00
2 100.00 99.50 100.00 100.00 50.35 98.30 50.00 100.00 53.60 90.85 50.00 100.00
3 100.00 99.10 100.00 100.00 50.20 98.30 50.00 100.00 55.85 90.85 50.00 100.00
4 100.00 99.70 100.00 100.00 50.00 99.20 50.00 100.00 50.15 100.00 50.00 100.00
5 100.00 100.00 100.00 100.00 50.00 99.20 50.00 100.00 54.40 100.00 50.00 100.00
6 100.00 98.70 100.00 100.00 50.00 99.20 50.00 100.00 50.25 100.00 50.00 100.00
7 100.00 98.10 100.00 100.00 50.00 96.75 50.00 100.00 24.75 80.95 50.00 98.65
8 100.00 95.80 100.00 100.00 50.05 96.75 50.00 100.00 26.60 80.95 49.85 98.65
9 100.00 99.60 99.90 100.00 50.25 96.75 49.95 100.00 27.45 80.95 49.90 98.65
10 100.00 99.60 100.00 100.00 50.00 98.55 50.00 100.00 50.20 99.40 50.00 100.00
11 100.00 99.70 100.00 100.00 50.40 98.55 50.00 100.00 50.25 99.40 50.00 100.00
12 100.00 97.80 100.00 100.00 50.05 98.55 50.00 100.00 53.25 99.40 50.00 100.00
24