ON THE CONVERGENCE OF THE DISTRIBUTED PROXIMAL
POINT ALGORITHM
WOOCHEOL CHOI
Abstract. In this work, we establish convergence results for the distributed proximal
point algorithm (DPPA) for distributed optimization problems. We consider the problem
on the whole domain Rdand find a general condition on the stepsize and cost functions
such that the DPPA is stable. We prove that the DPPA with stepsize η >0 exponentially
converges to an O(η)-neighborhood of the optimizer. Our result clearly explains the
advantage of the DPPA with respect to the convergence and stability in comparison with
the distributed gradient descent algorithm. We also provide numerical tests supporting
the theoretical results.
1.Introduction
This works consider the distributed optimization
min
x∈Rdf(x) =nX
i=1fi(x), (1.1)
where ndenotes the number of the agents in the network, and fi:Rd→Ris a differentiable
local cost only known agent ifor each 1 ≤i≤n. In recent years, extensive research has
been conducted on distributed optimization due to its relevance in various applications,
including wireless sensor networks [1, 24], multi-agent control [4, 22, 5], smart grids [9, 10],
and machine learning [11, 21, 30, 3, 27].
Numerous studies have focused on solving distributed optimization problems on net-
works. Relevant research works include [17, 18, 25, 26], and the references therein. A key
algorithm in this field is the distributed gradient descent algorithm (DGD), introduced in
[17]. Additionally, there exist various versions of distributed optimization algorithms such
as EXTRA [25] and decentralized gradient tracking [18, 20, 28]. Lately, there has been
growing interest in designing communication-efficient algorithms for distributed optimiza-
tion [23, 8, 12, 2].
The distributed proximal point algorithm (DPPA) was proposed in [15, 16] as a dis-
tributed counterpart of the proximal point method, analogous to the relation between
the distributed gradient descent algorithm and the gradient descent method. The works
[15, 16] established the asymptotic convergence of the DPPA under the assumptions of a
compact domain for each local cost fiand a decreasing step size. The work [14] designed
2010 Mathematics Subject Classification. Primary 90C25, 68Q25 .
Key words and phrases. Proximal point method, Distributed optimization, Distributed gradient
algorithm.
1arXiv:2305.17383v2  [math.OC]  10 Jul 20232 WOOCHEOL CHOI
the DPPA on a directed graph and proved a convergence estimate with rate O(1/√
t) when
the step size is set to 1 /√
tand each cost function has a compact domain.
It is a well-known fact that the proximal point method is more stable compared to
the gradient descent method for large choices of the stepsize. This fact suggests that the
DPPA may also exhibit be more stable than the DGD, as mentioned in the previous works
[13, 14, 16]. In this work, we provide convergence results for the DPPA in the case of the
entire domain and a constant step size. Comparing the results with the convergence result
[29] of the DGD, we will find that the DPPA is more stable than the DGD when the
stepsize is large.
The DPPA for the problem (1.1) is described as follows:
ˆxi(t) =nX
j=1wijxj(t)
xi(t+ 1) = argminx∈Rn
fi(x) +1
2η∥x−ˆxi(t)∥2
,(1.2)
where wijdenotes the weight for the communication among agents in the network desribed
by an undirected graph G= (V,E). Each node in Vrepresents an agent, and each edge
{i, j} ∈ E means that ican send messages to jand vice versa. We consider a graph G
satisfying the following assumption.
Assumption 1.The communication graph Gis undirected and connected, i.e., there exists
a path between any two agents.
We define the mixing matrix W={wij}1≤i,j≤nas follows. The nonnegative weight wij
is given for each communication link {i, j} ∈ E ,where wij̸= 0 if {i, j} ∈ E andwij= 0 if
{i, j}/∈ E. In this paper, we make the following assumption on the mixing matrix W.
Assumption 2.The mixing matrix W={wij}1≤i,j≤nis doubly stochastic, i.e., W1=1
and1TW=1T. In addition, wii>0 for all i∈ V.
In the following result, we establish that the sequence {xk(t)}n
k=1is stable, i.e., uniformly
bounded for t≥0 under suitable conditions.
Theorem 1.1. Suppose that the assumptions 1-2 hold, and assume that one of the fol-
lowing conditions holds:
(1) The following function
Fη(x) :=nX
k=1fk(xk) +1
2ηxT(I−W)x (1.3)
is bounded below and has an optimal solution (x∗
1,···, x∗
n).
(2) Each function fkisL-smooth and fisα-stronlgy convex. In addition, the stepsize
η >0satisfies the following inequality
η2(α2+αL) +η
α+L−(1−ρW)α2
L
<(1−ρW)α
L, (1.4)
where ρWis the spectral norm of the matrix W−1
n11T.3
Then the sequence {xk(t)}n
k=1of the DPPA with stepsize η >0is uniformly bounded for
t≥0.
We now compare the stability result with that of the DGD described by
xi(t+ 1) =NX
j=1wijxj(t)−η∇fi(xi(t)).
Letλn(W)∈Rbe the smallest eigenvalue of W. Then it is known from [29] that the
DGD is stable if the stepsize η >0 satisfies
η≤1 +λn(W)
L,
provided that each cost function fjis convex and L-smooth. Table 1 summarizes the
Condition on the costs Stepsize Paper
DGDEach fjis convex
andL-smoothη≤(1+λn(W))
L[29]
DPPAFηis bounded below
and has an optimizerη∈(0,∞) This work
Table 1. This table compares the condition on the stepsize for the stability
of the DGD and the DPPA.
condition on the stepsize η >0 for the stability of the DGD and the DPPA. We observe
thatFηdefined in (1.3) is bounded below for any η >0 when each fjis convex. Therefore,
the condition of (1) in Theorem 1.1 is not so restrictive than the condition that fjis convex
which is required for the stability result [29] of the DGD. Hence the result of Theorem
1.1 proves that the stepsize choice of η >0 is much wider for the DPPA than that for the
DGD.
For the convergence analysis of the DPPA, we assume the uniformly boundedness prop-
erty.
Assumption 3.The sequence {xk(t)}n
k=1is uniformly bounded for t≥0, i.e., there is
R > 0 such that
At≤Rand Bt≤R∀t≥0.
Although the property is guaranteed for broad class of functions by the result of The-
orem 1.1, we formulate this assumption of the sake of simplicity in the statement of the
convergence result. We also consider the following assumption.
Assumption 4.The aggregate cost function fisα-strongly convex for some α > 0 and
each cost function fjisL-smooth for each 1 ≤j≤n, i.e.,
∥∇fj(x)− ∇fj(y)∥ ≤L∥x−y∥
for all x, y∈Rd.4 WOOCHEOL CHOI
Under this assumption, there exists a unique optimizer x∗= arg minx∈Rdf(x). We let
D= max 1≤i≤n∥∇fi(x∗)∥. Also we regard xi(t) as a row vector in R1×d, and define the
variable x(t)∈Rn×dand¯x(t)∈Rn×dby
x(t) =
x1(t)T,···, xm(t)TT
and ¯x(t) =
¯x(t)T,···,¯x(t)TT
, (1.5)
where ¯ x(t) =1
nPn
k=1xk(t). We let
At=∥¯x(t)−x∗∥and Bt=1√n∥¯ x(t)−x(t)∥=1
nnX
k=1∥¯x(t)−xk(t)∥21/2
.
We show that the DPPA converges exponentially to an O(η)-neighborhood of the optimizer
in the following result.
Theorem 1.2. Suppose that the assumptions 1-3 hold and Then we have
At≤A0
(1 +ηα)t+tηLB 0ρW
(1 +ηα)maxn
ρW,1
1 +ηαot−1
+ηL(2RL+D)
α(1−ρW)(1.6)
and
Bt≤(ρW)tB0+η
(1−ρW)(2RL+D).
Upon knowing that the DGD is stable, the linear convergence result of the DGD is
proved when the stepsize ηsatisfies η≤2
α+L. We refer to [29, 7] for the detail. As for the
DPPA, we note that there is no restriction on the stepsize η >0 for the linear convergence
as obtained in Theorem 1.2. Table 2 compares the condition on the stepsize of the DGD
and the DPPA for the convergence of the algorithms.
Condition on the costs DGD Estimate Paper
DGDEach fjisL-smooth
fisα-strongly convexη≤2
α+LO(e−ct) +O
η
1−ρW
[29, 7]
DPPAEach fjisL-smooth
fisα-strongly convexη∈(0,∞)O(e−ct) +O
η
1−ρW
This work
Table 2. This table compares the condition on the stepsize for the stability
of the DGD and the DPPA.
The rest of this paper is organized as follows. In Section 2, we establish two sequential
inequalities of AtandBt. Section 3 is devoted to prove the uniform boundedness result
of Theorem 1.1. In Section 4, we prove the convergence result of Theorem 1.2. Numerical
results are presented in Section 5.
2.Sequential estimates
In this section, we dervie two sequential inequalities of AtandBt, which are main
ingredients for the stability and the convergence analysis of the DPPA.5
Proposition 2.1. Assume that fisα-strongly convex. Then, for any stepsize η >0, the
sequence {(At, Bt)}t≥0satisfies the follwoing inequality
(1 +ηα)At+1≤At+ηLB t+1 (2.1)
for all t≥0.
Proof. From the minimality of (1.2), it follows that
∇fk(xk(t+ 1)) +1
η
xk(t+ 1)−nX
j=1wkjxj(t)
= 0. (2.2)
We reformulate this as
xk(t+ 1) + η∇fk(xk(t+ 1)) =nX
j=1wkjxj(t). (2.3)
By averaging this for 1 ≤k≤n, we get
¯x(t+ 1) +η
nnX
k=1∇fk(xk(t+ 1)) = ¯ x(t). (2.4)
Using this and the fact that ∇f(x∗) = 0, we find
¯x(t+ 1)−x∗+η(∇f(¯x(t+ 1))− ∇f(x∗))
= ¯x(t)−x∗+ηnX
k=1∇fk(¯x(t+ 1))− ∇fk(xk(t+ 1))
.(2.5)
Since fis assumed to be α-strongly convex, we have
∥∇f(x)− ∇f(y)∥2≥α2∥x−y∥2
and
⟨x−y,∇f(x)− ∇f(y)⟩ ≥α∥x−y∥2.
Combining these estimates, we get
¯x(t+ 1)−x∗+η
∇f(¯x(t+ 1))− ∇f(x∗)2
=∥¯x(t+ 1)−x∗∥2+ 2η⟨¯x(t+ 1)−x∗,∇f(¯x(t+ 1))− ∇f(x∗)⟩
+η2∥∇f(¯x(t+ 1))− ∇f(x∗)∥2
≥(1 + 2 ηα+α2)∥¯x(t+ 1)−x∗∥2.
Using this estimate in (2.5) and applying the triangle inequality, we get
(1 +ηα)∥¯x(t+ 1)−x∗∥
≤ ∥¯x(t)−x∗∥+η
nnX
k=1∇fk(¯x(t+ 1))− ∇fk(xk(t+ 1))
≤ ∥¯x(t)−x∗∥+ηL
nnX
k=1∥¯x(t+ 1)−xk(t+ 1)∥
≤ ∥¯x(t)−x∗∥+ηL√n∥¯x(t+ 1)−x(t+ 1)∥,6 WOOCHEOL CHOI
where we used the Cauchy-Schwartz inequality in the last inequality. This gives the desired
inequality. □
Next we will derive a bound of Bt+1in terms of AtandBt. For this we will use the
following result (see [19, Lemma 1]).
Lemma 2.2. Suppose Assumptions 1 and 2 hold, and let ρWbe the spectral norm of the
matrix W−1
n11T.Then we have ρW<1and
nX
i=1nX
j=1wij(xj−¯x)2
≤(ρW)2nX
i=1∥xi−¯x∥2,
where ¯x=1
nPn
k=1xkfor any xi∈Rd×1and1≤i≤n.
In the following result, we find an estimate of Bt+1in terms of BtandAt+1.
Proposition 2.3. Suppose that each fjisL-smooth. Then the sequence {(At, Bt)}t≥0
satisfies the following inequality
Bt+1≤ρWBt+ηLB t+1+ηLA t+1+ηD (2.6)
for all t≥0.
Proof. We may write (2.3) and (2.4) in the following way
x(t+ 1) + η∇F(x(t+ 1)) = Wx(t)
and
¯x(t+ 1) + η∇F(x(t+ 1)) = ¯x(t),
where we have let
∇F(x(t+ 1)) =
∇f1(x1(t+ 1)) ,···,∇fn(xn(t+ 1))T
.
Combining the above equalities, we find
x(t+ 1)−¯x(t+ 1) = W(x(t)−¯x(t))−η
∇F(x(t+ 1))−∇F(x(t+ 1))
.
By applying the triangle inequality and Lemma 2.2, we deduce
∥x(t+ 1)−¯x(t+ 1)∥
≤ρW∥x(t)−¯x(t)∥+η∥∇F(x(t+ 1))−∇F(x(t+ 1))∥.(2.7)
Using the fact that the spectral radius of the matrix
In−1
n1T
n1n
is one, we obtain
∥∇F(x(t+ 1))−∇F(x(t+ 1))∥
≤ ∥∇ F(x(t+ 1))∥
≤ ∥∇ F(x(t+ 1))− ∇F(¯x(t+ 1))∥+∥∇F(¯x(t+ 1))− ∇F(x∗)∥+∥∇F(x∗)∥
≤L∥x(t+ 1)−¯x(t+ 1)∥+√nL∥¯x(t+ 1)−x∗∥+√nD.7
Inserting this into (2.7) we obtain
∥x(t+ 1)−¯x(t+ 1)∥
≤ρW∥x(t)−¯x(t)∥+ηL∥x(t+ 1)−¯x(t+ 1)∥
+√nLη∥¯x(t+ 1)−x∗∥+√nDη,
which is the desired inequality. □
3.Boundedness of the sequence
We prove the uniform boundedness result of Theorem 1.1 under the two conditions
separately in the below.
Proof of Theorem 1.1. Assume the first condition of Theorem 1.1. We claim the following
inequality
nX
k=1∥xk(t+ 1)−x∗
k∥ ≤nX
k=1∥xk(t)−x∗
k∥ ∀ t≥0. (3.1)
The optimizer ( x∗
1,···, x∗
n) of (2.7) satisfies
∇fk(x∗
k) +1
η
x∗
k−nX
j=1wkjx∗
j
= 0.
Combining this with (2.2) gives
η(∇fk(xk(t+ 1))− ∇fk(x∗
k)) + ( xk(t+ 1)−x∗
k) =nX
j=1wkj(xj(t)−x∗
j).
From this we have
∥xk(t+ 1)−x∗
k∥ ≤nX
j=1wkj(xj(t)−x∗
j)≤nX
j=1wkj∥xj(t)−x∗
j∥.
Summing up this for 1 ≤k≤n, we get
nX
k=1∥xk(t+ 1)−x∗
k∥ ≤nX
k=1nX
j=1wkj∥xj(t)−x∗
j∥=nX
j=1∥xj(t)−x∗
j∥,
which proves the inequality (3.1). It gives the following bound
nX
k=1∥xk(t)−x∗
k∥ ≤nX
k=1nX
j=1wkj∥xj(t)−x∗
j∥=nX
j=1∥xj(0)−x∗
j∥ ∀ t≥0.
Hence AtandBtare uniformly bounded.
Next we assume the second condition of Theorem 1.1. Then we claim that the sequence
AtandBtsatisfies
At≤Rand Bt≤α
LR,
where R > 0 is defined by
R= max(
A0,L
αB0,L
αB1,ηD
α
L
1−ηL−η2L2
(1+ηα)
−α
LρW−ηL
(1+ηα))
. (3.2)8 WOOCHEOL CHOI
We argue by induction to prove this claim. First, we note that A0≤R,B0≤Rand
B1≤Rby the definition of R. Next we assume that
At≤Rand Bt+1≤cR (3.3)
for some t≥0 and c=α
L. Then, we use these bounds in (2.1) to find
(1 +ηα)At+1≤(R+ηLcR ) = (1 + ηα)R,
which gives At+1≤R. Next we recall the estimates (2.1) and (2.6) with treplaced by
(t+ 1) as
Bt+2≤ρWBt+1+ηLB t+2+ηLA t+2+ηD
and
(1 +ηα)At+2≤At+1+ηLB t+2
≤R+ηLB t+1,
where we used At+1≤Rin the last inequality. Combining these estimates with (3.3) gives

1−ηL−η2L2
(1 +ηα)
Bt+2≤(ρW)(cR) +ηL
1 +ηαR+ηD.
This gives Bt+2≤cRprovided that
ρW(cR) +ηL
(1 +ηα)R+ηD≤Rc
1−ηL−η2L2
(1 +ηα)
.
This holds true for R > 0 defined in (3.2) and η >0 satisfying
α
L
(1−ρW)−ηL−η2L2
(1 +ηα)
>ηL
(1 +ηα),
which is same with
η2(α2+αL) +η
α+L−(1−ρW)α2
L
<(1−ρW)α
L.
The proof is done.
□
4.Convergence result
In this section, we prove the main convergence result of the decentralized proximal point
method.
Proof of Theorem 1.2. By Proposition 2.1 and Proposition 2.3 we have the following in-
equalities
(1 +ηα)At+1≤At+ηLB t+1 (4.1)
and
Bt+1≤ρWBt+ηLB t+1+ηLA t+1+ηD.
Using the assumption that At+1≤RandBt+1≤R, we have
Bt+1≤(ρW)Bt+η(2RL+D)9
for all t≥0. Using this iteratively, we get
Bt≤(ρW)tB0+η(2RL+D)h
1 +ρW+···+ (ρW)t−1i
≤(ρW)tB0+η
(1−ρW)(2RL+D).
Putting this inequality into (4.1) leads to
(1 +ηα)At+1
≤At+ηLh
(ρW)t+1B0+η
(1−ρW)(2RL+D)i
=At+ηLB 0(ρW)t+1+η2L
(1−ρW)(2RL+D).(4.2)
To analyize this sequential estimate, we consider two positive sequences {zt}t≥0and{yt}t≥0
satisfying
(1 +ηα)zt+1=zt+ηLB 0(ρW)t+1
and
(1 +ηα)yt+1=yt+η2L
(1−ρW)(2RL+D),
where z0=A0andy0= 0. It then follows from (4.2) that At≤zt+ytfor all t≥0.
We estimate ztas follows:
zt=z0
(1−ηα)t+ηLB 0ρW
(1 +ηα)ht−1X
j=0(ρW)j
(1 +ηα)t−1−ji
≤z0
(1−ηα)t+tηLB 0ρW
(1 +ηα)maxn
ρW,1
1 +ηαot−1
.
Next we estimate ytas
yt=1
(1 +ηα)ty0+η2L
(1 +ηα)(1−ρW)(2RL+D)t−1X
j=01
(1 +ηα)j−1
≤1
(1 +ηα)ty0+η2L
(1 +ηα)(1−ρW)(2RL+D)∞X
j=01
(1 +ηα)j
=y0
(1 +ηα)t+ηL(2RL+D)
α(1−ρW).
Combining the above estimates gives
At≤zt+yt
≤A0
(1−ηα)t+tηLB 0ρW
(1 +ηα)maxn
ρW,1
1 +ηαot−1
+ηL(2RL+D)
α(1−ρW).
This corresponds to the inequality (1.4) in the condition (2). Thus, it holds that At+1≤R
andBt+2≤cR. This completes the induction, and so the claim is proved. Hence the
uniform boundedness is proved. □10 WOOCHEOL CHOI
5.Numerical tests
This section gives numerical experimental results of the DPPA. We consider the cost
function
f(x) =1
nnX
k=1∥Akx−yk∥2,
where nis the number of agents and for each 1 ≤i≤nandAibe an m×dmatrix
whose element is chosen randomly following the normal distribution N(0,1). Also we set
yi∈Rmwhose each element is generated from the normal distribution N(0,1). We choose
n= 20, m= 5 and d= 10.
For the communication matrix W, we link each two agents with probability 0.4, and
define the weights wijby
wij=

1/max{deg(i),deg(j)}ifi∈Ni,
1−P
j∈Niwij ifi=j,
0 otherwise.
We define the following value
ηc=1 +λn(W)
L,
where λn(W) is the smallest eigenvalue of WandLis the constant for the smoothness
propery of fjfor 1≤j≤n. In our experiment, the constants are computed as L≃29.7312
andλn(W)≃ −0.4009. Therefore we find ηc≃0.0202.
We perform the numerical simulation for the DPPA and the DGD with stepsize chosen
asη=ηc+ 0.005 and η=ηc. Figure 1 indicates the graphs of the error log(Pn
k=1∥xk(t)−
x∗∥/n) with respect to t≥0. The result shows that both the DPPA and the DGD are
stable for η=ηcas the theoretical results of Table 1 guarantee. On the other hand,
if we choose η=ηc+ 0.005, then the DGD becomes unstable while the DPPA is still
stable. This supports the result of Theorem 1.1. Next we perform the numerical test
Figure 1. The graphs of the error log(Pn
k=1∥xk(t)−x∗∥/n) for the DPPA
and the DGD for t≥0 with stepsize η=ηc+ 0.005 and η=ηc.
for the DPPA with various stepsize η∈ {0.001,0.01,0.1,1,2}. We measure the error11
log(Pn
k=1∥xk(t)−x∗∥/n) and the graphs are given in Figure 2. The result shows that the
error decreases exponentially up to an O(η) value, which supports the convergence result
of Theorem 1.2.
Figure 2. The graphs of the error log(Pn
k=1∥xk(t)−x∗∥/n) for the DPPA
with respect to t≥0 and stepsize η∈ {0.001,0.01,0.1,1,2}.
Acknowledgments
The author was supported by the National Research Foundation of Korea (NRF)
grants funded by the Korea government No. NRF-2016R1A5A1008055 and No. NRF-
2021R1F1A1059671.
References
[1] J. A. Bazerque, G.B. Giannakis, Distributed spectrum sensing for cognitive radio networks by exploit-
ing sparsity. IEEE Trans. Signal Process. 58(3), 1847–1862 (2010)
[2] A.S. Berahas, R. Bollapragada, N.S. Keskar, E. Wei, Balancing communication and computation in
distributed optimization. IEEE Trans. Autom. Control 64(8), 3141–3155 (2018)
[3] L. Bottou, F. E. Curtis, and J. Nocedal, Optimization methods for large-scale machine learning, SIAM
Review, vol. 60, no. 2, pp. 223—311, 2018.
[4] F. Bullo, J. Cortes, S. Martinez, S. Distributed Control of Robotic Networks: A Mathematical Ap-
proach to Motion Coordination Algorithms, vol. 27. Princeton University Press, Princeton (2009)
[5] Y. Cao, W. Yu, W. Ren, and G. Chen, An overview of recent progress in the study of distributed
multi-agent coordination, IEEE Trans Ind. Informat., 9 (2013), pp. 427–438
[6] W. Choi, D. Kim, S. Yun, Convergence results of a nested decentralized gradient method for non-
strongly convex problems. J. Optim. Theory Appl. 195 (2022), no. 1, 172–204.
[7] W. Choi, J. Kim, On the convergence of decentralized gradient descent with diminishing stepsize,
revisited, arXiv:2203.09079.
[8] A. I. Chen and A. Ozdaglar, A fast distributed proximal-gradient method, in Communication, Control,
and Computing (Allerton), 2012 50th Annual Allerton Conference on. IEEE, 2012, pp. 601–608.
[9] G. B. Giannakis, V. Kekatos, N. Gatsis, S.-J. Kim, H. Zhu, and B. Wollenberg, Mon-itoring and
optimization for power grids: A signal processing perspective, IEEE Signal Processing Mag., 30
(2013), pp. 107–128,
[10] V. Kekatos and G. B. Giannakis, Distributed robust power system state estimation, IEEE Trans.
Power Syst., 28 (2013), pp. 1617–1626,12 WOOCHEOL CHOI
[11] P. A. Forero, A. Cano, and G. B. Giannakis, Consensus-based distributed support vector machines,
Journal of Machine Learning Research, vol. 11, pp. 1663—1707, 2010.
[12] D. Jakovetic, J. Xavier, and J. M. F. Moura, Fast Distributed Gradient Methods, IEEE Transactions
on Automatic Control, vol. 59, no. 5, pp. 1131–1146, 2014.
[13] X. Li, G. Feng, L. Xie, Distributed proximal algorithms for multiagent optimization with coupled
inequality constraints. IEEE Trans. Automat. Control 66 (2021), no. 3, 1223–1230.
[14] X. Li, G. Feng, L. Xie, Distributed Proximal Point Algorithm for Constrained Optimization over
Unbalanced Graphs. In 2019 IEEE 15th International Conference on Control and Automation (ICCA)
(pp. 824-829).
[15] K. Margellos, A. Falsone, S. Garatti, and M. Prandini, Proximal minimization based distributed
convex optimization,” in 2016 American Control Conference (ACC), July 2016, pp. 2466–2471.
[16] K. Margellos, A. Falsone, S. Garatti, and M. Prandini, Distributed constrained optimization and
consensus in uncertain networks via proximal minimization, IEEE Trans. Autom. Control, vol. 63, no.
5, pp. 1372–1387, May 2018.
[17] A. Nedi´ c and A. Ozdaglar, Distributed subgradient methods for multi-agent optimization, IEEE
Transactions on Automatic Control, vol. 54, no. 1, pp. 48, 2009.
[18] A. Nedi´ c, A. Olshevsky, and W. Shi, Achieving geometric convergence for distributed optimization
over time-varying graphs, SIAM Journal on Optimization, vol. 27, no. 4, pp. 2597–2633, 2017.
[19] S. Pu and A. Nedi´ c, Distributed stochastic gradient tracking methods, Math. Program, pp. 1–49, 2018
[20] G. Qu and N. Li, Harnessing smoothness to accelerate distributed optimization, IEEE Transactions
on Control of Network Systems, vol. 5, no. 3, pp. 1245–1260, 2018.
[21] H. Raja and W. U. Bajwa, Cloud K-SVD: A collaborative dictionary learning algorithm for big,
distributed data, IEEE Transactions on Signal Processing, vol. 64, no. 1, pp. 173—188, Jan. 2016.
[22] W. Ren, Consensus Based Formation Control Strategies for Multi-Vehicle Systems, in Proceedings of
the Amer-ican Control Conference, 2006, pp. 4237—4242.
[23] A. H. Sayed, Diffusion adaptation over networks. Academic Press Library in Signal Processing, 2013,
vol. 3.
[24] I.D. Schizas, G.B. Giannakis, S.I. Roumeliotis, A. Ribeiro, Consensus in ad hoc WSNs with noisy
links—part II: distributed estimation and smoothing of random signals. IEEE Trans. Signal Process.
56(4), 1650–1666 (2008)
[25] W. Shi, Q. Ling, G. Wu, W. Yin, Extra: an exact first-order algorithm for decentralized consensus
optimization. SIAM J. Optim. 25(2), 944–966 (2015)
[26] W. Shi, Q. Ling, K. Yuan, G. Wu, W. Yin, On the linear convergence of the ADMM in decentralized
consensus optimization. IEEE Trans. Signal Process. 62(7), 1750–1761 (2014)
[27] K. I. Tsianos, S. Lawlor, and M. G. Rabbat, Consensus-based distributed optimization: Practical
issues and applications in large-scale machine learning, in Proceedings of the IEEE Allerton Conference
on Communication, Control, and Computing, IEEE, New York, 2012, pp. 1543–1550,
[28] R. Xin and U. A. Khan, A linear algorithm for optimization over directed graphs with geometric
convergence, IEEE Control Systems Letters, vol. 2, no. 3, pp. 315–320, 2018.
[29] K. Yuan, Q. Ling, and W. Yin, On the convergence of decentralized gradient descent, SIAM Journal
on Optimization, vol. 26, no. 3, pp. 1835–1854, Sep. 2016.
[30] T. Yang, X. Yi, J. Wu, Y. Yuan, D. Wu, Z. Meng, Y. Hong, H. Wang, Z. Lin, and K. H. Johansson,
A survey of distributed optimization, Annual Reviews in Control, vol. 47, pp. 278–305, 2019.
Email address :choiwc@skku.edu