arXiv:2302.04124v2  [physics.geo-ph]  22 Feb 2024AN EXTENDED GAUSS -NEWTON METHOD FOR FULL
WAVEFORM INVERSION
A P REPRINT
Ali Gholami
Institute of Geophysics, Polish Academy of Sciences, Warsa w, Poland
agholami@igf.edu.pl
February 23, 2024
ABSTRACT
Full waveform inversion (FWI) is a large-scale nonlinear il l-posed problem for which computa-
tionally expensive Newton-type methods can become trapped in undesirable local minima, par-
ticularly when the initial model lacks a low-wavenumber com ponent and the recorded data lacks
low-frequency content. A modiﬁcation to the Gauss-Newton ( GN) method is proposed to address
these issues. The standard GN system for multisource multir eceiver FWI is reformulated into an
equivalent matrix equation form, with the solution becomin g a diagonal matrix rather than a vector
as in the standard system. The search direction is transform ed from a vector to a matrix by relaxing
the diagonality constraint, effectively adding a degree of freedom to the subsurface offset axis. The
relaxed system can be explicitly solved with only the invers ion of two small matrices that deblur
the data residual matrix along the source and receiver dimen sions, which simpliﬁes the inversion
of the Hessian matrix. When used to solve the extended source FWI objective function, the Ex-
tended GN (EGN) method integrates the beneﬁts of both model a nd source extension. The EGN
method effectively combines the computational effectiven ess of the reduced FWI method with the
robustness characteristics of extended formulations and o ffers a promising solution for addressing
the challenges of FWI. It bridges the gap between these exten ded formulations and the reduced FWI
method, enhancing inversion robustness while maintaining computational efﬁciency. The robustness
and stability of the EGN algorithm for waveform inversion ar e demonstrated numerically.
1 Introduction
Seismic waveform inversion is a nonlinear optimization pro blem that aims to estimate the physical properties of the
Earth from recorded seismic data. Traditionally, the best e stimate is obtained by minimizing the squared two norm
distance between the computed synthetic seismograms and th e recorded data [see, e.g., 19,27,31]. Iterative methods,
such as Newton-type methods [ 17,19], are commonly used to calculate this estimate. The crucial step in these methods
is to compute a direction in which a new estimate can be search ed, resulting in a better ﬁt to the data. This direction is
determined by solving the Newton system. However, the succe ss of these methods heavily relies on accurately solving
this system at each iteration to estimate a suitable model up date.
The preconditioned steepest-descent (PSD) method is a popu lar algorithm for full waveform inversion (FWI) due to
its computational efﬁciency, as it avoids computing the Hes sian matrix [ 8]. Its main requirement is to compute the
gradient of the misﬁt function with respect to the model para meters (i.e., squared slowness). This can be accomplished
efﬁciently by employing the ﬁrst-order adjoint-state meth od, which involves performing zero-lag cross-correlation
between the forward-propagated source-side waveﬁeld and b ackward-propagated receiver-side waveﬁeld, with the
data residual for the background model serving as the adjoin t source generating the receiver waveﬁeld [ 18]. However,
its convergence rate is relatively slow, necessitating a la rge number of iterations to reach a stationary point. To addr ess
this issue, truncated versions of the Newton method have bee n proposed, which implement the Hessian matrix through
a ﬁnite number of conjugate gradient (CG) iterations [ 17]. In this approach, the Hessian vector products, which are
required at each CG iteration, are performed implicitly usi ng a matrix-free formalism, such as second-order adjointExtended Gauss-Newton method Ali Gholami A P REPRINT
state formulas. This reduces the computational load by intr oducing new wave equations that must be solved for
each CG iteration. However, the singular or ill-conditione d nature of the Hessian matrix can make determining an
appropriate search direction difﬁcult, especially when th e initial model is far from the global solution. Overcoming
these challenges and improving the efﬁcacy and robustness o f FWI methods are ongoing research topics in the ﬁeld.
Several algorithms have been proposed in recent decades to i mprove the performance of FWI. In this paper, we will
look at some relevant methods that aim to address the shortco mings of traditional approaches. One method is to
expand the optimization problem by introducing artiﬁcial p arameters. These parameters are penalized during the
velocity model update, ensuring that the original problem i s reached at the convergence point [ 24]. Model extension
and source extension are two popular approaches to extensio n.
FWI based on model extension works by splitting the model int o short-wavelength (perturbation) and long-wavelength
(background) components. Symes and Kern [ 26], for example, employed separate perturbation models for e ach source,
extending the model along the surface offset or source coord inate. Similarly, the model can be extended along the
subsurface offset, which corresponds to the distance betwe en two subsurface points in the extended Born equation
related to the incident and reﬂected waveﬁelds [ 6,20]. It is also possible to extend along the scattering angle ax is [21]
or the time-lag axis [ 3]. Compared to the standard FWI, these methods are more robus t but their computational and
memory costs can be high due to the increased dimensionality of the problem [ 3].
In the extended-source FWI, the optimization is performed o ver the source extension term [ 15] or the extended wave-
ﬁeld [ 30], in addition to the model parameters, and the algorithm pen alizes the extending parameter while updating
the velocity, ensuring that the physics is satisﬁed at the co nvergence point. This is done in an alternating optimizatio n
framework that solves the constrained FWI problem with a qua dratic penalty formulation. These methods have been
demonstrated to be more robust than the conventional FWI, bu t they have high computational and memory costs. To
address this issue, van Leeuwen and Herrmann [ 29] eliminated the waveﬁeld variable, resulting in a modiﬁed o bjec-
tive function that only included the model parameters. This modiﬁed function was later shown to be equivalent to an
objective function in the standard FWI form with a model-dep endent weighting matrix [ 9,25,28]. The gradient re-
mains very similar to that of the standard FWI in this formula tion; it is the zero-lag cross-correlation between extende d
forward and backward waveﬁelds. The former is calculated by solving an augmented wave equation and the latter is
calculated by back propagating an extended data residual. T he FWI data residual is deblurred along the receiver axis
with a blurring matrix that is the data-space Hessian of the r eceiver-side Green functions to obtain this extended data
residual [ 9]. The associated GN Hessian is also very similar to that of th e standard FWI, except for the extra weighting
matrix and the replacement of the standard reduced waveﬁeld with the extended one [ 9, their equation 25]. In practice,
the Hessian is replaced with a sparse approximation, hence p erforming a PSD optimization [ 29].
In this paper, we propose an alternative extended algorithm for FWI by modifying the GN formulation. We begin
with the standard squared two norm misﬁt function for freque ncy-domain multisource multireceiver FWI and solve
it using the GN method. The GN search direction is a vector tha t solves the GN system in its standard form. We
show that the GN system can be expressed as a matrix equation u sing the relationship between matrix multiplication
and the Hadamard (element-wise) product operation [ 13], with the solution being a diagonal matrix with the search
direction on its main diagonal. This constraint is relaxed b y allowing the search direction to be a matrix rather than
a vector. This relaxation entails introducing an extra degr ee of freedom in the subsurface offset axis for the search
direction, effectively sampling the subsurface offset spa ce in terms of range and orientation [including horizontal a nd
non-horizontal offsets, see e.g., 4,5,24]. More importantly, it leads to a separable Hessian matrix i n which the source
and receiver parts are properly factored, allowing the rela xed system to be explicitly solved. This only necessitates t he
inversion of two separate Hessian matrices of the size of the number of sources and the number of receivers, which
are applied along the source and receiver coordinates of the FWI data residual matrix, respectively. The receiver side
Hessian is the same as in the source extended FWI discussed ab ove. The deblurring effect of the source-side Hessian
is similar along the source coordinate. As a result, unlike t he extended source method, which uses a 1D deblurring
ﬁlter on the data residual along the receiver coordinate, th e extended GN (EGN) method uses a 2D kernel along the
source and receiver coordinates to deblur the data residual s.
The proposed EGN approach can also be used for solving the (re duced) penalty objective function of extended-source
FWI [ 29], offering potential advantages in terms of computational efﬁciency and robustness. By replacing the standard
reduced waveﬁelds with extended waveﬁelds, the EGN method e stablishes a connection between extended waveform
inversion based on model extension and those based on source extension. In this case, the proposed EGN algorithm
lies at the interface between standard reduced FWI, extende d-source FWI, and extended-model FWI. By incorporating
the extended search direction and leveraging the separabil ity of the Hessian matrix, it provides a promising approach
for addressing the FWI problem. The explicit solution of the relaxed system and the potential computational beneﬁts
make the EGN algorithm an intriguing method to explore for en hancing the efﬁciency and effectiveness of FWI.
2Extended Gauss-Newton method Ali Gholami A P REPRINT
The remainder of the paper is organized as follows: we provid e the necessary notation and preliminaries that are not
the main focus of the paper, followed by the introduction of t he EGN theory. We also include details on computing
the reduced search direction from the extended one, selecti ng the step length, increasing efﬁciency through random
projections, and discussing the computational complexity of EGN. Subsequently, we apply EGN to solve the extended-
source FWI. We present three sets of numerical examples to il lustrate the effectiveness of EGN. Finally, we conclude
with discussions and conclusions.
2 Notation and Preliminaries
In this section, we introduce important notation, deﬁnitio ns, and fundamental matrix identities that are utilized thr ough-
out the paper. Vectors and matrices are denoted by bold lower case and uppercase letters, respectively. The transpose
and conjugate transpose of a matrix are represented by the su perscripttandT, respectively. The complex conjugate of
a quantity is denoted by an overline. The Hadamard multiplic ation is denoted by the symbol ◦. The angular frequency
is denoted as ω, the Laplacian as ∆, and the gradient operator as ∇.
For column N-vectorsuandv,/an}b∇acketle{tu,v/an}b∇acket∇i}ht=/an}b∇acketle{tv,u/an}b∇acket∇i}ht=uTvrepresents their inner product, and /ba∇dblu/ba∇dbl2=/radicalbig
/an}b∇acketle{tu,u/an}b∇acket∇i}htdenotes
the two norm of the vector. For M×NmatricesAandB,/an}b∇acketle{tA,B/an}b∇acket∇i}htF=/an}b∇acketle{tB,A/an}b∇acket∇i}htF=trace(ATB)represents the
Frobenius inner product, and /ba∇dblA/ba∇dblF=/radicalbig
/an}b∇acketle{tA,A/an}b∇acket∇i}htFdenotes the Frobenius norm of the matrix. For a scalar functi on
E(u), the gradient ∇E(u)is deﬁned as a column vector that contains the partial deriva tives ofEwith respect to each
component of u. For a vector function F(u), the Jacobian J=∇F(u)is a matrix whose rows consist of the gradients
of the vector components with respect to u. Additionally, diag (u)represents a diagonal matrix with the vector ualong
its main diagonal. These notations and deﬁnitions are emplo yed throughout the paper to facilitate the understanding
of subsequent derivations and discussions.
Consider AandBasM×Nmatrices, and uas anN-length vector. In this case, the ith diagonal element of the
matrixC=Adiag(u)Btis equal to the ith entry of the vector (A◦B)u. This relationship can be expressed as
follows:
Cii=/bracketleftbig
Adiag(u)Bt/bracketrightbig
ii= [(A◦B)u]i, (1)
whereCiirepresents the ith diagonal element of the matrix C[see page 305 of 13]. This equation demonstrates
the correspondence between the ith diagonal entry of the matrix Cand theith entry of the vector resulting from the
Hadamard product of AandB, multiplied by u.
Consider CandDas square invertible matrices of size M×MandN×N, respectively, and UandVas two
rectangular matrices of size M×NandN×Msuch that/parenleftbig
D−VC−1U/parenrightbig
and/parenleftbig
C−UD−1V/parenrightbig
are invertible. In this
case, the following matrix identities hold [ 11]:
/parenleftbig
D−VC−1U/parenrightbig−1VC−1=D−1V/parenleftbig
C−UD−1V/parenrightbig−1, (2)
(βI+VU)−1V=V(βI+UV)−1, (3)
whereβ >0, andIdenotes the identity matrix of an appropriate size. These id entities, in fact, provide efﬁcient
methods for solving normal equations involving the matrice sC,D,U, andV. By utilizing these identities, one can
simplify computation and achieve more efﬁcient solutions f or problems requiring the inversion or manipulation of
rectangular matrices.
3 Theory
The frequency-domain FWI can be formulated as a least-squar es problem, aiming to minimize the misﬁt between the
observed data and the data predicted by the forward operator . The objective function in this formulation is given by
[19]:
minimize
mE(m) =1
2Ns/summationdisplay
s=1/ba∇dblFs(m)−ds/ba∇dbl2
2, (4)
wheremrepresents the model parameters to be estimated. The forwar d operator Fs(m)maps the model space to the
data space, and it is deﬁned as
Fs(m) =PA(m)−1bs. (5)
Here,sdenotes the source index, Nsis the number of sources, and Nris the number of receivers. The observed
datadsand the predicted data Fs(m)are complex-valued vectors of size Nr×1. The forward operator involves the
sampling operator P, which samples the waveﬁeld usat the receiver locations. The waveﬁeld usis computed by
3Extended Gauss-Newton method Ali Gholami A P REPRINT
solving the Helmholtz equation with the squared slowness m, represented by the Helmholtz operator A(m). The
Helmholtz operator consists of the Laplacian operator ∆and the squared slowness term diag (m)weighted by the
square of the angular frequency: A(m) =∆+ω2diag(m).
Newton-type methods are commonly employed to solve the leas t squares problem in equation 4by iteratively lineariz-
ing the objective function. Starting from an initial model m0, the iterative process generates a sequence of models
{mk}using the update equation:
mk+1=mk+αkδmk, (6)
whereαkdenotes the step length and δmkrepresents the search direction. In the subsequent explana tion, we will
assume that the dependency of the variables on the iteration numberkhas been removed for the sake of compact
notation. This means that the variables like mandδmare implicitly understood to represent their values at the c urrent
iteration without explicitly denoting the iteration index . This simpliﬁcation allows for a more concise representati on
of the iterative process and equations.
In the Newton method, the search direction δmis determined by solving the Newton system given by
Hδm=−∇E, (7)
where∇E(m)is the gradient vector and H(m) =∇2E(m)is the Hessian matrix. The gradient vector is calculated
by computing the partial derivatives of Ewith respect to the model parameters,
∇E(m) =Ns/summationdisplay
s=1JT
sδds. (8)
It involves the data residual vectors δds=Fs(m)−ds, which represent the difference between the predicted data
Fs(m)and the observed data ds. The Jacobian matrices Js(m), deﬁned in equation 9, represent the gradients of the
forward operator Fs(m)with respect to the model parameters.
Js(m) =∇Fs(m) =−PA(m)−1∂A(m)
∂mus, (9)
whereA(m)us=bs. The Hessian matrix H(m)is computed by summing the contributions from ﬁrst-order in for-
mation provided by the Jacobian normal matrix and the nonlin ear termRs(m)that captures second-order information,
i.e.
H(m) =Ns/summationdisplay
i=1[Js(m)TJs(m)+Rs(m)]. (10)
It is extremely difﬁcult to solve equation 7with this Hessian matrix because the nonlinear term may resu lt in an indef-
inite Hessian unless the initial model is sufﬁciently close to the global minimum of the objective function [ 19]. The
GN method employs a positive semideﬁnite approximate Hessi an obtained by ignoring the Hessian’s nonlinear compo-
nent. This approximation is used to solve the GN system, whic h determines the search direction. Traditional methods,
such as the CG method, which introduces additional wave-equ ation solves per CG iteration, typically approximate the
solution of this system. However, the issue of convergence t o a local minimum persists [ 17].
In the subsection that follows, we reformulate the GN system by separating the effects of the shots and receivers in the
gradient and Hessian using the Hadamard product. Then, in or der to effectively solve the resulting system and beneﬁt
from the advantages of the model extension [ 3,20,21,24], we extend the GN search direction.
3.1 Extended Gauss-Newton method
The GN search direction, denoted as δm, is computed by solving the following equation:
/bracketleftBiggNs/summationdisplay
s=1JT
sJs/bracketrightBigg
δm=−Ns/summationdisplay
s=1JT
sδds. (11)
Here,Jsrepresents the Jacobian matrix associated with the sth source. To facilitate the notation, we introduce the
source matrix Bas:
B= [b1b2···bNs]. (12)
Additionally, we deﬁne the waveﬁeld matrix Uand the receiver-side Green function matrix Sas follows:
U=ω2BTA−T,S=PA−1. (13)
4Extended Gauss-Newton method Ali Gholami A P REPRINT
Utilizing the deﬁnition of the Jacobian matrix, equation ( 9), we can express the gradient vector as:
Ns/summationdisplay
s=1JT
sδds=−[(ST∆d)◦Ut]e. (14)
In this equation, ∆drepresents the data residual matrix, and eis anNs-length column vector consisting of all ones.
Each column of ∆dcorresponds to the data residual associated with a particul ar source:
∆d= [δd1δd2···δdNs]. (15)
To simplify the ith component of the gradient vector, we apply the relation de ﬁned in equation ( 1):
/bracketleftBiggNs/summationdisplay
s=1JT
sδds/bracketrightBigg
i=−[ST∆dU]i, (16)
wherei= 1,...,N . Additionally, the GN Hessian matrix can be rewritten as:
Ns/summationdisplay
s=1JT
sJs= (STS)◦(UTU). (17)
By utilizing equation ( 1), we can rewrite the GN system in equation ( 11) in an equivalent matrix equation form:
[STSdiag(δm)UTU]ii= [ST∆dU]ii, (18)
fori= 1,...,N . Solving the standard GN system, equation ( 11), is indeed equivalent to solving equation ( 18) for
δm. So far, we have simply reformulated the GN system into an alt ernative expression. While solving equation
(18) remains a challenging task, the newly formulated represen tation offers increased ﬂexibility, particularly when
considering extensions to the model. The EGN method departs from equation ( 18) by relaxing the diagonal constraint
on the matrix diag (δm)and considering the full equation. We introduce the extende d search direction ∆m, allowing
its off-diagonal coefﬁcients to have nonzero values. There fore, the EGN search direction solves the following Sylvest er
matrix equation:
STS∆mUTU=ST∆dU. (19)
It is worth noting that this equation reveals the separabili ty of the Hessian matrix in the EGN formulation, making it
easier to invert compared to the non-separable GN Hessian in the original formulation, equation ( 11). Also, equation
(19) is obtained due to the full relaxation of the diagonal const raint, however, partial relaxations are also possible but
may necessitate more intricate equation manipulation [e.g .,14].
A regularization term can be introduced to penalize the off- diagonal elements when solving equation ( 19). However,
it should be noted that this approach can be computationally and memory intensive due to the size of the resulting
solution, which is of size N×N. To explicitly solve equation ( 19), we obtain:
∆m= (STS+µSI)−1ST∆dU(UTU+µUI)−1, (20)
whereµSandµUare damping parameters greater than zero. These parameters ensure a unique solution and help
mitigate the ill-conditioning of the matrix inversion. Usi ng the identity in equation ( 3), we can rewrite equation ( 20)
as:
∆m=ST∆deU, (21)
where∆deis deﬁned as:
∆de=H−1
r∆dH−1
s. (22)
Here,HrandHsare the receiver-side and source-side Hessian matrices, re spectively, given by:
Hr=SST+µSI,Hs=UUT+µUI. (23)
Derived from equation ( 21), we observe that the coefﬁcients of ∆mcan be straightforwardly calculated by performing
zero-lag cross-correlation between the forward-propagat ed source-side waveﬁelds and the receiver-side waveﬁelds
obtained by back-propagating ∆de. Consequently, the primary focus of EGN lies in the calculat ion of the extended
data residual ∆deduring the inversion process. This is achieved by deblurrin g∆dalong the source and receiver
dimensions using the inverses of the Hessian matrices HsandHr.
5Extended Gauss-Newton method Ali Gholami A P REPRINT
3.2 Interpretation of the extended direction
The solution δmobtained from equation ( 18) also satisﬁes the linearized (Born) modeling equation in t he least squares
sense:
Sdiag(δm)UT= ∆d. (24)
In this equation, the (r,i)-th element of matrix Srepresents the Green’s function between the r-th receiver and the i-th
subsurface point, and the (s,j)-th element of matrix Urepresents the Green’s function between the s-th source and
thej-th subsurface point. Since only the diagonal elements of di ag(δm)can be non-zero, the scattered data matrix
∆dis constructed only from those source waveﬁelds that arrive at and reﬂect from the same subsurface point. This is
shown in Figure 1.
By the same token, the solution ∆mobtained from equation ( 19) also satisﬁes the extended Born modeling equation
in the least squares sense:
S∆mUT= ∆d. (25)
In this case, the off-diagonal elements of ∆malso contribute to the formation of the data residual matrix . The diagonal
elements ∆miicorrespond to the waveﬁelds arriving at and reﬂecting from t he same subsurface point, while the off-
diagonal elements ∆mij(wherei/ne}ationslash=j) correspond to waveﬁelds arriving at the i-th point but reﬂecting from the j-th
point. The distance between these subsurface points can be i nterpreted as the subsurface offset [ 6,24]. Thus, the EGN
formulation relaxes the constraint of diagonality and prov ides an explanation of extended Born modeling from a linear
algebra perspective.
Figure 2illustrates the subsurface model and the corresponding pat tern in matrix ∆m. Here is a clear description
of the visualization: In Figure 2a, we have a 5 by 5 subsurface model. The reference cell, (3, 3) , is shown in black.
Different colors are assigned to cells that are neighboring (3, 3) along different directions and distances. The colori ng
scheme is as follows:
• Cells (3, 2) and (3, 4) are colored magenta, representing th e immediate horizontal neighbors of (3, 3).
• Cells (3, 1) and (3, 5) have a larger horizontal subsurface o ffset and are colored red.
• Cells (2, 3) and (4, 3) are colored cyan, representing the im mediate vertical neighbors of (3, 3).
• Cells (1, 3) and (5, 3) have a larger vertical subsurface off set and are colored blue.
• Different colors are also assigned to cells along diagonal directions.
In Figure 2b, we visualize matrix ∆m, which has a size of 25 by 25 to accommodate the pattern. The go al is to
represent the relationships and positions of cells in the su bsurface model through the pattern in ∆m. To achieve this,
we reshape the original 5 by 5 matrix into a column vector and a ssign it to column 13 of ∆m, ensuring that the
reference cell (3, 3) aligns along the main diagonal of ∆m. We repeat this procedure for all values of iin the range 1
to 5 andjin the range 1 to 5, placing each reshaped column vector in the associated column of ∆msuch that cell (i,j)
aligns along the main diagonal. By following this process, t he cells neighboring (3, 3) in the subsurface, which were
assigned different colors, will be aligned along different sub-diagonals of matrix ∆m. This pattern in ∆mreﬂects
the relationships and positions of cells in the subsurface m odel, allowing us to visually understand their distances an d
directions from the reference cell (3, 3).
Generally, the range and orientation of the subsurface offs ets determine how the nonzero patterns in ∆mchange. It
takes a lot of memory and computational power to solve the ass ociated system for a general pattern. Hou and Symes
[14] proposed an effective asymptotic (high-frequency) appro ximate inverse that can work for a limited number of
subsurface offsets (partial relaxation). By completely sa mpling the subsurface offset in range and orientation, we ar e
allowed to fully relax the diagonal constraint in this paper . This is accomplished by allowing nonzero values for all of
the coefﬁcients in the matrix ∆m. With the diagonal constraint relaxed, the system can be sol ved more simply and
explicitly, which reduces the computational and memory dem ands of the conventional extended Born equation. This
method offers a more thorough and precise solution for the en tire range of subsurface offsets.
It should be noted that the emphasis of this paper is primaril y on the full relaxation of the diagonal constraint in matrix
∆mwhich allows for an explicit and exact solution for the assoc iated system. While partial relaxation can certainly
be applied by considering a variety of subsurface offsets, i t is beyond the scope of this study. Further investigation an d
analysis would be required to determine the challenges asso ciated with partial relaxation, which could be addressed in
broader studies or future research speciﬁcally focused on e xploring the range and relaxation considerations.
6Extended Gauss-Newton method Ali Gholami A P REPRINT
Figure 1: Simpliﬁed subsurface model with a single source an d receiver. The black wave represents the incident wave
propagating from the source to the i-th reﬂecting point in the subsurface. At the receiver locat ion, two reﬂected waves
are observed. The blue wave represents the reﬂection from th e samei-th point, characterized by the diagonal reﬂection
coefﬁcient ∆mii. The red wave represents a reﬂection from the j-th point, characterized by the off-diagonal reﬂection
coefﬁcient ∆mij.
Figure 2: Subsurface model and pattern in matrix ∆m. (a) Visualization of a 5 by 5 subsurface model. The black cel l
(3, 3) serves as the reference cell. Different colors are ass igned to cells neighboring (3, 3) along different direction s
and distances, highlighting their relationships in the mod el. (b) The corresponding pattern in matrix ∆m, constructed
to represent the relationships and positions of cells in the subsurface model. Matrix ∆mhas a size of 25 by 25, with
each column containing a reshaped column vector from the sub surface model, aligning the respective reference cell
along the main diagonal of ∆m. The pattern in ∆mreveals the alignment of neighboring cells based on their di stances
and directions from the reference cell (3, 3).
3.3 Computing δmfrom∆m
The proposed algorithm offers a signiﬁcant advantage in ter ms of memory efﬁciency for implementation of model
extension. The construction of the extended search directi on matrix ∆mis typically challenging due to its large size
ofN×N. However, if we have access to ∆de, each individual coefﬁcient of ∆mcan be computed independently by
cross-correlating the corresponding forward-propagated source-side waveﬁeld with the backward-propagated receiv er-
side waveﬁeld. Thus, compared to the original GN, EGN will no t signiﬁcantly increase the memory requirement. This
property is a key advantage of our algorithm compared to exis ting methods that rely on model extension, which require
storing the model for the entire desired range of subsurface offsets in memory [ 4,5,7,20,24,33].
We compute the desired search direction δmby averaging the extended coefﬁcients over a ball surroundi ng each
physical point. This approach is based on the observation th at the reﬂection energy tends to interfere constructively
within the ﬁrst Fresnel zone [ 16,22]. It is worth noting that a similar idea was employed by Yang e t al. [ 33], where
7Extended Gauss-Newton method Ali Gholami A P REPRINT
they averaged the coefﬁcients over a horizontal disk center ed at the physical point. Our approach extends this concept
by considering a ball instead of a disk, enabling more compre hensive averaging and capturing the interference effects
in all directions around each physical point.
The computation of the search direction is described by
δm(x) =Re/parenleftBigg/summationdisplay
s/summationdisplay
ω/summationdisplay
hφ(h)/parenleftbigg∂A(m)
∂mu(ω,x−h;xs)/parenrightbiggT
v(ω,x+h;xs)/parenrightBigg
. (26)
Assuming that the extended data residual ∆dein equation 22has been correctly computed, the search direction can
be obtained by performing a multiplication operation betwe en the source and receiver waveﬁelds. We can see that
the computed waveﬁelds can be space-shifted to compute the e xtended coefﬁcient corresponding to each subsurface
half-offset h, eliminating the need to solve additional simulation probl ems for each background model.
In detail, the equation involves the following steps:
1. The source waveﬁeld u(ω,x;xs)is computed for each source location xsand for a given frequency ω. This
waveﬁeld represents the wave propagation from the physical sourceb(ω,x;xs)to the subsurface location x.
They are multiplied by the radiation pattern matrix∂A(m)
∂m. We keep this form for different parameterizations.
2. The adjoint source PTδde(ω;xs)is used to generate the receiver waveﬁeld v(ω,x;xs). This adjoint wave-
ﬁeld represents the wave propagation from the receiver loca tions to the subsurface location x.
3. The product of these waveﬁelds is computed and summed over the desired subsurface half-offset vector h,
frequency range, and source range. φ(h)is a weight function [ 14]. It should be noted that the effect of the
least squares solve of the extended system is encoded direct ly in the extended data residual, ∆de. As a result,
there is no need to calculate and store individual subsurfac e offset coefﬁcients and perform separate averaging
operations. Instead, the averaging process is performed on -the-ﬂy as soon as the two waveﬁelds are available.
4. The real part of the resulting quantity is taken, represen ting the search direction at the subsurface location x.
3.4 Step length selection
After computing the step direction δm, the next step is to determine the step length αfor updating the model. The
ideal choice for αwould be the global minimizer of the data misﬁt function alon g the step direction. However, this
minimizer is generally difﬁcult to obtain, and approximate minimizers are typically used in practice. One approach
to approximate the minimizer is through standard line searc h methods, which involve iteratively testing different
step lengths and selecting the one that yields the lowest mis ﬁt. Alternatively, an approximate minimizer can be
obtained by setting the gradient of the misﬁt function with r espect toαequal to zero, which transforms the step length
determination into a ﬁxed-point problem. This is done using the equation:
α=/an}b∇acketle{tS(α)diag(δm)U(α)T,∆d/an}b∇acket∇i}htF
/an}b∇acketle{tS(α)diag(δm)U(α)T,S(0)diag(δm)U(α)T/an}b∇acket∇i}htF=:ϕ(α), (27)
whereS(α)andU(α)are constructed by mk+αδm. This equation deﬁnes a function ϕ(α)that represents the
ﬁxed-point iteration for ﬁnding a local minimizer of the mis ﬁt function.
The ﬁxed-point iteration is performed by starting with an in itial guess α0= 0 and iteratively updating αusing the
equation:
αl+1=ϕ(αl), (28)
wherelrepresents the iteration number. The ﬁrst iteration, α1, corresponds to the step length proposed by Pratt et al.
[19]. In cases where the nonlinearity of the data is not signiﬁca nt, the ﬁrst iteration often provides an accurate estimate
of the step length. However, when the data nonlinearity is hi gh, more iterations may be required to improve the
estimate of the step length.
3.5 Randomized EGN
In order to reduce the computational cost associated with so lving the EGN system, equation ( 25), in a least squares
sense, we employ random projection schemes [ 32]. These schemes allow us to effectively reduce the dimensio ns of
the system, making it more computationally efﬁcient to solv e.
We introduce a random projection (sketching) matrix Πa×bof sizea×b, wherebis much smaller than a, and it
satisﬁes the property
E(Πa×bΠT
a×b) =I, (29)
8Extended Gauss-Newton method Ali Gholami A P REPRINT
whereEdenotes the expectation. By applying this projection matri x, we can work with the projected matrices SΠ
andUΠ, obtained by multiplying the original matrices SandUbyΠT
Nr×NpandΠT
Ns×Nq. This compresses the data
residual matrix, ∆d, of sizeNr×Nsto∆dΠ=ΠT
Nr×Np∆dΠNs×Nqof sizeNp×Nq.
Various sketching matrices can be used for this purpose, suc h as random Gaussian sketch, random phase sketch,
random sampling, and count sketch [see 2, for a complete review]. The main advantage of using random p rojections
is that the resulting sketched system, given by equation ( 30), has a signiﬁcantly smaller dimension compared to the
original system. This reduction is particularly beneﬁcial for the receiver dimension, as the number of receivers is
typically much larger than the number of sources in practica l settings. By leveraging random projections, we can
achieve computational efﬁciency by effectively reducing t he size of the system and solving the sketched version of the
EGN system, i.e.
SΠ∆mUT
Π= ∆dΠ. (30)
3.6 Computational complexity
When comparing with the computational complexity of the ste epest-descent method, the primary computational cost
in our approach lies in the deblurring step of the data residu al matrix, as described in equations 22or39. This step
involves the computation of two Hessian matrices, HsandHr, and the application of their inverses to the source
and receiver coordinates of the data residual matrix. The si ze of these matrices is Ns×NsforHsandNr×Nrfor
Hr. Fortunately, these matrices can be constructed explicitl y and inverted using direct methods. The construction
ofHsdoes not impose additional computational cost since the req uired forward wave-equation solves are already
available from computing the data residuals. To build Hr, we only need Nradditional backward wave-equation solves.
However, by employing the random sketching strategy discus sed earlier, we can decrease the total number of required
wave-equation solves. In this case, we only need Npextra wave-equation solves compared to the number required
for the steepest-descent method. By utilizing the random sk etching approach, we achieve a signiﬁcant reduction
in computational burden by minimizing the number of wave-eq uation solves required for the deblurring step. This
reduction in computational cost enhances the efﬁciency and practicality of our approach while still preserving its
extension properties for robust inversion.
4 Application of EGN to extended source FWI
In the extended source FWI framework, we aim to increase the r obustness of waveform inversion by incorporating
wave-equation relaxation. While the objective function as sociated with this approach can be formulated in bivariate
form [ 1,15,30], it can also be deﬁned in a univariate form in the reduced spa ce by employing variable projection.
This results in a penalty objective function expressed as a w eighted misﬁt norm via
Eβ(m) =1
2Ns/summationdisplay
s=1/ba∇dblFs(m)−ds/ba∇dbl2
Q(m)−1, (31)
[9,28]. The penalty objective function, denoted as Eβ(m), is deﬁned as the sum of weighted misﬁt norms of the data
residuals. The model-dependent weights are determined by t he inverse of the covariance matrix Q(m). Speciﬁcally,
/ba∇dbly/ba∇dbl2
Q(m)=yTQ(m)ydenotes the weighted norm of vector ywith respect to Q(m), andQ(m)is deﬁned as
Q(m) =1
βS(m)S(m)T+I, (32)
whereβis a penalty parameter that penalizes wave-equation relaxa tion. It plays a crucial role in controlling the amount
of wave-equation relaxation in the inversion process. By in creasing the value of β, we impose a stronger penalty on
the wave-equation constraint, effectively reducing the re laxation and approaching the original waveform inversion
problem. At the beginning of the inversion process, a small v alue is assigned to β. As the iterations progress, the value
ofβmay be increased gradually, following a penalty continuati on strategy. In the limit as βapproaches inﬁnity, the
penalty objective function Eβreduces to the original objective function E, which represents the standard waveform
inversion without wave-equation relaxation.
To minimize Eβ(m), standard gradient-based optimization methods can be empl oyed. The GN method leads to a
linear system for the search direction δmas [9,29]
/bracketleftBiggNs/summationdisplay
s=1JT
sQ−1Js/bracketrightBigg
δm=−Ns/summationdisplay
s=1JT
sQ−1δds. (33)
9Extended Gauss-Newton method Ali Gholami A P REPRINT
In this equation, the Jacobian matrix Jsis deﬁned similar to equation ( 9), but with the extended waveﬁelds uβ
s, which
are deﬁned as
uβ
s= argmin
u/ba∇dblPu−ds/ba∇dbl2
2+β/ba∇dblAu−bs/ba∇dbl2
2 (34a)
=A−1(bs−1
βSTQ−1δds). (34b)
By transforming equation ( 33) into an equivalent matrix equation form, we arrive at the fo llowing equation which can
be solved for the search direction:
[STQ−1Sdiag(δm)UT
βUβ]ii= [STQ−1∆dUβ]ii, (35)
fori= 1,...N . In this equation, the matrix Uβincludes the extended waveﬁelds as its rows and is explicitl y deﬁned
as
Uβ=ω2/bracketleftbigg
B−1
βSTQ−1∆d/bracketrightbiggT
A−T. (36)
The EGN search direction for the extended source FWI is obtai ned by solving
STQ−1S∆mUT
βUβ=STQ−1∆dUβ. (37)
By using the matrix equalities in equations 2and3and the deﬁnition of Q, equation 32, we get the following explicit
solution for equation 37:
∆m=ST∆deUβ, (38)
where
∆de=H−1
r∆dH−1
s. (39)
The Hessian matrices HrandHsare deﬁned as
Hr=ǫ/parenleftbig
SST+ǫµSI/parenrightbig
,Hs=UβUT
β+µUI, (40)
whereǫ=β/(β+µS). As expected, equations 38-40reduce to equations 21-23forβ→ ∞ .
In the context of waveform reconstruction inversion (WRI), a sparse approximation is commonly employed for the
GN Hessian matrix JT
sQ−1Js[29]. This approximation replaces the full Hessian matrix in eq uation ( 33) with a sparse
approximation, given by βdiag(ω2uβ
s)Tdiag(ω2uβ
s). When applying this sparse approximation, we observe that t he
extended search direction in WRI remains deﬁned by equation s38to40. However, there is a simple modiﬁcation in
the receiver-side Hessian matrix Hr, which becomes Hr=SST+βI.
For the ease of comparison, the extended search direction an d associated parameters for both the reduced FWI and
penalty FWI are summarized in Table 1. The algorithms for these two cases are very similar, with th e only difference
lying in their incident waveﬁelds, which in turn lead to diff erent source-side waveﬁeld matrices: Ufor standard FWI
andUβfor penalty FWI. This distinction arises from the concept of extended sources, as deﬁned in equation ( 36):
bs−1
βSTQ−1δds. The extended source consists of two terms. The ﬁrst term rep resents the primary source, bs,
while the second term represents a secondary source, denote d asϕs=−1
βSTQ−1δds. These secondary sources
are obtained by solving the scattered data equation in a leas t squares sense: Sϕs=−δds. The interpretation of this
equation is straightforward: the data residuals from the ba ckground model are inverted in a least squares sense to
obtain the corresponding scattering source. The damping pa rameterβplays a crucial role in this process, allowing us
to ﬁnd a minimum energy source that explains the scattered da ta. When this estimated scattering source is added to
the physical source, it partially accounts for multiscatte ring effects and leads to an improved linearization of the FW I
forward problem [ 10]. However, this improvement in the incident waveﬁeld is obt ained by additional wave-equation
solves compared to the reduced waveﬁeld used in reduced FWI. The choice of a large damping parameter effectively
removes the contribution of these secondary sources, reduc ing the extended waveﬁelds to the reduced waveﬁelds,
which correspond to the standard FWI case.
5 NUMERICAL EXAMPLES
In this section, we assess the performance of the EGN method o n various 2D monoparameter synthetic examples. We
consider different acquisition settings, including trans mission data inversion, reﬂection-dominated data from sur face
acquisition, simultaneous inversion of multiple frequenc ies, and multiscale inversion using frequency continuatio n.
10Extended Gauss-Newton method Ali Gholami A P REPRINT
Table 1: The formula of extended search direction and the ass ociated parameters for the EGN method applied to the
FWI problem with reduced objective, equation 4, and penalty objective, equation 31.
∆m=ǫST(SST+ǫµSI)−1∆d(UUT+µUI)−1U
method ǫ SUs: us δbs δds
reduced 1PA−1ω2uT
sA−1[bs+δbs] 0 Sbs−ds
penaltyβ
β+µSPA−1ω2uT
sA−1[bs+δbs]−ST(SST+βI)−1δdsSbs−ds
To enable simultaneous inversion of multiple frequencies, we need to solve a matrix equation known as the generalized
Sylvester equation [ 12]. This equation takes the form:
/summationdisplay
ωST
ωSω∆mUT
ωUω=/summationdisplay
ωST
ω∆dωUω, (41)
where the subscript ωindicates the frequency dependence. It is important to note that the range of ωshould be
symmetric to ensure a real-valued result and to maintain con sistency with the fact that the gradient of the real-valued
misﬁt function with respect to real-valued parameters is al so real. However, solving this generalized Sylvester equat ion
efﬁciently, even for two frequencies, is challenging and re mains an open research problem. In this study, we address
this issue by separately and in parallel inverting differen t positive frequencies. The EGN step direction is then obtai ned
by averaging the results from individual frequencies and ta king its real value.
To emphasize the effect of the search direction extension, w e refrain from applying speciﬁc regularization or smoothin g
to the step direction. Additionally, in the EGN algorithm, t he damping parameters µSandµUin the Hessian matrices
are set to be a small fraction (0.01) of the maximum eigenvalu e of their respective matrices. The step length is
determined automatically at each iteration using the ﬁxed- point iteration method described by equation ( 28). For the
tests conducted in this study, we use the step length provide d by the ﬁrst iteration. This makes the inversion free of
parameters for ﬁne-tuning and automates the selection of th e essential EGN parameters. By automating the parameter
selection procedure, the algorithm strikes a reasonable ba lance between efﬁciency and robustness. It decreases the
dependence on user expertise while increasing the consiste ncy and effectiveness of the inversion process.
In our numerical examples, we employ the following inversio n methods:
1. PSD method: The search direction is determined by equatio n (11) while approximating the GN Hessian with
a sparse approximation, known as the pseudo-Hessian matrix ,JT
sJs≈diag(ω2us)Tdiag(ω2us)[23]. This
approximation only considers the diagonal elements of the s ource-side Hessian matrix UTUand neglects the
diagonal elements of the receiver-side Hessian matrix STS. Thus, it partially accounts for the geometrical
spreading phenomenon.
2. GN method: The search direction is determined by the GN for mulation in equation ( 11). More speciﬁcally,
we utilize the damped Hessian JT
sJs+µI, whereµis equal to 0.01 of the maximum eigenvalue of JT
sJs.
3. EGN solving the reduced FWI: The search direction is deter mined by equation ( 26), where the source wave-
ﬁelds are deﬁned as us=A(m)−1bs, and the extended data residual ∆dedeﬁning the receiver waveﬁelds
is computed using equation ( 22).
4. EGN solving the penalty FWI: The search direction is deter mined by equation ( 26), where the source wave-
ﬁelds are deﬁned as in equation ( 34b) and the extended data residual ∆dedeﬁning the receiver waveﬁelds is
computed using equation ( 39).
We want to emphasize that our main focus in this paper is on ach ieving complete relaxation of the diagonality con-
straint and obtaining an exact solution for the resulting EG N system. In most cases, the search direction extracted at
zero subsurface offset performs satisfactorily. Conseque ntly, in many of our numerical examples, the EGN algorithm
primarily utilizes the diagonal coefﬁcients of the extende d search direction. This means that equation ( 26) is evaluated
only forh=0or using the delta function as the weighting function φ(h). Note that the EGN method with h=0
differs from the original GN method. In the former, the exten ded search direction ∆mis initially computed by ﬁtting
data residuals in a least-squares sense, followed by the ext raction of its diagonal as δm. However, in the latter, δmis
directly computed by ﬁtting data residuals in a least-squar es sense. To further support our theoretical framework, we
also demonstrate the potential improvement in results by av eraging the coefﬁcients within the half-wavelength width.
Speciﬁcally, we consider the case for |h| ≤1
4λ, whereλis the dominant wavelength. In this case, we introduce a sim-
ple weight function φ(h)that decreases exponentially with |h|. However, determination of the optimum subsurface
offset range and weight function is beyond the scope of this s tudy and is left for future investigation.
11Extended Gauss-Newton method Ali Gholami A P REPRINT
5.1 Camembert model example
We evaluate the performance of the proposed method using the challenging “Camembert” model [ 8]. This model
consists of a circular anomaly with a velocity of 4.6 km/s emb edded in a homogeneous background with a velocity of
4.0 km/s (Figure 3a). The dimensions of the model are 4.8 km in distance and 6 km i n depth, with a grid spacing of
35.5 m. For the crosshole acquisition setup, we deploy 13 equ ally spaced sources on the left side of the model and
170 equally spaced receivers vertically on the opposite sid e, simulating a crosshole seismic experiment. The source
signature used in this study is a 10 Hz Ricker wavelet. The pre sence of a relatively large anomaly diameter makes the
inverse problem nonlinear and challenging. The convergenc e of local optimization algorithms in such cases strongly
depends on the initial model. In this study, we initiate the i nversion from the homogeneous background model (Figure
3b) to ensure that the problem remains in the nonlinear regime of FWI. We perform one cycle of inversion, meaning
that we do not follow a multiscale approach, and all frequenc ies in the data (ranging from 3 Hz to 25 Hz with a 1 Hz
frequency interval) are inverted simultaneously.
We compare the velocity models obtained after 50 iterations using different inversion methods: PSD (Figure 3c), GN
(Figure 3d), EGN solving the reduced FWI (Figure 3e), and EGN solving the penalty FWI (Figure 3f), both with
h=0. We observe that the classical methods (PSD and GN) fail to re cover the model due to severe cycle-skipping. In
contrast, the EGN methods effectively mitigate cycle-skip ping, resulting in reconstructed models (Figures 3e-f) that
closely resemble the ground truth model. It is worth noting t hat Figures 3e and 3f are visually indistinguishable, but
the penalty FWI shows a faster convergence rate, as indicate d by the associated misﬁt function in Figure 4(blue curve
versus green curve). We can also observe from Figure 4that GN exhibits a faster convergence rate than PSD, but
the estimated model (Figure 3d) contains more artifacts while better ﬁtting the data. Thi s suggests that both PSD and
GN converge to a stationary point, which is an undesirable lo cal minimum. Therefore, we do not present the results
obtained from the GN method in the subsequent analysis due to its inefﬁciency.
To demonstrate the effect of using the off-diagonal coefﬁci ents of∆m, we run the EGN method while computing δm
by averaging the extended coefﬁcients within the half-wave length width. The results obtained using the EGN method
for both the reduced and penalty FWI with |h| ≤1
4λare shown in Figures 3g-h. By comparing these ﬁgures with
Figures 3e-f, we observe that averaging over nonzero subsurface offs ets leads to an improvement in the velocity model.
This improvement is also evident from the associated conver gence curves in Figure 4(magenta and cyan curves versus
blue and green curves).
In Figure 5, we compare the model perturbation obtained during the ﬁrst ﬁve iterations for various methods used in
building the Camembert model. Starting at the top row (ﬁrst i teration) and moving down (up to the ﬁfth iteration),
each row in the subplots represents the model perturbation t hat was obtained after a speciﬁc number of iterations. We
can see that the perturbation produced by PSD (Figure 5a) and GN (Figure 5b) primarily includes the top and bottom
boundaries of the circular anomaly, demonstrating that the y become stuck in a local minimum. This observation is in
line with the characteristics of these techniques, which re ly on the ﬁrst-order Born scattering theory.
The EGN method signiﬁcantly enhances the estimate by gradua lly building the anomaly from its edge into its center,
while still only using the diagonal coefﬁcients of the exten ded search direction (Figure 5c). The performance is
further enhanced when applied to the penalty FWI due to the im provement in the incident waveﬁeld quality (Figure
5d). When the reduced FWI is still used and the off-diagonal co efﬁcients are added, a signiﬁcant improvement is
made (Figure 5e). When the off-diagonal coefﬁcients are used in the contex t of EGN solving the penalty FWI, the
greatest improvement is seen (Figure 5f). In this case, a signiﬁcant portion of the anomaly is recov ered even after the
ﬁrst iteration. The ability of EGN to invert multiscattered data as a result of the extension can be used to justify the
improvements.
5.2 Marmousi model example
We further evaluate the performance of the proposed EGN meth od in the inversion of reﬂection-dominated data using
surface acquisition. The true velocity model is shown in Fig ure6a, representing a subsurface model with dimensions
of 9.2 km width and 3 km depth, discretized with a 20 m grid inte rval. The ﬁxed spread acquisition setup consists of 47
equally-spaced sources and 154 equally-spaced receivers l ocated on the top side of the model. To mitigate boundary
effects, a perfectly matched layer (PML) absorbing boundar y condition is implemented, and a Ricker wavelet with an
8 Hz dominant frequency is used as the source signature.
We initiate the inversion process with a 1D initial model tha t linearly increases in depth from 1.5 km/s to 4.0 km/s.
Simultaneous inversion of all frequencies in the data is per formed, covering the range of 3 Hz to 13 Hz with a frequency
interval of 0.5 Hz. The obtained velocity models after 500 it erations of the PSD method and the EGN method, solving
the reduced FWI, are presented in Figures 6b and 6c, respectively. Additionally, the velocity model resulti ng from
12Extended Gauss-Newton method Ali Gholami A P REPRINT
0 2 40 2 4 6
4.6 km/s
4.0 km/s
0 2 40 2 4 6
0 2 40 2 4 6
0 2 40 2 4 6
0 2 40 2 4 6
0 2 40 2 4 6
0 2 40 2 4 6
0 2 40 2 4 6
Figure 3: Camembert model example. The (a) true velocity mod el and (b) initial model. (c-h) Final velocity models
inferred after 50 iterations of (c) PSD, (d) GN, (e) EGN solvi ng the reduced FWI with h=0, (f) EGN solving the
penalty FWI with h=0, (g) EGN solving the reduced FWI with |h| ≤1
4λ, (h) EGN solving the penalty FWI with
|h| ≤1
4λ.
the EGN method solving the penalty FWI is shown in Figure 6d. The associated convergence behavior of the misﬁt
functions versus iteration is illustrated in Figure 7.
It is evident that the PSD method failed to converge to a reaso nable solution, as shown in Figure 6b. The corresponding
misﬁt curve exhibited slow convergence towards an undesire d local minimum. In contrast, both EGN algorithms,
starting from the same initial model, successfully converg ed to accurate solutions, as shown in Figures 6c and 6d, with
rapid convergence of the associated misﬁt curves. Notably, the EGN method solving the penalty FWI exhibited even
faster convergence compared to the EGN method solving the re duced FWI. Although not presented here, it is worth
mentioning that the results obtained for |h| ≤1
4λwere similar to those achieved with h=0, as shown in Figures 6c
and6d.
5.3 Overthrust model example
We assess the EGN method against the Overthrust model and fol low a multiscale inversion approach. The subsurface
model has dimensions of 20 km width and 4.6 km depth, discreti zed with a 25 m grid interval (Figure 8a). The
ﬁxed spread acquisition consists of 134 equally-spaced sou rces and 134 equally-spaced receivers on the top side of
the model. We implement a PML absorbing boundary condition a round the model and use a Ricker wavelet with a
dominant frequency of 10 Hz as the source signature. We start the inversion from a strongly smoothed initial model
(Figure 8b) and perform one cycle of inversion using multiscale frequ ency continuation from 3 Hz to 13 Hz with a
0.5 Hz frequency interval. Each frequency is inverted indiv idually with 15 iterations per frequency, and the estimated
model from each frequency is used as the starting model for th e next frequency. The ﬁnal results obtained by the
PSD and EGN methods, solving the reduced FWI, are shown in Fig ures 8c and d, respectively. The results obtained
using EGN for penalty FWI were similar to those obtained for r educed FWI with h=0(Figure 8d). Figure 8c
demonstrates that the result obtained by the PSD method is in accurate and includes artifacts, while the EGN result
is accurate without artifacts. A direct comparison among th e true model, the initial model, and the estimated models
13Extended Gauss-Newton method Ali Gholami A P REPRINT
Figure 4: Trajectory of the misﬁt function versus iteration for the Camembert model obtained by different methods
(Figures 3c-f). The curves represent the misﬁt function evolution for the following methods: PSD (red line), GN
(black line), EGN solving the reduced FWI with h=0(green line), EGN solving the penalty FWI with h=0(blue
line), EGN solving the reduced FWI with |h| ≤1
4λ(magenta line), and EGN solving the penalty FWI with |h| ≤1
4λ
(cyan line).
along three vertical logs indicated by white dashed lines on Figure 8a is shown in Figure 9. Additionally, the associated
convergence curves in Figure 10show that EGN exhibits much faster convergence compared to P SD.
Furthermore, we examined the effect of each Hessian matrix HsandHrseparately. Figure 8e shows the result
obtained by EGN using only Hr, while Figure 8f is obtained using only Hs. In this example, since the same number
of sources and receivers were used at the surface, both HsandHrhave a similar effect and generate high-resolution
models. However, from the associated convergence curves (F igure 10), we observe that Hrbetter ﬁts low frequencies,
whileHsachieves a lower misﬁt at high frequencies. When both matric es are used by EGN, an improved misﬁt is
obtained at both low and high frequencies. Moreover, we ﬁnd t hatHsmay be a better alternative to the traditional
pseudo-Hessian matrix [ 23].Hsis formed by UUTand properly removes the effect of the Hessian from the sourc e
dimension of the data residuals, while the pseudo-Hessian m atrix uses the diagonal of this matrix and simply scales
the gradient. By comparing Figures 8c and f, we can see that Hsis more effective.
5.4 Examples with randomized EGN
Finally, using the same parameters as the previous examples , we assess the performance of the EGN method against
source-receiver sketching. We employ the simplest form of E GN that solves the reduced FWI with h=0. The ran-
domized EGN reduces to the deterministic algorithm when the sketching matrices are identity matrices. We employ
sketching matrices with random Gaussian entries. For the Ca membert and Marmousi examples, where multiple fre-
quencies are inverted at each iteration, we set Np=Nq= 10 . For the Overthrust example, where a single frequency is
inverted at each iteration, we set Np=Nq= 30 . The ﬁnal results obtained by the randomized EGN method are s hown
in Figure 11. By comparing Figures 11(a-c) with the associated deterministic results in Figures 3(e),6(c), and 8(d), we
observe that the randomized EGN method still produces high- resolution velocity models while reducing the overall
number of required wave-equation solves by a factor of 9, 10, and 4, respectively, compared to their deterministic
counterparts.
6 Discussions
The proposed EGN method offers a novel approach to FWI, expan ding upon the traditional GN method by extending
the search direction along the subsurface offset. This exte nsion allows for a more comprehensive exploration of the
model space, resulting in improved inversion results. By in corporating all possible subsurface offsets in the range an d
14Extended Gauss-Newton method Ali Gholami A P REPRINT
4.8 km6.0 km
Figure 5: Comparison of model perturbation accumulated in t he ﬁrst 5 iterations for different FWI methods. The ﬁgure
displays subplots (a) to (f), each corresponding to a differ ent method used in constructing the Camembert model. The
rows represent the model perturbation obtained after a spec iﬁc number of iterations (from the top row, representing
the ﬁrst iteration, to the bottom row, representing the ﬁfth iteration). The methods include (a) PSD, (b) GN, (c) EGN
applied to the reduced FWI with h=0, (d) EGN applied to the penalty FWI with h=0, (e) EGN applied to the
reduced FWI with |h| ≤1
4λ, and (f) EGN applied to the penalty FWI with |h| ≤1
4λ.
direction [ 6,24], our method decomposes the GN Hessian into separate Hessia n matrices, which can be efﬁciently
applied along the source and receiver dimensions of the data residual matrix. This decomposition enhances the com-
putational efﬁciency of the algorithm. For the case of simul taneous frequency inversion, where multiple frequencies
are inverted at each iteration, we tackle the challenge pose d by the generalized Sylvester equation 41by inverting each
15Extended Gauss-Newton method Ali Gholami A P REPRINT
0 2 4 6 80 1 2 3
0 2 4 6 80 1 2 3
0 2 4 6 80 1 2 3
0 2 4 6 80 1 2 3
Figure 6: Marmousi model example. The (a) true velocity mode l. Final velocity models inferred by (b) the PSD
method, (c) the EGN method solving the reduced FWI with h=0, and (d) the EGN method solving the penalty FWI
withh=0.
0 100 200 300 400 5000 1 2 3 4 5109
Figure 7: Trajectory of the misﬁt function versus iteration for the Marmousi model obtained by the PSD method (red
line), EGN method solving the reduced FWI (green line), and E GN method solving the penalty FWI (blue line).
frequency separately and subsequently stacking the result s over frequency. This strategy effectively extends the sea rch
direction along the frequency axis, providing an additiona l level of exploration in the model space.
16Extended Gauss-Newton method Ali Gholami A P REPRINT
0 5 10 15 200 2 4
0 5 10 15 200 2 4
0 5 10 15 200 2 4
0 5 10 15 200 2 4
0 5 10 15 200 2 4
0 5 10 15 200 2 4
Figure 8: The (a) Overthrust velocity model and (b) initial m odel. Inversion results obtained by solving the reduced
FWI using (c) PSD, (d) EGN, (e) EGN only using Hr, and (f) EGN only using Hs.
The extension of the EGN method to the time-domain formulati on of FWI involves extending the search direction in
both the subsurface offset and propagation time axes, resul ting in equations similar to those obtained in the frequency -
domain formulation. In the time-domain EGN formulation, th e data residual, denoted as ∆d, remains a matrix, where
each column represents a shot gather reshaped as a vector. Co nsequently, the Hessian matrix SSTtakes the form of a
block matrix with dimensions NrNt×NrNt, consisting of Nr×Nrblocks, each of size Nt×Nt, as illustrated in
Figure A-1 of [ 9]. The source-side Hessian matrix, UUT, retains its size of Ns×Ns.
The primary challenge encountered in the time-domain imple mentation of the EGN method is related to the construc-
tion and inversion of the SSTmatrix. To address this, a truncated EGN approach can be empl oyed to estimate the
extended data residuals by solving the corresponding linea r system using the CG iteration. This truncated EGN method
requires two additional wave-equation solves per CG iterat ion. However, it is worth noting that this extra computa-
tional cost is also present when applying the truncated GN me thod with the second-order adjoint state algorithm for
FWI [ 17]. Consequently, the computational cost of the EGN method us ing the matrix-free formalism is comparable
to that of the standard GN method. Once the extended data resi dual matrix is obtained, the subsequent steps involved
in the EGN algorithm remain the same as in the standard FWI alg orithm. These steps include the multiplication of
the forward and backward waveﬁelds and the summation over ti me and source. Summation over the subsurface offset
can also be done on the ﬂy by shifting the propagating waveﬁel ds in space. By utilizing the truncated EGN approach
and the matrix-free formalism, we can effectively address t he challenge associated with constructing and inverting
theSSTmatrix in the time-domain implementation of the EGN method. This enables us to achieve computational
efﬁciency comparable to the standard GN method while beneﬁt ing from the enhanced capabilities of the EGN method.
Finally, our investigations on various numerical examples have revealed that the impact of model extension on im-
proving inversion results is signiﬁcantly more pronounced compared to the effect of source extension. Although the
source extension plays a preconditioning role in the EGN fra mework (compare, e.g., Figure 3f with the reference 3e
and Figure 5d with the reference 5c), further investigation is needed to determine the speciﬁ c conditions under which
the source extension becomes more signiﬁcant and inﬂuentia l. Understanding these conditions will provide valuable
insights into optimizing the usage of source extension with in the EGN method.
17Extended Gauss-Newton method Ali Gholami A P REPRINT
3 4 5 60 0.5 1 1.5 2 2.5 3 3.5 4 4.53 4 5 60 0.5 1 1.5 2 2.5 3 3.5 4 4.53 4 5 60 0.5 1 1.5 2 2.5 3 3.5 4 4.5
Figure 9: Velocity logs extracted at locations indicated by white dashed lines on Figure 8a. The plot provides a direct
comparison between the true model (blue line), the initial m odel (gray line), and the reconstructed models obtained
solving the reduced FWI using the PSD (red line), EGN (black l ine), EGN only using Hr(green line), and EGN only
usingHs(cyan line).
0 50 100 150 200 250 3000 1 2 3 4 5108
Figure 10: Trajectory of the misﬁt function versus iteratio n for the Overthrust model obtained by solving the reduced
FWI using the PSD (red line), EGN (blue line), EGN only using Hr(magenta line), and EGN only using Hs(green
line).
7 Conclusions
We have developed the Extended Gauss-Newton (EGN) method fo r multisource multireceiver waveform inversion,
which extends the search direction of the standard Gauss-Ne wton (GN) method. After rewriting the GN system
as an equivalent matrix equation with a diagonal matrix as th e solution instead of a vector, we demonstrated how
relaxing the diagonal constraint added a degree of freedom f or search direction along the subsurface offset axis.
A separable Hessian is produced as a result of this relaxatio n of the diagonal constraint, making efﬁcient inversion
possible. The EGN method offers an alternative approach to e xtended FWI that allows us to use the advantages of both
model extension and source extension methods, while mainta ining computational efﬁciency of the reduced FWI. The
18Extended Gauss-Newton method Ali Gholami A P REPRINT
0 2 40 1 2 3 4 5 6
0 2 4 6 80 0.5 1 1.5 2 2.5 3
0 5 10 15 200 1 2 3 4
Figure 11: Inversion results obtained by the randomized EGN method solving the reduced FWI. The (a) Camembert
model, (b) Marmousi model, and (c) Overthrust model.
efﬁciency and stability of EGN in estimating high-quality v elocity models have been illustrated by several numerical
examples. It displayed strong performance, consistently d elivering accurate inversion results. The method is a usefu l
tool for tackling challenging FWI problems because of its ef ﬁciency and robustness.
8 ACKNOWLEDGMENTS
This research was ﬁnancially support by the SONATA BIS grant (No. 2022/46/E/ST10/00266) of the National Science
Center in Poland.
References
[1] Abubakar, A., W. Hu, T. M. Habashy, and P. M. van den Berg, 2 009, Application of the ﬁnite-difference contrast-
source inversion algorithm to seismic full-waveform data: Geophysics, 74, WCC47–WCC58.
[2] Aghazade, K., A. Gholami, H. Aghamiry, and S. Operto, 202 2, Randomized source sketching for full waveform
inversion: IEEE Transactions on Geoscience and Remote Sens ing,60, 1–12.
[3] Biondi, B. and A. Almomin, 2014, Simultaneous inversion of full data bandwidth by tomographic full-waveform
inversion: Geophysics, 79(3) , WA129–WA140.
[4] Biondi, B. and G. Shan, 2002, Prestack imaging of overtur ned reﬂections by reverse time migration, inSEG
Technical Program Expanded Abstracts 2002, 1284–1287. Soc iety of Exploration Geophysicists.
[5] Biondi, B. and W. Symes, 2004, Angle-domain common-imag e gathers for migration velocity analysis by
waveﬁeld-continuation imaging: Geophysics, 69(5) , 1283–1298.
19Extended Gauss-Newton method Ali Gholami A P REPRINT
[6] Claerbout, J., 1985, Imaging the Earth’s interior: Blac kwell Scientiﬁc Publication.
[7] Fu, L. and W. W. Symes, 2017, An adaptive multiscale algor ithm for efﬁcient extended waveform inversion:
Geophysics, 82, R183–R197.
[8] Gauthier, O., J. Virieux, and A. Tarantola, 1986, Two-di mensional nonlinear inversion of seismic waveforms:
numerical results: Geophysics, 51, 1387–1403.
[9] Gholami, A., H. S. Aghamiry, and S. Operto, 2022a, Extend ed full waveform inversion in the time domain by the
augmented Lagrangian method: Geophysics, 87, R63–R77.
[10] ——–, 2022b, On the connection between WRI and FWI: Analy sis of the nonlinear term in the hessian matrix,
inSEG Technical Program Expanded Abstracts 2022, 1–5. Societ y of Exploration Geophysicists.
[11] Guttman, L., 1946, Enlargement methods for computing t he inverse matrix: The annals of mathematical statistics,
336–343.
[12] Hautus, M. L. J., 1994, Operator substitution: Linear a lgebra and its applications, 205, 713–739.
[13] Horn, R. A. and C. R. Johnson, 1994, Topics in matrix anal ysis: Cambridge University Press.
[14] Hou, J. and W. W. Symes, 2015, An approximate inverse to t he extended Born modeling operator: Geophysics,
80, R331–R349.
[15] Huang, G., R. Nammour, and W. W. Symes, 2018, V olume sour ce-based extended waveform inversion: Geo-
physics, 83, R369–387.
[16] Lindsey, J. P., 1989, The Fresnel zone and its interpret ative signiﬁcance: The Leading Edge, 8, 33–39.
[17] M´ etivier, L., R. Brossier, S. Operto, and V . J., 2017, F ull waveform inversion and the truncated Newton method:
SIAM Review, 59, 153–195.
[18] Plessix, R. E., 2006, A review of the adjoint-state meth od for computing the gradient of a functional with geo-
physical applications: Geophysical Journal Internationa l,167, 495–503.
[19] Pratt, R. G., C. Shin, and G. J. Hicks, 1998, Gauss-Newto n and full Newton methods in frequency-space seismic
waveform inversion: Geophysical Journal International, 133, 341–362.
[20] Rickett, J. and P. Sava, 2002, Offset and angle-domain c ommon image-point gathers for shot-proﬁle migration:
Geophysics, 67, 883–889.
[21] Sava, P. C. and S. Fomel, 2003, Angle-domain common-ima ge gathers by waveﬁeld continuation methods:
Geophysics, 68, 1065–1074.
[22] Sheriff, R. E., 1980, Nomogram for Fresnel-zone calcul ation: Geophysics, 45, 968–972.
[23] Shin, C., S. Jang, and D. J. Min, 2001, Improved amplitud e preservation for prestack depth migration by inverse
scattering theory: Geophysical Prospecting, 49, 592–606.
[24] Symes, W. W., 2008, Migration velocity analysis and wav eform inversion: Geophysical Prospecting, 56, 765–
790.
[25] ——–, 2020, Waveﬁeld reconstruction inversion: an exam ple: Inverse Problems, 36, 105010.
[26] Symes, W. W. and M. Kern, 1994, Inversion of reﬂection se ismograms by differential semblance analysis: algo-
rithm structure and synthetic examples: Geophysical Prosp ecting, 42, 565–614.
[27] Tarantola, A., 1984, Inversion of seismic reﬂection da ta in the acoustic approximation: Geophysics, 49, 1259–
1266.
[28] van Leeuwen, T., 2019, A note on extended full waveform i nversion: arXiv preprint arXiv:1904.00363.
[29] van Leeuwen, T. and F. Herrmann, 2016, A penalty method f or PDE-constrained optimization in inverse prob-
lems: Inverse Problems, 32(1) , 1–26.
[30] van Leeuwen, T. and F. J. Herrmann, 2013, Mitigating loc al minima in full-waveform inversion by expanding
the search space: Geophysical Journal International, 195(1) , 661–667.
[31] Virieux, J. and S. Operto, 2009, An overview of full wave form inversion in exploration geophysics: Geophysics,
74, WCC1–WCC26.
[32] Wang, J., J. Lee, M. Mahdavi, M. Kolar, and N. Srebro, 201 7, Sketching meets random projection in the dual: A
provable recovery algorithm for big and high-dimensional d ata: Electronic Journal of Statistics, 11, 4896–4944.
[33] Yang, J., Y . Elita Li, A. Cheng, Y . Liu, and L. Dong, 2019, Least-squares reverse time migration in the presence
of velocity errors: Geophysics, 84, S567–S580.
20