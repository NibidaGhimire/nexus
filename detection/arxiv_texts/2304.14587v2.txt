Smooth Indirect Solution Method for State-constrained Optimal Control
Problems with Nonlinear Control-affine Systems
Kenshiro Oguri
©2023 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media,
including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers
or lists, or reuse of any copyrighted component of this work in other works. DOI: 10.1109/CDC49753.2023.10383623 . Presented at 2023 IEEE CDC.Abstract — This paper presents an indirect solution method
for state-constrained optimal control problems to address the
long-standing issue of discontinuous control and costate under
state constraints. It is known in optimal control theory that a
state inequality constraint introduces discontinuities in control
and costate, rendering the classical indirect solution methods
ineffective. This study re-examines the necessary conditions
of optimality for a class of state-constrained optimal control
problems, and shows the uniqueness of the optimal control
that minimizes the Hamiltonian under state constraints, which
leads to a unifying form of the necessary conditions. The unified
form of the necessary conditions opens the door to addressing
the issue of discontinuities in control and costate by modeling
them via smooth functions. This paper exploits this insight to
transform the originally discontinuous problems to smooth two-
point boundary value problems that can be solved by existing
nonlinear root-finding algorithms. This paper also shows the
formulated solution method to have an anytime algorithm-
like property, and then numerically demonstrates the solution
method by an optimal orbit control problem.
I. I NTRODUCTION
This paper presents a new indirect solution method for
state-constrained optimal control problems to address the
long-standing issue of discontinuous costate and control
under state constraints. It is widely known that imposing
pure state path constraints, S(x, t)≤0, in optimal control
problems introduces discontinuities in control and costate
[1]–[3]. Despite such difficulties, state-constrained optimal
control problems arise in many fields, including aerospace,
robotics, and other engineering and science applications.
In practice, many state-constrained optimal control prob-
lems are solved via direct methods. Direct methods con-
vert continuous-time optimal control problems into finite-
dimensional problems by parameterizing the problems via
multiple shooting [4], numerical collocation [5], or exact
time discretization [6]. The resulting parameter optimiza-
tion problems are solved via nonlinear programming [7],
sequential convex programming [8], model predictive control
[9], etc. Many successful commercial software for solving
general optimal control problems, such as GPOPS [10], fall
under the category of direct methods. To incorporate inequal-
ity constraints in the direct method framework, they almost
always employ the penalty function method and its variants
[11], [12], which impose soft constraints by penalizing the
violation of constraints and increase the penalty weight over
iterations, asymptotically achieving the feasibility and opti-
mality. These methods are usually combined with techniques
K. Oguri is with the School of Aeronautics and Astronautics, Purdue
University, IN 47907, USA ( koguri@purdue.edu ).in numerical optimization, such as the interior point method
[7] and the augmented Lagrangian method [13].
Although direct methods provide flexibility in solving a
variety of problems, they often compromise the feasibility
and/or optimality due to the nature of the penalty function
method [11], [12] and problem parameterization, which
often involves approximation [4], [5], [9]. The computa-
tional complexity can be also an issue due to the large
number (hundreds to thousands) of variables introduced
by the parameterization [4], [5], [8]. In contrast, indirect
methods possess an advantage of the fewer dimensionality
of the problem ( <10 unknowns). The fewer dimensionality
is attractive particularly for complex control problems, such
as those involving uncertainty [14] and multiple phases [15].
Motivated by these facts, this paper revisits the use of indi-
rect methods. However, classical indirect methods struggle to
solve state-constrained problems. Due to the discontinuities
in control and costate resulting from Pontryagin’s minimum
principle [2], classical approaches divide the entire trajectory
into sub-arcs and solve each sub-arc as separate two-point
boundary value problems (TPBVPs) while satisfying the
transversality conditions [1]–[3]. This approach requires a
priori information about the sub-arc structure (e.g., number
of constrained arcs), which is usually unknown in practice.
To address the issue, some recent studies have developed
indirect solution methods with various approaches, such
as using saturation function for problems with lower/upper
bounds on state [16]; introducing slack variables and penalty
function [17]; deriving a variant of the minimum principle by
requiring the continuity of Lagrange multipliers associated
with state constraints [18], [19]. On the other hand, like any
approaches, they have their own assumptions and limitations
(e.g., type of constraints considered, continuity).
This study tackles state-constrained optimal control via a
different indirect method approach that explicitly addresses
the discontinuities arising from the minimum principle. First,
we revisit necessary conditions of optimality for constrained
problems and show the uniqueness of optimal control that
minimizes the constrained control Hamiltonian. This analysis
leads to a unifying form of optimality necessary conditions,
which enables us to address the issue of discontinuities in
control and costate by modeling them via smooth functions
with a sharpness parameter ρ. This approach transforms the
originally discontinuous problem to a smooth TPBVP that
can be solved by existing root-finding algorithms, where the
sharpness parameter ρcontrols the optimality of the resulting
solutions. It is also shown that intermediate solutions of the
continuation process respect the state constraint, which isarXiv:2304.14587v2  [math.OC]  6 Mar 2024often a desirable property for safety-critical systems.
II. P RELIMINARY
A. Problem Statement
Consider a nonlinear, control-affine dynamical system:
˙x=f(x, u, t ) =f0(x, t) +F(x, t)u (1)
where x∈Rn,u∈Rm, and t∈Rare the state, control, and
time, respectively; this system arises in many aerospace [20],
[21] and robotic systems [22]. F(·)is twice continuously
differentiable, which holds for many practical problems (e.g.,
for most robotic/aerospace problems, F= [0 m×m, Im]⊤).
Without loss of generality, consider the cost functional in
the Lagrange form1:
J=ZT
0L(x, u, t )dt. (2)
A feasible trajectory must satisfy terminal constraints
ψ(x(0), x(T), T) = 0 (3)
where ψ:Rn×Rn×R7→Rq, and a scalar state constraint
S(x, t)≤0. (4)
Sis assumed to be twice continuously differentiable and first
order, implying that the first time derivative of Scontains the
control term uexplicitly, i.e.,
S(1)(x, u, t )≜˙S=Sxf+St=Sxf0+SxFu+St(5)
where Sx∈R1×n, St∈Rare the gradients of Swith respect
toxandt, i.e., Sx≜∇xSandSt≜∇tS. The first-order
constraint assumption is thus equivalent to SxF̸= 0,∀x, t.
Note that this assumption may limit the applicability of the
proposed method, as SxF= 0for some practical constraints.
Thus, our original problem is formulated as in Problem 1.
Problem 1 (Original problem) .Find x∗(t), u∗(t), T∗that
minimize the cost Eq. (2)subject to the dynamics Eq. (1),
terminal constraints Eq. (3), and state constraint Eq. (4).
Although the analysis in this study is focused on a scalar
state constraint Sfor conciseness, generalization to a vector-
valued state constraint Sis straightforward by requiring the
following condition in addition to SxF̸= 0,∀x, t; forS∈
Rlwithl >1, rows of SxFare independent (similar to the
linear independence constraint qualification, or LICQ, which
is often assumed in nonlinear programming algorithms [7]).
B. Optimality Necessary Conditions
The necessary conditions of optimality take different forms
depending on whether the trajectory is on a constrained arc
(S= 0) or on an unconstrained arc ( S <0) [2]. We use u∗
o
to refer to the optimal control on an unconstrained arc while
u∗
cto that on a constrained arc. u∗collectively denotes the
optimal control regardless of constrained/unconstrained arc.
1The other forms of cost, the Mayer and Bolza forms, can be converted
to the Lagrange form. Also, a time interval τ∈[τ0, τf]can be
transformed to t∈[0, T]viat=τ−τ0andT=τf−τ0.Clearly, a trajectory is characterized as follows:


unconstrained arc if S <0
constrained arc if S= 0∧S(1)
o≥0
infeasible if S >0(6)
where S(1)
ois a shorthand notation of S(1)(·)under u∗
o, i.e.,
S(1)
o≜S(1)(x, u∗
o, t). When S= 0 andS(1)
o≤0att=ti,
the trajectory is leaving the constrained arc, called an exit
point. Likewise, S= 0 andS(1)
o>0at an entry point.
1) Unconstrained arc: On an unconstrained arc, from
Pontryagin’s minimum principle, u∗
omust satisfy
u∗
o∈arg min
uHo (7)
Hois the unconstrained control Hamiltonian, defined as:
Ho(x, u, λ, t ) =L(x, u, t ) +λ⊤[f0(x, t) +F(x, t)u](8)
where λ∈Rnis the Lagrange multiplier associated with
Eq. (1), or costate. The costate dynamics are given by
−˙λ⊤=∇xHo=∇xL+λ⊤∇xf (9)
2) Constrained arc: On a constrained arc, a feasible
control must satisfy S(1)(x, u, t )≤0. Among several ap-
proaches in literature [1], [2], this study takes an approach
known as indirect adjoining to derive necessary conditions.
The indirect adjoining approach adjoins the control-
dependent constraint S(1)(x, u, t )≤0in addition to Eqs. (1)
and (3) to yield the control Hamiltonian [2]:
Hc(x, u, λ, µ, t ) =L+λ⊤f+µS(1)(10)
where Hcis the Hamiltonian on a constrained arc; µ(≥0)
is a Lagrange multiplier associated with S(1)≤0. Denoting
the optimal multiplier by µ∗, the following must hold [2]:
(u∗
c, µ∗)∈ {u, µ≥0|min
u,µHcs.t.S(1)= 0} (11)
The costate dynamics are given by
−˙λ⊤=∇xHc(x, u, λ, µ, t ) =∇xL+λ⊤∇xf+µ∇xS(1)
3) Discontinuity at corners: It is known that µ∗may be
discontinuous at the time of entry to a constrained arc, called
acorner2. At a corner (say t=ti),λandHobey [2], [23]:
∆λi≜λ(t+
i)−λ(t−
i) =−µ(t+
i)[Sx(ti)]⊤,
∆Hi≜H(t+
i)−H(t−
i) =µ(t+
i)St(ti)(12)
III. U NIQUENESS OF OPTIMAL CONTROL AND
MULTIPLIER
Although Eq. (11) states necessary conditions for (u∗, µ∗)
to satisfy, it does not clarify whether such (u∗, µ∗)is unique.
The uniqueness of (u∗, µ∗)is crucial for numerically solving
optimal control problems via indirect methods. Numerical
solutions for problems with no such uniqueness guarantee
typically have to rely on direct methods (e.g., GPOPS [10])
with greater computational complexity.
2In fact, one may also choose the discontinuity to occur at the exit
corner or distribute at both of the entry and exit corners (e.g., [1]).
This paper chooses to have the corner discontinuity at entry corners.A. Optimal Control on Unconstrained Arcs
We assume that the unique solution to Eq. (7) is available
in a closed form and continuously differentiable by satis-
fying the sufficient condition for the minimum Hamiltonian
(known as the Legendre-Clebsch condition [2]):
∇uHo=∇uL(x, u, t ) +λ⊤F= 0∧
∇2
uuHo=∇2
uuL(x, u, t )≻0(13)
Note that this assumption holds for many problems that are
solved by indirect methods, as demonstrated in Section III-D.
We generically express u∗
othat satisfies Eq. (13) as:
u∗
o=g(x, λ, t ) (14)
B. Optimal Control on Constrained Arcs
It can be shown that, with the assumption made in Sec-
tion III-A, Problem 1 has the unique pair of (u∗
c, µ∗)∀ton
constrained arcs. Lemma 1 formally states this fact.
Lemma 1. Under the assumption that the unique solution to
Eq.(7)is available in a closed form Eq. (14), the solution
to Eq. (11) is uniquely determined in the following form:
u∗
c=g(x, λ+µS⊤
x, t), (15)
µ∗=h(x, λ, t )≥0, (16)
where his continuously differentiable.
Proof. The goal is to find the unique pair of u∗
candµ∗that
solves the following Hamiltonian minimization:
(u∗
c, µ∗) = arg min
µ≥0min
uHcs.t.S(1)= 0 (17)
where Hcis given by Eq. (10). Expanding Hc, we have
Hc=L+ (λ⊤+µSx)(f0+Fu) +µSt. The Legendre-
Clebsch condition for Hcleads to
∇uHc=∇uL(x, u, t ) + (λ⊤+µSx)F= 0∧ (18a)
∇2
uuHc=∇2
uuL(x, u, t )≻0 (18b)
Noting Eq. (13), it is clear that u∗
cthat satisfies Eq. (18) is
given by Eq. (15). Next, note that Eqs. (18a) and (18b) must
be satisfied for any µ. Thus, the partial derivative of ∇uHc
with respect to µmust be identically zero, i.e.,
0 =∇µ[∇uHc] =∇2
µuL(x, u∗
c, t) +SxF
=Sxn
∇λg(x, λ+µS⊤
x, t)⊤∇2
uuL(x, u∗
c, t) +Fo
which implies that [∇λg(x, λ+µS⊤
x, t)]⊤∇2
uuL(x, u∗
c, t) +
F= 0, yielding ( ∵∇2
uuL(x, u∗
c, t)≻0, so invertible)
∇λg(x, λ+µS⊤
x, t) =−[∇2
uuL(x, u∗
c, t)]−1F⊤(19)
Eq. (19) becomes handy shortly.
From Eq. (17), µ∗must satisfy S(1)= 0 under u∗
c, i.e.,
S(1)=Sxf0+SxFg(x, λ+µ∗S⊤
x, t) +St= 0 (20)
Differentiating S(1)with respect to µand using Eq. (19),
∇µS(1)=SxF[∇µg(x, λ+µS⊤
x, t)]
=SxF[∇λg(x, λ+µS⊤
x, t)]S⊤
x
=−SxF[∇2
uuL(x, u∗
c, t)]−1F⊤S⊤
x(21)which implies ∇µS(1)<0because [∇2
uuL(x, u∗
c, t)]−1≻
0due to Eq. (18b) and SxF̸= 0,∀x, tas discussed in
Section II-A. Thus, S(1)is monotonically decreasing in µ.
Note also that, when µ= 0, we have that g(x, λ+µS⊤
x, t) =
g(x, λ, t ) =u∗
oand hence S(1)=S(1)
o≥0on a constrained
arc (recall Eq. (6)). Therefore, µ∗that satisfies Eq. (20) is
unique and must be non-negative, and the unique solution can
be represented by a function µ∗=h(x, λ, t ), i.e., Eq. (16).
Finally, h(x, λ, t )is continuously differentiable because S(·),
f0(·),F(·), and g(·)are twice differentiable.
C. Unified Form of Optimality Necessary Conditions
Thus, we can express the control Hamiltonian and neces-
sary conditions of optimality for Problem 1 in a unified form
without needing to separate the discussion, as follows:
H(x, u, λ, µ, t ) =L(·) +λ⊤f(·) +µS(1)(·), , (22a)
u∗=g(x, λ+µ∗S⊤
x, t), (22b)
˙λ=−[∇xH(x, u∗, λ, µ∗, t)]⊤, (22c)
µ∗=(
h(x, λ, t ) if S= 0∧S(1)
o≥0
0 otherwise(22d)
where Eqs. (22a) to (22c) give the unconstrained arc solution
by substituting µ∗= 0; Eq. (22d) is based on Eq. (6). This
is in sharp contrast to the classical discussion in literature
(e.g., [2]), which divides a state-constrained optimal control
problem into constrained and unconstrained arcs.
Remark 1. Even with the unifying form given by Eq. (22),
Problem 1 still experiences discontinuities in µ∗(and hence
inλ∗andH∗) when the trajectory enters a constrained arc.
Section IV addresses the issue identified in Remark 1.
D. Analytical Example
Let us consider an example to demonstrate the wide
applicability of the assumption made in Section III-A as well
as the procedure to find u∗andµ∗on constrained arcs based
on Lemma 1. This example considers L(·)in the form of
L(·) =c(x, t) +u⊤Ru+x⊤Pu, where R≻0. With this,
one can find the solution to Eq. (7) by solving Eq. (13) as:
u∗
o=−1
2R−1(Px+F⊤λ) (23)
which is continuously differentiable ( ∵Fis continuously
differentiable), hence satisfying the assumption made in
Section III-A. It is also straightforward to derive u∗
cby
applying Eqs. (18a) and (18b), yielding:
u∗
c=−1
2R−1[Px+F⊤(λ+µ∗S⊤
x)] (24)
which takes the form given in Eq. (15). Substituting Eq. (24)
into Eq. (20) and solving for µ∗yields
µ∗=2Sxf0+ 2St−SxFR−1(Px+F⊤λ)
SxFR−1F⊤S⊤x(25)
where SxFR−1F⊤S⊤
x̸= 0 since SxF̸= 0 andR≻0.
Eq. (25) is continuously differentiable because S(·),f0(·),
andF(·)are twice differentiable.IV. S OLUTION METHOD
This section presents the proposed solution method to ad-
dress discontinuities in Problem 1 and analyzes its properties.
A. Smooth Approximation of Discontinuous Multiplier
Let us address the discontinuity issue stated in Remark 1.
As clear from Eq. (22d), the discontinuity is triggered by
the two conditions S= 0 andS(1)
o≥0. Hence, this study
models µ∗via˜µ∗with two smooth activation functions as:
˜µ∗=h(x, λ, t )ϕ1(S)ϕ2(S(1)
o), (26)
where ϕ1(·)andϕ2(·)aim to smoothly characterize the
activation via S= 0 andS(1)
o≥0, respectively.
There are three guiding principles in designing ϕ1and
ϕ2: (i) for constraint satisfaction, both ϕ1andϕ2should
take unity when S= 0 andS(1)
o≥0; (ii) ϕ2should remain
unity for any values of S(1)
o≥0since S(1)
ocan be arbitrarily
large on constrained arcs; (iii) for the approximation to be
asymptotically precise, ϕ1should be close to zero when S <
0while ϕ2should be close to zero when S(1)
o<0.
Based on these guiding principles, we choose a hyperbolic
tangent-based function (a variant of the logistic function)
and a variant of the bump function to design ϕ1andϕ2,
respectively. Formally defining these activation functions,
ϕ1(x) =e2+ 1
2e2
1 + tanhx+ρ1
ρ1
, (27a)
ϕ2(x) =

1 x >0
exph
1
ρ2
2
1−1
1−x2i
x∈(−1,0]
0 x≤ −1(27b)
where ρ1∈Randρ2∈Rare positive scalars that control
the sharpness of the approximation; smaller ρ1andρ2lead to
sharper approximations. Fig. 1 illustrates their behavior with
different values of ρ, where ϕtanh, ϕbump represent ϕ1, ϕ2.
Lemma 2 formally states three key properties the proposed
approach possesses. The first property (1) is crucial to fa-
cilitating the numerical convergence of the solution method.
This property implies the smoothness of uand˙x, eliminating
the need to divide the trajectory into sub-arcs. The second
property (2) is vital when applying to safety-critical systems
where we do not want to compromise the state constraint
satisfaction for any ρ. The third property (3) ensures the
convergence to the local optimum of the original problem.
Lemma 2. The smooth approximation ˜µ∗as defined in
Eqs. (26) and (27) has the following properties:
1)˜µ∗is continuously differentiable over an optimal tra-
jectory including at corners;
2)˜µ∗respects the inequality constraint regardless of the
values of ρ1andρ2; and
3)˜µ∗approaches µ∗defined in Eq. (22d) asρ1, ρ2→+0.
Proof. (1) is shown first. It is clear from Eq. (27) that ϕ1
andϕ2are continuously differentiable in Sandh, respec-
tively, including at corners. Sandhare both continuously
differentiable as discussed earlier, thus proving (1).
- 1 - 0 . 8 - 0 . 6 - 0 . 4 - 0 . 2 0
S ; [ ! ]00 . 51? t a n h ; [ ! ]; = 0 : 5
; = 0 : 1
; = 0 : 0 5
; = 0 : 0 1(a)tanh(·)activation, Eq. (27a). The same legend applies to (b) and (c).
- 0 . 5 0 0 . 5
S( 1 ); [ ! ]00 . 51? b u m p ; [ ! ]
(b) Bump function, Eq. (27b)
- 0 . 5 0 0 . 5
S ; [ ! ]02 04 06 0~ / ( S ) ; [ ! ] (c) Costate jump approx, Eq. (31)
Fig. 1. Activation functions with various sharpness parameters ρ
For (2), it is clear from Eq. (27) that, when S= 0∧S(1)
o>
0,ϕ1(S)andϕ2(S(1)
o)take both unity independent of the
values of ρ1andρ2, and hence ˜µ∗=h, yielding S(1)= 0,
which ensures the constraint satisfaction on constrained arcs.
(3) is verified by showing the following facts: (a)
limρ1→+0ϕ1(S) = 0 ifS < 0; (b) ϕ1(S) = 1 ifS= 0
independent from ρ1; (c) ϕ2(S(1)
o) = 1 ifS(1)
o≥0inde-
pendent from ρ2; (d) limρ2→+0ϕ2(S(1)
o) = 0 ifS(1)
o<0;
(e)h= 0 ifS(1)
o= 0. (a) and (b) are shown by noting that
tanh (−∞) =−1and thate2+1
2e2=1
1+tanh 1, respectively. (c)
is true by definition, see Eq. (27b). (d) is shown by noting
thatlimρ2→+0ϕ2(S(1)
o) = 0 ifS(1)
o<0(∵exp (−∞) = 0 ).
(e) is shown by noting that the unique µ∗that simultaneously
satisfies S(1)
o= 0 andS(1)= 0 is necessarily zero, i.e.,
µ∗=h= 0 (∵S(1)
o=Sxf0+SxFg(x, λ, t ) +St, S(1)=
Sxf0+SxFg(x, λ+µ∗S⊤
x, t) +St).
B. Smooth Approximation of Discontinuous Control
With the smooth multiplier established in Section IV-A, it
is straightforward to approximate u∗via a smooth function:
˜u∗=g(x, λ+ ˜µ∗S⊤
x, t), (28)
which has the following desired properties due to Lemma 2:
(1)˜u∗is continuously differentiable; (2) ˜u∗respects the
inequality constraint regardless of the values of ρ1andρ2;
(3)˜u∗asymptotically approaches u∗asρ1, ρ2→+0.
C. Smooth Approximation of Jump in Costate & Hamiltonian
Recalling Eq. (12), the discontinuous change in costate at
thei-th corner, denoted by ∆λi, is given by
∆λi=−µ∗(t+
i)[Sx(ti)]⊤=−h(x(ti), λ(ti), ti)[Sx(ti)]⊤
where µ∗(t+
i)is replaced by h(·)due to Eq. (22d). The
following formulation directly applies to ∆Hias well.
By using the Dirac delta function, ∆λiis equivalent to
∆λi=−Z∞
−∞h(x, λ, t )[Sx(t)]⊤δ(t−ti)dt (29)where δ(x)satisfies the following conditions:
δ(x) =(
∞x= 0
0x̸= 0,Z∞
−∞δ(x)dx= 1 (30)
Noting that t=ticorresponds to a time when S= 0 and
thatSnever becomes positive under u∗withµ∗, the integral
of the Dirac delta can be expressed in terms of Sas:
Z∞
−∞δ(t−ti)dt= 2Z0
−∞δ(S)dS= 2Zti
−∞δ(S(t))S(1)dt
where dS=˙Sdt=S(1)dt.
Obviously, δ(x)is discontinuous at tiand needs a smooth
approximation for integrating the costate differential equation
across ti. Thus, we smoothly approximate δ(x)as follows:
˜δ(x)≜1
ρ3√
2πexp
−1
2x2
ρ2
3
, (31)
which corresponds to the probability distribution function
(pdf) of a zero-mean normal distribution with standard
deviation ρ3, where ρ3serves as another sharpness parameter.
It is straightforward to verify that ˜δ(x)given by Eq. (31)
has the following desirable properties: ˜δ(x)asymptotically
satisfies the left of Eq. (30) as ρ3→0; and ˜δ(x)always
satisfies the right of Eq. (30) regardless of the value of ρ3,
since ˜δ(·)represents a pdf. Fig. 1(c) illustrates the behavior
of˜δ(S)with respect to various ρ3.
Using Eq. (31), the jump condition Eq. (29) is smoothly
approximated via f∆λi, calculated as:
f∆λi=−2Zti
−∞h(x, λ, t )[Sx(t)]⊤˜δ(S(t))S(1)dt. (32)
Since Eq. (32) must hold for each i-th corner and takes
the form of integral with respect to t, this effect can be
incorporated into Eq. (22c), yielding:
˙λ=−[∇xH(x,˜u∗, λ,˜µ∗, t)]⊤−2h(·)˜δ(S)S(1)S⊤
x (33)
The jump in Hcan be similarly expressed with a substitution
ofStintoSx, resulting an ordinary differential equation for
Hthat takes into account the jump conditions at corners.
Note that the approximation quality of ∆λivia Eq. (33)
does not affect the feasibility of the problem. The feasibility
is guaranteed by the second property of Lemma 2.
D. Smooth State-constrained Optimal Control Problem
Applying the proposed solution method transforms Prob-
lem 1 into Problem 2, which no longer involves discontinu-
ities in control and costate and represents a smooth TPBVP.
Problem 2 (Smooth State-constrained Problem) .For given
sharpness parameters {ρ1, ρ2, ρ3}, find the initial costate
λ(0)(andTfor variable-time problems) such that satisfy the
transversality conditions subject to the state dynamics Eq. (1)
and costate dynamics Eq. (33) under control Eq. (28).
Due to the smoothness, we can solve Problem 2 by
the standard indirect shooting with no need for dividing
the problem into sub-arcs. For completeness, the standardindirect shooting procedure can be described as follows: (1)
define an augmented state, X= [x⊤, λ⊤]⊤, which obeys:
˙X=f(x,˜u∗, t)
−[∇xH(x,˜u∗, λ,˜µ∗, t)]⊤−2˜µ∗˜δ(S)S(1)S⊤
x
;(34)
(2) set up a shooting function Ψ(λ(0)) which, for given
λ(0), integrates Eq. (34) from t= 0 toTand evaluates
the transversality conditions; (3) use a nonlinear root-finding
solver to find λ(0)that yields Ψ(·) = 0 .
To approach the optimal solution of the original problem,
we perform continuation over a decreasing sequence of ρ’s,
where ρ≜ρ1=ρ2=ρ3is used for simple algorithm design.
That is, after solving Problem 2 with ρ(i), the solution is
used as the initial guess of λ(0)for the next iteration with
ρ(i+1), where ρ(i)decreases as iincreases. This approach
takes advantage of the third property in Lemma 2 and the
convergence property of ˜δ(·)toδ(·).
Remark 2. Each intermediate solution of the continuation
procedure respects the state constraint regardless of the
values of the sharpness parameters {ρ1, ρ2, ρ3}(i.e., anytime
algorithm) due to the second property of Lemma 2, which is
often a desirable property for safety-critical systems.
V. N UMERICAL EXAMPLE
We consider a 2-D orbit transfer problem. Let r, v∈R2
be the position and velocity of the spacecraft, x∈R4be the
state vector, and u∈R2the control vector, defined as:
x=r
v
, r =r1
r2
, v =v1
v2
, u =u1
u2
(35)
Orbital dynamics with gravity parameter µgare given by:
f(x, u) =f0(x) +Bu, f 0="
v
−µg
∥r∥3
2r#
, B=02×2
I2
where the canonical unit is used so that ∥r(t= 0)∥2=µg=
1.∥·∥2represents the 2-norm of a vector. The cost function,
boundary conditions, and state constraint are defined as:
L=1
2∥u∥2
2, x(0) = x0, x(T) =xT, S=pmin−p(x),
where p(x) = ( r1v2−r2v1)2/µgis the semilatus rectum
of an orbit. x0, xT, T, p minare given and defined as: x0=
[1,0,0,1]⊤, xT= [3√
3/2,1.5,−1/(2√
3),0.5]⊤, T =
3π, p min= 0.9. The necessary conditions are derived as:
u∗=−B⊤(λ+µ∗S⊤
x), µ∗=Sxf0−SxBB⊤λ
SxBB⊤S⊤x(36)
Note that this problem is a special case of the example in
Section III-D with F=B, S t= 0, c= 0, R=1
2I2, and
P= 0. The transversality condition is x(T)−xT= 0.
We solve this problem in the form of Problem 2 by using
Matlab’s fsolve , where ode45 is used for the integration
of Eq. (34). The tolerances used are Opt/FunTol = 10−8
forfsolve andRel/AbsTol = 10−8forode45 .
The solutions for ρ(i)∈ {0.5,0.1,5×10−2,10−2,5×
10−3,10−3}are shown in Fig. 2, including the uncon-
strained solution for comparison. Figs. 2(b) and 2(c) in-
dicate that control and costate experience a discontinuity- 4 - 2 0 2 4
r 1- 202r 2u n c o n s t r a i n e d
; = 0 : 5
; = 0 : 1; = 0 : 0 5
; = 0 : 0 1
; = 0 : 0 0 1(a) Optimal trajectories for various ρ. The same legend applies to (b)-(e).
The filled circle and triangle represent the initial and final positions.
0 2 4 6 8- 0 . 2- 0 . 100 . 1u 1
0 2 4 6 8
t- 0 . 1- 0 . 0 50u 2
(b) Optimal control profiles
00 . 26 1
- 0 . 200 . 26 2
00 . 26 3
0 2 4 6 8
t00 . 10 . 26 4 (c) Optimal costate profiles
0 2 4 6 8- 0 . 0 500 . 0 50 . 1~ 7
0 2 4 6 8
t024j u m p
(d) Smoothed µand costate jump
0 2 4 6 8- 2- 10S
0 2 4 6 8
t- 1- 0 . 50S( 1 ) (e) State constraint and derivative
Fig. 2. Numerical example results with various ρ.
around t= 0.55, which is well-modeled by the smooth
approximation. Fig. 2(b) shows a significant difference in the
optimal control profiles for the constrained and unconstrained
problems. Fig. 2(d) shows the behavior of ˜µ∗(constraint
multiplier) and 2h˜δ(S)S(1)(time derivative of costate jump;
see Eq. (33)), which numerically verifies the analysis in
Section IV. Fig. 2(e) plots SandS(1)overt, confirming that
intermediate solutions in the continuation respect the state
constraint, even for a blunt sharpness parameter ρ= 0.5,
which demonstrates Remark 2.
VI. C ONCLUSIONS
In this paper, a new indirect solution method for state-
constrained optimal control problems is presented to address
the long-standing issue of discontinuous control and costate
due to state inequality constraints. The proposed solution
method is enabled by re-examining the necessary conditions
of optimality for the constrained control problems and de-
riving a unifying form of necessary conditions based on the
uniqueness of the optimal control and constraint multiplier
on constrained arcs. In contrast to classical indirect solution
methods, the proposed method transforms the originally
discontinuous problems into smooth TPBVPs, eliminating
the need for a priori knowledge about the optimal so-
lution structure, which is usually unknown. A numerical
example demonstrates the proposed method and its anytime
algorithm-like property. A key next direction of this work is
to generalize the framework to higher-order state constraints.REFERENCES
[1] R. F. Hartl, S. P. Sethi, and R. G. Vickson, “A Survey of the Maximum
Principles for Optimal Control Problems with State Constraints,” SIAM
Review , vol. 37, pp. 181–218, June 1995.
[2] A. E. Bryson and Y .-C. Ho, Applied Optimal Control . CRC Press,
1975.
[3] J. L. Speyer and A. E. Bryson, “Optimal programming problems with
a bounded state space.,” AIAA Journal , vol. 6, pp. 1488–1491, Aug.
1968.
[4] H. G. Bock and K. J. Plitt, “A Multiple Shooting Algorithm for Direct
Solution of Optimal Control Problems*,” IFAC Proceedings Volumes ,
vol. 17, pp. 1603–1608, July 1984.
[5] C. R. Hargraves and S. W. Paris, “Direct Trajectory Optimization
Using Nonlinear Programming and Collocation,” Journal of Guidance,
Control, and Dynamics , vol. 10, no. 4, pp. 338–342, 1987.
[6] M. Szmuk, T. P. Reynolds, and B. Ac ¸ıkmes ¸e, “Successive Con-
vexification for Real-Time Six-Degree-of-Freedom Powered Descent
Guidance with State-Triggered Constraints,” Journal of Guidance,
Control, and Dynamics , vol. 43, pp. 1399–1413, Aug. 2020.
[7] J. Nocedal and S. J. Wright, Numerical Optimization . Springer New
York, 2006.
[8] Y . Mao, M. Szmuk, and B. Acikmese, “Successive convexification of
non-convex optimal control problems and its convergence properties,”
inIEEE 55th Conference on Decision and Control (CDC) , pp. 3636–
3641, IEEE, Dec. 2016.
[9] E. F. Camacho and C. Bordons, Model Predictive Control . 2007.
[10] M. A. Patterson and A. V . Rao, “GPOPS-II: A MATLAB Software for
Solving Multiple-Phase Optimal Control Problems Using hp-Adaptive
Gaussian Quadrature Collocation Methods and Sparse Nonlinear Pro-
gramming,” ACM Transactions on Mathematical Software , vol. 41,
pp. 1:1–1:37, Oct. 2014.
[11] W. F. Denham and A. E. Bryson, “Optimal programming problems
with inequality constraints. ii - solution by steepest-ascent,” AIAA
Journal , vol. 2, pp. 25–34, Jan. 1964.
[12] K. L. Teo and L. S. Jennings, “Nonlinear optimal control problems
with continuous state inequality constraints,” Journal of Optimization
Theory and Applications , vol. 63, pp. 1–22, Oct. 1989.
[13] D. P. Bertsekas, Constrained Optimization and Lagrange Multiplier
Methods . Elsevier, 1982.
[14] K. Oguri and J. W. McMahon, “Stochastic Primer Vector for Robust
Low-Thrust Trajectory Design Under Uncertainty,” Journal of Guid-
ance, Control, and Dynamics , vol. 45, pp. 84–102, Jan. 2022.
[15] Y . Sidhoum and K. Oguri, “Low-thrust Trajectory Optimization for
Enceladus Exploration using Indirect Forward-backward Shooting,” in
AAS/AIAA Astrodynamics Specialist Conference , (Big Sky, MT), 2023.
[16] K. Graichen, A. Kugi, N. Petit, and F. Chaplais, “Handling constraints
in optimal control with saturation functions and system extension,”
Systems & Control Letters , vol. 59, pp. 671–679, Nov. 2010.
[17] B. C. Fabien, “Indirect Solution of Inequality Constrained and Sin-
gular Optimal Control Problems Via a Simple Continuation Method,”
Journal of Dynamic Systems, Measurement, and Control , vol. 136,
p. 021003, Mar. 2014.
[18] A. V . Arutyunov and D. Yu. Karamzin, “On Some Continuity Proper-
ties of the Measure Lagrange Multiplier from the Maximum Principle
for State Constrained Problems,” SIAM Journal on Control and
Optimization , vol. 53, pp. 2514–2540, Jan. 2015.
[19] R. Chertovskih, D. Karamzin, N. T. Khalil, and F. L. Pereira, “An Indi-
rect Method for Regular State-Constrained Optimal Control Problems
in Flow Fields,” IEEE Transactions on Automatic Control , vol. 66,
pp. 787–793, Feb. 2021.
[20] B. A. Conway, Spacecraft Trajectory Optimization . Cambridge:
Cambridge University Press, 2010.
[21] K. Oguri, M. Ono, and J. W. McMahon, “Convex Optimization over
Sequential Linear Feedback Policies with Continuous-time Chance
Constraints,” in IEEE 58th Conference on Decision and Control
(CDC) , pp. 6325–6331, Dec. 2019.
[22] R. Bonalli, T. Lew, and M. Pavone, “Analysis of Theoretical and Nu-
merical Properties of Sequential Convex Programming for Continuous-
Time Optimal Control,” IEEE Transactions on Automatic Control ,
pp. 1–16, 2022.
[23] J. McIntyre and B. Paiewonsky, “On Optimal Control with Bounded
State Variables,” in Advances in Control Systems , vol. 5, pp. 389–419,
Elsevier, 1967.