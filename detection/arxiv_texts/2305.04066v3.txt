Semi-Asynchronous Federated Edge Learning for
Over-the-air Computation
Zhoubin Kou1, Yun Ji1, Xiaoxiong Zhong1,2, and Sheng Zhang1,*
1Graduate School in Shenzhen, Tsinghua University, Shenzhen, 518055, China
2Peng Cheng Laboratory, Shenzhen 518000, P.R. China
*Corresponding author: Sheng Zhang, email: zhangsh@sz.tsinghua.edu.cn
Abstract —Over-the-air Computation (AirComp) has been
demonstrated as an effective transmission scheme to boost
the efficiency of federated edge learning (FEEL). However,
existing FEEL systems with AirComp scheme often employ
traditional synchronous aggregation mechanisms for local model
aggregation in each global round, which suffer from the strag-
glers issues. In this paper, we propose a semi-asynchronous
aggregation FEEL mechanism with AirComp scheme (PAOTA)
to improve the training efficiency of the FEEL system in the
case of significant heterogeneity in data and devices. Taking the
staleness and divergence of model updates from edge devices into
consideration, we minimize the convergence upper bound of the
FEEL global model by adjusting the uplink transmit power of
edge devices at each aggregation period. The simulation results
demonstrate that our proposed algorithm achieves convergence
performance close to that of the ideal Local SGD. Furthermore,
with the same target accuracy, the training time required for
PAOTA is less than that of the ideal Local SGD and the
synchronous FEEL algorithm via AirComp.
Index Terms —Federated edge learning, semi-asynchronous
mechanism, over-the-air computation.
I.INTRODUCTION
With the advancement in computing capabilities and the
accessibility of an unprecedented amount of data for portable
devices, various machine learning based applications and ser-
vices has been introduced to Internet of Thing (IoT) systems.
However, the frequent data sharing of individual information
in some services led to privacy concerns. Due to its appeal-
ing features of privacy protection, federated learning (FL)
has been widely regarded as a promising machine learning
technology [1]. Nevertheless, there are several problems to
be addressed when deploying FL on wireless scenarios: 1)
resource limitation: the total bandwidth and the transmission
energy for all edge devices in wireless FL system are both
finite; 2) heterogeneity: wireless FL suffers from the data
heterogeneity and device heterogeneity, leading to global
non-IID data distribution and different computing latency
respectively.
In federated edge learning (FEEL) scenario, edge devices
that collaborate to build a global model are often dispersed
within a small physical range, and coordinated by a nearby
parameter server (PS) [2]. A traditional approach for the
uplink transmission of edge devices is to allocate channel
resources through orthogonal access techniques, such as
TDMA, CDMA and OFDMA. However, the limited wireless
resources and large model data size in FEEL impose aconstraint on the number of edge devices that can participate
in uploading.
Over-the-air computation (AirComp) has been proven to
be an efficient paradigm to alleviate the communication costs
and accelerate the FEEL training progress [3]. Leveraging the
superposition property of wireless spectrum, AirComp can
achieve uplink transmission of local models without the need
for spectrum and time channel resource allocation.
To enhance the performance of wireless FEEL system,
several studies related to the AirComp system for FEEL
have been done [3]–[5]. A large amount of works follow
the synchronous aggregation FEEL mechanism , where the
parameter server (PS) does not update the global model
until it receives local models from all the chosen edge
devices in each global aggregation. However, in the common
FEEL scenario of imbalanced computing ability among edge
devices, following the synchronous aggregation mechanism
for training FEEL can result in the risk of bottleneck nodes,
while discarding the stragglers may need to lose important
data. The former can prolong the training time of the model,
and the latter can decrease the predictive accuracy of the final
model.
In these circumstances, one potential solution is to apply
the asynchronous mechanism into the FEEL. To fully take
the advantage of high uplink throughput in AirComp, we
propose a semi-asynchronous model aggregation mechanism
with fixed interval time for global aggregation. The main
contributions are summarized as follows:
•We propose a semi-asynchronous P eriodic A ggregation
Over-T he-A ir computation strategy named PAOTA un-
der wireless multiple access channel (MAC) scenarios,
which can utilize the waveform superposition property
to realize AirComp during the wirless transmission.
•We analyze the convergence behavior of the semi-
asynchronous FEEL via AirComp and derive the upper
bound of the gap between the expected and optimal
global loss values with respect to the transmission power.
In PAOTA, the weighted parameters for model aggrega-
tion are proportional to the transmission power of the
edge devices. To overcome the staleness in asynchronous
aggregation and alleviate the data skewness caused by
non-IID data, we transform the power control for uplink
transmission into a trade-off optimization for the delayarXiv:2305.04066v3  [cs.LG]  30 May 2023BS
uplink downlinkLocal update for device 
Local update for device 
Parameter
ServerClient 1
Client k
Client K
Model aggregation
BS
uplink downlinkLocal update for device 
Parameter
ServerClient 1
Client k
Client K
Model aggregation
Fig. 1. FL system via wireless multiple-access channels.
factor of local model and the similarity factor of model
gradient.
•The trade-off optimization problem is a nonlinear frac-
tional programming of two convex quadratic functions.
We solve it by using Dinkelbach’s parametrization
scheme. To optimize the nonconcave quadratic program-
ming problem introduced by Dinkelbach’s transform, we
convert the problem into a 0-1 linear integer program-
ming problem through piecewise linear approximation.
•According to the numerical results, PAOTA shows good
training robustness under wireless FEEL system. Con-
sidering the heterogeneity of FEEL in the experiments,
we verify the superiority of the algorithm PAOTA in
terms of the predictive accuracy and the training time
for converging to the target prediction accuracy.
II. S YSTEM MODEL
A. FL Problems
We consider a wireless FL system which consists of one
parameter server and a set K={1, . . . , K }ofKedge
devices, as shown in Fig. 1. Each client k∈ K partici-
pating in the FL task is access to a local data set Dk=
{(xk,1, yk,1), . . . , (xk,Dk, yk,Dk)}, with size |Dk|=Dk.
Then, the total set of data samples in the whole system can be
denoted as D={D1, . . . ,DK}, where size D=PK
k=1Dk.
(xk,i, yk,i)is the i-th input-output pair stored in client k,
where xk,idenotes the feature vector and yk,idenotes the
corresponding label value. The goal of FL task is to minimize
the global loss function by training global model parameter w,
where the local data samples at edge devices are unavailable
to the PS on account of the privacy concern. The optimization
problem of FL can be formulated as follow:
min
wF(w) =XK
k=1Dk
DFk(w), (1)
where Fkis the local loss function defined as
Fk(w) =1
DkX
i∈Dkl(w; (xk,i, yk,i)), (2)
where l(w; (xk,i, yk,i))is the empirical loss function.
Client 1
Client 2
Client 3
Client K
Round 1 Round 2 Round 3 Round 4 Round R
Local model trainingLocal model training Broadcast global modelBroadcast global model Local model uploadLocal model upload
 
 
  
 
  
 
  
 
  
 
Client 1
Client 2
Client 3
Client K
Round 1 Round 2 Round 3 Round 4 Round R
Local model training Broadcast global model Local model upload
 
  
  
  
  
Fig. 2. The work-flow of federated learning with periodic aggregation.
B. Semi-asynchronous FL with Periodic Aggregation
Inspired by [8], we propose a time-triggered semi-
asynchronous aggregation. The work-flow of our proposed
PAOTA is shown in Fig. 2. The global aggregation proceeds
periodically, and the interval time of each cycle ∆Tremains
constant. We assume Rrounds of FL training are performed,
and use vector br= [br
1,···, br
K]∈ {0,1}to indicate the state
information of Kedge devices. After the PS broadcasts the
model to client k, the element of state vector br
kis assigned
as zero at first. When client kfinishes its local training at the
r-th round, it sends a signal to the server showing that client
kis ready to upload its local model. Then the PS will set the
value of br
kto1, which means client k will attend the global
aggregation at r-th round and be ready to receive the updated
global model at the beginning of the (r+1)-th round.
C. Asynchronous Aggregation via AirComp
In this paper, we consider the scenario where the downlink
communication is error-free. The uplink channels remain
unchanged when edge devices transmit local models to the
PS at one round, and the wireless MAC channels are adopted.
Following the Rayleigh distribution, the uplink channels are
independent across different transmission rounds.
We assume the PS will carry out Rrounds of iterations in
total for a FL task. At the r-th (r∈ {1,···, R}) round of
global training iteration:
(a)Global model broadcasting . At the beginning of
each global round, the PS broadcasts the global model wk
g
to edge devices according to the edge devices state vector
br= [br
1,···, br
K]∈ {0,1}. When client kdoes not complete
the local training of the previous global round, set br
k= 0; and
when client kis ready to participate in the FL task at the r-th
round, br
k= 1. In particular, the PS broadcasts global model
w1
gto all edge devices at the first global round, which means
b1
k= 1,∀k. Since the downlink communication is assumed
to be a perfect transmission, each client can get the global
model without transmission errors.
(b)Local model training . Ifbr
k= 1, client kreceives the
global model wr
gand use stochastic gradient decent (SGD)
to update local model based ont their own datasets Dk. We
assume each client runs Mrounds iterations for local modeltraining, at the m-th local update, m∈ {1,···, M}, the local
model wr
k,mis formed as
wr
k,m=wr
g−ηXm
τ=1∇Fk(wr
k,τ−1;Dτ
k), (3)
where ηis the learning rate, Dm
kis the data used in the m-th
round of local training. If br
k= 0, client kwill keep training
the local model which haven’t been finished at the previous
round. We define sr
kas the number of rounds that client kfalls
behind the global training round, then the update of straggler
kcan be expressed as
wr,sr
k
k,m=wr−sr
kg−ηXM
m=1∇Fk(wr,sr
k
k,m−1;Dm
k),(4)
As we can see, (3) is a special case of (4) when sr
kequals to
0. After MSGD training iterations, client kfinishes its local
training at r-th global round and the updated local model is
denoted as wr,sr
k
k,M.
(c)Local model upload. In this paper, we assume that
the wireless AirComp can achieve strict clock synchroniza-
tion, called alignment over-the-air computation, so that edge
devices’ signals overlap exactly with each other at the PS.
The edge devices who complete their local training during
r-th global round will transmit their local model through
AirComp at the same period, as shown in Fig. 2. Assuming
the channel state information (CSI) is known by all the edge
devices and the PS perfectly, we consider a pre-processing
parameter ϕr
kfor the transmitter of the edge devices which is
denoted by
ϕr
k=br
kpr
k(hr
k)H
|hr
k|2, (5)
where hr
k∈Cis the complex channel coefficient of the uplink
transmission between client kand the PS, pr
kis the transmit
power of client k, and (·)Hrepresents conjugate transpose.
The transmit signal of client kcan be expressed as xr
k=
ϕr
kwr,sr
k
k,M. As the PS knows the perfect CSI, the received signal
of PS can be formulated as
yr
g=XK
k=1hr
kxr
k+nr=XK
k=1br
kpr
kwr,sr
k
k,M+nr,(6)
where nr∈Cdrepresents the independent identical distribu-
tion (i.i.d) additive Gaussian white noise (AWGN) following
the distribution CN(0, σ2
nI). And σ2
n=BN0, where Bis the
bandwidth of uplink channel, and N0represents the channel
noise power spectral density. For limited power of each client,
we have:
∥ϕr
kwr,sr
k
k,M∥2
2≤Pr
k,max, (7)
where Pr
k,maxis the maximum power of client kat the r-th
round.
(d)Global model update . After the upload time slot of
each global round, the PS receives the aggregation signal
through AirComp, and performs a normalization operation
to obtain the updated global model wr+1
g
wr+1
g=yr
g
ςr=XK
k=1br
kpr
k
ςrwr,sr
k
k,M+nr
ςr
=XK
k=1αr
kwr,sr
k
k,M+˜nr,(8)where ςris the normalization factor at r-th round and can
be calculated by ςr=PK
k=1br
kpr
k. Then the actual weight
parameter of client kcan be formulated by αr
k=br
kpr
kPK
i=1br
ipr
i
for simplicity, where αr
ksatisfiesPK
k=1αr
k= 1.˜nris the
equivalent noise after the normalization operation.
To facilitate the derivation of convergence, we further
express global model aggregation as follow:
wr+1
g=˜wr+XK
k=1αr
k∆wr
k+˜nr, (9)
where ˜wr=PK
k=1αr
kwr−sr
kg represents the weighted sum of
the global model parameters based on the users participating
in uploading the local model during r-th round of aggregation,
and∆wr
k=−ηPE
τ=1∇Fk(wr,sr
k
k,τ−1;Dτ
k)is the local update
of client kat the r-th round.
III. C ONVERGENCE ANALYSIS AND OPTIMIZATION
ALGORITHM
In this section, we analyze how the wireless MAC en-
vironment and the periodic aggregation strategy affect the
convergence behavior of PAOTA presented in Section II.
Firstly, we derive the upper bound of the expected optimal
gap between the expected and optimal global loss values.
Then, combining with the characteristics of the asynchronous
mechanism and data heterogeneity, we minimize the derived
upper bound by optimizing the parameter βrelated to the
staleness factor and the gradient similarity factor. The whole
process of PAOTA is shown in Algorithm 1 .
A. Convergence Analysis
We present the following assumptions and lemmas that
are necessary when we derive the convergence behavior of
PAOTA algorithm at first.
Assumption 1 : The global loss function FisL-smooth,
i.e.,∀x,y:
F(x)−F(y)≤(x−y)T∇F(y) +L
2∥x−y∥2
2,(10)
∥∇F(x)− ∇F(y)∥ ≤L∥x−y∥, (11)
Assumption 2 [9]: The variance of the local model gradi-
ents at each local device is bounded by ζ:
Eh
∥∇Fk(wτ
k)− ∇F(wg)∥2
2i
≤ζ, (12)
where ζis the parameter related to the data heterogeneity.
These two assumptions above are widely used in the con-
vergence analysis for traditional synchronous FL. Assumption
1makes sure the gradient of Fdoes not change quickly during
global training. And the Assumption 2 captures the degree of
data heterogeneity by parameter ζ.
Assumption 3 [8]: The global model gradient change
within ntraining rounds is bounded as
 
wr−n
g−wr
gT∇F 
wr
g
≤δ∇F 
wr
g2
2, (13)
∥wr−n
g−wr
g∥ ≤ϵ, (14)where δandϵare constant value. And the local model
gradient change within mlocal rounds is bounded as
∥∇F(wr−m
k)∥ ≤ϑ∥∇F(wr
k)∥, (15)
where ϑis a constant value.
Assumption 4 : The SGD algorithm performed by the edge
device is unbiased, i.e.,
E[∇Fk(wk;Dk)] =∇Fk(wk), (16)
and the variance of stochastic gradients at each edge device
is bounded as
E[∥∇Fk(wk;Dk)− ∇Fk(wk)∥2
2]≤σ2, (17)
where σis a constant value.
Lemma 1 : The sum of the expected square norm of the
difference between the local updated model at each SGD
iteration and the previous global model is bounded by
XM
τ=1E[∥wr−sr
kg−wr−sr
k,τ−1
k∥2
2]
≤ηt2M3σ2+ 4ηt2M3L2ζ+ 4ηt2M3β2Eh∇F 
wr
g2
2i
1−2η2M2L2,
(18)
Proof: See the section Appendix A.
Lemma 2 : For a L-smooth function Fwith optimum
solution w∗, the following inequality holds
∥∇F(w)∥2
2≤2L(F(w)−F(w∗)), (19)
Proof: AsFis aL-smooth function, for wand the
optimum solution w∗, we have
1
2L∥∇F(w)− ∇F(w∗)∥2
2
≤F(w)−F(w∗)−(w−w∗)T∇F(w∗),(20)
where ∇F(w∗) = 0 . Rearrange the (20) and we can get the
(19).
Now, we present the main convergence analysis result in
the following theorem. Now, we present the main convergence
analysis result in the following theorem.
Theorem 1 : The expected optimal gap between the expected
and optimal global loss values is bounded as
E[F(wR+1)]−F(w∗)
≤RY
r=1ArE
F 
w1
g
−F(w∗)
+GR
+RX
r=1 RY
i=r+1Ai!
Gr,(21)
where
Ar=1 + 2 Lδ−LηM + 8L2η2Mϑ2
+ 
ηL2+ 4Mη2L38Lη2M3ϑ2
1−2η2M2L2,(22)and
Gr= (2ηM+ 8LηM2+4η2M3L2(ηL2+ 4Mη2L3)
1−2η2M2L2)ζ
| {z }
(a)+
2ηML2ϵ2
|{z}
(b)+ (2η2LM2+(ηL2+ 4Mη2L3)η2M3
1−2η2M2L2)σ2
| {z }
(c)
+Lϵ2KXK
k=1(αr
k)2
| {z }
(d)+2Ldσ2
n
(PK
k=1br
kpr
k)2
|{z }
(e),
(23)
Proof: Due to space limitations, please see Appendix A
in the extended version [10].
According to the Theorem 1 , we can learn that the upper
bound of E[F(wR+1)]−F(w∗)depends only on the second
termGrgiven a sufficient number of iteration rounds, as long
as the setting of learning rate ηsatisfies A(t)<1.
It is natural to think of minimizing the value of Gr
by adjusting the controllable parameters in the wireless FL
system. As shown in (23), Grconsists of 5 terms (a)-(e):
the terms (a)-(c)are only dependent on the hyper-parameters
that relate to the wireless FL system settings, which can not
change during the training iterations. Term (d)and term (e)
contain the upload transmit power value pk, which control the
aggregation weight of the local models uploaded by different
edge devices.
To sum up, there are two kinds of factors affecting the
global model convergence in our proposed system. On the
one hand, the asynchronous aggregation process introduces
stale models to global update, thus impairing the convergence
speed of FEEL. On the other hand, the noise present in
the wireless transmission environment negatively impacts the
convergence performance of federated learning.
B. Power Control Optimization
Based on the Theorem 1 , we can minimize the upper bound
ofE[F(wR+1)]−F(w∗)by optimizing the terms (d)and
(e)through the uplink transmit power pk,k= 1,···, K. By
dropping the notation rfor simplicity, the optimal problem
can be formulated as:
P1: min
p1,···,pKLϵ2KXK
k=1αk2+2Ldσ2
n P
k∈Kbkpk2(24a)
s.t.pk≤Pk
max, k= 1,···, K, (24b)
where p= [p1,···, pK]∈R1×Kis the transmission power
ofKclients.
Different with synchronous FL, PAOTA has to suffer the
impact of the stale information. Meanwhile, the problem of
data bias introduced by the non-IID data distribution also
should be considered. As the model aggregation weights isAlgorithm 1 PAOTA
Require: Global training rounds R; Time duration of each
round ∆T; Local training rounds E; Uplink power budget
of each client pmax
k; Initial global model w0
g; State Tag of
each client b0
k= 1,∀k;
1:forr= 0,1,···, R−1do
2: PS broadcasts wr
gto clients ksatisfying bk= 1,∀k;
3: Setbk←0;
4: fork= 1,···, Kin parallel do
5: forτ= 1,···, Mdo
6: wr,τ+1
k←wr,τ
k−η∇Fk(wr,τ
k;Dτ+1
k);
7: ifτ=Mthen
8: bk←1;
9: Obtain current round value r′, uplink channel
gains hr′
kand parameter βr′;
10: Set the ϕr′
kbased on (5) and (25);
11: Transmit the signal xr′,r′−r
k=ϕr′
kwr
k,Eat the
aggregation time slot of round r′;
12: end if
13: end for
14: end for
15: PS receives MAC signal (6) at the aggregation time
slot, performs the normalization operation based on (8)
and obtains the updated global model wr+1
g;
16:end for
determined by the uplink transmission power directly accord-
ing to (8), we represent the power parameter as follow:
pk=pmax
k·βk·Ω
sk+ Ω
+pmax
k·(1−βk)·Θ(∆wt
k,wt
g−wt−1
g) + 1
2
=pmax
k(βk·ρk+ (1−βk)·θk),(25)
where skis the staleness factor of local model wkat each
round, θkis the interference factor of local model, Ωis
a constant to limit the maximum degree of latency, and
Θ(a,b)∈[−1,1]represents the cosine of the angle between
two vector aandb.βk∈[0,1]is a hyper-parameter that
can make a trade-off between the staleness factor ρkand the
interference factor θk[7], and makes pkstill subject to the
individual transmit power condition (7) where 0≤pk≤pmax
k.
By substituting the expression for pkinto the original
optimization problem P1and representing it in matrix form,
we obtain the final optimization problem:
P2: min
β(θ+Dβ)TPT
maxΘPmax(θ+Dβ) + 2Ldσ2
u
(θ+Dβ)TPT
maxIITPmax(θ+Dβ)
=βTGβ+gTβ+g0
βTQβ+qTβ+q0=h1(β)
h2(β)(26a)
s.t.βk∈[0,1], k= 1,···, K, (26b)
where ρT= [ ρ1,···, ρK],θT= [ θ1,···, θK],
βT= [β1,···, βK],Pmax= diag {pmax
1,···, pmax
K}
andD = diag {ρ1−θ1,···, ρK−θK}.Q=DTPT
maxbbTPmaxDis a K×Ksymmetric positive
definite matrix, G=DTPT
maxΘTPmaxDis a K×
Ksymmetric positive semi-definite definite matrix, q=
2θTPT
maxbbTPmaxD,g= 2θTPT
maxΘTPmaxDareK-
vectors. q0=θTPT
maxbbTPmaxθ,g0=θTPT
maxΘTPmaxθ+
2Ldσ2
uare constants.
Problem (26) is a nonlinear fractional programming prob-
lem, where both the dividend and divisor are convex quadratic
functions subject to linear constraints. To solve this problem,
we adopt an improved version of the Dinkelbach’s algorithm
[6], as shown in Algorithm 2 . The Dinkelbach’s transform
of problem P2can be formulated as:
P3: max
βF(β;λ) =h2(β)−λh1(β) (27a)
s.t.βk∈[0,1], k= 1,···, K. (27b)
where λ > 0is treated as a parameter. And P3is a
maximization of a non-concave quadratic function. Now,
we apply the standard piecewise linear approximation of
quadratic functions and reformulate P3as a 0-1 linear integer
programming problem. Since Gis symmetric and positive
definite, there exists a nonsingular matrix M1such that
G=MT
1M1. Letβ=M1β. Then
F(β;λ) =yTSy−λyTy+(qT−λgT)β+(q0−λg0),(28)
and since Qis symmetric and positive semi-definite, there
exists an orthogonal matrix M2such that MT
2SM 2=N,
MT
2M=I, where N=diag(ni). Therefore, we have
F(β;λ) =βTMT
1M2(N−λI)MT
2M1β
+ (qT−λgT)β+ (q0−λg0),(29)
Problem P3can be represented as follow:
P4: max
βf(β;λ) =zT(N−λI)z
+ (qT−λgT)M−1z+ (q0−λg0)(30a)
s.t.βk∈[0,1], k= 1,···, K, (30b)
z=Mβ, (30c)
where M=MT
2M1. Now, let
Z={z∈Rn|M−1z=β} (31)
and let
ziϱ+1= max {zi|z∈Z}, i= 1,2,···, n, (32)
z1= min {zi|z∈Z}, i= 1,2,···, n, (33)
We split the interval [zi1, ziϱ+1]into m sub-intervals of
equal length. The piecewise linear approximation of the ob-
jective function can be represented by introducing a number of
auxiliary variables γij,i= 1,2,···, nandj= 1,2,···, ϱ+
1, as follows:
zT(N−λI)z=−n−hX
i=1ci(λ)ϱ+1X
j=1z2
ijγij
+nX
i=n−h+1ci(λ)ϱ+1X
j=1z2
ijγij(34)Algorithm 2 Dinkelbach’s Method
Require: tolerance ε;λ0satisfying F(β;λ0)≥0; iteration
number n= 0;
1:repeat
2: setλ=λn
3: Solve 0-1 MIP Problem (39) derived from (27)’s piece-
wise linear approximation to obtain β∗;
4:λn+1←h2(β∗)
h1(β∗);
5:n←n+ 1;
6:until F(β;λn)≤ε
zi=ϱ+1X
j=1zijγij, i= 1,2,···, n, (35)
ϱ+1X
j=1γij= 1, i= 1,2,···, n, (36)
γij≥0, i= 1,2,···, nandj = 1,2,···, ϱ+ 1 (37)
Let us note that we need to introduce the 0-1 variables cij,
i=n−j+ 1,···, nforj= 1,2,···, ϱ,
γi1≤ci1,
γi2≤ci1+ci2,
...
γiϱ≤cih−1+cih,
mX
j=1=yij= 1,(38)
Therefore, the 0-1 linear integer programming problem can
be reformulated as follow:
max
z−n−hX
i=1ci(λ)ϱ+1X
j=1z2
ijγij+nX
i=n−h+1ci(λ)ϱ+1X
j=1z2
ijγij
+ (qT−λgT)M−1z+ (q0−λg0) (39a)
s.t.z∈Z, (39b)
(34),(35),(36),(37),(38).
This is a mixed integer programming problem with h×ϱ
0-1 variables which can be solved by IBM CPLEX Optimizer
efficiently. And then we can get the optimal βby using (30c)
and the solution of the problem P1by adopting (25).
IV. S IMULATION RESULTS
A. Experiment Settings
We consider a cellular network consisting of a basic station
(BS) and 100 clients participating in FEEL training, where the
downlink transmission is error-free. The maximal transmit
power of local devices is pk
max= 15 w. We set the uplink
transmission bandwidth as 20MHz, and the channel noise
power spectral density as N0=−174dBm/Hz. And we set
M= 5,L= 10 , and Ω = 3 . We train a multi-layer perception
(MLP) network which has two hidden layers with 10 nodes
on the MNIST dataset. Considering the non-IID distributionamong each clients, we set the number of training samples in
different clients varies from {300,600,900,1200,1500}and
each device contains five categories of digit images at most.
In order to realize the heterogeneity of edge devices in
the computing ability, we set the computation latency of
each client during different local training round to follow
the uniform distribution U(5,15)s, and the period of model
aggregation at each epoch for PAOTA as ∆T= 8s.
B. Performance Comparison
We compare the proformance of PAOTA algorithm with the
following federated learning algorithms:
(1) Local SGD [1]: An ideal synchronous federated learn-
ing algorithm, where each user transmits its local model
without considering transmission loss.
(2) COTAF [3]: One of the classic AirComp based FEEL
algorithms where each user transmits its model updates
through the MAC and performs time-varying pre-coding.
For fairness consideration, we set an equal number of
participating clients for each round of training in the three
algorithms. To verify the effectiveness of the proposed algo-
rithm, we first numerically evaluate the gap between expected
objective and optimal loss function value, i.e., E[F(wr)]−
F(w∗).
As shown in Fig. 3, we observe that PAOTA can achieve
convergence speed close to Local SGD when N0=
−174dBm/Hz. This verifies that the PAOTA algorithm can
effectively compensate for the negative impact of additive
noise and asynchronous aggregation mechanism on model
convergence speed. Moreover, as the number of iterations
increases, PAOTA can achieve a smaller gap than Local SGD,
indicating that PAOTA improves the utilization of heteroge-
neous data in clients through the proposed semi-asynchronous
aggregation strategy.
Furthermore, in Fig. 3, both COTAF and PAOTA can
achieve similar convergence performance when N0=
−174dBm/Hz. However, when the noise power spectral den-
sity is increased to -74dBm/Hz while ensuring that the uplink
transmission power of clients remains constant, PAOTA is
more robust than COTAF. This is because when optimizing
transmission power, PAOTA considers the additive noise pa-
rameters of the channel in optimization and thus implements
uplink power control adaptively.
Fig. 4 compares the test set accuracy of the three algorithms
with respect to communication rounds and training time
where we set N0=−174dBm/Hz. It can be observed that
PAOTA ultimately achieved a prediction accuracy of 83.5%,
which is 1.1% higher than that of Local SGD; the prediction
accuracy under COTAF is 81%, which is lower than the ideal
situation due to the negative impact of the wireless channel
on the model accuracy.
From the perspective of training time, the global iteration
training time of PAOTA is set to ∆T, while the global iter-
ation training time of Local SGD and COTAF is determined
by the client with the longest local computing time in this
global round. We list the time and rounds required to achieveFig. 3. Train loss in non-IID settings with bandwidth B=20MHz.
Communication Round Training Time / s
Fig. 4. Test accuracy in non-IID settings.
the target accuracy algorithms in Table I. It can be seen that
PAOTA requires more rounds than Local SGD to achieve the
target accuracy. However, since the time per round is fixed for
PAOTA, while Local SGD needs to wait for all selected clients
to complete training before aggregation, PAOTA spends less
time to achieve the same target accuracy. For example,
PAOTA saves 25% of time to achieve the target accuracy
80% than Local SGD. PAOTA achieves the performance
improvement mentioned above because its semi-asynchronous
aggregation mechanism can avoid the generation of bottleneck
nodes for each global round. Additionally, it controls the
weights of expired local models in aggregation to ensure the
utilization of data in clients with long local training time.
V. C ONCLUSION
In this paper, we first propose a semi-asynchronous mecha-
nism called PAOTA under wireless MAC channels, where the
clients suffer from computing heterogeneity. Then, we analyze
the convergence behavior of PAOTA and illustrate how the
asynchronous strategy and the wireless transmission affect
the upper bound of the expected gap between the expected
and optimal global loss. Considering the staleness discount
introduced by the asynchronous mechanism and the interfer-
ence effect of local client’s update, we model this trade-off
problem as the transmission power optimization. In non-IID
settings, the simulation results demonstrate that PAOTA can
achieve a better performance than other benchmarks in termsTABLE I
CONVERGENCE TIME
Target Accuracy 50% 60% 70% 80%
PAOTAround 6 10 18 57
time/s 36 60 108 342
Local SGDround 3 6 12 29
time/s 45.61 78.17 181.24 451.62
COTAFround 6 12 29 44
time/s 91.30 181.21 316.75 676.93
of the robustness in terrible wireless condition and convergent
speed.
REFERENCES
[1] B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-Efficient Learning of Deep Networks from Decen-
tralized Data,” in Proceedings of the 20th International Conference on
Artificial Intelligence and Statistics , PMLR, Apr. 2017, pp. 1273–1282.
[2] G. Zhu, Y . Wang, and K. Huang, “Broadband Analog Aggregation
for Low-Latency Federated Edge Learning,” IEEE Trans. Wireless
Commun. , vol. 19, no. 1, pp. 491–506, Jan. 2020.
[3] T. Sery and K. Cohen, “On Analog Gradient Descent Learning Over
Multiple Access Fading Channels,” IEEE Trans. Signal Process. , vol.
68, pp. 2897–2911, 2020.
[4] Y . Shao, D. Gunduz, and S. C. Liew, “Federated Edge Learning
With Misaligned Over-the-Air Computation,” IEEE Trans. Wireless
Commun. , vol. 21, no. 6, pp. 3951–3964, Jun. 2022.
[5] K. Yang, T. Jiang, Y . Shi, and Z. Ding, “Federated Learning via Over-
the-Air Computation,” IEEE Trans. Wireless Commun. , vol. 19, no. 3,
pp. 2022–2035, Mar. 2020.
[6] J.-Y . Gotoh and H. Konno, “Maximization of the Ratio of Two Convex
Quadratic Functions over a Polytope,” Computational Optimization and
Applications, vol. 20, no. 1, pp. 43–60, Oct. 2001.
[7] N. Su and B. Li, “How Asynchronous can Federated Learning Be?,” in
2022 IEEE/ACM 30th International Symposium on Quality of Service
(IWQoS) , Jun. 2022, pp. 1–11.
[8] X. Zhou, Y . Deng, H. Xia, S. Wu, and M. Bennis, “Time-Triggered
Federated Learning Over Wireless Networks,” IEEE Trans. Wireless
Commun. , vol. 21, no. 12, pp. 11066–11079, Dec. 2022.
[9] W. Guo, R. Li, C. Huang, X. Qin, K. Shen, and W. Zhang, “Joint
Device Selection and Power Control for Wireless Federated Learning,”
IEEE J. Select. Areas Commun. , vol. 40, no. 8, pp. 2395–2410, Aug.
2022.
[10] Z. Kou, Y . Ji, X. Zhong, and S. Zhang, “Semi-Asynchronous Feder-
ated Edge Learning Mechanism for Over-the-air Computation.” 2023,
arXiv:2305.04066 .APPENDIX A
PROOF OF LEMMA 1
Firstly, we derive the upper bound of the expected
square norm of the difference between the local updated
model at each SGD iteration and the previous global model
E[∥wr−sr
kg−wr−sr
k
k,τ−1∥2
2]as follow:
E[∥wr−sr
kg−wr−sr
k
k,τ−1∥2
2]
=E[∥ηtXτ−1
l=1∇Fk(wr−sr
k
k,l−1;Dr−sr
k
k,l)∥2
2]
≤ηt2(τ−1)Xτ−1
l=1E[∥∇Fk(wr−sr
k
k,l−1;Dr−sr
k
k,l)∥2
2]
(a)=ηt2(τ−1)Xτ−1
l=1E[∥∇Fk(w−r−sr
k
k,l−1;Dr−sr
k
k,l)
− ∇Fk(wr−sr
k
k,l−1)∥2
2]
+ηt2(τ−1)Xτ−1
l=1E[∥∇Fk(wr−sr
k
k,l−1)∥2
2]
(b)=ηt2(τ−1)2σ2
+ηt2(τ−1)Xτ−1
l=1E[∥∇Fk(wr−sr
k
k,l−1)∥2
2]
≤ηt2M2σ2+ηt2MXτ−1
l=1E[∥∇Fk(wr−sr
k
k,l−1)
− ∇Fk(wr−sr
kg) +∇Fk(wr−sr
kg)∥2
2]
(c)
≤ηt2M2σ2+ 2ηt2MXτ−1
l=1E[∥∇Fk(wr−sr
kg)∥2
2]
+ 2ηt2MXτ−1
l=1E[∥∇Fk(wr−sr
k
k,l−1)− ∇Fk(wr−sr
kg)∥2
2]
(d)
≤ηt2M2σ2
+ 2ηt2L2MXτ−1
l=1E[∥wr−sr
k
k,l−1−wr−sr
kg∥2
2]
+ 2ηt2MXτ−1
l=1E[∥∇Fk(wr−sr
kg)
− ∇Fg(wr−sr
kg) +∇Fg(wr−sr
kg)∥2
2]
(e)
≤ηt2M2σ2+ 2ηt2L2MXτ−1
l=1E[∥wr−sr
k
k,l−1−wr−sr
kg∥2
2]
+ 4ηt2MXτ−1
l=1E[∥∇Fk(wr−sr
kg)− ∇Fg(wr−sr
kg)∥2
2
+∥∇Fg(wr−sr
kg)∥2
2]
(f)
≤ηt2M2σ2+ 4ηt2M2ζ+ 4ηt2M2β2E[∥∇Fg(wr
g)∥2
2]
+ 2ηt2L2MXτ−1
l=1E[∥wr−sr
k
k,l−1−wr−sr
kg∥2
2] (40)
where equality (a) is due to
E[∥x∥2] =E[∥x−E[x]∥2] +∥E[x]∥2, (41)
and
E[∇Fk(wr−sr
k
k,l−1;Dr−sr
k
k,l)] =∇Fk(wr−sr
k
k,l−1), (42)
equality (b) is due to the equation
E[∥∇Fk(wr−sr
k
k,l−1;Dr−sr
k
k,l)− ∇Fk(wr−sr
k
k,l−1)∥2] =σ2,(43)
equality (c) and equality (e) are both due to
∥x1+x2∥2
2≤2∥x1∥2
2+ 2∥x2∥2
2 (44)equality (d) is by the inequality (11) in Assumption 1, equality
(f) is by the inequality (12) in Assumption 2 and the (15) in
Assumption 3.
Then, summing both sides of (40) from τ= 1toMyields
XM
τ=1E[∥wr−sr
kg−wr−sr
k
k,τ−1∥2
2]
≤ηt2M3σ2+ 4ηt2M3ζ+ 4ηt2M3β2E[∥∇Fg(wr
g)∥2
2]
+ 2ηt2L2MXM
τ=1Xτ−1
l=1E[∥wr−sr
k
k,l−1−wr−sr
kg∥2
2]
≤ηt2M3σ2+ 4ηt2M3ζ+ 4ηt2M3β2E[∥∇Fg(wr
g)∥2
2]
+ 2ηt2L2M2XM
τ=1E[∥wr−sr
k
k,τ−1−wr−sr
kg∥2
2]
(45)
Finally, rearranging the terms in (45) yields Lemma 1.
APPENDIX B
PROOF OF THEOREM 1
According to (9) and the (10) in Assumption 1, we have
F(wr+1
g)≤F(wr
g)+<wr+1
g−wr
g,∇F(wr
g)>
+L
2∥wr+1
g−wr
g∥2
2,(46)
By taking expectation on both sides of (46), we obtain
E[F(wr+1
g)]
≤E[F(wr
g)] +E[<wr+1
g−wr
g,∇F(wr
g)>]
| {z }
A1
+L
2E[∥wr+1
g−wr
g∥2
2]
| {z }
A2.(47)
Then we bound the terms A1andA2in the right hand sides
of (47) in the following.
A. Bound of A1
In this section, we derive the bound of A1,
A1=E[<wr+1
g−wr
g,∇F(wr
g)>]
=E[<˜wr−wr
g+XK
k=1αr
k∆wr
k+˜nr,∇F(wr
g)>]
=E[<˜wr−wr
g,∇F(wr
g)>]
| {z }
B1+E[<˜nr,∇F(wr
g)>]
| {z }
B3
+E[<XK
k=1αr
k∆wr
k,∇F(wr
g)>]
| {z }
B2(48)
where b3= 0 because of ˜nris orthogonal to ∇F(wr
g), and
E[˜nr] = 0 .
We analyze B1andB2separately. We bound the term B1
as ,
B1=E[<XK
k=1αr
k(wr−sr
kg−wr
g),∇F(wr
g)>]
=XK
k=1αr
kE[<wr−sr
kg−wr
g,∇F(wr
g)>]
(a)
≤XK
k=1αr
kδE[∥∇F(wr
g)∥2
2]
=δE[∥∇F(wr
g)∥2
2](49)where (a) is due to the (13) in Assumption 3. Then, we study
the term B2as follow,
B2
=E[<XK
k=1αr
k∆wr
k,
∇F(wr
g)>]
=E[<XK
k=1αr
k(−ηtXM
τ=1∇Fk(wr−sr
k
k,τ−1;Dr−sr
k
k,τ)),
∇F(wr
g)>]
=−ηtXM
τ=1E[<XK
k=1αr
k∇Fk(wr−sr
k
k,τ−1;Dr−sr
k
k,τ),
∇F(wr
g)>]
(a)
≤ −ηtM
2E[∥∇F(wr
g)∥2
2] +ηtXK
k=1αr
kXM
τ=1
E[∥∇Fk(wr−sr
kg)− ∇Fk(wkr−sr
k,τ−1)∥2
2]
+ηtXM
τ=1E[∥∇F(wr
g)−XK
k=1αr
k∇Fk(wr−sr
kg)∥2
2]
(b)
≤ −ηtM
2E[∥∇F(wr
g)∥2
2]
+ηtL2XK
k=1αr
kXM
τ=1E[∥wr−sr
kg−wr−sr
k
k,τ−1∥2
2]
+ηtXM
τ=1E[∥∇F(wr
g)−XK
k=1αr
k∇Fk(wr−sr
kg)∥2
2]
| {z }
C1(50)
where (a) follows the inequality (44) and Jensen’s inequality,
and (b) follows the (10) in assumption 1 and wr−sr
kg =
wr−sr
k,0
k.
For (49), we further need to bound the term C1as follow,
C1
=ηtXM
τ=1E[∥∇F(wr
g)−XK
k=1αr
k∇Fk(wr−sr
kg)∥2
2]
=ηtXM
τ=1E[∥XK
k=1αr
k(∇F(wr
g)− ∇Fk(wr−sr
kg))∥2
2]
(a)
≤ηtXK
k=1αr
kXM
τ=1E[∥∇F(wr
g)− ∇Fk(wr−sr
kg)∥2
2]
=ηtXK
k=1αr
kXM
τ=1E[∥∇F(wr
g)− ∇F(wr−sr
kg)
+∇F(wr−sr
kg)− ∇Fk(wr−sr
kg)∥2
2]
(b)
≤ηtXK
k=1αr
kXM
τ=12E[∥∇F(wr
g)− ∇F(wr−sr
kg)∥2
2]+
ηtXK
k=1αr
kXM
τ=12E[∥∇F(wr−sr
kg)− ∇Fk(wr−sr
kg)∥2
2]
(c)
≤2LηtXK
k=1αr
kXM
τ=1E[∥wr
g−wr−sr
kg∥2
2]+
2ηtXK
k=1αr
kXM
τ=1E[∥∇F(wr−sr
kg)− ∇Fk(wr−sr
kg)∥2
2]
(d)
≤2ηtML2ε2+ 2ηtMζ (51)
where (a) follows the Jensen’s Inequality, (b) follows the
inequality ∥x1+x2∥2
2≤2∥x1∥2
2+ 2∥x2∥2
2, (c) follows the
(10) in assumption 1, and (d) follows the (12) in Assumption
2 and the (14) in Assumption 3.Combining (48)-(51), we can obtain
A1≤B1+B2+B3
≤(δ−ηtM
2)E[∥∇F(wr
g)∥2
2] + 2ηtML2ε2+ 2ηtMζ
+ηtL2XK
k=1αr
kXM
τ=1E[∥wr−skg−wr−sk
k,τ−1∥2
2]
(52)
B. Bound of A2
In this section, we derive the bound of A2,
A2=E[∥wr+1
g−wr
g∥2
2]
=E[∥˜wr−wr
g+XK
k=1αr
k∆wr
k+˜nr∥2
2]
(a)
≤2E[∥˜wr−wr
g∥2
2] + 4E[∥XK
k=1αr
k∆wr
k∥2
2]
+ 4E[∥˜nr∥2
2]
(b)=2E[∥˜wr−wr
g∥2
2]
|{z }
B1+ 4E[∥XK
k=1αr
k∆wr
k∥2
2]
| {z }
B2
+4dσ2
u
(P
k∈Kar
kpr
k)2(53)
where (a) follows the inequality (44), and (b) follows noise
mean square calculation.
We analyze B1andB2separately. We bound the term B1
as ,
B1=E[∥˜wr−wr
g∥2
2]
=E[∥XK
k=1αr
k(wr−sr
kg−wr
g)∥2
2]
=KXK
k=1(αr
k)2E[∥wr−sr
kg−wr
g∥2
2]
≤ε2KXK
k=1(αr
k)2(54)
we study the term B2as follow,
B2
=E[∥XK
k=1αr
k∆wr
k∥2
2]
(a)
≤XK
k=1αr
kE[∥∆wr
k∥2
2]
=ηt2XK
k=1αr
kE[∥XM
τ=1∇Fk(wr−sr
k
k,τ−1;Dr−sr
k
k,τ)∥2
2]
≤ηt2MXK
k=1αr
kXM
τ=1E[∥∇Fk(wr−sr
k
k,τ−1;Dr−sr
k
k,τ)∥2
2]
(b)=ηt2MXK
k=1αr
kXM
τ=1E[∥∇Fk(wr−sr
k
k,τ−1;Dr−sr
k
k,τ)
− ∇Fk(wr−sr
k
k,τ−1)∥2
2]
+ηt2MXK
k=1αr
kXM
τ=1E[∥∇Fk(wr−sr
k
k,τ−1)∥2
2]
(c)
≤ηt2M2σ2
+ηt2MXK
k=1αr
kXM
τ=1E[∥∇Fk(wr−sr
k
k,τ−1)∥2
2]
(d)=ηt2M2σ2+ηt2MXK
k=1αr
kXM
τ=1E[∥∇Fk(wr−sr
k
k,τ−1)
− ∇Fk(wr−sr
kg) +∇Fk(wr−sr
kg)∥2
2]
(e)
≤ηt2M2σ2+ 2ηt2M2XK
k=1αr
kE[∥∇Fk(wr−sr
kg)∥2
2]+ 2Mηt2XK
k=1αr
kXM
τ=1E[∥∇Fk(wr−sr
k
k,τ−1)
− ∇Fk(wr−sr
kg)∥2
2]
(f)
≤ηt2M2σ2
+ 2Mηt2L2XK
k=1αr
kXM
τ=1E[∥wr−sr
k
k,τ−1−wr−sr
kg∥2
2]
+ 2ηt2M2XK
k=1αr
kE[∥∇Fk(wr−sr
kg)− ∇F(wr−sr
kg)
+∇F(wr−sr
kg)∥2
2]
(g)
≤ηt2M2σ2+ 4ηt2M2ζ+ 4ηt2M2β2E[∥∇F(wr
g)∥2
2]
+ 2Mηt2L2XK
k=1αr
kXM
τ=1E[∥wr−sr
k
k,τ−1−wr−sr
kg∥2
2]
(55)
where (a) follows Jensen’s Inequality, (b) and (d) follow
equality (41), (c) follows the equality (43), (e) follow equality
(44), (f) follows the (11) in Assumption 1, and (g) follows
the (12) in Assumption 2 and (15) in Assumption 3.
Combining (53)-(55), we can obtain
A2≤2B1+ 4B2+4dσ2
u
(P
k∈Kar
kpr
k)2
≤4dσ2
u
(P
k∈Kar
kpr
k)2+ 4ηt2M2σ2+ 16ηt2M2ζ
+ 16ηt2M2β2E[∥∇F(wr
g)∥2
2] + 2ε2KXK
k=1(αr
k)2
+ 8Mηt2L2XK
k=1αr
kXM
τ=1E[∥wr−sr
k
k,τ−1
−wr−sr
kg∥2
2]
(56)
C. Proof of Theorem 1
Combining (47), (52) and (56), we obtain
E[F(wr+1
g)]
≤E[F(wr
g)] +A1+L
2A2
(a)
≤E[F(wr
g)] + ( δ−ηtM
2+ 8Lη2
tM2β2
+ (ηtL2+ 4Mη2
tL3)4η2
tM3β2
1−2η2
tM2)E[∥∇F(wr
g)∥2
2]
+ 2ηtML2ε2+ 2ηtMζ+Lε2KXK
k=1(αr
k)2
+ 2Lη2
tM2σ2+ 8Lη2
tM2ζ
+ (ηtL2+ 4Mη2
tL3)η2
tM3σ2+ 4η2
tM3L2ζ
1−2η2
tM2L2
+2Ldσ2
u
(P
k∈Kar
kpr
k)2(57)
where (a) follows (18) in Lemma 1.
By subtracting F∗at both sides of (57), we have
E[F(wr+1
g)−F∗](a)
≤ArE[F(wr
g)−F∗] +Gr(58)with
Ar=1 + 2 Lδ−LηM + 8L2η2Mβ2
+ (ηL2+ 4Mη2L3)8Lη2M3β2
1−2η2M2L2,(59)
and
Gr= (2ηM+ 8LηM2+4η2M3L2(ηL2+ 4Mη2L3)
1−2η2M2L2)ζ
| {z }
(a)
+ 2ηML2ϵ2
|{z}
(b)+ (2η2LM2+(ηL2+ 4Mη2L3)η2M3
1−2η2M2L2)σ2
| {z }
(c)
+Lϵ2KXK
k=1(αr
k)2
| {z }
(d)+2Ldσ2
n
(PK
k=1br
kpr
k)2
|{z }
(e),
(60)
where (a) follows (19) in Lemma 2.
Assume the FL algorithm terminates after Rrounds, given
an initial global model w1,we carry out recursions as
E[F(wR+1
g)−F∗]
≤ARE[F(wR
g)−F∗] +GR
≤ARAR−1E[F(wR−1
g)−F∗] +GR−1+GR
≤···
≤RY
t=1ArE[F(w1
g)−F∗] +RX
t=1(RY
i=r+1Ar)Gr+GR(61)
Thus, this completes the proof.