arXiv:2401.07178v1  [econ.TH]  14 Jan 2024Utilitarian Beliefs in Social Networks: Explaining
the Emergence of Hatred
Houda Nait El Barj, Stanford University
Théophile Sautory, U.C. Berkeley
July 2021
Abstract
We study the dynamics of opinions in a setting where a leader h as a payoff that depends on
agents’ beliefs and where agents derive psychological util ity from their beliefs. Agents sample
a signal that maximises their utility and then communicate w ith each other through a network
formed by disjoint social groups. The leader has a choice to t arget a ﬁnite set of social groups
with a speciﬁc signal to inﬂuence their beliefs and maximise his returns. Heterogeneity in
agents’ preferences allows us to analyse the evolution of op inions as a dynamical system with
asymmetric forces. We apply our model to explain the emergen ce of hatred and the spread
of racism in a society. We show that when information is restr icted, the equilibrium level of
hatred is determined solely by the belief of the most extremi st agent in the group regardless of
the inherent structure of the network. On the contrary, when information is dense, the space is
completely polarised in equilibrium with the presence of mu ltiple “local truths” which oscillate
in periodic cycles. We ﬁnd that when preferences are uniform ly distributed, the equilibrium
level of hatred depends solely on the value of the practical p unishment associated with holding
a hate belief. Our ﬁnding suggests that an optimal policy to r educe hatred should focus on
increasing the cost associated with holding a racist belief .
1“If societies cannot enforce the separability of the human m ind into sensitivity for what is science
and for what is not science, then we can predict that as humans evolve, the taste for truth will
disappear incrementally as it yields less pleasure” - Fried rich Nietzsche, Gay Science 1882.
1 Introduction and motivation
Not all beliefs are born equal. Traditional models of learni ng often assume that the only obstacles
to the truth are agents’ cognitive capacity and the informat ion structure. However, in some cases,
the main obstacle preventing an agent from learning the trut h could be her own self. Take the
example of an employee who is being told repeatedly by a colle ague that he is doing a bad job.
Our employee may choose to ignore what his colleague is telli ng him because it hurts his self-
image. In fact, his colleague is sending him a truthful signa l about his work performance. After
a certain period of time, the employee gets ﬁred for bad perfo rmance. If the truth did not hurt the
employee, he might have been more attentive to the signals se nt by his colleague. This would have
potentially allowed him to improve his work performance and avoid getting ﬁred.
In general, knowing the truth allows agents to take optimal a ctions in the real world. This is
the main motivation for humans to learn about the world in whi ch they live in. In certain cases,
knowing the truth also yields some psychological utility, a nd as such this can alter the extent to
which agents learn. Knowledge of a certain topic can create a trade-off between the psychological
and the practical utility associated with it. When learning the truth yields psychological discomfort,
we can observe that agents “choose their own version of reali ty”.
In a February 2021 article, the New York Times interviewed a n umber of experts in differ-
ent ﬁelds on how the Biden administration can solve what they call our new “reality crisis”: a
world where an increasing number of citizens chose to create “their own version of reality” from
hoaxes and conspiracies.1Examples of conspiracy theories relate to whether the Covid Vaccine
will implant a tracking microchip or whether Satanic cannib alistic pedophiles run a global child
sex trafﬁc. Conspiracy theories are gaining in popularity a nd can have practical consequences for
the democracy and social stability of a country.
1“How the Biden Administration Can Help Solve Our Reality Cri sis These steps, experts say, could prod more
people to abandon the scourge of hoaxes and lies.” New York Ti mes, 02/02/2021
2Indeed, various theories propogated the idea that COVID-19 was manufactured in a Chinese
lab fueling anti-Asian racism globally. Xenophobic and vio lent acts targetted at the Chinese com-
munity spurged after COVID-19: as of October 2020 more than 2 ,800 incidents were ofﬁcially
reported in the USA.2Similarly, the United Kingdom disclosed an increase of 21% i n anti-asian
hate crimes as compared to the previous year suggesting the p attern is not unique to the US.3In
parallel, the Black Lives Matter movement raised awareness on the ubiquitous violence and racism
that impacts the global Black community.
The rise in hate crimes has opened up a social and political de bate about the roots and mecha-
nisms of hatred. In our paper, we show that hatred can be exact ly understood as a belief that yields
utility. Starting with René Girard, the anthropological li tterature argues that in order for someone
to turn hateful towards a social group, they must be able to bl ame the scapegoat for some event
they suffered from. As such, degrees of hatred can be equated to strength of beliefs: “The more I
am convinced that COVID-19 has been created by the Chinese, t he more likely I am to act upon
it by comitting a racist act”. Besides, hatred can also resul t from network effects, where certain
individuals turn hateful the more they are surrounded with h ateful people to feel socially integrated
to their circle.
In fact, hate crimes and scapegoating are not a new phenomeno n. Armenians were blamed
for the decline of the Ottoman Empire, Jews were blamed for th e austerity in Germany following
World War I, Tutsis were blamed by the Hutus for Rwanda’s econ omic crisis in the 80s...4Not only
have scapegoats emerged to take on the blame for economic and social downturns, but various
social groups have also been designated as the cause of the ap pearance and spread of pandemics.
Jews were blamed for the Plague in 1347, AIDS was blamed onto t he gay community and the
Chikungunya disease was blamed on the Comorean immigrants. One could think that strong insti-
tutions, social progress, and increasing education levels would eradicate such irrational behaviours.
Yet the Coronavirus pandemic brought scapegoating and raci st acts to modern evidence. Even in
democratic and well-educated nations, the Chinese have bee n blamed by some of the local popu-
lation for the virus. A natural question that arises then is h ow does hatred emerge and how can we
reduce it?
2As reported by STOP AAPI Hate.
3https://www.theguardian.com/world/2020/may/13/anti- asian-hate-crimes-up-21-in-uk-during-coronavirus-cr isis
4Moise, Jean. 2014. “The Rwandan Genocide: The True Motivati ons for Mass Killings”
3This paper aims to provide a general model of utilitarian bel iefs that can be applied to answer
this question. We study the mechanisms through which belief s that yield psychological utility
emerge and spread in a social network. The recent psychologi cal litterature has revealed the key
role of social groups and cognitive dissonance in shaping ag ents’ choices of beliefs. We base
our model on psychological evidence for these forces in orde r to better capture and explain the
dynamics of utalitarian beliefs. Our framework is based on Y ariv (2002) belief utility model where
we assume that a given belief yields both instrumental and ps ychological utility. Thus, when
agents face a choice of signals to sample to learn about a stat e of the world, they sample whichever
brings them the highest utility. In our setting, agents have hetereogenous preferences: the relative
importance of the psychological utility in determining the ir choice of belief vary. This reﬂects
the fact that people value the truth differently. We can thin k of the value of the truth as being
pinned down by some psychological cost. Some people will wan t to learn the truth no matter what,
whereas some other people will avoid learning the truth to ke ep a good self image. We analyse
a society composed of disjoint social groups where agents wa nt to learn a state of the world.
Their belief determines their action and the associated pay -off but also the psychological pleasure
they feel. As in DeGroot (1974), beliefs evolve as agents com municate with other agents in their
group. Through their communication, they update their beli efs until a consensus is reached. In our
framework, the consensus reached in a social group will depe nd on the topology of the network,
the signals agents received as well as their underlying pref erences.
We then apply our model to explain the dynamics of hatred. We r eview the psychological and
anthropological litterature related to hatred. We identif y two forces: the desire to blame and the
desire to belong, that are essential in the emergence of hatr ed. Our general model of utilitarian
beliefs can be conveniently applied to the case of hatred, as it encompasses these two forces. In
our setting, a leader has a political interest in blaming the cause of a downturn or pandemic onto a
social minority group. The majority of agents suffered from this event. They hold a belief on how
likely the scapegoat is responsible for it. This belief then determines whether or not they commit
a racist act but also yields them psychological utility. If t hey commit a racist act, agents receive
a punishment. Individual’s preferences, the structure of s ocial groups -their sizes, connectedness
and segregation as well as the access to information all dete rmine the level of hatred. Our model
thus provides a rich framework through which we can study the dynamics of hatred.
4We show that when information is restricted, the level of hat red is determined solely by the be-
lief of the most extremist agent in the network. However, in t he presence of free and diverse source
of information, the space becomes polarised with the local c onsensus varying accross groups.
These consensus are driven by network effects, where some in dividuals end up chosing a hate be-
lief only after their neighbour adopts it. On the contrary we ﬁnd that when information is dense,
the equilibrium level of hatred oscillates in periodic cycl es and the space is completely polarised.
This gives a greater incentive to the leader to spread hatred . In such societies, agents can create
their own information circles to hold a belief that yields th em higher utility without inccuring the
cost of social dissonance. We show that when agents have unif orm preferences, , the equilibrium
level of hatred depends uniquely on the practical punishmen t associated with holding such a belief.
As the number of agents in the population grows, the populati on tends to satisfy these assumptions.
The primary contribution of this paper is to provide a framew ork guided by psychological
evidence to study the forces that shape the formation of util itarian beliefs. In contrast to prior
work, our model studies the dynamics of beliefs with a networ k fragmented into social groups
and from which agents yield utility. This allows us to study t he impact of both preferences and
topological structures of communities on the evolution of o pinions. To the best of our knowledge,
we are not aware of any prior work that provides such a framewo rk. This paper also makes a
contribution to the theoretial literature on the analysis o f dynamical systems. An advantage of our
framework is that we can deﬁne our system under asymetric for ces resulting in the characterisation
of periodic equilibria. In such a setting, our model describ es a population with a polarised basis
of agents, and a set of oscillating members whose beliefs evo lve. Grounded on psychological
and anthropological evidence, our model can be applied to st udy the dynamics of hatred within
societies. We hope that our conclusions can help inform the d esign of policies to limit racism.
The remainder of the paper proceeds as follows. Section 2 pre sents the model. Section 3
exposes the psychological litterature on which our model is based, reviews the related economic
litterature and lays the groundwork for our application to h ate dynamics. Consequently, Section
4 applies the model to study the diffusion of hatred followin g a major disastrous event. Section 5
concludes. The Appendix contains the proofs for all the resu lts.
52 Model
Consider a world with two possible states Θ={0,1}. Society is composed of Nagents. Let
G={G1,G2,...,Gk,Gk+1}be the set of all K+1 ﬁxed social groups.5We impose that agents
belong to a single social group, i.e., for all j,k∈{1,2,..,K+1}such that j/\e}atio\slash=k, Gj∩Gk=/ 0.
Agents evaluate the probability of the true state. We let µt,i=pt,i(θ=1)be the belief of agent i
in time t. At the beginning of period 0 ,µ0,i=0∀i. This means that initially, all agents believe the
true state to be θ=0 with certainty.
Rounds of communication take place at each period through wh ich agents discuss and update
their beliefs. We will explain how beliefs are updated later in this section. For now, we want
to introduce the concept of “credibility” and deﬁne how agen ts interact. Let φi,jrepresent the
credibility of agent jfor agent i, this represents how much agent ilistens and trusts agent j, where
φi,j≤1. If φi,j=1, then agent ibelieve agent jto tell the truth, and at the other extreme, φi,j=0
implies that agent idoes not listen to agent j. Deﬁne gto be the function that maps an invidiual i
to his social group gin society, g:N→G. We assume that communication happens only within
agents of the same social group, and that each agent listens t o any agent of its group, including
herself, thus imposing:
φi,j=0⇐⇒ g(i)/\e}atio\slash=g(j)
There is a leader, who is not part of any social group. He has a p ayoff that depends on agents’
beliefs. In particular, he maximises his payoff when all age nts believe the true state to be θ=1
(i.e. µi=1,∀i). To inﬂuence agents’ belief and increase his return, the le ader can send them a
signal suggesting that the true state is θ=1 . Denote the signal sent by the leader as sL=1. The
leader can choose which social groups to target with such sig nals. All agents which are part of
social groups not targetted by the leader stick to their init ial belief. This means that the leader can
affect only the beliefs of the social groups he explicitly ta rgets.
Similarly to how agents hold grant certain credibility for e ach other, agents also grant credibil-
ity to the leader. We denote by φL
ithe credibility of the leader for agent i. While the credibility of
5In our paper, we are not interested in how social groups are de ﬁned: they could represent different political
afﬁliations, demographics or preferences.
6agents are ﬁxed, we let the credibility of the leader vary. In particular, we assume that the more
social groups the leader targets with his signals, the less c redible he is.6LetS⊂Gbe the set of
social groups targetted by the leader. We then have that:


φL
i,S>φL
i,S′⇐⇒ | S|<|S′| ∀ i,S,S′g(i)∈S,g(i)∈S′
φL
i,S=0⇐⇒ g(i)/∈S
Consequently, the return of the leader will depend on the set of social groups he targets. Let
Rt:S→Rbe the function that gives the return of the leader in a period t:
RT(S)=∑
i∈SµT,i−|S|c
where cis a cost of communication. The leader maximisation problem is thus to ﬁnd a set of
groups S∗that will maximise his returns.
We now explain how agents form and update their beliefs. At th e beginning of each period t,
agents are exposed to a single or to multiple signals, st∈(0,1]and can choose whether or not to
sample one of them.7Each agent weigh a signal sC
tfrom source Cby the the trust or accuracy they
assign to the source. We denote by λC
ibe the trust agent igives to source C. Let ˆµt,ibe agent i
chosen belief in period t, after she decided which signal to sample (if any). Agent i’s chosen belief
fully determines her action in period t. We let at,idenote the action of agent i.at,i∈{0,1}where
ˆµt,i=p(at,i=1).
An agent chooses her belief ˆµt,ito maximise her per-period utility:
U(µt,i)=u(µt,i)+σiv(µt,i)
Assume no discounting such that each util is felt in the prese nt period and vanishes afterwards.
In this setting, the ﬁrst component uis the instrumental utility that the agents gets from the act ions
implied by her belief. The instrumental utility function is the following :
6This has a natural interpretation: when targetting a single social group, a leader can adjust his communication
to the exact preferences of that social group in order to pers uade them. As the number of social groups he targets
increases, his speech becomes less speciﬁc and de facto less effective.
7We assume that a signal exactly equal to 0 is impossible where as we allow for a signal to be exactly equal to 1
since such a signal is sent by the leader which we endow with co mmunicative and manipulative skills.
7u(µt,i)=

χ at,i=0
−χat,i=1
where χ>0. The second component of our utility, v,is the psychological utility the agent gets
from her belief. σcharacterises how much an agent cares about the psychologic al pleasure derived
from his belief relative to its practical consequences mate rialised by χ. In our set up, we want the
psychological utility to be maximal when agents believe the true state of the world to be θ=1
at antipodes with their instrumental utility, creating a di lemma. An agent’s belief depend on the
signal they chose to sample. As such, and to provide to provid e a psychological utility in the range
[−1,1], we deﬁne v:
v(µt,i)=2λC
t,i/parenleftbigg
sC
t,i−1
2/parenrightbigg
Note that vis not deﬁned when the agent chooses not to sample a signal (i. e. when st,i=/ 0 ). In
such a case, we set v(µt,i)=0.
Once agent have chosen their belief, rounds of communicatio ns happen within each social
group. We represent our social network as a directed weighte d graph G(N,E(G))where each
connected component corresponds to a social group. Vertice s correspond to agents and edges
corresponds to interactions between agents. The weight on a n edge− →i jcaptures the inﬂuence of
agent ion agent j, which corresponds to φj,iin our model and is assumed to be ﬁxed accross periods.
8Note that φi,j/\e}atio\slash=φj,iis allowed since our model allows for asymetric inﬂuence or c redibility
accross agents. Let Φbe the n×nnon-negative stochastic matrix of interactions and µt,kbe the
row vector of beliefs of agents in period tafter krounds of communication. The dynamics are
described by:
µt,k=µt,k−1Φ
We then have that µt,k+r=µt,kΦ(r)where Φcan be thought of the transition matrix of a Markov
chain. We assume that Φis irreducible and aperiodic which allow us to apply the mart ingale con-
vergence theorem to the beliefs.9Irreducibility corresponds to the existence of a path conne cting
8Fixing the credibility of agents can be interpreted as agent s having bounded rationality. Indeed, rational agents
should update the credibility or accuracy they give to a cert ain source when new information is revealed to them.
9See Kemeny and Snell (1960)
8any two vertices in the graph and implies aperiodicity when φi,i>0∀i(all agents value their previ-
ous belief). Deﬁne ω∗as the left row eigenvector corresponding to the unique eige nvalue equal to
1 for Φ. After enough rounds of communication in period t, beliefs converge :
ct=ω∗ˆµt
Let’s now illustrate the dynamics of our model with a simple e xample.
Example. A society with two social groups G1andG2. Only G1is targeted by the leader.
There are 3 agents in group G1. Since G2is not targeted by the leader, all agents in this social
group will stick to their prior by construction, so we are onl y interested in the dynamics of the
group G1.
Letχ=0.4. At the start of period 0, they all have a belief of exactly 0. Now, at the begining
of period 0, they are exposed to only one signal sL=1. With each agent is associated a triplet
{σ,φL}. We have for agent 1: {σ1=0.1,φL
1=0.2}, for agent 2: {σ2=0.9,φL
2=0.5}and for
agent 3:{σ3=0.9,φL
3=0.8}.
We characterise the matrix of interactions Φin this example to be :
Φ=
0.1 0.4 0.5
0.1 0.6 0.3
0.3 0.5 0.2

Let’s analyse the belief decision of agent 1.
If he samples no signal, i.e. s0=/ 0, then he stays at his prior which is µo=0 and so his utility
is:
U(ˆµ0|so=/ 0)=−χ·µ0+χ·(1−µ0)+σ1·0
=0·(−0.4)+0.4·1+0.1·0
=0.4
If he samples s0=1, then his chosen belief is ˆµo=φL
1·sL+(1−φL
1)·µo=0.2·1+0.8·0=0.2
9and so his utility is
U(ˆµ0|so=1)=−χ·µ0+χ·(1−µ0)+σ1·2φL
1/parenleftbigg
sL−1
2/parenrightbigg
=0.2·(−0.4)+0.4·0.8+0.1·0.1·1
=0.25
In this case, for agent 1, U(ˆµ0|so=/ 0)>U(ˆµ0|so=1), and as such, he will chose not to sample
the signal and stick to his prior. Thus, his chosen belief at t he begining of period 0, is ˆµ0,1=0.
Applying the same logic to agent 2 and 3, we get ˆµ0,2=0.5 and ˆµ0,3=0.8. Thus, our row vector
of initial chosen belief in period 0 is :
ˆµ0=(0 0.5 0.8)
After one round of communication, the row vector of beliefs i s given by :
µ0,1=ˆµ0·Φ
=(0 0.5 0.8)·
0.1 0.4 0.5
0.1 0.6 0.3
0.3 0.5 0.2

=(0.29 0.70 0.30)
After 6 rounds of communication, beliefs eventually conver ge,µ0,6= (0.51 0.51 0.51).
Thus, c0=0.51 and the period 0 ends. Period 1 begins, and all agents of G1initially hold a belief
µ1=0.51. Then, the same steps described for period 0 happen and sim ilarly for all future periods.
103 Psychological evidence and related litterature
In our model, we want to capture the idea that the dynamics of l earning are singular in presence of
utilitarian beliefs. In particular they depend on how much w eight agents place on the psycholog-
ical component of their belief. Furthermore, as humans are s ocial beings who communicate with
one another, the dynamics of opinions should be studied from a social network framework. This
becomes even more crucial in the presence of utilitarian bel iefs. Indeed, we will show in Section
4 that network effects can create incentives for individual s to adopt certain beliefs that they would
not have adopted with different neighbours. Consequently, in this section, we want to provide
psychological evidence for the forces that shape the dynami cs of utilitarian beliefs. We review the
psychological litterature associated with scapegoating t o show how hatred can be understood as a
belief that yields utility. This will allow us to apply our mo del to the dynamics of racism in Section
4.
In his seminal book “Le bouc émisssaire”, French anthropolo gist René Girard establishes a
theory where scapegoating is deﬁned as a collective phenome non that emerges when individuals
have been experiencing an endemic and unconscious violence . By being able to gather “all against
one”, the scapegoat allows for violence to be released and ex pressed in society. Under his theory,
the choice of the scapegoat is arbitrary, as it only serves th e purpose of an external outlet through
which the majority can get deliverance from their internal a nxiety. Consequently, moments of
scapegoating in History should be recurring, as they repres ent a collective crisis that rises in in-
tensity until the internalized violence culminates and mus t be released. While the designation of
the scapegoat is independent of any cause, the targetted gro up must ﬁt certain criteria. First, the
scapegoat must be a minority group that can clearly distingu ished from the majority. Second, the
majority must believe that the scapegoat is somewhat respon sible for the misfortune they are ac-
cusing them of. Finally, the scapegoat must present some ext reme quality such as wealth, beauty,
vice, or weakness.
René Girard’s theory is closely related to Freud’s notion of projection which he deﬁnes as
the “self reproach repressed by erecting defensive symptom of distrust of other people. In this
way, the subject withdraws his acknowledgement of the self- reproach”(Freud, Further Remarks
on the Neuro-Psychoses Of Defence 1896b) . In Freudian psych oanalytic theory, projection is an
11unconscious defense mechanism through which agents get rel ief by displacing their reproach onto
someone else and can do so “without any consideration for rea lity”. Doing so allows the agent to
reduce cognitive dissonance that could result from discove ring unﬂattering aspects of one’s image
or reality such as the notion of guilt (Freud, Fragment of An A nalysis Of A Case Of Hysteria
1905).
Building up on Freud’s ideas, Dollard et al. (1939) theorize the emergence of scapegoats
as the result of society’s frustration following a speciﬁc e vent. Individuals cannot target their
violence at the original source (either because it is absent or non accessible). Consequently, the
aggression is displaced towards an easy target, which usual ly happens to be a minority group.
Providing evidence for the frustration-aggression hypoth esis of Dollard, Hovland and Sears (1940)
show that incidence of lynchings of Black people in Southern states is positively correlated with
bad economic indicators. Amongst other works, Douglas (199 5) characterizes scapegoating as a
strategy used by agents to minimize feelings of guilt over th e outcome of a negative event for which
they could be responsible. Related to this theory, Rothschi ld et al. (2012) posit that a scapegoat
allows for the majority to keep their moral integrity by disp lacing guilt. In three studies, they show
that a negative outcome that could be linked to one’s own acti ons or whose source is unknown
increase scapegoating. In their theory, two fundamental fo rces lead to scapegoating : the need to
perceive oneself as morally valuable and the need to perceiv e oneself as having control over one’s
environment.10
Common to all these theories is the desire to blame a social gr oup to get a sense of relief
from the potential responsibility agents could have in thei r own misfortune. The need for blame
as a fundamental process in social cognition has been docume nted in the psychology litterature.
Beardsley (1970) characterizes blame as “a power and poigna ncy for human life unparalleled by
other moral concepts”. While blame allows agent to project g uilt onto a chosen scapegoat, they
must be able to justify that the victim deserves her mistreat ment. (McKenna, 2012). Cikara,
Botvinick and Fiske (2019) show that the more an individual p erceive themselves as threatened by
the minority, the more pleasure they get from punishing them .
Malle, Guglielmo and Monroe (2014), propose a theory of blam e in which an ordering of
10Glick (2002) and Glick (2005) also develop a theory where sca pegoating is attractive as it allows individuals to
make sense of negative outcomes without a clear cause in a sim ple way, which restores the desire for control over their
environment, as they can now simply punish the scapegoat.
12criteria (event detection, agent causality, intentionali ty, obligation, reasons and capacity) deﬁnes
degrees of blame. The human desire for meaning, and avoidanc e of uncertainty as well as avoid-
ance of the responsibility for a negative outcome all justif y the desire for blame (Malle and Knobe
1997, Wong and Weiner 1981, Hilton 2007). Experimental evid ence for blame has been provided
in Gurdal, Miller and Rustichini (2013) where principals bl ame agents for the negative outcome of
a lottery even though they are aware it is a random event.
Another essential force of scapegoating is operated via the collective power of social groups
versus the targeted minority. An essential criterion is the ability of the blamers to self-dissociate
from the blamed, which must hence stem from categorization o f social groups into in-groups (the
blamers) and the outgroups (the scapegoat).11.Tajfel et al. (1971) show that more deﬁned social
categorization allows for increased discriminative behav iors with more “ingroup favoritism” and
more “outgroup prejudice”. Tajfel (1981) and Chen and Li (20 09) show that agents usually seek to
maximize the difference between salient in-groups and outg roups. Categorization of society into
social groups operates as the necessary structure through w hich differential treatments of oneself
and the other can happen, so long as they can be differentiate d. Therefore, the more distinct and
distanced the scapegoat in society relative to other groups , the easier it is for agents to direct hate
and blame at them.
At the heart of social groups lies the human need for belongin g. From an evolutionary per-
spective, belonging could represent a survival advantage s ince groups can better hunt, protect
themselves from predators, and ﬁnd potential mates to repro duce. (Mangel and Clark 1985).
Baumesteir and Leary (1995) deﬁne the need to belong as an “ev olutionary selection that guide
individual human beings into social groups and lasting rela tionships. These mechanisms would
presumably include a tendency to orient towards other membe rs of the species, a tendency to ex-
perience affective distress when deprived of social contac t or relationships, and a tendency to feel
pleasure or positive affect from social contact and related ness”. Baumesteir and Wotman (1992),
show that belonging to a social group is usually associated w ith positive emotions such as hap-
piness and safety, while Baumesteir and Tice (1990), Leary a nd Tambor (1993), Argyle (1987)
and Myers (1992) all show that social exclusion, and a sense o f isolation as well as being de-
11See L. Z. Tiedens & C. W. Leach (Eds.). Studies in emotion and s ocial interaction. The social life of emotions (p.
314–335)
13prived of relationships is associated with higher depressi on, anxiety and grief. Kiecolt-Glaser et
al. (1984) found that loneliness was associated with decrea se in immunocompetence and increase
in urinary cortisol respectively. Lynch (1977) summarises evidence from many studies to conclude
that “U.S. mortality rates for all causes of death are consis tently higher for divorced, single, and
widowed individuals" than for married individuals”.
Social groups deﬁne their own social norms, which are a set of implicit rules that categorize
what is acceptable within the group. Deviation from one’s gr oup social norms has been shown to
lead to communication to produce conformity and eventually loss of social status (Festinger 1950,
and Schachter 1951). Since belonging is a fundamental need f or humans, the above imply that
agents would not in general not want to deviate from their gro up’s accepted beliefs at a given time.
The structure of social groups has a dual impact on the format ion of hatred: at the scapegoat
level, it allows individual to dissociate from that particu lar group and to direct the hatred at them.
Further, when social groups are rigid and static, agents fee l more pressured to adhere to the average
group belief as they would not be integrated in society other wise. If a belief forms in a given group
and the agent would not initially choose to believe in it, she might feel pressured to do so in order
to be integrated in her own social group. However, this press ure lessens when the agent has the
possibility to belong to a different social group if she expr esses different views than his initial
group majority. Therefore, in our model, agents’ desire to b elonging is an essential force in the
formation of the hate belief that is shaped by the topology of social groups.
The other essential force that we will capture is the desire f or self-esteem. This implies that
agents are more inclined into believing a speciﬁc group is re sponsible for the bad economic en-
vironment when they have themselves suffered from it. Agent s blame the scapegoat following an
unconscious desire to vengeance, holding them responsible for a global event that causes them
distress.12Even if they do not feel attacked or threatened by the scapego at, holding them respon-
sible allows hatred to operate as a mean of projection of dist ress into a clear recipient object. This
mechanism provides agents with relief and a sense of certain ty.
To our knowledge, the economic literature on scapegoating i s limited to the work of Glaeser
(2005). He uses a model of supply and demand to derive an equil ibrium level of hatred in an econ-
12Galofré-Vilà et al. (2017) ﬁnd that between 1930 and 1933, Ge rman districts most im-
pacted by radical austerity measured are associated with hi gher vote shares for the Nazi party.
https://www.nber.org/system/ﬁles/working_papers/w24 106/revisions/w24106.rev0.pdf
14omy where factors such as desire for vengeance, time spent li stening to atrocities stories about
the minority as well as costs from reduced economic interact ions impact the demand side while
the desire to complement policies from a political candidat e, ﬁnancial resources of actors and ho-
mogenous party platforms determine the supply side. Our wor k is closely related to Glaeser (2005)
since we both characterise hatred as being initially sparke d by a leader who has some political gain
in blaming a minority and where agents have some utility in fe eling hateful. However, our model
uses a new framework of non-Bayesian learning where beliefs enter the utility of agents. This al-
lows us to study how both the interactions within social grou ps and selﬁsh preferences impact the
level of hatred. Furthermore, in our model, we are able to cha racterise how some individuals are
incited to hatred only because of their neighbours being hat eful. In Glaeser (2005) agents become
haters as a function of the amount of time spent hearing horri ble stories, whereas in our model,
hatred is a belief that varies with the information access an d the preferences of each agent. In our
setting, the macroscopical level of hatred is determined gl obally by the structure of social groups.
On the contrary to Glaeser (2005), limiting factors take acc ount of the propensity through which
individuals update their belief with the available informa tion and through communication.
Our work is also closely related to the economic literature o n psychological expected utility
whereby beliefs about a given state impact the utility direc tly. Laying the grounds for our model
are Yariv, (2001); Koszegi, (2003), Oster, Shoulson and Dor sey (2014) and Caplin and Leahy
(2001). In those models, agents actions depend on their beli efs and are the result of a utility-
maximisation problem. These beliefs yield ego-utility whi ch interferes with the optimal actions
being taken. On the other hand, our paper also relates to the l iterature on non-bayesian updating.
The closest works to ours in the questions asked are Golub and Jackson (2010), Acemoglu et al.
(2008) and De Marzo, Vayanos, and Zwiebel (2003). Other rele vant paper to our work are Banerjee
(1992); Acemoglu and Ozdaglar (2010), Bikhchandani, Hirsh leifer, and Welch (1992); Ellison and
Fudenberg (1993), Acemoglu Chernozhukov, and Yildiz (2016 ), Banerjee and Fudenberg (2004)
Mossel, Sly and Tamuz (2015), Molavi, Tahbaz-Salehi and Jad babaie (2018) and Reshidi (2020).
4 Application of our model to the dynamics of hatred
We can now aply our model to understand how hatred emerges and spread within a society.
15Consider a society initially prosperous, until a major hars h economic or social event happens
that touches a signiﬁcant share of the population.13This cause-event is disastrous at a large scale:
not only does it impact the life of many agents but the impact i tself is consequential for each agent.
Following such a large-scale event, no clear responsible ca n be unequivocally identiﬁed. This
represents a threat for the political leader14to be blamed. Targetting the blame at a speciﬁc group
represents a political advantage where he can win some elect orate. As argued in section 3, the
chosen scapegoat group must meet two criteria : they must be a minority to provide a political
advantage to the leader (otherwise he would loose more elect orate than he can potentially win) and
the majority should be able to make a link between the current event and the scapegoat group.15
Consider a world with two possible states , Θ={0,1}with θ=1 corresponding to the event
“The scapegoat is responsible for the event and should be pun ished” and θ=0 corresponding to
the event “The scapegoat is not responsible”. Let µt,i=pt,i(θ=1)be the belief of agent iin time
t. Initially, at the onstart of period 0, µ0,i=0∀i, essentially representing the fact that racism is not
“innate” since we are interested in studying its emergence a nd dynamics.
There are K+1 social groups in our society, assume that the group GK+1is the scapegoat. It
is a minority group associated with the global event. Then, t he leader has a choice of which subset
S⊆G\Gk+1to target with hateful signals about the scapegoat to incite hatred.
4.1 A dictator world
First, let’s study the dynamics of hatred in a dictator world , where information is restricted to the
one provided by the leader.
Consider a group in G\Gk+1and assume that they are targetted by the leader. We know that
initially all agents start with µ0,i=0, and at each period they receive a signal st,i=sL=1,∀i,tand
13Examples of such events can be found in history. For instance , following World War I, Germany was held
responsible for the damages caused and had to repay an amount of 67.8 billion goldmarks, which led to a period of
austerity that touched in particular middle and lower class es. Another modern example could be the pandemic of the
Coronavirus that led to more than 300,000 deaths in the USA.
14In our model we assume the existence of a unique leader intere sted in spreading hatred. Extensions with multiple
competing political parties are left for future research.
15For instance, in the 1920s in Germany, the majority of middle and lower classes lived under dire economic
conditions due to the austerity imposed while Jews were usua lly in the upper class and hence very wealthy. Thus
Hitler could introduce the idea that since Jews were untouch ed by austerity they must have wanted it, and are hence
responsible for Germany’s misery. In a similar way, Trump in troduces the idea the Chinese people are responsible for
the Coronavirus pandemic since the virus originated in Chin a.
16λt,i=φL
i,∀t. Thus the choice of agents when receiving this signal is eith er to sample it, or ignore
it and stick to their prior. Since initially µi,−1=0∀i, agents must gain a lot of blaming-utility to
choose to adopt the leader’s belief. There are huge initial c osts of holding a hate belief.16Thus
after being exposed to the leader in period 0, the beliefs of a gents are :


ˆµ0,i=φi,Lifσi>2X
ˆµ0,i=0 if σi≤2X
Then, after choosing their belief, they communicate, and th ey do so at each new period. We
then have the following result:
Proposition 1. Equilibrium level of hatred
At ﬁnite horizons, the network topology matters, in particu lar, within one round of commu-
nication we can guarantee a minimum consensus belief at unde r the following condition on the
network topology. We have ω∗
j≤ω∗
kfor every σj≥σkandφL
j<φL
k. On the contrary, at inﬁnite
horizon, the network topology is irrelevant. Provided ther e is a single agent with σi>2X, then
limk→∞ck=max{φL
i}
i:σi>2X(φL
i−cq)
φL
i,for some q. In particular, if there a single agent k with σk>2X
andφL
k=max{φL
i}i∈Nthen lim k→∞ck=φL
kregardless of the network topology.
This proposition reveals an important dynamic of a utilitar ian belief. At the ﬁnite horizons,
for a given sequence of initially chosen beliefs, as determi ned by σ, agents with lowest beliefs on
hate should be those who have the highest social inﬂuence on t he network. Under the dynamics of
our system, the ﬁnite horizon consensus belief is a convex co mbination of the leader’s credibility
for agents. Some agents are forced into hatred due to the comm unication round and convergence
of opinions without it ever being the result of the inﬂuence o f the leader on them. Those agents
can be interpreted as individuals who do not have much incent ive to develop hatred and the only
way their individual belief is contributing into the ﬁnal ha te consensus level is via them adopting
their group belief. On the reverse, agents with high incenti ve to hatred make an individual choice
to become hateful and their adopting of the leader’s belief h as a direct impact on the ﬁnal belief.
But at inﬁnite horizon, the steady-state level of hatred is i ndependent of the network topology
16An interesting empirical question would be whether φLandσare independent. Is the credibility or accuracy an
agent assigns to another dependent on how much they want to be lieve in their words. Or said differently, do we tend
to take as accurate statements that we desire to believe in?
17and at equilibirum, the leader targets all agents in the majo rity group, and they all have belief
µ∞=max{φL
i}
i:σi>2X(φL
i−cq)
φL
i,for some qand commit a racist act with probability µ∞. The intuition for
inﬁnite horizon equilibrium is the follow. At the beginning of each period, agents can adopt the
leader’s belief weighted by his credibility whenever it yie lds enough utility. Utility is increasing in
the probability that the true state is θ=1, where more agents adopt the leader’s belief giving other
agents an incentive to adopt it as it establishes social norm s in their society. Said differently, the
people with the highest utility to blame will be the ﬁrst to ad opt the leader’s belief. Even though
preferences of agents and the punishment for holding a hate b elief never change, as the consensus
increases more agent have an incentive to adopt the leader’s belief as it becomes the norm. This is
exactly because of the group effect that we described in sect ion 3.
Given these dynamics, we are now interested in the decision o f the leader. Who will he target
with hateful messages to spark hatred?
Consequently, the leader has a choice of choosing which grou ps in S={G1,G2,...,Gk}to
target with hateful messages in order to maximise his return s as deﬁned in Section 2.
Assume that the leader cares about the level of hatred in a fut ure period r(for example rcould
be the election period) but sends hateful messages in all per iods 0 to r.
We can thus redeﬁne our leader maximisation problem using ou r assumption of distinct groups
:
max
i∑
i∈Sµi−|S|c⇐⇒ max
G∈Sck,G|G|−|S|c
subject to

φL
i,S>φL
i,S′⇐⇒ | S|<|S′| ∀ i,S,S′g(i)∈S,g(i)∈S′
φL
i,S=0⇐⇒ g(i)/∈S
where gis the mapping function deﬁned in section 2 .
In particular, we let φL
i,S=max{0,φL
i−Ns
K}where Ns=|∪G∈SG|andK=|G1∪...∪Gk|. Then
his return R: 2S→R, is given by R(S′)=ck,G|G|−|S′|cforG∈S′andS′⊆S. In the below, we will
assume that c=0, representing the fact that nowadays targetting individu als with messages can be
18done at virtually no cost via social platforms such as Twitte r or Facebook. This assumption does
not alter the qualitative or comparative nature of our resul ts. Adding a cost reduces the incentive
for the leader homogenously accross all groups. We will be lo oking at a period rwhere all groups
are in equilibrium consensus as deﬁned in the above section.
Proposition 2. In a dictator world, where the leader can have full control of the signals sent to
individuals, if max i∈GφL
iis equal in all groups, then the choice of the leader is simply determined
by the size of the groups. Let S∗denote the set of social groups maximising the leader’s retu rns,
which may not be unique, then S∗is chosen such that |S∗|=φL,max·K
2. Under heterogenous
preferences, and equal group sizes, |g|=N∀g,then the leader targets all group g with φg>N
K.
Finally, if social groups are not heterogenous in their pref erences and sizes, then the leader return
maximising set must balance off adverse effects of group siz es. In fact if S∗is a return-maximising
set of groups, then: all omitted groups G m/∈S∗are such that φm<|Gm|
K+2∑s∈S∗|gs|
Kand all
included groups G s∈S∗verify φs>|Gs|
K+2∑l∈S∗,l/\e}atio\slash=s|gl|
K.
Proposition 2 calls attention to an important fact: the size of a group is at the same time a curse
and an advantange for the leader. The bigger the group, the gr eater the number of people that turn
hateful if this group is targetted by the leader, which incre ases his returns. However, the bigger the
group, the more it represents an absolute advantage to the le ader so the more he has to adapt his
communication to ﬁt the preferences of this group. Conseque ntly he is less credible for all groups,
thus reducing back his returns. As such, when groups all have a similar extreme individual (i.e. as
an individual whose credibility for the leader is maximal an d similar in all groups) then the choice
of the leader simply comes back to selecting social groups su ch that his choice is half the population
size hence balancing the trade off. However, when groups are very heterogenous in the agent who
has maximum credibility, then the leader has to select which groups to target individually where
both(φL,max
G,|G|)matter. Intuitively, he wants to target groups with the high est possible φL,max
G
but with a size |G|enhancing the absolute effect of φL,max
G(more hateful people) instead of having
more effect on reducing φL,max
G′for all other groups G′/\e}atio\slash=G(leader is less credible for everyone
because of high size group). Thus, even when the cost of commu nication is 0, to optimise his
returns and maximise the level of hatred in society, the lead er should not target all groups. The
relative sizes of groups and their preferences will be an imp ortant factor in determining whether or
19not they are being targetted by hateful messages from the lea der to spark hatred.
4.2 A world with diverse information
We now focus on a modern world of free diverse information whe re agents are not only targetted
by signals from the leader but they are also exposed to a conti nuum of signals on (0,1].17Since
there is a continuum of signals on (0,1]we will simplify our choice space and assume that the
agent has at the begining of each period ka choice to sample a signal sk∈{s0,1,/ 0}where s0≈0
is a signal sent from a policymaker whose interest is to ﬁght h atred and sk=1=sLis the signal
sent from the leader. Indeed, since the agent choses which si gnal to sample based on her realised
utility, she is always comparing levels of utility. We assum e that this comparison ends up being a
binary comparison between a signal of almost 0 and a signal of 1.18If the agent does not sample
a signal, she sticks to her prior which is last period’s conse nsus.
In the presence of multiple signals and a leader targetting a t each period all agents to promote
hatred, one might wonder when does the policymaker have the m ost return in treating agents
with information to reduce their hate belief. In this set up, agents sample a signal if and only
if it provides the most utility. Thus, signals from the polic ymaker might be never sampled and
represent a pure economic cost. In the next proposition, we s how when the policymaker has the
highest return in sending truthful information to agents.
Proposition 3. Suppose the policymaker had the option to randomly send trut hful information
(sP≈0)to agents in order to reduce their hate belief. When agents yi eld ego utility from their belief
and sample a signal in order to maximise their utility, then t he policymaker has the most return in
sending truthful signals when σis distributed on U(0,1), where Uis the uniform distribution.19
The result of proposition 3 is very intuititive. The choice o f signal sampled by the agent de-
pends on the value of their σ. If the policymaker treats randomly agents with informatio n, she
17We assume that skcan be equal to 1 exactly since it is the signal sent from the le ader who has some manipulative
power whereas a signal can never be exactly 0.
18This is not exactly correct, as signals of different magnitu de can be weighted differently (reﬂecting accuracy or
trust of each source) and so the comparison is not always tran sitive. However, in the below, we will assume that we
can always ﬁnd two signals of very close magnitude coming fro m inﬁnite sources which are hence assigned different
level of trust, such that our comparison can be transitive an d reduce to a choice between a signal of magnitude almost
0 and a signal of magnitude 1.
19E. Weinan, Li, Tiejun and Vanden-Eijnden. 2019. “Applied St ochastic Analysis”. Graduate Studies In Mathe-
matics. American Mathematical Society. has been a useful resource to derive this result.
20wants the effect of her treatment to be the greatest. This hap pens exactly when σis uniformly
distributed. Indeed, if σwere deterministic, the policymaker would be better off lea rning about
the types of agents beforehands and selecting the agents who seσimply they will sample her sig-
nal. Yet, when she treats randomly agents (because the cost o f learning their type is too high for
instance) she maximises the effect of her treatment when σis random as well. Practically, the
policy maker has the most return in sending informative sign als randomly when an event touches
a large population in a similar manner (a pandemic, a large ec onomic crisis...).
Recall that agents weigh the signal from the leader by φL
i.In the below we will assume that λP
i,
the accuracy or trust the agent has in the policymaker is λP
i=1−φL
i.Since we restrict signals to
be diametrically opposite, they likely come from antitheti c sources. As such, agents will trust one
or the other depending on their identity and preferences. He nce at the beginning of each period,
agents choose to sample or not a signal such that :
sk,i=argmax
ˆµk,iU(ˆµk,i) subject to ˆµk,i=λC
k,isC
k,i+(1-λC
k,i)ck−1∀k,sC
k,i∈{s0,1,/ 0}
Studying the dynamics of hatred, we get the following result which describes how society
becomes more polarised as the consensus belief increases. T he society becomes split into followers
(agents who always sample the signal of the leader and follow him) and resistants (agents who
follow the policynaker) and the agents who are indifferent d ecreases.
Proposition 4. Under the presence of both a leader and a policymaker targett ing all agents with
signals respectively sP≈0and µL=1, when agents choose their belief in order to maximise
their utility, then as the consensus group belief increases , the network becomes more polarised.
Eventually, when c k>1
2, the society is completely polarised with agents either fol lowing the leader
by sampling his belief or resisting him by sampling the polic ymaker belief and these form two
distinct groups.
When ck<1
2, as the consensus increases, more people are incentivised t o sample the signal
from the policymaker and similarly more people are incentiv ised to sample the signal from the
leader. Equivalently, as the consensus increases, less peo ple have an incentive to stick to the
consensus. This is reﬂected by different effects on each gro up.
21Initially, when the consensus is low, a large group of people would rather stick to the consensus
without explicitly taking an individual risk in either upda ting their belief towards the policymaker
or towards the leader. Sampling the leader’s signal leads to a higher hate belief and implies higher
risk of being punished by acting upon it. On the reverse, samp ling the policymaker signal implies
a lower hate belief and hence imposes a psychological cost on the agent (who can no longer blame
as much on the scapegoat). Therefore, sticking to the consen sus is the conservative option and
balances out the two risks. Said differently, it is less cost ly for agents to adopt either version of
reality passively rather than explicitly chosing it. Howev er, as the consensus increases, this group
of people becomes smaller as they have more incentive to adop t either version of reality. The
consensus increasing has different implication on the grou p of people who are inclined to sample
the signal of the leader vs those who sample the policymaker’ s.
As the consensus increases, agents with low utility of blami ng perceive a higher risk of being
punished by adopting a high hate belief if they stick to the av erage group belief and as such make
an explicit decision to chose a lower hate belief by sampling the policymaker’s signal. On the
reverse, agents with higher utility of blaming are more incl ined into explicitly adopting a higher
hate belief by sampling the signal of the policymaker since t he average group belief is already high
anyways. (i.e. they are incentivised to be more hateful when other people around them are already
somehow hateful).
These two effects are opposite on each group and can be descri bed of as risk-aversion (or
empathy) versus ego utility effect.
Eventually, when ck>1
2, the society becomes completely polarised with agents eith er explicitly
adopting the signal of the leader or adopting the the signal o f the policymaker. On the one hand
agents with high utility of blaming will always follow the le ader (followers) and agents with low
utility of blaming (or equivalently agents who weigh more th e practical implications of hatred -lack
of empathy, loss of opportunities in life..) will resist the leader (resistants) but no one is indifferent.
Given these asymetric dynamics, we can study the equilibriu m level of hatred. In the next
proposition, we show that we can characterise it under diffe rent settings.
Proposition 5. Let F be the function describing the dynamics of the consensu s, i.e. c k=F(ck−1)
and c∗denote its equilibrium if it exists. We then have the followi ng results:
1. When φLandσare independently distributed on U(0,1), then c∗=1−χ, as N→∞.
222. Without any assumption on the distribution of φLandσ, then F is piecewise linear function
deﬁned on [0,1]composed of M +1disjoint intervals I 1,...,IM, where M is the number of discon-
tinuities of F over [0,1]. Then, F admits a stable ﬁxed point c∗if c∗is the ﬁxed point of the ﬁrst
visited interval such that F (Im)⊆Im.
3. When F does not admit a stable ﬁxed point c∗in the ﬁrst interval where F (Im)⊆Imand
without any assumption on the distribution of φLandσ, then the consensus belief is eventually
periodic.
The results of proposition 5 are striking. Recall that σdescribes how much an agent weighs
the psychological utility yield from his beliefs relative t o its practical utility. As such, σpins
down which agents sample the leader or the policymaker’s sig nal or none. Which agents belong to
which category further depends on the general level of hatre d at each period, and hence varies with
time. Consequently, when we do not assume any distribution f orφLandσ, the equilibrium level
of hatred will depend on the relative proportions of these th ree groups, which vary accross periods.
Either these proportions balance out exactly, and Fadmits a stable ﬁxed point, or the consensus
belief will be eventually periodic. In such a case, an exact e quilibrium is not guaranteed, and the
level of hatred varies periodically. In this equilibrium st ate, the population is split into three distinct
groups: the resistants, the followers, and the agents who os cillate between beliefs.Regardless of
the bounds of the periodic oscillations, the value of the pun ishment Xplays a crucial role in the
equilibrium level of hatred. As Xincreases, the number of agents who always sample the signal
from the policy-maker (leader) cannot decrease (increase) . This suggests that directing policy
towards increasing the practical cost associated with hold ing a hate belief has potential to reduce
each agent’s hatred level.
In fact, in a society where agents’ credibility for the leade r and their desire to blame are uni-
formly distributed, then the equilbrium level of hatred is s olely a function of the punishment associ-
ated with holding a hate belief. This means that if the cause e vent touched agents homogeneously,
then the best way to reduce the level of hatred, is to increase the cost associated with it. This
observation complements the ﬁndings from Proposition 3. Wh enσis uniformly distributed, the
policymaker has the highest returns in proposing general in formation campaigns, rather than fo-
cusing on speciﬁc agents in the population. This is because t reating agents randomly, even if they
are not the most hateful, will reduce the general level of hat red via network feedback effects. In
23large populations, the equilibrium level of hatred becomes completely pinned down by the punish-
ment value. This is because the types of agent as deﬁned by the ir value of {σ,φL}determine their
actions. When {σ,φL}are distributed uniformly and independently, the asymetri c forces guiding
agents’ choices eventually balance out in the system. Then, the only threshold determining the
direction of their force (i.e. whether they lean towards the policymaker or the leader), is only a
function of the punishment χ. Consequently, to reduce the level of hatred, governments s hould
increase the cost associated with it. This can be understood either as legal punishment for hate
crimes, social cost associated with being racist...This su ggests an important direction for future
policy.
5 Conclusion
Humans optimal decision-making process is often associate d with desires to reduce suffering and
maximise happiness. As such, it makes sense to interpret bel iefs within the same framework
when they yield utility to the agent who holds them. We propos e a framework to study utilitarian
beliefs within social networks. We believe that it is import ant to understand how such beliefs
must be analysed differently. They result from the utility- maximising choice of the agent, where
heterogeneity in preferences implies different individua l decision-making processes. Studying
these asymmetric forces within network effects is essentia l to better understand how these beliefs
evolve. We based our model on psychological and anthropolog ical evidence for such forces and
applied it to study the dynamics of hatred, -which can be repr esented as a utilitarian belief. We ﬁnd
that when preferences are uniformly distributed, the equil ibrium level of hatred depends solely on
the value of the practical punishment associated with holdi ng a hate belief. Our ﬁnding suggests
that misinformation campaigns are inefﬁcient when agents d erive utility from their beliefs. An
optimal policy should instead focus on increasing the cost o f holding a racist belief.
24References
Acemoglu, Daron, Victor Chernozhukov, and Muhamet Yildiz. 2016. “Fragility of asymptotic
agreement under bayesian learning.” Theoretical Economics 11(1): 187–225.
Acemoglu, Daron, and Ozdaglar, Asuman. (2010). “Opinion Dy namics and Learning in Social
Networks”. Working Paper
Acemoglu, Daron, Dahleh, M.A., Lobel, Ilan, and Ozdaglar, A suman. (2008). “Bayesian Learning
in Social Networks”. Review of Economic Studies. 78:1201-1236.
Argyle, M. (1987). “The psychology of happiness”. Methuen.
Banerjee, A. (1992). “A Simple Model of Herd Behavior”. The Quarterly Journal of Economics .
107(3): 797–817
Banerjee, Abhijit, and Fudenberg, Drew. (2004). “Word-of- Mouth Learning”. Games and Eco-
nomic Behavio r. 46(1):1-22
Baumeister, R. F., and Leary, M. R. (1995). “The need to belon g: Desire for interpersonal attach-
ments as a fundamental human motivation”. Psychological Bulletin , 117(3), 497–529.
Baumeister, R. F., and Wotman, S. R. (1992).” Emotions and so cial behavior.Breaking hearts: The
two sides of unrequited love”. Guilford Press.
Baumeister, R. F., and Tice, D. M. (1990). “Anxiety and socia l exclusion”. Journal of Social and
Clinical Psychology : 9(2), 165–195.
Beardsley, Elizabeth. (1970). “Moral Disapproval and Mora l Indignation”. Philosophy and Phe-
nomenological Research (31): 161-176
Bikhchandani, Sushil, David Hirshleifer, and Ivo Welch. (1 992).“A Theory of Fads, Fashion,
Custom, and Cultural Change as Informational Cascades”. Journal of Political Economy .
100(5): 992-1026.
Caplin, Andrew, and Leahy, John. (2001). “Psychological Ex pected Utility Theory and Anticipa-
tory Feelings”. The Quarterly Journal of Economics. 116(1):55-79
Chen, Yan, and Sherry Xin Li. 2009. "Group Identity and Socia l Preferences." American Eco-
nomic Review, 99 (1): 431-57
Cikara M, Botvinick MM and Fiske ST. (2011). “Us versus them: social identity shapes neural
responses to intergroup competition and harm”. Psychol Sci . 22(3): 306-13
Degroot, Morris H. 1974. “Reaching a Consensus”. Journal of the American Statistical Associa-
tion. 69(345) : 118-121.
De Marzo, Peter, Vayanos, Dimitri, and Zwiebel, Jeffrey. (2 003). “Persuasion Bias, Social In-
ﬂuence, and Unidimensional Opinions”. The Quarterly Journal of Economics . (118)-3:
909–968.
Dollard, J., Miller, N. E., Doob, L. W., Mowrer, O. H., & Sears , R. R. (1939). Frustration and
25aggression. Yale University Press.
Douglas, T. (1995). Scapegoats: Transferring blame. New Yo rk, NY: Routledge Press.
Ellison, Glenn, and Fudenberg, Drew. (1993). “Rules of thum b for social learning”. Journal of
Political Economy . 101(4): 612-643
E. Weinan, Li, Tiejun and Vanden-Eijnden. 2019. “Applied St ochastic Analysis”. Graduate Stud-
ies In Mathematics. American Mathematical Society.
Festinger, L. (1950). “Informal social communication”. Psychological Review . 57(5): 271–282
Festinger, L., Schachter, S., and Back, K. (1950). “Social p ressures in informal groups; a study of
human factors in housing”. Harper
Freud, Sigmund. 1896. “Further Remarks on the Neuro-Psycho ses Of Defence - Weitere Be-
merkungen Über Die Abwehrneuropsychosen” Neurol. Zbl., 15 (10): 434-48.
Freud, Sigmund. 1905. “Fragment of An Analysis Of A Case Of Hy steria - Bruchstück einer
Hysterie-Analyse”. Mschr Psychiat Neurol (18):285–309.
Galofré-Vilà, Gregori, Meissner, Christoper M., McKee, Ma rtin and Stuckler, David. 2017 “Aus-
terity and the rise of the Nazi party”. NBER Working Paper 24106.
Girard, René. 1982. “Le bouc émissaire”. Editions Grasset .
Glaeser, Edward L. 2005. “The Political Economy of Hatred”. The Quarterly Journal of Eco-
nomics. 120(1):45-86.
Glick, P. (2002). “Sacriﬁcial lambs dressed in wolves’ clot hing: Envious prejudice, ideology, and
the scapegoating of Jews.” In L. S. Newman & R. Erber (Eds.), Understanding genocide:
The social psychology of the Holocaust (p. 113–142). Oxford University Press.
Glick, P. (2005). Choice of Scapegoats. In J. F . Dovidio, P . Glick, & L. A. Rudman (Eds.), On the
nature of prejudice: Fifty years after Allport (p. 244–261). Blackwell Publishing.
Golub, Benjamin, and Jackson, Matthew O. (2010). “Naïve Lea rning in Social Networks and the
Wisdom of Crowds”. American Economic Journal: Microeconom ics, 2 (1): 112-49
Gurdal, M.Y ., Miller J.B. and Rustichini, A. (2013). “Why Bl ame?”. Journal of Political Economy .
121(6):1205-1246. The University of Chicago Press
Hovland, C. I., & Sears, R. R. (1940). Minor studies of aggres sion: VI. Correlation of lynch-
ings with economic indices. The Journal of Psychology: Inte rdisciplinary and Applied, 9,
301–310.
Hilton, D. J. (2007). “Causal explanation: From social perc eption to knowledge-based causal
attribution”. In A. W. Kruglanski & E. T. Higgins (Eds.), Social psychology: H andbook of
basic principles (2nd ed., pp. 232–253) . New York, NY: Guilford
Kemeny, J.G. and Snell, J.L. (1960). “Finite Markov Chains” .
Kiecolt-Glaser, J.K. et al. (1984). “Psychosocial modiﬁer s of immunocompetence in medical
students”. Psychosom Med : 46(1):7-14
26Köszegi, Botond. (2003). “Ego Utility, Overconﬁdence, and Task Choice”. Journal of the Euro-
pean Economic Association. 4(4):673-707
Leary, M. R., Tambor, E. S., Terdal, S. K., & Downs, D. L. (1995 ). “Self-esteem as an interper-
sonal monitor: The sociometer hypothesis”. Journal of Personality and Social Psychology :
68(3), 518–530
Lynch, J. J. (1977). “The broken heart: the medical conseque nces of loneliness in America”. New
York: Basic Books.
Malle, B. F., Guglielmo, S., & Monroe, A. E. (2014). “A theory of blame”. Psychological Inquiry .
25(2): 147–186.
Malle, B. F. and Knobe, J. (1997). “The folk concept of intent ionality”. Journal of Experimental
Social Psychology. 33(2): 101–121
Mangel, M, and Clark, C.W. (1986). “Towards a Uniﬁed Foragin g Theory”. Ecology, 67(5):1127-
1138.
McKenna, M. (2012). Directed blame and conversation. In Blame: Its nature and norms: 119–140.
New York, NY: Oxford University Press.
Moise, Jean. 2014. “The Rwandan Genocide: The True Motivati ons for Mass Killings”.
Molavie, Pooya, Tahbaza-Salehi, Alireza, and Jadbabaie Al i. (2018). Econometrica. 86(2):445-
490.
Mossel, Elchanan, Sly, Allan, and Tamuz, Omer. (2015). “Str ategic Learning and the Topology of
Social Networks”. Econometrica . 83(5):1755-1794.
Myers, D. (1992).The pursuit of happiness.New York: Morrow
Nogueira, A. and Pires, B., Rosales, R. A., (2013) Asymptoti cally periodic piecewise contractions
of the interval Nonlinearity, IOP Publishing, 2014, 27 (7), pp.1603--1610.
Nogueira, A. and Pires, B., (2012). Dynamics of piecewise co ntractions of the interval. Er-
godic Theory and Dynamical Systems, Cambridge University P ress (CUP), 2015, 35 (07),
pp.2198-2215.
Oster, Emily, Ira Shoulson, and E. Ray Dorsey. 2013. "Optima l Expectations and Limited Medical
Testing: Evidence from Huntington Disease." American Economic Review . 103 (2): 804-
30.
Rothschild ZK, Landau MJ, Sullivan D, Keefer LA. 2012. “A dua l-motive model of scapegoating:
displacing blame to reduce guilt or increase control”. J Pers Soc Psychol . 102(6):1148-63.
Schachter, S. (1951). “Deviation, rejection, and communic ation”. The Journal of Abnormal and
Social Psychology : 46(2), 190–207
Tajfel, H, Billig, M.G., Bundy, R.P. and Flament, Claude. (1 971). “Social categorization and
intergroup behaviour”. European Journal of Social Psychology 1(2):149-178.
27Tajfel, H. (1981). “Human Groups and Social Categories: Stu dies in Social Psychology” .Cam-
bridge University Press.
Tiedens, L. Z. and C. W. Leach (Eds.). (2004). “Studies in emo tion and social interaction. The
social life of emotions” (p. 314–335
Yariv, Leeat. (2001). “Believe and Let Believe: Axiomatic F oundations for Belief Dependent
Utility Functionals”. Available at SSRN.
Yariv, Leeat. (2002). “I’ll See it When I Believe it ? A Simple Model of Cognitive Consistency”.
Available at SSRN.
Wong, P. T., and Weiner, B. (1981). “When people ask "why" que stions, and the heuristics of
attributional search”. Journal of Personality and Social Psychology . 40(4): 650–663”
28A Appendix : Proofs
Proof of Proposition 1
Proof. First, let’s prove the ﬁnite horizon case.
In period 0, the consensus is c0=ω∗
i/hatwideµ0,i, where ˆµ0is either 0 or φL
i. Agents start period 0 with no hatred,
i.e.µ−1,i=0 for all iand are xposed to s0=µL=1. They can choose to adopt it weighted by φL
i,
where φL
i>0 in which case /hatwideµ0,i=φL
i>0 or stick to his prior in which case ˆµ0,i=µ−1,i=0.
Utility if she adopts the leader belief
E(U|x0=µL)=φL
i(−X)+(1−φL
i)X+σiφL
i
=−2XφL
i+X+σiφL
i
Utility if she sticks to his prior
E(U|x0=/ 0)=µ−1(−X)+(1−µ−1)X
=X
Thus an agent adopts the leader belief in period 0 if and only i fE(U|x0=µL)>E(U|x0=/ 0)which
happens when σi>2X
Consequently after their utility maximisation choice, age nts have either /hatwideµ0,i=φL
iifσi>2Xor/hatwideµ0,i=
µ−1=0 ifσi≤2X.
Then c0=∑i|σi>2Xω∗
iφL
i+∑i|σi≤2Xω∗
i·0=∑i|σi>2Xω∗
iφL
i. It follows that min ω∗c0⇐⇒ ω∗
j≤ω∗
kfor every σj≥
σkandφL
j<φL
k.
Let’s now prove the inﬁnite case now.
Let’s evaluate the utility at any period k>0.In any other period, the agent is evaluating the utility if he
adopts the leader belief
E(U|x1=µL)=φL
i(−X)+(1−φL
i)X+σiφL
i
=−2XφL
i+X+σiφL
i
vs the utility if he sticks to his prior:
29E(U|x2=/ 0)=ck−1(−X)+(1−ck−1)X
=−2ck−1X+X
Indeed,at round k, an agent adopts the leader belief if φL
i>µk−1andσi>2X(φL
i−ck−1)
φL
ior sticks to last
period consensus belief ck−1.
We can rewrite the consensus in period kas :
ck= ∑/braceleftbigg
i:σi>2X(φL
i−ck−1)
φL
i,φL
i>ck−1/bracerightbiggwiφL
i+ ∑/braceleftbigg
i:σi<2X(φL
i−ck−1)
φL
i/bracerightbiggwick−1+ ∑/braceleftbigg
i:σi>2X(φL
i−ck−1)
φL
i,φL
i<ck−1/bracerightbiggwick−1
ck= ∑/braceleftbigg
i:σi>2X(φL
i−ck−1)
φL
i,φL
i>ck−1/bracerightbiggwiφL
i+ck−1
∑/braceleftbigg
i:σi<2X(φL
i−ck−1)
φL
i/bracerightbiggwi+ ∑/braceleftbigg
i:σi>2X(φL
i−ck−1)
φL
i,φL
i<ck−1/bracerightbiggwi

Let’s prove the ﬁrst result. First note that as long as there i s an agent for whom σi>2X(φL
i−ck−1)
φL
i,φL
i>ck−1
then ck>ck−1.
If there is at least one agent jwith σj>2X, he adopts φL
jin period 0, then c0>0 and ckis updated
dynamically as more agents have an incentive to switch to hat red. Indeed, in period k, the incentive
to switch to hatred is σi>2X(φL
i−ck−1)
φL
iwhereas, in period k+1 it is σi>2X(φL
i−ck)
φL
i.
Let the consensus becomes stable from period K∗onwards. Then, in period K∗all agents have µk∗=c.
Assume for the sake of contradiction that c<max{φL
i}
i:σi>2X(φL
i−cq)
φL
i,for some q. Let agent mbe the
agent such that φL
m=max{φL
i}
i:σi>2X(φL
i−cq)
φL
i,for some qbutφL
m>c.
Then in period K∗,agent mchoose φL
mwhich contradicts our initial assumption.
Thus, limk→∞ck=max{φL
i}
i:σi>2X(φL
i−cq)
φL
i,for some q.
To prove the ﬁrst result, let jbe an agent such that σi>2XandφL
j=max{φL
i}i∈N.
Then by the above, if agent jhas incentive to switch in period 0 to φL
j, then at each period he chooses φL
j.
By deﬁnition, at stationary state, µi=c∀i.
Again by contradiction, at stationary state, agent c=φL
j.
Thus lim k→∞ck=max{φL
i}i∈N
30Proof of Proposition 2
LetSbe the set of groups from which the leader can choose. S={G1,G2,...,Gk}.
We deﬁne his return R: 2S→Rand for a given set S′⊆S, we have :
R(S′)=∑g∈S′(cr,g|g|−(r+1)c|g|)
Assuming c=0,
R(S′)=∑g∈S′cr,g|g|
Since ris a period of equilibrium, then we have showed above that cr,g=max i∈g{φL
i}
i:σi>2X(φL
i−cq)
φL
i,for some q.
In large groups, we can assume that the condition i:σi>2X(φL
i−cq)
φL
i,for some q is satisﬁed,
and hence cr,g=max i∈gφL
i=φg.
Then we deﬁned φL
i,S=max(0,φL
i−|∪g∈Sg|
K), soφL
g,S=max(0,φL
g−|∪g∈Sg|
K).
Since we already deﬁned φG=max i∈gφL
i, then we will let φL
g,S>0,hence φL
g,S=φL
g−|∪g∈Sg|
K.
Then
R(S′)=∑
g∈S′(φg−|∪g∈S′g|
K)|g|
=∑
g∈S′(φg|g|−|∪g∈S′g|·|g|
K)
Since we deﬁned social groups such that gi∩gj=/ 0∀i/\e}atio\slash=jthen,
R(S′)=∑
g∈S′(φg|g|−|g|2
K)
In the case with homogenous preferences, φG=φ∀g
R(S′)=∑
g∈S′(φ·|g|−|g|2
K)
Then the return becomes only a function of the total size of th e groups chosen in a given set S′. Let
N=∑g∈S′|g|for a given set S′.
31We can rewrite
R(N)=φN−N2
K
Then we see that the return maximising set S′is characterised by N=φK
2
In the case with non-homegenous preferences but equal size g roups, we can rewrite
R(S′)=∑
g∈S′(φG·M·N−M2N2
K)
=MN∑
g∈S′(φG−MN
K)
where M=|S′|andN=|g|,∀g
Then notice that adding a group increases return by φG−N
K. Consequently, the leader will target
all groups gwith φg>N
K.
Finally, under non-homegenous preferences and unequal gro up sizes, then, we can rewrite
R(S′)=∑
g∈S′(φg|g|−|g|2
K)
=∑
g∈S′φg|g|−∑
g∈S′|g2|
K−2∑M
j=1∑j−1
i=1|gi|·|gj|
K
IfS′is a return-maximising set, then if gmis an omitted group in equilibrium, we must have
R(S′∪gm)−R(S′)<0⇐⇒ φgm|gm|−|gm|2
K−2∑l∈S′|gm|·|gl|
K<0
Thus all omited groups gm/∈S′are such that φgm<|gm|
K+2∑l∈S′|gl|
K.
And on the contrary, all included groups, gs∈S′are such that φgs<|gs|
K+2∑l∈S′,l/\e}atio\slash=s|gl|
K
Proof of Proposition 3
Deﬁne the outcome xjto be the event that when the policy maker sends a signal xk=0 to
agent j, the consensus in our network ckends up being lower versus when they do not.
We have,
32pj=P(X=xj)
=P(ck|agent jgets signal xk=0<ck|agent jdoes not get signal xk=0)
=P(agent j samples signal xk=0)
=P(Uk,j(agent j samples signal xk=0)>Uk,j(agent j does not sample signal xk=0))
=

P(σj≤2Xck−1) ifck−1≤1
2
P/parenleftig
σj<2X(φL
j+ck−1−2φL
jck−1)/parenrightig
ifck−1>1
2
We can then deﬁne our Shannon entropy to provide the expected information content of X:
H(X)=E(I(X))=E(−log(P(xj))
We then get:
H(X)=−n
∑
j=1pjlog(pj)
Let’s prove that His maximized when Xand hence σis uniformely distributed.
We deﬁne the function fon the range (0, 1] as follows:
f(x)=xlog(x)
We can then write:
H(X)=−n
∑
j=1f(pj)
The second derivative of fis:
f′′(x)=1
x
which is strictly positive on the (0, 1]. Hence fis strictly convex on (0, 1], and the sum ∑n
j=1f(pj)
is a stricly convex function. Thus, His strictly concave. From the convexity of f, we make
use of the Jensen’s inequality applied to the random variabl eP(X), to write the following:
33f(E(P(X)))≤E(f(P(X))) =⇒f/parenleftbigg∑n
j=1pj
n/parenrightbigg
≤1
nn
∑
j=1f(pj)
=⇒1
nn
∑
j=1f(pj)≥f/parenleftbigg1
n/parenrightbigg
=⇒ − H(X)≥n1
nlog/parenleftbigg1
n/parenrightbigg
=⇒H(X)≤log(n)
For a uniform distribution, where pj=1
n,∀j, the Shannon entropy is:
H(X)=−n
∑
j=1pjlog(pj)=−n1
nlog/parenleftbigg1
n/parenrightbigg
=log(n)
which achieves the upper bound limit.
Finally, as His a striclty concave function, the uniform distribution is the unique distribution which
maximizes the Shannon entropy.
Intuitively this mean that information has highest power wh enσis uniformely distributed. Since a
signal x=0 can only reduce the consensus, then the effect of informati on is strictlly posi-
tive. Therefore, maximising the expected information cont ent of our information release is
equivalent to maximising the return of information.
Proof of Proposition 4
Fix a period kand remember that now the agent has a choice to sample three si gnals sk∈
{sP,sL,/ 0}where sP≈0 is the signal from the policymaker, sL=µL=1 is the signal from
the leader. Let’s evaluate the utility under each sampling p ossibility.
•Utility if the agent samples the signal from the policy-make r
The belief of the agent becomes ˆµk,i=λP
isP+(1−λP
i)ck−1≈(1−λP
i)ck−1since sk≈0
and the expected utility Uis:
E(U(ˆµk,i|s=sP
k=0))=X(1−(1−λP
i)ck−1)−X(1−λP
i)ck−1−σiλP
i
=X−2X(1−λP
i)ck−1−σiλP
i
•Utility if the agent samples the signal from the leader
34The belief of the agent becomes ˆµk,i=φL
i+(1−φL
i)ck−1and the expected utility Uis:
E(U(ˆµk,i|s=sL
k=1))=X(1−(φL
i+(1−φL
i)ck−1))−X(φL
i+(1−φL
i)ck−1)+σiφL
i
=X−2XφL
i−2X(1−φL
i)ck−1+σiφL
i
•Utility if the agent sticks to its prior
The belief of the agent becomes ˆµk,i=ck−1and the expected utility Uis:
E(U(ˆµk,i|sk=/ 0))=X(1−ck−1)−Xck−1
=X−2Xck−1
The agent will sample from the policy-maker or the leader iff it provides the highest utility of the
three methods, assume that λP
i=1−φL
i.
Then the agent prefers sampling the signal of the leader over sticking to the consensus when
E(U(ˆµk,i|s=sk=1))>E(U(ˆµk,i|s=sk=/ 0))
⇐⇒ X−2XφL
i−2X(1−φL
i)ck−1+σiφL
i>X−2Xck−1
⇐⇒ σi>2X(1−ck−1)
Then the agent prefers sampling the signal of the leader over the policymaker when
E(U(ˆµk,i|s=sk=1))>E(U(ˆµk,i|s=sk=0))
⇐⇒ σi>2X(φL
i+ck−1(1−2φL
i))
1
σi>2X(ck−1+φL
i−2φL
ick−1)
Finally, the agent prefers sticking to the consensus over sa mpling the policymaker when:
E(U(ˆµk,i|s=sk=/ 0))>E(U(ˆµk,i|s=0))
⇐⇒ X−2Xck−1>X−2X(1−λP
i)ck−1−σiλP
i
⇐⇒ σi>2Xck−1
We can then deﬁne :
35α=2X(1−ck−1)
β=2X(ck−1+φL
i−2φL
ick−1)
γ=2Xck−1
We will then rank α,β,λon[0,1]
1. Rank α,β
α<β⇐⇒ 1−ck−1<ck−1+φL
i−2φL
ick−1
⇐⇒ 1−2ck−1<φL
i(1−2ck−1)
⇐⇒ φL
i>1,ck−1<1
2orφL
i<1,ck−1>1
2
⇐⇒ ck−1>1
2asφL
i<1∀i.
2. Rank α,γ
α<γ⇐⇒ 1−ck−1<ck−1⇐⇒ ck−1>1
2
3. Rank β,γ
β<γ⇐⇒ ck−1+φL
i−2φL
ick−1<ck−1⇐⇒ ck−1>1
2
We then have two cases
Case 1 ck−1<1
2
Then we have

α>β
α>γ
β>γ
Hence we have α>β>γ
Letσi∈[0,1]where 0≤γ<β<α≤1. We evaluate the preferences on each interval. Deﬁne
C={L,P,C}to be the set of choices for the agent where he can of sampling t he leader
signal, the policmaker’s and sticking to the cosnensus. Per above each is associate with an
expected utility level so we can establish preferences.
In[0,γ], we have C/greaterorsimilarL,P/greaterorsimilarLandP/greaterorsimilarC, hence by transitivity, the agent prefers to sample the
policymaker’s signal.
In(γ,β], we have C/greaterorsimilarL,P/greaterorsimilarLandC/greaterorsimilarP, hence by transitivity, the agent prefers to stick to the
consensus.
36In(β,α], we have C/greaterorsimilarL,L/greaterorsimilarPandC/greaterorsimilarP, hence by transitivity, the agent prefers to stick to the
consensus.
In(α,1], we have L/greaterorsimilarC,L/greaterorsimilarPandC/greaterorsimilarP, hence by transitivity, the agent prefers to sample the
leader.’s signal.
Therefore we get a complete mapping on [0,1]for the choices of sampling by the agent :

Agent samples the policymaker signal ⇐⇒ σi∈[0,2Xck−1]
Agent sticks to the consensus ⇐⇒ σi∈(2Xck−1,2X(1−ck−1)]
Agent samples the leader signal ⇐⇒ σi∈(2X(1−ck−1),1]
Consequently we see that as ck−1↑, less people choose to stick to the consensus.
Case 2 ck−1>1
2
Then we have

α<β
α<γ
β<γ
Hence we have α<β<γ
In[0,α], we have C/greaterorsimilarL,P/greaterorsimilarLandP/greaterorsimilarC, hence by transitivity, the agent prefers to sample the
policymaker’s signal.
In(α,β], we have L/greaterorsimilarC,P/greaterorsimilarLandP/greaterorsimilarC, hence by transitivity, the agent prefers to sample the
policymaker’s signal.
In(β,γ], we have L/greaterorsimilarC,L/greaterorsimilarPandP/greaterorsimilarC, hence by transitivity, the agent prefers to sample the
leader’s signal.
In(γ,1], we have L/greaterorsimilarC,L/greaterorsimilarPandC/greaterorsimilarP, hence by transitivity, the agent prefers to sample the
leader’s signal.
Therefore we get a complete mapping on [0,1]for the choices of sampling by the agent :

Agent samples the policymaker signal ⇐⇒ σi∈[0,2X(ck−1+φL
i−2φL
ick−1)]
Agent sticks to the leader signal ⇐⇒ σi∈(2X(ck−1+φL
i−2φL
ick−1),1]
Consequently when ck−1>1
2, the choice space becomes completely polarised, and agents adopt
either the policymaker’s signal or the leader signal.
Proof of Proposition 5
Part 1. When the punishment value X is such that X ≥1
2, agents never sample the leader’s
signal and ∀k∈Nthe consensus belief c k=0.
Proof. Let’s prove that if X≥1
2, then∀k∈Nthe consensus belief remains ck=0.
We will prove the proposition by induction.
37LetX≥1
2and suppose ck−1=0,k−1∈N. We will show that no agent will sample from the leader nor
the policy-maker. Thus, the consensus belief will remain ck=0.
From the Proof of Proposition 4, with ck−1=0, we write that agents will sample the leader’s signal:
⇐⇒ σi>2X(1−ck−1)=2X≥1.
We also note that agents will sample the policy-makers’s sig nal:
⇐⇒ σi≤2Xck−1=0.
Recall that:
∀i∈n,σi∈(0,1).
Thus, no agent sample from the leader nor the policy-maker at timepoint k. Each agent will stick to the
consensus and hold a belief µi,k=ck−1=0.
Therefore,
ck=n
∑
i=1wiµi,k=0.
We proved that:
∀k∈N,X≥1
2,ck−1=0=⇒ck=0.
We note that the consensus belief at timepoint k=0 is such that ck=0. Thus c1=0 and we proved by
induction that:
X≥1
2=⇒ ∀ k∈N,ck=0.
Part 2. For X<1
2, if we assume that σiandφL
iare realizations of i.i.d uniformly distributed
random variables ΣandΦLover(0,1)respectively, and let the number of agents n tend
to inﬁnity, then the sequence of consensus belief c k=f(ck−1)∀k∈N∗starting at c 0=0is
monotonically increasing and converges to c ∞=1−X.
Proof. We will follow three steps to prove Proposition 2: 1) we will s how that by assuming σi
andφL
iare realizations of i.i.d uniformly distributed random var iables ΣandΦLover(0,1)respec-
tively, and letting the number of agents ntend to inﬁnity, we can express the consensus sequence
ck=f(ck−1)∀k∈Nas a quadratic and linear function of ck−1forck−1∈[0,1
2]andck−1∈(1
2,1]
respectively. 2) These expressions will allow us to prove th at for X<1
2, the consensus belief
sequence is monotonically increasing on [0,1−X). 3) We will then be able to conclude on the
convergence of the sequence to c∞=1−X.
38We will ﬁrst use the results from Proof of Proposition 4 to exp ress for all kinNthe sequence ck=f(ck−1)
as a quadratic and linear function of ck−1forck−1∈[0,1
2]andck−1∈(1
2,1]respectively.
Recall that the consensus belief is deﬁned as:
ck=n
∑
i=1wiµi,k,∀k∈N,
where µi,krepresents the hatred belief of agent iat timepoint kandwiis ﬁxed∀isuch that ∀i∈n,wi>
0 and ∑n
i=1wi=1.
To explore the dynamics of the consensus belief sequence, we will express ckas a function of the param-
eters σi,φL
ifor agents i, the constant X, and the previous consensus belief ck−1.
The Proof of Proposition 4 allows us to express f(ck−1)over the domain ck−1∈[0,1
2]as:
f(ck−1)= ∑
i,σi≤2Xck−1/bracketleftbig
wiφL
ick−1/bracketrightbig
+ ∑
i,2Xck−1<σi≤2X(1−ck−1)[wick−1]+ ∑
i,σi>2X(1−ck−1)/bracketleftbig
wi/parenleftbig
φL
i+(1−φL
i)ck−1/parenrightbig/bracketrightbig
.
(1)
Similarly, over the domain ck−1∈(1
2,1], we can write:
f(ck−1)= ∑
i,σi≤2X(φL
i+ck−1−2φL
ick−1)/bracketleftbig
wiφL
ick−1/bracketrightbig
+ ∑
i,σi>2X(φL
i+ck−1−2φL
ick−1)/bracketleftbig
wi/parenleftbig
φL
i+(1−φL
i)ck−1/parenrightbig/bracketrightbig
.
(2)
We will now apply the assumption that σiandφL
iare realizations of i.i.d uniformly distributed random
variables ΣandΦLrespectively, to simplify Equations (1,2).
From this assumption, ckis the sum of i.i.d random variables and is itself a random var iable. We can thus
apply the weak law of large numbers as the number of agents n→∞. From now on, we let n→∞.
We can write: ck=E(ck). We will now show that this allows us to express the function fover the
domain[0,1
2]and(1
2,1]as a quadratic and linear function of ck−1respectively.
We will start by taking the expected values of ckas deﬁned in Equations (1,2) respectively, and simplify
the expression for fover[0,1]. In order to compute these expected values, we will remove th e
dependencies on σiof the sum terms in Equation (1,2) and express fas a single sum over all
agents i∈N. To do so, we let, Hbe the Heaviside function deﬁned over Rsuch that:
H(x):=

0x≤0
1x>0.
For clarity, we will compute the expected values of Equation (1) and Equation (2) separately.
We now consider fin the region ck−1∈[0,1
2]deﬁned by Equation (1) and make use of the Heaviside
function Hto compute the expected value for ck.Starting from Equation (1), we write:
39f(ck−1)=E/bracketleftigg
n
∑
i=1wi/bracketleftbig
φL
ick−1+ck−1(1−φL
i)H(σi−2Xck−1)+φL
i(1−ck−1)H(σi−2X(1−ck−1))/bracketrightbig/bracketrightigg
=n
∑
i=1wiE/bracketleftbig
ΦLck−1+ck−1(1−ΦL)H(Σ−2Xck−1)+ΦL(1−ck−1)H(Σ−2X(1−ck−1))/bracketrightbig
(3)
=E/bracketleftbig
ΦLck−1+ck−1(1−ΦL)H(Σ−2Xck−1)+ΦL(1−ck−1)H(Σ−2X(1−ck−1))/bracketrightbig
.
To simplify Equation (3), we note that the expected value of H(Σ−a)fora∈Ris equal to the probability
of the event Σ>a. When a∈[0,1]andΣ∼U(0,1):
E[H(Σ−a)]=P(Σ>a)=1−P(Σ≤a)=1−a
We are now ready to express f(ck−1)in the range ck−1∈[0,1
2]as a quadratic function of ck−1:
f(ck−1)=ck−1/parenleftbigg1
2+(1−1
2)(1−2Xck−1)−1
2(1−2X(1−ck−1))/parenrightbigg
+1
2(1−2X(1−ck−1))(4)
=−2Xc2
k−1+(2X+1
2)ck−1+1
2−X.
Equation (4) will allow us to study the dynamics of the consen sus belief ckaskincreases in the range
ck−1∈[0,1
2].
The next step of the analysis is to simplify the expression fo rfas deﬁned over the range ck−1∈(1
2,1]by
Equation (2). We will then be ready to explore the dynamics of the consensus belief in the range
ck−1∈[0,1].
We will now express fas deﬁned in Equation (2) as a linear function of ck−1by using the Heaviside
function and computing the expected value of ck.
f(ck−1)=E/bracketleftigg
n
∑
i=1wi/bracketleftbig
φL
ick−1+/parenleftbig
φL
i+(1−2φL
i)ck−1/parenrightbig
H/parenleftbig
σi−2X(φL
i+ck−1−2φL
ick−1)/parenrightbig/bracketrightbig/bracketrightigg
=n
∑
i=1wiE/bracketleftbig
ΦLck−1+/parenleftbig
ΦL+(1−2ΦL)ck−1/parenrightbig
H/parenleftbig
Σ−2X(ΦL+ck−1−2ΦLck−1)/parenrightbig/bracketrightbig
(5)
=E/bracketleftbig
ΦLck−1+/parenleftbig
ΦL+(1−2ΦL)ck−1/parenrightbig
H/parenleftbig
Σ−2X(ΦL+ck−1−2ΦLck−1)/parenrightbig/bracketrightbig
.
We must now compute the expected value expressed by Equation (5). Speciﬁcally, we must calculate
40E/bracketleftbig
H/parenleftbig
Σ−2X(ΦL+ck−1−2ΦLck−1)/parenrightbig/bracketrightbig
. To do so, we let Tbe the random variable deﬁned as:
T=2X(ck−1+ΦL(1−2ck−1)).
We will now prove that Tis a uniformly distributed random variable over [2X(1−ck−1),2Xck−1], which
will allow us to prove that
∀X∈[0,1
2),∀ck−1∈(1
2,1],E/bracketleftbig
H/parenleftbig
Σ−2X(ΦL+ck−1−2ΦLck−1)/parenrightbig/bracketrightbig
=1−X.
We ﬁrst note that:
X=0,Σ∼U(0,1) =⇒E/bracketleftbig
H/parenleftbig
Σ−2X(ΦL+ck−1−2ΦLck−1)/parenrightbig/bracketrightbig
=E[H(Σ−0))]= 1=1−X.
Then, we note that:
X∈(0,1
2),ck−1∈(1
2,1] =⇒dT
dΦL=2X(1−2ck−1)<0.
Thus Tis deﬁned by a monotonically decreasing function of ΦL.ΦL∼U(0,1), therefore Tis uniformly
distributed over its range. The boundaries of Tare:
T(ΦL=0)=2Xck−1.
T(ΦL=1)=2X(1−ck−1).
We note that:
X∈(0,1
2),ck−1>1
2=⇒2Xck−1>2X(1−ck−1).
Therefore, T∼U(2X(1−ck−1),2Xck−1). By letting fT(y)be the density function of the random variable
Twe write:
fT(y)=

1
2Xck−1−2X(1−ck−1)=1
2X(2ck−1−1),ify∈[2X(1−ck−1),2Xck−1],
0, otherwise.
We are now ready to compute E/bracketleftbig
H/parenleftbig
Σ−2X(ΦL+ck−1−2ΦLck−1)/parenrightbig/bracketrightbig
. We let FΣbe the cumulative distri-
bution function of the random variable Σ∼U(0,1)and write:
E[H(Σ−T)]=1−P(Σ≤T) (6)
=1−/integraldisplay2Xck−1
2X(1−ck−1)FΣ(y)fT(y)dy
=1−1
2X(2ck−1−1)/integraldisplay2Xck−1
2X(1−ck−1)FΣ(y)dy.
41To calculate the integral in Equation (6) we note that
X∈[0,1
2),ck−1∈[1
2,1] =⇒[2X(1−ck−1),2Xck−1]⊆[0,1].
Thus:
E[H(Σ−T)]=1−1
2X(2ck−1−1)/integraldisplay2Xck−1
2X(1−ck−1)ydy
=1−1
2X(2ck−1−1)·(2X)2·(c2
k−1−(1−ck−1)2)
2
=1−2X(2ck−1−1)
2(2ck−1−1)
=1−X.
Therefore we proved that:
∀X∈[0,1
2),∀ck−1∈(1
2,1],E/bracketleftbig
H/parenleftbig
Σ−2X(ΦL+ck−1−2ΦLck−1)/parenrightbig/bracketrightbig
=1−X.
We can now simplify the expression for fdeﬁned in Equation (5) for ck−1∈(1
2,1]as a linear function of
ck−1:
f(ck−1)=E/bracketleftbig
ΦLck−1+/parenleftbig
ΦL+(1−2ΦL)ck−1/parenrightbig
H/parenleftbig
Σ−2X(ΦL+ck−1−2ΦLck−1)/parenrightbig/bracketrightbig
(7)
=1
2ck−1+(1
2+(1−21
2)ck−1)(1−X)
=1
2ck−1+1−X
2.
Equation (7) will allow us to study the dynamics of the consen sus belief ckin the range ck−1∈(1
2,1].
The sequence of consensus belief ckis now deﬁned by Equation (4) and Equation (7) on ck−1∈[0,1
2]and
ck−1∈(1
2,1]respectively. This will allow us to enter the second step of t he proof and show that
the sequence ck=f(ck−1)starting at c0=0 is monotonically increasing on ck−1∈[0,1−X).We
will then prove that the lim k→∞ck=1−X.
To prove that ckis monotonically increasing with kon the region ck−1∈[0,1−X), we will ﬁrst prove that
the consensus belief increases montonically up to a value ck∗at a period k∗∈Nsuch that ck∗>1
2.
At that timepoint, it will enter in the region where the seque nce is deﬁned by Equation (7). We will
then prove that it increases monotonically and converges to c∞=1−X.
Let’s prove that ∀X∈[0,1
2), the consensus belief sequence is monotonically increasin g in the range ck−1∈
[0,1
2], and reaches a value ck∗at a period k∗∈Nsuch that ck∗>1
2.
42From Equation (4), we note that:
ck−ck−1=−2Xc2
k−1+(2X+1
2)ck−1+1
2−X−ck−1 (8)
=−2Xc2
k−1+(2X−1
2)ck−1+1
2−X.
We will now prove that:
X∈[0,1
2),ck−1∈[0,1
2] =⇒ck>ck−1.
First, we observe that for X=0:
∀ck−1∈[0,1
2],X=0=⇒ck−ck−1=1
2(1−ck−1)>0.
Thus, for X=0, the sequence for ckis increasing for ck−1∈[0,1
2]. Let’s now prove it is also the case for
X∈(0,1
2).
We note that on ck−1∈[0,1
2]:
ck−ck−1=0⇐⇒ − 2Xc2
k−1+(2X−1
2)ck−1+1
2−X=0. (9)
We can now show that the quadratic function deﬁned by Equatio n (9) is striclty positive for ck−1∈[0,1
2],
and thus that the consensus sequence ckis monotonically increasing for ck−1∈[0,1
2].
When X∈(0,1
2), the discriminant of Equation (9) is ∆=−4X2+2X+1
4, and ∆∈(1
4,1
2]. Equation (9)
admits real solutions c1,c2of the form
c1=(2X−1
2)−/radicalig
−4X2+2X+1
4
4Xandc2=(2X−1
2)+/radicalig
−4X2+2X+1
4
4X.
By substituting the extreme values for ∆,we observe that c1<0 and c2>1
2. Therefore we observe that
forck−1∈[0,1
2],ck−ck−1is deﬁned by a quadratic function with a negative coefﬁcient for the 2nd
order polynomial term, whose roots are c1<0 and c2>1
2. Therefore:
X∈(0,1
2),ck−1∈[0,1
2] =⇒ck−ck−1>0.
We proved that:
X∈[0,1
2),ck−1∈[0,1
2] =⇒ck>ck−1.
The sequence ckis thus monotonically incerasing for ck−1∈[0,1
2].
Let’s now show that the sequence of consensus belief ckwill reach a value ck∗at period k∗such that ck∗>1
2
with ck∗−1≤1
2. This will allow us to show that the sequence enters the regio nck−1>1
2, in which
43it will converge to c∞=1−X.
First, for X=0, we notice that
ck=1
2−X+1
2ck−1=1
2(1+ck−1) =⇒c1=1
2=⇒c2>1
2.
Thus for X=0, the sequence of consensus belief ckreaches a value ck∗at period k∗∈Nsuch that ck∗>1
2.
Let’s prove that the statement holds ∀X∈(0,1
2).
Forck−1∈[0,1
2],fis a polynomial function of ck−1with a negative coefﬁcient for the 2nd order polyno-
mial term. Therefore, fis monotonically increasing on the region (−∞,argmaxck−1f(ck−1)). We
notice that:
X∈(0,1
2) =⇒argmax
ck−1f(ck−1)=1
2+1
8X>1
2.
Thus∀X∈(0,1
2),fis monotonically increasing on ck−1∈(−∞,1
2+1
8X), and speciﬁcally in [0,1
2]. Thus:
∀X∈(0,1
2),ck−1∈[0,1
2] =⇒max f(ck)=f(1
2)=3
4−X
2>1
2. (10)
Therefore, for ckto remain smaller than1
2for all k∈N, the sequence must converge to a point ck−1∈[0,1
2].
Recall that we proved Equation (8) admits no solution in ck−1∈[0,1
2]. Therefore, for ck−1∈[0,1
2]
there exist no ﬁxed point of f, and the consensus belief cannot converge to a value ∈[0,1
2]. Thus,
because the sequence of consensus beliefs ckis monotonically increasing for ck−1∈[0,1
2], and that
forck−1∈[0,1
2], max f(ck)>1
2, there exists a period k∗∈Nsuch that ck∗>1
2.
We will now prove that the consensus belief then increases mo notonically on ck−1∈(1
2,1−X)and con-
verges to c∞=1−X.
We will start by proving that the sequence of consensus belie f is monotonically increasing for ck−1∈
(1
2,1−X).
From Equation (2), we note that:
ck−ck−1=1
2ck−1+1−X
2−ck−1=1−X
2−1
2ck−1. (11)
Thus,
ck−ck−1>0⇐⇒1−X
2−1
2ck−1>0⇐⇒ ck−1<1−X. (12)
Therefore, we conclude by induction that ∀k∈N,k≥k∗=⇒ck<1−Xand the sequence of consensus
belief ckis monotonically increasing on ck−1∈(1
2,1−X].
We will now complete the proof by showing that ckis bounded above by 1 −X, which allows us to prove
the third step described, namely that lim k→∞ck=1−X.
44We use the result from Equation (12) to prove by induction tha t:
∀k∈N,ck−1∈(1
2,1],ck−1<1−X=⇒ck<1−X.
Suppose that ck−1<1−X, then:
ck<1
2(1−X)+1−X
2=⇒ck<1−X.
We now verify that the relation holds for ck∗, the ﬁrst term such that ck>1
2. From Equation (10), we note
thatck∗is bounded such that:
ck∗≤3
4−X
2.
We observe that:
3
4−X
2<1−X⇐⇒ X<1
2.
Thus:
X∈[0,1
2) =⇒ck∗<1−X.
The consensus sequence is thus bounded above by 1 −X. Therefore, it is monotonically incereasing and
bounded above, which implies its limit lim k→∞ckexists. Let c∞be this limit. We can express c∞
as:
lim
k→∞ck=lim
k→∞ck−1=⇒1
2c∞+1−X
2=c∞=⇒c∞=1−X.
We proved that, ∀X∈(0,1
2), by assuming σiandφL
iare realizations of i.i.d uniformly distributed random
variables ΣandΦLover(0,1)respectively, and letting the number of agents ntend to inﬁnity,
the consensus belief starting at c0=0 is monotonically increasing with k∈Nand converges to
c∞=1−X.
45Part 3 .f is a piecewise linear function of M +1∈Nintervals I 1,...,IM+1, whose range are deﬁned
by the M discontinuities of f over [0,1]. The discontinuites repesent the unique threshold
values of c k−1for which at least one agent i changes the signal it samples. T he M+1
pairwise disjoint intervals are such that ∪M+1
i=1Ii= [0,1]. Some of these interval I∗⊂I
admit ﬁxed points. If the consensus belief converges to a ﬁxe d point, then it will converge
to the ﬁxed point of the ﬁrst interval it visits which belongs to I*.
Proof. We are interested in providing explicit equations for the ﬁx ed points cof each of the linear
functions which deﬁne fin its continuous intervals. The discontinuities of frepesent the unique
threshold values of ck−1for which at least one agent ichanges opinion. To provide an explicit
equation for each ﬁxed point, we will ﬁrst proceed in three st eps: 1) group the agents based on
their change in signal sampling as the consensus increases, and deﬁne tias the threshold value of
ck−1for agent ifor such a change to occur, 2) order the agents in each of these respective groups
such that i<j=⇒ti<tj, 3) express the equation for the ﬁxed point cof each of these intervals.
We will then prove that intervals I∗of[0,1]which admit a ﬁxed point are such that f(I∗)⊂I∗.
This will allow us to prove that, if the consensus belief conv erges to a ﬁxed point c, then the ﬁxed
point is that of the linear function deﬁning fin the ﬁrst visited interval I∗.
We will start by providing explicit equations for the ﬁxed po ints of the linear functions which deﬁne each
interval of f.
From Proof of Proposition 5 part 2, we know that over ck−1∈[0,1],fis deﬁned as a piecewise linear
function expressed by Equations (1,2) for ck−1∈[0,1
2]andck−1∈(1
2,1]respectively. We will thus
proceed with our three step analysis for the range ck−1∈[0,1
2]andck−1∈(1
2,1]separately.
Let’s proceed with the three deﬁned steps for the region ck−1∈[0,1
2].
1) We will show that we can group all agents in iinto three sub-groups as ck−1increases in [0,1
2]: a)
agents who always sample the leader’s signal, b) agents who s tick to the consensus before always
sampling from the policy-maker when a threshold value for ck−1is reached, c) agents who stick to
the consensus before always sampling from the leader when a t hreshold value for ck−1is reached.
From Proof of Proposition 4, we recall that:


0≤σi≤2Xck−1, the agent samples the policy-maker,
2Xck−1<σi≤2X(1−ck−1),the agent sticks to the consensus,
2X(1−ck−1)<σi≤1, the agent samples the leader.
To show that we can group the agents in a), b), and c), we ﬁrst sh ow that at timepoint k=1, agents have
either stuck to the consensus or sampled from the leader:
∀i∈N,σi>0 and c0=0=⇒σi>2Xc0,
46and no agent sampled from the policy-maker. Hence at period k=1, agents stuck to the consensus
or sampled from the leader. This will allow us to group the age nts in the sub-groups as deﬁned in
a), b) and c).
a) Some agents will always sample from the leader’s signal as ck−1increases in [0,1
2]. Indeed, an agent i
will sample the leader at period 1 if σi>2X. We notice that the threshold 2 X(1−ck−1)decreases
asck−1increases in Rand escpecially on [0,1
2]. Thus, all agents isuch that σi>2Xwill sample
from the leader for all ck−1∈[0,1
2]. LetA={i|σi>2X}. Without loss of generality, we relabel
the agents in Afrom 1 to |A|=A.
b) We will now show that some agents will change from sticking to the consensus to sampling the policy-
maker as ck−1increases from 0 to1
2. By observing that:
∀ck−1∈[0,1
2],2X(1−ck−1)∈[X,2X],
we state that:
∀ck−1∈[0,1
2],∀i,σi≤X=⇒σi≤2X(1−ck−1).
Therefore, for ck−1∈[0,1
2], agents such that σi≤Xwill never sample the leader. In the limit ck−1→
1
2,2Xck−1=2X(1−ck−1)and these agents will therefore change from sticking to the c onsenus to
sampling from the polic-maker as ck−1increases in [0,1
2]. For each of these agents i, the change
will occur at a threshold value tiforck−1, such ti=σi
2X. LetBbe the set of cardinality Bof agents
isuch that σi≤X. Without loss of generality, we label the agents in Bfrom A+1 toA+B.
c) We will now show that some agents will change from sticking to the consensus to sampling the leader
asck−1increases from 0 to1
2. By observing that:
∀c∈[0,1
2],2Xc∈[0,X],
we state that:
∀ck−1∈[0,1
2],∀i,σi>X=⇒σi>2Xck−1.
Therefore, for ck−1∈[0,1
2], agents such that σi>Xwill never sample from the policy-maker. Using the
same argument as in point b), as ck−1increases in [0,1
2], these agents will transfer from sticking to
the consensus to sampling from the leader. For each of these a gents i, the change will occur at a
threshold ti=1−σi
2X. LetDbe the set of cardinality Dof agents such that σi>X. Without loss of
generality, we label the agents in Dfrom A+B+1 toA+B+D.
Now that the agents who exhibit the same behaviour as ck−1increase in [0,1
2]are grouped, we are ready to
reorder these agents within each group. This will allow us to provide explicit expressions for the
47ﬁxed points cof each of the linear functions which deﬁne the intervals of f.
2) Without loss of generality, we re-order the agents in BandD, such that within each group i<j=⇒
ti≤tj.
We will now express the explicit equations for the ﬁxed point s of the linear functions deﬁning ffor
ck−1∈[0,1
2].
3) Let Ebe the set of agents who change opinion as ck−1increases in [0,1
2]:E:=B∪D. We order the
set of threshold values tifor all iinE, such that i<j=⇒ti≤tj. We have E=|E|=B+D. Let
I1,...,IB+D+1be the Epairwise disjoint intervals such that ∪B+D+1
i=1Ii=[0,1
2], where t1,...,tB+Dare
the discontinuities of the function, t0=0 and tB+D+1=1
2. We can now deﬁne the equation for the
consensus update in the interval Im= (tm,tm+1], where 1 ≤m≤B+D. We let bbe the number
of agents iinBsuch that ti≤tm, and dthe number of agents iinDsuch that ti≤tm. We deﬁne
fm:=f(ck−1),∀ck−1∈Im. According to Equation (1) we can express that:
fm(ck−1)=A
∑
i=1wi(φL
i+(1−φL
i)ck−1)+A+b
∑
i=A+1wiφick−1+A+B
∑
i=A+b+1wick−1
+A+B+d
∑
i=A+B+1wi(φL
i+(1−φL
i)ck−1)+A+B+D
∑
i=A+B+d+1wick−1.
We can now write an explicit equation for the ﬁxed poins of the linear intervals of fforck−1∈[0,1
2]. A
point cmust be such that c∈Imandfm(c)=c. We express the latter condition as:
c=∑A
i=1wiφL
i+∑A+B+d
i=A+B+1wiφL
i
1−/bracketleftig
∑A
i=1wi(1−φL
i)+∑A+b
i=A+1wiφi+∑A+B
i=A+b+1wi+∑A+B+d
i=A+B+1wi(1−φL
i)+∑A+B+D
i=A+B+d+1wi/bracketrightig.
(13)
We expressed the equation and conditions for a ﬁxed point to e xist in the region ck−1∈[0,1
2]. We will now
repeat the anlysis on the range ck−1∈(1
2,1]before showing that if these ﬁxed points exist for f
over ck−1∈[0,1], then they are stable and the sequence of consensus belief co nverges to the ﬁxed
point cof the ﬁrst visited interval which admits a ﬁxed point.
Let’s repeat the analysis for fdeﬁned on ck−1∈(1
2,1]by Equation (7).
1) We will start by showing that we can split the agents into fo ur distinct sub-groups as ck−1increases over
(1
2,1]: a) agents who will always sample from the policy-maker, b) a gents who will always sample
from the leader, c) agents who will transfer from sampling th e leader to sampling the policy-maker
when a threshold value for ck−1is reached, and d) agents who will transfer from sampling the
policy-maker to sampling the leader when a threshold value f orck−1is reached.
We will now understand the behaviour of agents within ck−1∈(1
2,1], to subsequently group them.
48From Proof of Proposition 4, we can write:


0≤σi≤2X(φL
i+ck−1−2φL
ick−1),the agent samples the policy-maker ,
2X(φL
i+ck−1−2φL
ic)<σi≤1, the agent samples the leader.
Agents will change opinion if the order of σiand 2 X(φL
i+ck−1−2φL
ick−1)changes. To understand the
behaviour of agents, we explore the variation of 2 X(φL
i+ck−1−2φL
ick−1)with ck−1in the range
(1
2,1].
d(2X(φL
i+ck−1−2φL
ick−1))
dck−1=2X(1−2φL
i). (14)
The sign of 2 X(1−2φL
i)varies on φL
i, hence we split the agents between φL
i≤1
2andφL
i>1
2to analyse
their respective decision making behaviour.
We will now explore the behaviour of each agent iasck−1increases in (1
2,1].
We ﬁrst consider agents isuch that φL
i≤1
2and observe that:
∀ck−1∈(1
2,1],∀i,φL
i≤1
2=⇒d(2X(φL
i+ck−1−2φL
ick−1))
dck−1≥0.
We note that the thresholds at the boundaries of the interval ck−1∈(1
2,1]for agents to change are respec-
tively:

2X(φL
i+1
2−21
2φL
i)=X, ifck−1=1
2,
2X(φL
i+1−2φL
i)=2X(1−φL
i),ifck−1=1.(15)
Thus, by using the bounds from Equation (15), we state that th e threshold value of σfor an agent to sample
the leader increase linearly from Xto 2X(1−φL
i)ack−1increases from1
2to 1. So we note that:
∀ck−∈(1
2,1],∀i,φL
i≤1
2,

σi≤X, =⇒agent ialways samples the policy-maker,
σi>2X(1−φL
i),=⇒agent ialways samples the leader,
X<σi≤2X(1−φL
i),=⇒agent isamples the leader, then the policy-maker.
We now consider agents isuch that φL
i>1
2. We note that:
∀ck−1∈(1
2,1],∀i,φL
i>1
2=⇒d(2X(φL
i+ck−1−2φL
ick−1))
dck−1<0.
Thus the threshold value of σifor an agent to sample the leader decreases linearly from Xto 2X(1−φL
i)
49asck−1increases from1
2to 1. Therefore, we note that:
∀ck−1∈(1
2,1],∀i,φL
i>1
2,

σi≤2X(1−φL
i) = ⇒agent ialways samples the policy-maker.
σi>X =⇒agent ialways samples the leader.
2X(1−φL
i)<σi≤X=⇒agent isamples the policy-maker, then the leader.
We are now ready to split the population into the four distinc t sets deﬁned in a), b), c) and d). From these
groups, we will be able to write down the expressions for ﬁxed points of the afﬁne functions which
deﬁne fin the region ck−1∈(1
2,1].
Let’s group the agents.
a) Agents who will always sample from the policy-maker. We sh owed that agents isuch that


φL
i≤1
2,σi≤X,
φL
i>1
2,σi≤2X(1−φL
i).
always sample from the policy-maker. We denote Rthe set of such agents, with R=|R|. Without loss of
generality, we label the agents in Rfrom 1 to R.
b) Agents who will always sample from the leader. We showed th at agents isuch that


φL
i≤1
2,σi>2X(1−φL
i),
φL
i>1
2,σi>X.
always sample from the leader. We denote Uthe set of such agents, with U=|U|. Without loss of
generality, we label the agents in Ufrom R+1 toR+U.
c) Agents who will transfer from sampling the leader to sampl ing the policy-maker when a threshold value
forck−1is reached. We showed these agents iare such that
φL
i≤1
2,X<σi≤2X(1−φL
i).
LetWbe the set of such agents i, with W=|W|. These agents will change opinon when threshold
values tiofck−1is reached such that the order between σiand 2 X(φL
i+ck−1−2φL
ick−1)changes.
Without loss of generality, we label the agents in Wfrom R+U+1 to R+U+W. We deﬁne
∀i∈W,ti=σi
2X−φL
i
1−2φL
i.
d) Agents who will transfer from sampling the policy-maker t o sampling the leader when a threshold value
forck−1is reached. We showed these agents iare such that
φL
i>1
2,2X(1−φL
i)<σi≤X.
50LetYbe the set of such agents i, with Y=|Y|. These agents will change opinon when threshold values ti
ofck−1is reached such that the order between σiand 2 X(φL
i+ck−1−2φL
ick−1)changes. Without
loss of generality, we label the agents in Yfrom R+U+W+1 to R+U+W+Y. We deﬁne
∀i∈Y,ti=σi
2X−φL
i
1−2φL
i.
We grouped agents into four distinct sub-groups. We are now r eady to reorder the agents within the groups
and express the ﬁxed points of each of the linear functions de ﬁning fforck−1∈(1
2,1].
2) Without loss of generality, we re-order the agents in WandY, such that within each group i<j=⇒
ti≤tj.
We will now express the explicit equations for the ﬁxed point s of the linear functions deﬁning ffor
ck−1∈(1
2,1].
3) Let Zbe the set of agents who change opinion as ck−1increases in (1
2,1]:Z:=W∪Y. We order the
set of threshold values tifor all iinZ, such that i<j=⇒ti≤tj. We have Z=|Z|=W+Y.
LetIB+D+2,...,IB+D+W+Y+2be the Zpairwise disjoint intervals such that ∪B+D+W+Y+2
i=B+D+2Ii=(1
2,1],
where tB+D+2,...,tB+D+W+Y+1are the discontinuities of fonck−1∈(1
2,1], and tB+D+W+Y+1=1.
We can now deﬁne the equation for the consensus update in the i nterval Im= (tm,tm+1], where
B+D+2≤m<B+D+W+Y+2. We let wbe the number of agents iinWsuch that ti≤tm, and
ythe number of agents iinYsuch that ti≤tm. We deﬁne fm:=f(ck−1),∀ck−1∈Im. According
to Equation (2) we can express that:
fm(ck−1)=R
∑
i=1wiφL
ick−1+R+U
∑
i=R+1wi(φL
i+(1−φL
i)ck−1)+R+U+w
∑
i=R+U+1wiφL
ick−1+R+U+W
∑
i=R+U+w+1wi(φL
i+(1−φL
i)ck−1)
+R+U+W+y
∑
i=R+U+W+1wi(φL
i+(1−φL
i)ck−1)+R+U+W+Y
∑
i=R+U+W+y+1wiφL
ick−1
To be a ﬁxed point in the interval m, a point cmust be such that c∈Imandfm(c)=c.
c=R+U
∑
R+1wiφL
i+P+U+W+y
∑
P+U+w+1wiφL
i
1−/bracketleftigg
R
∑
i=1wiφL
i+R+U
∑
i=R+1wi(1−φL
i)+P+U+w
∑
R+U+1wiφL
i+R+U+W+y
∑
R+U+w+1wi(1−φL
i)+R+U+W+Y
∑
R+U+W+y+1wiφL
i/bracketrightigg
(16)
We expressed the equation and conditions for a ﬁxed point to e xist in the region ck−1∈[0,1]. We are now
ready to study the dynamics of these ﬁxed points, and conclud e on the convergence of the sequence
of consensus belief.
We have shown how to compute the ﬁxed ponits for the afﬁne func tion deﬁned within each interval sepa-
rating discontinuities. We will now prove that such ﬁxed poi nts which are in fare stable.
With M+1 as the number of distinct linear intervals of fforck−1∈[0,1],∀m∈[1,...,M+1], we deﬁne
51the slope of the afﬁne function in Imasβm. If we deﬁne n1m,n2m,n3mas the sets of indices of agents
who choose to sample the policy-maker, stick to the consensu s, and sample the leader respectively
in each interval Im, we can write:
∀m,βm=∑
i∈n1mwiφL
i+∑
i∈n2mwi+∑
i∈n3mwi(1−φL
i).
We note that:
∀i∈n,φL
i∈(0,1),wi∈(0,1),n
∑
i=1wi=1.
Thus with n1m∪n2m/\e}atio\slash=/ 0,
0<∑
i∈n1mwiφL
i+∑
i∈n2mwi+∑
i∈n3mwi(1−φL
i)<∑
i∈n1mwi+∑
i∈n2mwi+∑
i∈n3mwi=1
Thus, for any continuous interval Imof the function, if a ﬁxed point c∈Im,|βm|<1 and F(Im)⊆Im.
Therefore, all ﬁxed point deﬁned over [0,1]are stable.
Thus, if a ﬁxed point cexists in ck−1∈[0,1], the ﬁxed point is a solution of Equation (13) or Equation
(16) if cis such that c≤1
2orc>1
2respectively. We have proved that if the consensus belief vi sits
an interval Imsuch that fadmits a ﬁxed point on Im, then the consensus belief ckwill converge to
that ﬁxed point as k→∞. The consensus belief can therefore admit a ﬁxed point and co nverge to
a single value.
52Part 4. Let I vbe the set of intervals visited by the consensus belief seque nce c k=f(ck−1)as
k→∞. Let x∈N∗. Let D xbe the set of discontinuities of the xth iterate of f over c k−1∈
[0,1], deﬁned as fx. If∄I∗∈Iv,f(I∗)⊂I∗,and∃x∗∈N,∀x≥x∗,∀ck−1∈[0,1],fx(ck−1)∈
Dx−1=⇒ck−1∈Dx−1, then the consensus belief sequence is eventually periodic . Once the
consensus belief is periodic, the agents are split into thre e distinct sub-groups: a) agents
who will always sample the policy-maker, b) agents who will a lways sample the leader, c)
agents who will periodically oscillate between a combinati on of sampling the leader, the
policy-maker, or sticking to the consensus.
Proof. We will prove Proposition 4 by showing that if the discontinu ities in the iterates fxof
function fare ﬁnite as x→∞, then fis a piecewise linear function whose iterates converge to
a piecewise step function. The discontinuities of the piece wise step function are a subset of the
discontinuities of all the iterates of f. If the consensus belief visits no interval of fadmitting a
ﬁxed point, then the sequence of consensus belief is eventua lly periodic.
We sart by expressing a condition for the disconinuities in t he iterates fxoffto be ﬁnite as x→∞. This
will allow us to prove that lim x→∞fxis a stepwise function with a ﬁntite number of discontinuiti es,
and thus show that the sequence of consensus belief is eventu ally periodic.
Letx∈Nandfxbe the xth iterate of f. We deﬁne Dxas the set of discontinuities of fxover ck−1∈[0,1].
Assume that:
∃x∗∈N,∀x≥x∗,∀ck−1∈[0,1],fx(ck−1)∈Dx−1=⇒ck−1∈Dx−1. (17)
Condition (17) ensures that there exists x∗∈N, such that from the iterate x∗offonwards, no new pre-
image ck−1∈[0,1]yield a discontinuity. Therefore, there is a maximum and ﬁni te number of
disconinuities for all iterates fx,x>x∗.
From this statement, we will prove that the consensus sequen ceckis eventually periodic by showing that
ftends to a piecewise step function where each continuous int erval converges to a value in [0,1].
As the number of values visited by the consensus ckwould then become ﬁnite, the sequence of
consensus belief will become periodic.
To do so, we let gbe the ﬁrst iterate of ffor which Condition (17) holds. Suppose there are M−1 discon-
tinuities in the function g,(M−1)∈N∗. We have shown in Proof of Statement 3 of Proposition 5
that fis a piecewise linear function, where each afﬁne interval mis deﬁned with a slope βm, with
βm<1. We also let γmbe the Y-intercept of each afﬁne function mdeﬁning f. We can write:
∀m∈[1,...,M],gm(ck−1)=βmck−1+γm.
Writing g2
m(ck−1)as the second iterate of the function gover each interval m, we have:
53g2
m(ck−1)=βm(βmck−1+γm)+γm
=β2
mck−1+βmγm+γm
Generalising for all p∈N:
gp
m(ck−1)=βp
mck−1+p−1
∑
i=0βi
mγm (18)
We must now prove that lim n→∞gn
m(ck−1)converges for any min[1,...,M]. Equation (18) implies that:
βmgp
m=βp+1
mck−1+p
∑
i=1βi
mγm
Therefore,
βmgp
m−gp
m=βp
mck−1(βm−1)+βp
m−γm
=⇒gp
m=βp
m[ck−1(βm−1)+1]−γm
βm−1
Following the same reasoning as in in Proof of Statement 3 of P roposition 5, as the iterates of frepresent
a new decision making step of the agents in the population, we must have that the slope βm<1 for
all interval ming(ck−1). Thus, 0 <βm<1, and at inﬁnite horizon we have:
lim
p→∞gp
m(ck−1)=γm
1−βm
To show that lim p→∞gp
m(ck−1)converges for all ∀m∈[1,...,M], we deﬁne n1m,n2m,n3mas the sets of
agents who choose the policy-maker, consensus and leader re spectively, in interval m, and write:
∀m∈[1,...,M],βm=∑
i∈n1mwiφL
i+∑
i∈n2mwi+∑
i∈n3mwi(1−φL
i).
Correspondingly we have:
∀m,γm=∑
i∈n3mwiφL
i.
54Therefore:
∀m∈[1,...,M],βm+γm=∑
i∈n1mwiφL
i+∑
i∈n2mwi+∑
i∈n3mwi(1−φL
i)+∑
i∈n3mwiφL
i
=∑
i∈n1mwiφL
i+∑
i∈n2mwi+∑
i∈n3mwi
<∑
i∈n1mwi+∑
i∈n2mwi+∑
i∈n3mwi
=1.
Thus,
∀m∈[1,...,M],βm+γm<1=⇒γm<1−βm,
and with γm∈(0,1),βm∈(0,1)∀m∈[1,...,M],
∀ck−1∈[0,1],lim
p→∞gp
m(ck−1)∈(0,1).
Therefore, each afﬁne interval mconverges when ptends to ∞, and the function gptends to a piecewise
step function of Mconstant values ∈(0,1).
We will now show that a sequence deﬁned by a function gpwhich is a piecewise step function of M
constant values is eventually periodic.
Let:
∀m∈[1,...,M],lm=lim
p→∞gp
m(ck−1).
In the limit where p→∞:
gp([0,1])={l1,...,lM}.
The sequence becomes the mapping of a ﬁnite set within itself , which is eventually periodic. This com-
pletes the proof of statement 3.
We will now analyse the behaviour of agents when the dynamica l system is periodic.
Assume that the dynamical system of the consensus belief is p eriodic, with p0andp1the extremum
values of the period, such that 0 <p0<p1≤1. the behaviour of the agents can be separated
into: 1) agents who do not change opinion as the system evolve s over the period, 2) agents
who oscillate between different opinions. We consider the t hree cases for the values of p0
andp1, namely a) 0 <p0<p1≤1
2, b) 0<p0≤1
2and1
2<p1≤1, c)1
2<p0<p1≤1.
Case a. 0<p0<p1≤1
2
55In this range of periodic orbit, the agents’ behaviours are s plit as follows:


σi≤2X p0, the agent will always sample from the policy-maker,
σi>2X(1−p0), the agent will always sample from the leader ,
2X p0<σi≤2X p1, the agent will oscillate between the consensus and the polic y-maker,
2X(1−p1)<σi≤2X(1−p0),the agent will oscillate between the consensus and the leade r.
Case b. 0<p0≤1
2and1
2<p1≤1
In this range of extremum values, the agents’ behaviours are split as follows:
For agents isuch that φL
i<1
2:
σi≤2X p0andσi≤2X(φL
i+p1−2φL
ip1) =⇒the agent will always sample from the policy-maker
For agents isuch that φL
i>1
2:
σi>2X(1−p0)andσi>2X(φL
i+p1−2φL
ip1) =⇒the agent will always sample from the leader
For agents isuch that φL
i=1
2:


σi≤2X p0, the agent will always sample from the policy-maker,
σi>2X(1−p0),the agent will always sample from the leader .
Remaining agents will oscillate either from consensus to po licy-maker or leader, or between leader
and policy-maker.
Case c.1
2<p0<p1≤1
In this range of extremum values, the agents’ behaviours are split as follows:
For agents isuch that φL
i≤1
2:


σi≤2X(φL
i+p0−2φL
ip0),the agent will always sample from the policy-maker,
σi>2X(φL
i+p1−2φL
ip1),the agent will always sample from the leader .
For agents isuch that φL
i>1
2:


σi≤2X(φL
i+p1−2φL
ip1),the agent will always sample from the policy-maker,
σi>2X(φL
i+p0−2φL
ip0),the agent will always sample from the leader .
56Remaining agents will oscillate between sampling from the p olicy-maker and the leader.
57