arXiv:2304.13504v1  [cs.PL]  26 Apr 2023Deterministic stream-sampling for probabilistic
programming: semantics and veriﬁcation
Fredrik Dahlqvist
Queen Mary University of London
andUniversity College London
London, United Kingdom
f.dahlqvist@qmul.ac.ukAlexandra Silva
Department of Computer Science
Cornell University
Ithaca, USA
alexandra.silva@cornell.eduWilliam Smith
Department of Computer Science
University College London
London, United Kingdom
william.smith.19@ucl.ac.uk
Abstract —Probabilistic programming languages rely funda-
mentally on some notion of sampling, and this is doubly
true for probabilistic programming languages which perfor m
Bayesian inference using Monte Carlo techniques. Verifyin g
samplers—proving that they generate samples from the corre ct
distribution—is crucial to the use of probabilistic progra mming
languages for statistical modelling and inference. Howeve r, the
typical denotational semantics of probabilistic programs is in-
compatible with deterministic notions of sampling. This is prob-
lematic, considering that most statistical inference is pe rformed
using pseudorandom number generators.
We present a higher-order probabilistic programming lan-
guage centred on the notion of samplers and sampler operations .
We give this language an operational and denotational seman -
tics in terms of continuous maps between topological spaces .
Our language also supports discontinuous operations, such as
comparisons between reals, by using the type system to track
discontinuities. This feature might be of independent inte rest,
for example in the context of differentiable programming.
Using this language, we develop tools for the formal veriﬁca tion
of sampler correctness. We present an equational calculus t o
reason about equivalence of samplers, and a sound calculus
to prove semantic correctness of samplers, i.e. that a sampl er
correctly targets a given measure by construction.
Index Terms —Probabilistic programming, operational and de-
notational semantics, veriﬁcation
I. I NTRODUCTION
Probabilistic programming languages without conditionin g
– that is to say, programming languages capable of drawing
random samples – and the concepts of Monte Carlo methods
and randomized algorithms have been around as long as
true computers have1; however, the introduction of languages
with conditioning, higher-order features, continuous var iables,
recursion, and their application to statistical modelling and
machine learning, is a product of the twenty-ﬁrst century
[36], [26], [15], [27], [40], [8], [4]. Since a probabilisti c
programming language with conditioning must come equipped
with a range of inference algorithms and sampling methods,
and since the rate of introduction of these has increased in
This work was supported by the Leverhulme Project Grant “Ver iﬁcation of
Machine Learning Algorithms”.
1See [5] for an overview of probabilistic programming langua ges, [7] for
a historical overview of the Monte Carlo method, and [23] for a history of
pseudorandom number generation.recent years, new formal methods must be developed for the
veriﬁcation of these algorithms.
We aim to make the veriﬁcation of inference algorithms
straightforward by introducing a language endowed with a
sampler type, featuring many of the sampler operations used
in these inference algorithms, and a calculus for reasoning
about correctness of these samplers relative to intended ‘t arget’
distributions. The semantics of our language is fully deter min-
istic, in order to allow the use of deterministic – pseudoran dom
– samplers, in a simple manner and without paradox.
When assigning operational and denotational semantics to
probabilistic programs, an interesting asymmetry emerges : the
simplest reasonable denotational semantics of a ﬁrst-orde r
language with continuous datatypes is in terms of probabil-
ity measures [21], while the simplest reasonable operation al
semantics is in terms of sampled values – the latter being much
closer to the intuitions used by programmers of languages wi th
the ability to draw samples.
The denotational semantics of probabilistic programming
languages, in terms of measures (broadly construed) is well -
understood [21], [16], [12], [38], [9]. The most common
approaches to the operational semantics of such a language,
as highlighted by [12], are trace semantics andMarkov chain
semantics . The latter is the chosen operational semantics for
a number of probabilistic λ-calculi [11], [22], [6], [13], [12],
[14] and probabilistic languages [34], [38], but does not sp eak
of sampled values, only of distributions on execution paths .
From the perspective of the asymmetry described above, it is
thus closer to a denotational semantics.
Trace semantics, originally developed in [21] and later
applied in [32], [6], [10], [2], assumes that for each distri bution
in the language, an inﬁnite set of samples has been produced
ahead-of-time. When a sample is requested, the head of this
sequence is popped and used in the computation, and the tail
of the sequence is kept available for further sampling. This
perspective models samplers, such as rand(), as functions with
hidden side effects on the state of the machine – in line with
a programmer’s intuition on the nature of sequential calls t o
rand(). The natural notion of adequacy with respect to the de-
notational semantics is to show that subject to the assumpti on
that each element of these sequences is sampled independent ly
from its corresponding distribution, the resulting pushfo rwardthrough the program is identical to the program’s denotatio nal
semantics. We see two issues with this approach.
First, the supposition that all samples are pre-computed
ahead-of-time is incompatible with pseudorandom generati on
of ‘random’ values, since computationally-generated samp les
and truly-random samples are in fact distinguishable. For
example, if (x0,x1,...)is a sequence of samples targeting
the distribution Pwhich was produced via iteration of a
computable map xn+1=T(xn), then the program T(x)−x
will behave differently if xis a ‘truly random’ sample from
Pthan ifxis produced by the aforementioned iterative
procedure, and so the operational and denotational semanti cs
no longer cohere; similar counterexamples exist for any pse u-
dorandom number generator. If (x0,x1,...)is a deterministic
sequence, meaningful coherence between the operational an d
denotational sequence can only be assured if it is assumed
that this sequence is Martin-Löf random (ﬁrst deﬁned in [29],
later generalised to computable metric spaces in [17]); unf or-
tunately, all Martin-Löf random sequences are uncomputabl e.
Pseudorandom numbers are in fact used in simulation far
more commonly than ‘true’ physical randomness, as they
are typically faster to obtain, have the advantage of being
reproducible given a particular seed, and, subject to certa in
assumptions, can even have better convergence properties2.We
ﬁnd the inability of trace semantics to describe pseudorand om
number generation to be a signiﬁcant weakness.
Second, from the trace semantics perspective, the notion of
a sampler type is inextricably bound up in issues regarding
side-effects, which makes veriﬁcation challenging. In ord er
to properly assign the syntax rand , without parentheses,
a meaningful semantics as a function, we must give it a
monadic interpretation as in [32], accounting for its hidde n
effect on the trace. The correctness of code which inputs and
outputs samplers – sampler operations – is then subject to th e
state of the trace when computation is started, which is not
contained within either the code of the sampler operation in
question or the code of the samplers it inputs. This pattern, of
using sampler operations to create composite samplers whic h
make use of other ‘primitive’ samplers, is a central theme
in computational statistics. In particular, inference alg orithms
within Bayesian statistics, to which probabilistic progra mming
languages with conditioning compile, make heavy use of this
technique. Commonly-used sampling methods, such as impor-
tance sampling, rejection sampling, and particle Markov ch ain
Monte Carlo methods, are naturally understood as composite
samplers of this type [1], [33]. We prefer a side-effect-fre e
perspective from which the correctness of sampler operatio ns
can be demonstrated subject to assumptions about the sample rs
input to these programs, as opposed to a perspective in which
their correctness depends also on the state of the machine on
which these operations are run.
Contributions. We develop a language based around the idea
of sampler types and sampler operations, which allows reaso n-
2This remark is in reference to the related ﬁeld of quasi-Mont e Carlo
techniques, outlined in [24].ing about deterministic and real-valued samplers, and whic h
is designed to make veriﬁcation of these samplers natural. A
syntax, operational semantics, and denotational semantic s for
our language are introduced in § III, and an adequacy result
relating them is shown. § IV lays out a notion of equivalence
of samplers, which will be applied to simplify programs.
Finally, in § V, we discuss methods for proving that samplers
target the desired probability measure (i.e. verifying sam plers),
and introduce a sound calculus for verifying the correctnes s
of composite samplers which is capable of demonstrating
the soundness of common Monte Carlo techniques such as
importance sampling and rejection sampling.
II. E XAMPLES
The purpose of this section is twofold. First, we present
examples of how samplers are transformed in order to create
new samplers. We use this opportunity to informally introdu ce
a language with a sampler type constructor Σand opera-
tions for constructing and manipulating samplers. Second,
we present techniques to reason about the correctness of
sampling algorithms. These come in two ﬂavours. We reason
equationally about the equivalence between samplers (see
§ IV), and we reason semantically about whether a sampler
does the job it is designed to do – namely, generate deviates
from a target distribution (see § V).
A. Von Neumann extractor
We begin with a simple family of discrete samplers known
as von Neumann extractors. This example will illustrate the
concept of a sampler’s self-product , a central concept for a
language featuring sampler types. The von Neumann extrac-
tor [37] is a simple procedure which, given ﬂips from a biased
coin on{True,False}with probability p∈(0,1)of landing
True , produces ﬂips from an unbiased coin with probability
1/2of landing True . We view this as a sampler vof Boolean
type – notation v:ΣB– which, given another Boolean-valued
samplerflip:ΣBrepresenting our biased coin, constructs an
unbiased Boolean-valued sampler. A simple implementation
of the von Neumann extractor is given in Listing 1.
letchoice = λb : B×B .
if(fst(b)andsnd(b))or(notfst(b)and
notsnd(b))then0else1
in letproj = λb : B×B .fst(b)
inmap(proj,reweight (choice, flip2))
Listing 1: von Neumann extractor
The idea behind this algorithm is that if (b1,b2)are
sampled independently from a Bernoulli distribution with
parameter p, then the probabilities of the outcomes (b1,b2) =
(False,True)and(b1,b2) = (True,False)are bothp(1−p),
and so the ﬁrst element b1of each pair is an unbiased ﬂip.
In Listing 1, samples (b1,b2)whereb1=b2are removed by
thereweight operation, which sets the weight of such pairs
to zero; then, the command map applies the function proj
to each pair (b1,b2), returning the sampler whose outputs are
only the ﬁrst element b1.⊢flip2:Σ(B×B)/squigglerightBer(p)2⊢choice:B×B→R+
⊢reweight (choice,flip2) :Σ(B×B)/squiggleright/llbracketchoice /rrbracket·Ber(p)2⊢proj:B×B→B
⊢map(proj,reweight (choice,flip2)) :ΣB/squiggleright/llbracketproj/rrbracket∗(/llbracketchoice /rrbracket·Ber(p)2) =Ber(1/2)
Fig. 1: Validity of von Neumann extractor
⊢rand2:Σ(R×R)/squigglerightU2⊢plus:R×R→R
⊢map(plus,rand2) :ΣR/squiggleright/llbracketplus/rrbracket∗U2⊢phi:R→R+
⊢reweight (phi,map(plus,rand2)) :ΣR/squiggleright/llbracketphi/rrbracket·(/llbracketplus/rrbracket∗U2) =P
Fig. 2: Validity of importance sampling in Listing 2
Note the appearance of flip2in the von Neu-
mann extractor; this is the ‘self-product’ of the sam-
plerflip . Whereflip:ΣBproduces Boolean-valued sam-
ples,flip2:Σ(B×B)produces samples which are pairs of
Booleans. Given a sampler t:ΣTof typeT, the self-product
t2:Σ(T×T)is a sampler whose elements are adjacent samples
fromT; the same construction, detailed in § III, is easily
extended to arbitrary self-powers tK:Σ(TK).
The main application of our language is to serve as a
setting for the formal veriﬁcation of its samplers. Let v:ΣB
be the von Neumann extractor deﬁned in Listing 1; the task
of verifying vis the task of showing that v‘targets’ the
uniform distribution Ber (1/2)– meaning, informally, that in
the limit of increasing sample size, vgenerates unbiased ﬂips.
In § V-B, we deﬁne a relation /squigglerightbetween samplers and
distributions which reiﬁes this notion: we read ⊢v:ΣB/squiggleright
Ber(1/2)as ‘the sampler vtargets the measure Ber (1/2)’. The
aforementioned self-product operation plays a crucial rol e in
sampler veriﬁcation, as it does notsufﬁce, in order to conclude
thatvtargets Ber (1/2), to assume that flip targets Ber (p)
for some p∈(0,1). Instead, we are required to make the
stronger assumption that flip2targets Ber (p)2: in essence,
that adjacent samples from flip act as if they are independent.
Following the literature on pseudorandom number generatio n,
we refer to this property as K-equidistribution (in this case,
forK= 2): we will say that a sampler sisK-equidistributed
with respect to the distribution PifsKtargetsPK. For
example, the assertion that a pseudorandom number generato r
which takes values in {0,...,N−1}isK-equidistributed
with respect to the uniform distribution is the assertion th at
allK-length words w∈{0,...,N−1}Kare produced in
equal proportion. Several commonly-used discrete PRNGs,
such as xorshift and the Mersenne twister, have well-known
K-equidistribution guarantees; see [39], [30].
In our calculus for asymptotic targeting, the validity
of the von Neumann extractor is shown in Fig. 1. Be-
fore we begin this derivation, it must be shown that the
von Neumann extractor vis equivalent to the simpliﬁed
samplermap(proj,reweight (choice,flip2))in a con-
text in which access to a Boolean-typed sampler flip
is assumed, where proj andchoice are deﬁned as in
Listing 1. We write this equivalence as flip:ΣB⊢
v≈map(proj,reweight (choice,flip2)) :ΣB; this equiv-
alence relation is discussed in § IV, and is shown in thisparticular case using the let-binding rule of Table IV.
Having rewritten vin this way, and using the hypothesis
of 2-equidistribution ⊢flip2:ΣB/squigglerightBer(p)2, we derive our
conclusion in Fig. 1 by applying the rules from § V-B corre-
sponding to the sampler operations reweight andmap. These
rules show us that vtargets the measure /llbracketproj/rrbracket∗(/llbracketchoice /rrbracket·
Ber(p)2). (Here, as we will discuss in § V-B, /llbracketf/rrbracket∗µdenotes
the pushforward of the measure µthrough the function f, and
the notation f·µdenotes the measure µreweighted by the
densityf.) To complete the proof, we show that this measure
is identical to Ber (1/2), the uniform measure on B; this is
straightforward. It is easily seen ﬁrst that /llbracketchoice /rrbracket·Ber(p)2
assigns probability 1/2to the samples (True,False)and
(False,True)and zero probability to all other samples; the
desired result then follows by observing that the function proj
simply drops the second sample.
B. Importance sampling
A central application of the reweighting operation is its ro le
inimportance sampling . This is a commonly used technique
[33], [7] in Bayesian learning and statistical inference, w hich
transforms samples from a ‘proposal’ distribution Qon the
latent space Xinto approximate samples from a ‘target’
distribution P, wherePis absolutely continuous with respect
toQwith Radon-Nikodym derivativedP
dQ(x). Its operation
is straightforward: for each sample xn∼Q, compute the
sample’s weight wn=dP
dQ(x), and then the weighted sample
(xn,wn)is informally understood as an approximate sample
from the target P. Formally, the normalised empirical measure/summationtextN
n=1wn/summationtextN
i=1wiδxn, whereδxis the Dirac measure at x∈X,
converges weakly as N→∞ to the target measure P.
For example, consider the Bayesian inference problem in
which the prior P0is the triangular distribution on [0,2]and
the likelihood of the observation y= 3 given the latent value
xis a standard Gaussian L(x) =1√
2πexp/parenleftBig
−(3−x)2
2/parenrightBig
. Let
Prepresent the corresponding posterior distribution, whos e
density is proportional to the pointwise product of the tria n-
gular and Gaussian densities; a simple importance-samplin g
procedure for sampling from Pin our language is shown
in Listing 2. Here, we assume access to a sampler rand
which targets the uniform distribution on [0,1]; recalling
that a triangular random variable is the sum of two inde-
pendent uniform random variables, and assuming rand has
the necessary independence property of 2-equidistributio n, we⊢tri⊗rand:ΣT/squigglerightTri⊗U⊢accept:T→R+
⊢reweight (accept,tri⊗rand) :ΣT/squiggleright/llbracketaccept /rrbracket·(Tri⊗U)⊢proj:T→R
⊢map(proj,reweight (accept,tri⊗rand)) :ΣR/squiggleright/llbracketproj/rrbracket∗(/llbracketaccept /rrbracket·(Tri⊗U)) =P
Fig. 3: Validity of rejection sampling in Listing 3
sum two draws from rand to produce a triangular random
variable. Finally, we reweight the result according to the
likelihood L(x), yielding a sampler which targets the posterior
distribution Pcorresponding to the observed datum y= 3.
letphi =λx : R . 1/sqrt(2 *pi)*exp(-1/2 *(3-
x)*(3-x))
in letplus = λu : R×R .fst(u) +snd(u)
inreweight (phi,map(plus, rand2))
Listing 2: Importance sampling
The validity of this sampler – i.e. the fact that it targets
the correct posterior distribution – follows easily in our
targeting calculus. Under the hypothesis that rand produces
2-equidistributed samples with respect to the uniform dist ribu-
tionU, the derivation Fig. 2 proves that the sampler deﬁned in
Listing 2 targets the measure /llbracketphi/rrbracket·(/llbracketplus/rrbracket∗U2). It remains
to show that this measure is the desired P; once one shows
that the sum of two independent uniform variates is triangul ar,
this follows by deﬁnition of the reweighting operation ·. The
same argument sufﬁces for any observation y.
C. Rejection sampling
Our ﬁnal example of sampler veriﬁcation is an instance
of the technique known as rejection sampling . Listing 3
applies rejection sampling from the prior to the same Bayesi an
inference problem discussed in § II-B to yield a sampler
which targets the same posterior distribution P. Of particular
importance is the discontinuity of the accept-reject step, which
signiﬁcantly complicates the argument of sampler veriﬁcat ion
in the presence of pseudorandom number generation.
letphi =λx : R . 1/sqrt(2 *pi)*exp(-1/2 *(3-
x)*(3-x))
in letaccept = λ(u,v) : T .
ifv≤phi(u)*sqrt(2*pi)then1else0
in letproj = λz : T.fst(cast/an}bracketle{tR×R/an}bracketri}ht(z))in
map(proj,reweight (accept, tri ⊗rand))
Listing 3: Rejection sampling
In order to show the validity of rejection sampling from
the prior, we must assume access to a sampler on the prior
distribution (here tri), an independent standard uniform ran-
dom sampler (here rand ), and an upper bound supx∈RL(x) =
1
2πsupx∈Rexp(−(3−x)2
2) =1
2πon the likelihood, which is
used in the acceptance condition. Fig. 3 proves that, subjec t
to the natural independence assumption for the samplers tri
andrand , the rejection sampler deﬁned by Listing 3 targets
the measure /llbracketproj/rrbracket∗(/llbracketaccept /rrbracket·(Tri⊗U)). We can then show,
using standard methods, that this measure is identical to P,
the posterior distribution also targeted by Listing 2.We have omitted, for the moment, one crucial part of
the proof. Note that, in both Listing 3 and Fig. 3, the
function accept , which one might expect to have type
R×R→R+, instead has type T→R+. Correspondingly, the
producttri⊗rand must be assumed to produce samples of
typeT, rather than R×R, andproj must accepts inputs of type
Trather than pairs R×R. The nature of this type T, asubtype
ofR×R, will be explained in § III, but it encodes the fact
thataccept is discontinuous when viewed as a function on
the standard topologies, as well as where those discontinui ties
are allowed to lie. The type-inference of Listing 3, detaili ng
the structure of T, is given in the Appendix, Figs. 6 and 7.
III. L ANGUAGE
A. Syntax
We use a λ-calculus with a notion of subtype and a type
constructorΣfor samplers.
1) Types: Types are generated by the mostly standard
grammar in Fig. 4a, where the set Ground of ground types is
{N,R,R+}∪{f−1(i)|f∈{≤,<,≥,>,=,/ne}ationslash=},i= 0,1}.
Our ground types include the natural, real and nonnegative
real numbers, as well as important sets of pairs of reals: for
example, <−1(1)will be denoted, as the notation suggests,
by the pairs of reals whose ﬁrst component is strictly smalle r
than the second. The boolean type B/defines1+1 will be treated
as a ground type.
The only unusual type constructors are the pullback types
Ts twhich – as the name suggests – will be interpreted as
pullbacks (in fact inverse images), and the sampler typesΣT
which will be deﬁned as the coinductive (stream) types deﬁne d
by the (syntactic) functors T×R+×−. In other words, we
assume that samplers can be weighted; this covers the specia l
case of unweighted samplers, in which every weight is set to
1. As these are the only coinductive types we need, and to
highlight the central role played by samplers, we choose not
to add generic coinductive types to the language.
The subtyping relation ⊳on types is the reﬂexive transitive
closure of the relation generated by the rules of Fig. 4b.
2) Terms: Fig. 4c presents the grammar generating the set
Expr of terms in our language. We assume the existence of
a setFunc of built-in functions which come equipped with
typing information f:T→G, whereGis a ground type.
Some built-in functions will be continuous w.r.t. to the usu al
topologies, such as the addition operation + :R×R→R, but
others will be discontinuous, such as the comparison operat ors
{≤,<,≥,>,=,/ne}ationslash=}:R×R→B. Dealing with such functions
is the main reason for adding coproducts to the grammar, as
we will discuss in § III-C. We also employ the syntactic sugar
ifbthensTrueelsesFalse/definescase(b,_)of{(i,_)⇒si}i∈B.S,T::=G∈Ground|1|S×T|S+T|Ts t|S→T|ΣTs,t:T
(a) Type grammar
f−1(0)+f−1(1)⊳R×Rf∈{<,≤,>,≥,=,/ne}ationslash=}S1⊳S2T1⊳T2
S1×T1⊳S2×T2S1⊳S2T1⊳T2
S1+T1⊳S+T2
S⊳T
ΣS⊳ΣT/summationtext
i∈nSi⊳S/summationtext
j∈mS′
i⊳S
/summationtext
i∈n,j∈mSi∩S′
j⊳/summationtext
i∈nSi/summationtext
i∈nSi⊳S/summationtext
j∈mS′
j⊳S
/summationtext
i∈n,j∈mSi∩S′
j⊳/summationtext
j∈mSj
(b) Subtyping rules
t::=x∈Var|b∈{True,False}|n∈N|r∈R| Variables and constants
f(t,...,t),f∈Func|cast/an}bracketle{tT/an}bracketri}htt| Built-in functions
casetof{(i,xi)⇒si}i∈n|ini(t)|λx:T.t|t(t)|letx=tint| Programming constructs
(t,t)|fst(t)|snd(t)| Products
prng(t,t)|t⊗t|map(t,t)|reweight (t,t)|hd(t)|wt(t)|tl(t)|thin(t,t) Sampler operations
(c) Term grammar
Fig. 4: Grammars and subtyping rules
Most of our language constructs are standard for a typed
functional language without recursion, but we endow our
language with several nonstandard (sampler) operations:
•The operation prng(f,t)is used to construct a sampler
as a pseudo-random number generator, using an initial
valuetand a deterministic endomap f.
•s⊗trepresents the product of samplers s,t.
•The syntax map(f,t)maps the function fover the
elements produced by the sampler tto produce a new
sampler, in analogy to the pushforward of a measure.
•The operation reweight (f,t)applies the reweighting
schemefto the sampler tto form a new sampler.
•Given a sampler t, the operation hd(t)returns the ﬁrst
sample produced by t,wt(t)the weight of the ﬁrst sample
produced by t, andtl(t)returns the sampler tbut with
its ﬁrst sample-weight pair dropped.
•The operation thin(n,t), given a natural number nand a
samplert, returns the sampler which includes only those
elements of twhose index is a multiple of n.
The intuition and purposes of most of these language con-
structs was explained in § II, and their precise meaning will
be made clear when we introduce their semantics.
3) Well-formed terms: Our typing system is mostly stan-
dard and presented in Table I. The only non-standard rules ar e
thecontext-restriction rule on the second line of Table I, and
the typing rules for the sampler operations, which should be
straightforward given their descriptions above. The purpo se of
the context-restriction rule is, in a nutshell, to be able to pass
the result of a computation of type Twhich is continuous w.r.t.
a topology τon the denotation of T, to a computation using
a variable of type Tbut which is continuous w.r.t. to a ﬁner
topology τ′⊃τon the denotation of T. After application of
this rule, it is no longer possible to λ-abstract on the individual
variables of the context. There are good semantic reasons fo r
this feature, which we discuss in § III-C. For readability an dintuition’s sake, the rule is written using the syntactic su gar
t−1(Ti)/defines Tcast/an}bracketle{tT/an}bracketri}htini(x)t wherex:Ti (1)
For the subtyping rules Fig. 4b, we use the syntactic sugar
Si∩S′
j/defines Scast/an}bracketle{tS/an}bracketri}htini(xi)cast/an}bracketle{tS/an}bracketri}htinj(x′
j)wherexi:Si,x′
j:S′
j
Our typed lambda calculus does not feature recursion for
two reasons. First, it is not necessary: as any computable pr ob-
ability measure can be obtained as a computable pushforward
of the uniform measure on the unit interval [18], [17], any
sampler language which features the sampler operation map
can, given a uniform sampler, target any computable proba-
bility measure. In particular, many rejection samplers, wh ich
are commonly implemented recursively, can alternatively b e
implemented using the operation reweight , as shown in
Listing 3. Second, the categorical semantics of a typed, pro ba-
bilistic, higher-order lambda calculus with recursion are a very
recent area of investigation [38]; we consider the inclusio n of
recursive samplers to be further work.
B. Operational semantics
In practice, in order to evaluate a program containing a
sampler, one must specify a ﬁnite number of samples N∈N
which are to be produced. Our (big-step) operational seman-
tics correspondingly takes the form of a reduction relation
(t,N)→v, where the left side consists of a well-typed closed
termt∈Expr and a number of samples N∈N, and the right
side is a valuev∈Value, i.e. a term generated by the grammar
v::=x∈Var|g∈G|(v,v)|ini(v)|λx:T. v (2)
The rules of this big-step operational semantics, shown in
full in the Appendix, Table VI, are the usual rules for the
standard language constructs, together with additional ru les
for our implemented sampler operations; these are given in
Table II. For notational simplicity, these operations make use
of lists(a,b,c,d), which are in fact interpreted within our
language as nested pairs (a,(b,(c,d))). In order to keep theΓ⊢g:Gg∈/llbracketG/rrbracketΓ,x:T,∆⊢x:TΓ⊢t:T
Γ⊢f(t) :GFunc∋f:T→G∆⊢t:S
Γ⊢cast/an}bracketle{tT/an}bracketri}htt:TS⊳T,Γ⊳∆
Γ⊢t:T,
(x1,...,x n) :/summationtext
i∈mt−1(Ti)⊢t:/summationtext
i∈mTi/summationtext
i∈mTi⊳T,Γ =x1:S1,...,x n:Sn
Γ⊢s:SΓ⊢t:T
Γ⊢(s,t) :S×TΓ⊢t:S×T
Γ⊢fst(t) :SΓ⊢t:S×T
Γ⊢snd(t) :TΓ,x:S⊢t:TΓ⊢s:S
Γ⊢letx=sint:T
Γ,x:S⊢t:T
Γ⊢λx:S. t:S→TΓ⊢s:SΓ⊢t:S→T
Γ⊢t(s) :TΓ⊢t:Tj
Γ⊢inj(t) :/summationtext
i∈nTij∈nΓ⊢t:/summationtext
i∈ITiΓ,xi:Ti⊢si:T
Γ⊢casetof{(i,xi)⇒si}i∈I:T
Γ⊢t:ΣT
Γ⊢hd(t) :TΓ⊢t:ΣT
Γ⊢wt(t) :R+Γ⊢t:ΣT
Γ⊢tl(t) :ΣTΓ⊢s:ΣSΓ⊢t:ΣT
Γ⊢s⊗t:Σ(S×T)
Γ⊢s:T→TΓ⊢t:T
Γ⊢prng(s,t) :ΣTΓ⊢t:ΣTΓ⊢n:N
Γ⊢thin(t,n) :ΣTΓ⊢s:ΣSΓ⊢t:S→T
Γ⊢map(t,s) :ΣTΓ⊢s:T→R+Γ⊢t:ΣT
Γ⊢reweight (s,t) :ΣT
TABLE I: Typing rules
rules readable, we also introduce the shorthand (t,N)→
((v1,w1),...,(vN,wN))to denote the Nreductions
(hd(t),wt(t))→(v1,w1),
(hd(tl(t)),wt(tl(t)))→(v2,w2),...,
(hd(tlN−1(t)),wt(tlN−1(t)))→(vN,wN).
Note that the product of two weighted samplers has as its
weights the product of its factors’ weights. The product and
the operation reweight are the only operations modifying the
weights of samplers.
The following proposition shows that the operational se-
mantics is well-formed in that for any N∈N, samplers can
only reduce to weighted lists of length N.
Proposition III.1. [Appendix A] If⊢s:ΣSis a closed
sampler, then for any N∈N, if(s,N)→v, thenvhas
the form ((v1,w1),...,(vN,wN)), wherevnare values and
wn∈R≥0are weights. If Sis not a sampler type, then vn:S;
more generally, each vnmight be a weighted list itself.
The self-product operation: Having clariﬁed the meaning
of the product and of the thin operation, we are now in a
position to formally justify the operation which we referre d
to, in § II, as the ‘self-product’ of a sampler. To motivate
it, consider a sampler t:ΣTwhich evaluates as (t,2N)→
(x1,...,x 2N), where for notational clarity we have omitted
the weights. From the above operational semantics, the lagg ed
samplerthin(2,t⊗tl(t)) :Σ(T×T)evaluates to
(thin(2,t⊗tl(t)),N)→((x1,x2),(x3,x4),...,(x2N−1,x2N)).
This is the ‘self-product’ which was denoted t2in § II. This
notion is important because it is the construction which all ows
us to generate pairs of independent samples from a given
sampler. Note that simply taking t⊗twill produce pairs of
perfectly correlated samples: the operational semantics g ives
(t⊗t,N)→((x1,x1),...(xN,xN)). More generally, for any
K∈N, we deﬁne the K-fold self-product of a sampler as
tK/definesthin(K,t⊗tl(t)⊗...⊗tlK−1(t)). (3)
Sampling from tKis intended to allow the sampling of K-
tuples of independent deviates generated by the sampler K.Ultimately, it is only to deﬁne this self-product operation
that the sampler operation thin is included at all, it being
somewhat of an unnatural construct.
C. Denotational semantics
1) Denotational universe: We will see in § V that contin-
uous maps play a special role in the veriﬁcation of sampler
properties. We therefore need a denotational domain in whic h
continuity is a meaningful concept. We also need a Cartesian
closed model, as we want to interpret the lambda-abstractio n
operation of our calculus. A standard solution is to conside r
the category of compactly generated topological spaces [35],
[31], [25] (henceforth CG-spaces ). A topological space Xis
compactly generated if it is Hausdorff and has the property t hat
C⊆Xis closed iff C∩Kis closed in Kfor every compact
KinX[35, §1]. We need not worry about the theory of these
spaces, but the following facts are essential in what follow s.
Proposition III.2 ([35], [25]) .1) The category CG of CG-
spaces and continuous functions is Cartesian closed.
2) The category CG is complete and cocomplete.
3) Every metrizable topological space is CG.
4) Locally closed subsets (i.e. intersections of an open and
a closed subset) of CG-spaces are compactly generated.
It is worth brieﬂy describing the Cartesian closed structur e
ofCG. The product is in general different from the product in
Top , the category of topological spaces: if the usual product
topology is not already compactly generated, then it needs t o
be modiﬁed to enforce compact generation [35, §4]. However,
in most practical instances the usual product topology is
already compactly generated – for example, any countable
product of metrizable spaces is metrizable, and thus compac tly
generated by Prop. III.2. The internal hom [X,Y]between CG-
spacesX,Y is given by the set of continuous maps X→Y
together with the topology of uniform convergence on compac t
sets, also known as the compact-open topology [35, §5].
2) Semantics of types: With this categorical model in place
we deﬁne the semantics of types. The semantics of ground
types is as expected: /llbracketN/rrbracket=N, equipped with the discrete
topology, and /llbracketR/rrbracket=R,/llbracketR+/rrbracket= [0,∞)with the usual((s(hd(t)),wt(t)),N)→(v1,w1)...((s(hd(tlN−1(t)),wt(tlN−1(t))),N)→(vN,wN)
(map(s,t),N)→((v1,w1),...,(vN,wN))
((hd(t),s(hd(t))·wt(t)),N)→(v1,w1)...((hd(tlN−1(t)),s(hd(tlN−1(t)))·wt(tlN−1(t))),N)→(vN,wN)
(reweight (s,t),N)→((v1,w1),...,(vN,wN))
(s,N)→((v1,w1),...,(vN,wN)) (t,N)→((v′
1,w′
1),...,(v′
N,w′
N))
(s⊗t,N)→(((v1,v′
1),w1·w′
1),...,((vN,v′
N),wN·w′
N))
(t,N)→((v1,w1),...,(vN,wN))
(hd(t),N)→v1(t,N)→((v1,w1),...,(vN,wN))
(tl(t),N−1)→((v2,w2),...,(vN,wN))(t,N)→((v1,w1),...,(vN,wN))
(wt(t),N)→w1
(s,N)→i(t,Ni)→((v1,w1),...,(vNi,wNi))
(thin(s,t),N)→((v1,w1),(vi+1,wi+1),(v2i+1,w2i+1),...,(v(N−1)i+1,w(N−1)i+1))
(t,N)→v1(s(t),N)→v2...(sN−1(t),N)→vN
(prng(s,t),N)→((v1,1),...,(vN,1))
TABLE II: Big-step operational semantics of sampler operat ions
topology. The spaces f−1(i),f∈{≤,<,≥,>,=,/ne}ationslash=},i∈2
are interpreted precisely as the notation suggests, e.g.
/largellbracket
<−1(0)/largerrbracket
={(x,y)|x,y∈R∧x≥y},/largellbracket
=−1(1)/largerrbracket
={(x,x)|x∈R}
together with the subspace topology inherited from R×R.
Since all these spaces are metrizable, our ground types are
interpreted in CG by Prop. III.2.
Products (including the unit type) and function types are
interpreted in the obvious way using the Cartesian closed
structure of CG. Coproduct types are interpreted by coprod-
ucts inCG, and given two terms s,t:Tinterpreted as CG-
morphisms /llbrackets/rrbracket:A→/llbracketT/rrbracket,/llbrackett/rrbracket:B→/llbracketT/rrbracket, the pullback type
Ts tis interpreted as the pullback A×/llbracketT/rrbracketBof/llbrackets/rrbracketalong /llbrackett/rrbracket.
All these spaces live in CG by Prop. III.2.
Since sampler types are coinductive types, their semantics
will hinge on the existence of terminal coalgebras.
Theorem III.1 (Adámek) .LetCbe a category with ter-
minal object 1, and F:C→Cbe a functor. If Chas
andFpreserves ωop-indexed limits, then the limit νF of
1F1!/d111/d111 FF1F!/d111/d111 ...FF!/d111/d111 is the terminal coalgebra of F.
SinceCG is complete, it has ωop-indexed limits. Recall
that we want to interpret ΣTas the coinductive type deﬁned
by the ‘functor’ T×R+×−. Formally, given a type Twe want
/llbracketΣT/rrbracket/definesν(/llbracketT/rrbracket×R+×Id). (4)
Since products are limits, and limits commute with limits, i t
is clear that the functor /llbracketT/rrbracket×R+×Idpreserves limits, and in
particular ωop-indexed ones. Adámek’s theorem thus guaran-
tees the existence of an object satisfying (4). More concret ely,
since the termimal object 1 is trivially metrizable, and sin ce
R+is metrizable, each object in the terminal sequence will
be metrizable provided /llbracketT/rrbracketis, and thus/producttext
n(/llbracketT/rrbracket×R+)nwill
be metrizable whenever /llbracketT/rrbracketis, and will therefore be equipped
with the usual product topology. The limit deﬁning (4) is a
closed subspace of this product, which means that the limit
inCG deﬁning /llbracketΣT/rrbracketis the same as in Top when /llbracketT/rrbracketismetrizable (for example, if Tis a ground type or a product of
ground types). However, by deﬁning /llbracketΣT/rrbracketcoinductively rather
than simply as (/llbracketT/rrbracket×R+)ω, we obtain a terminal coalgebra
structure on /llbracketΣT/rrbracket, and therefore the ability to deﬁne sampler
operations coinductively.
3) Semantics of the subtyping relation: Our language con-
tains the predicates f∈ {≤,<,≥,>,=,/ne}ationslash=}(essential for
rejection sampling § II-C) and yet is meant to be interpreted in
a universe of topological spaces and continuous maps. These
predicates are not continuous maps R×R→2for the usual
topology on R×R. However, for each such predicate f,
the sets/largellbracket
f−1(0)/largerrbracket
and/largellbracket
f−1(1)/largerrbracket
arelocally closed sets , that
is to say the intersection of an open set and a closed set
(for the usual topology on R×R), and therefore CG-spaces
by Prop. III.2, e.g./largellbracket
<−1(0)/largerrbracket
is closed and/largellbracket
<−1(1)/largerrbracket
open.
Our central idea for dealing with discontinuities is that si nce
CG is cocomplete, the space/largellbracket
f−1(0)/largerrbracket
+/largellbracket
f−1(1)/largerrbracket
is a CG-
space. This space has the nice property that fis continuous
as a map f:/largellbracket
f−1(0)+f−1(1)/largerrbracket
→2. Since each f−1(i)is
a type, we can enforce this semantics by simply typing these
built-in functions in Func asf:f−1(0)+f−1(1)→B.
The topology on/largellbracket
f−1(0)+f−1(1)/largerrbracket
is ﬁner than the usual
topology on R×R, which means that the identity map
Id :/largellbracket
f−1(0)+f−1(1)/largerrbracket
→R×Ris continuous. This is
the semantic basis for the axiom in Fig. 4b. From the other
rules it is easy to see by induction that the subtyping relati on
is always between spaces sharing the same carrier set and
is semantically given by coarsening the topology. In other
words, if S⊳T, then /llbracketS/rrbracketand/llbracketT/rrbracketshare the same carrier and
the corresponding identity map Id :/llbracketS/rrbracket→/llbracketT/rrbracketis continuous.
Example III.1. Letp/definesifx= 0then1else−1; we will
ﬁrst show how the context-restriction rule allows us to type -
check this program. For readability’s sake, let Eq/defines=−1(1)
andNeq/defines=−1(0). We now derive, using = :Neq+Eq→R,x:R⊢x:R⊢0 :R
x:R⊢(x,0) :R×R
x: (x,0)−1Neq+(x,0)−1Eq⊢(x,0) :Neq+EqNeq+Eq⊳R×R
x: (x,0)−1Neq+(x,0)−1Eq⊢x= 0 :B⊢1 :R⊢−1 :R
x: (x,0)−1Neq+(x,0)−1Eq⊢ifx= 0then1else−1 :R
Anticipating the semantics on terms discussed shortly, it c an
easily be shown that
/largellbracket
(x,0)−1Neq+(x,0)−1Eq/largerrbracket
= ((−∞,0)∪(0,∞))+{0}
and thus /llbracketp/rrbracketis the continuous map
/llbracketp/rrbracket: ((−∞,0)∪(0,∞))+{0}→R,x/mapsto→/braceleftBigg
1 ifx= 0
−1else
4) Semantics of well-formed terms: Axioms, weakening,
subtyping, product, projections, let-binding, λ-abstraction,
function application, injections and pattern matching are in-
terpreted in the expected way (given that CG is a Cartesian
closed category with coproducts).
Continuous built-in functions, for example + :R×R→Ror
exp:R→R, are interpreted in the obvious way. As explained
above, discontinuous built-in functions {≤,<,≥,>,=,/ne}ationslash=}are
typed in such a way that their natural interpretations are
tautologically continuous.
We can now describe the semantics of the context-restrictio n
rule. From the premise, our observations in § III-C3, and the
side-conditions, we have morphisms
/llbrackett/rrbracket:/productdisplay
j∈n/llbracketSj/rrbracket→/llbracketT/rrbracket,andId :/coproductdisplay
i∈m/llbracketTi/rrbracket→/llbracketT/rrbracket.
By Eq. (1) we interpret each ‘inverse image type’ t−1(Ti)as
the pullback (inverse image) of /llbrackett/rrbracketalong the inclusion /llbracketT/rrbracketi֒→/coproducttext
i∈m/llbracketTi/rrbracketwhich is, as the notation implies, simply given by
/llbrackett/rrbracket−1(/llbracketTi/rrbracket). Since/coproducttext
i∈m/llbracketTi/rrbracketand/llbracketT/rrbracketshare the same carrier,
it is clear that this deﬁnes a partition of /llbracketΓ/rrbracket, and we can thus
retypetas a continuous map/coproducttext
i∈m/largellbracket
t−1(Ti)/largerrbracket
→/coproducttext
i∈m/llbracketTi/rrbracket,
interpreting the rule.
As mentioned earlier in this section, context-restriction
preventsλ-abstraction; the following example illustrates why
this must be the case.
Example III.2. Consider the program x < y derived by:
x:R,y:R⊢(x,y) :R×R
(x,y):(x,y)−1(<−1(0))+(x,y)−1(<−1(1))⊢(x,y):<−1(0)+<−1(1)
(x,y) : (x,y)−1(<−1(0))+(x,y)−1(<−1(1))⊢x < y:B
The interpretation of x < y is given by the continuous function
/llbracket</rrbracket:{(x,y)|x < y}+{(x,y)|x≥y}→2.
Although it has the same carrier R×R, the domain of this
map is no longer of product of topological spaces; it is now
a coproduct of topological spaces. This means that it is no
longer possible to λ-abstract over one of the variables of this
function using the Cartesian closed structure of CG.In order to be able to λ-abstract the map <, we would
need a topology on R×Rwith the property that for any
givenx0∈Rthe function x0<−:R→2is continuous.
This would introduce the open sets [x0,∞)to the topology
ofRfor each x0∈R, meaning that we must equip Rwith
the notoriously problematic lower limit topology (a.k.a. t he
Sorgenfrey line). Whether or not this is a CG-space seems to
be a thorny question, possibly independent of ZF [20].
Finally, we deﬁne the denotational semantics of sampler
operations using the coinductive nature of sampler types.
Recall that for a type T,/llbracketΣT/rrbracket/definesν(/llbracketT/rrbracket×R+×Id). In particular,
/llbracketΣT/rrbracketcomes equipped with a coalgebra structure map
unfoldT:/llbracketΣT/rrbracket→/llbracketT/rrbracket×R+×/llbracketΣT/rrbracket.
Moreover, for any other (continuous) coalgebra structure m ap
γ:X→/llbracketT/rrbracket×R+×X, the terminal nature of /llbracketΣT/rrbracketprovides
a unique /llbracketT/rrbracket×R+×Id-coalgebra morphism
beh(γ) :X→/llbracketΣT/rrbracket.
Since /llbracketΣT/rrbracketis interpreted in CG, it follows automatically that
bothunfoldTandbeh(γ)are continuous. However, what is
not immediately clear is that beh is in fact continuous in γ.
Proposition III.3. [Appendix A] Let F:CG→CG satisfy
the condition of Thm. III.1 as well as the condition that
int(νF)/ne}ationslash=∅in/producttext
iFi1, and let behX: [X,FX]→[X,νF]
be the (behaviour) map associating to any F-coalgebra struc-
ture onXthe unique coalgebra morphism into the terminal
coalgebra. The map behXis continuous, i.e. is a CG-
morphism.
Usingunfold andbeh we deﬁne the denotational semantics
of all the sampler operations in Table III. These deﬁni-
tions are precisely the inﬁnite (coinductive) versions of t he
ﬁnitary transformations deﬁned in the operational semanti cs
of Table II. All the maps involved in these deﬁnitions are
continuous; this follows from Prop. III.3 and the fact that
evaluation and function composition are continuous operat ions
on the internal hom sets of CG ([35, 5.2,5.9]).
D. Adequacy
This language features an interesting asymmetry in that its
denotational semantics is written in terms of the coinducti ve
sampler type /llbracketΣT/rrbracket, while its operational semantics is written
in terms of ﬁnitary operations on ﬁnite sequences of samples .
Moreover, the operational semantics is given in terms of red uc-
tions to values , i.e. terms whose types are constructed without
the type constructor Σ, whereas the denotational semantics
does not make this distinction. To establish a connection, w e
start by deﬁning a generic way to convert terms of arbitrary
types into values, following the idea behind the operationa l
semantics. Given a type Tand an integer Nwe inductively
deﬁne its associated value type valN(T)∈Value by:
valN(G) =G valN(ΣT) =/parenleftbig
valNT/parenrightbigN
valN(S∗T) = valN(S)∗valN(T),∗∈{×,+,→}/llbracketΓ⊢t:ΣT/rrbracket=f
/llbracketΓ⊢hd(t) :T/rrbracket=π1◦unfoldT◦f/llbracketΓ⊢t:ΣT/rrbracket=f
/largellbracket
Γ⊢wt(t) :R+/largerrbracket
=π2◦unfoldT◦f/llbracketΓ⊢t:ΣT/rrbracket=f
/llbracketΓ⊢tl(t) :ΣT/rrbracket=π3◦unfoldT◦f
/llbracketΓ⊢s:N/rrbracket=f/llbracketΓ⊢t:ΣT/rrbracket=g
/llbracketΓ⊢thin(s,t) :Σ(T)/rrbracket= evΣT,ΣT◦(idΣT×behΣT)◦/parenleftbigidΣT×/parenleftbigunfoldT◦(π3◦unfoldT)(· −1)/parenrightbig/parenrightbig◦/an}bracketle{tf,g/an}bracketri}ht
/llbracketΓ⊢s:ΣS/rrbracket=f/llbracketΓ⊢t:ΣT/rrbracket=g
/llbracketΓ⊢s⊗t:Σ(S×T)/rrbracket= behΣS,ΣT(π1×π4×(π2·π5)×π3×π6◦unfoldS×unfoldT)◦/an}bracketle{tf,g/an}bracketri}ht
/llbracketΓ⊢s:ΣS/rrbracket=f/llbracketΓ⊢t:S→T/rrbracket=g
/llbracketΓ⊢map(t,s) :ΣT/rrbracket= evΣS,ΣT◦(idΣS×behΣS)◦(idΣS×((−×idR+×idΣS)◦unfoldS))◦/an}bracketle{tf,g/an}bracketri}ht
/llbracketΓ⊢s:ΣT/rrbracket=f/largellbracket
Γ⊢t:T→R+/largerrbracket
=g
/llbracketΓ⊢reweight (t,s)/rrbracket= evΣT,ΣT◦(idΣT×behΣT)◦(idΣT×((idT×−×idΣT)◦unfoldT))◦/an}bracketle{tf,g/an}bracketri}ht
/llbracketΓ⊢t:T/rrbracket=f/llbracketΓ⊢s:T→T/rrbracket=g
/llbracketΓ⊢prng(s,t) :ΣT/rrbracket= evT,ΣT◦(idT×behT)◦(idT×(idT×1×−))◦/an}bracketle{tf,g/an}bracketri}ht
TABLE III: Denotational semantics of sampler operations
whereG∈Ground .3We now deﬁne the generalized projection
mapspN
T:/llbracketT/rrbracket→/Largellbracket
valN(T)/Largerrbracket
recursively via
pN
G= id /llbracketG/rrbracket, pN
S∗T=pN
S∗pN
T,∗∈{×,+}
pN
S→T= id /llbracketS→T/rrbracketpN
ΣT=π1:N◦(pN
T×R+)ω
The reader will have noticed that we have deﬁned pN
S→T
trivially. The reason is that, as a quick examination of the r ules
of Table II will reveal, there is no conclusion and no premise
of the type (t,N)→vwheretis of function type. The only
occurrence of terms of function types are within an evaluati on,
or are values , i.e. terms trivially reducing to themselves.
Theorem III.2. [Appendix A] For any program ⊢t:T, we
have
(t,N)→v⇔pN
T(/llbrackett/rrbracket) =/llbracketv/rrbracket.
IV. E QUIVALENCE OF SAMPLERS
In order to implement a system for reasoning about whether
a deterministic sampler targets a particular probability d istri-
bution, it is necessary to ﬁrst deﬁne a notion of equivalence
between samplers. Having such a system gives a natural path
towards verifying a sampler: ﬁrst rewrite a given sampler s
in an equivalent but simpler form, and then show that this
simpliﬁed form targets the correct distribution. This is th e
approach taken in the derivations in § II, which implicitly u sed
several equivalence results – in particular, let-reduction and
the equivalence of the nested self-product (sm)nto the self-
productsm∗nfor any sampler s. In this section, we introduce a
relation≈on programs which justiﬁes this type of reasoning.
Deﬁnition IV .1. We say that two programs Γ⊢s:Tand
Γ⊢t:Tareequivalent , notation Γ⊢s≈t:T, if they
are related by the smallest congruence relation on well-typ ed
terms containing the rules of Table IV.4
3Since we’re only interested in closed samplers here, and sin ce pullback
types can only occur in a context, we need not deﬁne valNon pullback types.
4Bycongruence relation , we mean that≈is an equivalence relation
preserved by all operations in the language. For example, if Γ⊢s≈t:ΣT
holds, then Γ⊢tl(s)≈tl(t) :ΣTmust hold as well, and the same for all
operations in the language.The rules of Table IV employ a number of shorthand
conventions for a more concise presentation. We introduce
identity functions idS/definesλx:S. x:S→S, constant functions
1S/definesλx:S.1:S→R+, function composition t◦s/definesλx:
S. t(s(x)) :S→Uwheres:S→T,t:T→U, compositions
f0/definesidS:S→S,fn/definesf◦fn−1for anyn∈N, pointwise
productss·t/definesλx:S,y:T. s(x)∗t(y) :S×T→R+of real-
valued functions s:S→R+,t:T→R+, and ﬁnally Cartesian
products s×t/definesλx:S,y:T.(s(x),t(y)) :S×T→S′×T′
of functions s:S→S′,t:T→T′.
Theorem IV .1. [Appendix A] The rules of Table IV are sound:
ifΓ⊢s≈t:T, then /llbracketΓ⊢s:T/rrbracket=/llbracketΓ⊢t:T/rrbracket.
The proof is a straightforward exercise in coinductive rea-
soning and can be found in the Appendix, along with the
full list of equivalence rules. The soundness of these rules
with respect to operational equivalence then follows from
abstraction, though it is also straightforward to show dire ctly.
Recall that an important application of our sampler opera-
tions is to provide a formal deﬁnition of the self-product of
samplers, given in (3). It is crucial that our equivalence ru les
should show that this self-product is well-deﬁned.
Proposition IV .1. [Appendix A] For any Γ⊢s:ΣS,m,n∈
N, the self-product satisﬁes Γ⊢(sm)n≈smn:Σ(Smn).
The equivalence rules in Table IV suggest a procedure
for simplifying samplers. Consider samplers which have no
occurrences of the operation prng . Of our remaining sampler
operations, we identify two groups: {tl,hd,wt,thin,⊗}and
{map,reweight}. Applying the rules of Table IV, we see that
for each combination of operations in the ﬁrst and second
group, there is a rule which enables us to pull the ﬁrst
operation into the body of the second. Therefore, any sample r
with no instances of prng can be written so that the sampler
operations tl,hd,wt,thin,⊗are pulled all the way inwards.
Proposition IV .2. LetΓ⊢t:ΣTbe a sampler which contains
no instances of prng . Applying the rules of Table IV, it follows
that we can equivalently rewrite such a sampler in eitherΓ,s:S⊢(λx:S.t)(s)≈t[x←s] :TΓ⊢λx:S.t(x)≈t:S→T
Γ,s:S⊢letx=sint≈(λx:S. t)(s) :T
Γ⊢if True then selset≈s:TΓ⊢if False then selset≈t:T
Γ⊢fst((s,t))≈s:S Γ⊢snd((s,t))≈t:T
Γ⊢hd(map(s,t))≈s(hd(t)) :T Γ⊢wt(map(s,t))≈wt(t) :R+Γ⊢tl(map(s,t))≈map(s,tl(t)) :ΣT
Γ⊢(hd(s),hd(t))≈hd(s⊗t) :S×T Γ⊢wt(s)∗wt(t)≈wt(s⊗t) :R+Γ⊢tl(s)⊗tl(t)≈tl(s⊗t) :Σ(S×T)
Γ⊢hd(thin(n,t))≈hd(t) :T Γ⊢wt(thin(n,t))≈wt(t) :R+{Γ⊢tl(thin(n,t))≈thin(n,tln(t)) :ΣT|n∈N}
Γ⊢thin(1,t)≈t:ΣT
Γ⊢hd(prng(s,t))≈t:T Γ⊢wt(prng(s,t))≈1 :R+Γ⊢tl(prng(s,t))≈prng(s,s(t)) :ΣT
Γ⊢hd(reweight (s,t))≈hd(t) :TΓ⊢wt(reweight (s,t))≈s(hd(t))∗wt(t) :R+Γ⊢tl(reweight (s,t))≈reweight (s,tl(t)) :ΣT
Γ⊢thin(n,thin(m,t))≈thin(n∗m,t)≈ΣT Γ⊢map(g,map(f,t))≈map(g◦f,t) :ΣT
Γ⊢reweight (g,reweight (f,t))≈reweight (f·g,t) :ΣT
{Γ⊢thin(n,prng(s,t))≈prng(sn,t) :ΣT|n∈N} Γ⊢thin(n,map(s,t))≈map(s,thin(n,t)) :ΣT
Γ⊢s⊗map(f,t)≈map(idS×f,s⊗t) :Σ(S×T) Γ⊢map(f,s)⊗t≈map(f×idT,s⊗t) :Σ(S×T)
Γ⊢s⊗reweight (g,t)≈reweight (1S·g,s⊗t) :Σ(S×T) Γ⊢reweight (f,s)⊗t≈reweight (f·1T,s⊗t) :Σ(S×T)
Γ⊢prng(f,a)⊗prng(g,b)≈prng(f×g,(a,b)) :Σ(S×T) Γ⊢thin(n,s)⊗thin(n,t)≈thin(n,s⊗t) :Σ(S×T)
TABLE IV: Rules for sampler equivalence
the form Γ⊢map(f,reweight (g,map(f′,...,s))) :ΣTor
Γ⊢reweight (g,map(f,reweight (g′,...,s))) :ΣT, i.e. a
composition of invocations of map andreweight (including
the trivial case of zero occurrences of either), where cruci ally
the sampler sdoes not contain the sampler operations mapor
reweight .
We can also show that the self-product distributes over the
operations mapself-andreweight ; such operations are useful
for representing the self-product of a composite sampler in a
simpler form whose correctness can then be veriﬁed.
Proposition IV .3. [Appendix A] For any mapped sampler
Γ⊢map(f,s) :ΣTand any n∈N, it follows that
Γ⊢map(f,s)n≈map(f×...×f,sn) :Σ(Tn); for a
reweighted sampler Γ⊢reweight (f,s) :ΣS, it follows that
Γ⊢reweight (f,s)n≈reweight (f·...·f,sn) :Σ(Sn).
V. S EMANTIC CORRECTNESS OF SAMPLERS
The fundamental correctness criterion for a sampler is that it
should produce samples which are distributed according to t he
desired target distribution. This section aims to sketch a s imple
‘targeting calculus’ to compositionally verify this prope rty.
We frame this correctness in terms of weak convergence of
measures; while other notions of convergence could be used,
weak convergence is standard and will sufﬁce for our purpose s.
A. The empirical transformation
First, we need to formalise what we mean when we say
that a sampler s:ΣTtargets a probability distribution on /llbracketT/rrbracket.
Given a topological space X, let us writePXfor the space
of probability measures on (the Borel σ-algebra generated
by)X, equipped with the topology of weak convergence, i.e.
limn→∞µn=µinPXif for any bounded continuous map
f:X→R,limn→∞/integraltext
f dµn=/integraltext
f dµ . In fact,Pdeﬁnes
a functor Top→Top : iff:X→Yis a continuous map,
thenP(f)/definesf∗:PX→PYis the pushforward map, whichis easily shown to be continuous. We do not know if PXis a
CG-space when Xis, and in particular we do not know if P
can be given a monad structure on CG. These questions are,
however, orthogonal to this work since Pplays no role in the
semantics of § III-C.
For any stream σ:N→X×R+we deﬁne ˆσn∈PXas
ˆσn/defines1
nn/summationdisplay
i=1π2(σ(i))/summationtextn
j=1π2(σ(j))δπ1(σ(i)),
theempirical distribution based on the ﬁrst n(weighted)
samples of σ. We also deﬁneP⊥X/definesPX+1, where1 ={⊥}
is the terminal object and +the coproduct in Top .
Deﬁnition V .1. The empirical measure transformation is the
Topobj-collection of maps
εX: (X×R+)N→P⊥X,σ/mapsto→/braceleftBigg
lim
n→∞ˆσnif it exists
⊥∈1 else
The empirical measure transformation cannot be natural, as
the following example shows.
Example V .1. Letσ:N→Xbe a diverging unweighted
sampler on X, i.e.εX(σ) =⊥, and consider the map to the
terminal object ! :X→1. Thenε1(!◦σ) =ε1(⊥,⊥,...) =
δ⊥, butP⊥(!)(εX(σ)) =P⊥(!)(⊥) =⊥.
However, if a sampler does deﬁne a probability measure via
ε, this is preserved by continuous maps.
Proposition V .1. [Appendix A] Let σ:N→X×R+and
f:X×R+→Y×R+be continuous. If εX(σ) =µ, then
εY(f◦σ) =f∗(µ).
It is tempting to try to generalise this nice property of con-
tinuous maps to more general maps – for example, measurable
maps. The following example shows that this is not possible.
Example V .2. LetX= [0,1]andσ:N→[0,1]denote any
unweighted sampler such that ε(σ)is the Lebesgue measureon[0,1]. Now consider the map f: [0,1]→{0,1}deﬁned
byf(x) = 1 ifx=σ(i)for some iand 0 else. This function
is the indicator function of a countable, therefore closed, set,
and so is Borel-measurable. On the one hand we have that
ε(f◦σ) =δ1sincef◦σis the constant stream on ones, but
on the other we have f∗(ε(σ))(1) =ε(σ)(f−1(1)) = 0 since
only a countable set is mapped onto 1 by f.
Even for functions with ﬁnitely many discontinuities, it is
impossible to extend the class of functions for which Prop. V .1
holds. However, the semantic framework adopted in § III-C
allows us to bypass this problem altogether. We illustrate t hese
two points by revisiting Ex. III.1.
Example V .3. Consider the sampler s/definesprng(λx:
R. x/2,1)and the term p/definesifx= 0then1else−1
of Ex. III.1. Assume ﬁrst that Ris equipped with its standard
topology, i.e. that /llbracketp/rrbracketis not continuous at 0. Since Ris a
metric space we can use the Portmanteau Lemma and rephrase
weak convergence by limiting ourselves to bounded Lipschit z
functions. It is then easy to show that ε(/llbrackets/rrbracket) =δ0: letting
f:R→Rbe bounded Lipschitz, we have
lim
n→∞/vextendsingle/vextendsingle/vextendsingle/vextendsingle/integraldisplay
f d/hatwider/llbrackets/rrbracketn−/integraldisplay
f dδ0/vextendsingle/vextendsingle/vextendsingle/vextendsingle= lim
n→∞/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle1
nn/summationdisplay
i=1f/parenleftbigg1
2i/parenrightbigg
−f(0)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle
≤lim
n→∞/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle1
nn/summationdisplay
i=11
2i/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle≤lim
n→∞2
n= 0
Prop. V .1 now fails on /llbracketp/rrbracket, since ε(/llbracketp/rrbracket◦/llbrackets/rrbracket) =
ε(−1,−1,...) =δ−1/ne}ationslash=P(/llbracketp/rrbracket)(ε(/llbrackets/rrbracket)) =/llbracketp/rrbracket∗(δ0) =δ1.
Let us now equip Rwith the topology given by type-checking
pas described in Ex. III.1. This makes /llbracketp/rrbracketbounded and
continuous, and we therefore no longer have ε(/llbrackets/rrbracket) =δ0;
indeedlimn/integraltext
/llbracketp/rrbracketd/hatwider/llbrackets/rrbracketn=−1/ne}ationslash=/llbracketp/rrbracket(0) = 1 . In fact
we now have ε(/llbrackets/rrbracket) =⊥, i.e.sis no longer a sampler
targeting anything for this topology, which prevents the fa ilure
of Prop. V .1 on /llbracketp/rrbracket.
This example also shows that our semantics has provided us
with many more morphisms satisfying Prop. V .1 than would
have been the case had we only considered programs which are
continuous w.r.t. the usual topology on the denotation of ty pes.
Our semantics allows us to push forward a sampler sthrough
any piecewise continuous function, except in the narrow cas e
where this function has a point of discontinuity which is
asymptotically assigned positive mass by s. We illustrate this
further in the next example.
Example V .4. Consider the sampler of Ex. V .3, but now
letp/definesifx= 2then1else−1instead. To make
this function continuous, our semantics adds the open set
{2}to the usual topology of R. This does not interfere
with the derivation that ε(/llbrackets/rrbracket) =δ0, since we can write/integraltext
f d/hatwider/llbrackets/rrbracketn=/integraltext
{2}cf d/hatwider/llbrackets/rrbracketn+/integraltext
{2}f d/hatwider/llbrackets/rrbracketn=/integraltext
{2}cf d/hatwider/llbrackets/rrbracketn,
and similarly for δ0. Because the discontinuity of /llbracketp/rrbracketis not
assigned any mass by δ0, the topology on Rmaking /llbracketp/rrbracket
continuous no longer prevents ε(/llbrackets/rrbracket)from converging, and
we can therefore safely push sforward through pusingmap.B. Calculus for asymptotic targeting
Deﬁnition V .2. We will say that the sampler Γ⊢s:ΣS
asymptotically targets , or simply targets , the continuous map
µ:/llbracketΓ/rrbracket→P/llbracketS/rrbracketif for every γ∈/llbracketΓ/rrbracket,
ε/llbracketS/rrbracket◦/llbrackets/rrbracket(γ) =µ(γ).
In particular, /hatwider/llbrackets/rrbracket(γ)nalways converges as n→∞ ; diverging
samplers do not target anything.
We will say that Γ⊢s:ΣSisK-equidistributed with respect
to the morphism µ:/llbracketΓ/rrbracket→ P /llbracketS/rrbracketif for every γ∈/llbracketΓ/rrbracket,
ε/llbracketS/rrbracket◦/largellbracket
sK/largerrbracket
(γ) =µK(γ), where the self-product sKis deﬁned
in(3)andµK(γ)∈P(/llbracketS/rrbracketK)is theK-fold product of the
measureµ(γ)with itself.
We introduce in Table V a relation /squigglerightwhich is sound with
respect to asymptotic targeting; this is the relation which was
used in the proofs of § II. That is, if Γ⊢s:ΣS/squigglerightµ, thens
is a parametrised sampler on Swhich asymptotically targets a
parametrised distribution µon/llbracketS/rrbracket. Here, we use Greek lower
case letters µ,ν to represent (parametrised) distributions in
order to emphasise their role as meta-variables, used only
in the context of the targeting calculus, and not within the
language itself. In the rule for reweight , we abbreviate the
operation of reweighting a measure µonXbyf:X→R≥0
as the product (f·µ)(A) =/integraltext
Af(x)dµ(x)/integraltext
Xf(x)dµ(x), assuming that the
integral in question is ﬁnite and nonzero.
Table V incorporates a rule for building samplers from
scratch as pseudo-random number generators deﬁned by a
deterministic endomap t:T→Tand an initial value x:Tvia
prng(t,x) :ΣT.5However, Table V also incorporates a set
of ‘axioms’ for built-in samplers randi, each targeting distri-
butionsµi∈P/llbracketTi/rrbracket; in some settings, it may be defensible
to assume access to ‘truly random’ samplers which generate
samples using a physical process.
The reader might wonder why Table V does not have a
rule for the thin operation: after all, if σis a sampler
targeting a distribution µ, then only keeping every nsamples
should produce a good sampler as well. Whilst this is true of
the sequences produced by ‘true’ i.i.d. samplers (for examp le
physical samplers) with probability 1, this rule is in gener al
not sound, as the following simple example shows.
Example V .5. Consider the sampler on {0,1}deﬁned by
the program prng(λx:R.1−x,0). This sampler, which
generates the unweighted samples (0,1,0,1,...), targets the
uniform Bernoulli distribution; however, applying thin(2,−)
to it yields a sampler which targets the Dirac measure δ0.
This example highlights the fact that samplers can be man-
ifestly non-random, and yet from the perspective of inferen ce
– that is to say, from the perspective of the topology of weak
convergence – target bona ﬁde probability distributions.
5Applying this rule requires showing that the initial point o f the sampler is
typical ; a point x∈/llbracketT/rrbracketis called typical if it belongs to the µ-mass 1 subset
X⊆/llbracketT/rrbracketin which the ergodic theorem holds [19, Theorem 9.6].Γi⊢randi:ΣTi/squigglerightµii∈IΓ⊢s≈t:ΣTΓ⊢s:ΣT/squigglerightµ
Γ⊢t:ΣT/squigglerightµΓ⊢s:ΣS/squigglerightµ
Γ⊢tl(s) :ΣS/squigglerightµ
Γ⊢s:ΣS/squigglerightµΓ⊢f:S→T
Γ⊢map(f,s) :ΣT/squigglerightγ/mapsto→(/llbracketf/rrbracket(γ))∗µ(γ)Γ⊢s:ΣS/squigglerightµΓ⊢f:S→R+
Γ⊢reweight (f,s) :ΣS/squigglerightγ/mapsto→/llbracketf/rrbracket(γ)·µ(γ)/integraltext
/llbracketS/rrbracket/llbracketf/rrbracket(γ)dµ(γ)∈(0,∞)
Γ⊢prng(f,x)/squigglerightµ/llbracketf/rrbracket:/llbracketT/rrbracket→/llbracketT/rrbracketergodic w.r.t. µ,x typical
TABLE V: Rules for asymptotic targeting
⊢rand3:ΣS/squigglerightU3⊢idR×box:S→T
⊢map(idR×box,rand3) :ΣT/squiggleright/llbracketidR×box/rrbracket∗(U3) =U⊗N(0, 1)⊢accept:T→R+
⊢reweight (accept,joint) :ΣT/squiggleright/llbracketaccept /rrbracket·(U⊗N(0,1)) ⊢produce :T→R
⊢map(produce,reweight (accept,joint)) :ΣR+/squiggleright/llbracketproduce /rrbracket∗(/llbracketaccept /rrbracket·(U⊗N(0,1))) = Γ( α,1)
Fig. 5: Validity of Marsaglia sampler in Listing 4
Theorem V .1. [Appendix A] Targeting /squigglerightis sound: if Γ⊢s:
ΣS/squigglerightµ, thenε/llbracketS/rrbracket◦/llbrackets/rrbracket=µ.
It is easily seen that the natural corresponding notion of
completeness, ε/llbracketS/rrbracket◦/llbrackets/rrbracket=µ→Γ⊢s:ΣS/squigglerightµ, does not
hold; see the following example.
Example V .6. Lets/definesprng(λn:R.n+1,0); clearly, s
does not target any (probability) measure. Apply to sthe
transformation map(λn:R.2∧(−1∗n),s). Whilesdoes not
target anything, and so our targeting calculus cannot prove
that the transformed sampler targets anything, it is immedi ate
that this sampler does target the Dirac measure δ0.
We saw in § V-A how our (sub-)typing system can be used
to safely pushforward samplers through maps which are only
piecewise continuous. Our typing system also allows us to ad d
additional constraints to samplers. Speciﬁcally, we can en sure
that a sampler visits certain subsets inﬁnitely often.
Proposition V .2. [Appendix A] Assume Γ⊢s:ΣS/squiggleright
µ,S⊳Tand/llbracketT/rrbracketsecond-countable; then Γ⊢map(λx:
S.cast/an}bracketle{tT/an}bracketri}htx,s) :ΣTtargets the same measure µonT.
Moreover, if /llbracketT/rrbracketis metrizable, if Uis in the topology of /llbracketS/rrbracket
but not /llbracketT/rrbracketandµ(∂TU)>0(where∂Tdenotes the boundary
in/llbracketT/rrbracket) thensmust visit ∂TUi.o. (inﬁnitely often).
Example V .7. Suppose we want s:ΣR/squigglerightBern(1/2). A
sampler alternating between the sampler z/definesprng(λx:
R. x/2,1)of Ex. V .3 and its shifted version map(λx:
R.1+x,z)will satisfy the condition, but will never visit 0
or1! We can use the previous result to enforce that a sampler
stargeting Bern(1/2)should visit 0i.o. by constructing sin
such a way that it has type Σ/parenleftbig
(x,0)−1Neq+(x,0)−1Eq/parenrightbig
(see
Ex. III.1). We can, in the same manner, enforce that a sampler
s′targeting Bern(1/2)visits1i.o. Finally, using the last two
rules of Fig. 4b which build the coarsest common reﬁnement of
two topologies, we can combine sands′to create a sampler
targeting Bern(1/2)and guaranteed to visit 0,1i.o.
Example V .8. We conclude with an example highlighting sam-
pler compositionality by chaining two well-known sampling
algorithms. Consider the following program:letbox =λu : R+×R+. sqrt(-2 *log(fst(u)))*
cos(2*pi*snd(u))in
letjoint = map(idR×box, rand3)in
letd =α- 1/3in
letc = 1/(3 *sqrt(d)) in
letaccept = λ(u, x) : T .
letv = (1+c *x)^3in
ifv > 0andlog(u) < x^2 + d - d *v + d*
log(v)then1else0in
letproduce = λz : T . d *(1+c*fst(cast/an}bracketle{tR×R/an}bracketri}htz))
^3in
map(proj,reweight (accept, joint))
Listing 4: Marsaglia sampler for gamma random variables
First, the Box-Muller technique is a well-known technique
for generating standard normal random variates using two
independent uniform samples; its veriﬁcation using the map
rule of Table V is straightforward. We then form a joint sam-
pler consisting of independent uniform and Gaussian sample s,
and then consume both of these samples to generate gamma-
distributed random variables z∼Γ(α,1), for shape α≥1,
using a well-known rejection sampling technique; see [28] f or
a proof. The validity of this sampler is sketched in Fig. 5; we
omit some types for brevity.
VI. D ISCUSSION
We have presented a ‘probabilistic’ language designed to
compositionally construct samplers . We have given this lan-
guage an intuitive operational semantics and a denotationa l se-
mantics in the category of CG-spaces, and shown that the two
are equivalent for closed samplers. This denotational univ erse
is sufﬁciently rich to interpret sampler types coinductive ly, and
to interpret functions which are only piecewise-continuou s on
the standard topologies given by the type system (§ III-C).
With the support of this language, we have shown how
to compositionally reason about the validity of sampler con -
structions, an essential aspect in the practice of probabil istic
programming. Our approach draws on a sound equational
system to reason about equivalent ways of constructing the
same sampler (§ IV) and a sound system for reasoning about
semantic correctness (§ V).What distinguishes our approach is that we are in effect
providing a purely deterministic semantics for probabilis tic
programs. This approach is much closer to the practice of
probabilistic programming, in which samples and samplers a re
the most important concrete entities; this distinction bet ween
samplers and the measures they target is necessary in order t o
support pseudo-random number generation. Measure-theore tic
entities, which have typically been a part of the denotation al
semantics of probabilistic languages, e.g. [21], [16], [12 ], [38],
[9], instead take a meta-theoretic role as veriﬁcation crit eria.
Two commonly-used schemes for producing samplers are
missing from our calculus: Markov chain Monte Carlo meth-
ods and resampling techniques, as applied in e.g. particle
ﬁlters. We consider adding these constructions to our langu age,
together with the corresponding correctness proofs in our
targeting calculus, to be future work.REFERENCES
[1] A NDRIEU , C., D OUCET , A., AND HOLENSTEIN , R. Particle markov
chain monte carlo methods. Journal of the Royal Statistical Society:
Series B (Statistical Methodology) 72 , 3 (2010), 269–342.
[2] B AGNALL , A., S TEWART , G., AND BANERJEE , A. Formally veriﬁed
samplers from probabilistic programs with loops and condit ioning, 2023.
[3] B ILLINGSLEY , P.Convergence of probability measures . John Wiley &
Sons, 2013.
[4] B INGHAM , E., C HEN, J. P., J ANKOWIAK , M., O BERMEYER , F., P RAD-
HAN , N., K ARALETSOS , T., S INGH , R., S ZERLIP , P. A., H ORSFALL ,
P.,AND GOODMAN , N. D. Pyro: Deep universal probabilistic program-
ming. J. Mach. Learn. Res. 20 (2019), 28:1–28:6.
[5] B LACKWELL , A., K OHN , T., E RWIG , M., B AYDIN , A. G., C HURCH ,
L., G EDDES , J., G ORDON , A., G ORINOVA , M., G RAM -HANSEN , B.,
LAWRENCE , N., M ANSINGHKA , V., P AIGE , B., P ETRICEK , T., R OBIN -
SON, D., S ARKAR , A., AND STRICKSON , O. Usability of probabilistic
programming languages. In Psychology of Programming Interest Group
Annual Workshop (PPIG 2019), Newcastle, UK, 28–30 August 20 19
(2019).
[6] B ORGSTRÖM , J., D ALLAGO, U., G ORDON , A. D., AND SZYMCZAK ,
M. A lambda-calculus foundation for universal probabilist ic program-
ming. ACM SIGPLAN Notices 51 , 9 (2016), 33–46.
[7] B ROOKS , S., G ELMAN , A., J ONES , G., AND MENG, X.-L. Handbook
of Markov Chain Monte Carlo . CRC press, 2011.
[8] C ARPENTER , B., G ELMAN , A., H OFFMAN , M. D., L EE, D.,
GOODRICH , B., B ETANCOURT , M., B RUBAKER , M., G UO, J., L I, P.,
AND RIDDELL , A. Stan: A probabilistic programming language. Journal
of statistical software 76 , 1 (2017).
[9] D AHLQVIST , F., AND KOZEN , D. Semantics of higher-order prob-
abilistic programs with conditioning. Proceedings of the ACM on
Programming Languages 4 , POPL (2019), 1–29.
[10] D AHLQVIST , F., K OZEN , D., AND SILVA , A.Semantics of Probabilistic
Programming: A Gentle Introduction . Cambridge University Press,
2020, pp. 1–42.
[11] E HRHARD , T., P AGANI , M., AND TASSON , C. The computational
meaning of probabilistic coherence spaces. In 2011 IEEE 26th Annual
Symposium on Logic in Computer Science (2011), IEEE, pp. 87–96.
[12] E HRHARD , T., P AGANI , M., AND TASSON , C. Measurable cones and
stable, measurable functions: a model for probabilistic hi gher-order
programming. Proceedings of the ACM on Programming Languages
2, POPL (2017), 1–28.
[13] E HRHARD , T., P AGANI , M., AND TASSON , C. Full abstraction for
probabilistic pcf. Journal of the ACM (JACM) 65 , 4 (2018), 1–44.
[14] F AGGIAN , C., AND DELLA ROCCA , S. R. Lambda calculus and
probabilistic computation. In 2019 34th Annual ACM/IEEE Symposium
on Logic in Computer Science (LICS) (2019), IEEE, pp. 1–13.
[15] G OODMAN , N., M ANSINGHKA , V., R OY, D. M., B ONAWITZ , K., AND
TENENBAUM , J. B. Church: a language for generative models. arXiv
preprint arXiv:1206.3255 (2012).
[16] H EUNEN , C., K AMMAR , O., S TATON , S., AND YANG , H. A convenient
category for higher-order probability theory. In 2017 32nd Annual
ACM/IEEE Symposium on Logic in Computer Science (LICS) (2017),
IEEE, pp. 1–12.
[17] H OYRUP , M., AND ROJAS , C. Computability of probability measures
and martin-löf randomness over metric spaces. Information and Com-
putation 207 , 7 (2009), 830–847.
[18] H UANG , D., M ORRISETT , G., AND SPITTERS , B. Application of
Computable Distributions to the Semantics of Probabilisti c Programs .
Cambridge University Press, 2020, p. 75–120.
[19] K ALLENBERG , O. Foundations of modern probability . Springer, 1997.
[20] K EREMEDIS , K., Ö ZEL, C., P I ˛ EKOSZ , A., S HUMRANI , M. A., AND
WAJCH , E. Compact complement topologies and k-spaces. arXiv
preprint arXiv:1806.10177 (2018).
[21] K OZEN , D. Semantics of probabilistic programs. J. Comput. Syst. Sci.
22, 3 (June 1981), 328–350.
[22] L AGO, U. D., AND ZORZI , M. Probabilistic operational semantics for
the lambda calculus. RAIRO-Theoretical Informatics and Applications-
Informatique Théorique et Applications 46 , 3 (2012), 413–450.
[23] L’E CUYER , P. History of uniform random number generation. In 2017
Winter Simulation Conference (WSC) (2017), pp. 202–230.
[24] L EOBACHER , G., AND PILLICHSHAMMER , F. Introduction to quasi-
Monte Carlo integration and applications . Springer, 2014.[25] L EWIS , L. G. The stable category and generalized Thom spectra.
Appendix A . PhD thesis, University of Chicago, Department of Mathe-
matics, 1978.
[26] L UNN , D., T HOMAS , A., B EST, N., AND SPIEGELHALTER , D. Winbugs
- a bayesian modeling framework: Concepts, structure and ex tensibility.
Statistics and Computing 10 (10 2000), 325–337.
[27] M ANSINGHKA , V., S ELSAM , D., AND PEROV , Y. Venture: a higher-
order probabilistic programming platform with programmab le inference.
arXiv e-prints (Mar. 2014), arXiv:1404.0099.
[28] M ARSAGLIA , G., AND TSANG , W. W. A simple method for generating
gamma variables. ACM Trans. Math. Softw. 26 , 3 (sep 2000), 363–372.
[29] M ARTIN -LÖF, P. The deﬁnition of random sequences. Information and
control 9 , 6 (1966), 602–619.
[30] M ATSUMOTO , M., AND NISHIMURA , T. Mersenne twister: A 623-
dimensionally equidistributed uniform pseudo-random num ber genera-
tor.ACM Trans. Model. Comput. Simul. 8 , 1 (1998), 3–30.
[31] M CCORD, M. C. Classifying spaces and inﬁnite symmetric products.
Transactions of the American Mathematical Society 146 (1969), 273–
298.
[32] P ARK, S., P FENNING , F., AND THRUN , S. A probabilistic language
based upon sampling functions. ACM SIGPLAN Notices 40 , 1 (2005),
171–182.
[33] R OBERT , C., AND CASELLA , G. Monte Carlo statistical methods .
Springer Science & Business Media, 2013.
[34] S TATON , S., W OOD , F., Y ANG , H., H EUNEN , C., AND KAMMAR ,
O. Semantics for probabilistic programming: higher-order functions,
continuous distributions, and soft constraints. In Proceedings of the 31st
Annual ACM/IEEE Symposium on Logic in Computer Science (LIC S)
(2016), IEEE, pp. 1–10.
[35] S TEENROD , N. E. A convenient category of topological spaces.
Michigan Mathematical Journal 14 , 2 (1967), 133–152.
[36] T HOMAS , A. Bugs: a statistical modelling package. RTA/BCS Modular
Languages Newsletter 2 (1994), 36–38.
[37] T REVISAN , L., AND VADHAN , S. Extracting randomness from sam-
plable distributions. In Proceedings of the 41st Annual Symposium
on Foundations of Computer Science (USA, 2000), FOCS ’00, IEEE
Computer Society, p. 32.
[38] V ÁKÁR , M., K AMMAR , O., AND STATON , S. A domain theory for
statistical probabilistic programming. Proceedings of the ACM on
Programming Languages 3 , POPL (2019), 1–29.
[39] V IGNA , S. Further scramblings of marsaglia’s xorshift generator s.
Journal of Computational and Applied Mathematics 315 (2017), 175–
181.
[40] W OOD , F., VAN DE MEENT , J. W., AND MANSINGHKA , V. A new
approach to probabilistic programming inference. In Proceedings of the
17th International conference on Artiﬁcial Intelligence a nd Statistics
(2014), pp. 1024–1032.(v,N)→vva value(t,N)→v
(f(t),N)→f(v)Func∋f:T→G
((λx:T.t)(s),N)→v
(letx=sint,N)→v(t[x←s],N)→v
((λx:T.t)(s),N)→v
(t,N)→v
(cast/an}bracketle{tT/an}bracketri}htt,N)→v(c,N)→j∈I(sj[xj←t],N)→v
(case(c,t)of{(i,xi)⇒si}i∈I),N)→v(t,N)→v
(inj(t),N)→v
(s,N)→v1(t,N)→v2
((s,t),N)→(v1,v2)(t,N)→(v1,v2)
(fst(t),N)→v1(t,N)→(v1,v2)
(snd(t),N)→v2
((s(hd(t)),wt(t)),N)→(v1,w1)...((s(hd(tlN−1(t)),wt(tlN−1(t))),N)→(vN,wN)
(map(s,t),N)→((v1,w1),...,(vN,wN))
((hd(t),s(hd(t))·wt(t)),N)→(v1,w1)...((hd(tlN−1(t)),s(hd(tlN−1(t)))·wt(tlN−1(t))),N)→(vN,wN)
(reweight (s,t),N)→((v1,w1),...,(vN,wN)
(s,N)→((v1,w1),...,(vN,wN)) (t,N)→((v′
1,w′
1),...,(v′
N,w′
N))
(s⊗t,N)→(((v1,v′
1),w1·w′
1),...,((vN,v′
N),wN·w′
N))
(t,N)→((v1,w1),...,(vN,wN))
(hd(t),N)→v1(t,N)→((v1,w1),...,(vN,wN))
(tl(t),N−1)→((v2,w2),...,(vN,wN))(t,N)→((v1,w1),...,(vN,wN))
(wt(t),N)→w1
(s,N)→i(t,Ni)→((v1,w1),...,(vNi,wNi))
(thin(s,t),N)→((v1,w1),(vi+1,wi+1),(v2i+1,w2i+1),...,(v(Ni)+1,w(Ni)+1))
(t,N)→v1(s(t),N)→v2...(sN−1(t),N)→vN
(prng(s,t),N)→((v1,1),...,(vN,1))
TABLE VI: Full big-step operational semantics
APPENDIX
Type-checking of Rejection-sampling (§ II-C)
We ﬁrst type-check accept from § II-C. This determines the type Twhich was left unspeciﬁed. To keep the derivation
readable we deﬁne t/defines(y,phi(x)∗sqrt(2∗pi)).
x:R,y:R⊢y:Rx:R,y:R⊢x:R⊢phi:R→R⊢2 :R⊢pi:R
x:R,y:R⊢phi(x)∗2∗pi:R
x:R,y:R⊢(y,phi(x)∗sqrt(2∗pi)) :R×R
(x,y) :t−1(<−1(0))+t−1(<−1(1))⊢(y,phi(x)∗sqrt(2∗pi)) :<−1(0)+<−1(1)<−1(0)+<−1(1)⊳R×R
(x,y) :t−1(<−1(0))+t−1(<−1(1))⊢y <phi(x)∗sqrt(2∗pi) :B⊢0 :R+⊢1 :R+
(x,y) :t−1(<−1(0))+t−1(<−1(1))⊢ify <phi(x)∗sqrt(2∗pi)then1else0 :R+
⊢λ(x,y) :t−1(<−1(0))+t−1(<−1(1)).ify <phi(x)∗sqrt(2∗pi)then1else0 :t−1(<−1(0))+t−1(<−1(1))→R+
Fig. 6: Derivation of accept from § II-C
We now deﬁne T=t−1(<−1(0))+t−1(<−1(1)) andproj/definesλu:T.fst(cast/an}bracketle{tR×R/an}bracketri}htu).
u:T⊢u:T
u:T⊢cast/an}bracketle{tR×R/an}bracketri}htu:R×RT⊳R×R
u:T⊢fst(cast/an}bracketle{tR×R/an}bracketri}htu) :R×R
⊢proj:T→R⊢accept:T→R+⊢tri:ΣR⊢rand:ΣR
⊢tri⊗rand:Σ(R×R)
⊢tri⊗rand:ΣTΣT⊳Σ(R×R),Γ =∅
⊢reweight (accept,tri⊗rand)) :ΣT
⊢map(reweight (accept,tri⊗rand),proj) :ΣR
Fig. 7: Derivation of the rejection sampling algorithm § II- CProof of Prop. III.1.
In order to prove this result by induction on the derivation t ree of(t,N)→v, we must ﬁrst generalise it to include higher
samplers.
Proposition A.1. If⊢s:ΣkSis a closed k-order sampler where Sis not a sampler type and k∈{0,1,2,...}, then for
anyN∈N, if(s,N)→v, thenvhas the form of a k-nested weighted list of values of type S. For example, for k= 0,
v:Sis simply a value of type S; fork= 1,v= ((v1,w1),...,(vN,wN))is a weighted list of values vn:Sandwn≥0;
fork= 2,v= (((v1
1,w1
1),...,(v1
N,w1
N)),w1),...,(((vN
1,wN
1),...,(vN
N,wN
N)),wN))is a weighted list of weighted lists of
values of type vn
n:S, and so on.
Base case. As values vcannot have sampler type, the only possibility for a derivat ion(v,N)→vwherev:ΣkTfor some
typeTisk= 0, which makes our result immediate.
Inductive case. We illustrate the inductive argument for each case, dependi ng on the last rule of the derivation of (t,N)→v,
where⊢t:ΣkTis ak-order sampler for some k∈{0,1,2,...}, andTis not a sampling type (i.e. contains no occurrences of
Σ).
1)Built-in functions. There are no built-in functions which either input or output sampler types, so k= 0. Taking the
inductive hypothesis that each input si:Gireduces to a value vi:Gi, whereGnare ground types, we immediately obtain
that(f(s1,...,s n),N)→vevaluates to a value vof ground type G, giving our result.
2)Case. Assuming that t=case(c,t′)of{(i,xi)⇒si}i∈n, we must have⊢si:ΣkT. Taking the inductive hypothesis
that(si[xi←t′],N)→vevaluates to a k-nested weighted list, if (c,N)→i∈n, it immediately follows that (t,N)→v
does as well.
3)Function application. Taket= (λx:Σk′S.t′)(s)to be an instance of function application, where the functio n in question
inputs ak′-sampler and outputs a k-sampler, where Sdoes not contain any sampler types itself; we must have ⊢s:Σk′S
in order for the expression to be well-typed. In order to have (t,N)→vevaluate to a value, our operational semantics
requires(t′[x←s],N)→v; taking the inductive hypothesis that t′[x←s]evaluates to a k-nested list of values of type
S, our desired result follows.
4)let-binding. Trivially follows from function application, as (letx=sint′,N)→viff((λx:S.t′)(s),N)→v.
5)Product. Ift= (s,s′), the result is trivial as ⊢t:ΣkTimpliesk= 0 and soT=S×S′where⊢s:S,⊢s′:S′are each
not sampler types; therefore, (s,s′)is clearly a value of type T(i.e., a 0-nested weighted list).
6)Projections. Ift=fst((s,s′)), then⊢s:ΣkT, and so the inductive hypothesis (s,N)→vimmediately implies our
result; the same argument applies to snd andt.
7)Head. Ift=hd(s), then⊢s:Σk+1T. Taking the inductive hypothesis that (s,N)→vimplies that vis a(k+1)-nested
weighted list of values of type T, we need only note that the ﬁrst element of this list is itself ak-nested weighted list of
values of type T.
8)Weight. Ift=wt(s), our result is trivially true, as the output of wt(s)can only be a nonnegative real number ⊢t:R+.
9)Tail. Ift=tl(s), then by our inductive hypothesis, (s,N+ 1)→((v1,w1),...,(vN+1,wN+1))where each vnis a
(k−1)-nested weighted list of elements of type T. It immediately follows that (tl(s),N)evaluates to a weighted list of
Nelements whose elements are each (k−1)-nested lists of type T.
10)Thin. Ift=thin(i,s), then⊢n:Nand⊢s:ΣkT, and by our inductive hypothesis, (s,Ni)→
((v1,w1),...,(vNi+1,wNi+1))where each vnis a(k−1)-nested weighted list of elements of type T. It immediately
follows that (thin(i,s),N)evaluates to a weighted list of Nelements whose elements are each (k−1)-nested lists of
typeT.
11)Map. Ift=map(s,t′)and(t,N)→v, the operational semantics of map requires that
/parenleftbig
(s(hd(tln−1(t′))),wt(tln−1(t′))),N/parenrightbig
→(vn,wn)
for each n∈ {1,...,N}. Ast′is a subterm of t, our inductive hypothesis implies that if ⊢t′:Σk′Sfor some
k′∈{1,2,...}, then for any N∈N,t′evaluates to a k′-nested weighted list of values of type S. Note that in order for
tto be well-typed, we must have ⊢s:Σk′−1S→Σk−1T. We have already shown that if this is the case, then tln−1(t′)
evaluates to a k′-nested weighted list of values of type S, and then that hd(tln−1(t′))evaluates to a (k′−1)-nested
weighted list of values of type Sof length N, and then that s(hd(tln−1(t′)))evaluates to a (k−1)-nested weighted list of
values of type Tof length N. Our result follows by observing that if ((s(hd(tln−1(t′))),wt(tln−1(t′))),N)→(vn,wn)
for each n∈ {1,...,N}where each vnis ak−1-nested weighted list of values of type T, then the expression
((v1,w1),...,(vN,wN))is ak-nested weighted list of values of type T, completing the proof.
12)Reweight. This proof works in exactly the same way as that of map.
13)Product of samplers. Ift=s⊗s′and⊢t:ΣkTwhereTcontains no instances of Σ, then it must be that k≥1,
that⊢s:ΣkS, and that⊢s′:ΣkS′. Our inductive hypothesis states that (s,N)→((v1,w1),...,(vN,wN))whereeachv1is a(k−1)-nested weighted list of values of type S, and(s′,N)→((v′
1,w′
1),...,(v′
N,w′
N))where each v′
1
is a(k−1)-nested weighted list of values of type S′. Our result then follows by noting that the product (((v1,v′
1),w1·
w′
1),...,((vN,v′
N),w′
N))is ak-nested weighted list of values of type S.
14)Pseudorandom number generators. Finally, assume t=prng(s,t′); in order for this expression to be well-typed, we
must have k≥1,⊢t′:Σk−1T, and⊢s:Σk−1T→Σk−1T. In order for (t,N)to evaluate to anything, we must have
(sn−1(t),N)→vnfor eachn∈{2,...,N}; as we have already proven the case for function abstraction , we know that
eachvnis a(k−1)-nested weighted list of values of type T. We need only note then that ((v1,1),...,(vN,1))is clearly
ak-nested weighted list of values of type T.
Proof of Prop. III.3.
Letfn→fbe a convergent sequence a coalgebra maps in [X,FX]; we need to show that behX(fn)→behX(f)in[X,νF].
The topology on [X,νF]is the compact-open topology, which means that it is generat ed by the subbase of open sets of the
shape
(K,V)/defines{h:X→νF|h[K]⊂U}
for some ﬁxed compact set K⊆Xand open set U⊆νF. Moreover, by construction of νF(see Thm. III.1), we know that
the topology is induced by the product topology on/producttext
iFi1. A base for this topology is given by intersections of cylind er sets
withνF. Because we are also assuming that int(νF)/ne}ationslash=∅in/producttext
iFi1, it contains such an open set, and we can thus simply
start with an open neighbourhood of behXfof the shape (K,/producttext
iVi)where for all but ﬁnitely many indices Vi=Fi1, and for
the other indices Viis an open subset of Fi1(and we don’t have to worry about intersecting with νF). Given such an open
set, we need to ﬁnd N∈Nsuch that for all n > NbehX(fn)∈(K,/producttext
iVi).
By the construction of Thm. III.1 we have that
behX(f)(x) = (!X(x),F!X(f(x)),F2!X(Ff(f(x))),...)
where!X:X→1is the unique morphism to the terminal object. For each of the ﬁnitely many non-trivial open subsets
Vik⊂Fik1,1≤k≤M, because fn→fand composition with continuous functions is a continuous o peration on internal
hom sets in CG ([35, 5.9]), it follows that there exists Nksuch that for every n > N k
Fik!X◦Fik−1fn◦...◦fn∈(K,Vik)
By taking N= max 1≤k≤MNk, we get that for for alli∈Nand alln > N
Fi!X◦Fi−1fn◦...◦fn∈(K,Vi)
In other words, for any n > N ,behX(fn)∈(K,/producttext
iVi), which concludes the proof.
Proof of Thm. III.2.
⇐) By induction on the derivation tree of (t,N)→v.
Base case. The base case is trivial: the only derivation of length 0 allo wed by Table II assumes that t=vis a value. It is
easy to check that if t:Tis a value, then pN
T= id /llbracketT/rrbracketand thus pN
T(/llbrackett/rrbracket) =/llbrackett/rrbracket=/llbracketv/rrbrackettautologically.
Inductive case. Assume that the last rule of the derivation of (t,N)→vis
(i)Built-in functions. t=f(s1,...,s n)for some si:Gi,1≤i≤n. Since for a ground type Gwe have pN
G= id /llbracketG/rrbracket, we
immediately get
pN
G(/llbracketf(s1,...,s n)/rrbracket)/defines/llbracketf/rrbracket(/llbrackets1/rrbracket,.../llbracketsn/rrbracket)
=/llbracketf/rrbracket(/llbracketv1/rrbracket,...,/llbracketvn/rrbracket) induction hypothesis
(ii)Case.t=case(c,t′)of{(i,xi)⇒si}i∈I. Ifcchooses the branch j∈n, then
pN
T/parenleftbig/largellbracket
case(c,t′)of{(i,xi)⇒si}i∈I/largerrbracket/parenrightbig
/defines/llbracketsj/rrbracket(/llbrackett′/rrbracket)
=/llbracketv/rrbracket induction hypothesis(iii)λ-abstraction. t= (λx:S. t′)(s) :Tfor some s:Sand some t′:T.
pN
T(/llbracket(λx:T. t′)(s)/rrbracket)/definespN
T◦ev/llbracketS/rrbracket,/llbracketT/rrbracket(/llbracketλx:T. t′/rrbracket×/llbrackets/rrbracket)
/definespN
T◦ev/llbracketS/rrbracket,/llbracketT/rrbracket/parenleftBig/hatwidest/llbrackett′/rrbracket×/llbrackets/rrbracket/parenrightBig
Currying /llbrackett′/rrbracket
=pN
T◦ev/llbracketS/rrbracket,/llbracketT/rrbracket(/llbrackett′/rrbracket×/llbrackets/rrbracket) /llbrackett′/rrbrackethas only one variable
=pN
T(/llbrackett′/rrbracket(/llbrackets/rrbracket))
=/llbracketv/rrbracket induction hypothesis
(iv)let-binding. t=letx=sint′:Tfor some s:Sandt′:T.
pN
T(/llbracketletx=sint/rrbracket)/defines/llbrackett′/rrbracket(/llbrackets/rrbracket)
=pN
T(/llbracketλx. t′/rrbracket(/llbrackets/rrbracket))
=/llbracketv/rrbracket induction hypothesis
(v)Product. t= (s,s′)for some s:S,s′:S′
pN
S×S′(/llbracket(s,s′)/rrbracket)/definespN
S×S′(/an}bracketle{t/llbrackets/rrbracket,/llbrackets′/rrbracket/an}bracketri}ht)
=/an}bracketle{tpN
S(/llbrackets)/rrbracket,pN
S′(/llbrackets′/rrbracket)/an}bracketri}ht inductive deﬁnition of pN
T
=/an}bracketle{t/llbracketv1/rrbracket,/llbracketv2/rrbracket/an}bracketri}ht induction hypothesis
=/llbracket(v1,v2)/rrbracket
(vi) Projections t=fst(s,s′)for some s:S,s′:S′
pN
S(/llbracketfst(s,s′)/rrbracket)/definespN
S(π1/an}bracketle{t/llbrackets/rrbracket,/llbrackets′/rrbracket/an}bracketri}ht)
=pN
S(/llbrackets/rrbracket)
=/llbracketv1/rrbracket induction hypothesis
and similarly for snd.
(vii) Pushforward. t=map(s,t)for some s:S→Tandt:ΣS. To keep the derivation readable we will write sinstead of
/llbrackets/rrbracket,tinstead of /llbrackett/rrbracketand we introduce the following notation. Let Fdenote the functor /llbracketT/rrbracket×R+×Id, letγ:νF→FνF
denote the terminal coalgebra structure map unfoldT, letδ/defines/llbrackets/rrbracket×idR+×idΣS◦unfoldS, the coalgebra structure map
deﬁning the map operation, let b= beh(δ), and let
h/definesπ1◦unfoldS i.e.h(t)is the ﬁrst sample of t
w/definesπ2◦unfoldS i.e.w(t)is the weight of the ﬁrst sample of t
f/definesπ3◦unfoldS i.e.f(t)is the tail of t
With this we can now derive
pN
ΣT(/llbracketmap(s,t)/rrbracket)
/definesπ1:N◦/parenleftbig
pN
T×R+/parenrightbigω(/llbracketmap(s,t)/rrbracket)
/definesπ1:N◦/parenleftbig
pN
T×R+/parenrightbigω(b(t))
(1)=/parenleftbig
pN
T×R+/parenrightbigN◦π1:N(b(t))
(2)=/parenleftbig
pN
T×R+/parenrightbigN◦Fπ1:N−1◦γ◦(b(t))
(3)=/parenleftbig
pN
T×R+/parenrightbigN◦FN−1π1◦FN−2γ◦...◦F0γ(b(t))
(4)=/parenleftbig
pN
T×R+/parenrightbigN◦FN−1π1◦FN−1b◦FN−2δ◦...◦F0δ(t)
(5)=/parenleftbig
pN
T×R+/parenrightbigN◦FN−1π1◦FN−1b/parenleftbig
(s(h(t)),w(t)),...,(s(h(fN−1(t))),w(fN−1(t))),fN−1(t)/parenrightbig
(6)=/parenleftbig
pN
T×R+/parenrightbigN◦/parenleftbig
(s(h(t))),w(t)),...,(s(h(fN−1(t))),w(fN−1(t)))/parenrightbig
=/parenleftbig
pN
T×R+(s(h(t))),w(t)),...,pN
T×R+(s(h(fN−1(t))),w(fN−1(t)))/parenrightbig
=/parenleftbig
(pN
T(s(h(t))),w(t)),...,(pN
T(s(h(fN−1(t)))),w(fN−1(t)))/parenrightbig
(7)=/llbracket((v1,w1),...,(vN,wN))/rrbracketwhere(1)is the simple observation that π1:N◦(pN
T)ω= (pN
T)N◦π1:N,(2)is by deﬁnition of γ,(3)is by iteration of
(2),(4)follows from the fact that bis a coalgebra morphism, (5)is by deﬁnition of δ,(6)is by deﬁnition of F,band
p1
T, and(7)is by the induction hypothesis on the Npremises of the rule.
(viii) Reweight. The proof is very similar to the case of map. Again, writing
δ/definesid/llbracketT/rrbracket×(−·−)×id/llbracketΣT/rrbracket◦/an}bracketle{tid/llbracketT/rrbracket,/llbrackets/rrbracket/an}bracketri}ht×idR+×id/llbracketΣT/rrbracket◦γ
for the coalgebra structure deﬁning reweight andb= beh(δ), we get
pN
ΣT(reweight (s,t))
/definesπ1:N◦/parenleftbig
pN
T×R+/parenrightbigω(reweight (s,t))
/defines/parenleftbig
pN
T×R+/parenrightbigN◦π1:N◦b(t)
(1)=/parenleftbig
pN
T×R+/parenrightbigN◦FN−1π1◦FN−1b/parenleftbig
(h(t),s(h(t))w(t)),...,(h(fN−1(t)),s(fN−1(t))w(fN−1(t))),fN−1(t)/parenrightbig
(2)=/parenleftbig
(pN
T(h(t)),s(h(t))w(t)),...,(pN
T(h(fN−1(t))),s(fN−1(t))w(fN−1(t)))/parenrightbig
(3)= ((/llbracketv1/rrbracket,/llbracketw1/rrbracket),...,(/llbracketvN/rrbracket,/llbracketwN/rrbracket))
where(1)follows the same derivation as in the case of map but with the deﬁnition of δas above, (2)is by deﬁnition
ofFandpN
T×R+, and(3)is by the the induction hypothesis applied to the Npremises of the reweight rule.
(ix) Product of samplers. The proof works in exactly the same way as for map andreweight .
(x)Thin. The proof works in exactly the same way as for map andreweight .
(xi) Pseudorandom number generators. Consider the term prng(s,t) :ΣT. Using
δ/defines/an}bracketle{tid/llbracketT/rrbracket,1,/llbrackets/rrbracket/an}bracketri}ht
andb= beh(δ), the same steps as in the case of map andreweight yield
pN
ΣT(/llbracketprng(s,t)/rrbracket)/definesπ1:N◦(pN
T×R+)ω(/llbracketprng(s,t/rrbracket)
=/parenleftbig
pN
T×R+/parenrightbigN◦FN−1π1◦FN−1b((t,1),(s(t),1),...,sN−1(t),1),sN(t))
= ((pN
T(t),1),(pN
T(s(t)),1),...,(pN
T(sN−1(t)),1))
=/llbracket(v1,1),(v2,1),...,(vN,1))/rrbracket
(xii) Head. Consider the term hd(t)for some t:ΣT. Using the same notation as above
pN
T◦/llbrackethd(t)/rrbracket/definespN
T◦π1◦γ(/llbrackett/rrbracket)
=π1◦π1◦/parenleftbig
pN
T×R+/parenrightbigN◦π1:N(/llbrackett/rrbracket)
=π1◦π1/llbracket(v1,w1),...,(vN,wN)/rrbracket induction hypothesis
=/llbracketv1/rrbracket
(xiii) Weight. Consider the term wt(t)for some t:ΣT. The proof is the same as the above:
pN
T◦/llbracketwt(t)/rrbracket/definespN
T◦π2◦γ(/llbrackett/rrbracket)
=π2◦π1◦/parenleftbig
pN
T×R+/parenrightbigN◦π1:N(/llbrackett/rrbracket)
=π2◦π1/llbracket(v1,w1),...,(vN,wN)/rrbracket induction hypothesis
=/llbracketw1/rrbracket
(xiv) Tail. Consider the term tl(t)f for some t:ΣT. It is immediate that
pN
ΣT◦/llbrackettl(t)/rrbracket/defines/parenleftbig
pN
T×R+/parenrightbigN◦π1:N(π3◦γ(/llbrackett/rrbracket))
=/parenleftbig
pN
T×R+/parenrightbigN◦π2:N+1(/llbrackett/rrbracket)
=π2:N+1◦/parenleftbig
pN
T×R+/parenrightbigN+1◦π1:N+1(/llbrackett/rrbracket)
=π2:N+1/llbracket(v1,w1),...,(vN+1,wN+1)/rrbracket inductive hypothesis
=/llbracket(v2,w2),...,(vN+1,wN+1)/rrbracket
⇒) By induction on the typing-proof of t. Note that for any term t:T,pN
T/llbrackett/rrbracketis necessarily a value, by deﬁnition of pN
T.Base case. The only programs which are type-checkable in 0 steps are the constants. Since all constants are values and
values operationally evaluate to themselves, the base case holds trivially.
Inductive case. The proof is routine and we only show a few cases. Suppose that the last step of the rule applied in the
type-checking of twas
(i)Product. Suppose⊢(s,t) :S×Tand thatpN
S×T(/llbracket(s,t)/rrbracket) =/llbracketv/rrbracketfor some value v. Since the last applied rule had premises
⊢s:Sand⊢t:Twe have
/llbracketv/rrbracket=pN
S×T(/llbrackets⊗t/rrbracket)
=pN
S×pN
T/an}bracketle{t/llbrackets/rrbracket,/llbrackett/rrbracket/an}bracketri}ht inductive deﬁnition of pN
S×T
= (pN
S/llbrackets/rrbracket,pN
T/llbrackett/rrbracket)
= (/llbracketv1/rrbracket,/llbracketv2/rrbracket)
for some values v1,v2. By the induction hypothesis it is therefore the case that (s,N)→v1and(t,N)→v2for any
N∈Nand it follows that (s⊗t,N)→(v1,v2)by deﬁnition of the reduction relation →.
(ii)λ-abstraction. If⊢λx:S. t:S→T, then the term λx:S. tis a value, and thus (λx:S. t,N)→λx:S. ttrivially.
(iii) Head. Suppose that⊢hd(t) :T, and that pN
T(/llbrackethd(t)/rrbracket) = /llbracketv1/rrbracketfor some value v1. Since the last applied
rule has the premise ⊢t:ΣT, and given the semantics of hd, it must be the case that for any N≥1,/parenleftbig
pN
T×R+/parenrightbigN◦π1:N(t) =/llbracket((v1,w1),...,(vN,wN))/rrbracketfor some values vi,wi. By the induction hypothesis it must be the
case that (t,N)→((v1,w1),...,(vN,wN)), and thus that (hd(t),N)→v1.
(iv) Weight. The proof is the same as that for hd. Suppose that⊢wt(t) :T, and that pN
T(/llbracketwt(t)/rrbracket) =/llbracketw1/rrbracketfor some weight
w1≥0. Since the last applied rule has the premise ⊢t:ΣT, and given the semantics of wt, it must be the case that
for anyN≥1,/parenleftbig
pN
T×R+/parenrightbigN◦π1:N(t) =/llbracket((v1,w1),...,(vN,wN))/rrbracketfor some values vi,wi. By the induction hypothesis it
must be the case that (t,N)→((v1,w1),...,(vN,wN)), and thus that (wt(t),N)→w1.
(v)Pushforward. Suppose that⊢map(t,s) :ΣTand that pN
ΣT(/llbracketmap(t,s)/rrbracket) =/llbracket((v1,w1),...,(vn,wn)/rrbracket. The premises of
the last applied rule must have been ⊢s:ΣSand⊢t:S→T, and it follows from the semantics of map that/llbracketvi/rrbracket=
pN
T/largellbracket
t(hd(tli−1(s)))/largerrbracket
)and/llbracketwi/rrbracket=/largellbracket
wt(tli−1(s))/largerrbracket
. It follows from the induction hypothesis that (t(hd(tli−1(s)),N)→
viand(wt(tli−1(s)),N)→wi, and thus by the deﬁnition of →we have that (map(t,s),N)→((v1,w1),...,(vn,wn).
Proof of Thm. IV .1.
Standard rules :
1)β- andη-equivalence.
/llbracketΓ⊢(λx:S.t)(s) :T/rrbracket=/llbracketΓ⊢t[x←s] :T/rrbracket,
/llbracketΓ⊢λx:S.t(x) :S→T/rrbracket=/llbracketΓ⊢t:S→T/rrbracket
The soundness of β- andη-equivalence is well-known and immediate from the properti es of exponential objects.
2)let-reduction.
/llbracketΓ,s:S⊢letx=sint:T/rrbracket=/llbracketΓ,s:S⊢(λx:S.t)(s) :T/rrbracket
True by deﬁnition of the denotational semantics of let.
3)Projections.
/llbracketΓ⊢fst((s,t)) :S/rrbracket=/llbracketΓ⊢s:S/rrbracket,
/llbracketΓ⊢snd((s,t)) :T/rrbracket=/llbracketΓ⊢t:T/rrbracket
Immediate from the properties of Cartesian products.
Congruence rules : Trivial in the denotational setting: if /llbracketΓ⊢s:S/rrbracket=/llbracketΓ⊢s′:S/rrbrackethave identical semantics, then clearly, for
any built-in operation op:S→T,/llbracketΓ⊢op(s) :T/rrbracket=/llbracketΓ⊢op(s′) :T/rrbracket; the same extends to n-ary operations.
Coinductive deﬁnitions :
1)Map.
/llbracketΓ⊢hd(map(s,t)) :T/rrbracket=/llbracketΓ⊢s(hd(t)) :T/rrbracket,/largellbracket
Γ⊢wt(map(s,t)) :R+/largerrbracket
=/largellbracket
Γ⊢s(wt(t)) :R+/largerrbracket
,
/llbracketΓ⊢tl(map(s,t)) :ΣT/rrbracket=/llbracketΓ⊢map(tl(t)) :ΣT/rrbracket
Immediate from the coinductive deﬁnition of map.2)Product.
/llbracketΓ⊢(hd(s),hd(t)) :S×T/rrbracket=/llbracketΓ⊢hd(s⊗t) :S×T/rrbracket,/largellbracket
Γ⊢wt(s)∗wt(t) :R+/largerrbracket
=/largellbracket
Γ⊢wt(s⊗t) :R+/largerrbracket
,
/llbracketΓ⊢tl(s)⊗tl(t) :Σ(S×T)/rrbracket=/llbracketΓ⊢tl(s⊗t) :Σ(S×T)/rrbracket
Immediate from the coinductive deﬁnition of ⊗.
3)Thinning.
/llbracketΓ⊢hd(thin(n,t)) :T/rrbracket=/llbracketΓ⊢hd(t) :T/rrbracket,/largellbracket
Γ⊢wt(thin(n,t)) :R+/largerrbracket
=/largellbracket
Γ⊢wt(t) :R+/largerrbracket
,
∀n∈N,/llbracketΓ⊢tl(thin(n,t)) :ΣT/rrbracket=/llbracketΓ⊢thin(n,tln(t)) :ΣT/rrbracket,
/llbracketΓ⊢thin(1,t) :ΣT/rrbracket=/llbracketΓ⊢t:ΣT/rrbracket
Immediate from the coinductive deﬁnition of thin .
4)Pseudorandom number generators.
/llbracketΓ⊢hd(prng(s,t)) :T/rrbracket=/llbracketΓ⊢t:T/rrbracket,/largellbracket
Γ⊢wt(prng(s,t)) :R+/largerrbracket
=/largellbracket
Γ⊢1 :R+/largerrbracket
,
/llbracketΓ⊢tl(prng(s,t)) :ΣT/rrbracket=/llbracketΓ⊢prng(s,s(t)) :ΣT/rrbracket
Immediate from the coinductive deﬁnition of prng .
5)Reweighting.
/llbracketΓ⊢hd(reweight (s,t)) :T/rrbracket=/llbracketΓ⊢hd(t) :T/rrbracket,/largellbracket
Γ⊢wt(reweight (s,t)) :R+/largerrbracket
=/largellbracket
Γ⊢s(hd(t))∗wt(t) :R+/largerrbracket
,
/llbracketΓ⊢tl(reweight (s,t)) :ΣT/rrbracket=/llbracketΓ⊢reweight (s,tl(t)) :ΣT/rrbracket
Immediate from the coinductive deﬁnition of reweight .
Composition rules :
1)Thinning over thinning.
/llbracketΓ⊢thin(n,thin(m,t)) :ΣT/rrbracket=/llbracketΓ⊢thin(n∗m,t) :ΣT/rrbracket
For any possible value of the context γ∈/llbracketΓ/rrbracket, we show equality between the elements /llbracketΓ⊢thin(n,thin(m,t)) :ΣT/rrbracket(γ)
and/llbracketΓ⊢thin(n∗m,t) :ΣT/rrbracket(γ)of/llbracketΣT/rrbracketcoinductively. As all of the arguments we will make have prec isely the same
structure, we will only give that structure in full detail fo r this proof; for the rest, we will only present the bisimulat ion
which gives our result.
We show this result by constructing, for each γ∈/llbracketΓ/rrbracket, a bisimulation R(γ)⊆/llbracketΣT/rrbracket×/llbracketΣT/rrbracket. This is a set of samplers
satisfying three properties:
a)∀(s,t)∈R(γ),π1(unfold T(s)) =π1(unfold T(t)); that is, the head of sand the head of tare the same
b)∀(s,t)∈R(γ),π2(unfold T(s)) =π2(unfold T(t)); that is, the ﬁrst weight of sand the ﬁrst weight of tare the same
c)∀(s,t)∈R(γ),(π3(unfold T(s)),π3(unfold T(t)))∈R(γ); that is, applying tlto two samplers in the bisimulation
yields two more samplers in the bisimulation.
The structure of this bisimulation R(γ)is typically found by applying tlto both sides of the equivalence we wish to
show, and then applying the rules we have previously shown (t ypically, the coinductive deﬁnitions of each operation, in
this casethin ) to simplify what results. For example, in this case, we can s implify
/llbracketΓ⊢tl(thin(n,thin(m,t))) :ΣT/rrbracket=/llbracketΓ⊢thin(n,thin(m,tlm∗n(t))) :ΣT/rrbracket
and
/llbracketΓ⊢tl(thin(n∗m,t)) :ΣT/rrbracket=/llbracketΓ⊢thin(n∗m,tln∗m(t)) :ΣT/rrbracket.
This suggests as a bisimulation the following set:
R(γ) =/braceleftbig/largellbracket
(Γ⊢thin(n,thin(m,tlk(t))) :ΣT/largerrbracket
(γ),/largellbracket
Γ⊢thin(n∗m,tlk(t)) :ΣT)/largerrbracket
(γ)|k∈N/bracerightbig
.
In future, as this expression is quite crowded, we will drop t he dependence on γ.We must now show that this is a valid bisimulation. First, we m ust show that applying hdandwtto each of these programs
yields the same result, which is always immediate. In this ca se, applying the rule we had previously referred to as the
coinductive deﬁnition of thin gives
/largellbracket
Γ⊢hd(thin(n,thin(m,tlk(t)))) :T/largerrbracket
=/largellbracket
Γ⊢hd(thin(m,tlk(t))) :T/largerrbracket
=/largellbracket
Γ⊢hd(tlk(t)) :T/largerrbracket
and/largellbracket
Γ⊢hd(thin(n∗m,tlk(t))) :T/largerrbracket
=/largellbracket
Γ⊢hd(tlk(t)) :T/largerrbracket
;
The same argument exactly applies for wt:
/largellbracket
Γ⊢wt(thin(n,thin(m,tlk(t)))) :R+/largerrbracket
=/largellbracket
Γ⊢wt(thin(m,tlk(t))) :R+/largerrbracket
=/largellbracket
Γ⊢wt(tlk(t)) :R+/largerrbracket
and/largellbracket
Γ⊢wt(thin(n∗m,tlk(t))) :R+/largerrbracket
=/largellbracket
Γ⊢wt(tlk(t)) :R+/largerrbracket
;
Finally, we must show that applying tlto each of these expressions yields another element of the bi simulation. This is
essentially the same argument as the one which led us to the bi simulation R:
/largellbracket
Γ⊢tl(thin(n,thin(m,tlk(t)))) :ΣT/largerrbracket
=/largellbracket
Γ⊢thin(n,tln(thin(m,tlk(t)))) :ΣT/largerrbracket
=/largellbracket
Γ⊢thin(n,thin(m,tln∗m+k(t))) :ΣT/largerrbracket
and
/largellbracket
Γ⊢tl(thin(n∗m,tlk(t))) :ΣT/largerrbracket
=/largellbracket
Γ⊢thin(n∗m,tln∗m+k(t)) :ΣT/largerrbracket
Therefore, for any γ, applying tlwill yield another element of our bisimulation, and so our pr oof is complete. Using
this proof as a reference, we will abbreviate the remainder o f the bisimulation proofs in the Appendix, as the structure o f
each argument is identical.
2)Map over map.
/llbracketΓ⊢map(g,map(f,t)) :ΣT/rrbracket=/llbracketΓ⊢map(g◦f,t) :ΣT/rrbracket
Applying the coinductive deﬁnition of map, we can easily see
/llbracketΓ⊢tl(map(g,map(f,t))) :ΣT/rrbracket=/llbracketΓ⊢map(g,map(f,tl(t))) :ΣT/rrbracket
and
/llbracketΓ⊢tl(map(g◦f,t)) :ΣT/rrbracket=/llbracketΓ⊢map(g◦f,tl(t)) :ΣT/rrbracket;
which suggests the bisimulation
R={(/llbracketΓ⊢map(g,map(f,tln(t))) :ΣT/rrbracket,/llbracketΓ⊢map(g◦f,tln(t)) :ΣT)/rrbracket|n∈N},
This bisimulation is easily veriﬁed: simply apply hdto both sides and reduce by applying the coinductive deﬁniti on of
map and we will see that we obtain two equal expressions; apply wtto both sides and reduce by applying the coinductive
deﬁnition of map, and two equal expressions will result; and ﬁnally apply tlto both sides and reduce by applying the
coinductive deﬁnition of map, and we will see that the resulting pair is also included with in this bisimulation.
3)Reweighting over reweighting.
/llbracketΓ⊢reweight (g,reweight (f,t)) :ΣT/rrbracket=/llbracketΓ⊢reweight (f·g,t) :ΣT/rrbracket
Applying tlto both sides and using the previous rule relating tlandreweight , we easily obtain
/llbracketΓ⊢tl(reweight (g,reweight (f,t))) :ΣT/rrbracket=/llbracketΓ⊢reweight (g,reweight (f,tl(t))) :ΣT/rrbracket
and
/llbracketΓ⊢tl(reweight (g·f,t)) :ΣT/rrbracket=/llbracketΓ⊢reweight (g◦f,tl(t)) :ΣT/rrbracket.
Equivalence then follows from the bisimulation
R={(/llbracketΓ⊢reweight (g,reweight (f,tlm(t))) :ΣT/rrbracket,/llbracketΓ⊢reweight (g◦f,tlm(t)) :ΣT)/rrbracket|m∈N}
which is easily veriﬁed, giving our desired equality.4)Thinning over pseudorandom number generators.
∀n∈N,/llbracketΓ⊢thin(n,prng(s,t)) :ΣT/rrbracket=/llbracketΓ⊢prng(sn,t) :ΣT/rrbracket
Applying tlto both sides of each expression and simplifying using the co inductive deﬁnitions of thin andprng , we
obtain
/llbracketΓ⊢tl(thin(n,map(s,t))) :ΣT/rrbracket=/llbracketΓ⊢thin(n,map(s,tln(t))) :ΣT/rrbracket
and
/llbracketΓ⊢tl(map(s,thin(n,t))) :ΣT/rrbracket=/llbracketΓ⊢map(s,thin(n,tln(t))) :ΣT/rrbracket.
This suggests the choice of bisimulation
R={(/llbracketΓ⊢thin(n,map(s,tlm(t))) :ΣT/rrbracket,/llbracketΓ⊢map(s,thin(n,tlm(t))) :ΣT)/rrbracket)|m∈N}
which is easily veriﬁed and gives our result.
5)Thinning over map.
/llbracketΓ⊢thin(n,map(s,t)) :ΣT/rrbracket=/llbracketΓ⊢map(s,thin(n,t)) :ΣT/rrbracket
Using the coinductive deﬁnitions of map andthin , we obtain
/llbracketΓ⊢tl(thin(n,map(s,t)) :ΣT/rrbracket=/llbracketΓ⊢thin(n,map(s,tln(t))) :ΣT/rrbracket
and
/llbracketΓ⊢tl(map(s,thin(n,t))) :ΣT/rrbracket=/llbracketΓ⊢map(s,thin(n,tln(t))) :ΣT/rrbracket.
The desired result follows from
R={(/llbracketΓ⊢thin(n,map(s,tlm(t))) :ΣT/rrbracket,/llbracketΓ⊢map(s,thin(n,tlm(t))) :ΣT/rrbracket)|m∈N}
which is easily seen to be a valid bisimulation.
Product rules :
1)Thinning.
/llbracketΓ⊢thin(n,s)⊗thin(n,t) :Σ(S×T)/rrbracket=/llbracketΓ⊢thin(n,s⊗t) :Σ(S×T)/rrbracket
Use the coinductive deﬁnition of thin to show
/llbracketΓ⊢tl(thin(n,s)⊗thin(n,t)) :Σ(S×T)/rrbracket=/llbracketΓ⊢thin(n,tln(s))⊗thin(n,tln(t)) :Σ(S×T)/rrbracket
and
/llbracketΓ⊢tl(thin(n,s⊗t)) :Σ(S×T)/rrbracket=/llbracketΓ⊢thin(n,tln(s)⊗tln(t)) :Σ(S×T)/rrbracket,
which suggests
R={(/llbracketΓ⊢thin(n,tlm(s))⊗thin(n,tlm(t)) :Σ(S×T)/rrbracket,
/llbracketΓ⊢thin(n,tlm(s⊗t)) :Σ(S×T)/rrbracket) :m∈N}
as a bisimulation.
2)Map.
/llbracketΓ⊢s⊗map(g,t′) :Σ(S×T)/rrbracket=/llbracketΓ⊢map(idS×g,s⊗t′) :Σ(S×T)/rrbracket
Applying tlto each expression yields
/llbracketΓ⊢tl(s⊗map(g,t′)) :Σ(S×T)/rrbracket=/llbracketΓ⊢tl(s)⊗map(g,tl(t′)) :Σ(S×T)/rrbracket
and
/llbracketΓ⊢tl(map(idS×g,s⊗t′)) :Σ(S×T/rrbracket=/llbracketΓ⊢map(idS×g,tl(s)⊗tl(t′)) :Σ(S×T)/rrbracket,
suggesting
R={(/llbracketΓ⊢tlm(s)⊗map(g,tlm(s′)) :Σ(S×T)/rrbracket,
/llbracketΓ⊢map(idS′×g,tlm(s),tlm(s))) :Σ(S×T)/rrbracket)|m∈N}
as a bisimulation./llbracketΓ⊢map(f,t)⊗s′:Σ(S×T)/rrbracket=/llbracketΓ⊢map(f×idT,t⊗s′) :Σ(S×T)/rrbracket
Same proof as previous.
3)Reweighting.
/llbracketΓ⊢s⊗reweight (g,t′) :Σ(S×T)/rrbracket=/llbracketΓ⊢reweight (1S·g,s⊗t′) :Σ(S×T)/rrbracket
Applying tlto both sides and simplifying using the coinductive deﬁniti on ofreweight gives
/llbracketΓ⊢tl(s⊗reweight (g,t′)) :Σ(S×T)/rrbracket=/llbracketΓ⊢tl(s)⊗reweight (g,tl(t′)) :Σ(S×T)/rrbracket
and
/llbracketΓ⊢tl(reweight (1S·g,s⊗t′)) :Σ(S×T)/rrbracket=/llbracketΓ⊢reweight (1S·g,tl(s)⊗tl(t′)) :Σ(S×T)/rrbracket.
Choosing the bisimulation
R={(/llbracketΓ⊢tlm(s)⊗reweight (g,tlm(t′)) :Σ(S×T)/rrbracket,
/llbracketΓ⊢reweight (1S·g,tlm(s)⊗tlm(t′)) :Σ(S×T)/rrbracket)|m∈N},
our result follows.
/llbracketΓ⊢reweight (f,t)⊗s′:Σ(S×T)/rrbracket=/llbracketΓ⊢reweight (f·1T,s′⊗t) :Σ(S×T)/rrbracket
Same proof as previous.
4)Pseudorandom number generators.
/llbracketΓ⊢prng(f,a)⊗prng(g,b) :Σ(S×T)/rrbracket=/llbracketΓ⊢prng(f×g,(a,b)) :Σ(S×T)/rrbracket
Using the coinductive deﬁnition of prng , we quickly obtain
/llbracketΓ⊢tl(prng(f,a)⊗prng(g,b)) :Σ(S×T)/rrbracket=/llbracketΓ⊢prng(f,f(a))⊗prng(g,g(b)) :Σ(S×T)/rrbracket
and
/llbracketΓ⊢tl(prng(f×g,(a,b))) :Σ(S×T)/rrbracket=/llbracketΓ⊢prng(f×g,(f×g)(a,b)) :Σ(S×T)/rrbracket,
suggesting the bisimulation
R={(/llbracketΓ⊢prng(f,fm(a))⊗prng(g,gm(b)) :Σ(S×T)/rrbracket,
/llbracketΓ⊢prng(f×g,(f×g)m(a,b)) :Σ(S×T)/rrbracket)|m∈N}
which gives our desired result.
Proof of Prop. IV .1.
Expanding Eq. (3), for any well-typed sampler Γ⊢s:ΣS, the nested self-product (sm)nis deﬁned as
thin(n,thin(m,s⊗tl(s)⊗···⊗tlm−1(s))⊗···⊗tln−1(thin(m,s⊗tl(s)⊗···⊗tlm−1(s)))).
Applying the rule Γ⊢tl(thin(m,t))≈thin(m,tlm(t)) :ΣTfrom Table IV on the innermost expressions, it follows that
this program is equivalent in the context Γto
thin(n,thin(m,tl0(s)⊗···⊗tlm−1(s))⊗···⊗thin(m,tlmn−m(s)⊗···⊗tlmn−1(s))).
Next, applying the rule Γ⊢thin(m,s⊗t)≈thin(m,s)⊗thin(m,t) :Σ(S×T), we see that the nested self-product is
equivalent to
thin(n,thin(m,tl0(s)⊗tl1(s)⊗···⊗tlmn−1(s))).
Applying the rule Γ⊢thin(n,thin(m,t))≈thin(mn,t) :ΣTfor composition of thin yields
thin(mn,tl0(s)⊗tl1(s)⊗···⊗tlmn−1(s)),
and the above is precisely the deﬁnition of the self-product smn.Proof of Prop. IV .3.
•Map : Applying the deﬁnition of the self-product Eq. (3), the syn taxmap(f,s)nis shorthand for the sampler
thin(n,map(f,s)⊗tl(map(f,s))⊗···⊗tln−1(map(f,s)))
In a context Γin which this sampler is well-typed, applying the rule Γ⊢tl(map(f,s))≈map(f,tl(s)) :ΣTshows that
the above sampler is equivalent to
thin(n,map(f,tl0(s))⊗···⊗map(f,tln−1(s))).
For the purposes of this proof, abbreviate the n-fold Cartesian product of a program f:S→Tasf×n:Sn→Tn.
Applying the rule Γ⊢map(f,s)⊗map(g,t)≈map(f×g,(s,t)) :Σ(S×T), this sampler can also be written in the
equivalent form
thin(n,map(f×n,tl0(s)⊗···⊗tln−1(s))).
Finally, applying the rule Γ⊢thin(n,map(f,s))≈map(f,thin(n,s)) :ΣSyields
map(f×n,thin(n,tl0(s)⊗···⊗tln−1(s))))
which is, by the deﬁnition of the self-product, our desired r esultmap(f×n,sn).
•Reweight : This proof proceeds the same as the above, but with map replaced with reweight and the Cartesian product
×replaced with the pointwise product ·; nevertheless, we will go through it. Applying the deﬁnitio n of the self-product
Eq. (3), the syntax reweight (f,s)nis shorthand for
thin(n,reweight (f,s)⊗tl(reweight (f,s))⊗···⊗tln−1(reweight (f,s)))
In a context Γin which this sampler is well-typed, applying the rule Γ⊢tl(reweight (f,s))≈reweight (f,tl(s)) :ΣT
shows that the above sampler is equivalent to
thin(n,reweight (f,tl0(s))⊗···⊗reweight (f,tln−1(s))).
For the purposes of this proof, abbreviate the n-fold pointwise product of a program f:S→Rasf·n:Sn→R. Applying
the ruleΓ⊢reweight (f,s)⊗reweight (g,t)≈reweight (f·g,(s,t)) :Σ(S×T), this sampler can also be written in
the equivalent form
thin(n,reweight (f·n,tl0(s)⊗···⊗tln−1(s))).
Finally, applying the rule Γ⊢thin(n,reweight (f,s))≈reweight (f,thin(n,s)) :ΣSyields
reweight (f·n,thin(n,tl0(s)⊗···⊗tln−1(s))))
which is, by the deﬁnition of the self-product, our desired r esultreweight (f·n,sn).
Proof of Prop. V .1.
Letg:Y→Rbe a bounded continuous function. Then g◦f:X→Ris also bounded continuous, and it follows from the
deﬁnition of weak convergence and of εthat
lim
n→∞/integraldisplay
Xg d/hatwidef◦σn= lim
n→∞/integraldisplay
Xg◦f dˆσn by deﬁnition
=/integraldisplay
Xg◦f dµ sinceεX(σ) =µ
=/integraldisplay
Xg df∗µ change of variable
Thus/hatwidef◦σn−→f∗µweakly, i.e. ε(f◦σ) =f∗(µ).
Proof of Thm. V .1.
By induction on the derivation.
(i)Built-in samplers. These axioms are true by assumption.
(ii)Equivalence. The fact that equivalent terms target the same measure is a si mple consequence of the deﬁnition of targeting
and of Thm. IV .1.(iii) Tail. The fact that the tail of a sampler σtargets the same measure as σis a simple consequence of the deﬁnition of
targeting in terms of a limit.
(iv) Pushforward. If/llbracketf/rrbracketis continuous for the standard topologies of the type system , the the rule is a direct consequence of
Prop. V .1. If /llbracketf/rrbracketis not continuous for the standard topologies of the type sys tem, then either: (a) a measure µ(γ)assigns
some mass to the boundary of an element of the partition makin g/llbracketf/rrbracketpiecewise continuous, in which case ε/llbrackets/rrbracket(γ)will
not converge to µ(γ)and the premise of the rule does not hold, or (b) no measure µ(γ)assigns any mass to the boundary
of an element of the partition making /llbracketf/rrbracketcontinuous, in which case ε/llbrackets/rrbracket(γ) =µ(γ), and the conclusion is again a
consequence of Prop. V .1.
(v)Reweight. This rule simply encodes the validity of importance samplin g. Dropping the dependency in γfor clarity of
notation, and letting ν=f·µbe the reweighted measure, the premise and side-condition o f the rule together say that
there exists α∈R+such that f=αdµ
dν, and that fis bounded on the support of µ. Sinceµis a probability distribution,
we have /integraldisplay
f dµ=α/integraldisplaydµ
dνdν=α/integraldisplay
dν=α
Moreover, since stargetsµandfis bounded continuous, we get by writing xi/definesπ1(πi(/llbrackets/rrbracket)andwi/definesπ2(πi(/llbrackets/rrbracket)that
α=/integraldisplay
f dµ= lim
N→∞1
N/summationtextN
i=1f(xi)wi/summationtextN
k=1wk(5)
Lettinggbe any bounded continuous function /llbracketS/rrbracket→Rand noting that the pointwise product g.fis bounded continuous
on the support of µandν, we have
/integraldisplay
g dν=1
α/integraldisplay
g.f dµ
=1
αlim
N→∞1
NN/summationdisplay
i=1g(xi)f(xi)wi/summationtextN
k=1wkSincestargetsµ
=/parenleftBigg
lim
N→∞1
N/summationtextN
i=1f(xi)wi/summationtextN
k=1wk/parenrightBigg−1/parenleftBigg
lim
N→∞1
N/summationtextN
i=1g(xi)f(xi)wi/summationtextN
k=1wk/parenrightBigg
By (5)
= lim
N→∞1
N/summationtextN
i=1g(xi)f(xi)wi/summationtextN
i=1f(xi)wi
/defineslim
N→∞/integraldisplay
g d/hatwiderreweight (f,s)n
In other words, reweight (f,s)targetsν.
(vi) Pseudorandom number generators. Theprng rule is just a restatement of the well-known ergodic theorem [19,
Theorem 9.6].
Proof of Prop. V .2.
The ﬁrst part of the proof follows immediately if we can show t hatS⊳Timplies that /llbracketS/rrbracketand/llbracketT/rrbracketare the same measurable
space; this will be shown by induction on the sub-typing deri vation. We start by showing that the functor Borel:Top→Meas
commutes with coproducts. This will prove the base case, the coproduct rule, and the last two rules of Fig. 4b.
LetX,Y be two topological spaces (we will use the same name for topol ogical (resp. measurable) spaces and their topologies
(resp.σ-algebras)). We use the π-λlemma to prove Borel(X+Y) =Borel(X)+Borel(Y). First note that Borel(X+Y) =
σ(X+Y)by deﬁnition. Since X+Yis a topology, it is trivially also a π-system, and since Borel(X)+Borel(Y)is aσ-algebra
it is also trivially a λ-system. By deﬁnition, every open set UinX+Yhas the property that U=X∩Uis open in X, and is
thus an element of Borel(X). Similarly Y∩Uis open in Yand thus belongs to Borel(Y). It follows that U= (U∩X)⊎(U∩Y)
belongs to Borel(X)+Borel(Y)by deﬁnition of the coproduct in Meas . The inclusion Borel(X+Y)⊆Borel(X)+Borel(Y)
now follows from the π-λlemma.
Conversely, every measurable AinBorel(X)+Borel(Y)is, by deﬁnition, of the shape (A∩X)⊎(A∩Y)with(A∩X)∈
Borel(X)and(A∩Y)∈Borel(Y). Using the π-λlemma it is easy to show that Borel(X)⊆Borel(X+Y)andBorel(Y)⊆
Borel(X+Y), and it thus follows, since Borel(X+Y)is closed under unions, that A= (A∩X)⊎(A∩Y)∈Borel(X+Y)
which proves Borel(X+Y)⊇Borel(X)+Borel(Y).
To show that the functor Borel:Top→Meas commutes with products we need the extra assumption that the spaces are
second-countable. A proof can then be found in e.g. [3, p244] .For the second part of the proof, let Ube in the topology of /llbracketS/rrbracketbut not in the topology of /llbracketT/rrbracket. This means that ∂T(U) =
U∩intT(U)/ne}ationslash=is open in /llbracketS/rrbracket(since it’s the intersection of two open sets in /llbracketS/rrbracket). In particular it is a continuity set in /llbracketS/rrbracket
(since it is open, its interior is the empty set and it can ther efore not have any µ-mass). By the Portmanteau lemma (which
applies since the spaces are assumed to be metrizable) we mus t thus have
lim
n→∞/hatwider/llbrackets/rrbracketn(∂T(U)) =µ(∂T(U))>0
In particular, this is clearly impossible if /llbrackets/rrbracketonly visits ∂T(U)ﬁnitely many times.