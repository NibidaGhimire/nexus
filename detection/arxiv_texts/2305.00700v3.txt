Double and Single Descent in Causal Inference
with an Application to High-Dimensional Synthetic Control
Jann Spiess Guido Imbens Amar Venugopal
October 12, 2023
Abstract
Motivated by a recent literature on the double-descent phenomenon in machine learning, we consider
highly over-parameterized models in causal inference, including synthetic control with many control units.
In such models, there may be so many free parameters that the model fits the training data perfectly.
We first investigate high-dimensional linear regression for imputing wage data and estimating average
treatment effects, where we find that models with many more covariates than sample size can outperform
simple ones. We then document the performance of high-dimensional synthetic control estimators with
many control units. We find that adding control units can help improve imputation performance even
beyond the point where the pre-treatment fit is perfect. We provide a unified theoretical perspective
on the performance of these high-dimensional models. Specifically, we show that more complex models
can be interpreted as model-averaging estimators over simpler ones, which we link to an improvement
in average performance. This perspective yields concrete insights into the use of synthetic control when
control units are many relative to the number of pre-treatment periods.
1 Introduction
Motivated by a recent literature on the double-decent phenomenon in machine learning, we investigate the
properties of common econometric estimators when we increase their complexity. For high-dimensional
linear regression and for synthetic control with many control units, we document empirical applications
where extremely over-parameterized models impute missing out-of-sample and out-of-time outcomes well.
We then provide a common explanation for the returns to complexity in high-dimensional linear regression
and synthetic control in terms of a simple model-averaging property, which we link to an improvement in
imputation performance.
We often conceptualize the effect of complexity on econometric models in terms of a bias–variance trade-
off: Adding complexity makes models more expressive and reduces bias, while increased overfitting leads
Jann Spiess, Graduate School of Business, Stanford University, jspiess@stanford.edu. Guido Imbens, Graduate School of
Business and Department of Economics, Stanford University, imbens@stanford.edu. Amar Venugopal, Department of Eco-
nomics, Stanford University, amar.venugopal@stanford.edu. We thank Tengyuan Liang, Sendhil Mullainathan, Ashesh Ram-
bachan, audiences at Emory University, the 2023 “Econometrics in the Era of Machine Learning” conference at the University
of Chicago, the 2023 “HDMetrics: Big Data, High-Dimensional Methods, and Machine Learning” workshop at the University of
Illinois at Urbana-Champaign, the 2023 CEME Conference for Young Econometricians at Georgetown University, and the 2023
California Econometrics Conference at the University of Washington, as well as four anonymous reviewers for helpful comments
and discussions. Replication code is available at github.com/amarvenu/causal-descent.
1arXiv:2305.00700v3  [econ.EM]  12 Oct 2023to additional variance. In this view, an overly complex model fits overly well in the training sample, but
fails to recover true parameters or generalize to new data. For example, linear regression with too many
variables or synthetic control with many control units may perform poorly because of overfitting and excess
variance. Consistency results for high-dimensional econometric models therefore usually assume that the
expressiveness of models is limited relative to the available sample size, and practical advice often highlights
choosing simple models or regularizing complex ones, in a way that balances bias and variance optimally to
achieve good estimation and prediction performance.
A recent literature in statistics and machine learning has highlighted the surprisingly good prediction per-
formance of extremely high-dimensional models that fit the data perfectly. That literature has documented a
so-called double-descent phenomenon for deep neural networks and other high-dimensional regression mod-
els: increasing complexity beyond the interpolation threshold at which the training sample error is zero
can lead to a gradual reduction in variance and improvement in out-of-sample performance. In such cases,
there are often two complexity regimes: below the interpolation threshold, the usual bias–variance trade-off
leads to a decrease (first descent) and then an increase in out-of-sample loss, while beyond the interpolation
threshold, out-of-sample loss decreases again (second descent).
In order to investigate the properties of highly over-parameterized models in causal inference, we first
demonstrate a double-descent curve for linear regression in imputing wage outcomes and estimating average-
treatment effects. In the LaLonde (1986) sample of the Current Population Survey (CPS) drawn from
Dehejia and Wahba (1999, 2002), we generate over 8,000 variables from binning and interacting the original
eight demographic and employment-related variables. We then fit a linear regression model on 3,000 training
units and an increasing, randomly chosen subset of these variables, choosing the norm-minimizing solution
once the model fits perfectly. Evaluated on the LaLonde (1986) control sample from the National Supported
Work Demonstration (NSW) experiment, we observe the usual bias–variance trade-off for a low and moderate
number of included covariates, where performance first increases slightly, before deteriorating substantially
when approaching the interpolation threshold. Beyond the interpolation threshold, however, out-of-sample
performance increases again. Ultimately, an extremely over-parameterized model on over 8,000 variables
even outperforms less complex regressions with a randomly chosen set of covariates and achieves performance
comparable to a linear regression on the original, unmanipulated set of covariates.
Having demonstrated the returns to complexity in high-dimensional linear regression, we document the
performance of synthetic control estimators with many control units. In the California smoking data (Abadie
et al., 2010), we impute missing smoking rates based on a small number of pre-treatment periods and an
increasingly large number of control states. As in the case of linear regression, we see returns to increasing
model complexity, even beyond the point where some of the synthetic-control models fit the training data
perfectly. However, for synthetic control we do not observe an initial trade-off between bias and variance:
in our empirical example, the performance on future periods is always better for the more complex models,
with no intermittent increase in errors. Unlike the double-descent relationship for linear regression, the
performance of synthetic control in our application yields a single-descent curve that only improves with
complexity, no matter whether there are a few or many control states.
We then connect the returns to complexity in high-dimensional linear regression and in synthetic control in
terms of a simple model-averaging property. While both estimators are constructed differently and represent
different regressions, they both share a common feature: More complex models can be represented as convex
2averages over simpler models. We show that this model-averaging property applies to linear regression in
the interpolation regime, as well as to synthetic control in general. The property holds purely mechanically
and does not depend on the training or target distributions. It relates to other model-agnostic properties of
linear regression, for which we also show a reduction in (conditional) variance for minimal-norm least-squares
estimators beyond the interpolation threshold.
Having established a model-averaging property for interpolation linear regression and for synthetic con-
trol, we provide high-level assumptions under which this property translates to better imputation perfor-
mance. A direct consequence of model averaging is that the (convex) prediction loss of a more complex
model cannot be worse than the corresponding average prediction loss of simpler models, when the same
weights are used to average. When the complex model on average also outperforms comparable models of
the same complexity, then we show that the model-averaging property translates into a reduction in average
out-of-sample error relative to a randomly selected simpler model. These results only put high-level, largely
model-agnostic assumptions on the data-generating process, and are driven by mechanical properties of the
underlying estimators.
Our results have practical implications for the use of synthetic control with many control units. Conven-
tional wisdom may indicate that synthetic control with a very large number of donor units relative to the
number of pre-treatment periods is problematic, and that selecting among many, ex-ante exchangeable units
in this case may represent a challenge. However, our results imply that this is not the case: as long as ties
are broken by a suitable regularization procedure (such as the minimum-norm solution in our case), making
an ex-ante choice among many control units is not necessary. That said, if ex-ante information is available
about which units are particularly suitable as controls, then using this information can still be helpful and
improve imputation.
We build upon results on over-parameterized regression in machine learning and statistics, where double-
descent curves for kernel and linear regression and the performance of norm-minimizing interpolating solu-
tions have been studied extensively (including Liang and Rakhlin, 2020; Liang et al., 2020; Liang and Recht,
2023; Bartlett et al., 2020; Hastie et al., 2022) as part of a broader literature on double descent and inter-
polation in deep learning (Zhang et al., 2016; Belkin et al., 2018; Belkin, 2021; Mei and Montanari, 2022).
Kelly et al. (2022) documents the benefits of over-parameterized models in asset return prediction both in
theory and empirically. Kato and Imaizumi (2022) provides results on the estimation of conditional average
causal effects using over-parametrized linear regression. Relative to this work on interpolating regression,
we show connections to synthetic control based on simple mechanical properties that are largely agnostic
about the true data-generating process. Thereby, we also relate to work on high-dimensional and regularized
synthetic control (Doudchenko and Imbens, 2016; Abadie and L’Hour, 2021; Ben-Michael et al., 2021) and
the connections between synthetic control and linear regression (Athey et al., 2021; Agarwal et al., 2021;
Shen et al., 2022; Bruns-Smith et al., 2023).1Finally, we connect to a literature on model averaging in
econometrics and statistics (e.g. Hansen, 2007; Claeskens and Hjort, 2008). More specifically, Wilson and
Izmailov (2020) consider Bayesian model averaging in deep learning, and discuss relationships to double
descent. While our linear-regression solutions are closely related to available results on norm-minimizing
regression, we are not aware that the results on synthetic control were noted previously.
1For example, Bruns-Smith et al. (2023) shows that synthetic-control-type balancing estimators with non-negative weights
can be related to outcome regressions, which connects our OLS setup in Section 2 to the synthetic-control setup in Section 3.
3The remaining note is structured as follows. Section 2 provides an empirical example of double descent
for linear regression and discusses some properties of the norm-minimizing linear-regression estimator in
the interpolating case. Section 3 discusses the relationship of complexity and imputation performance of
synthetic control in an empirical example, and makes connections to the properties of interpolating linear
regression. Section 4 discusses high-level consequences of the model-averaging property of interpolating linear
regression and synthetic control. Section 5 concludes by discussing some limitations and open questions.
2 Double Descent for Linear Regression
In this section, we consider imputation by high-dimensional linear regression as an illustration of the perfor-
mance of highly over-parameterized models. We start with an empirical illustration of wage imputation in
CPS data with a varying number of randomly ordered covariates, which we evaluate in terms of its ability
to estimate an average treatment effect. We then discuss theoretical properties of the interpolating linear-
regression estimator, followed by a graphical illustration. These results are closely related to prior work on
interpolating linear and kernel regression (including Bartlett et al., 2020; Liang et al., 2020; Hastie et al.,
2022; Kato and Imaizumi, 2022).
2.1 Setup and Estimator
We consider a linear-regression estimator in data ( yi, xi)n
i=1∈R×Rkfrom nobservations of a scalar outcome
andkscalar covariates. We write X= (x′
i)n
i=1∈Rn×kandY= (yi)n
i=1∈Rn. For a subset J⊆ {1, . . . , k }of
the covariates, we denote by BJ= arg minβ∈Rk;βj=0∀j /∈JPn
i=1(yi−x′
iβ)2the set of all least-squares linear-
regression estimates on J. Among these, we choose the norm-minimizing estimate ˆβJ= arg minβ∈BJ∥β∥.
Throughout, we assume that XJ= (xij)i∈{1,...,n},j∈J∈Rn×|J|is of full row rank. Hence, there are multiple
least-squares solutions, |BJ|>1, if and only if |J|> n. In that case, Y=XˆβJandˆβJis the minimal-norm
interpolating solution (cf. Liang et al., 2020).
2.2 Empirical Motivation
We impute wages in the non-experimental LaLonde (1986) sample of the Current Population Survey (CPS)
using linear regression on a large number of covariates, based on data drawn from Dehejia and Wahba
(1999, 2002). From the original eight covariates, we obtain k= 8408 explanatory variables by binning
and interacting the available features. We train minimal-norm least-squares regression models on a training
sample of n= 3000 randomly chosen observations, and evaluate their mean-squared error in imputing average
wages for subsets (of various sizes) of the 260 LaLonde (1986) National Supported Work Demonstration
(NSW) experimental controls as provided through Dehejia and Wahba (1999, 2002). To these covariates
we add a small amount of iid Gaussian noise to avoid rank deficiency when estimating linear regression.
When fitting wage imputation models, we vary the set of covariates included in the regression. Specifically,
we order all features randomly. For a complexity ℓ∈ {1, . . . , k }, we then choose the first ℓcovariates, and
obtain the estimate ˆβJforJ={1, . . . , ℓ }. Our presented results reflect an average over five such random
orderings of covariates.
4In Figure 1, we consider CPS data and plot the average root-mean-squared error (RMSE) for pointwise
prediction of the wages, reporting the in-sample performance as well. The vertical dashed line denotes the
interpolation threshold where ℓ=n.
0 2000 4000 6000 8000
Number of Covariates01020304050RMSE (thousands $)Out-of-sample
In-sample
Figure 1: Average out-of-sample (blue) and in-sample (orange) RMSE on non-experimental CPS controls.
In order to assess the viability of this approach for applications to average treatment effect (ATE)
estimation, we assess each model by its ability to accurately predict the average outcome on a new dataset.
In particular, we consider various subsets of size mof the NSW experimental control set. For each m, we
draw 1000 samples of size mwithout replacement from the NSW experimental control dataset. For each
sample, we average the mobservation-level outcome predictions and compare the result to the true mean
outcome of the given sample. We then take the RMSE across the 1000 draws of size mto obtain our
evaluation metric.2
Figure 2 shows this RMSE metric, once again averaged over five random orderings of the covariates,
for various subset sizes. The horizontal dashed lines show the RMSE of a simple linear regression on
the original, unmanipulated (low-dimensional) features, colored according to corresponding sample size m.
Figure 2a shows these results across the entire range of tested covariate dimensionalities ℓ, while Figure 2b
zooms in on the same, showing only dimensionalities ℓ >5000.
The out-of-sample losses in these illustrations show a descent in loss right of the interpolation threshold
(denoted by the vertical dashed line), at which point in-sample loss is zero. For NSW experimental controls,
out-of-sample error initially decreases (first descent), while for CPS non-experimental controls it remains
initially flat. For both out-of-sample datasets, loss then goes on to increase and peaks sharply at ℓ=n,
at which point the linear models start to fit perfectly. As complexity increases further, loss decreases again
(second descent). In both cases, loss continues to decrease throughout. For NSW experimental controls, loss
ultimately reaches a minimum that is below the lowest error achieved left of the interpolation threshold, while
the loss achieved in the CPS case is similar between the right tails and the minimum on the left. Furthermore,
2Form= 1, taking 1000 draws would necessarily yield duplication; in this case, we instead simply consider the full set of
260 NSW experimental control observations. Note that results for m= 1 therefore correspond to a standard (observation-level)
RMSE calculation, analogous to the out-of-sample curve in Figure 1.
50 2000 4000 6000 8000
Number of covariates051015202530ATE RMSE (thousands $)m = 1
m = 5
m = 50
m = 100(a) Full covariate range
5000 5500 6000 6500 7000 7500 8000 8500
Number of covariates012345ATE RMSE (thousands $)m = 5
m = 50
m = 100
(b) Highly over-parameterized regime
Figure 2: Average RMSE for linear regression for a varying number of covariates.
as the sample size mincreases in Figure 2, the highly complex interpolating models outperform a simple
model based on the original set of provided features; the m= 50 and m= 100 curves have minima below
their corresponding dashed lines.
In this setting, highly over-parameterized linear models constructed via discretizing and interacting avail-
able features exhibit performance improvements over a linear model fitted on the original features. This
result appears remarkable, since the heavily over-parameterized models do not include the original non-
binary covariates, but only indicators obtained from quantile binning (see Section B.1 for details). Further
improvement could be achieved by always including the original covariates in the model.
As a further illustration, Figure 3 shows the average norm of the model coefficients across different model
complexities. Starting small, model coefficients initially grow (in terms of their Euclidean norm), reaching
6their peak at the interpolation threshold. To the right of the interpolation threshold, the norm of the model
coefficients decreases mechanically, since the estimator now minimizes the norm among all interpolating
solutions with fewer and fewer sparsity constraints.
0 2000 4000 6000 8000
Number of covariates025050075010001250150017502000Coefficient norm
Figure 3: Average of the coefficient norm ∥ˆβJ∥for varying size of the set Jof covariates.
We note that our illustration is extreme in that it artificially creates a large number of low-signal covari-
ates, for which the best model only slightly outperforms a small, hand-curated model based on the original
covariates. Nevertheless, this simple empirical exercise demonstrates the non-monotonicity in the relation-
ship of complexity to variance and loss that has been studied by the literature on interpolating regression
and double descent, and extends it to causal target parameters like the average treatment effect.
2.3 Theoretical Properties and Geometric Illustration
Motivated by the empirical illustration, we note some theoretical properties that are direct consequences
of the structure of the norm-minimizing linear least-squares estimator, and will later serve as a comparison
point for synthetic control. We note that formal results on the bias–variance properties in terms of more
primitive properties of the data-generating process are available, including in Bartlett et al. (2020); Liang
et al. (2020); Hastie et al. (2022). Here, we focus on illustrating properties that follow mechanically from the
construction of the estimator. Our focus is on comparing more complex models, with covariates J, to slightly
simpler (more sparse) ones, with covariates J\ {j}, where the j-th covariate is dropped. Throughout, we
assume that the covariate matrices are of full row rank for the more and less complex models
Assumption 1 (Full rank) .The covariate matrix XJ∈Rn×|J|with columns Jas well as the covariate
matrices XJ\{j}∈Rn×(|J|−1)for all j∈Jare of full row rank.
We first consider the geometry of interpolating solutions, for which we note that more complex model
can be expressed by an average over simpler models.
Proposition 1 (Model averaging for interpolating linear least-squares regression) .For every XandJwith
7|J|> nsuch that Assumption 1 holds there exists
λ∈[0,1]J,X
j∈Jλj= 1 such that ˆβJ=X
j∈JλjˆβJ\{j}.
We can choose the weights in Proposition 1 as a function of the covariate matrix XJonly. Specifically,
weights can be chosen as λj=1−X′
j(XJX′
J)−1Xj
|J|−n, where Xjis the j-th column of XandX′
j(XJX′
J)−1Xj
can be seen as the “leverage” of feature j∈J, analogously to the leverage of an observation in the usual
(low-dimensional) linear regression case.3
β1β2
ˆβ{1,2}
ˆβ{2}
ˆβ{1}
(a) Non-interpolating case with n= 2.β1β2
ˆβ{2}
ˆβ{1}ˆβ{1,2}
(b) Interpolating case with n= 1.
Figure 4: Minimal-norm least-squares solutions for linear regression with J={1,2}, where nvaries.
The model averaging property of interpolating linear regression is illustrated in the right panel of Figure 4
for the simple case of two covariates ( J={1,2}) and a single data point ( n= 1). Here, the models β∈RJ
that for the model perfectly lie on the line through ˆβ{1}andˆβ{2}, with the norm-minimizing solution ˆβ{1,2}
lies between the two. In contrast, if ˆβ{1}andˆβ{2}are not interpolating (such as in the case of the left panel
of Figure 4, where n= 2), then the more complex model ˆβ{1,2}does not generally lie in the convex hull of
the simpler ones.
As an immediate consequence, any interpolating model can in this case be expressed as a convex average
of simpler interpolating models, ˆβJ=P
L⊆J;|L|=ℓλjˆβLfor all ℓ∈ {n, . . . , |J|}(provided all XLare of full
row rank). A particularly interesting special case is ℓ=n, for which we express ˆβJas a model average of
just-interpolating models ˆβLwith ˆβL
L=X−1
LY.
In addition to the model-averaging property, the geometry of interpolating solutions also implies that
the variance of the norm-minimizing linear least-squares estimator generically decreases in the interpolation
regime |J|> n, for which the complex estimator ˆβJalong with the simpler estimator ˆβJ\{j}both fit the
training data perfectly.
Proposition 2 (Variance reduction for linear least-squares regression) .Suppose Assumption 1 and that Y
has a second moment. If |J|> nthen a.s. tr Var( ˆβJ|X)≤minj∈Jtr Var( ˆβJ\{j}|X).
The reduction in variance is a direct consequence of a more general property of the least-squares solution.
Specifically, the next proposition shows that if we redraw new outcome data in the interpolation regime,
then the distance between more complex solutions is smaller than the distance between less complex models.
3We thank Tengyuan Liang for pointing out this connection to us, as well as for suggesting a direct proof via the Sherman–
Morrison–Woodbury formula.
8Proposition 3 (Variation hierarchy for linear least-squares regression) .For fixed XandJfor which As-
sumption 1 holds consider two draws YAandYByielding minimal-norm least-squares estimates ˆβJ
A,ˆβJ\{j}
A
andˆβJ
B,ˆβJ\{j}
B , respectively.
1. If|J| ≤n, then ∥ˆβJ
A−ˆβJ
B∥X′X≥max j∈J∥ˆβJ\{j}
A−ˆβJ\{j}
B∥X′X.
2. If|J|> n, then ∥ˆβJ
A−ˆβJ
B∥ ≤minj∈J∥ˆβJ\{j}
A−ˆβJ\{j}
B∥.
Here, we write ∥β∥M=√β′Mβfor some positive semi-definite symmetric matrix M∈Rk×k.
In words, the variation of models across draws of the outcome data increases with complexity on the left
of the interpolation threshold, while it decreases on the right. Here, the choice of norm is essential for these
results to hold uniformly across simpler models.4
Figure 5 depicts this graphically. In Figure 5a, for the non-interpolating case we observe that the norm
of the difference between the model coefficient vectors making use of both covariates ( ˆβ{1,2},˜β{1,2}) is larger
than the norm of the differences between the coefficient vectors taking into consideration just a single
covariate at a time. In Figure 5b for the interpolating case, we observe that the reverse is true; in this case,
the norm of the difference between the complex models is smaller than the norms of the differences between
the simpler models.
β1β2
ˆβ{1,2}
ˆβ{2}
ˆβ{1}˜β{1,2}
˜β{2}˜β{1}
(a) Non-interpolating case with n= 2.β1β2
ˆβ{1,2}
ˆβ{2}
ˆβ{1}˜β{2}
˜β{1}˜β{1,2}
(b) Interpolating case with n= 1.
Figure 5: Minimal-norm least-squares solutions for draws YA(black) and YB(orange) for linear regression
with J={1,2}, where nvaries
In practice, we may care about model properties beyond variance, and consider imputation loss beyond
the above norms in the parameters. In Section 4, we will leverage the model-averaging properties from
Proposition 1 to establish such bounds on more general imputation errors.
We believe that these variance and geometric properties of linear regression are well understood in the
literature and likely not new, although we are not aware of an explicit statement of the model-averaging
connection between more and less complex interpolating linear-regression models.
3 Single Descent for Synthetic Control
We next consider imputation using synthetic control with many control units. As in the case of linear
regression, we start with an empirical illustration. In the Abadie et al. (2010) California smoking dataset,
4The second result still holds for an alternative norm ∥β∥M=√β′Mβwith Mpositive definite and symmetric, provided
that the same norm is used when selecting the norm-minimizing estimator in the interpolation regime.
9we impute smoking rates for a target state for a varying number of control states. We then discuss theoretical
properties of the synthetic control estimator, which we connect to its imputation quality in the following
Section 4.
3.1 Setup and Estimator
We consider a panel of N+ 1 units observed over Ttime periods, Y= (yit)i∈{0,...,N},t∈{1,...,T}∈R(N+1)×T,
where i= 0 denotes the target unit. Our goal is to impute y0tfort∈ {T+ 1, . . . , T +S}given yitfor
i∈ {1, . . . , N }, t∈ {T+ 1, . . . , T +S}by the synthetic-control estimator ˆ y0t=PN
i=1ˆwiyitwith convex
weights ˆ w∈ W ={w∈[0,1]N;Pn
i=1wi= 1}. Specifically, for a subset J⊆ {1, . . . , N }of control units, we
consider the synthetic control weights
ˆwJ= arg min
w∈cWJ∥w∥ cWJ= arg min
w∈W;wj=0∀j /∈JTX
t=1(y0t−NX
i=1wiyit)2. (1)
Here, we choose the (unique) norm-minimizing synthetic control weights whenever there is more than one
empirical risk minimizer. We can also interpret this solution as the limit ˆ wJof a ridge penalized synthetic
control estimator ˆ wJ
η,
ˆwJ= lim
η→0ˆwJ
η ˆwJ
η= arg min
w∈W;wj=0∀j /∈JTX
t=1 
y0t−NX
i=1wiyit!2
+η∥w∥2, (2)
where ˆ wJ
ηputs a penalty on the Euclidean norm ∥w∥2of the weights, multiplied by a factor η >0. This
form of the penalized synthetic-control estimator is also considered by Shen et al. (2022).
We note that, unlike in the linear-regression case, we can now end up with non-interpolating solutions
even in the case of high model complexity (many control units). The reason is that the convexity restriction
ˆw∈ W allows for interpolation only if the target outcomes are in the convex hull of the control outcomes.
3.2 Empirical Motivation
To illustrate some properties of the synthetic control estimator, we impute California smoking rates in the
Abadie et al. (2010) dataset. In that dataset, California experiences the introduction of smoking legislation
in 1989, for which Abadie et al. (2010) provides a causal effect estimate by imputing counterfactual smoking
rates for those years when the legislation is in effect. We instead consider only the time before the legislation
is introduced, giving us access to observed control outcomes in all years, even for California. Specifically, we
fit synthetic control models for California on T= 3 years of data (1984–1986), and evaluate their imputation
performance on the following S= 2 years (1987–1988) in terms of mean-squared error.
When fitting synthetic control models, we vary how many of the N= 20 control states we include in the
estimation process. Specifically, for a given complexity ℓ∈ {1, . . . , N }, we average out-of-time root-mean
squared error (RMSE) across all N
ℓ
combinations of control states. We report results in Figure 6.
Unlike the linear-regression case, the loss in the synthetic-control case changes monotonically: as we
increase the number of control units, average RMSE decreases. We therefore observe a single-descent curve
100 5 10 15 20
Number of control states05101520RMSE (daily cigarette packs)Out-of-time
TrainingFigure 6: Average out-of-time (blue) and training (orange) RMSE for synthetic control for a varying number
of control units.
in the relationship of complexity and loss, with no notable change in regimes when the number of control
states surpasses the number T= 3 of training periods.
As before, our illustration is extreme: by using only three training periods and a random selection of
control states, we can provide a stark illustration of the difference in behavior between the synthetic control
and linear-regression estimators.
3.3 Theoretical Properties and Graphical Illustration
While linear regression and synthetic control behave differently in terms of their double- vs single-descent
behavior, we note that both exhibit continuing returns to increasing complexity, with no limit. In our
empirical illustration, that return to complexity kicks in in the interpolation regime for linear regression
and throughout for synthetic control. We now connect this commonality in returns to complexity to a
corresponding theoretical connection.
Proposition 4 (Model averaging for synthetic control) .For all Jwith|J|>1and data Ythere exists
ˆλ∈[0,1]J,X
j∈Jˆλj= 1 such that ˆwJ=X
j∈JˆλjˆwJ\{j}.
Hence, synthetic control has the same model-averaging property as interpolating linear regression (Propo-
sition 1). Now, however, the model-averaging property also holds without interpolation, and is instead driven
by the convexity of synthetic control weights. Furthermore, the weights can depend on outcome data, al-
though only for pre-treatment outcomes. We further note that the result extends to penalized synthetic
control with some fixed penalty parameter η.
We illustrate the model-averaging property for synthetic control in Figure 7, where we show that synthetic
California with |J|= 2 (left) and |J|= 3 (right) control states is a convex combination of synthetic California
with fewer control states. Here, we focus on the fit in the training data, and do not explicitly show the
11underlying synthetic-control weights. We note that Figure 7 covers both cases where the synthetic estimator
for California has perfect training fit (right) and cases where it does not (left).
MAIL
yi1yi2
CAˆy{MA,IL}
CAˆy{MA}
CAˆy{IL}
CA
(a) Non-interpolating case, |J|= 2.MAIL
NJ
yi1yi2
CAˆy{MA,IL}
CA
ˆy{IL,NJ}
CAˆy{NJ,MA}
CA
ˆy{MA,IL,NJ}
CA
(b) Interpolating case, |J|= 3.
Figure 7: Synthetic-control examples for T= 2, where the set Jof included units varies.
Unlike in the case of linear regression (Proposition 3) we do not, however, obtain an immediate bound
on the variation of synthetic control models. Indeed, as the case of |J|= 2 controls in Figure 7 clarifies,
the complex model can have more variance in weights than the simple ones (which here do not vary at all),
despite the model-averaging property. In the next section, we will therefore connect model averaging directly
to improvements of imputation quality, without relying on explicit variation results.
4 Model-Averaging Based Risk Bounds
Above, we argued that more complex models are model averages over simpler models in two cases that are
relevant to causal inference: interpolating linear regression and synthetic control. In this section, we discuss
conditions under which model averaging leads to better imputation quality.
To unify the above cases, we now consider generic estimated functions ˆf∗:X →Rthat can be related
to simpler models ˆfj:X →Rfor an index set j∈Jby the model-averaging property
ˆf∗=X
j∈Jˆλjˆfjfor some ˆλ∈[0,1]J,X
j∈Jˆλj= 1. (MA)
We see this model-averaging property as a purely mechanical property of estimators, which we applies to
interpolating linear regression (Proposition 1) and to synthetic control (Proposition 4) by our results above
Model averaging provides some insurance against excess loss. Intuitively, being able to represent a more
complex model ˆf∗in terms of a model average over simpler models diversifies the risk of a bad imputation
fit. When considering convex loss functions, we can make this intuition precise via a simple application of
Jensen’s inequality, which yields for the case of squared error that
(y−ˆf∗(x))2≤X
j∈Jˆλj(y−ˆfj(x))2. (3)
for any target point ( y, x)∈R× X. Hence, imputation loss using the complex model is at most a weighted
12average over the loss of simpler models. The relationship also extends directly to estimating averages of
outcomes yby averages of predictions ˆf(x), as in the case of average treatment effects in Section 2.
In principle, the simple portfolio bound in (3) leaves open the possibility that the more complex model
ˆf∗performs as poorly as the worst of the simpler models ˆfj. However, for this to occur, the weights would
have to be positively correlated with badperformance. A condition on imputation quality we can therefore
consider imposing is that the selection of weights is not, on average, working against imputation quality.
The following result formalizes this idea on a (very) high level.
Proposition 5 (Model-agnostic risk bound) .Assume that (MA) holds and that for some distribution over
training and target data we have that for all permutations π:J→J
E[(y−ˆf∗(x))2]≤E[(y−ˆf∗
π(x))2] where ˆf∗
π=X
j∈Jˆλπ(j)ˆfj. (P)
Then we obtain the bound E[(y−ˆf∗(x))2]≤1
|J|P
j∈JE[(y−ˆfj(x))2].
In words, if the model chosen by the data on average over some distribution is not worse than a model
where we mix up weights, then the imputation performance of the complex model is not worse than the
average of the imputation performances of simple models, leading to observations like those in Figures 2 and
6 where increased model complexity leads to improved imputation quality for randomly-ordered models.
We make two comments on the formal conditions of the proposition. First, it is enough to assume that
(P) holds on average over permutations chosen uniformly at random. Second, the distribution behind the
expectation E can incorporate prior distributions over underlying parameters, in which case the resulting
bound holds on average over the same distribution.
In the examples of linear regression and synthetic control, Figure 8 illustrates the respective permuted
models. In those cases, the permutation assumption (P) assumes that, on average, the model chosen by the
data is not worse than a model where we mix up the weights (in gray).
β1β2
ˆβ{2}
ˆβ{1}ˆβ{1,2}
ˆβ{1,2}
π
(a) Interpolating linear regressionMAIL
yi1yi2
CAˆy{MA,IL}
CAˆy{MA,IL}
π,CA
ˆy{MA}
CAˆy{IL}
CA
(b) Synthetic control
Figure 8: Illustration of permutation bound based on the examples from Figures 4 and 7.
While more primitive conditions may be helpful to judge when a condition like (P) holds, we note
two attractive properties. First, the assumption complements the model-averaging property (MA) in an
important way: While model averaging relates more complex to less complex models, the permutation
property only compares models of comparable complexity (assuming that there are no systematic ex-ante
13differences between the ˆfj). To violate this property would thus amount to assuming that selection among
models with comparable complexity is disadvantageous, which may be unreasonable to expect on average.
Second, we can formulate this condition on the level of estimators, without explicit reference to the underlying
data-generating process.
5 Conclusion
We study the imputation performance of interpolating linear regression and synthetic control, and provide a
unified perspective on returns to complexity in both cases: More complex models can be expressed as model
averages over simpler ones. While we provide some high-level assumptions on when this model-averaging
property improves average imputation risk, more work is needed to establish primitive sufficient conditions.
This includes, in particular, studying how the bias changes as models become more complex. In addition, we
limit our analysis to comparing more complex to simpler models when features or control units are randomly
ordered, but in practice, we may have knowledge about which simple models are more plausible than others.
However, our results show that highly over-parameterized models that achieve perfect in-sample fit can yield
measurable performance improvements over non-random simple models in causal settings. Future research
could explore conditions under which this phenomenon holds, namely where complex models can beat non-
random simple ones.
References
Abadie, Alberto, Alexis Diamond, and Jens Hainmueller (2010). Synthetic control methods for comparative
case studies: Estimating the effect of california’s tobacco control program. Journal of the American
statistical Association , 105(490):493–505. (Cited on pages 2, 9, 10, and 22.)
Abadie, Alberto and J´ er´ emy L’Hour (2021). A penalized synthetic control estimator for disaggregated data.
Journal of the American Statistical Association , 116(536):1817–1834. (Cited on page 3.)
Agarwal, Anish, Munther Dahleh, Devavrat Shah, and Dennis Shen (2021). Causal matrix completion. arXiv
preprint arXiv:2109.15154 .(Cited on page 3.)
Athey, Susan, Mohsen Bayati, Nikolay Doudchenko, Guido Imbens, and Khashayar Khosravi (2021). Ma-
trix completion methods for causal panel data models. Journal of the American Statistical Association ,
116(536):1716–1730. (Cited on page 3.)
Bartlett, Peter L, Philip M Long, G´ abor Lugosi, and Alexander Tsigler (2020). Benign overfitting in linear re-
gression. Proceedings of the National Academy of Sciences of the United States of America , 117(48):30063–
30070. (Cited on pages 3, 4, and 7.)
Belkin, Mikhail (2021). Fit without fear: remarkable mathematical phenomena of deep learning through the
prism of interpolation. Acta Numerica , 30:203–248. (Cited on page 3.)
Belkin, Mikhail, Siyuan Ma, and Soumik Mandal (2018). To understand deep learning we need to understand
kernel learning. In International Conference on Machine Learning , pages 541–549. PMLR. (Cited on page 3.)
14Ben-Michael, Eli, Avi Feller, and Jesse Rothstein (2021). The augmented synthetic control method. Journal
of the American Statistical Association , 116(536):1789–1803. (Cited on page 3.)
Bruns-Smith, David, Oliver Dukes, Avi Feller, and Elizabeth L Ogburn (2023). Augmented balancing weights
as undersmoothed regressions. (Cited on page 3.)
Claeskens, Gerda and Nils Lid Hjort (2008). Model selection and model averaging .(Cited on page 3.)
Dehejia, Rajeev H and Sadek Wahba (1999). Causal effects in nonexperimental studies: Reevaluating the
evaluation of training programs. Journal of the American statistical Association , 94(448):1053–1062. (Cited
on pages 2, 4, and 20.)
Dehejia, Rajeev H and Sadek Wahba (2002). Propensity score-matching methods for nonexperimental causal
studies. Review of Economics and statistics , 84(1):151–161. (Cited on pages 2, 4, and 20.)
Doudchenko, Nikolay and Guido W Imbens (2016). Balancing, regression, difference-in-differences and syn-
thetic control methods: A synthesis. Technical report, National Bureau of Economic Research. (Cited on
page 3.)
Hansen, Bruce E (2007). Least squares model averaging. Econometrica , 75(4):1175–1189. (Cited on page 3.)
Hastie, Trevor, Andrea Montanari, Saharon Rosset, and Ryan J Tibshirani (2022). Surprises in high-
dimensional ridgeless least squares interpolation. The Annals of Statistics , 50(2):949–986. (Cited on pages 3,
4, and 7.)
Kato, Masahiro and Masaaki Imaizumi (2022). Benign-overfitting in conditional average treatment effect
prediction with linear regression. arXiv preprint arXiv:2202.05245 .(Cited on pages 3 and 4.)
Kelly, Bryan T, Semyon Malamud, and Kangying Zhou (2022). The virtue of complexity in return prediction.
Technical report, National Bureau of Economic Research. (Cited on page 3.)
LaLonde, Robert J (1986). Evaluating the econometric evaluations of training programs with experimental
data. The American economic review , pages 604–620. (Cited on pages 2, 4, and 20.)
Liang, Tengyuan and Alexander Rakhlin (2020). Just interpolate: Kernel “Ridgeless” regression can gener-
alize. The Annals of Statistics , 48(3):1329–1347. (Cited on page 3.)
Liang, Tengyuan, Alexander Rakhlin, and Xiyu Zhai (2020). On the Multiple Descent of Minimum-Norm
Interpolants and Restricted Lower Isometry of Kernels. In Abernethy, Jacob and Shivani Agarwal, edi-
tors, Proceedings of Thirty Third Conference on Learning Theory , volume 125 of Proceedings of Machine
Learning Research , pages 2683–2711. PMLR. (Cited on pages 3, 4, and 7.)
Liang, Tengyuan and Benjamin Recht (2023). Interpolating Classifiers Make Few Mistakes. Journal of
machine learning research: JMLR .(Cited on page 3.)
Mei, Song and Andrea Montanari (2022). The generalization error of random features regression: Precise
asymptotics and the double descent curve. Communications on Pure and Applied Mathematics , 75(4):667–
766. (Cited on page 3.)
15Shen, Dennis, Peng Ding, Jasjeet Sekhon, and Bin Yu (2022). Same Root Different Leaves: Time Series and
Cross-Sectional Methods in Panel Data. (Cited on pages 3 and 10.)
Wilson, Andrew G and Pavel Izmailov (2020). Bayesian deep learning and a probabilistic perspective of
generalization. Advances in neural information processing systems , 33:4697–4708. (Cited on page 3.)
Zhang, Chiyuan, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals (2016). Understanding
deep learning requires rethinking generalization. (Cited on page 3.)
16A Proofs
Proof of Proposition 1. We provide a direct proof for the choice λj=1−X′
j(XJX′
J)−1Xj
|J|−nvia the Sherman–
Morrison–Woodbury formula. We first note that, for k≥n,A∈Rn×kof full row rank n,a∈Rn, and
ˆα= arg minα∈Rk;Aα=a∥α∥we have that ˆ α=A′(AA′)−1a.Indeed, Aˆα=a, and for any α∈Rkwith Aα=a
andα̸= ˆα, for Π = A′(AA′)−1Awe have that
∥α∥2=∥Πα∥2+∥(I−Π)α∥2=∥Πˆα∥2+∥(I−Π)(α−ˆα)∥2=∥ˆα∥2+∥α−ˆα∥2>∥ˆα∥2.
We next write XJ∈Rn×kfor the matrix with columns XJ
j=Xjforj∈JandXJ
j=0forj /∈J. Applying
the above result to ˆβJandˆβJ\{j}for all j∈J, we find
ˆβJ=XJ′(XJX′
J)−1Y, ˆβJ\{j}=XJ\{j}′(XJ\{j}X′
J\{j})−1Y.
Using that XJ\{j}X′
J\{j}=XJX′
J−XjX′
j, which is invertible by the assumption that XJ\{j}is of full row
rank, we find by the Sherman–Morrison–Woodbury that
(XJ\{j}XJ\{j})−1= (XJX′
J)−1+ (XJX′
J)−1Xj(1−X′
j(XJX′
J)−1Xj)−1X′
j(XJX′
J)−1(4)
with X′
j(XJX′
J)−1Xj̸= 1. Plugging in,
ˆβJ\{j}= (XJ−X{j})′(XJ\{j}XJ\{j})−1Y
=ˆβJ−X{j}′(XJX′
J)−1Y−X{j}′(XJX′
J)−1YX′
j(XJX′
j)−1Xj
1−X′
j(XJX′
j)−1Xj
+XJ′(XJX′
J)−1XjX′
j(XJX′
J)−1Y1
1−X′
j(XJX′
j)−1Xj
=ˆβJ+
XJ′(XJX′
J)−1XjX′
j(XJX′
J)−1−X{j}′(XJX′
J)−1
Y1
1−X′
j(XJX′
j)−1Xj.
SinceP
j∈JXjX′
j=XJX′
JandP
j∈JX{j}=XJ, we have that
X
j∈JˆβJ\{j}λj=ˆβJX
j∈Jλj+ (|J| −n)(XJ′(XJX′
J)−1XJX′
J(XJX′
J)−1Y−XJ′(XJX′
J)−1Y) =ˆβJX
j∈Jλj.
Finally, X′
j(XJX′
J)−1Xj≥0 since XJX′
Jpositive definite, X′
j(XJX′
J)−1Xj≤1 since XJ\{j}X′
J\{j}=
XJX′
J−XjX′
j⪯XJX′
Jin (4), andP
j∈JX′
j(XJX′
J)−1Xj= trP
j∈JXjX′
jXJX′
J
=n, soλj∈[0,1] for
allj∈JandPJ
j=1λj= 1.
Proof of Proposition 2. The result follows from Proposition 3 by noting that, for two indpendent draws YA
andYBfor fixed X, we have that
E[∥ˆβJ
A−ˆβJ
B∥2|X] = E[∥(ˆβJ
A−E[ˆβJ|X])−(ˆβJ
B−E[ˆβJ|X])∥2|X]
= E[∥ˆβJ
A−E[ˆβJ|X]∥2|X] + E[∥ˆβJ
B−E[ˆβJ|X]∥2|X] = 2 tr Var( ˆβJ|X)
17(and the same for J\ {j}), and thus
tr Var( ˆβJ|X) =1
2E[∥ˆβJ
A−ˆβJ
B∥2|X]≤1
2E
min
j∈J∥ˆβJ\{j}
A−ˆβJ\{j}
B∥2X
≤min
j1
2E[∥ˆβJ\{j}
A−ˆβJ\{j}
B∥2|X] = tr Var( ˆβJ\{j}|X).
Proof of Proposition 3. Consider first the case |J| ≤n. Under Assumption 1, we define the projection
matrices
ΠJ=XJ(X′
JXJ)−1X′
J∈Rn×n, ΠJ\{j}=XJ\{j}(X′
J\{j}XJ\{j})−1X′
J\{j}∈Rn×n.
Since ΠJ\{j}= ΠJ\{j}ΠJ, we have that XˆβJ\{j}= ΠJ\{j}Y= ΠJ\{j}ΠJY= ΠJ\{j}ˆβJ. Therefore,
∥ˆβJ
A−ˆβJ
B∥2
X′X=∥XˆβJ
A−XˆβJ
B∥2=∥ΠJ\{j}(XˆβJ
A−XˆβJ
B)∥2+∥(I−ΠJ\{j})(XˆβJ
A−XˆβJ
B)∥2
≥ ∥ΠJ\{j}(XˆβJ
A−XˆβJ
B)∥2=∥XˆβJ\{j}
A−XˆβJ\{j}
B∥2=∥ˆβJ\{j}
A−ˆβJ\{j}
B∥2
X′X.
Consider now the case |J|> n. Using the notation from the proof of Proposition 1, under Assumption 1
we have that XJˆβJ=XˆβJ=Y=XˆβJ\{j}=XJˆβJ\{j}and thus Π ˆβJ= ΠˆβJ\{j}(as well as ( I−Π)ˆβJ=0)
for the projection matrix Π = XJ′(XJX′
J)−1XJ∈Rk×k. As a consequence,
∥ˆβJ
A−ˆβJ
B∥2=∥Π(ˆβJ
A−ˆβJ
B)∥2+∥(I−Π)(ˆβJ
A−ˆβJ
B)∥2=∥Π(ˆβJ\{j}
A−ˆβJ\{j}
B )∥2
≤ ∥Π(ˆβJ\{j}
A−ˆβJ\{j}
B )∥2+∥(I−Π)(ˆβJ\{j}
A−ˆβJ\{j}
B )∥2=∥ˆβJ\{j}
A−ˆβJ\{j}
B∥2.
Proof of Proposition 4. Building upon the notation from Section 3.1, for J⊂ {1, . . . , N }write WJ=
{w∈ W ;wj= 0 for all j /∈J}(where W={w∈[0,1]N;PN
i=1wi= 1}is the N−1-simplex) and let
∂WJ=S
j∈JWJ\{j}⊆ WJbe the boundary of WJ. For outcomes, it will also be convenient to write
X= (yit)t∈{1,...,T},i∈{1,...,N}∈RT×Nfor the pre-treatment outcomes of the control units (with columns
representing units), and y= (y0t)t∈{1,...,T}∈RTfor the pre-treatment outcomes of the treated unit.
As the first step , we note that we can express the quality of synthetic control weights w∈ WJas
∥Xw−y∥2=∥Xw−yJ∥2+∥yJ−y∥2(5)
in terms of the fitted values yJ=XwJfor the solution wJto a relaxed problem that drops the non-
negativity constraint. That solution with weights in W∗={w∈RN;Pn
i=1wi= 1}is defined, analogously
to the synthetic-control solution in (1), as
wJ= arg min
w∈WJ∥w∥ ∈ W∗, WJ= arg min
w∈W∗;wj=0∀j /∈J∥Xw−y∥ ⊆ W∗.
For this solution, we note that ∥Xw−y∥2=∥X(w−wJ)∥2+2(w−wJ)′X′(XwJ−y)+∥XwJ−y∥2. Assume
now that ( w−wJ)′X′(XwJ−y)̸= 0. Then there is some ε̸= 0 such that wJ(ε) =wJ−(w−wJ)ε∈ W∗
with wj= 0 for j /∈Jfulfills ∥XwJ(ε)−y∥<∥XwJ−y∥, contradicting the choice of wJ. Hence we must
have that ∥Xw−y∥2=∥X(w−wJ)∥2+∥XwJ−y∥2=∥Xw−yJ∥2+∥yJ−y∥2, which establishes (5).
18As the second step , we note that we can therefore define the synthetic control solution in (1) in terms of
the fitted values yJof the relaxed solution as
ˆwJ= arg min
w∈cWJ∥w∥ ∈ WJ, cWJ= arg min
w∈WJ∥Xw−yJ∥ ⊆ WJ.
This follows immediately from (5) since ∥yJ−y∥is not affected by the choice of w∈ WJ. Similarly, for the
constrained solutions with index set J\ {j}forj∈J, we have that
ˆwJ\{j}= arg min
w∈cWJ\{j}∥w∥ ∈ WJ\{j}, cWJ\{j}= arg min
w∈WJ\{j}∥Xw−yJ∥ ⊆ WJ\{j}
sinceWJ\{j}⊆ WJfor all j∈J.
As the third (and central) step , we use Farkas’ lemma to argue that there exist λ∈RJwith λj≥0 for
allj∈Jsuch that XwJ=P
j∈JλjXwJ\{j}.
Assume first that XˆwJ̸=yJ. Then we must have that ˆ wJ∈∂WJ. Indeed, if ˆ wJ∈ WJ\∂WJthen there
exists some ε >0 such that ˆ wJ(ε) = ˆwJ(1−ε)+wJε∈ WJ, for which ∥XˆwJ(ε)−yJ∥=∥X( ˆwJ(ε)−wJ)∥=
(1−ε)∥X( ˆwJ−wJ)∥<∥XˆwJ−yJ∥, contradicting the choice of cWJand ˆwJ. Hence ˆ wJ∈∂WJ, so there is
some jwith ˆ wJ∈ WJ\{j}, which implies that ˆ wJ\{j}= ˆwJandXˆwJ=XˆwJ\{j}. This means that we can
choose λas the indicator for component j.
Assume now that XˆwJ=yJ, and that there exists no such λ. Then, by Farkas’ lemma, there exists
v∈RT\ {0}such that v′XˆwJ<0 and v′XˆwJ\{j}≥0 for all j∈J. Define the projection matrix
Π =vv′
v′v∈RT×T, and let W∗= arg minw∈WJ;ΠX(w−ˆwJ)=X(w−ˆwJ)v′Xw⊆ WJ. Then the minimum is
attained at a boundary point w∗∈ W∗∩∂WJof the feasible set. Indeed, the feasible set is non-empty since
it includes ˆ wJ, and it is compact and convex. The minimum of the linear function is therefore attained at
a boundary point, which is in ∂WJ. As a consequence, w∗∈ WJ\{j}for some j∈J. Since ˆ wJ∈ WJ, we
have that v′Xw∗≤v′XˆwJ< v′XˆwJ\{j}. Hence there is some ε∈(0,1] such that ˆ wJ\{j}(ε) = ˆwJ\{j}(1−
ε) +w∗ε∈ WJ\{j}fulfills v′XˆwJ\{j}(ε) =v′XˆwJ. Since we therefore have Π XˆwJ\{j}(ε) = Π XˆwJ, as well
as (I−Π)XˆwJ\{j}(ε) = (I−Π)X( ˆwJ\{j}(1−ε) +εˆwJ) since Π X(w∗−ˆwJ) =X(w∗−ˆwJ), we have that
∥XˆwJ\{j}(ε)−yJ∥2=∥X( ˆwJ\{j}(ε)−ˆwJ)∥2
=∥ΠX( ˆwJ\{j}(ε)−ˆwJ)∥2+∥(I−Π)X( ˆwJ\{j}(ε)−ˆwJ)∥2= 0 + (1 −ε)2∥(I−Π)X( ˆwJ\{j}−ˆwJ)∥2
<∥ΠX( ˆwJ\{j}−ˆwJ)∥2+∥(I−Π)X( ˆwJ\{j}−ˆwJ)∥2=∥X( ˆwJ\{j}−ˆwJ)∥2=∥XˆwJ\{j}−yJ∥2,
contradicting the choice of ˆ wJ\{j}. Hence, such λmust exist.
As the fourth step , we expand the previous result on fitted values to the weights themselves in the case
of penalized synthetic control, and show that the weights sum to one in that case. To this end, note that
we can write the penalized synthetic control estimator from (2) as ˆ wJ
η= arg minw∈WJ∥Xw−y∥2+η∥w∥2.
Write now ˜XJ
η= (X′
JXJ+ηI)1/2∈RJ×Jfor the symmetric positive-definite matrix square root of the
symmetric positive-definite X′
JXJ+ηI, where XJis a matrix of the columns of Xwith index in J, and
19˜yJ
η= (˜XJ
η)−1X′
Jy∈RJ. For wJthe entries of w∈ WJcorresponding to the index set J, we find
∥Xw−y∥2+η∥w∥2=∥XJwJ−y∥2+η∥wJ∥2
=w′
JX′
JXJwJ−2w′
JX′
Jy+y′y+ηw′
JwJ=w′
J(X′
JXJ+ηI)wJ−2w′
JX′
Jy+y′y
=w′
J˜XJ′
η˜XJ
ηwJ−2w′
J˜XJ′
η
(˜XJ
η)−1X′
Jy
+y′y=∥˜XJ
ηwJ−˜yJ
η∥2− ∥˜yJ
η∥2+∥y∥2.
Hence, we can write (noting that WJ\{j}⊆ WJ)
ˆwJ
η= arg min
w∈WJ∥˜XJ
ηwJ−˜yJ
η∥, wJ\{j}
η = arg min
w∈WJ\{j}∥˜XJ
ηwJ−˜yJ
η∥,
so we can interpret penalized synthetic control on units JandJ\ {j}with time periods {1, . . . , T }and
the original outcomes as non-penalized synthetic control on units JandJ\ {j}with time periods Jand
transformed outcomes, where we note that the synthetic-control solutions are unique in this case. Hence,
we can apply the previous result to conclude that there exists λη∈RJwith λη,j≥0 for all j∈Jsuch that
˜XJ
η˜wJ
η=P
j∈Jλη,j˜XJ
η˜wJ\{j}
η . Since ˜XJ
ηis invertible, it now also follows that ˜ wJ
η=P
j∈Jλη,j˜wJ\{j}
η . Since
also ˜wJ
η∈ W and ˜wJ\{j}
η∈ W for all j∈J, we have thatP
j∈Jλη,j=P
j∈Jλη,j1′˜wJ\{j}
η =1′˜wJ
η= 1. This
establishes the main claim of the proposition for penalized synthetic control.
As the fifth and final step , we derive the main result on minimum-norm synthetic control from the above
results on penalized synthetic control. Consider some sequence ( ηι)∞
ι=1in (0,∞) with ηι→0, and for every ι
apply the previous step to the penalized synthetic control estimator with penalty ηιto obtain a weight vector
ληι∈ΛJ=
λ∈[0,1]J;PJ
j=1λj= 1	
. Since ΛJis compact, ( ληι)∞
ι=1must have a converging subsequence
with some limit λ∈ΛJ. Using the limit along this subsequence, we have that
ˆwJ= lim
ι→∞ˆwJ
ηι= lim
ι→∞X
j∈Jληι,j˜wJ\{j}
ηι=X
j∈J 
lim
ι→∞ληι,j 
lim
ι→∞˜wJ\{j}
ηι
=X
j∈Jλj˜wJ\{j}.
Proof of Proposition 5. By Jensen’s inequality applied to an average over the bounds in (3),
E[(y−ˆf∗(x))2]≤1
|J|!X
πE[(y−ˆf∗
π(x))2]≤X
j∈JE"
1
|J|!X
πˆλπ(j)
|{z}
=1
|J|(y−ˆfj(x))2#
.
B Details of the Empirical Illustrations
B.1 Many-Regressor Linear Least-Squares on CPS Data
We utilize the publicly available5CPS control and NSW experimental control datasets, drawn from the
study presented in LaLonde (1986) as used by Dehejia and Wahba (1999, 2002). The resulting data has
15,992 observations for CPS and 260 for NSW, with both datasets containing an identical set of variables,
detailed in Table 1.
5users.nber.org/ ~rdehejia/data/.nswdata2.html . We use the files corresponding to cpscontrols.txt and
nswre74 control.txt .
20Variable Data Type Description
age Discrete Age
education Discrete Years of education
black Dummy Black
hispanic Dummy Hispanic
married Dummy Marital status
nodegree Dummy Lack of college degree
re74 Continuous Income in 1974
re75 Continuous Income in 1975
re78 Continuous Income in 1978
Table 1: CPS and NSW dataset variables
We use re78 as the outcome variable and all other variables as covariates. In order to achieve high
dimensionality, we first discretize the continuous income covariates into 50 bins via quantile binning. We
then construct a series of dummies for each discrete variable, corresponding to indicators for each discretized
value. We then interact all these dummy variables, as well as those covariates which were originally dummies,
taking care not to interact those which are mutually exclusive (e.g. originating from the same original
covariate or corresponding to race). We then drop any interactions that are zero for all observations in
the data. The resulting transformed dataset contains 8,408 dummy covariates, as well as the unmodified
outcome variable. In order to ensure that the covariate matrix is full row rank for an arbitrary subset of
columns, we go on to add iid N(0,0.0004) noise to each of the covariate values (again leaving the outcome
variable unaffected). We then select a random subset of 3,000 observations from the CPS dataset as our
in-sample set, using the 260 NSW observations as our out-of-sample set.
For fitting models of varying complexity, we randomly permute the order of the columns of the covariate
matrix; denote the resulting matrix as X. We then add an intercept and iterate over varying levels of
complexity ℓ, ranging from 1 to 8,409, corresponding to the number of covariates that we will use for
estimation. We then estimate the OLS coefficient vector ˆβℓ=Xℓ†y, where †denotes the Moore–Penrose
pseudoinverse.
To evaluate performance, we first select a sample size mand then draw 1000 samples of size mfrom
the NSW set. We then take define our evaluation metric to be the RMSE across these 1000 samples, with
error defined as the difference between the average predicted outcome and the true average outcome for each
sample:
RMSE( ℓ, m) =vuut1
10001000X
j=1" 
1
mmX
i=1y∗
ji!
− 
1
mmX
i=1x∗⊤
jiˆβℓ!#2
This metric assesses the ability of the given model to accurately predict mean outcomes, a quantity of direct
relevance to ATE estimaiton. Where X∗, y∗denote the out-of-sample covariate and outcome variables,
respectively, and can correspond to either the CPS or NSW held-out samples. The subscript jirefers to
theith observation of the jth sample of size m. In order to smooth out the effects of the random ordering
of columns, we repeat this exercise for five different random orderings and take a pointwise average to
obtain smooth RMSE vs. complexity and coefficient vector norm vs. complexity curves (Figures 2 and 3,
21respectively).
B.2 Many-Unit Synthetic Control on Smoking Data
For our synthetic-control exercise, we utilize public data from the Centers for Disease Control and Prevention6
containing annual cost, revenue, tax, and quantity data for cigarette sales by state for the years 1970 to 2019.
We follow the approach of Abadie et al. (2010) in using synthetic control to estimate per-capita cigarette
pack consumption for the target state, California, as a function of the other 49 states and Washington, D.C.
For our evaluation, we utilize two years of data (1987 and 1988) as a hold-out sample and fit the model on
three years (1984 to 1986). All of our data precedes the year in which anti-smoking legislation took effect in
California (1989).
We begin by selecting a random subset of 20 states to serve as our donor pool, for computational
tractability. We then select a level of complexity ℓand select a subset of ℓstates from the chosen 20. Using
that subset, we then estimate synthetic control weights based on the in-sample period, choosing convex
weight vector ˆ wℓ∈ W ={w∈[0,1]N;Pn
i=1wi= 1}as described in Section 3.1:
ˆwℓ= arg min
w∈cWℓ∥w∥ cWℓ= arg min
w∈W;wj=0∀j /∈J1986X
t=1984(y0t−ℓX
i=1wiyit)2.
Here, y0denotes the target state, California. We then compute the out-of-sample prediction error as:
RMSE( ℓ) =vuut1
21988X
t=1987(y0t−ℓX
i=1ˆwℓ
iyit)2
We then iterate over all 20
ℓ
possible combinations of donor units for the given complexity level and take
the average RMSE value to be the predictive error for the given complexity level. We vary ℓfrom 1 to 20 to
trace out the curve of synthetic control prediction risk vs. complexity (Figure 6).
As a robustness check, we also consider synthetic control with 10 pre-treatment periods, where the
included control states are chosen among all 50 available donors (49 other states and Washington, D.C.). In
particular, at each complexity level ℓwe consider min { 50
ℓ
,10000}combinations of donor units. The results
are qualitatively similar, and provided in Figure 9.
6chronicdata.cdc.gov/Policy/The-Tax-Burden-on-Tobacco-1970-2019/7nwe-3aj9 .
220 10 20 30 40 50
Number of control states05101520RMSE (daily cigarette packs)Out-of-time
TrainingFigure 9: Average out-of-time (blue) and training (orange) RMSE for synthetic control for a varying number
of control units as in Figure 6, but with ten pre-treatment periods and control units chosen randomly among
all available donors.
23