On the Convergence of Hermitian Dynamic Mode
Decomposition
Nicolas Boull´ ea, Matthew J. Colbrookb
aDepartment of Mathematics, Imperial College London, London, SW7 2AZ, UK
bDepartment of Applied Mathematics and Theoretical Physics, University of
Cambridge, Cambridge, CB3 0WA, UK
Abstract
We study the convergence of Hermitian Dynamic Mode Decomposition (DMD)
to the spectral properties of self-adjoint Koopman operators. Hermitian
DMD is a data-driven method that approximates the Koopman operator as-
sociated with an unknown nonlinear dynamical system, using discrete-time
snapshots. This approach preserves the self-adjointness of the operator in
its finite-dimensional approximations. We prove that, under suitably broad
conditions, the spectral measures corresponding to the eigenvalues and eigen-
functions computed by Hermitian DMD converge to those of the underlying
Koopman operator. This result also applies to skew-Hermitian systems (af-
ter multiplication by i), applicable to generators of continuous-time measure-
preserving systems. Along the way, we establish a general theorem on the
convergence of spectral measures for finite sections of self-adjoint operators,
including those that are unbounded, which is of independent interest to the
wider spectral community. We numerically demonstrate our results by ap-
plying them to two-dimensional Schr¨ odinger equations.
Keywords: dynamical systems, Koopman operators, dynamic mode
decomposition, spectral convergence, self-adjoint operators
1. Introduction
We consider discrete-time dynamical systems of the form:
xn+1=F(xn), n∈N, (1.1)
where x∈Ω denotes the state of the system, and Ω ⊆Rdis the state-space
ford∈N. The (typically) nonlinear function F: Ω→Ω governs the system’s
Preprint submitted to ArXiv October 8, 2024arXiv:2401.03192v2  [math.NA]  7 Oct 2024evolution and is unknown. We assume that our knowledge of the system is
limited to M≥1 discrete-time snapshots of the system, i.e., one has only
access to a finite dataset of the form

x(m),y(m)	M
m=1,such that y(m)=F(x(m)),1≤m≤M. (1.2)
This snapshot data can be collected from either one long trajectory or multi-
ple shorter trajectories and acquired via experimental observations or numer-
ical simulations. In general, one aims to use this data to infer and reconstruct
properties of the underlying dynamical system given by (1.1). With the ar-
rival of big data and machine learning, this data-driven viewpoint is currently
undergoing a renaissance. Examples of applications of this framework arise
naturally across many scientific fields, including fluid dynamics [1], epidemi-
ology [2], chemistry [3], and neuroscience [4], to name a few.
One of the most prominent algorithms for data-driven analysis of dynam-
ical systems is Dynamic Mode Decomposition (DMD), which is closely con-
nected with Koopman operators . In 1931, Koopman introduced an operator-
theoretic approach to dynamical systems, initially to describe Hamiltonian
systems [5]. This theory was further expanded by Koopman and von Neu-
mann [6] to include systems with continuous spectra. A Koopman operator K
lifts a nonlinear system (1.1) into an infinite-dimensional space of observable
functions g: Ω→Cas
[Kg](x) =g(F(x)),such that [ Kg](xn) =g(xn+1) for n≥0.
Through this approach, the evolution dynamics become linear, enabling the
use of generic solution techniques based on spectral decompositions. DMD
was initially developed in the context of fluid dynamics [7, 1]. Earlier, Mezi´ c
introduced the Koopman mode decomposition [8], providing a theoretical ba-
sis for Rowley et al. to connect DMD with Koopman operators [2]. However,
the standard DMD algorithm is based on linear observables and generally fails
to capture truly nonlinear phenomena. To address this limitation, Extended
DMD (EDMD) [9] extends the DMD algorithm to nonlinear observables.
Then, under suitable conditions, in the large-data limit M→ ∞ , EDMD
converges to the numerical approximation obtained by a Galerkin method in
the limit of large data sets. At its core, EDMD is a projection method that
aims to compute the spectral properties of Koopman operators. It is impor-
tant to realize that EDMD only converges in the strong operator topology
2toK[10]1and its spectral properties need not converge [11, Example 2]. For
ways of overcoming this and classifications of how difficult Koopman spectral
computations are, see [12].
In a recent paper [13], Baddoo et al. provided a unified framework,
Physics-Informed Dynamic Mode Decomposition (piDMD), for imposing phys-
ical constraints in DMD with a linear choice of dictionary. For some con-
straints, this framework can be extended to the setting of EDMD, thus pro-
viding an approximation of Koopman operators in the spirit of geometric
integration [14]. A scenario where it is possible to extend piDMD to non-
linear observables occurs when the Koopman operator associated with the
dynamical system is Hermitian, and one aims to compute finite-dimensional
Hermitian approximations to preserve spectral properties. The correspond-
ing algorithm, known as Hermitian Dynamic Mode Decomposition , has been
studied extensively by Drmaˇ c [15]. However, there is currently no proof
of convergence of this method to the spectral properties of the underlying
Koopman operator, despite encouraging numerical results [13, 15].
This note addresses this gap by showing the convergence of Hermitian
Dynamic Mode Decomposition to the spectral properties of self-adjoint Koop-
man operators. Along the way, we derive Theorem 4.5, a result that may be
of independent interest in the wider spectral community. For methods that
compute spectral measures of general self-adjoint systems, see [16, 17]. All
of our results naturally extend to the case when the Koopman operator is
skew-Hermitian, another structure of broad interest. As an example, Koop-
man generators of invertible measure-preserving continuous-time dynamical
systems are skew-adjoint. Hence, our analysis carries over to the application
of (skew) Hermitian DMD to DMD methods that approximate such genera-
tors [18]. Our results can also be extended to stochastic dynamical systems
and the stochastic Koopman operator [19, 20, 21, 22].
It is worth pointing out the myriad of papers on Koopman operators
and DMD, as evidenced by various surveys [23, 24, 25, 26, 27, 28]. For
example, the survey [25] characterizes structure-preserving methods as one
of the flavors of DMD. Despite this widespread interest, convergence results
1Essentially, this means that the action of EDMD on observables converges to the
action of the Koopman operator on observables. This form of convergence implies that
limit points of eigenpairs of EDMD are also eigenpairs of the Koopman operator if the
limiting vector is non-zero [10, Theorem 4]. As the authors of [10] highlight, this is an
extremely weak form of convergence.
3pertaining to the relevant spectral properties of Koopman operators remain
decidedly rare. Exceptions to this rule include methods with theoretical
guarantees, such as Hankel-DMD [29], Residual DMD [30, 31], Rigged DMD
[32], Measure-Preserving EDMD [33], compactification methods [34, 35], and
periodic approximation methods [36, 37]. While related to the present note,
the latter four approaches assume that the system is measure-preserving,
which differs from the setup addressed here. Given the keen interest in
convergence results, we hope this note will encourage further exploration
into the conditions under which methods like piDMD converge.
The rest of the paper is organized as follows. We provide preliminaries in
Section 2 on Koopman operators and EDMD. Then, in Section 3, we recall
and derive Hermitian DMD in the context of EDMD. Finally, Section 4
contains our main convergence results, which are demonstrated numerically
in Section 5.
2. Preliminaries
In this section, we provide preliminaries on Koopman operators, EDMD,
and the role of spectral measures for self-adjoint Koopman operators.
2.1. Koopman operators
To define a Koopman operator, we begin with a space Fof functions
g: Ω→C, where Ω is the state space of our dynamical system. The functions
g, referred to as observables , serve as tools for indirectly measuring the state
of the system described in (1.1). Specifically, g(xn) indirectly measures the
state xn. Koopman operators enable us to capture the time evolution of
these observables through a linear operator framework. For a suitable domain
D(K)⊂ F, we define the Koopman operator via the composition formula:
[Kg](x) = [g◦F](x) =g(F(x)), g∈ D(K). (2.1)
In this context, [ Kg](xn) =g(F(xn)) =g(xn+1) represents the measurement
of the state one time step ahead of g(xn). This process effectively captures the
dynamic progression of the system. The overarching concept is summarized
in Fig. 1.
The key property of the Koopman operator Kis its linearity . This lin-
earity holds irrespective of whether the system’s dynamics, as represented
in (1.1), are linear or nonlinear. Consequently, the spectral properties of K
4Linear
Nonlinear Finite- dimensionalInfinite -DimensionalFigure 1: Summary of the idea of Koopman operators. By lifting to a space of observables,
we trade a nonlinear finite-dimensional system for a linear infinite-dimensional system.
become a powerful tool to analyze the dynamical system’s behavior. We fo-
cus on cases where F=L2(Ω, ω) is a Hilbert space with the following inner
product
⟨g1, g2⟩=Z
Ωg1(x)g2(x) dω(x),
for some positive measure ω. In going from a pointwise definition in (2.1) to
the space L2(Ω, ω), a little care is needed since L2(Ω, ω) consists of equiva-
lence classes of functions. We assume that the map Fis nonsingular with
respect to ω, meaning that
ω(E) = 0 implies ω({x:F(x)∈E}) = 0 .
This ensures that the Koopman operator is well-defined since g1(x) =g2(x)
forω-almost every ximplies that g1(F(x)) =g2(F(x)) for ω-almost every x.
The above Hilbert space setting is standard in most of the Koopman lit-
erature. It is crucial to recognize that the Koopman operator is not uniquely
defined by the dynamical system in (1.1); rather, it is fundamentally de-
pendent on the choice of the space of observables F. Since Kacts on an
infinite-dimensional function space, we have exchanged the nonlinearity in
(1.1) for an infinite-dimensional linear system. This means that the spec-
tral properties of Kcan be significantly more complex than those of a finite
matrix, making them more challenging to compute [38, 39].
52.2. Extended dynamic mode decomposition
The objective of EDMD is to approximate the action of the Koopman
operator Kon a finite-dimensional vector space of functions by a matrix
K. For the sake of simplicity, the initial formulation of EDMD assumes
that the sample points {x(m)}M
m=1in the snapshot dataset are independently
sampled from the distribution ω. In this section, we consider the points x(m)
asquadrature nodes used for integration with respect to the measure ω. This
adaptability enables the choice of quadrature weights tailored to different
scenarios.
One first chooses a dictionary of functions {ψ1, . . . , ψ N}, i.e., a list of
observables, in the space D(K)⊂L2(Ω, ω). These observables form a finite-
dimensional subspace VN= span {ψ1, . . . , ψ N}. EDMD consists of selecting
a matrix K∈CN×Nthat approximates the action of Kconfined to this
subspace, such that for 1 ≤j≤Nwe have,
[Kψj](x) =ψj(F(x))≈NX
i=1Kijψi(x).
We define the vector-valued feature map, Ψ: Ω→CN, as
Ψ(x) =
ψ1(x)··· ψN(x)
∈C1×N,x∈Ω. (2.2)
Any function g∈VNcan be expressed as a linear combination of the ba-
sis functions as g(x) =PN
j=1ψj(x)gj=Ψ(x)g, for some vector g∈CN.
Therefore,
[Kg](x) =Ψ(F(x))g=Ψ(x)(K g) +NX
j=1ψj(F(x))gj−Ψ(x)(K g)
| {z }
R(g,x).
In general, VNis not an invariant subspace of K. Hence, there is no choice
ofKthat makes the residual R(g,x) zero for all g∈VNandω-almost every
x∈Ω. Instead, it is natural to select the matrix Kto minimize the residual:
K= argmin
K∈CN×NZ
Ωmax
g∈CN
∥Cg∥ℓ2=1|R(g,x)|2dω(x)
= argmin
K∈CN×NZ
ΩΨ(F(x))C−1−Ψ(x)KC−12
ℓ2dω(x).(2.3)
6Here, C∈RN×Nis a positive self-adjoint matrix that controls the size of
g=Ψg. One should interpret the matrix Cas choosing an appropriate
norm. This becomes important when N→ ∞ since not all the norms defined
on an infinite-dimensional vector space are equivalent.
While it is not possible to directly evaluate the integral in (2.3) from
the snapshot data, one can instead approximate it via a quadrature rule
with nodes {x(m)}M
m=1and weights {wm}M
m=1. For notational convenience, we
introduce the weight matrix W= diag( w1, . . . , w M) and the matrices
ΨX=
Ψ(x(1))
...
Ψ(x(M))
∈CM×N,and ΨY=
Ψ(y(1))
...
Ψ(y(M))
∈CM×N.
After discretizing (2.3), one obtains the following weighted least-squares
problem:
K= argmin
K∈CN×NMX
m=1wmΨ(y(m))C−1−Ψ(x(m))KC−12
2
= argmin
K∈CN×NW1/2ΨYC−1−W1/2ΨXKC−12
F,(2.4)
where ∥ · ∥ Fdenotes the Frobenius norm. By reducing the size of the dictio-
nary if necessary, we may assume without loss of generality that W1/2ΨX
has rank N. A solution to (2.4) is given by
K= (W1/2ΨX)†W1/2ΨY= (Ψ∗
XWΨ X)†Ψ∗
XWΨ Y,
where †denotes the Moore–Penrose pseudoinverse. The second equality fol-
lows since W1/2ΨXhas linearly independent columns. Note that this solu-
tion is independent of the matrix C. However, a suitable choice of Cis vital
once constraints on the matrix Kare added to the optimization problem
in (2.3) [33]. In the case where the quadrature weights are equal and Ψis
the state (i.e., a linear dictionary), then K⊤is the transpose of the classical
DMD matrix.
We now define the two correlation matrices G∈CN×NandA∈CN×N:
G=Ψ∗
XWΨ X=MX
m=1wmΨ(x(m))∗Ψ(x(m)),
A=Ψ∗
XWΨ Y=MX
m=1wmΨ(x(m))∗Ψ(y(m)).(2.5)
7If we consider the discrete measure ωM=PM
m=1wmδx(m), then
Gjk=Z
Ωψj(x)ψk(x) dωM(x),Ajk=Z
Ωψj(x)ψk(F(x)) dωM(x).
Additionally, if the quadrature discretization converges as the number of data
points M→ ∞ , then we have
lim
M→∞Gjk=⟨ψk, ψj⟩,and lim
M→∞Ajk=⟨Kψk, ψj⟩. (2.6)
Therefore, in the large data limit, K=G†Aapproaches a matrix represen-
tation of the operator PVNKP∗
VN, where PVN:L2(Ω, ω)→VNdenotes the
orthogonal projection onto the subspace VN. In essence, EDMD is a Galerkin
method. The EDMD eigenvalues thus approach the spectrum of PVNKP∗
VN,
and EDMD is an example of the so-called finite section method [40].
2.3. Spectral measures of self-adjoint Koopman operators
Ifg∈L2(Ω, ω) is an eigenfunction ofKwith eigenvalue λ, then gexhibits
perfect coherence2with
g(xn) = [Kng](x0) =λng(x0), n∈N. (2.7)
The oscillation and decay/growth of the observable gare dictated by the
complex argument and absolute value of the eigenvalue λ, respectively. In
infinite dimensions, the appropriate generalization of the set of eigenvalues
ofKis the spectrum , denoted by Sp( K), and defined as
Sp(K) =
z∈C: (K −zI)−1does not exist as a bounded operator	
⊂C.
Here, Idenotes the identity operator. The spectrum Sp( K) includes the
set of eigenvalues of K, but in general, Sp( K) contains points that are not
eigenvalues. This is because there are more ways for ( K −zI)−1to not exist
in infinite dimensions than in finite dimensions. For example, we may have
continuous spectra.
2In the setting of dynamical systems, coherent sets or structures are subsets of the phase
space where elements (e.g., particles, agents, etc.) exhibit similar behavior over some time
interval. This behavior remains relatively consistent despite potential perturbations or the
chaotic nature of the system.
8From now on, we assume that Kis a self-adjoint operator acting on
L2(Ω, ω). Under this condition, the spectral theorem3[42, Thm. X.4.11]
allows us to diagonalize the Koopman operator K, and its spectrum Sp( K)
lies within the real line RsinceKis self-adjoint. There is a projection-valued
measure Esupported on Sp( K), which associates an orthogonal projector
with each Borel measurable subset of R. For such a subset S⊂R,E(S) is
a projection onto the spectral elements of Kinside S. For any observable
g∈ D(K),
g=Z
RdE(λ)
gandKg=Z
RλdE(λ)
g.
The essence of this formula is the decomposition of gaccording to the spectral
content of K. The projection-valued measure Esimultaneously decomposes
the space L2(Ω, ω) and diagonalizes the Koopman operator. For example, if
g∈ D(Kn), we have
g(xn) = [Kng](x0) =Z
RλndE(λ)
g
(x0). (2.8)
The spectral theorem offers a custom Fourier-type transform specifically
for the operator Kthat extracts coherent features. Scalar-valued spectral
measures are of particular interest. Hence, given a normalized observable
g∈L2(Ω, ω) with ∥g∥= 1, the scalar-valued spectral measure of Kwith
respect to gis a probability measure defined as
µg(S) =⟨E(S)g, g⟩.
The spectral measure of Kwith respect to g∈L2(Ω, ω) is a signature for
the forward-time dynamics of (1.1). In this paper, we show that the spectral
measures computed by Hermitian DMD converge to those of K.
3. Hermitian Dynamic Mode Decomposition
When the Koopman operator Kis Hermitian, i.e., K=K∗, a natural
constraint is to preserve the Hermitian property on its finite-dimensional ap-
proximation, K. This ensures that the spectral properties of Kare consistent
3For readers unfamiliar with the spectral theorem, [41] provides an excellent and read-
able introduction.
9with those of Kas the size of the dictionary increases. Generally, the solu-
tion to (2.4) is not Hermitian, and diverse strategies have been proposed to
enforce this constraint [15]. Here, we consider the Hermitian DMD algorithm
introduced in [13].
First, given the Gram matrix G=Ψ∗
XWΨ X, one can approximate the
inner product ⟨·,·⟩onL2(Ω, ω) via the inner product induced by Gas
⟨Ψg,Ψh⟩=NX
j,k=1hjgk⟨ψk, ψj⟩ ≈NX
j,k=1hjgkGj,k=h∗Gg. (3.1)
If (2.6) holds, then this approximation converges to the inner product on
L2(Ω, ω) in the large data limit as M→ ∞ . We follow the EDMD approach
described in Section 2.2 but enforce the additional constraint that the matrix
representation of the Koopman operator is self-adjoint with respect to the
inner product induced by the matrix G. Hence, we consider the following
constrained least-square problem:
K= argmin
K∈CN×N
GK=K∗GMX
m=1Ψ(y(m))G−1/2−Ψ(x(m))KG−1/22
2
= argmin
K∈CN×N
GK=K∗GW1/2ΨYG−1/2−W1/2ΨXKG−1/22
F.
After performing the change of variables B=G1/2KG−1/2, we obtain
min
B∈CN×N
B∗=BW1/2ΨYG−1/2−W1/2ΨXG−1/2B2
F. (3.2)
Here, we recognize a symmetric Procrustes problem [13, 43] of the form
min
M∈CN×N
M∗=M∥Y−XM∥2
F.
A solution can be computed from the economized singular value decompo-
sition of the matrix X=UΣΣΣV∗, where Σ ΣΣ is the N×Ndiagonal matrix
containing the singular values σ1≥σ2≥ ··· ≥ σN≥0. The solution is given
by the matrix M=VΥΥΥV∗, where the entries of Hermitian matrix Υ ΥΥ∈CN×N
are defined by
ΥΥΥij=(σicij+σjcji
σ2
i+σ2
j,ifσ2
i+σ2
j̸= 0,
0, otherwise ,
10for 1≤i, j,≤N. Here, the coefficients cijare the entries of the matrix
C=U∗YV. As observed by Higham [43], this algorithm is backward stable
following the backward stability of the Golub–Reinsch SVD algorithm [44,
Sec. 5.5.8].
We make an additional observation compared to the original formulation
in [13], which considerably simplifies the algorithm to solve (3.2). In the
case of (3.2), we have X=W1/2ΨXG−1/2andY=W1/2ΨYG−1/2, and
the symmetric Procrustes algorithm can be simplified since X∗X=I, the
identity matrix. Hence, one can select Σ ΣΣ and Vto be the identity matrices,
and the solution becomes
K=G−1/2BG1/2=G−1A+A∗
2
. (3.3)
Therefore, if the convergence in (2.6) holds, the large data limit of Hermitian
DMD becomes a Galerkin approximation of the Koopman operator since
⟨Kψk, ψj⟩=⟨ψk,Kψj⟩. Additionally, the formula given by (3.3) is more
computationally efficient than the standard symmetric Procrustes approach
employed in [13] as it avoids the computation of the SVD of X, as well
as a matrix square-root, which can be numerically unstable when Gis ill-
conditioned.
Given this convergence result, it is natural to study the convergence of this
approximation as the size of the dictionary increases. It is well-known that
spectra of Galerkin approximations of operators can suffer from discretization
issues such as spectral pollution (spurious eigenvalues), spectral invisibility
(missing parts of the spectrum), instabilities, and so forth [45, 46, 47]. These
issues occur and, in fact, can worsen as the dictionary’s size increases. Hence,
the convergence of the Hermitian DMD algorithm might be difficult to estab-
lish. Nevertheless, we will show in Section 4 that the (scalar-valued) spectral
measures converge weakly, thus providing theoretical guarantees for Hermi-
tian DMD. One crucial property exploited in the proof is the self-adjointness
of the finite-dimensional approximations, as imposed by Hermitian DMD.
4. A general convergence result
Throughout this section, we consider an arbitrary self-adjoint operator L
acting on a Hilbert space Hwith domain D(L). For example, the differential
operator −d2/dx2onL2(R) is self-adjoint with domain {g∈L2(R) :g′′∈
11L2(R)}. This is an example of an unbounded operator (recall that an oper-
atorAis bounded if supx∈D(A),∥x∥=1∥Ax∥<∞). Moreover, the operators in
this section need not be Koopman operators. Let {Pn:H → V n}n∈Nbe a
sequence of orthogonal projections onto a Hilbert space Vn⊂ H, such that
P∗
nPnconverges strongly to the identity, meaning that
lim
n→∞∥P∗
nPnu−u∥= 0, u∈ H.
We also assume that Vn⊂ D(L). We are interested in the spectral measure
ofLwith respect to a vector v∈ H, which we denote by µv. We let µv,n
represent the scalar-valued spectral measure of PnLP∗
nwith respect to the
vector Pnv∈ V n. We will show that the spectral measures µv,nconverge
weakly to µv. While this is a well-known result for bounded self-adjoint
operators, the standard proof does not carry over to the unbounded case,
which requires a different approach.
4.1. Bounded operators - the easy case
The case when Lis bounded is well-known. The following standard proof
of convergence essentially boils down to a moment-matching procedure.
Lemma 4.1. Consider the above setup and suppose that Lis bounded. Then,
for any bounded, continuous, function ϕonRand for any v∈ H,
lim
n→∞Z
Rϕ(λ) dµv,n(λ) =Z
Rϕ(λ) dµv(λ). (4.1)
In particular, µv,nconverges weakly to µvasn→ ∞ .
Proof. Since∥PnLP∗
n∥ ≤ ∥L∥ , Sp(PnLP∗
n) is contained in some finite fixed
interval. Since the support of µv,nis contained in Sp( PnLP∗
n), without loss
of generality, we assume that ϕis supported on a finite interval. Since any
such function can be approximated to arbitrary accuracy by a polynomial,
it is enough to prove (4.1) for ϕ(λ) =λk, for any k∈Z≥0. In other words, it
is enough to show that the moments of the measures converge.
The functional calculus shows that
Z
Rλkdµv,n(λ) =⟨P∗
n(PnLP∗
n)kPnv, v⟩,Z
Rλkdµv(λ) =⟨Lkv, v⟩.
SinceLis bounded and P∗
nPnconverges strongly to the identity,
P∗
n(PnLP∗
n)kPn=P∗
nPn(LP∗
nPn)k
12converges strongly to Lkfor any k∈Z≥0. It follows that P∗
n(PnLP∗
n)kPnv
converges weakly to Lkv. The convergence in (4.1) follows.
Remark 4.2. Note that we proved strong convergence of the sequence of
operators P∗
n(PnLP∗
n)kPn. The proof, therefore, automatically upgrades the
lemma to weak convergence (in the sense of measures) of projection-valued
spectral measures in the strong operator topology.
The above proof cannot be carried over to unbounded operators since the
moments may not exist. Instead, we replace the polynomials appearing in
the proof of Lemma 4.1 with rational functions. To do this, we must look at
the resolvent.
4.2. Strong convergence of the resolvent
To deal with unbounded operators, we make the following assumption.
Assumption 4.3. There exists a core S⊂ D(L)such that
lim
n→∞LP∗
nPnu=Lu, lim
n→∞P∗
nPnu=u∀u∈S.
Without such assumptions, spectral measures need not converge [48, The-
orem 2.3]. The following lemma shows that with this assumption, the resol-
vents of our projected operators converge strongly to the resolvent of L. For
a discussion of these kinds of results, see [49, Chapter VIII] and [50, 51].
Lemma 4.4. Suppose that Assumption 4.3 holds. Then
lim
n→∞P∗
n[Pn(L −zI)P∗
n]−1Pnv= (L −zI)−1v,∀v∈ H, z∈C\R.
Proof. Fixz∈C\Rand suppose first that there exists u∈Swith ( L −
zI)−1v=u. For notational convenience, let Tn= [Pn(L −zI)P∗
n]−1, which
exists since Sp( PnLP∗
n)⊂R. We may write
P∗
nPn(L −zI)−1v=P∗
nPnu=P∗
nTnPnP∗
n[Pn(L −zI)P∗
n]Pnu.
This quantity converges to ( L−zI)−1v, and hence it is enough to prove that
lim
n→∞P∗
nTnPnv− P∗
nTnPnP∗
n[Pn(L −zI)P∗
n]Pnu= 0.
The quantity on the left is equal to
P∗
nTnPn[(L −zI)− P∗
nPn(L −zI)P∗
nPn]u.
13Since∥Tn∥ ≤1/|Im(z)|, Assumption 4.3 shows that this converges to zero.
Hence, to prove the lemma, we must show that we can drop the assumption
that u∈S. Let u= (L −zI)−1vbe general, then there exists a sequence
{um} ⊂Swith lim m→∞um=uand lim m→∞Lum=Lu. Let vm= (L −
zI)um, then we have just shown that
lim
n→∞P∗
n[Pn(L −zI)P∗
n]−1Pnvm= (L −zI)−1vm.
Now lim m→∞vm=vand∥Tn∥,∥(L −zI)−1∥ ≤1/|Im(z)|. Hence, the result
also holds with v.
4.3. General convergence theorem
We now have all of the tools needed to prove the convergence of spectral
measures. We first prove the general result and then the result for Hermitian
DMD. All the required assumptions are stated explicitly in the theorems.
Theorem 4.5. LetLbe a self-adjoint operator on a Hilbert space Hwith
domain D(L). Let {Pn:H → V n}n∈Nbe a sequence of orthogonal projec-
tions onto a Hilbert space Vn⊂ H, such that P∗
nPnconverges strongly to the
identity and Vn⊂ D(L). In addition, suppose that Assumption 4.3 holds.
Then, for any v∈ H and any bounded continuous function fonR,
lim
n→∞Z
Rf(λ) dµv,n(λ) =Z
Rf(λ) dµv(λ), (4.2)
where µv,nis the spectral measure of PnLP∗
nw.r.t. the vector vn=Pnv.
Proof. The idea of the proof is to use rational functions in the application of
the Stone–Weierstrass theorem to first prove vague convergence of measures,
and then upgrade the convergence to weak convergence using tightness. We
first let f(λ) = 1 /(λ−z) forz∈C\R. For this choice, the functional calculus
shows thatZ
Rf(λ) dµv,n(λ) =⟨P∗
n[Pn(L −zI)P∗
n]−1Pnv, v⟩,
Z
Rf(λ) dµv(λ) =⟨(L −zI)−1v, v⟩.
Lemma 4.4 now shows that (4.2) holds for this particular choice of f. The
Stone–Weierstrass theorem (for locally compact Hausdorff spaces) then im-
plies that (4.2) holds if lim |x|→∞f(x) = 0. To finish the proof, note that
limn→∞µv,n(R) =µv(R) =∥v∥2, which implies weak convergence given the
vague convergence.
14The convergence of Hermitian DMD now follows almost immediately. For
a given observable g∈L2(Ω, ω), we define
gN,M= (W1/2ΨX)†W1/2 
g(x(1)), . . . , g (x(M))⊤.
such that
lim
M→∞gN,M=gN,with PNg=ΨgN,
where Ψis the dictionary feature map in Eq. (2.2). We emphasize that this is
the standard way to compute expansion coefficients in the EDMD algorithm.
Theorem 4.6 (Convergence of Hermitian DMD) .Consider the space of
functions VN= span {ψ1, . . . , ψ N}and let PN:L2(Ω, ω)→VNbe the cor-
responding orthogonal projection. Suppose that P∗
NPNconverges strongly to
the identity, the Koopman operator Kis self-adjoint, the quadrature rule
converges as in (2.6), and that
Ku= lim
N→∞PNKP∗
NPNu, u ∈ D(K).
Then, for any observable g∈L2(Ω, ω)and any bounded continuous function
fonR,
lim
N→∞lim
M→∞Z
Rf(λ) dµ(M)
gN,M(λ) =Z
Rf(λ) dµg(λ), (4.3)
were µ(M)
gN,Mis the spectral measure of ΨgN,Mwith respect to the Hermitian
DMD matrix.
Remark 4.7. The use of Hermitian DMD is crucial in Theorem 4.6 to re-
strict the least squares problem in (3.2), and ensure that the spectral measures
µ(M)
gNare supported on R.
Proof of Theorem 4.6. The convergence of Hermitian DMD as M→ ∞ im-
plies that
lim
M→∞Z
Rf(λ) dµ(M)
gN,M(λ) =Z
Rf(λ) dµgN(λ),
where µgNis the spectral measure of PNKP∗
Nwith respect to PNg. The rest
of the proof follows directly from Theorem 4.5.
155. Numerical example
In this section, we evaluate the convergence of the Hermitian DMD algo-
rithm on the two-dimensional Schr¨ odinger equation given by
i∂u
∂t=ˆH(u) =−1
2∆u+V(x, y)u,(x, y)∈R2,
where V(x, y) = (x2+y2)/2 is an external harmonic potential, u: Ω→Cis a
normalized wave function, and ˆHis the Hamiltonian operator of the system.
Here, we select a computational domain Ω = ( −5,5)2to be large enough so
that solutions vanish well before reaching the boundary. The snapshot data
contain functions of the form ( u, i∂ tu), which are related by the self-adjoint
Hamiltonian operator ˆH. We use N= 400 initial conditions consisting of
Gaussian bumps (the dictionary) inside Ω as
u(x, y) = (1 + i)e−3((x−xi)2+(y−yj)2),1≤i, j≤20,
where the Gaussian centers ( xi, yj) are uniformly distributed in the domain
[−4,4]2.4We then evaluate the functions on the domain Ω at a uniform
tensor-product grid of M= 3002snapshot points, and discretize the integral
in (2.3) using a trapezoidal rule. Finally, we compute the N×NKoopman
matrix Kusing the Hermitian DMD algorithm described in Section 3, and
perform an eigenvalue decomposition of Kto obtain the first eigenstates and
corresponding eigenvalues to the Schr¨ odinger operator (see Fig. 2).
The analytical expression for the eigenmodes of the Schr¨ odinger equation
are obtained using the standard ansatz u(x, y, t ) = ϕ(x, y)e−iEt, where ϕ
is the eigenfunction and Eis the corresponding eigenvalue. Following a
separation of variables, one finds that the eigenmodes are proportional to [52,
Eq. (8)]
ϕm,n(x, y) =Hm(x)Hn(y)e−(x2+y2)/2,(x, y)∈R2, m, n ≥0,
where Hmis the Hermite polynomial of degree m, and the corresponding
eigenvalues are given by Em,n=m+n+ 1. We report in Fig. 3 the first
hundred eigenvalues obtained by Hermitian DMD along with the exact ones
and observe a good agreement up to the 50th eigenvalue.
4For suitable Gaussian bump functions, one can easily show that Assumption 4.3 is
satisfied for our Schr¨ odinger operator.
16−5 0 5−505
xyλ1= 1.00
00.10.20.3(a)
−5 0 5−505
xyλ2= 2.00
00.050.10.150.2(b)
−5 0 5−505
xyλ3= 2.00
00.050.10.150.2(c)
−5 0 5−505
xyλ4= 3.00
00.050.10.15(d)
−5 0 5−505
xyλ5= 3.00
00.050.10.15(e)
−5 0 5−505
xyλ6= 3.00
00.10.20.3(f)Figure 2: The first 6 energy eigenstates and eigenvalues of the Schr¨ odinger operator dis-
covered by Hermitian DMD.
0 20 40 60 80 100051015
jλj
Hermitian DMD
Exact eigenvalues
Figure 3: The first 100 eigenvalues of the Schr¨ odinger operator discovered by Hermitian
DMD along with the exact ones.
170 5 10 15 200246
cjApproximation at N = 752
0 5 10 15 200246
λjcjApproximation at N = 1502
0 5 10 15 200246
λjcjλj
Approximation at N = 3002
0 5 10 15 200246
λjcjExactFigure 4: Visualization of the approximate measures in (5.1). For this example, weak
convergence in Theorem 4.6 means that the positions and heights of the spikes converge.
The heights of the spikes, cj, can be thought of as an energy distribution akin to a Fourier
transform (but now provided by the spectral theorem).
18Table 1: Convergence of cj(λj) in the first five spikes of Fig. 4 for different values of N.
N= 7523.56 (3.00) 5.79 (5.00) 5.23 (7.00) 4.55 (9.01) 2.77 (11.06)
N= 15023.56 (3.00) 5.79 (5.00) 5.85 (7.00) 4.62 (9.01) 2.77 (11.06)
N= 30023.56 (3.00) 5.79 (5.00) 5.90 (7.00) 4.59 (9.01) 2.86 (11.06)
Exact 3.56 (3.00) 5.79 (5.00) 5.90 (7.00) 4.59 (9.00) 2.86 (11.00)
Then, we estimate µffor the function fdefined as
f(x, y) = sin( πx/5) sin( πy/5),(x, y)∈[−5,5]2.
The measure µf,nis given as a sum of Dirac measures
µf,N=NX
j=1cjδλj, c j=|v∗
jGf|2. (5.1)
Here, ( λj,vj) are the eigenpairs computed by Hermitian DMD and f=Ψf.
For comparison, for each analytic eigenvalue, we take the mean of the cluster
of the eigenvalues λjthat approximate it and then sum the weights cj. The
results are shown in Fig. 4 and Table 1 and demonstrate the convergence in
Theorem 4.6.
Data availability
The code to reproduce the numerical experiments is publicly available on
GitHub at https://github.com/NBoulle/ConvergenceHermitianDMD .
Acknowledgments
NB was supported by the SciAI Center funded by the Office of Naval
Research (ONR), under Grant Number N00014-23-1-2729.
References
[1] P. J. Schmid, Dynamic mode decomposition of numerical and ex-
perimental data, J. Fluid Mech. 656 (2010) 5–28. doi:10.1017/
s0022112010001217 .
19[2] C. W. Rowley, I. Mezi´ c, S. Bagheri, P. Schlatter, D. S. Henningson,
Spectral analysis of nonlinear flows, J. Fluid Mech. 641 (2009) 115–127.
doi:10.1017/s0022112009992059 .
[3] A. Narasingam, J. S.-I. Kwon, Koopman Lyapunov-based model pre-
dictive control of nonlinear chemical process systems, AIChE J. 65 (11)
(2019) e16743. doi:10.1002/aic.16743 .
[4] B. W. Brunton, L. A. Johnson, J. G. Ojemann, J. N. Kutz, Extracting
spatial-temporal coherent patterns in large-scale neural recordings using
dynamic mode decomposition, J. Neurosci. Methods 258 (2016) 1–15.
doi:10.1016/j.jneumeth.2015.10.010 .
[5] B. O. Koopman, Hamiltonian systems and transformation in Hilbert
space, Proc. Natl. Acad. Sci. U.S.A. 17 (5) (1931) 315–318. doi:10.
1073/pnas.17.5.315 .
[6] B. O. Koopman, J. von Neumann, Dynamical systems of continuous
spectra, Proc. Natl. Acad. Sci. U.S.A. 18 (3) (1932) 255–263. doi:
10.1073/pnas.18.3.255 .
[7] P. Schmid, J. Sesterhenn, Dynamic Mode Decomposition of numerical
and experimental data, Bull. Am. Phys. Soc. 53 (2008).
[8] I. Mezi´ c, Spectral properties of dynamical systems, model reduction and
decompositions, Nonlinear Dyn. 41 (1) (2005) 309–325. doi:10.1007/
s11071-005-2824-x .
[9] M. O. Williams, I. G. Kevrekidis, C. W. Rowley, A data–driven ap-
proximation of the Koopman operator: Extending dynamic mode de-
composition, J. Nonlinear Sci. 25 (6) (2015) 1307–1346. doi:10.1007/
s00332-015-9258-5 .
[10] M. Korda, I. Mezi´ c, On convergence of extended dynamic mode decom-
position to the Koopman operator, Journal of Nonlinear Science 28 (2)
(2018) 687–710. doi:10.1007/s00332-017-9423-0 .
[11] I. Mezi´ c, On numerical approximations of the Koopman operator, Math-
ematics 10 (7) (2022) 1180. doi:10.3390/math10071180 .
20[12] M. J. Colbrook, I. Mezi´ c, A. Stepanenko, Limits and powers of koopman
learning, arXiv preprint arXiv:2407.06312 (2024).
[13] P. J. Baddoo, B. Herrmann, B. J. McKeon, J. Nathan Kutz, S. L. Brun-
ton, Physics-informed dynamic mode decomposition, Proc. R. Soc. A
479 (2271) (2023) 20220576. doi:10.1098/rspa.2022.0576 .
[14] E. Hairer, C. Lubich, G. Wanner, Geometric numerical integration, 2nd
Edition, Springer, 2010.
[15] Z. Drmaˇ c, Hermitian dynamic mode decomposition-numerical analysis
and software solution, ACM Transactions on Mathematical Software
50 (1) (2024) 1–23.
[16] M. J. Colbrook, Computing spectral measures and spectral types, Com-
munications in Mathematical Physics 384 (1) (2021) 433–501. doi:
10.1007/s00220-021-04072-4 .
[17] M. J. Colbrook, A. Horning, A. Townsend, Computing spectral measures
of self-adjoint operators, SIAM Review 63 (3) (2021) 489–524. doi:
10.1137/20m1330944 .
[18] S. Klus, F. N¨ uske, S. Peitz, J.-H. Niemann, C. Clementi, C. Sch¨ utte,
Data-driven approximation of the Koopman generator: Model reduc-
tion, system identification, and control, Physica D: Nonlinear Phenom-
ena 406 (2020) 132416. doi:10.1016/j.physd.2020.132416 .
[19] I. Mezi´ c, A. Banaszuk, Comparison of systems with complex behav-
ior: spectral methods, in: Proceedings of the 39th IEEE Conference on
Decision and Control (Cat. No. 00CH37187), Vol. 2, IEEE, 2000, pp.
1224–1231.
[20] N. ˇCrnjari´ c- ˇZic, S. Ma´ ceˇ si´ c, I. Mezi´ c, Koopman operator spectrum for
random dynamical systems, Journal of Nonlinear Science 30 (5) (2020)
2007–2056. doi:10.1007/s00332-019-09582-z .
[21] M. Wanner, I. Mezi´ c, Robust approximation of the stochastic Koopman
operator, SIAM Journal on Applied Dynamical Systems 21 (3) (2022)
1930–1951. doi:10.1137/21m1414425 .
21[22] M. J. Colbrook, Q. Li, R. V. Raut, A. Townsend, Beyond expecta-
tions: Residual dynamic mode decomposition and variance for stochas-
tic dynamical systems, arXiv preprint arXiv:2308.10697 (Aug. 2023).
arXiv:2308.10697 ,doi:10.48550/ARXIV.2308.10697 .
[23] M. Budiˇ si´ c, R. Mohr, I. Mezi´ c, Applied Koopmanism, Chaos 22 (4)
(2012) 047510. doi:10.1063/1.4772195 .
[24] S. L. Brunton, M. Budiˇ si´ c, E. Kaiser, J. N. Kutz, Modern Koopman
theory for dynamical systems, SIAM Rev. 64 (2) (2022) 229–340. doi:
10.1137/21m1401243 .
[25] M. J. Colbrook, The Multiverse of Dynamic Mode Decomposition Al-
gorithms, arXiv preprint arXiv:2312.00137 (2023).
[26] I. Mezi´ c, Analysis of fluid flows via spectral properties of the Koopman
operator, Annu. Rev. Fluid Mech. 45 (1) (2013) 357–378. doi:10.1146/
annurev-fluid-011212-140652 .
[27] S. E. Otto, C. W. Rowley, Koopman operators for estimation and control
of dynamical systems, Annu. Rev. Control Robot. Auton. Syst. 4 (1)
(2021) 59–87. doi:10.1146/annurev-control-071020-010108 .
[28] P. J. Schmid, Dynamic mode decomposition and its variants,
Annu. Rev. Fluid Mech. 54 (1) (2022) 225–254. doi:10.1146/
annurev-fluid-030121-015835 .
[29] H. Arbabi, I. Mezi´ c, Ergodic theory, dynamic mode decomposition, and
computation of spectral properties of the Koopman operator, SIAM J.
Appl. Dyn. Syst. 16 (4) (2017) 2096–2126. doi:10.1137/17m1125236 .
[30] M. J. Colbrook, L. J. Ayton, M. Sz˝ oke, Residual dynamic mode decom-
position: Robust and verified Koopmanism, J. Fluid Mech. 955 (2023)
A21. doi:10.1017/jfm.2022.1052 .
[31] M. J. Colbrook, A. Townsend, Rigorous data-driven computation of
spectral properties of Koopman operators for dynamical systems, Com-
mun. Pure Appl. Math. 77 (1) (2023) 221–283. doi:10.1002/cpa.
22125 .
22[32] M. J. Colbrook, C. Drysdale, A. Horning, Rigged dynamic mode de-
composition: Data-driven generalized eigenfunction decompositions for
Koopman operators, arXiv preprint arXiv:2405.00782 (2024).
[33] M. J. Colbrook, The mpEDMD algorithm for data-driven computations
of measure-preserving dynamical systems, SIAM J. Numer. Anal. 61 (3)
(2023) 1585–1608. doi:10.1137/22m1521407 .
[34] S. Das, D. Giannakis, J. Slawinska, Reproducing kernel Hilbert space
compactification of unitary evolution groups, Appl. Comput. Harmon.
Anal. 54 (2021) 75–136. doi:10.1016/j.acha.2021.02.004 .
[35] C. Valva, D. Giannakis, Consistent spectral approximation of
Koopman operators using resolvent compactification, arXiv preprint
arXiv:2309.00732 (2023). doi:10.48550/ARXIV.2309.00732 .
[36] N. Govindarajan, R. Mohr, S. Chandrasekaran, I. Mezi´ c, On the ap-
proximation of Koopman spectra for measure preserving transforma-
tions, SIAM J. Appl. Dyn. Syst. 18 (3) (2019) 1454–1497. doi:
10.1137/18m1175094 .
[37] N. Govindarajan, R. Mohr, S. Chandrasekaran, I. Mezi´ c, On the ap-
proximation of Koopman spectra of measure-preserving flows, SIAM J.
Appl. Dyn. Syst. 20 (1) (2021) 232–261. doi:10.1137/19m1282908 .
[38] M. J. Colbrook, The foundations of infinite-dimensional spectral com-
putations, Ph.D. thesis, University of Cambridge (2020).
[39] J. Ben-Artzi, M. J. Colbrook, A. C. Hansen, O. Nevanlinna, M. Seidel,
Computing spectra–on the solvability complexity index hierarchy and
towers of algorithms, arXiv preprint arXiv:1508.03280 (2015).
[40] A. B¨ ottcher, B. Silbermann, The finite section method for Toeplitz op-
erators on the quarter-plane with piecewise continuous symbols, Math.
Nachr. 110 (1) (1983) 279–291. doi:10.1002/mana.19831100120 .
[41] P. R. Halmos, What does the spectral theorem say?, Am. Math. Mon.
70 (3) (1963) 241–247. doi:10.1080/00029890.1963.11990075 .
[42] J. B. Conway, A course in functional analysis, 2nd Edition, Springer
New York, 2007. doi:10.1007/978-1-4757-4383-8 .
23[43] N. J. Higham, The symmetric Procrustes problem, BIT Numer. Math.
28 (1) (1988) 133–143. doi:10.1007/bf01934701 .
[44] G. H. Golub, C. F. Van Loan, Matrix computations, 3rd Edition, Johns
Hopkins University Press, 1996.
[45] M. J. Colbrook, B. Roman, A. C. Hansen, How to compute spectra with
error control, Physical Review Letters 122 (25) (2019) 250201. doi:
10.1103/physrevlett.122.250201 .
[46] M. J. Colbrook, On the computation of geometric features of spectra
of linear operators on Hilbert spaces, Foundations of Computational
Mathematics (2022) 1–82 doi:10.1007/s10208-022-09598-0 .
[47] M. J. Colbrook, A. C. Hansen, The foundations of spectral computations
via the solvability complexity index hierarchy, Journal of the European
Mathematical Society 25 (12) (2022) 4639–4728. doi:10.4171/jems/
1289.
[48] M. Levitin, E. Shargorodsky, Spectral pollution and second-order rela-
tive spectra for self-adjoint operators, IMA Journal of Numerical Anal-
ysis 24 (3) (2004) 393–416. doi:10.1093/imanum/24.3.393 .
[49] T. Kato, Perturbation Theory for Linear Operators, 2nd Edi-
tion, Vol. 132, Springer Berlin Heidelberg, 1995. doi:10.1007/
978-3-642-66282-9 .
[50] J. Weidmann, Strong operator convergence and spectral theory
of ordinary differential operators, Zeszyty Naukowe-Uniwersytetu
Jagiellonskiego-All Series 1208 (1997) 153–163.
[51] F. Rellich, St¨ orungstheorie der spektralzerlegung. v, Mathematische An-
nalen 118 (1) (1941) 462–484.
[52] E. Charalampidis, P. Kevrekidis, P. E. Farrell, Computing stationary
solutions of the two-dimensional Gross–Pitaevskii equation with deflated
continuation, Commun. Nonlinear Sci. Numer. Simul. 54 (2018) 482–499.
24