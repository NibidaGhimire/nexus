Unbinned Profiled Unfolding
Jay Chan1, 2,∗and Benjamin Nachman2, 3,†
1Department of Physics, University of Wisconsin-Madison, Madison, WI 53706, USA
2Physics Division, Lawrence Berkeley National Laboratory, Berkeley, CA 94720, USA
3Berkeley Institute for Data Science, University of California, Berkeley, CA 94720, USA
(Dated: July 11, 2023)
Unfolding is an important procedure in particle physics experiments which corrects for detec-
tor effects and provides differential cross section measurements that can be used for a number of
downstream tasks, such as extracting fundamental physics parameters. Traditionally, unfolding is
done by discretizing the target phase space into a finite number of bins and is limited in the num-
ber of unfolded variables. Recently, there have been a number of proposals to perform unbinned
unfolding with machine learning. However, none of these methods (like most unfolding methods)
allow for simultaneously constraining (profiling) nuisance parameters. We propose a new machine
learning-based unfolding method that results in an unbinned differential cross section and can profile
nuisance parameters. The machine learning loss function is the full likelihood function, based on
binned inputs at detector-level. We first demonstrate the method with simple Gaussian examples
and then show the impact on a simulated Higgs boson cross section measurement.
I. INTRODUCTION
One of the most common analysis goals in particle and
nuclear physics is the measurement of differential cross
sections. These quantities encode the rate at which a par-
ticular process occurs as a function of certain observables
of interest. From measured cross sections, a number of
downstream inference tasks can be performed, including
the estimation of fundamental parameters, tuning simu-
lations, and searching for physics beyond the Standard
Model. The key challenge of cross section measurements
is correcting the data for detector distortions, a process
called deconvolution or unfolding . See Refs. [1–4] for re-
cent reviews on unfolding and Refs. [5–7] for the most
widely-used unfolding algorithms.
Until recently, all cross section measurements were per-
formed with histograms. In particular, the target spectra
and experimental observations were binned and the un-
folding problem is recast in the language of linear algebra.
That is, one would like to determine the signal strength,
defined as the ratio of the observed signal yield to the
theoretical prediction, for each bin based on the measure-
ments from experimental observations. This approach
comes with the limitation that the binning must be de-
termined beforehand. This makes it difficult to compare
measurements with different binning. Furthermore, the
optimal binning depends on the downstream inference
task.
Modern machine learning (ML) has enabled the cre-
ation of unfolding methods that can process unbinned
data [8]. Deep generative models such as Generative
Adversarial Networks (GAN) [9–11] and Variational Au-
toencoders (VAE) [12, 13] produce implicit models that
represents the probability density of the unfolded result
∗cchan62@wisc.edu
†bpnachman@lbl.govand allow to sample from the probability density. Meth-
ods based on Normalizing Flows (NF) [14–17] allow for
both sampling and density estimation. In contrast, the
classifier-based method OmniFold Refs. [18, 19] itera-
tively reweights a simulated dataset. A summary of ma-
chine learning-based unfolding methods can be found in
Ref. [8] and recent applications of these techniques (in
particular, of OmniFold) to experimental data are pre-
sented in Refs. [20–23]. While powerful, none of these
approaches can simultaneously estimate cross sections
and fit (nuisance) parameters. This can be a significant
shortcoming when the phase space region being probed
has non-trivial constraining power for systematic uncer-
tainties.
Unfolding methods that can also profile have been pro-
posed. One possibility is to treat the cross section in each
region of particle-level phase space (i.e. in a histogram
bin) as a free parameter and then perform a likelihood
fit as for any set of parameters of interest and nuisance
parameters. For example, this is the setup of the the Sim-
plified Template Cross Section (STXS) (e.g. Refs. [24–
27]) measurements for Higgs boson kinematic properties.
Another possibility is Fully Bayesian Unfolding (FBU)
[28], which samples from the posterior probability over
the cross section in each bin of the particle-level phase
space and over the nuisance parameters. All of these
methods require binning.
In this paper, we propose a new machine learning-
based unfolding method that is both unbinned at particle
level and can profile, referred to as Unbinned Profiled Un-
folding (UPU). UPU reuses all the standard techniques
used in binned maximum likelihood unfolding and com-
bines them with ML methods that allow for unbinned
unfolding. Specifically, we use the binned maximum like-
lihood at detector level as the metric to optimize the un-
folding, while the unfolding takes unbinned particle-level
simulations as inputs.
The rest of this paper is organized as follows. In Sec. II,
we describe the procedure and implementation detailsarXiv:2302.05390v3  [hep-ph]  7 Jul 20232
of UPU. We then present simple Gaussian examples to
demonstrate the usage of UPU in Sec. III. In Sec. IV,
we apply UPU to a simulated Higgs boson cross section
measurement at the Large Hadron Collider (LHC). The
conclusions and outlook are then given in Sec. V.
II. UNBINNED PROFILED UNFOLDING
A. Statistical Setup
UPU generalizes binned maximum likelihood unfold-
ing to the unbinned case. Binned maximum likelihood
unfolding can be described by the following optimization
setup:
(ˆk,ˆθ) = argmax(k,θ)Pr(m|k, θ)p0(θ), (1)
where m∈RNmis a vector representing the counts in
each of the Nmbins at detector level, k∈RNkis a vector
representing the counts in each of the Nkbins at particle
level (usually Nm≥Nk),θare the nuisance parameters,
andp0is the prior on θ. Our idea is to keep the structure
of Eq. 1, but replace kwith an unbinned estimator of the
particle-level spectrum. Suppose that the particle-level
phase space is1RNand let2τ[ω]∈RRNparameterize
the probability density over this space for parameters ω.
The goal of UPU is then to optimize
(ˆω,ˆθ) = argmax(ω,θ)Pr(m|τ[ω], θ)p0(θ), (2)
where the final result would be given by τ[ˆω]. The chal-
lenge with the construction in Eq. 2 is that for a given
truth spectrum τ[ω], we need to know the predicted
detector-level distribution. In the binned case, this is
readily computed by multiplying kby the response ma-
trixRij= Pr(measure in bin i|truth is bin j). When the
truth are unbinned, we need the full detector response.
This is never known analytically and would be challeng-
ing to estimate numerically with a surrogate density es-
timator3. To address this challenge, we make use of the
fact that simulated events come in pairs, with a matching
between particle-level and detector-level events. Instead
of estimating τdirectly, we use a fixed simulation (with
particle-level spectrum τ[ω0]) and then learn a reweight-
ing function w0[λ] to estimate the likelihood ratio be-
tween the unfolded result and the fixed simulation at
1Assuming the space is suitably standardized to remove units.
2We will use [ ·] to denote the parameters of the function and ( ·)
to denote the inputs of the function, e.g. f[θ](x) is a functional
inθand a function in x.
3Note that Eq. 2 is a probability distribution over probability
distributions so building it from the per-event detector response
is non-trivial.particle level. Schematically:
(ˆλ,ˆθ) = argmax(λ,θ)Pr(m|τ[ω0]w0[λ], θ)p0(θ),(3)
where in practice, we only have samples from τ[ω0] and
w0is a surrogate model. The number of predicted
events in a given bin iis then a sum over weights w0[ˆλ]
(evaluated at particle-level) for simulated events with a
detector-level value in bin i. The probability over values
mis then a product over Poisson probability mass func-
tions, since the bins are statistically independent. The
fact that the probability mass is known is crucial and
means that UPU does not readily generalize the case
where the detector-level phase space is also unbinned.
This is the case for OmniFold, which also uses reweight-
ing at particle-level. In contrast to UPU, OmniFold
uses an Expectation-Maximization-type algorithm to it-
eratively converge to the maximum likelihood estimate
and does not currently allow for mixed implicit/explicit
likelihood constraints (as is needed for nuisance parame-
ters).
B. Machine Learning Approach
For particle-level features Tand detector-level features
R, the main goal is to train the likelihood ratio estima-
torw0(T), which reweights the simulated particle-level
spectrum. In the absence of profiling, this corresponds
to the following loss function:
L=nbinsY
i=1Pr
ninMCX
j=1w0(Tj)Ii(Rj)
, (4)
where niis the number of observed events in bin i,nMC
is the number of simulated events, and Ii(·) is the in-
dicator function that is one when ·is in bin iand zero
otherwise. When w0is parameterized as a neural net-
work (see Sec. II C), then the logarithm of Eq. 4 is used
for training:
logL= (5)
nbinsX
i=1
nilog
nMCX
j=1w0(Tj)Ii(Rj)
−nMCX
i=1w0(Tj)Ii(Rj)
,
where we have dropped constants that do not affect the
optimization. Experimental nuisance parameters modify
the predicted counts in a particular bin given the particle-
level counts. We account for these effects with a second
reweighting function:
w1(R|T, θ) =pθ(R|T)
pθ0(R|T), (6)3
TABLE I. Summary of Gaussian example data sets.
Data set Parameters Number of events Purpose
D1.0
sim µ= 0,σ= 1 and ϵ= 1 200,000 Nominal simulation
Dobs µ= 0.8,σ= 1 and ϵ= 1.2 100,000 Observed data
D∗
sim µ= 0,σ= 1 and ϵ= (0.2,1.8) 200,000 Train w1
D1.2
sim µ= 0,σ= 1 and ϵ= 1.2 100,000 Validate w1
where pθ(R|T) is the conditional probability density of
Rgiven Twith nuisance parameters θ. Importantly, w1
does not modify the target particle level distribution. In-
corporating w1into the log likelihood results in the full
loss function:
logL=nbinsX
i=1"
nilog
nMCX
j=1w0(Tj)w1(Rj|Tj, θ)Ii(Rj)

−nMCX
j=1w0(Tj)w1(Rj|Tj, θ)Ii(Rj)#
+ log p0(θ).
(7)
Since w1does not depend on the particle-level spec-
trum, it can be estimated prior to the final fit and only
the parameters of w0and the value(s) of θare allowed to
float when optimizing Eq. 7.
C. Machine Learning Implementation
In our subsequent case studies, the reweighting func-
tions w0andw1are parametrized with neural networks.
Thew0function is only constrained to be non-negative
and so we choose it to be the exponential of a neural
network.
The pre-training of w1requires neural conditional
reweighting [29], as a likelihood ratio in Rconditioned
onTand parameterized in θ. While there are multiple
ways of approximating conditional likelihood ratios, the
one we found to be the most stable for the examples we
have studied for UPU is the product approach:
w1(R|T, θ) =pθ(R, T)
pθ0(R, T)pθ0(T)
pθ(T)
, (8)
where the two terms on the righthand side are separately
estimated and then their product is w1. For a single fea-
tureT, a likelihood ratio between samples drawn from a
probability density pand samples drawn from a prob-
ability density qis estimated using the fact that ma-
chine learning-classifiers approximate monotonic trans-
formations of likelihood ratios (see e.g. Ref. [30, 31]). In
particular, we use the standard binary cross entropy loss
functionLBCE[f] =−X
Y∼plog(f(Y))−X
Y∼qlog(1−f(Y)),(9)
and then the likelihood ratio is estimated as f/(1−f).
The last layer of the fnetworks are sigmoids in order
to constrain their range to be between 0 and 1. The
function fis additionally trained to be parameterized in
θby training with pairs ( Y,Θ) instead of just Y, where Θ
is a random variable corresponding to values θsampled
from a prior. We will use a uniform prior when training
the parameterized classifiers.
All neural networks are implemented using PyTorch
[32] and optimized with Adam [33] with a learning rate
of 0.001 and consist of three hidden layers with 50 nodes
per layer. All intermediate layers use ReLU activation
functions. Each network is trained for 10,000 epochs with
early stopping using a patience of 10. The w1training
uses a batch size of 100,000. The w0network is simul-
taneously optimized with θand uses a batch size that is
the full dataset, which corresponds to performing the fit
in Eq. 7 over all the data. All neural networks are imple-
mented using PyTorch [32] and optimized with Adam [33]
with a learning rate of 0.001 and consist of three hidden
layers with 50 nodes per layer. All intermediate layers
use ReLU activation functions. Each network is trained
for 10,000 epochs with early stopping using a patience of
10. The w1training uses a batch size of 100,000. The
w0network is simultaneously optimized with θand uses
a batch size that is the full dataset, which corresponds
to performing the fit in Eq. 7 over all the data.
III. GAUSSIAN EXAMPLE
We now demonstrate the proposed method with a sim-
ple numerical example. Here, each data set represents
a one-dimension Gaussian distribution in the particle
level and a two-dimension distribution in the detector
level. The particle-level Gaussian random variable Tis
described by mean µand standard deviation σ, while the
detector-level variables are given by
R=T+Z, (10)
R∗=T+Z∗, (11)
where Z(Z∗) is a Gaussian random variable with mean
β(β∗) and standard deviation ϵ(ϵ∗).ϵis considered to4
be the only nuisance parameter, and β,β∗are fixed to 0,
andϵ∗is fixed to 1. In this case, the nuisance parameter
ϵonly has effect on the Rspectrum and the R∗spectrum
depends purely on the particle-level spectrum T. This
setup is thus sensitive to both the effect of w0and that
ofw14.
Three data sets are prepared for the full training pro-
cedure. As summarized in Tab. I, the first data set D1.0
sim
is used as the nominal simulation sample, which contains
200,000 events with µ= 0,σ= 1 and ϵ= 1. The second
data set Dobsis used as the observed data, which contains
100,000 events with µ= 0.8,σ= 1 and ϵ= 1.2. To train
thew1reweighter, the third data set D∗
sim, which con-
tains 200,000 events with µ= 0, σ= 1 and ϵuniformly
distributed from 0.2 to 1.8, is prepared and used as the
simulation with systematic variations. In addition, an-
other data set D1.2
simof 100,000 events with µ= 0, σ= 1
andϵ= 1.2 is produced for validating the w1reweighter.
All data sets used in the training procedure are split to
50% for training and 50% for validating.
Aw1reweighter is trained to reweight D1.0
simtoD∗
sim.
The trained w1is tested with the nominal RandR∗
spectra ( D1.0
sim) reweighted to ϵ= 1.2 and compared to
theRandR∗spectra with ϵ= 1.2. As shown in Fig.
1, the trained w1reweighter has learned to reweight the
nominal Rspectrum to match the Rspectrum with ϵat
1.2, and R∗is independent of the w1reweighter.
Based on the trained w1reweighter, a w0reweighter
and the nuisance parameter ϵare optimized simultane-
ously using Dsimas the simulation template with Dobsas
the observed data used in Eq. 7. The prior in the penalty
term in Eq. 7 is configured with an uncertainty of 80%.
The fitted ϵis 1.20±0.0045(correct value is 1.2). As
shown in Fig. 2, the reweighted spectra match well with
observed data in both detector and particle level. For
more realistic uncertainties (so long as the simulation is
close to the right answer), the fidelity is even better.
IV. HIGGS BOSON CROSS SECTION
We now demonstrate the unfolding method in a physics
case — a Higgs boson cross section measurement. Here,
we focus on the di-photon decay channel of the Higgs bo-
son. The goal is then to measure the transverse momen-
tum spectrum of the Higgs boson pT
Husing the transverse
momentum of the di-photon system pT
γγat detector level.
4An ill-defined example is shown in App. A, where the considered
detector-level observable, a one-dimension Gaussian distribution,
is not able to distinguish between effects from particle level and
effects from detector level with θ. This limitation also exists in
the standard binned maximum likelihood unfolding, as shown in
App. B
5The fitted value is averaged over five different w0reweighters
which are trained in the same way, but with different random
initializations. The standard deviation of the fitted values is
taken as the error.The photon resolution ϵγis considered as a nuisance pa-
rameter. In this case, the pT
γγspectrum is minimally
affected by ϵγ. Therefore, we also consider the invariant
mass spectrum of the di-photon system mγγat detector
level, which is highly sensitive to ϵγ. In addition, In order
to have a large spectrum difference between different data
sets for demonstration purpose, we consider only events
that contain at least two reconstructed jets, where the
leading-order (LO) calculation would significantly differ
from next-to-leading-order calculation (NLO)
Similar to the Gaussian examples, we prepare the fol-
lowing data sets:
•Dobs: used as the observed data.
•D1.0
sim: used as the nominal simulation sample.
•D1.2
sim: used as the simulation sample with a system-
atic variation.
•D∗
sim: simulation sample with various ϵγvalues for
training the w1reweighter.
Dobsis generated at NLO using the PowhegBox pro-
gram [34, 35], while the rest are generated at LO us-
ingMadGraph 5aMC@LO v2.6.5 [36]. For all sam-
ples, the parton-level events are processed by Pythia
8.235 [37, 38] for the Higgs decay, the parton shower,
hadronization, and the underlying event. The detector
simulation is based on Delphes 3.5.0 [39] with detec-
tor response modified from the default ATLAS detector
card. For both DobsandD1.2
sim, the photon resolution ϵis
multiplied by a factor of 1.2. For D∗
sim, the multiplier of
ϵis uniformly scanned between 0.5 and 1.5 with a step
size of 0.01. D1.0
simuses the default ATLAS detector card.
Each of the spectra of particle-level pT
γγ, detector-level
pT
γγand detector-level mγγis standardized to the spec-
trum with a mean of 0 and a standard deviation of
1 before being passed to the neural networks. A w1
reweighter is then trained to reweight D1.0
simtoD∗
sim. The
trained w1is tested with the nominal detector level pT
γγ
andmγγspectra ( D1.0
sim) reweighted to ϵγ= 1.2 and com-
pared to the detector level pT
γγandmγγspectra with
ϵγ= 1.2. As shown in Fig. 3, the trained w1reweighter
has learned to reweight the nominal detector level mγγ
spectrum to match the detector level mγγspectrum with
ϵγat 1.2, and the detector level pT
γγvariable is indepen-
dent of the w1reweighter.
Thew0reweighter and ϵare optimized simultaneously
based on the pre-trained w1reweighter. The prior of ϵγis
50%. The fitted ϵγis 1.19±0.007. As shown in Fig. 4, the
reweighted spectra match well with observed data in both
detector and particle level. This means that the observed
data pT
Hspectrum is successfully unfolded with nuisance
parameter ϵγproperly profiled. For comparison, we also
perform UPU with ϵγfixed at 1. As shown in Fig. 4,
the unfolded pT
Hspectrum in this case has a larger non-
closure with the observed data due to the lack of profiling.5
6
 4
 2
 0 2 4 0200040006000EventsGaussian 2D example
=1.2 (target)
=1
=1 (w1 rw.)
6
 4
 2
 0 2 4
R0.81.01.2Result/Target
6
 4
 2
 0 2 4 0200040006000EventsGaussian 2D example
=1.2 (target)
=1
=1 (w1 rw.)
6
 4
 2
 0 2 4
R*0.81.01.2Result/Target
FIG. 1. Gaussian 2D example: the nominal detector-level spectra R(left) and R∗(right) with ϵ= 1 reweighted by the trained
w1conditioned at ϵ= 1.2 and compared to the spectra with ϵ= 1.2. The shaded band in the bottom panel represents the data
statistical uncertainty, which is estimated as 1 /√n, where nis the number of D1.2
simevents in a given bin.
V. CONCLUSION AND OUTLOOK
In this paper, we proposed Unbinned Profiled Unfold-
ing (UPU), a new ML-based unfolding method that can
process unbinned data and profile. The method uses the
binned maximum likelihood as the figure of merit to op-
timize the unfolding reweighting function w0(t), which
takes unbinned particle-level spectra as inputs. w0(t)
and the nuisance parameters θare optimized simultane-
ously, which also requires to learn a conditional likelihood
ratio w1(t, r|θ) that reweights the detector-level spectra
based on the profiled values of nuisance parameters and
is taken as an input for the optimization of w0(t) and θ.
In the Gaussian example, we demonstrated the op-
timization of w1and the optimization of w0and θ.
The setup considers one dimension in the particle level
and two dimension in the detector level. The addi-
tional detector-level observable which does not depend
onθbreaks the degeneracy between particle-level and
detector-level effects and thus allows for optimization of
w1andθat the same time.
We also applied UPU to the Higgs boson cross sec-
tion measurement. We considered one dimension at par-
ticle level and two dimensions at detector level. With
one detector-level variable sensitive to the target particle-
level observable and one sensitive to the effect of nuisance
parameters, the data are successfully unfolded and pro-
filed. The impact of profiling is also demonstrated by
comparing with the result of nuisance parameter fixed
to the nominal value. This can be readily extended to
higher dimensions in either particle level or detector level,
provided all particle-level and detector-level effects are
distinguishable in the considered detector-level spectra.In the case of more than one nuisance parameters, one
can either train multiple w1for each nuisance parameter
separately or train a single w1which takes all nuisance
parameters as inputs. As the effects of multiple nuisance
parameters are usually assumed independent, one could
take a product of individually trained reweighters.
As with any measurement, quantifying the uncertainty
is critical to interpret UPU results. Just as in the binned
case, one can calculate the uncertainty on the nuisance
parameters which can be determined by fixing a given
parameter to target values and then simultaneously re-
optimizing w0and the rest of the nuisance parameters.
A new feature of UPU is that the likelihood (ratio) itself
is only an approximation, using neural networks as surro-
gate models. This is a challenge for all machine learning-
based unfolding, and uncertainties can be probed by com-
paring the results with different simulations. Future ex-
tensions of UPU may be able to also use machine learning
to quantify these model uncertainties as well as process
unbinned data also at detector level.
CODE AND DATA
The code for this paper can be found at
https://github.com/qwerasd903/UnbinnedProfiledUnfolding,
which uses Jupyter notebooks [40] and employs NumPy
[41] for data manipulation and Matplotlib [42] for
visualization. All of the machine learning was performed
on an NVIDIA A100 Graphical Processing Unit (GPU)
and reproducing the entire notebook takes about 13
hours. The physics data sets are hosted on Zenodo at
Ref. [43].6
10
 8
 6
 4
 2
 0 2 4 02000400060008000EventsGaussian 2D example
Data
Sim
Rw. (=1.20)
10.0
 7.5
 5.0
 2.5
 0.0 2.5 5.0
R0.81.01.2Result/Data
10
 8
 6
 4
 2
 0 2 4 02000400060008000EventsGaussian 2D example
Data
Sim
Rw. (=1.20)
10.0
 7.5
 5.0
 2.5
 0.0 2.5 5.0
R*0.81.01.2Result/Data
6
 4
 2
 0 2 4 0200040006000800010000EventsGaussian 2D example
Data
Sim
Rw. (=1.20)
6
 4
 2
 0 2 4
T0.81.01.2Result/Data
FIG. 2. Gaussian 2D example: results of the w0optimization. The nuisance parameter ϵis optimized simultaneously with w0
with the prior constraint set to 80%. The fitted ϵis 1.20±0.004. (Top-left) The detector-level spectrum Rof the simulation
template Dsimreweighted by the trained w0×w1, compared to the Rspectrum of the observed data Dobs. (Top-right) The
detector-level spectrum R′of the simulation template Dsimreweighted by the trained w0×w1, compared to the R∗spectrum of
the observed data Dobs. (Bottom) The particle-level spectrum Tof the simulation template Dsimreweighted by the trained w0,
compared to the Tspectrum of the observed data Dobs. The shaded band in the bottom panel represents the data statistical
uncertainty, which is estimated as 1 /√n, where nis the number of observed events in a given bin.
ACKNOWLEDGMENTS
We thank A. Ghosh, V. Mikuni, J. Thaler, D. White-
son and S. L. Wu for helpful discussions and detailed
feedback on the manuscript. BN is supported by the U.S.
Department of Energy (DOE), Office of Science under
contract DE-AC02-05CH11231. JC is supported by the
U.S. Department of Energy (DOE), Office of Science un-
der contracts DE-AC02-05CH11231 and DE-SC0017647.Appendix A: Gaussian example with one-dimension
in both particle and detector level
In this appendix, we apply UPU to the Gaussian ex-
ample where each data set represents one-dimensional
Gaussian random variables in both the particle and de-
tector level. The particle-level random variable Tis de-
scribed by mean µand standard deviation σ, while the
detector-level variable is given by
R=T+Z, (A1)7
118 120 122 124 126 128 130 0200004000060000EventsggF Higgs nj2
=1.2 (target)
=1
=1 (w1 rw.)
118 120 122 124 126 128 130
Reco m
0.80.91.01.11.2Result/T arget
0 25 50 75 100 125 150 175 200 0200004000060000EventsggF Higgs nj2
=1.2 (target)
=1
=1 (w1 rw.)
0 50 100 150 200
Reco pT
0.80.91.01.11.2Result/T arget
FIG. 3. Higgs boson cross section: the nominal detector-level spectra mγγ(left) and pT
γγ(right) with ϵγ= 1 reweighted by
the trained w1conditioned at ϵγ= 1.2 and compared to the spectra with ϵγ= 1.2. The shaded band in the bottom panel
represents the data statistical uncertainty, which is estimated as 1 /√n, where nis the number of D1.2
simevents in a given bin.
where Zis a Gaussian random variable with mean βand
standard deviation ϵ.
ϵis considered to be the only nuisance parameter, and
βis fixed to 0. Similar to the setup in Sec. III, three data
sets are prepared for the full training procedure:
•D1.0
sim: 200,000 events with µ= 0,σ= 1 and ϵ= 1
•Dobs: 100,000 events with µ= 0.2,σ= 1 and
ϵ= 1.2
•D∗
sim: 200,000 events with µ= 0, σ= 1 and ϵ
uniformly distributed from 0.2 to 1.8.
•D1.2
sim: 100,000 events with µ= 0,σ= 1 and ϵ= 1.2.
Aw1reweighter is trained to reweight D1.0
simtoD∗
sim.
The trained w1is then tested with the nominal Rdistri-
bution ( D1.0
sim) reweighted to ϵ= 1.2 (w1(R|T, ϵ= 1.2))
and compared to the Rspectrum with ϵ= 1.2 (D1.2
sim). As
shown in Fig. 5, the trained w1reweighter has learned to
reweight the nominal Rspectrum to match the Rspec-
trum with ϵat 1.2.
With this trained w1reweighter, a w0reweighter is
trained using D1.0
simas the simulation template with Dobs
as the observed data used in Eq. 7. In the first scenario,
the nuisance parameter ϵfor the w1reweighter is fixed
to 1.2, and the penalty term in Eq. 7 log( θ) is set to 0
(no constraint). As shown in Fig. 6, the w0reweighter is
able to learn to reweight the particle-level spectrum Tby
matching the detector-level spectrum Rto the observed
spectrum. In the second scenario, the nuisance param-
eterϵis trained together with the w0reweighter. The
prior in the penalty term in Eq. 7 is set to be a Gaussian
probability density with a 80% uncertainty. As shownin Fig. 7, the trained w0and optimized ϵare tested.
The fitted ϵis 1.03±0.0166(true value is 1.2). The
reweighted distribution matches well with observed data
in the detector-level spectrum but the particle-level spec-
trum has a large non-closure. This is because of the de-
generacy between the w0andw1reweighters in the effect
on the detector-level spectrum. In other words, detector
effects can mimic changes in the particle-level cross sec-
tion, so the data cannot distinguish between these two
scenarios. This is a common issue which also exists in
the standard binned maximum likelihood unfolding. For
comparison, we also perform the standard binned max-
imum likelihood unfolding. As shown in App. B, the
unfolded Tspectrum in this case also fails to represent
the true Tspectrum. An 80% uncertainty is highly ex-
aggerated from typical scenarios, but it clearly illustrates
the challenge of profiling and unfolding at the same time.
Appendix B: Binned maximum likelihood unfolding
with Gaussian examples
In this appendix, we present results of the standard
binned maximum likelihood unfolding (BMLU) with
Gaussian examples. The scenarios are:
•One-dimension in both particle and detector level:
this is the same example as described in App. A.
6The fitted value is averaged over five different w0reweighters
which are trained in the same way, but with different random
initializations. The standard deviation of the fitted values is
taken as the error.8
116 118 120 122 124 126 128 130 02000400060008000EventsggF Higgs nj2
Data
Sim
Rw. (=1.19)
Rw. (1)
115.0 117.5 120.0 122.5 125.0 127.5 130.0
Reco m [GeV]
0.81.01.2Result/Data
0 25 50 75 100 125 150 175 200 02000400060008000EventsggF Higgs nj2
Data
Sim
Rw. (=1.19)
Rw. (1)
0 50 100 150 200
Reco pT [GeV]
0.81.01.2Result/Data
0 25 50 75 100 125 150 175 200 02000400060008000EventsggF Higgs nj2
Data
Sim
Rw. (=1.19)
Rw. (1)
0 50 100 150 200
Truth pT [GeV]
0.81.01.2Result/Data
FIG. 4. Higgs boson cross section: results of the w0optimization. The nuisance parameter ϵγis optimized simultaneously with
w0with the prior constraint set to 50% (orange) or fixed to 1 for comparison (red). The fitted ϵγis 1.19±0.007. (Top-left)
The detector-level spectrum mγγof the simulation template Dsimreweighted by the trained w0×w1, compared to the mγγ
spectrum of the observed data Dobs. (Top-right) The detector-level spectrum pT
γγof the simulation template Dsimreweighted
by the trained w0×w1, compared to the pT
γγspectrum of the observed data Dobs. (Bottom) The particle-level spectrum pT
γγ
of the simulation template Dsimreweighted by the trained w0, compared to the pT
γγspectrum of the observed data Dobs. The
shaded band in the bottom panel represents the data statistical uncertainty, which is estimated as 1 /√n, where nis the number
of observed events in a given bin.
The prior constraint for ϵis set to 80%. The re-
sult is shown in Fig. 8 with ϵfitted to 1 .08±0.02,
which also indicates a degeneracy problem between
particle and detector levels.
•One-dimension in particle level and two-dimension
in detector level: this is the same example as de-
scribed in Sec. III. The prior constraint for ϵis setto 80%. The result is shown in Fig. 9 with ϵfitted
to 1.19±0.003. The degeneracy problem is resolved
after considering an additional spectrum in the de-
tector level.
All the maximum likelihood fittings are performed
using pyhf [44, 45].
[1] G. Cowan, A survey of unfolding methods for particle
physics, Conf. Proc. C 0203181 , 248 (2002).[2] V. Blobel, Unfolding Methods in Particle Physics, PHY-
STAT2011 Proceedings , 240 (2011).9
6
 4
 2
 0 2 4 0200040006000EventsGaussian 1D Example
=1.2 (target)
=1
=1 (w1 rw.)
6
 4
 2
 0 2 4
R0.80.91.01.11.2Result/T arget
FIG. 5. Gaussian 1D example: the nominal Rdistribution
(ϵ= 1) reweighted by the trained w1conditioned at ϵ= 1.2
and compared to Rdistribution with ϵ= 1.2. The shaded
band in the bottom panel represents the data statistical un-
certainty, which is estimated as 1 /√n, where nis the number
ofD1.2
simevents in a given bin.
[3] V. Blobel, Unfolding, Data Analysis in High Energy
Physics , 187 (2013).
[4] R. Balasubramanian, L. Brenner, C. Burgard, G. Cowan,
V. Croft, W. Verkerke, and P. Verschuuren, Statistical
method and comparison of different unfolding techniques
using RooFit, (2019), arXiv:1910.14654 [physics.data-
an].
[5] G. D’Agostini, A Multidimensional unfolding method
based on Bayes’ theorem, Nucl. Instrum. Meth. A362 ,
487 (1995).
[6] A. Hocker and V. Kartvelishvili, SVD approach to
data unfolding, Nucl. Instrum. Meth. A372 , 469 (1996),
arXiv:hep-ph/9509307 [hep-ph].
[7] S. Schmitt, TUnfold: an algorithm for correcting migra-
tion effects in high energy physics, JINST 7, T10003,
arXiv:1205.6201 [physics.data-an].
[8] M. Arratia et al. , Publishing unbinned differential cross
section results, JINST 17(01), P01024, arXiv:2109.13243
[hep-ph].
[9] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu,
D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio,
Generative adversarial nets, in Proceedings of the 27th In-
ternational Conference on Neural Information Processing
Systems - Volume 2 , NIPS’14 (MIT Press, Cambridge,
MA, USA, 2014) pp. 2672–2680.
[10] K. Datta, D. Kar, and D. Roy, Unfolding with Gener-
ative Adversarial Networks, (2018), arXiv:1806.00433
[physics.data-an].
[11] M. Bellagente, A. Butter, G. Kasieczka, T. Plehn, and
R. Winterhalder, How to GAN away Detector Effects,
(2019), arXiv:1912.00477 [hep-ph].
[12] D. P. Kingma and M. Welling, Auto-encoding variational
bayes, (2014), arXiv:1312.6114 [stat.ML].
8
 6
 4
 2
 0 2 4 02000400060008000EventsGaussian 1D Example
Data
Sim
Rw. (1.2)
7.5
 5.0
 2.5
 0.0 2.5 5.0
R0.80.91.01.11.2Result/Data
6
 4
 2
 0 2 4 0200040006000800010000EventsGaussian 1D Example
Data
Sim
Rw. (1.2)
6
 4
 2
 0 2 4
T0.80.91.01.11.2Result/DataFIG. 6. Gaussian 1D example: results of the w0optimization.
The nuisance parameter ϵis fixed to 1.2, and the the penalty
term in Eq. 7 is set to 0. (Top) The detector-level spectrum
Rof the simulation template Dsimreweighted by the trained
w0×w1, compared to the Rspectrum of the observed data
Dobs. (Bottom) The particle-level spectrum Tof the simula-
tion template Dsimreweighted by the trained w0, compared
to the Tspectrum of the observed data Dobs. The shaded
band in the bottom panel represents the data statistical un-
certainty, which is estimated as 1 /√n, where nis the number
of observed events in a given bin.
[13] J. N. Howard, S. Mandt, D. Whiteson, and Y. Yang,
Foundations of a Fast, Data-Driven, Machine-Learned
Simulator, (2021), arXiv:2101.08944 [hep-ph].
[14] D. J. Rezende and S. Mohamed, Variational inference
with normalizing flows, International Conference on Ma-
chine Learning 37, 1530 (2015).
[15] M. Bellagente, A. Butter, G. Kasieczka, T. Plehn,
A. Rousselot, R. Winterhalder, L. Ardizzone, and
U. K¨ othe, Invertible Networks or Partons to Detec-10
8
 6
 4
 2
 0 2 4 02000400060008000EventsGaussian 1D Example
Data
Sim
Rw. (=1.03)
7.5
 5.0
 2.5
 0.0 2.5 5.0
R0.80.91.01.11.2Result/Data
6
 4
 2
 0 2 4 0200040006000800010000EventsGaussian 1D Example
Data
Sim
Rw. (=1.03)
6
 4
 2
 0 2 4
T0.80.91.01.11.2Result/Data
FIG. 7. Gaussian 1D example: results of the w0optimization. The nuisance parameter ϵis optimized simultaneously with w0
and the best-fit value is ˆ ϵ= 1.03±0.016. (Left) The detector-level spectrum Rof the simulation template Dsimreweighted
by the trained w0×w1, compared to the Rspectrum of the observed data Dobs. (Right) The particle-level spectrum Tof the
simulation template Dsimreweighted by the trained w0, compared to the Tspectrum of the observed data Dobs. The shaded
band in the bottom panel represents the data statistical uncertainty, which is estimated as 1 /√n, where nis the number of
observed events in a given bin.
8
 6
 4
 2
 0 2 4 01000020000300004000050000EventsGaussian 1D example
Data
Sim
BMLU (=1.08)
7.5
 5.0
 2.5
 0.0 2.5 5.0
R0.80.91.01.11.2Result/Data
8
 6
 4
 2
 0 2 4 0200004000060000EventsGaussian 1D example
Data
Sim
BMLU (=1.08)
7.5
 5.0
 2.5
 0.0 2.5 5.0
T0.80.91.01.11.2Result/Data
FIG. 8. Gaussian 1D example: results of the binned maximum likelihood unfolding. The prior constraint for ϵis set to 80%
and the fitted ϵis 1.08±0.02. (Left) The fitted detector-level spectrum Rof the simulation template Dsim, compared to the R
spectrum of the observed data Dobs. (Right) The unfolded particle-level spectrum Tof the simulation template Dsim, compared
to the Tspectrum of the observed data Dobs. The shaded band in the bottom panel represents the data statistical uncertainty,
which is estimated as 1 /√n, where nis the number of observed events in a given bin.
tor and Back Again, SciPost Phys. 9, 074 (2020),
arXiv:2006.06685 [hep-ph].
[16] M. Vandegar, M. Kagan, A. Wehenkel, and G. Louppe,
Neural Empirical Bayes: Source Distribution Estima-
tion and its Applications to Simulation-Based Inference,
inProceedings of The 24th International Conference onArtificial Intelligence and Statistics , Proceedings of Ma-
chine Learning Research, Vol. 130, edited by A. Baner-
jee and K. Fukumizu (PMLR, 2021) pp. 2107–2115,
arXiv:2011.05836 [stat.ML].
[17] M. Backes, A. Butter, M. Dunford, and B. Malaescu, An
unfolding method based on conditional Invertible Neu-11
8
 6
 4
 2
 0 2 4 01000020000300004000050000EventsGaussian 2D example
Data
Sim
BMLU (=1.19)
7.5
 5.0
 2.5
 0.0 2.5 5.0
R0.81.01.2Result/Data
8
 6
 4
 2
 0 2 4 01000020000300004000050000EventsGaussian 2D example
Data
Sim
BMLU (=1.19)
7.5
 5.0
 2.5
 0.0 2.5 5.0
R*0.81.01.2Result/Data
8
 6
 4
 2
 0 2 4 0200004000060000EventsGaussian 2D example
Data
Sim
BMLU (=1.19)
7.5
 5.0
 2.5
 0.0 2.5 5.0
T0.81.01.2Result/Data
FIG. 9. Gaussian 2D example: results of the binned maximum likelihood unfolding. The prior constraint for ϵis set to 80%
and the fitted ϵis 1.19±0.003. (Top-left) The fitted detector-level spectrum Rof the simulation template Dsim, compared to
theRspectrum of the observed data Dobs. (Top-right) The fitted detector-level spectrum R∗of the simulation template Dsim,
compared to the R′spectrum of the observed data Dobs. (Bottom) The unfolded particle-level spectrum Tof the simulation
template Dsim, compared to the Tspectrum of the observed data Dobs. The shaded band in the bottom panel represents the
data statistical uncertainty, which is estimated as 1 /√n, where nis the number of observed events in a given bin.
ral Networks (cINN) using iterative training, (2022),
arXiv:2212.08674 [hep-ph].
[18] A. Andreassen, P. T. Komiske, E. M. Metodiev, B. Nach-
man, and J. Thaler, OmniFold: A Method to Simulta-
neously Unfold All Observables, Phys. Rev. Lett. 124,
182001 (2020), arXiv:1911.09107 [hep-ph].
[19] A. Andreassen, P. T. Komiske, E. M. Metodiev, B. Nach-
man, A. Suresh, and J. Thaler, Scaffolding Simulations
with Deep Learning for High-dimensional Deconvolution,
in9th International Conference on Learning Representa-
tions (2021) arXiv:2105.04448 [stat.ML].
[20] H1 Collaboration, Measurement of Lepton-Jet Correla-
tion in Deep-Inelastic Scattering with the H1 Detector
Using Machine Learning for Unfolding, Phys. Rev. Lett.
128, 132002 (2022), arXiv:2108.12376 [hep-ex].[21] V. Andreev et al. (H1), Measurement of Lepton-Jet Cor-
relation in Deep-Inelastic Scattering with the H1 Detec-
tor Using Machine Learning for Unfolding, Phys. Rev.
Lett. 128, 132002 (2022), arXiv:2108.12376 [hep-ex].
[22] H1 Collaboration, Multi-differential Jet Substructure
Measurement in High Q2DIS Events with HERA-II
Data, H1prelim-22-034 (2022).
[23] LHCb Collaboration, Multidifferential study of identified
charged hadron distributions in Z-tagged jets in proton-
proton collisions at√s=13 TeV, arXiv:2208.11691
(2022).
[24] D. de Florian et al. (LHC Higgs Cross Section Working
Group), Handbook of LHC Higgs Cross Sections: 4.
Deciphering the Nature of the Higgs Sector 2/2017 ,
10.23731/CYRM-2017-002 (2016), arXiv:1610.0792212
[hep-ph].
[25] J. R. Andersen et al. , Les Houches 2015: Physics at
TeV Colliders Standard Model Working Group Report,
in9th Les Houches Workshop on Physics at TeV Collid-
ers(2016) arXiv:1605.04692 [hep-ph].
[26] N. Berger et al. , Simplified Template Cross Sections -
Stage 1.1, (2019), arXiv:1906.02754 [hep-ph].
[27] S. Amoroso et al. , Les Houches 2019: Physics at TeV
Colliders: Standard Model Working Group Report, in
11th Les Houches Workshop on Physics at TeV Colliders:
PhysTeV Les Houches (2020) arXiv:2003.01700 [hep-ph].
[28] G. Choudalakis, Fully bayesian unfolding (2012).
[29] B. Nachman and J. Thaler, Neural Conditional Reweight-
ing, Phys. Rev. D 105, 076015 (2022), arXiv:2107.08979
[physics.data-an].
[30] T. Hastie, R. Tibshirani, and J. Friedman, The Ele-
ments of Statistical Learning , Springer Series in Statistics
(Springer New York Inc., New York, NY, USA, 2001).
[31] M. Sugiyama, T. Suzuki, and T. Kanamori, Density Ratio
Estimation in Machine Learning (Cambridge University
Press, 2012).
[32] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury,
G. Chanan, T. Killeen, Z. Lin, N. Gimelshein, L. Antiga,
A. Desmaison, A. Kopf, E. Yang, Z. DeVito, M. Rai-
son, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang,
J. Bai, and S. Chintala, Pytorch: An imperative style,
high-performance deep learning library, in Advances in
Neural Information Processing Systems 32 (Curran As-
sociates, Inc., 2019) pp. 8024–8035.
[33] D. P. Kingma and J. Ba, Adam: A method for stochastic
optimization (2017), arXiv:1412.6980 [cs.LG].
[34] C. Oleari, The POWHEG-BOX, Nucl. Phys. B Proc.
Suppl. 205-206 , 36 (2010), arXiv:1007.3893 [hep-ph].
[35] S. Alioli, P. Nason, C. Oleari, and E. Re, NLO Higgs
boson production via gluon fusion matched with shower
in POWHEG, JHEP 04, 002, arXiv:0812.0578 [hep-ph].
[36] J. Alwall, R. Frederix, S. Frixione, V. Hirschi, F. Maltoni,
O. Mattelaer, H. S. Shao, T. Stelzer, P. Torrielli, and
M. Zaro, The automated computation of tree-level and
next-to-leading order differential cross sections, and their
matching to parton shower simulations, JHEP 07, 079,arXiv:1405.0301 [hep-ph].
[37] T. Sj¨ ostrand, S. Mrenna, and P. Z. Skands, PYTHIA
6.4 Physics and Manual, JHEP 05, 026, arXiv:hep-
ph/0603175 [hep-ph].
[38] T. Sj¨ ostrand, S. Ask, J. R. Christiansen, R. Corke, N. De-
sai, P. Ilten, S. Mrenna, S. Prestel, C. O. Rasmussen, and
P. Z. Skands, An Introduction to PYTHIA 8.2, Comput.
Phys. Commun. 191, 159 (2015), arXiv:1410.3012 [hep-
ph].
[39] J. de Favereau, C. Delaere, P. Demin, A. Giammanco,
V. Lemaˆ ıtre, A. Mertens, and M. Selvaggi (DELPHES
3), DELPHES 3, A modular framework for fast simu-
lation of a generic collider experiment, JHEP 02, 057,
arXiv:1307.6346 [hep-ex].
[40] T. Kluyver, B. Ragan-Kelley, F. P´ erez, B. Granger,
M. Bussonnier, J. Frederic, K. Kelley, J. Hamrick,
J. Grout, S. Corlay, P. Ivanov, D. Avila, S. Abdalla,
and C. Willing, Jupyter notebooks – a publishing format
for reproducible computational workflows, in Position-
ing and Power in Academic Publishing: Players, Agents
and Agendas , edited by F. Loizides and B. Schmidt (IOS
Press, 2016) pp. 87 – 90.
[41] C. R. Harris, K. J. Millman, S. J. van der Walt, R. Gom-
mers, P. Virtanen, D. Cournapeau, E. Wieser, J. Tay-
lor, S. Berg, N. J. Smith, R. Kern, M. Picus, S. Hoyer,
M. H. van Kerkwijk, M. Brett, A. Haldane, J. F. del R´ ıo,
M. Wiebe, P. Peterson, P. G´ erard-Marchant, K. Shep-
pard, T. Reddy, W. Weckesser, H. Abbasi, C. Gohlke,
and T. E. Oliphant, Array programming with NumPy,
Nature 585, 357 (2020).
[42] J. D. Hunter, Matplotlib: A 2d graphics environment,
Computing in Science & Engineering 9, 90 (2007).
[43] J. Chan and B. Nachman, Higgs to diphoton channel at
least 2 jet datasets, 10.5281/zenodo.7553271 (2023).
[44] L. Heinrich, M. Feickert, and G. Stark, pyhf: v0.7.0,
https://github.com/scikit-hep/pyhf/releases/tag/v0.7.0.
[45] L. Heinrich, M. Feickert, G. Stark, and K. Cranmer,
pyhf: pure-python implementation of histfactory statis-
tical models, Journal of Open Source Software 6, 2823
(2021).