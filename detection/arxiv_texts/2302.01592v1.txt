arXiv:2302.01592v1  [eess.IV]  3 Feb 20231
Graph-Based Compensated Wavelet Lifting for
Scalable Lossless Coding of Dynamic Medical Data
Daniela Lanz, Member, IEEE , and Andr´ e Kaup, Fellow, IEEE
Abstract —Lossless compression of dynamic 2-D+t and 3-D+t
medical data is challenging regarding the huge amount of
data, the characteristics of the inherent noise, and the hig h bit
depth. Beyond that, a scalable representation is often requ ired
in telemedicine applications. Motion Compensated Tempora l
Filtering works well for lossless compression of medical vo lume
data and additionally provides temporal, spatial, and qual ity scal-
ability features. To achieve a high quality lowpass subband , which
shall be used as a downscaled representative of the original data,
graph-based motion compensation was recently introduced t o this
framework. However, encoding the motion information, whic h is
stored in adjacency matrices, is not well investigated so fa r. This
work focuses on coding these adjacency matrices to make the
graph-based motion compensation feasible for data compres sion.
We propose a novel coding scheme based on constructing so-
called motion maps. This allows for the ﬁrst time to compare t he
performance of graph-based motion compensation to traditi onal
block- and mesh-based approaches. For high quality lowpass
subbands our method is able to outperform the block- and mesh -
based approaches by increasing the visual quality in terms o f
PSNR by 0.53 dB and 0.28 dB for CT data, as well as 1.04 dB and
1.90 dB for MR data, respectively, while the bit rate is reduc ed
at the same time.
Index Terms —Scalability, Discrete Wavelet Transform, Motion
Compensation, Graph-Based Signal Processing, Computed To -
mography, Magnetic Resonance Imaging.
I. I NTRODUCTION
IN the daily medical routine, dynamic volume data from
Computed Tomography (CT) and Magnetic Resonance
Imaging (MR) provide a good basis for analyses and pre-
dictions of spatio-temporal movements of particular parts of
the human body. According to [1], modern multi-slice CT
scanners allow for recording volumes of the human body
over a speciﬁc time. For example, when examining cardiac
diseases, this offers the possibility to record the human th orax
over multiple cardiac cycles. By simultaneously recording an
electrocardiography trace (ECG), all recorded frames can b e
sorted retrospectively resulting in a 3-D+t data set coveri ng an
entire cardiac cycle. Fig. 1 shows the resulting representa tion
of such a 3-D+t volume consisting of Ttemporally equidistant
spatial 3-D volumes of size X×Y×Z.
Data rates of such systems depend on the number of detector
rows and gantry rotation times. According to [2], a 4-slice
CT system with 0.5seconds rotation time roughly generates
5.6MB of data per rotation. This corresponds to 11.2MB/s,
while a 16-slice CT scanner with the same rotation time
The authors are with the Chair of Multimedia Communications
and Signal Processing, Friedrich-Alexander-University E rlangen-N¨ urnberg
(FAU), Cauerstr. 7, 91058 Erlangen, Germany (e-mail: danie la.lanz@fau.de,
andre.kaup@fau.de).
PSfrag replacements
xyz
tXY
Z
T 1 2
Fig. 1: Example of a dynamic medical data set: The sketch
shows a 3-D+t CT volume of a thorax which consists of
temporally succeeding 3-D volumes.
generates already 45 MB/s, and a 64-slice CT system produces
up to200MB/s.
This huge amount of data is challenging for data trans-
mission off the gantry and for archiving the 3-D+t volumes.
According to [3], various telemedicine applications exist ,
including remote surgery systems, patient remote telemon-
itoring facilities, and transmission of medical content fo r
remote assessment. The exchange of medical content between
medical experts for educational purposes is also of high
relevance. Since lossless reconstruction is a crucial cond ition
in medical environments, a lossless scalable representati on is
advantageous which allows for tasks like browsing and fast
previewing. Two additional properties need to be taken into
account for lossless compression. Firstly, medical volume data
contain a lot of sensor noise. For CT, this is caused by the
radiation, which has to be kept low to reduce the risks for
the patients, as well as the short acquisition time which is
kept as low as possible to avoid motion artifacts. According
to [4], the noise in an MR imaging system arises from the
resistance of the coil, dielectric and inductive losses in t he
sample, and the preampliﬁer. Secondly, medical image data
have typically a bit depth of 12 bits per pixel whereas natura l
video sequences originating from the entertainment indust ry
are commonly stored in 8 bit format.
All these conditions require an appropriate coding scheme
for dynamic volume data. One way is to apply common video
codecs to medical dynamic volumes by generating a single
sequence over tfor every slice position z, resulting in Z
temporal sequences. In Fig. 1, the resulting sequence for sl ice
positionz=3is highlighted. Every single temporal sequence
can then be compressed using common video coding schemes
under the condition of lossless compression and adaption of
the range of the bit depth.
Fig. 2 describes the basic concepts for lossless compressio n
of video data. Lossless single-layer (SL) coding represent s the2
SL
BL
EL
BLSimulcastLossless Scalable lossless
Bit rate
Fig. 2: Different approaches for lossless coding of video data.
While SL coding typically costs less bits than scalable ap-
proaches, EL coding and simulcast provide scalability feat ures.
most direct way. Beside conventional still image compressi on
schemes allowing lossless compression, like JPEG-LS [5],
also motion compensated predictive coders, like the HEVC
codec [6] in lossless mode, can be applied. Although SL
video coding typically costs less bits compared to scalable
lossless video coding [7], the time needed for transmission of
an entire medical volume, considering for example any wire-
less network, may still be high. Therefore, scalable lossle ss
video coding would be preferable, where videos are coded in
multiple layers and each layer represents a different quali ty
representation of the same video scene.
Basically, three different types of video scalability can b e
distinguished. Temporal scalability affects the frame rat e of
the video, spatial scalability controls the spatial resolu tion of
the video, and quality scalability manipulates the ﬁdelity of
the video.
In this context, two different approaches of scalable loss-
less video coding can be differentiated: Encoding a video
separately at different bit rates and transmitting all laye rs
simultaneously is called simulcast. In Fig. 2, one base laye r
(BL), which is of lower quality, is transmitted in addition t o the
original video sequence. This BL is encoded with less bits an d
can be sent, if the physical channel is limited. Obviously, t he
required bit rate for transmitting both layers is always hig her
than SL coding.
The second approach is characterized by transmitting in
addition to the BL, one or more enhancement layers (EL),
which provide additional data necessary for lossless recon -
struction of the coded video sequence. In Fig. 2, the residua l
data is transmitted by one EL. Typical approaches based
on this concept are Scalable High Efﬁciency Video Coding
(SHVC) [8] and Sample-Based Weighted Prediction for En-
hancement Layer Coding (SELC) [9], [10]. Both approaches
employ conventional DCT-based hybrid coding schemes for
encoding the BL and differ regarding the encoding of the
EL. An alternative coding scheme is represented by 3-D sub-
band coding (SBC) [11]. A wavelet-based approach naturally
achieves scalability features without additional overhea d [12].In every transformation step, the signal is decomposed into a
lowpass (LP) and a highpass (HP) subband with the energy
concentrated in the LP subband. The HP subband contains the
structural information of the video sequence and correspon ds
therefore to the EL. Accordingly, the LP subband serves as
the BL. Both layers offer only half the frame rate compared
to the original sequence. If both layers are coded for exampl e
by the wavelet-based volume coder JPEG 2000 [13], all of the
above mentioned scalability types are supported by SBC.
Since data ﬁdelity is a very important aspect in the medical
environment, a high visual quality of the BL is of huge
relevance. However, SBC causes ghosting artifacts in the
LP subband due to temporal displacements in the sequence.
These can be reduced by incorporating motion compensation
(MC) methods into the subband coder. This is called Motion
Compensated Temporal Filtering (MCTF) and was introduced
by Ohm in [14]. Beside block-based MC, as investigated
in [15], also mesh-based MC can successfully be applied to
medical volume data. The latter one is optimized for medical
volume data in [16], by performing one compensated Haar
wavelet transform (WT) in temporal direction. The results a re
promising regarding the visual quality of the LP subband and
the compression ratio of the entire coding scheme. However,
a further improvement of the data ﬁdelity without a major
increase of the required bit rate is desirable. By applying
graph-based MC as introduced in [17] instead of mesh-based
MC in the lifting structure of the MCTF coder, the geometric
structure of the data can directly be incorporated into the
WT [18] and allows for a superior visual quality of the
LP subband. The motion information used for prediction in
graph-based MC is stored in adjacency matrices. However,
appropriate ways to encode the resulting prediction matric es
are not investigated so far.
In this article, we introduce a novel method for encoding
the adjacency matrices based on the construction of motion
maps. To make this approach feasible for data compression,
we apply sparse sampling to these motion maps. After a
scanning operation, the resulting symbol streams are entro py
coded using multiple-context adaptive arithmetic coding [ 19].
An important step within the lifting structure is the update
step, where the MC has to be inverted. So far, inversion has
been done by recalculating the required adjacency matrix.
However, this leads to a rising bit rate, since this update ma trix
also has to be transmitted. To omit this additional overhead ,
we suggest to estimate the update matrix from the already
encoded prediction matrix. This can be done by applying the
speciﬁcation of the optimum update for motion-compensated
lifting as introduced in [20].
This article is outlined as follows. After a short review
on compensated wavelet lifting in Section II-A, Section II- B
provides an overview of graph-based MC, followed by the de-
scription of the inversion of graph-based MC in Section II-C .
The proposed coding scheme is presented in Section III
including the construction of motion maps and the encoding
process. Simulation results are presented in Section IV. In
Section V, a conclusion and outlook is given.3
f2t−1
f2tf2t−1
f2tPU PULPt
HPt−−
Fig. 3: Block diagram of the lifting structure.
II. G RAPH -BASED COMPENSATED WAVELET LIFTING
An efﬁcient implementation of the discrete WT was pro-
posed by Swelden [21]. The so-called lifting structure con-
sists of three steps: split, predict, and update. The princi pal
scheme is to decorrelate data quickly by using polynomial
factorizations instead of employing Fourier Transforms. F ig. 3
shows a block diagram of the lifting structure. In the ﬁrst st ep,
splitting is performed by decomposing the input video signa l
into even- and odd-indexed frames f2tandf2t−1. In a second
step, the even frames are predicted from the odd frames by a
prediction operator Pwhich is independent of the data to get
a more compact representation of the input signal. Subtract ing
the predicted value P(f2t−1)from the even frames, results in
the HP frames. If the prediction works well, the HP frames wil l
contain less information than the original signal. To maint ain
global properties of the original video signal, in an update step,
the HP frames are ﬁltered by an update operator Uand are
added back to the odd frames, resulting in the LP frames. Thus ,
the LP subband can be used as a downscaled representative for
the original video sequence, corresponding to a BL with lowe r
temporal resolution and different visual quality. Accordi ngly,
the HP and LP coefﬁcients are generated by
HPt=f2t−P(f2t−1),
LPt=f2t−1+U(HPt).(1)
The inversion of the lifting structure works straightforwa rd.
After reversing the prediction and update operations and
toggle+and−signs, the original video signal can easily
be regenerated by
f2t−1=LPt−U(HPt),
f2t=HPt+P(f2t−1).(2)
Hereby, the lifting structure offers a ﬂexible framework wh ich
can be modiﬁed in multiple ways. Common wavelet ﬁlters
often have ﬂoating point coefﬁcients. By introducing round ing
operators as introduced in [22], integer to integer transfo rms
can be achieved. Hence, perfect reconstruction can be guara n-
teed which makes the WT highly attractive for telemedicine
applications by offering a scalable representation and los sless
reconstruction at the same time.
In case of the Haar wavelet, the HP coefﬁcients are com-
puted by taking the difference of f2tandf2t−1. The LP
coefﬁcients are achieved by calculating the average of thes e
two framesf2t−1+f2t
2=f2t−1+1
2HPt. Applying rounding
operators to ensure lossless reconstruction, leads to
HPt=f2t−f2t−1,
LPt=f2t−1+/floorleftbigg1
2HPt/floorrightbigg
.(3)1
25
763
4Even nodes
Odd nodesEdges of same parity
Edges of different parity
Fig. 4: Arbitrary graph showing a possible splitting into even
and odd subsets is shown.
However, blurriness and ghosting artifacts will appear in
the LP frames due to displacements over time. This can be
alleviated by incorporating compensation methods directl y into
the lifting structure without losing the perfect reconstru ction
property.
A. Compensated Wavelet Lifting
A compensated wavelet transform in temporal direction is
called Motion Compensated Temporal Filtering (MCTF) [14].
To achieve a compensated transform, the prediction
operatorPis realized by the warping operator W2t−1→2t.
Instead of the original odd frames f2t−1, a compensated
version is subtracted from the even frames f2t. Then, the
prediction step of the Haar transform is given by
HPt=f2t−⌊W2t−1→2t(f2t−1)⌋. (4)
To preserve perfect reconstruction, rounding operators ar e
set. However, to achieve an equivalent wavelet transform, t he
compensation has to be inverted in the update step [23]. By
reversing the index of W, the LP coefﬁcients of the Haar
transform can be calculated by
LPt=f2t−1+/floorleftbigg1
2W2t→2t−1(HPt)/floorrightbigg
. (5)
To guarantee lossless reconstruction, rounding operators are
required. If Wis realized by a graph-based MC, the geometric
structure of the data is directly incorporated, providing a high-
performing motion compensation.
B. Graph-Based Motion Compensation
In Fig. 4, an arbitrary graph G(V,E)is shown, where V
is the set of nodes, indexed as 1,2,3,...,N andEis the
set of links between the nodes. Every link is deﬁned by a
triplet(i,j,wij), whereiandjare the start and end nodes,
respectively, and wijis the weight which has a value /negationslash= 0, ifi
andjare linked to each other. These relations are stored in an
adjacency matrix A. Further, a vector xis introduced which
contains the amplitude values of every single node. In [24], a
lifting-based WT on arbitrary graphs is introduced, where t he
ﬁrst step comprises the splitting of the nodes into even and
odd subsets. As a consequence, the corresponding adjacency
matrixAhas to be rearranged accordingly:
x=/parenleftbigg
xeven
xodd/parenrightbigg
,A=/parenleftbigg
F J
K L/parenrightbigg
. (6)
The submatrices FandLcontain edges which connect nodes
of same parity and the submatrices JandKcontain all edges4
f2t f2t−1Even frame Odd frame
r=1
1
2
34
5
67
8
9
(a)Node assignment for graph signals on videos
with a predeﬁned neighborhood with radius r=1.
One single node iof the even frame can get linked
to9different end nodes jof the odd frame.PSfrag replacements
nz=169nz=25
0
5
10
15
20
25
r=1
Start node iStart nodes i
1234 56789
Possible end nodesEnd nodes j
(b) Adjacency matrix for a fully connected
neighborhood with radius r=1for a frame of
size5×5pixels. It consists of nz=169 nonzero
entries distributed over 9 possible diagonals.PSfrag replacements
nz=169
nz=250
5
10
15
20
25
r=1
Start node iStart nodes i
1234 56789
Possible end nodesEnd nodes j
(c)Adjacency matrix for a reduced neighbor-
hood with radius r=1for a frame size of 5×5
pixels. It consists of nz=25 nonzero entries
distributed over 9 possible diagonals.
Fig. 5: Correspondences of positions in a predeﬁned neighborhood a nd the diagonals in the related adjacency matrices are
shown. If only one edge is set for every start node i, the number of nonzero entries can be reduced signiﬁcantly c ompared to
a fully connected neighborhood.
which connect nodes of different parity. Now, the HP and LP
coefﬁcients can be calculated by
H=xeven−JP×xodd,
L=xodd+KU×H,(7)
whereHandLcorrespond to the vector notation of the HP
and LP coefﬁcients. The matrices JPandKUare computed
fromJandKby assigning prediction and update weights,
respectively. Since the matrices FandLare not used in (7)
anymore, a perfect splitting of nodes should be intended [25 ].
Considering videos as graph signals, as introduced in [17]
and shown in Fig. 5 on the left side, and applying the graph-
based wavelet transform, every single pixel of a frame corre -
sponds to a node and its associated intensity value is stored
in vector x. To fulﬁll the constraint of perfect splitting, every
node of an even indexed frame f2tgets solely connected to
nodes of the odd indexed frame f2t−1. In Fig. 5a, this proce-
dure is shown for one single node using a 9-grid neighborhood
which corresponds to a radius r=1. The prediction and update
weights of JPandKUare calculated by measuring the
similarity of two connected nodes. The higher the weight,
the more similar two linked nodes are. Hence, every node
of the even frame f2tis predicted by a weighted average
of its assigned neighboring nodes in frame f2t−1. According
to [17], an increasing radius for the considered neighborho od
of a single node results in an increasing visual quality of
the LP subband and decreasing mean energy in the HP
subband. However, to assure perfect reconstruction, the ch osen
neighborhood as well as the prediction and update weights
have to be known at the decoder side. While the transmission
of the corresponding radius of the chosen neighborhood is
trivial, the transmission of the prediction and update weig hts
is challenging.C. Inversion of the Graph-Based Motion Compensation
So far, the update step is performed by predicting from
f2t−1tof2t[17]. The resulting edge weights are stored in KU
and have to be known at decoder side, too. However, concern-
ing the coding costs to transmit all these update weights in
addition to the prediction weights, we force a solution whic h
reuses the prediction weights to generate the update weight s.
The formulation of an optimum update Uoptbased on a given
general linear predictor Pwas already provided in [20]. They
formulated the closed-form expression
Uopt= (I+PTP)−1PT(8)
for motion compensated wavelet lifting, where Idescribes the
identity matrix. This formula requires the prediction oper ator
Pto be given in matrix notation. Fortunately, the calculatio n
rules for graph-based MC are already given in matrix and
vector notation by equation (7). Accordingly, Pcan directly
be substituted by the prediction matrix JP. In addition, they
provide a sparse matrix technique that enables the practica l
implementation of the optimal update step for MCTF, which
is also used in this work. This allows us to omit the calculati on
ofKUand thus also the transmission of the update weights.
Hence, the remaining task is to ﬁnd a proper way to encode
the graph description by considering the chosen radius and t he
corresponding prediction weights.
III. P ROPOSED CODING SCHEME
A larger radius for the chosen neighborhood results in a
better visual quality of the LP frames and a lower mean
energy of the HP frames, which can be used as an indi-
cator for the corresponding bit rate needed to encode the
HP subband. However, a larger radius comprises also more
prediction weights which have to be transmitted. Since the
prediction weights are highly uncorrelated, common coding
schemes like transformation and quantization are not suita ble5
(a)Reference frame f2t−1
 (b)Current frame f2t
(c)Mforr=1
 (d)Mforr=3
(e)Absolute difference |f2t−1−f2t|
 (f)Mforrmax=3
Fig. 6: Top: two subsequent frames of a CT data set showing
a beating heart over time. Middle: corresponding motion
mapsMfor different radii r. Bottom: Absolute difference
|f2t−1−f2t|to determine the assignment of radii and the
corresponding smoothed motion map for rmax=3.
for this application. Therefore, we suggest to reduce the gr aph
description and convert the remaining adjacency matrices t o
motion maps.
A. Reducing the Graph Description
Assuming a predeﬁned radius of r=1, so far, every start
nodeiis connected to nine end nodes j, as shown in Fig. 5a
for one single start node i. In the corresponding adjacency
matrix, given in Fig. 5b, nine diagonals can be observed. The
entries for the speciﬁc start node iin Fig. 5a are highlighted.
Obviously, each of the nine possible positions corresponds
to exactly one diagonal. The exact correspondences can be
observed by the assigned numbers. Accordingly, for a fullyPossible positions
for end nodes j1
2
3
4
5
6
78
9
10
11
12
13
1415
16
17
18
19
20
2122
23
24
25
26
27
2829
30
31
32
33
34
3536
37
38
39
40
41
4243
44
45
46
47
48
49r=3
r=2
r=1
PSfrag replacements
51015202530354045
Fig. 7: Embedding of the indices for smaller radii into the
indices of the maximum radius rmax=3. By assigning various
radii to different regions, the variance of the motion maps c an
be smoothed. By allocating for every possible index a differ ent
shade of gray, as shown by the color bar on the right hand
side, the motion maps in Fig. 6 are generated.
connected neighborhood with radius r=1for a frame of size
5×5pixelsnz=169 nonzero weights are distributed over 9
diagonals.
To reduce the graph description, the maximum prediction
weight of every single start node iis now set to wij,max=1,
while all other prediction weights related to start node iare
set to0. For the considered example, only nz=25 nonzero
weights remain, as can also be observed in Fig. 5c.
B. Construction of Motion Maps
After the reduction of the graph description as described
above, every start node ican now be represented by one
speciﬁc end node jlying within a predeﬁned neighborhood.
Each node can also be assigned to one speciﬁc diagonal of
the adjacency matrix. This allows for introducing a novel
representation of the adjacency matrix, called motion map
M. Therefore, a matrix of size X×Yis built, where every
position(x,y)corresponds to the spatial position of a start
nodeiin the even frame. Then, for every position (x,y)the
index of the position of the corresponding end node jwith
wij,max=1is stored. In Fig. 6a - Fig. 6d, two subsequent frames
of the data set, which was already used in Section I, and
their corresponding motion maps for a chosen neighborhood
with radius r=1andr=3are shown. Since a radius of r=3
means more possible positions for end node j, the variance of
the corresponding motion map is signiﬁcantly higher. These
motion maps can be compared to motion ﬁelds resulting from
pixel-based approaches for MC. However, pixel-based motio n
models require a large overhead to transmit to the decoder.
For efﬁcient encoding of these motion maps, several pro-
cessing steps are performed. In a ﬁrst step the motion maps
are scanned in Peano-Hilbert order. Since Peano-Hilbert sp ace6
Fig. 8: Binary mask Bfor a threshold τ(t)with
PSNR target=50 dB.
ﬁlling curve ﬁts only square images corresponding to a power
of two, for different shaped data a space ﬁlling curve of size
2⌈log2(max(X,Y))⌉is generated. Then, path coordinates which
are outside of the required shape are skipped during scannin g.
In the next step, the resulting symbol string sis entropy coded
using multiple-context adaptive arithmetic coding provid ed by
the QccPack library [26]. This implementation allocates an
arithmetic coding model which contains the probability mod els
for the different contexts. We are using the previous symbol
as the context of the current symbol and update the frequency -
count information in the arithmetic model after encoding ea ch
symbol.
Further, we propose to enhance the coding efﬁciency by
smoothing and masking the motion maps as described in the
following.
1) Smoothing of Motion Maps: As described in [17], an
increasing radius rresults in an increasing visual quality of
the LP subband and a decreasing mean energy in the HP
subband. However, the variance of the assigned end nodes
rises with increasing radius r, which is adversely for encoding
the resulting symbol stream. Therefore, we propose to smoot h
the motion maps by assigning larger radii to areas with stron g
motion, to ensure good reconstruction results for these par ts,
whereas a smaller radius shall be sufﬁcient, when almost no
motion occurs. To determine the amount of motion between
two subsequent frames, we calculate their absolute differe nce
|f2t−1−f2t|and map it into a range between 0and1. An
example can be seen in Fig. 6e, where the normalized absolute
difference of the reference and current frame of Fig. 6a and 6 b
is shown. The spatial intensity results from a combination o f
spatial and temporal gradients. We use it as an indicator for
the local amount of motion. Hence, for a maximum radius of
rmax=3, radiusr=3is assigned to areas which offer a high
value (white), radius r=2is assigned to areas with medium
values (gray), and radius r=1is assigned to areas with values
close to zero (black). An example can be seen in Fig. 6f.
However, as can be seen in Fig. 7, the indices of the positions
for radius r=1are no longer in a range of 1to9. The indices
of the inner radii have to be adapted to the indexing of the
maximum radius. By doing this, a unique mapping of the
single start nodes to their related end nodes can be guarante ed.
2) Masking of Motion Maps: A further improvement re-
garding the coding efﬁciency can be reached by masking the
motion maps by a binary mask B. This binary mask equalsPSfrag replacementsOmitted pixelOmitted pixel
Considered pixelConsidered pixel
Fig. 9: Construction scheme for sparse sampling masks with
increasing densities.
1in areas with strong motion and equals 0in areas with
almost no motion. In case there is no motion assumed, the
corresponding nodes are not transmitted. Instead, they are
reconstructed at the decoder side by connecting them to thei r
direct neighbors. The direct neighboring position corresp onds
to the main diagonal in the adjacency matrix JP. Therefore,
the missing end nodes can easily be restored by ﬁlling the
main diagonal with entries, where no other end node is not
yet assigned.
To calculate the binary mask, the normalized absolute
difference |f2t−1−f2t|is binarized. Therefore, a certain
threshold for every pair of frames is required. This thresho ld
τ(t)is chosen with respect to the underlying mean squared
error (MSE) of the two considered frames and a PSNR
value which we want to guarantee for the reconstructed LP
frame at the decoder side. By rearranging the general formul a
for calculating the PSNR value with a maximum possible
amplitude Amax
PSNR target= 10log10/parenleftbiggA2
max
MSE target/parenrightbigg
(9)
to
MSE target=A2
max
10PSNR target
10, (10)
the corresponding value MSE target is achieved. Then, threshold
τ(t)can be computed by relating MSE target to the actual MSE
of the two underlying frames:
τ(t) =MSE target
1
XY/summationtextX−1
x=0/summationtextY−1
y=0(f2t−1(x,y)−f2t(x,y))2.(11)
For example, taking PSNR target= 50 dB, the binary mask B
for the two subsequent frames in Fig. 6 is shown in Fig. 8.
After multiplying Mwith the corresponding binary mask,
the remaining masked motion map MBhas to be scanned
and the resulting symbol stream shas to be entropy coded.
To reduce the length of s, only the nonzero values shall be
encoded and transmitted. Therefore, after scanning MB, all
zero elements are deleted. To reconstruct the motion map at
the decoder side without any loss, the exact positions of the
nonzero elements have to be known. Since the shape of the
binary masks depend on every pair of consecutive frames, all
binary masks have to be transmitted as metadata to the decode r
side. This is done by using JBIG compression standard [27]
which was designed for bi-level image data such as scanned7
f2t−1rmax S
τ(t)f2tPredict
|f2t−1−f2t|Reduce
and convertSmooth
Create
binary maskScanZero
deletionEntropy
coding
JBIGJP M MB˜MB
Bs
B
Fig. 10: Block diagram of the encoder for the proposed coding scheme. rmaxandShave to be known at the decoder, too.
JBIGEntropy
decodingInverse
scanReconstruct Convertrmax S
ˆs ˆM
ˆBˆJP
Fig. 11: Block diagram of the decoder for the proposed coding
scheme.rmaxandShave to be known.
documents. By choosing higher values for PSNR target, more
information of the motion maps is available after masking
them and therefore a higher quality of the reconstructed mot ion
maps can be achieved. The coding costs for transmitting the
masks will not increase signiﬁcantly. However, the coding
costs for transmitting the resulting symbol stream swill
strongly rise.
C. Sparse Sampling of Motion Maps
Further bit rate savings can be reached by applying sparse
sampling to the masked motion maps MB. This processing
step allows to meet different application scenarios with va rious
channel capacities, e.g., wireless networks, for which a hi gh
sparsity would be preferable to save bandwidth. Therefore,
sparse sampling masks Swith different density patterns are
generated.
Fig. 9 shows binary patches of size 4×4which are copied
periodically to ﬁt the required size of the motion map. The
upper left patch has the lowest density of considered pixels
shown in white. By copying the red marked inner block of
size2×2to the remaining quarters in the order the red arrow
indicates, the density dcan be successively increased from
6.25% to25%, as shown in the ﬁrst row of Fig. 9. For further
increase, the remaining pixels of the inner block of size 2×2
are also considered one after another according to the blue a r-
row and are copied to the remaining quarters in the same order
as before. Using this procedure, the density can successive ly be
increased by 6.25percentage points, resulting in 16different
masks. The subsampled masked motion maps are further
denoted as ˜MB. Since the applied sparsity pattern depends
on the available physical channel, it has to be determined in
advance for the whole coding setup. Therefore, the applied
(a)Final motion map ˜MBfor a
sampling density of d=100% .
Coding costs for s=22.62kB.
(b)Final motion map ˜MBfor a
sampling density of d=50% .
Coding costs for s=12.95kB.
Fig. 12: Exemplary motion maps after all applied processing
steps. The coding costs for B=4.66kB are the same for both
cases.
sampling mask is known at the encoder and decoder side. An
suitable selection of the sparsity pattern for a given chann el
capacity is not investigated so far. Then, the missing posit ions
of the symbol stream scan be reconstructed by applying
common interpolation methods. Therefore, the indexing of t he
possible end nodes in ˜MBrequires a conversion to cartesian
coordinates, resulting in two separate motion maps ˜MBx
and˜MBy. For reconstruction, linear interpolation, nearest
neighbor, and natural neighbor interpolation, which is bas ed
on V oronoi tessellation, are evaluated.
To summarize the entire encoding scheme, Fig. 10 shows
a block diagram of the proposed method. To predict f2t
fromf2t−1, a graph with a certain radius is set up between
two frames. Afterwards, the resulting adjacency matrix JP
is reduced and converted to a motion map M. To save bit
rate, the motion map is smoothed and masked by a binary
maskB. Both steps are based on the normalized absolute
difference of the input frames |f2t−1−f2t|. The resulting
masked motion map MBis subsampled by applying a sparse
maskS, resulting in ˜MB. After scanning the map in Peano-
Hilbert order all zero entries in sare deleted and the remaining
symbol stream is encoded using multiple-context adaptive
arithmetic coding. This requires to additionally encode B,
which is done by employing the JBIG algorithm. As an
example, Fig. 12 shows the resulting motion maps for two8
TABLE I: For simulation a 3D+t CT data set which com-
prises 127 temporal sequences, and 28 independent temporal
sequences from a MR device are used.
x y z t #temporal sequences
CT 512 512 127 10 127
MR 144 192 1 25 28
different densities d=50% andd=100% after all discussed
processing steps. As input serves the same data as used befor e.
The speciﬁc ﬁle sizes of the two output bit streams are given
below. The structure of the decoder is shown in Fig. 11. To
achieve the reconstructed motion map ˆM, an inverse Peano-
Hilbert scan followed by an interpolation of the missing val ues
due to the sparse sampling mask is required. Afterwards, the
reconstructed motion map is converted to an adjacency matri x
again. It should be mentioned that neither the threshold τ(t)
nor the chosen MSE target have to be transmitted, since this
information is inherently stored in the binary mask B.
IV. S IMULATION RESULTS
The simulation setup comprises dynamic volumes from CT1
and MR devices, showing sequences of a beating heart. The
dimensions for the spatial and temporal resolution are sum-
marized in Table I. The bit depth for all sequences constitut es
12 bits per sample.
In the following, we will at ﬁrst analyze the impact of
smoothing and masking the motion maps. Afterwards, we
will evaluate the novel coding scheme for different samplin g
masksSand for various interpolation algorithms. Therefore,
one Haar wavelet decomposition step in temporal direction i s
performed. For measuring the visual quality of the resultin g
LP subbands, we use PSNR LPt[dB]as introduced in [28]. This
metric considers not only the similarity of the LP subband to
the odd-indexed frames, but also the similarity to the even
indexed frames, which is a very important aspect, if the LP
subband is to be used as a downscaled representative for
the original sequence. All results are summed up for each
sequence and are then averaged over the whole data sets.
Additionally, we will compare the best performing approach
of our proposed graph-based MCTF coder to some state-of-
the-art methods including SL and EL coding schemes.
A. Analysis of Smoothing and Masking the Motion Maps
To demonstrate the enhancement of the coding efﬁciency
due to the different processing steps of the novel coding
scheme, Table II shows the PSNR and rate results for in-
creasing radii of the considered neighborhoods as well as
the impact of smoothing and masking the motion maps. The
required motion information, which has to be transmitted to
the decoder side, is summarized by mtx. The resulting LP
and HP subbands are compressed without any loss, using
the wavelet-based volume coder JPEG 2000. Therefore, the
OpenJPEG [29] implementation with four spatial wavelet
1The CT volume data set was kindly provided by Siemens Healthi neers.TABLE II: PSNR in [dB] of the LP subband and ﬁle size in
[kB] of the single subbands and the motion information mtx
for different radii and a maximums radius of rmax=3as well
as for the masked motion maps with a maximum radius of
rmax=3.
r=1r=2r=3rmax=3rmax=3,
maskedCTPSNR LPt 50.26 54.49 57.34 53.75 50.25
File size LP t894.13 830.50 797.10 880.33 808.80
File size HP t817.12 727.54 643.45 817.00 802.26
File size mtx444.25 682.02 841.27 497.45 153.11
File size/summationtext2155.49 2240.06 2281.81 2194.78 1764.17MRPSNR LPt 67.85 71.63 73.97 70.00 66.50
File size LP t195.63 192.66 191.33 194.18 191.14
File size HP t124.81 100.62 83.28 121.07 138.56
File size mtx107.61 165.04 200.82 120.43 36.41
File size/summationtext428.04 458.31 475.43 435.67 366.12
decomposition steps in xy-direction is used. As already men-
tioned above, an increasing radius results in an increasing
visual quality of the LP subband, but also in an increasing ﬁl e
size for the motion maps. To ﬁnd an appropriate compromise
between visual quality and ﬁle size, we smooth the motion
maps as described in Section III-B. In the second column from
right, the results for a maximum radius rmax=3are given. The
exact distribution of the possible radii considering |f2t−1−f2t|
is set to following intervals:
[0;0.12[→r= 1
[0.12;0.29[→r= 2
[0.29;1]→r= 3.(12)
These intervals are trained on the ﬁrst temporal sequence of
the CT data set. Although this is a very poor training, it give s
satisfying results also for the MR data set, as the lower part of
Table II proves. A larger training set, which is different fr om
the test data sets, will probably lead to even better results .
The contribution of the smoothing process to the overall
rate reduction compared to a ﬁxed radius of r=3constitutes
approximately 4% for both data sets. By multiplying the
motion maps with the binary masks, a further rate reduction
can be reached. For calculating the threshold τ(t)according
to equation (11), the covered range of the given bit depth has
to be considered. Since the maximum amplitude values for
CT data are much higher than for MR data, the mean squared
error of CT data also covers larger ranges than for MR data.
Therefore, a value of PSNR target=50 dB for the CT data set and
PSNR target=65 dB for the MR data set is used. The impact
to the ﬁle sizes of the single subbands and the overall ﬁle
size by encoding the resulting symbol stream, as introduced
in Section III-B, can be seen in the last column of Table II.
Accordingly, a further rate reduction of 19% and16% can be
achieved for the CT and MR data sets, respectively, while the
visual quality of the LP subband is controlled by the thresho ld
τ(t).9
47 48 49 5050100150File size mtx[kB]CT 12 bit
58 60 62 64 6610203040
PSNR LPt[dB]File size mtx[kB]MR 12 bit
Linear Nearest neighbor Natural neighbord: 6.25% 100%
Fig. 13: PSNR LPtresults of the CT data (top) and MR data
(bottom) compared against the ﬁle size in [kB] of the require d
motion information mtxfor our proposed coding scheme.
Three different interpolation methods are evaluated, whic h are
displayed over increasing densities dof the applied sampling
masksS.
B. Analysis of Sparse Sampling and Reconstruction of the
Motion Maps
To analyze the performance of our proposed coding scheme
regarding the sparse sampling masks, both data sets are
evaluated for all possible sampling masks Sand all consid-
ered interpolation methods. The results are shown in Fig. 13
for the CT as well as the MR data set. Accordingly, it is
possible to further reduce the required ﬁle size for encodin g
mtx, while the visual quality is degraded simultaneously.
The optimal rate-distortion ratio depends on the capacity o f
the considered physical channel. Further, for both data set s,
linear interpolation is never the best choice. Especially f or
the CT data set, the amplitude values of the motion maps
have still a relatively high variance, even after the smooth ing
and masking steps. This leads to inferior results for linear
interpolation. The MR data set covers a smaller range of
possible amplitude values and therefore comprises smoothe r
motion maps, which is why linear interpolation works better
compared to the CT data set. In the following, for the CT data
set nearest neighbor interpolation is chosen and for the MR
data set natural neighbor interpolation is used.
C. Evaluation of the Proposed Method
In the following, we will compare our proposed graph-
based MCTF coder to state-of-the-art SL and EL codingTABLE III: PSNR in [dB] and rate results in [kB] from
encoding the data sets by HEVC-RA and JPEG-LS.
12 bit 8 bitCTHEVC-RAPSNR LPt[dB] 35.50 30.89
File size Σ[kB] 1745.91 775.77
JPEG-LS File size Σ[kB] 4338.99 654.58MRHEVC-RAPSNR LPt[dB] 46.40 26.81
File size Σ[kB] 290.94 238.70
JPEG-LS File size Σ[kB] 1012.76 297.01
schemes. As prominent representatives for SL coding, we
employ the JPEG-LS as a conventional still image coder and
the HEVC codec as a motion compensated predictive coder.
By choosing the Lowdelay Main RExt conﬁguration (HEVC-
LD) and lossless mode, it is possible to apply HEVC also to
medical sequences. The test model HM-16.16 was used for
simulation.
For a fair comparison to state-of-the-art EL coding schemes ,
the degree of the three main types of scalability have to be
considered. For our proposed graph-based MCTF coder, the
frame rate of the BL is halved. Due to the encoding of the
single subbands by JPEG 2000, the spatial resolution is also
decreased. The quality scalability is controlled by the den sity
of the sparse sampling masks. SHVC and SELC also support
all these scalability types. However, the temporal scalabi lity of
both codecs is achieved by subsampling the BL without any
ﬁltering process. Since MCTF employs subband ﬁltering alon g
the motion trajectories of the temporal axis, a fair compari son
to SHVC and SELC is not possible. Additionally, SHVC is
only implemented for 8and10bit data. However, temporal
scalability is inherently achieved by the Randomaccess Main
RExt conﬁguration of the HEVC codec (HEVC-RA), which
supports12bit data. By decoding only the ﬁrst temporal layer
and omitting the spatial scalability aspect for compressio n, a
visual comparison between the BL of HEVC and MCTF can
be achieved.
Additionally, we compare our proposed graph-based MCTF
to SBC without any MC as well as to block-based and
mesh-based MCTF. These approaches are all based on the
same system concept and allow for an evaluation with equal
conditions. Therefore, the search range of both compared
MCTF methods is set to the maximum radius rmaxof the
graph-based approach. Both compared MCTF methods are
evaluated for block and grid sizes sbandsgof2,4,and8,
respectively. Again, one Haar wavelet decomposition step i n
temporal direction is performed. As already mentioned, the
resulting subbands are compressed without any loss, using
the wavelet-based volume coder JPEG 2000 implemented by
OpenJPEG [29] with four spatial wavelet decomposition step s
inxy-direction. The required motion vector ﬁelds of the block-
and mesh-based approaches are encoded using the QccPack
library [26].
The performance of our proposed graph-based MCTF coder
compared to SL coding with JPEG-LS and HEVC-LD as well
as to HEVC-RA, SBC, block-based, and mesh-based MCTF
with respect to the overall ﬁle size and the visual quality of10
44 46 48 50 521400160018002000File size [kB]CT 12 bit
60 61 62 63 64 65 66 67300350400MR 12 bit
40 42 44 46 486008001000
PSNR LPt[dB]File size [kB]CT 8 bit
40 42 44 46250300350
PSNR LPt[dB]MR 8 bit
HEVC-LD [6] SBC [11] Block-based MCTF [15] Mesh-based MCTF [16] Graph-based MCTFd: 6.25% 100%
sb/sg: 8 2d: 6.25% 100%
sb/sg: 8 2
Fig. 14: PSNR LPtresults of the CT data (left) and MR data (right) compared aga inst the overall ﬁle size in [kB]. The graph-
based approach is evaluated for rmax=3. Our method is displayed for increasing densities, while th e block- and mesh-based
approaches are displayed over decreasing block and grid siz es, respectively. In addition, the rate results of lossless HEVC and
SBC without any MC are shown. Top row: Original 12 bit data. Bo ttom row: Converted 8 bit data.
the LP subband in terms of PSNR LPt, is graphically shown
in Fig. 14. Since the resulting ﬁle sizes from JPEG-LS on 12
bit data are signiﬁcantly higher than from all other applied
methods and therefore, cannot be displayed properly in Fig. 14,
we provide these results in Table III. For the same reasons
regarding the visual quality of the BL from HEVC-RA, we
provide the results for HEVC-RA also in this table. To exclud e
that our results are only valid for 12 bit data, we perform the
same experiments also on 8 bit data. 8 bit medical data sets
are usually preconverted from 12 or 16 bits to 8 bits due to
medical displays, which support very often only 8 bits per
pixel. Therefore, we do the same for our used CT and MR
data sets.
Comparing the considered EL coding schemes, the compres-
sion efﬁciency is much higher for SBC than for any MCTF
coder. According to [30], this is caused by the correlated
noisy structures that can be exploited by a traditional wave let
transform without MC. By applying MCTF, these structures
can not be exploited with the same efﬁciency. Additionally,
the corresponding motion information has to be coded and
contributes to the overall ﬁle size. However, if the LP subba nd
is to be used as a downscaled representative in telemedicineapplications, the visual quality is of high relevance, whic h can
signiﬁcantly be increased by incorporating various compen sa-
tion methods into the coding scheme.
Comparing our proposed method to the block- and mesh-
based MCTF, the novel graph-based approach is less efﬁcient
for LP subbands with low quality. However, for high quality
LP subbands the new method is able to outperform the
other state-of-the-art methods. This is very advantageous for
telemedicine applications, where a high visual quality of t he
LP subband is indispensable, if it is to be used as a downscale d
representative for the original sequence. Block-based MCT F
also achieves high quality LP subbands, but the required bit
rate for transmitting the entire volume without any loss, is
huge. This is caused by high frequency components arising
from the block structures. Deformable motion models like
mesh-based and graph-based MC can avoid these structures
and result in lower bit rates.
In general, our proposed method results in higher PSNR LPt
values and higher bit rates with an increasing sampling dens ity.
However, for the MR data the green curve is not monotonically
increasing with increasing values of d. But if Fig. 13 is
considered again, it can be observed that the ﬁle size for11
TABLE IV: PSNR in [dB] and rate in [kB] of the single subbands for certai n values of Fig. 14. Absolute and relative differences
against the proposed graph-based MCTF are also provided.
Block-based Mesh-based Graph-based ∆Proposed ∆Proposed
MCTF MCTF MCTF to Block-based to Mesh-basedCTPSNR LPt [dB] 49.72 49.97 50.25 + 0.53 + 0.28
File size LP t[kB] 878.70 822.44 808.80 - 69.90 - 8.64 % - 13.64 - 1.69 %
File size HP t[kB] 867.81 827.73 802.26 - 65.55 - 8.17 % - 25.47 - 3.17 %
File size mtx[kB] 73.98 201.63 153.11 + 79.13 + 51.68 % - 48.52 - 31.69 %
File size/summationtext[kB] 1820.50 1851.80 1764.17 - 56.33 - 3.19 % - 87.63 - 4.97 %MRPSNR LPt [dB] 65.46 64.60 66.50 + 1.04 + 1.90
File size LP t[kB] 197.76 194.22 191.14 - 6.62 - 3.46 % - 3.08 - 1.61 %
File size HP t[kB] 138.28 141.60 138.56 + 0.28 + 0.20 % - 3.04 - 2.19 %
File size mtx[kB] 57.23 40.11 36.41 - 20.82 - 57.18 % - 3.70 - 10.16 %
File size/summationtext[kB] 393.28 375.92 366.12 - 27.16 - 4.62 % - 9.80 - 2.61 %
transmitting mtxis increasing as well as for the CT data.
Consequently, the required bit rate for transmitting the re sult-
ing LP and HP frames decreases for sampling densities equal
or higher than 62.5%. Since for higher sampling densities
the corresponding LP and HP frames contain less artifacts,
they can be compressed more efﬁciently. This leads to higher
coding gains compared to the overhead, which the motion
information generates.
For a closer examination, we choose some values in Fig. 14,
which operate at similar bit rates. All these values are mark ed
with black circles in Fig. 14. The corresponding values for
the quality in terms of PSNR LPt, the exact distribution of the
rate into the single subbands, and the amount of bits needed t o
encode the motion information for both data sets can be found
in Table IV. The differences against our proposed graph-bas ed
method are also provided. Accordingly, compared to the mesh -
based approach, the visual quality of the LP subband can be
increased by 0.28dB and1.90dB for the CT and MR data set,
respectively. Compared to the block-based approach, PSNR
gains of 0.53dB and1.04dB for the CT and MR data set
can be achieved, respectively. We want to emphasize, that th e
required ﬁle size to transmit the LP subband and the overall ﬁ le
size to reconstruct the volumes in a lossless way, are always
smaller than compared to the other approaches.
Comparing our proposed graph-based approach to SL cod-
ing with HEVC, an interesting fact can be observed. Contrary
to the conventional assumption, that SL coding requires les s
bits than any scalable lossless coding scheme as introduced
in Section I, the opposite behavior occurs. For the 12 bit CT
data set it is possible, to achieve smaller bit rates with wav elet-
based EL coding than with SL coding. This may be caused by
the noise characteristics of CT data. The noise in CT images i s
typically correlated to the acquisition process. Wavelet- based
coding schemes seem to be able to exploit these correlated
noisy structures better than DCT-based coding schemes, lik e
HEVC. However, for the 8 bit CT data set, HEVC performs
better than for 12 bit data. This leads to the assumption that
12 bit medical data can be compressed better with wavelet-
based coding schemes. For telemedicine applications, wher e
scalable lossless coding schemes are of high relevance, thi s
observation should be focused in further research.D. Visual Example of the Proposed Method
To demonstrate the visual performance of our proposed
method, two original frames at t=1andt=2and slice z=46
from the 12 bit CT data set are shown in Fig. 15 at the top.
Additionally, in the left column a detail (position marked i n
red) of the corresponding LP frame LP 1using SBC without
any MC and MCTF with block-, mesh-, and graph-based MC
is shown. To measure the visual quality of the LP frames,
the similarity to f1andf2has to be considered. While the
ﬁrst evaluation can easily be done by evaluating LP 1in terms
of PSNR with respect to f1, the second evaluation is more
complex. To measure the similarity to f2, the LP frames have
to be warped to the corresponding time step. Then, these
motion compensated LP frames MC (LP1)can also be eval-
uated in terms of PSNR with respect to f2. Accordingly, the
right column of Fig. 15 comprises the corresponding motion
compensated LP frames MC (LP1). As indicated by the low
PSNR values of LP 1and MC(LP1)for SBC, the LP frame is
not suitable for being used in telemedicine applications, s ince
ﬁne structures, marked by the dashed ellipses, are blurred.
For a fair comparison, all methods used for MCTF are
evaluated at approximately the same rate. Therefore, the bl ock-
based approach is evaluated at a block size of sb=4, the
mesh-based approach at a grid size of sg=2and the graph-
based approach for a density of d=100% . These conﬁgurations
correspond to the values chosen in Table IV. The block-
based approach causes blocking artifacts in LP 1, which are
marked by the red ellipse, and blurred structures in MC (LP1),
which are marked by the dashed circle. In contrast, the mesh-
based approach provides a smoother visual result. However,
some erroneous structures appear, as the red arrows show. In
addition, blurring artifacts occur, which are marked by the
dashed circle and ellipse. The graph-based approach is capa ble
to cope with all mentioned artifacts, which is also constitu ted
by the high PSNR values. Additionally, our approach require s
less ﬁle size than the block- and mesh-based approach with
sb=4andsg=2, respectively, as already shown in Table IV.
V. C ONCLUSION
Temporal scalability of dynamic volume data and a high
visual quality of the corresponding representative is indi s-12
Reference frame f1
 Current frame f2
Zoom into reference frame f1
 Zoom into current frame f2
42.15dB
SBC: No compensation, LP 1
46.38dB
MCTF: Block-based, LP 1
42.25dB
SBC: No compensation, MC (LP1)
45.11dB
MCTF: Block-based, MC (LP1)
45.84dB
MCTF: Mesh-based, LP 1
50.38dB
MCTF: Graph-based, LP 1
44.53dB
MCTF: Mesh-based, MC (LP1)
49.14dB
MCTF: Graph-based, MC (LP1)
Fig. 15: Visual example for two successive frames at slice z= 46 of the 12 bit CT volume. Left: reference frame f1and
details of the corresponding frames LP 1using SBC without any motion compensation and MCTF with bloc k-, mesh-, and
graph-based motion compensation. Right: current frame f2and details of the corresponding frames MC (LP1)for all considered
approaches.
pensable for telemedicine applications. Scalable lossles s EL
coding schemes based on MCTF are characterized by their
high data ﬁdelity due to subband ﬁltering along the motion
trajectories. In this context, graph-based motion compens ation
turned out to achieve superior results regarding the visual
quality, but encoding of the motion information, which is
stored in adjacency matrices, was not considered in current
research. We proposed a method to uniquely convert these
adjacency matrices into motion maps. After smoothing andsubsampling these motion maps, they are encoded using
multiple-context adaptive arithmetic coding. Missing val ues
due to the subsampling step are reconstructed at decoder sid e.
By applying this novel coding scheme, the visual quality of
the lowpass subband can be improved by up to 0.53 dB and
0.28 dB for 12 bit CT data, as well as 1.04 dB and 1.09 dB
for 12 bit MR data, respectively, compared to the block- and
mesh-based approaches, while the ﬁle size can be reduced at
the same time.13
At some points in the proposed processing chain we decided
for some thresholds and methods empirically. Nevertheless ,
the ﬁnal results are already very promising. We expect fur-
ther improvements by training the intervals for smoothing
the motion maps on larger data sets, which include various
medical devices. The same training data may be used to reﬁne
the choice of the PSNR target. Additionally, the choice of the
sampling density as well as the selection of the reconstruct ion
algorithm after sparse sampling can be improved by ﬁtting
these parameters automatically to the given requirements. To
achieve further coding gains binary arithmetic coding with
several types of context information can be analyzed for
encoding the binary masks more efﬁciently. Beyond PSNR,
a medical application-guided assessment, e.g., ROC metric s,
may be considered in future works.
ACKNOWLEDGMENT
We gratefully acknowledge that this work has been sup-
ported by the Deutsche Forschungsgemeinschaft (DFG) under
contract number KA 926/4-3.
REFERENCES
[1] B. Ohnesorge and T. Flohr, Principles of Multi-slice Cardiac CT
Imaging . Berlin, Heidelberg: Springer, 2007, pp. 71–126.
[2] S. Ulzheimer and T. Flohr, Multislice CT: Current Technology and
Future Developments . Berlin, Heidelberg: Springer, 2009, pp. 3–23.
[3] C. Doukas and I. Maglogiannis, “Adaptive transmission o f medical
image and video using scalable coding and context-aware wir eless
medical networks,” EURASIP Journal on Wireless Communications and
Networking - Wireless Telemedicine , vol. 2008, no. 25, pp. 1–12, Jan
2008.
[4] E. R. McVeigh, R. M. Henkelman, and M. J. Bronskill, “Nois e and
ﬁltration in magnetic resonance imaging,” Medical Physics , vol. 12,
no. 5, pp. 589–591, 1985.
[5] M. J. Weinberger, G. Seroussi, and G. Sapiro, “The LOCO-I lossless
image compression algorithm: Principles and standardizat ion into JPEG-
LS,” IEEE Trans. on Image Processing , vol. 9, no. 8, pp. 1309–1324,
Aug 2000.
[6] ITU-T and ISO/IEC, “High efﬁciency video coding (HEVC), ” inITU-T
Rec. H.265 and ISO/IEC FDIS 23008-2 , Dec 2016.
[7] J. M. Boyce, Y . Ye, J. Chen, and A. K. Ramasubramonian, “Ov erview
of SHVC: Scalable extensions of the high efﬁciency video cod ing
standard,” IEEE Trans. on Circuits and Systems for Video Technology ,
vol. 26, no. 1, pp. 20–34, Jan 2016.
[8] J. Chen, J. Boyce, Y . Ye, M. M. Hannuksela, G. J. Sullivan, and Y .-K.
Wang, “High efﬁciency video coding (HEVC) Scalable Extensi on: Draft
7,” document JCTVC-R1008v7, Ed., Sapporo, Japan, June 2014 .
[9] A. Heindel, E. Wige, and A. Kaup, “Low-complexity enhanc ement layer
compression for scalable lossless video coding based on HEV C,”IEEE
Trans. on Circuits and Systems for Video Technology (IEEE TC SVT) ,
vol. 27, no. 8, pp. 1749–1760, Aug 2017.
[10] ——, “Analysis of prediction algorithms for residual co mpression in a
lossy to lossless scalable video coding system based on HEVC ,” in Proc.
SPIE Applications of Digital Image Processing XXXVII , vol. 9217, San
Diego, CA, USA, Aug 2014, p. 13.
[11] G. Karlsson and M. Vetterli, “Three dimensional sub-ba nd coding of
video,” in Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal
Processing (ICASSP) , vol. 2, New York City, NY , USA, Apr 1988, pp.
1100–1103.
[12] J. Garbas, B. Pesquet-Popescu, and A. Kaup, “Methods an d tools for
wavelet-based scalable multiview video coding,” IEEE Trans. on Circuits
and Systems for Video Technology , vol. 21, no. 2, pp. 113–126, Feb 2011.
[13] ITU-T and ISO/IEC, “JPEG 2000 Image Coding System: Core Coding
System,” in ITU-T Rec. T.800 and ISO/IEC 15444-1:2004 , Sep 2004.
[Online]. Available: https://jpeg.org/jpeg2000/index. html
[14] J. R. Ohm, “Three-dimensional subband coding with moti on compen-
sation,” IEEE Trans. on Image Processing , vol. 3, no. 5, pp. 559–571,
Sep 1994.[15] W. Schnurrer, J. Seiler, E. Wige, and A. Kaup, “Analysis of displacement
compensation methods for wavelet lifting of medical 3-D tho rax CT
volume data,” in Proc. IEEE Int. Conf. on Visual Communication and
Image Processing (VCIP) , San Diego, CA, USA, November 2012, pp.
1–6.
[16] W. Schnurrer, N. Pallast, T. Richter, and A. Kaup, “Temp oral scalability
of dynamic volume data using mesh compensated wavelet lifti ng,” IEEE
Trans. on Image Processing , vol. 27, no. 1, pp. 419–431, Jan 2018.
[17] D. Lanz and A. Kaup, “Graph-based compensated wavelet l ifting for 3-
D+t medical CT data,” in Proc. IEEE Picture Coding Symposium (PCS) ,
Nuremberg, Germany, Dec 2016, pp. 1–5.
[18] D. Shuman, S. K. Narang, P. Frossard, A. Ortega, P. Vande rgheynst
et al. , “The emerging ﬁeld of signal processing on graphs: Extendi ng
high-dimensional data analysis to networks and other irreg ular domains,”
IEEE, Signal Processing Magazine , vol. 30, no. 3, pp. 83–98, Mar 2013.
[19] I. H. Witten, R. M. Neal, and J. G. Cleary, “Arithmetic co ding for data
compression,” Communications of the ACM , vol. 30, no. 6, pp. 520–540,
June 1987.
[20] B. Girod and S. Han, “Optimum update for motion-compens ated lifting,”
IEEE Signal Processing Letters , vol. 12, no. 2, pp. 150–153, Feb 2005.
[21] W. Sweldens, “Lifting scheme: a new philosophy in biort hogonal
wavelet constructions,” in Proc. SPIE Int. Symp. on Optical Science,
Engineering, and Instrumentation , vol. 2569, San Diego, CA, USA, Sep
1995, pp. 68–79.
[22] A. Calderbank, I. Daubechies, W. Sweldens, and B.-L. Ye o, “Lossless
image compression using integer to integer wavelet transfo rms,” in Proc.
IEEE Int. Conf. on Image Processing (ICIP) , vol. 1, Oct 1997, pp. 596–
599.
[23] N. Bozinovic, J. Konrad, W. Zhao, and C. Vazquez, “On the importance
of motion invertibility in MCTF/DWT video coding,” in Proc. IEEE
Int. Conf. on Acoustics, Speech, and Signal Processing (ICA SSP) ,
Philadelphia, PA, USA, Mar 2005, pp. 49–52.
[24] S. K. Narang and A. Ortega, “Lifting based wavelet trans forms on
graphs,” in Proc. IEEE Asia-Paciﬁc Signal and Information Processing
Association, Annual Summit and Conference (APSIPA ASC) , Sapporo,
Japan, Oct 2009, pp. 441–444.
[25] M. Hidane, O. L´ ezoray, and A. Elmoataz, “Lifting schem e on graphs
with application to image representation,” in Proc. IEEE Glob. Conf. on
Signal and Information Processing (GlobalSIP) , Austin, TX, USA, Dec
2013, pp. 431–434.
[26] J. Fowler, “Qccpack: An open-source software library f or quantization,
compression, and coding,” in Proc. SPIE Applications of Digital Image
Processing XXIII , vol. 4115, San Diego, CA, USA, Aug 2000, pp. 294–
301.
[27] ITU-T and ISO/IEC, “Information technology – Coded rep resentation
of picture and audio information – Progressive bi-level ima ge
compression,” in ITU-T Rec. T.82 and ISO/IEC 11544:1993 , Dec 1993.
[Online]. Available: https://jpeg.org/jbig/index.html
[28] D. Lanz, J. Seiler, K. Jaskolka, and A. Kaup, “Compressi on of dynamic
medical CT data using motion compensated wavelet lifting wi th de-
noised updatea,” in Proc. IEEE Picture Coding Symposium (PCS) , San
Francisco, CA, USA, June 2018, pp. 1–5.
[29] A. Descampe, F. Devaux, H. Drolon, D. Janssens, and Y . Ve rschueren.
(2012, Nov) OpenJPEG 2.0.0. Universit´ e Catholique de Louv ain (UCL).
Belgium. [Online]. Available: http://www.openjpeg.org
[30] W. Schnurrer, J. Seiler, M. Sch¨ oberl, and A. Kaup, “On t he inﬂuence
of clipping in lossless predictive and wavelet coding of noi sy images,”
inProc. IEEE Picture Coding Symposium (PCS) , Krakau, Poland, May
2012, pp. 185–188.