arXiv:2301.09203v1  [cs.DS]  22 Jan 2023Relaxed Models for Adversarial Streaming:
The Advice Model and the Bounded Interruptions Model∗
Moshe Shechner†Menachem Sadigurschi‡Uri Stemmer§
January 22, 2023
Abstract
Streaming algorithms are typically analyzed in the oblivious setting, where we assume that
the input stream is ﬁxed in advance. Recently, there is a growing inte rest in designing adver-
sarially robust streaming algorithms that must maintain utility even when the input st ream
is chosen adaptively and adversarially as the execution progresses. While several fascinating
results are known for the adversarial setting, in general, it comes at a very high cost in terms of
the required space. Motivated by this, in this work we set out to exp lore intermediate models
that allow us to interpolate between the oblivious and the adversaria l models. Speciﬁcally, we
put forward the following two models:
•The advice model , in which the streaming algorithm may occasionally ask for one bit of
advice.
•The bounded interruptions model , in which we assume that the adversary is only partially
adaptive.
We present both positive and negative results for each of these tw o models. In particular,
we present generic reductions from each of these models to the ob livious model. This allows us
to design robust algorithms with signiﬁcantly improved space complex ity compared to what is
known in the plain adversarial model.
1 Introduction
Streaming algorithms are algorithms for processing data st reams in which the input is presented
as a sequence of items. Generally speaking, these algorithm s have access to limited memory,
signiﬁcantly smaller than what is needed to store the entire data stream. This ﬁeld was formalized
by Alon, Matias, and Szegedy [3], and has generated a large bo dy of work that intersects many
other ﬁelds in computer science.
In this work, we focus on streaming algorithms that aim to tra ck a certain function of the input
stream, and to continuously report estimates of this functi on. Formally,
∗This project was partially supported by the Israel Science F oundation (grant 1871/19) and by Len Blavatnik and
the Blavatnik Family foundation.
†Tel Aviv University. moshe.shechner@gmail.com
‡Ben-Gurion University. menisadi@gmail.com
§Tel Aviv University and Google Research. u@uri.co.il
1Deﬁnition 1.1 (Informal version of Deﬁnition 2.1) .LetXbe a ﬁnite domain and let g:X∗→R
be a function that maps every input /vector x∈X∗to a real number g(/vector x)∈R.
LetAbe an algorithm that in every round i∈[m]obtains an element xi∈Xand outputs a
response zi∈R. AlgorithmAis said to be an oblivious streaming algorithm forgwith accuracy
α, failure probability β, and stream length m, if the following holds for every input sequence /vector x=
(x1,x2,...,x m)∈Xm. Consider an execution of Aon the input stream /vector x. Then,
Pr[∀i∈[m]we have zi∈(1±α)·g(x1,...,x i)]≥1−β,
where the probability is taken over the coins of algorithm A.
Note that in Deﬁnition 1.1, the streaming algorithm is requi red to succeed (w.h.p.) for every
ﬁxedinput stream. In particular, it is assumed that the choice fo r the elements in the stream is
independent from the internal randomness of the streaming algorithm. Th is assumption, called the
oblivious setting , is crucial for the correctness of most classical streaming algorithms. In this work,
we are interested in the setting where this assumption does n ot hold, referred to as the adversarial
setting.
1.1 The (Plain) Adversarial Model
The adversarial streaming model, in various forms, was cons idered by [27, 17, 18, 1, 2, 20, 9,
8, 21, 30, 7, 4]. The adversarial setting is modeled by a two-p layer game between a (random-
ized) StreamingAlgorithm and an Adversary . At the beginning, we ﬁx a function g:X∗→R.
Throughout the game, the adversary chooses the updates in th e stream, and is allowed to query
the streaming algorithm at Ttime steps of its choice (referred to as “query times”). Form ally,
1. For round i= 1,2,...,m
(a) The Adversary chooses an update xi∈Xand a query demand qi∈{0,1}, under the
restriction that/summationtexti
j=1qj≤T.
(b) The StreamingAlgorithm processes the new update xi. Ifqi= 1 then, the Streaming-
Algorithm outputs a response zi, which is given to the Adversary .
The goal of the Adversary is to make the StreamingAlgorithm output an incorrect response zi
at some query time iin the stream. Let gbe a function deﬁning a streaming problem, and suppose
that there is an oblivious streaming algorithm Aforgthat uses space s. It is easy to see that g
can be solved in the adversarial setting using space ≈s·T, by running Tcopies ofAand using
each copy for at most one query. The question is if we can do bet ter. Indeed, Hassidim et al. [21]
showed the following result.
Theorem 1.2 ([21], informal) .If there is an oblivious streaming algorithm for a function gthat
uses space s, then there is an adversarially robust streaming algorithm for gsupporting Tqueries
using space≈√
T·s.
Note that when the number of queries Tis large, this construction incurs a large space blowup.
One way for coping with this is to assume additional restrict ions on the function gor on the input
stream. Indeed, starting with Ben-Eliezer et al. [8], most o f the positive results on adversarial
streaming assumed that the input stream is restricted to hav e a small ﬂip-number , deﬁned as
follows.
2Deﬁnition 1.3 (Flip number [8]) .The(α,m)-ﬂip number of an input stream /vector xw.r.t. a function
g, denoted as λα,m(/vector x,g), or simply λ, is the maximal number of times that the value of gchanges
(increases or decreases) by a factor of (1+α)during the stream /vector x.
Starting from [8], the prior works of [8, 21, 30, 4] presented generic constructions that transform
anoblivious streamingalgorithm withspace sintoan adversarially robuststreamingalgorithm with
space≈s·poly(λ). That is, under the assumption that the ﬂip-number is bound ed, these prior
works can even support T=mqueries. This is useful since the parameter λis known to be small
for many interesting streaming problems in the insertion-only model (where there are no deletions
in the stream). However, in general it can be as big as Θ( m), in which case the transformations of
[8, 21, 30, 4] come at a very high cost in terms of space.
To summarize this discussion, current transformations fro m the oblivious to the adversarial
setting are useful when either the number of queries Tis small, or under the assumption that the
ﬂip-number is small.
1.2 Our Results
One criticism of the adversarial model is that it is (perhaps ) too pessimistic. Indeed, there could be
many scenarios that donot fall into the oblivious model, but are still quite far froman “adversarial”
setting. Motivated by this, in this work, we set out to explor e intermediate models that allow us
to interpolate between the oblivious model and the adversar ial model. Speciﬁcally, we study two
such models, which we call the advice model and thebounded interruptions model .
1.2.1 Adversarial Streaming with Advice (ASA)
We put forward a model where the streaming algorithm may occa sionally ask for one bit of advice
throughout the execution. Let η∈Nbe a parameter controlling the query/advice rate. We
consider the following game, referred to as the ASA game, bet ween the StreamingAlgorithm and
anAdversary .
For round i= 1,2,...,m:
1. The Adversary chooses an update xi∈Xand a query demand qi∈ {0,1}, under the
restriction that/summationtexti
j=1qj≤T.
2. The StreamingAlgorithm processes the new update xi.
3. Ifqi= 1 then
(a) The StreamingAlgorithm outputs a response zi, which is given to the Adversary .
(b) If/parenleftBig/summationtexti
j=1qj/parenrightBig
modη= 0 then the StreamingAlgorithm speciﬁes a predicate pi:X∗→
{0,1}, and obtains pi(x1,x2,...,x i).
That is, in the ASA model the adversary is allowed a total of Tqueries, and once every η
queries the streaming algorithm is allowed to obtain one bit of advice, computed as a predicate of
the items in the stream so far.
3The main motivation to study this model is a theoretical one; it gives us an intuitive way
to measure the amount of additional information that the str eaming algorithm needs in order to
maintain utility in the adversarial setting. This model cou ld also be interesting from a practical
standpoint in the following context. Consider a streaming s etting in which the input stream is fed
into both a (low space) streaming algorithm Aand to a serverS. The server has large space and
can store all the input stream (and, therefore, can in princi ple solve the streaming problem itself).
However, suppose that the server has some communication bot tleneck and is busy serving many
other tasks in parallel. Hence we would like to delegate as mu ch of the communication as possible
to the “cheap” (low space) streaming algorithm A. The ASA model allows for such a delegation,
in the sense that the streaming algorithm handles most of the queries itself, and only once in every
ηqueries it asks for one bit of advice from the server.
We show the following generic result.
Theorem 1.4 (informal version of Theorem 3.5) .If there exists an oblivious linearstreaming
algorithm for a function g:X∗→Rwith space s, then for every η∈Nthere exists an adversarially
robust streaming algorithm for gin the ASA model with query/advice rate ηusing space≈η·s2.
To obtain this result, we rely on a technique introduced by Ha ssidim et al. [21] which uses
diﬀerential privacy [15] to protect not the input data, but rather the internal ra ndomness of the
streaming algorithm. Intuitively, this allows us to make su rethat the “robustness” of our algorithm
deteriorates slowerthan the advice rate, which allows us to obtain an advice-rob ustness tradeoﬀ.
NotethatthespacecomplexityofthealgorithmfromTheorem 1.4doesnotdependpolynomially
on the number of queries T. For example, the following is a direct application of this t heorem in
the context of F2estimation (i.e., estimating the second moment of the frequ ency vector of the
input stream).
Theorem 1.5 (F2estimation in the ASA model, informal) .Letη∈N. There exists an adver-
sarially robust F2estimation algorithm in the ASA model with query/advice rat eηthat guarantees
α-accuracy (w.h.p.) using space ˜O/parenleftbig
η/α4/parenrightbig
.
Remark 1.6. We stress that there is a formal sense in which the ASA model is “between” the
oblivious and the (plain) adversarial models. Clearly, the A SA model is easier than the plain
adversarial model, as we can simply ignore the advice bits. O n the other hand, a simple argument
shows that the ASA model (with any η >1) is qualitatively harder than the oblivious setting. To
see this, letAbe an algorithm in the ASA model for a function gwith query/advice rate η >1.
ThenAcan be transformed into the following oblivious algorithm Aobliviousforg(that returns an
estimate in every time step without getting any advice):
1. InstantiateA.
2. In every time i∈[m]:
(a) Obtain an update xi∈X.
(b) DuplicateA(with its internal state) into a shadow copy Ashadow.
(c) Feed the update (xi,0)toAand the update (xi,1)toAshadow, and obtain an answer zifrom
the shadow copy. Note that we only query the shadow copy.
(d) Output ziand erase the shadow copy from memory.
4As we “rewind”Aafter every query, it is never expected to issue an advice-re quest and soAoblivious
never issue advice-request as well. That is, Aobliviousis an oblivious model algorithm. Furthermore,
a simple argument shows that this algorithm maintains utili ty in the oblivious setting.1
Remark 1.7. Our construction has the beneﬁt that the predicates speciﬁe d throughout the interac-
tion are “simple” in the sense that every single one of them ca n be computed in a streaming fashion.
That is, given the predicate pi, the bitpi(x1,x2,...,x i)can be computed using small space with one
pass over x1,x2,...,x i.
A negative result for the ASA model. Theorem 1.4 shows a strong positive result in the
ASA model, for streaming problems that are deﬁned by real val ued functions. We compliment this
result by presenting a negative result for a simple streamin g problem which is notdeﬁned by a
real valued function. Speciﬁcally, we consider (a variant o f) the well-studied ℓ0-sampling problem,
wherethe streaming algorithm must return a uniformly random element from the set of non-deleted
elements. It is known that the ℓ0-sampling problem is easy in the oblivious setting (see e.g. [22])
and hard in the plain adversarial setting (see e.g. [1]). Usi ng a simple counting argument, we show
that the ℓ0-sampling problem remains hard also in the ASA model even if the query/advice rate is
1, i.e., even if the streaming algorithm gets an advice bit for everyquery.
1.2.2 Adversarial Streaming with Bounded Interruptions (ASBI)
Recall that in the plain adversarial model, the adversary is fully adaptive in the sense the ith
update may be chosen based on all of the information availabl e to the adversary up until this point
in time. We consider a reﬁnement of this setting in which the a dversary is only partially adaptive.
Thegamebeginswiththeadversaryspecifyingacomplete inp utstream. Throughouttheexecution,
the adversary (who sees all the outputs given by the streamin g algorithm) can adaptively decide to
interrupt and to replace the suﬃx of the stream (which has not yet been pr ocessed by the streaming
algorithm). For simplicity, here we assume that the streami ng algorithm is queried on every time
step (i.e., T=m).
Formally, let R∈Nbe a parameter bounding the number interruptions. We consid er the
followinggame, referredtoastheASBIgame, betweenthe StreamingAlgorithm andan Adversary .
1To see this, ﬁx an input stream /vector x= (x1,x2,...,x m), and ﬁx j∈[m]. Note that the distribution of the output
given by Aobliviousin timejwhen running on /vector xis identical to the outcome distribution of Awhen running on the
stream (( x1,0),...,(xj−1,0),(xj,1)), which must be accurate w.h.p. by the utility guarantees ofA(since there is
only 1 query in this alternative stream, then Agets no advice when running on it). The claim now follows by a u nion
bound over the query times.
51. The Adversary chooses a stream /vector x= (x1,x2,...,x m)∈Xm.
2. For round i= 1,2,...,m
(a) The StreamingAlgorithm obtains the update xiand outputs a response zi.
(b) The Adversary obtainszi, and outputs an interruption demand di∈ {0,1}, under the
restriction that/summationtexti
j=1dj≤R.
(c) Ifdi= 1 then the adversary outputs a new stream suﬃx ( x′
i+1,...,x′
m) and we override
(xi+1,...,x m)←(x′
i+1,...,x′
m).
That is, the adversary sees all of the outputs given by the str eaming algorithm, and adaptively
decides on Rplaces in which it arbitrarily modiﬁes the rest of the stream . Importantly, the stream-
ing algorithm “does not know” when interruptions occur. Thi s model gives us a very intuitive
interpolation between the oblivious setting (in which R= 0) and the full adversarial setting (ob-
tained by setting R=m, or more subtly by setting R=Twhen there are at most T≤mqueries).
We show the following generic result.
Theorem 1.8 (informal version of Theorem 4.1) .If there exists an oblivious streaming algorithm
for a function g:X∗→Rusing space sthen for every R∈Nthere exists an adversarially robust
streaming algorithm for gin the ASBI model that resists Rinterruptions using space ≈R·s.
To obtain this result, we rely on the sketch switching technique introduced by Ben-Eliezer et
al. [8]. Intuitively, we maintain 2 Rcopies of an oblivious streaming algorithm A, where in every
given moment exactly two of these copies are designated as “a ctive”. As long as the two active
copies produce (roughly) the same estimates, they remain as the “active” copies, and we use their
estimates as our response. Once they disagree, we discard th em both (never to be used again)
and designate two (fresh) copies as “active”. We show that th is construction can be formalized to
obtain Theorem 1.8.
NotethatthespacecomplexityofthealgorithmformTheorem 1.8doesnotdependpolynomially
on the number of time steps m. For example, the following is a direct application of Theor em 1.8
forF2estimation.
Theorem 1.9 (F2estimation in the ASBI model, informal) .LetR∈N. There exists an adversar-
ially robust F2estimation algorithm in the ASBI model that guarantees α-accuracy (w.h.p.) while
resisting Rinterruptions using space ˜O/parenleftbig
R/α2/parenrightbig
.
A negative result for the ASBI model. Note that the space blowup of our construction
from Theorem 1.8 grows linearly with the number of interrupt ionsR. Recall that in the full
adversarial model (where R=TforTqueries) it is known that a space blowup of√
Tsuﬃces
(see Theorem 1.2). Thus, one might guess that the correct dep endence in Rin the ASBI model
should be√
R. However, we show that this is generally not the case. Speciﬁ cally, we show that
there exists a streaming problem that can easily be solved in the oblivious setting with small space,
but necessitates space linear in Rin the ASBI model, provided that the number of queries is larg e
enough (polynomial in R).
61.3 Additional Related Works
Theadversarial streaming model (in a setting similar to our s)dates back to at least [1], who studied
it implicitly and showed an impossibility result for robust ℓ0sampling in sublinear memory. The
adversarial streaming model was then formalized explicitl y by [20], whoshowed strongimpossibility
results for linear sketches. A recent line of work, starting with [8] and continuing with [21, 30, 4, 7]
showedpositiveresults (i.e., robust algorithms ) for many problems of interest, underthe assumption
that the ﬂip-number of the stream is bounded. On the negative side, [8] also prese nted an attack
withO(n) number of adaptive rounds on a variant of the AMS sketch, whe renis the size of the
domain. Later, [25] constructed a streaming problemfor which every adversarially-robust streaming
algorithm must use polynomial space, thus showing a separat ion between the oblivious model and
the (plain) adversarial model. More recently, [12] present ed an attack on a concrete algorithm,
namely CountSketch , that has length that is linearin the space of the algorithm and is using only
two rounds of adaptivity.
2 Preliminaries
In this work we consider streaming problems which are deﬁned by a real valued function (in which
case the goal is to approximate the value of this function) as well as streaming problems that deﬁne
set of valid solutions and the goal is to return one of the vali d solutions. The following deﬁnition
uniﬁes these two objectives for the oblivious setting.
Deﬁnition 2.1 (Oblivious streaming) .LetXbe a ﬁnite domain and let g:X∗→2Wbe a function
that maps every input /vector x∈X∗to a subset g(/vector x)⊆Wof valid solutions (from some range W).
LetAbe an algorithm that, for mrounds, obtains an element xi∈Xand outputs a response
zi∈W. AlgorithmAis said to be an oblivious streaming algorithm forgwith failure probability
β, and stream length m, if the following holds for every input sequence /vector x= (x1,x2,...,x m)∈Xm.
Consider an execution of Aon the input stream /vector x. Then,
Pr[∀i∈[m]we have zi∈g(x1,...,x i)]≥1−β,
where the probability is taken over the coins of algorithm A.
For example, in the problem of estimating the number of disti nct elements in the stream, the
function gin the above deﬁnition returns the interval g(x1,...,x i) = (1±α)·|{x1,...,x i}|, where
αis the desired approximation parameter.
2.1 Preliminaries from Diﬀerential Privacy
Diﬀerential privacy [15] is a mathematical deﬁnition for pri vacy that aims to enable statistical
analyses of databases while providing strong guarantees th at individual-level information does not
leak. Consider an algorithm Athat operates on a database in which every row represents the
data of one individual. Algorithm Ais said to be diﬀerentially private if its outcome distribution
is insensitive to arbitrary changes in the data of any single individual. Intuitively, this means
that algorithmAleaks very little information about the data of any single in dividual, because its
outcome would have been distributed roughly the same even wi thout the data of that individual.
Formally,
7Deﬁnition 2.2 ([15]).LetAbe a randomized algorithm that operates on databases. Algor ithmA
is(ε,δ)-diﬀerentially private if for any two databases S,S′that diﬀer on one row, and any event
T, we have
Pr[A(S)∈T]≤eε·Pr/bracketleftbig
A(S′)∈T/bracketrightbig
+δ.
2.1.1 Privately Approximating the Median of the Data
Given a database S∈X∗, consider the task of privately identifying an approximate median ofS.
Speciﬁcally, for an error parameter Γ, we want to identify an elementx∈Xsuch that there are at
least|S|/2−Γ elements in Sthat are larger or equal to x, and there are at least |S|/2−Γ elements
inSthat are smaller or equal to x. The goal is to keep Γ as small as possible, as a function of the
privacy parameters ε,δ, the database size |S|, and the domain size |X|.
There are several advanced constructions in the literature with error that grows very slowly as a
function of the domain size (only polynomially with log∗|X|) [6, 11, 10, 24, 13]. In our application,
however, simpler constructions suﬃce (where the error grow s logarithmically with the domain size).
The following theorem can be derived as an immediate applica tion of the exponential mechanism
[26].
Theorem 2.3. There exists an (ε,0)-diﬀerentially private algorithm that given a database S∈X∗
outputs an element x∈Xsuch that with probability at least 1−βthere are at least |S|/2−Γ
elements in Sthat are bigger or equal to x, and there are at least |S|/2−Γelements in Sthat are
smaller or equal to x, whereΓ =O/parenleftBig
1
εlog/parenleftBig
|X|
β/parenrightBig/parenrightBig
.
2.1.2 Composition of Diﬀerential Privacy
The following theorem allows arguing about the privacy guar antees of an algorithm that accesses
its input database using several diﬀerentially private mech anisms.
Theorem 2.4 ([16]).Let0< ε,δ′≤1, and let δ∈[0,1]. A mechanism that permits kadap-
tive interactions with mechanisms that preserve (ε,δ)-diﬀerential privacy (and does not access the
database otherwise) ensures (ε′,kδ+δ′)-diﬀerential privacy, for ε′=/radicalbig
2kln(1/δ′)·ε+2kε2.
2.1.3 The Generalization Properties of Diﬀerential Privacy
Dwork et al. [14] and Bassily et al. [5] showed that if a predic atehis the result of a diﬀerentially
private computation on a random sample, then the empirical a verage of hand its expectation over
the underlying distribution are guaranteed to be close. For mally,
Theorem 2.5 ([14, 5, 29]) .Letε∈(0,1/3),δ∈(0,ε/4)andn≥1
ε2log(2ε
δ). LetA:Xn→2X
be an(ε,δ)-diﬀerentially private algorithm that operates on a databa se of size nand outputs a
predicate h:X→{0,1}. LetDbe a distribution over X, letSbe a database containing ni.i.d.
elements fromD, and let h←A(S). Then
Pr
S∼Dn
h←A(S)/bracketleftBigg/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle1
|S|/summationdisplay
x∈Sh(x)−E
x∼D[h(x)]/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle≥10ε/bracketrightBigg
<δ
ε.
83 Adversarial Streaming with Advice (ASA)
In this section we present our results for the ASA model, deﬁn ed in Section 1.2.1. We begin with
our generic transformation.
3.1 A Generic Construction for the ASA Model
Ourgeneric construction for theASA model transformsan obl ivious and linearstreaming algorithm
Ainto a robust streaming algorithm in the ASA model. The linea rity property that we need is the
following. Suppose that three copies of A, call themA1,A2,A3, are instantiated with the same
internal randomness r, and suppose that A1processes a stream /vector x1and thatA2processes a stream
/vector x2and thatA3processes the stream /vector x1◦/vector x2. Then there is an operation (denote it as “+”) that
allows us to obtain an internal state ( A1+A2) that is identical to the internal state of A3. Many
classical streaming algorithms have this property (for exa mple, the classical AMS sketch for F2has
this property [3]). Formally,
Deﬁnition 3.1 (Linear state algorithm) .LetAbe an algorithm with the three segments of mem-
ory state. The ﬁrst segment is randomized in the beginning of t he algorithm and remain ﬁxed
throughout its execution and denoted as SR. The second segment is an encoding of vector in Rd,
and denotedSv. The third segment is the rest of its memory space and denoted a sScand is used
for other computations. Then, Aislinear state w.r.t. its input stream if for any two streams
/vector u1= ((x1,q1),...,(xl,ql))∈(X×{0,1})l,/vector u2= ((x1,q1),...,(xp,qp))∈(X×{0,1})pwith length
ofl,p∈Nand three diﬀerent executions of Awith the same randomized state ( SR) the following
holds:
Sv(/vector u1◦/vector u2) =Sv(/vector u1)+Sv(/vector u2)
WhereSv(/vector u)is the encoded vector v∈Rdresulting from the input stream /vector uencoded in the corre-
sponding memory state.
Consider algorithm RobustAdvice . In the beginning of each iteration of the outer loop, algo-
rithm RobustAdvice sampleskfresh random strings, with which it instantiates the corres ponding
nextandshadowcopies of algorithm Afor that outer loop iteration. Denote by τthe number of
such outer loops ( τ≤m). Instead of sampling these random strings, let us imagine t hat algorithm
RobustAdvice gets these strings as inputs in the following format:
/vector r=/parenleftBig/vectorr1,/vectorr2,...,/vectorrτ/parenrightBig
=/parenleftbig
(r1
1,...,r1
k),(r2
1,...,r2
k),...,(rτ
1,...,rτ
k)/parenrightbig
,
where/vectorrj= (rj
1,...,rj
k) for some j∈[τ] is used as the random strings for the iteration of the
outer loop for the kinstances initialized on Step 2 aand their kduplicates at step 2b. Denote by
(t1<···< tτ) the times that each outer loop began (Step 2 a) and by /vector xtthe input stream till time
t. Then the following lemma states that at the beginning of the outer loop iteration (say, time tj
for some j∈[τ]) the instances of Aactive
ifori∈[k] consist of the state that corresponds to the
input stream in time tj,/vector xtj, for a random string rtj−1
i. That is, Step 2e has successfully recovered
the state of instance iof algorithmAactivew.r.t.rtj−1
ifor input /vector xtj.
Lemma 3.2 (State recovery) .Denote by τthe number of outer loops, by (t1<···< tτ)∈[m]τ
the times of the beginning of each outer loop (Step 2a) and by /vector xtthe input stream till time t. Then,
for allj∈{1,...,τ−1}, for alli∈[k]algorithm instance Aactive
iconsist of state segment Sv(/vector xtj)
corresponding to state segment SR(rj−1
i).
9Algorithm 1 RobustAdvice (β,m,η)
Input:Parameters: βis the failure probability, mis the length of input stream and ηis the
advice query cycle.
Algorithm used: An oblivious linear streaming algorithm Awith space sforαaccuracy.
Constants calculation:
1.k= Ω(ηslog(m/β)log2(m/(βα))) is the number of instances of each of the sets ‘active’,
‘next’ and ‘shadow’.
2.ε0=ε√
8ηksln(1/δ)is the privacy parameter of PrivateMed executions, where ε= 1/100,
δ=O(β/m).
1. Initialize kindependent instances Aactive
1,...,Aactive
kof algorithmA.
2. REPEAT (outer loop)
(a) Initialize kindependent instances Anext
1,...,Anext
kof algorithmA.
(b) LetAshadow
1,...,Ashadow
kbe duplicated copies of Anext
1,...,Anext
k, where eachAshadow
jis
initiated with the same randomness as Anext
j.
(c) Denote the current time step as t. (That is, so far we have seen tupdates in the stream.)
(d) REPEAT (inner loop)
i. Receive next update xiand a query demand qi∈{0,1}.
ii. Insert update xiinto each ofAactive
1,Anext
1,...,Aactive
k,Anext
k.
iii. Ifqi= 1 then:
•QueryAactive
1,Aactive
2,...,Aactive
kand obtain answers yi,1,yi,2,...,yi,k
•Outputzi←PrivateMed (yi,1,yi,2,...,yi,k) with privacy parameter ε0.
•If/parenleftBig/summationtexti
j=1qj/parenrightBig
modη= 0 then deﬁne the predicate pithat given a (preﬁx of a)
stream/vector ureturnsthe nextbit in the inner state of ( Ashadow
1,Ashadow
2,...,Ashadow
k)
after processing the ﬁrst tupdates in /vector u. Update the corresponding bit in the
state of the corresponding Ashadow
j.
•If/parenleftBig/summationtexti
j=1qj/parenrightBig
modηks= 0 then EXIT inner loop. Otherwise, CONTINUE inner
loop.
(e) Forj∈[k] letAactive
j←Anext
j+Ashadow
j.
Proof.Fixj∈{1,...,τ−1}. In time tj−1the strings rtj−1
iwas used for the randomization of
bothAshadow
i,Anext
ifori∈[k]. We focus on the execution of the inner loop, that is time ste ps
t∈[tj−1,tj). Throughout the execution of time steps t∈[tj−1,tj), the stateSvof algorithmsAnext
are updated by the stream update of these time steps. In addit ion, during time steps t∈[tj−1,tj),
algorithm RobustAdvice issues advice queries that are corresponding to the input st ream/vector xtj−1
10with randomization strings/vectorrj−1, where each query recovers additional bit from the kSv-states of
theAshadowinstances. Now, since the inner loop is of size at least η·k·swheresis the number of
bits of the stateSv, then during time steps t∈[tj−1,tj) all of the sbits of stateSvof all of the k
instances ofAshadoware recovered via these advice queries. That is, each of the i nstancesAshadow
i
consist ofSvcorresponding to /vector xtj−1with randomization string rj−1
i, fori∈[k]. Recall that for
i∈[k] each of the pairs ( Ashadow
i,Anext
i) have stateSvcorresponding to the same randomization
rj−1
i. And so by the linearity of algorithm Awe have that summing the state Svfor each of the
pairs (Ashadow
i,Anext
i) in Step 2e resulting in state Svof the instancesAactivecorresponding to the
input stream /vector xtj. That is, we have that all of the Aactiveinstances have recovered their Svfor time
tj.
Lemma 3.3. Letτbe the number of outer loops of algorithm RobustAdvice and denote by/vectorrjfor
j∈[τ]the random strings vector of the outer loop number j. Then for every j∈[τ], algorithm
RobustAdvice is(ε,δ)-diﬀerential privacy w.r.t./vectorrj.
Proof.Denote by τthe number of outer loops and denote by t1,...,tτthe time steps that the
algorithm executes 2a. In each such time tj∈{t1,...,tτ}algorithm RobustAdvice uses a new
database: throughout time steps t∈[tj,tj+1) the algorithm is using/vectorrjexclusively. Now, ﬁx
j∈[τ]. For timesteps t∈[tj,tj+1) algorithm RobustAdvice is executing ηkstimes the PrivateMed
mechanism. By composition (Theorem 2.4) and PrivateMed guarantee (Theorem 2.3), selecting
ε0=ε//radicalbig
8ηkslog(1/δ) assures that each inner loop j∈[τ] is (ε,δ)-DP w.r.t. its exclusive database
/vectorrj.
Theorem 3.4 (Algorithm RobustAdvice is robust) .Denote by /vector xtthe input stream till time t.
Provided thatAis an oblivious linear algorithm for a real valued function g, s.t. w.p. at least 9/10
it is accurate for all t∈[m]in the oblivious setting (i.e. it gives estimations ˆg(/vector xt)∈(1±α)·g(/vector xt)),
then w.p. at least 1−βfor allt∈[m]we have:
zt∈(1±α)·g(/vector xt).
Proof.Lett1<···< tτbe the times when the outer loop begins (Step 2a). Fix j∈[τ], and
focus on time segment t∈[tj−1,tj) during which the j’th outer loop iteration is executed. Let
/vector xt= (x1,...,x t) denote the ﬁrst tupdates in the stream. By Lemma 3.2 we have that on time tj−1
all of the kinstances ofAactiveare updated w.r.t. the input stream /vector xtj−1each corresponding to the
random string rj−1
ifori∈[k]. We now argue that these instances remain robust throughou t the
time segment t∈[tj−1,tj) in which they receive the input stream updates of this time s egment and
the output of RobustAdvice is a function of these instances estimations. Let A(r,/vector xt) denote the
output of the oblivious algorithm Awhen it is instantiated with the random string rand queried
after seeing the stream /vector xt. Consider the following function:
f/vector xt(r) = /BD{A(r,/vector xt)∈(1±α)·g(/vector xt)}.
By Lemma 3.3 algorithm RobustAdvice is/parenleftBig
ε=1
100,δ=εβ
2m/parenrightBig
- diﬀerentially private w.r.t. the col-
lection of strings/vectorrj−1. Furthermore, the updates in the stream /vector xtare chosen (by the adversary)
by post-processing the estimates returned by RobustAdvice , and the function f/vector xt(·) is deﬁned by
/vector xt. As diﬀerential privacy is closed under post-processing, we can view the function f/vector xt(·) as the
11outcome of a diﬀerentially private computation on the collec tion of strings/vectorrj−1. Therefore, by the
generalization properties of diﬀerential privacy (Theorem 2.5), assuming that k≥1
ε2log(2ε
δ), with
probability at least (1 −δ
ε), for every t∈[tj−1,tj) it holds that
/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleE
r[f/vector xt(r)]−1
kk/summationdisplay
i=1f/vector xt(rj−1
i)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle≤10ε=1
10.
This holds for any j∈[τ], and so holds for all t∈[m] w.p. at least 1−β/2 by selectingδ
ε=β
2m(for
the corresponding random strings and functions f/vector xt(r)). We continue the analysis assuming that
this is the case. Now observe that Er[f/vector xt(r)]≥9/10 by the utility guarantees of A(because when
the stream is ﬁxed its answers are accurate to within multipl icative error of (1 ±α) with probability
at least 9 /10). Thus, for at least (9
10−10ε)k= 4k/5 of the executions of Awe have that f/vector xt(ri) = 1,
which means that yt,i∈(1±α)·g(/vector xt). That is, in every time step t∈[m] we have that at least
4k/5 of theyt,i’s satisfy yt,i∈(1±α)·g(/vector xt). Recall that when the algorithm outputs an estimate,
it is computed using algorithm PrivateMed , which is executed on the database ( yt,1,...,yt,k). By
Theorem 2.3, assuming that2
k= Ω/parenleftbigg1
ε0log/parenleftbiggm
βlogm
α/parenrightbigg/parenrightbigg
= Ω/parenleftBigg/radicalBigg
ηks·log/parenleftbiggm
β/parenrightbigg
·log/parenleftbiggm
βα/parenrightbigg/parenrightBigg
,
then with probability at least 1 −β
2malgorithm PrivateMed returns an approximate median ˜ gfor
the estimates yt,1,...,yt,k, satisfying
|{i:yt,i≥˜g}|≥4k
10and|{i:yt,i≤˜g}|≥4k
10.
Since 4k/5 of the yi,j’s satisfy yt,i∈(1±α)·g(/vector xt), such an approximate median ztmust also be
in the range (1±α)·g(/vector xt). This holds separately for every estimate computed in time t∈[m]
(approximated median zt) with probability at least 1 −β
2m, thus holds simultaneously for all the
estimates computed throughout the execution with probabil ity at least 1−β/2. Overall, we have
robustness for all t∈[m] w.p. at least 1−β/2 and PrivateMed for allt∈[m] executed within
its error guarantee w.p. at least 1 −β/2, and so we have that w.p. at least 1 −βfor allt∈[m]
RobustAdvice outputztadmits:
zt∈(1±α)·g(/vector xt).
The following Theorem now follows from Theorem 3.4.
Theorem 3.5. Fix any real valued function gand ﬁxα,β >0andη∈N. LetAbe an oblivious
linear streaming algorithm for gthat uses space sand guarantees accuracy αwith failure probabil-
ity1/10. Then there exists an adversarially robust streaming algori thm forgin the ASA model with
query/advice rate η, accuracy α, and failure probability βusing space O(ηs2log(m/β)log2(m/(βα))).
2We assume that the estimates that Areturns are in the range [ −nc,−1/nc]∪ {0} ∪[1/nc,nc] (polynomially
bounded in n) for some constant c >0. In addition, before running PrivateMed we may round each yt,ito its nearest
power of (1+ α), which has only a small eﬀect on the error. There are at most O(1
αlogn) possible powers of (1 ±α)
in that range, and hence, PrivateMed guarantees error at most Γ = O(1
ε0log/parenleftbigλ
αδlogn/parenrightbig
) with probability at least
1−δ/λ. See Theorem 2.3. Recall also our assumption that log m= Θ(log n).
123.2 A Negative Result for the ASA Model
In this section we show that ℓ0-sampling, a classical streaming problem, cannot be solved with
sublinear space in the adversarial setting with advice. Con sider a turnstile stream /vector u= (u1,...,u m)
where each ui= (ai,∆i)∈[n]×{±1}. Aβ-errorℓ0-sampler returns with probability at least 1 −β
a uniformly random element from
support( u1,...,u m) =/braceleftBigg
a∈[n] :/summationdisplay
i:ai=a∆i/\e}atio\slash= 0/bracerightBigg
,
provided that this support is not empty. The next theorem, du e to Jowhari et al. [23], shows that
ℓ0sampling is easy in the oblivious setting.
Theorem 3.6 ([23]).There is a streaming algorithm with storage O/parenleftBig
log2(n)log(1
β)/parenrightBig
bits, that
with probability at most βreports FAIL, with probability at most 1/n2reports an arbitrary answer,
and in all other cases produces a uniform sample from support( /vector u).
Nevertheless, as we next show, this is a hard problem in the AS A setting. In fact, our negative
result even holds for a simpler variant of the ℓ0sampling problem, in which the algorithm is allowed
to return an arbitrary element, rather than a random element. Formally,
Deﬁnition 3.7. LetXbe a ﬁnite domain and let Abe an algorithm that operates on a stream of
updates(u1,...,u m)∈(X×{±1}), given toAone by one. Algorithm Asolves the J0problem
with failure probability βif, except with probability at most β, wheneverAis queried it outputs an
element with non-zero frequency w.r.t. the current stream. That is, ifAis queried in time ithen
it should output an element from support( u1,...,u i).
Theorem 3.8. LetXbe a ﬁnite domain and let Tbe such that|X|= Ω(T)(large enough). Let A
be an algorithm for solving the J0streaming problem over Xin the adversarial setting with advice
withTqueries and with failure probability at most 3/4. ThenAuses space Ω(T). Furthermore,
this holds also when η= 1, that is, even if algorithm Agets an advice after everyquery.
Proof.LetAbe an algorithm for J0sampling with Tqueries over domain Xin the ASA setting
with failure probability at most 3 /4. Consider the following thought experiment.
Input:Y⊆Xof size|Y|=T
1. For every x∈Y, feed algorithmAthe update ( x,1).
2. Initiate ˆY=∅.
3. Repeat Ttimes:
(a) QueryAand obtain an outcome x∈X
(b) IfArequests an advice then give it a random bit b.
(c) Add xtoˆY
(d) Feed the update ( x,−1) toA
4. Output ˆY.
13We say that the thought experiment succeeds ifˆY=Y. By the assumption on A, for every
inputY, our thought experiment succeeds with probability at least 2−T/4. This is because if all
of the bits of advice are correct then Asucceeds with probability at least 1 /4, and the advice bits
are all correct with probability at least 2−T. Hence, there must exist a ﬁxture of A’s coins and a
ﬁxture of an advice string /vectorbfor which our thought experiments succeeds on at least 2−T/4 fraction
of the possible inputs Y.3
That is, after ﬁxing A’s coins and the advice string /vectorbas above, there is a subset of inputs B
of size|B|≥2−T
4/parenleftbig|X|
T/parenrightbig
such that for every Y∈B, when executed on Y, our thought experiment
outputsˆY=Y. Finally, notethat theinnerstate ofalgorithm Aat theendof Step1 determines the
outcome of our thought experiment. Hence, as there are at lea st2−T
4/parenleftbig|X|
T/parenrightbig
diﬀerent outputs, there
must be at least2−T
4/parenleftbig|X|
T/parenrightbig
possible diﬀerent inner states for algorithm A, meaning that its space
complexity (in bits) is at least log/parenleftBig
2−T
4/parenleftbig|X|
T/parenrightbig/parenrightBig
,which is more than Tprovided that|X|= Ω(T)
(large enough).
4 Adversarial Streaming with Bounded Interruptions (ASBI)
In this section we present our results for the ASBI model, deﬁ ned in Section 1.2.2. We begin with
our generic transformation.
4.1 A Generic Construction for the ASBI Model
Our construction is speciﬁed in algorithm RobustInterruptions . The following theorem speciﬁes
its properties.
Theorem 4.1. Fix any function gand ﬁxα,β >0. LetAbe an oblivious streaming algorithm
forgthat uses space sand guarantees accuracy αwith failure probability β. Then there exists an
adversarially robust streaming algorithm for gthat resists Rinterruptions and guarantees accuracy
5αwith failure probability O(Rβ)using space O(Rs).
Fix an adversary Band consider the interaction between algorithm RobustInterruptions and
the adversaryB. Forr∈[R], letirdenote the time step in which zcheck
r,iris returned.
Lemma 4.2. Fixr∗∈[R]. With probability at least 1−β, the answers returned by Acheck
r∗in times
1,2,...,ir∗areα-accurate. That is, for every 1≤i≤ir∗it holds that zcheck
r∗,i∈(1±α)·g(x1,...,x i).
Proof.For simplicity, we assume that the adversary Bis deterministic (this is without loss of
generality by a simple averaging argument). Fix the randomn ess of all copies of algorithm A,
except forAcheck
r∗. Let RIr∗be a variant of algorithm RobustInterruptions which is identical to
RobustInterruptions until the time step i∗in which rbecomes r∗. In times i≥i∗, algorithm
RIr∗simply outputs zanswer
r∗,i, i.e., the answer given by Aanswer
r∗. Note thatAcheck
r∗does not exist in
algorithm RIr∗.
As we ﬁxed the coins of the copies of A /\e}atio\slash=Acheck
r∗, the interaction between Band RIr∗is
deterministic. In particular, it generates a single stream /vector xr∗. By the utility guarantees of algorithm
3Otherwise, consider sampling an input Yuniformly. We have that2−T
4≤Prr,/vectorb,Y[Ar,/vectorb(Y) succeeds] =
/summationtext
r,/vectorbPr[r,/vectorb]·PrY[Ar,/vectorb(Y) succeeds] </summationtext
r,/vectorbPr[r,/vectorb]·2−T
4=2−T
4, which is a contradiction. Here rdenotes the
randomness of Aand/vectorbis the advice string.
14Algorithm 2 RobustInterruptions
Input:Parameter Rbounding the number of possible interruptions.
Algorithm used: An oblivious streaming algorithm Awith space s, accuracy α, and conﬁdence
β.
1. Initialize 2 Rindependent instances of algorithm A, denoted asAanswer
1,...,Aanswer
Rand
Acheck
1,...,Acheck
R. Setr= 1.
2. Fori= 1,2,...,m:
(a) Obtain the next item in the stream xi∈X.
(b) Feed xitoallof the copies of algorithm A.
(c) Letzanswer
r,iandzcheck
r,idenote the answers returned by Aanswer
randAcheck
r, respectively.
(d) Ifzanswer
r,i∈(1±2α)·zcheck
r,ithenoutput zanswer
r,i. Otherwise, output zcheck
r,iandsetr←r+1.
(e) Ifr > Rthen FAIL. Otherwise continue to the next iteration.
Acheck
r∗, when run on this stream, then with probability at least 1 −βit maintains α-accuracy
throughout the stream.
The lemma now follows by observing that until time ir∗the stream generated by the interaction
betweenBand algorithm RobustInterruptions is identical to the stream /vector xr∗.
Lemma 4.3. With probability at least 1−Rβ, all of the answers given by RobustInterruptions
(before returning FAIL) are 5α-accurate.
Proof.Follows from a union bound over Lemma 4.2, and by Step 2d of RobustInterruptions .
Lemma 4.4. Algorithm RobustInterruptions returns FAIL with probability at most 2Rβ.
Proof.Letj1,j2,...,jRdenote the time steps in which the adversary conducts interr uptions. That
is,j1is the ﬁrst time in which the adversary switches the suﬃx of th e stream, j2is the second time
this happens, and so on. Also let p1,p2,...,pRdenote the time steps in which the parameter r
increases during the execution of algorithm RobustInterruptions . Speciﬁcally, pℓis the time iin
whichrbecomes equal to ℓ+1. We show that for every r∈[R], with probability at least 1 −2rβ
it holds that jr≤pr. (That is, interruptions happen “faster” then rincreases.)
The proof is by induction on r. For the base case, r= 1, let/vector x1denote the ﬁrst stream chosen
by the adversary. By the utility guarantees of A, with probability at least 1 −2βwe have that both
Aanswer
1andAcheck
1areα-accurate w.r.t. this stream, in which case rdoes not increase. Thus, with
probability at least 1 −2βwe have j1≤p1.
The inductive step is similar: Fix r∈[R], and suppose that jr≤pr, which happens with
probability at least (1 −2rβ) by the inductive assumption. Let /vector xrdenote the last stream speciﬁed
by the adversary before time pr. Note that the internal coins of Aanswer
r+1andAcheck
r+1are independent
with this stream. Hence, by the utility guarantees of A, with probability at least 1 −2βwe have
that bothAanswer
r+1andAcheck
r+1areα-accurate w.r.t. this stream, in which case rdoes not increase.
Overall, with probability at least 1 −2(r+1)βwe have jr+1≤pr+1.
15The lemma now follows by recalling that there are at most Rinterruptions throughout the
execution. Hence, with probability at least 1 −2Rβit holds that rnever increases beyond R, and
the algorithm does not fail.
Theorem 4.1 now follows by combining Lemmas 4.2, 4.3, 4.4.
4.2 A Negative Result for the ASBI Model
Theorem 4.5. For every R, there exists a streaming problem over domain of size poly(R)and
stream length poly(R)that requires at least Ω(R)space to be solved in the ASBI model with R
interruptions to within constant accuracy (small enough), but can be solved in the oblivious setting
using space polylog(R).
This theorem follows by revisiting the negative result of Ka plan et al. [25] for the (plain)
adversarial model. They presented a streaming problem, cal led the SADA problem, that is easy
to solve in the oblivious setting but requires large space to be solved in the adversarial setting.
To obtain their hardness results, [25] showed a reduction fr om a hard problem in learning theory
(called the adaptive data analysis (ADA) problem ) to the task of solving the SADA problem in the
adversarial setting with small space.
In the ADA problem, the goal is to design a mechanism Athat initially obtains a dataset D
containing ni.i.d.samplesfromsomeunknowndistribution P, andthenanswers kadaptively chosen
queriesw.r.t.P. Importantly,A’s answers must be accurate w.r.t. the underlying distribut ionP,
and not just w.r.t. the empirical dataset D. Hardt, Ullman, and Steinke [19, 28] showed that the
ADA problem requires a large sample complexity. Speciﬁcall y, they showed that every eﬃcient4
mechanism for this problem must have sample complexity n≥Ω(√
k).
Theorem 4.5 follows by the following two observations regar ding the negative result of [25] for
the SADA problem, and regarding the underlying hardness res ult of [19, 28] for the ADA problem:
1. In the hardness results of [19, 28] for the ADA problem, the adversary generates the queries
usingO(n) rounds of adaptivity, where nis the sample size. In more detail, even though the
adversary poses poly( n) queries throughout the interaction5, these queries are generated in
O(n) bulks where queries in the jth bulk depend only on answers given to queries of previous
bulks.
2. The reduction of Kaplan et al. [25] from the ADA problem to t he SADA problem maintains
the number of adaptivity rounds. That is, the reduction of Ka plan et al. [25] transforms an
adversary for the ADA problem that generates the queries in ℓbulks into an adversary for
the SADA problem that uses ℓinterruptions.
We remark that Theorem 4.5 holds even for a model in which the s treaming algorithm is
strengthen and gets an indication during each interruption round. That is true since by the tech-
nique of [25], the streaming algorithm can identify the exac t round of a new bulk and such round
corresponds to an interruption round.
In Appendix A we survey the necessary details from [25, 19, 28 ], and provide a more detailed
account of the modiﬁcations required in order to obtain Theo rem 4.5.
4The results of [19, 28] hold for all computationally eﬃcient mechanisms, or alternatively, for a class of unbounded
mechanisms which they call naturalmechanisms.
5The adversary poses O(n3) in [19] and O(n2) in [28].
16References
[1] K. J. Ahn, S. Guha, and A. McGregor. Analyzing graph struc ture via linear measurements.
InSODA, pages 459–467, 2012.
[2] K. J. Ahn, S. Guha, and A. McGregor. Graph sketches: spars iﬁcation, spanners, and sub-
graphs. In PODS, pages 5–14, 2012.
[3] N. Alon, Y. Matias, and M. Szegedy. The space complexity o f approximating the frequency
moments. J. Comput. Syst. Sci. , 58(1):137–147, 1999.
[4] I. Attias, E. Cohen, M. Shechner, and U. Stemmer. A framew ork for adversarial streaming via
diﬀerential privacy and diﬀerence estimators. CoRR, abs/2107.14527, 2021.
[5] R. Bassily, K. Nissim, A. D. Smith, T. Steinke, U. Stemmer , and J. Ullman. Algorithmic
stability for adaptive data analysis. In STOC, pages 1046–1059, 2016.
[6] A.Beimel, K.Nissim, andU.Stemmer. Privatelearningan dsanitization: Purevs.approximate
diﬀerential privacy. In APPROX-RANDOM , pages 363–378, 2013.
[7] O. Ben-Eliezer, T. Eden, and K. Onak. Adversarially robu st streaming via dense-sparse trade-
oﬀs. InSOSA@SODA , pages 214–227, 2022.
[8] O. Ben-Eliezer, R. Jayaram, D. P. Woodruﬀ, and E. Yogev. A f ramework for adversarially
robust streaming algorithms. J. ACM, 69(2):17:1–17:33, 2022.
[9] O. Ben-Eliezer and E. Yogev. The adversarial robustness of sampling. In PODS, pages 49–62,
2020.
[10] M. Bun, C. Dwork, G. N. Rothblum, and T. Steinke. Composa ble and versatile privacy via
truncated CDP. In STOC, pages 74–86, 2018.
[11] M. Bun, K. Nissim, U. Stemmer, and S. P. Vadhan. Diﬀerenti ally private release and learning
of threshold functions. In FOCS, pages 634–649, 2015.
[12] E. Cohen, X. Lyu, J. Nelson, T. Sarl´ os, M. Shechner, and U. Stemmer. On the robustness of
countsketch to adaptive inputs. In K. Chaudhuri, S. Jegelka , L. Song, C. Szepesv´ ari, G. Niu,
andS.Sabato, editors, International Conference on Machine Learning, ICML 2022, 17-23 July
2022, Baltimore, Maryland, USA , volume 162 of Proceedings of Machine Learning Research ,
pages 4112–4140. PMLR, 2022.
[13] E.Cohen, X. Lyu, J.Nelson, T.Sarl´ os, andU. Stemmer. ˜Optimal diﬀerentially privatelearning
of thresholds and quasi-concave optimization. CoRR, abs/2211.06387, 2022.
[14] C. Dwork, V. Feldman, M. Hardt, T. Pitassi, O. Reingold, and A. L. Roth. Preserving
statistical validity in adaptive data analysis. In STOC, pages 117–126, 2015.
[15] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrat ing noise to sensitivity in private
data analysis. In TCC, pages 265–284, 2006.
[16] C. Dwork, G. N. Rothblum, and S. P. Vadhan. Boosting and d iﬀerential privacy. In FOCS,
pages 51–60, 2010.
17[17] A. C. Gilbert, B. Hemenway, A. Rudra, M. J. Strauss, and M . Wootters. Recovering simple
signals. In Information Theory and Applications Workshop (ITA) , pages 382–391, 2012.
[18] A. C. Gilbert, B. Hemenway, M. J. Strauss, D. P. Woodruﬀ, a nd M. Wootters. Reusable low-
error compressive sampling schemes through privacy. In IEEE Statistical Signal Processing
Workshop (SSP) , pages 536–539, 2012.
[19] M. Hardt and J. Ullman. Preventing false discovery in in teractive data analysis is hard. In
FOCS. IEEE, October 19-21 2014.
[20] M. Hardt and D. P. Woodruﬀ. How robust are linear sketches to adaptive inputs? In STOC,
pages 121–130, 2013.
[21] A. Hassidim, H. Kaplan, Y. Mansour, Y. Matias, and U. Ste mmer. Adversarially robust
streaming algorithms via diﬀerential privacy. J. ACM, 2022.
[22] H. Jowhari, M. Saglam, and G. Tardos. Tight bounds for lp samplers, ﬁnding duplicates in
streams, and related problems. In PODS, pages 49–58. ACM, 2011.
[23] H. Jowhari, M. Sa˘ glam, and G. Tardos. Tight bounds for l p samplers, ﬁnding duplicates
in streams, and related problems. In Proceedings of the thirtieth ACM SIGMOD-SIGACT-
SIGART symposium on Principles of database systems , pages 49–58, 2011.
[24] H. Kaplan, K. Ligett, Y. Mansour, M. Naor, and U. Stemmer . Privately learning thresholds:
Closing the exponential gap. In COLT, pages 2263–2285, 2020.
[25] H. Kaplan, Y. Mansour, K. Nissim, and U. Stemmer. Separa ting adaptive streaming from
oblivious streaming using the bounded storage model. In CRYPTO , pages 94–121, 2021.
[26] F.McSherryandK.Talwar. Mechanism designviadiﬀerent ial privacy. In FOCS,pages 94–103,
2007.
[27] I. Mironov, M. Naor, and G. Segev. Sketching in adversar ial environments. SIAM J. Comput. ,
40(6):1845–1870, 2011.
[28] T. Steinke and J. R. Ullman. Interactive ﬁngerprinting codes and the hardness of preventing
false discovery. In 2016 Information Theory and Applications Workshop, ITA 2016, L a Jolla,
CA, USA, January 31 - February 5, 2016 , pages 1–41. IEEE, 2016.
[29] U. Stemmer. Individuals and privacy in the eye of data analysis . PhD thesis, Ben-Gurion
University of the Negev, 2016. Supervisors – Amos Beimel and Kobbi Nissim.
[30] D.P.WoodruﬀandS.Zhou. Tightboundsforadversariall y robuststreamsandslidingwindows
via diﬀerence estimators. In FOCS, pages 1183–1196, 2022.
A Details for Theorem 4.5
In this section we elaborate on the components from which The orem 4.5 follows:
1. The hardness results of [19, 28] for the ADA problem.
182. The reduction of Kaplan et al. [25] from the ADA problem to t he SADA problem.
The purpose is to show that the number of adaptive rounds of the reduction is O(R) whereR
is the bound on the interruptions, in spite of the fact that th e number of queries throughout the
attack of [28] is O(R2) and despite the fact that, in the reduction of [25], these O(R2) queries are
encoded and delivered to the streaming algorithm using a som ewhat long stream of length poly( R).
In other words, we show that the negative result presented by [25] for algorithms that solve the
SADA problem is in fact stronger in the sense that it rules out algorithms in the ASBI model, and
not only algorithms in the plain adversarial model.
A.1 IFPC adaptivity level
We now elaborate on the number of adaptive rounds in the hardness results [19, 28] (as apposed
to the total number of rounds). Speciﬁcally, [28] presents a two player game protocol (see def-
inition below) between the players adversaryPand the ﬁnger printing code F. In their paper,
[28] use this deﬁnition of a game along with a code, namely Interactive Finger Printing Code (de-
note IFPA) to prove an upper bound on the number of accurate qu eries that can be guaranteed
against an adaptive analyst. The role of the analyst is playe d byF. [28] present an algorithm for
Fthat assures that Plooses after O(n2) adaptive rounds (i.e. return an inaccurate answer to a
queryoftheanalyst), where nisthesizeofthedatabaseinthegame. Thegameisdeﬁnedasfo llows:
Game protocol: adversary Pvs IFPCF
1.Pselects a subset S1⊆[N], unknown toF.
2. Forj= 1,...,ℓ:
(a)Foutputs a column vector cj∈{±1}N
(b) Letcj
Sj∈{±1}|Sj|be a restriction of Cjto coordinates Sj, which is given to P.
(c)Poutputsaj∈{±1}, which is given to F.
(d)Faccuses (possibly empty) set of users Ij⊆[N]. LetSj+1=Sj\Ij.
In above game,Pis deﬁned as a coalition of the users S1, that receives in each round only a
partial code word Cj. The goal ofPis to remain consistent . That means that whenever the query
cjis all +1 or all−1, thenPmust answer +1 or −1 correspondingly. On each round, Fchooses
some subset Ij⊆[N] to accuse. That means that in the next round these entries wi ll be also
restricted fromP. The goal ofFis to makePbe inconsistent while it cannot accuse ”too many”
users that are not from P(i.e. users S1).
In their paper [28] show an algorithm for Fthat assures inconsistency of any PafterO(n2)
number of rounds (see algorithm 3). In that algorithm (3), Dα,ζis a distribution over [0 ,1] from
which a Bernoulli parameter pjis drawn and used to generate the jth code word cj
1...N∈pjand
φpj:{0,1}→Ris a function that measures a correlation quantity between u seri’s input cj
iand
the output aj. The main idea is to accumulate for each user this correlatio n quantity over the
iterations, and once this quantity crossing some threshold for a user, then the algorithm decides
that the user is a part of the coalition and is marked as such (a ccused).
Importantly to our use case, note that in algorithm 3 all of th e code words cjcan be drawn in
19Algorithm 3 IFPC(n,N,δ,β ) [28]
Input:Parameters: Nis the number of users, 1 ≤n≤Nis the size of the coalition, δ∈(0,1] is
the failure probability, β <1/2 is the fraction of allowed inconsistent rounds.
1. Set parameters α= (1/2−β)/4n= Ω(1/n),ζ= 3/8−β/4 = 1/2−1/4(1/2−β),σ=
O((n/(1/2−β)2)/log(δ−1)),ℓ=O((n2/(1/2−β)4)log(1/δ))
2. Lets0
i= 0 for every i∈[N]
3. forj= 1,...,ℓ:
(a) Draw pj∼Dα,ζandcj
1...N∼pj.
(b) Issue cj∈{±1}Nas a challenge and receive aj∈{±1}as a response.
(c) Fori∈[N], letsj
i=sj−1
i+aj·φpj(cj
i).
(d) Accuse Ij=/braceleftBig
i∈[N]|sj
i> σ/bracerightBig
advance. That is, they are independent from the answers aj. The code words are not presented to
Pall at once but one by one, and so the algorithm 3 is interactive , while it is not adaptive .
Yet the game protocol itself, isadaptive. In the protocol step 2b, the part of the code word
that is sent toPis restricted only to the coalition users Sj. That is, the users from the initial
coalition S1that have not yet been accused, which is a function of all prev ious answers aj. And
so, the adaptivity is reﬂected by the times that code words th at are given toPare determined.
We now conclude that the number of such determining times is o nlyO(n): The list of coalition
users that are not accused Sjis monotonic decreasing, thus can be updated at most ntimes. Now,
recall that the algorithm has length of O(n2) iterations. In addition the set of code words that
are given toPbetween two consecutive modiﬁcations of Sjis ﬁxed. And so, denote by j1,...,jk
as the times that the list Sjis modiﬁed (for some k≤n), then for i∈[k] during the iterations
[ji,...,ji+1) the game protocol is notadaptive.
A.2 ADA to SADA reduction maintains adaptivity level
Now we look on the hardness result of Kaplan et al. [25]. In the ir paper, Kaplan et al. show
a reduction from the ADA problem, that is shown to be hard (a bo und ofO(n2) query rounds)
in [28], to SADA problem (Streaming Adaptive Data Analysis) . In high level, the idea has the
following components:
1.Stream generation and a streaming algorithm: The stream is determined w.r.t. the
game protocol of IFPC where Pis a streaming algorithm that answers queries (encoded in
the input stream).
2.Compression: Algorithms with small space (signiﬁcantly smaller than the size of their input
dataset) are known to have strong generalization propertie s. Hence, if a small space algorithm
is solving the SADA problem (for number of queries ≫O(n2) and with space ≪n) then it
must, in fact, solve the underlying statistical ADA problem for the same number of queries,
contradicting [28].
20These two components show that any algorithm for the SADA pro blem must have space Ω( n).
Since the number of bounded interruptions in our lower bound paradigm is the number of adaptive
rounds that is determined in the ﬁrst component, we elaborat e on that component only.
The stream is deﬁned w.r.t. the IFPC game protocol in two stag es. First stage is setting the set
S1vianupdates in the stream. Each stream update encode a single use r inS1. Then on the second
stage, for O(n2) game protocol rounds, the restricted query cj
Sjis sent for the streaming algorithm
for an answer. A small issue is that each of these queries is of encoded size of poly( n), and thus it
takes poly( n) stream updates for the streaming algorithm to receive it (a nd so, the stream length
of the attack is of poly( n)). After each such (encoded) query, the streaming algorith m must answer
(by [28], any such algorithm must fail after O(n2) queries).
Yet, the observation that we have only O(n)adaptive rounds remains, since the reduction uses
the game protocol of [28]. And so, a similar reduction holds f rom the ADA problem to the SADA
problem in the ASBI model with O(n) rounds of interruptions. This implies a lower bound on the
space of this model.
21