Deep learning for full-eld ultrasonic characterization
Yang Xu1, Fatemeh Pourahmadian1;2, Jian Song1, Conglin Wang3
1Department of Civil, Environmental & Architectural Engineering, University of Colorado Boulder, USA
2Department of Applied Mathematics, University of Colorado Boulder, USA
3Department of Physics, University of Colorado Boulder, USA
Abstract
This study takes advantage of recent advances in machine learning to establish a physics-based data analytic
platform for distributed reconstruction of mechanical properties in layered components from full waveform
data. In this vein, two logics, namely the direct inversion and physics-informed neural networks (PINNs), are
explored. The direct inversion entails three steps: (i) spectral denoising and dierentiation of the full-eld
data, (ii) building appropriate neural maps to approximate the prole of unknown physical and regularization
parameters on their respective domains, and (iii) simultaneous training of the neural networks by minimizing
the Tikhonov-regularized PDE loss using data from (i). PINNs furnish ecient surrogate models of complex
systems with predictive capabilities via multitask learning where the eld variables are modeled by neural
maps endowed with (scaler or distributed) auxiliary parameters such as physical unknowns and loss function
weights. PINNs are then trained by minimizing a measure of data mist subject to the underlying physical
laws as constraints. In this study, to facilitate learning from ultrasonic data, the PINNs loss adopts (a)
wavenumber-dependent Sobolev norms to compute the data mist, and (b) non-adaptive weights in a specic
scaling framework to naturally balance the loss objectives by leveraging the form of PDEs germane to elastic-
wave propagation. Both paradigms are examined via synthetic and laboratory test data. In the latter case, the
reconstructions are performed at multiple frequencies and the results are veried by a set of complementary
experiments highlighting the importance of verication and validation in data-driven modeling.
Keywords: deep learning, ultrasonic testing, data-driven mechanics, full-waveeld inversion
1. Introduction
Recent advances in laser-based ultrasonic testing has led to the emergence of dense spatiotemporal datasets
which along with suitable data analytic solutions may lead to better understanding of the mechanics of complex
materials and components. This includes learning of distributed mechanical properties from test data which is
of interest in a wide spectrum of applications from medical diagnosis to additive manufacturing [1, 2, 3, 4, 5,
6, 7]. This work makes use of recent progress in deep learning [8, 9] germane to direct and inverse problems in
partial dierential equations [10, 11, 12, 13] to develop a systematic full-eld inversion framework to recover the
prole of pertinent physical quantities in layered components from laser ultrasonic measurements. The focus is
on two paradigms, namely: the direct inversion and physics-informed neural networks (PINNs) [14, 15, 16, 17].
The direct inversion approach is in fact the authors' rendition of elastography method [18, 19, 20] through the
prism of deep learning. To this end, tools of signal processing are deployed to (a) denoise the experimental
data, and (b) carefully compute the required eld derivatives as per the governing equations. In parallel,
the unknown distribution of PDE parameters in space-frequency are identied by neural networks which are
then trained by minimizing the single-objective elastography loss. The learning process is stabilized via the
Tikhonov regularization [21, 22] where the regularization parameter is dened in a distributed sense as a
separate neural network which is simultaneously trained with the sought-for physical quantities. This unique
Corresponding author: tel. 303-492-2027, email fatemeh.pourahmadian@colorado.edu
Preprint submitted to Elsevier January 9, 2023arXiv:2301.02378v1  [math.NA]  6 Jan 2023exercise of learning the regularization eld without a-priori estimates, thanks to neural networks, proved to
be convenient, eective, and remarkably insightful in inversion of multi-delity experimental data.
PINNs have recently come under the spotlight for oering ecient, yet predictive, models of complex
PDE systems [10] that has so far been backed by rigorous theoretical justication within the context of linear
elliptic and parabolic PDEs [23]. Given the multitask nature of training for these networks and the existing
challenges with modeling sti and highly oscillatory PDEs [12, 24], much of the most recent eorts has been
focused on (a) adaptive gauging of the loss function [12, 25, 26, 27, 28, 29, 13], and (b) addressing the gradient
pathologies [24, 13] e.g., via learning rate annealing [30] and customizing the network architecture [11, 31, 32].
In this study, our initially austere implementations of PINNs using both synthetic and experimental waveforms
led almost invariably to failure which further investigation attributed to the following impediments: (a) high-
norm gradient elds due to large wavenumbers, (b) high-order governing PDEs in the case of laboratory
experiments, and (c) imbalanced objectives in the loss function. These problems were further magnied
by our attempts for distributed reconstruction of discontinuous PDE parameters { in the case of laboratory
experiments, from contaminated and non-smooth measurements. The following measures proved to be eective
in addressing some of these challenges: (i) training PINNs in a specic scaling framework where the dominant
wavenumber is the reference length scale, (ii) using the wavenumber-dependent Sobolev norms in quantifying
the data mist, (iii) taking advantage of the inertia term in the governing PDEs to naturally balance the
objectives in the loss function, and (iv) denoising of the experimental data prior to training.
This paper is organized as follows. Section 2 formulates the direct scattering problem related to the
synthetic and laboratory experiments, and provides an overview of the data inversion logic. Section 3 presents
the computational implementation of direct inversion and PINNs to reconstruct the distribution of L ame
parameters in homogeneous and heterogeneous models from in-plane displacement elds. Section 4 provides
a detailed account of laboratory experiments, scaling, signal processing, and inversion of antiplane particle
velocity elds to recover the distribution of a physical parameter aliated with exural waves in thin plates.
The reconstruction results are then veried by a set of complementary experiments.
2. Concept
This section provides (i) a generic formalism for the direct scattering problem pertinent to the ensuing
(synthetic and experimental) full-eld characterizations, and (ii) data inversion logic.
2.1. Forward scattering problem
Consider ultrasonic tests where the specimen Rd,d= 2;3, is subject to (boundary or internal)
excitation over the incident surface Sincand the induced (particle displacement or velocity) eld u:
[0T]!RN(N6d) is captured over the observation surface Sobsin a timeframe of length T. Here, 
is an open set whose closure is denoted by , and the sensing conguration is such that Sinc\Sobs=;. In
this setting, the spectrum of observed waveforms ^u:Sobs
!CNis governed by
[^u;#](;!) = 0;^u:=F[u](;!);2Sobs; !2
; (1)
where  of size N1 designates a dierential operator in frequency-space; Frepresents the temporal Fourier
transform;#of dimension N#1 is the vector of relevant geometric and elastic parameters e.g., Lam e constants
and mass density; 2Rdis the position vector; and !>0 is the frequency of wave motion within the specied
bandwidth 
.
2.2. Dimensional platform
All quantities in (1) are rendered dimensionless by identifying ,, and`as the respective reference
scales [33] for mass density, elastic modulus, and length whose explicit values will be later specied.
2.3. Data inversion
Given the full waveform data ^uonSobs
, the goal is to identify the distribution of material properties
overSobs. For this purpose, two reconstruction paradigms based on neural networks are adopted in this
study, namely: (i) direct inversion, and (ii) physics-based neural networks. Inspired by the elastography
2method [18, 19], quantities of interest in (i) are identied by neural maps over Sobs
 that minimize a
regularized measure of  in (1). The neural networks in (ii), however, are by design predictive maps of the
waveform data (i.e., ^u) obtained by minimizing the data mismatch subject to (1) as a soft or hard constraint.
In this setting, the unknown properties of  may be recovered as distributed parameters of the (data) network
during training via multitask optimization. In what follows, a detailed description of the deployed cost
functions in (i) and (ii) is provided after a brief review of the aliated networks.
2.3.1. Waveform and parameter networks
Laser-based ultrasonic experiments furnish a dense dataset on Sobs
. Based on this, multilayer per-
ceptrons (MLPs) owing to their dense range [34] may be appropriate for approximating complex waveelds
and distributed PDE parameters. Moreover, this architecture has proven successful in numerous applications
within the PINN framework [15]. In this study, MLPs serve as both data and property maps where the
input consists of discretized space and frequency coordinates ( i;!j),i= 1;2;:::;N,j= 1;2;:::;N!, as
well as distinct experimental parameters, e.g., the source location, distilled as one vector kon domain T
withk= 1;2;:::;N, while the output represents waveform data Dijk= [R^u;I^u](i;!j;k)2RNRN,
and/or the sought-for mechanical properties Pijn= [R#n;I#n](i;!j)2RR,n= 1;2;:::;N#. Note that
following [35], the real Rand imaginary Iparts of (1) and every complex-valued variable are separated such
that both direct and inverse problems are reformulated in terms of real-valued quantities. In this setting, each
fully-connected MLP layer with Nlneurons is associated with the forward map  l:RNl 1!RNl,
l(xl 1) = tanh(Wlxl 1+bl);xl 12RNl 1; (2)
whereWl2RNlNl 1andbl2RNlrespectively denote the lthlayer's weight and bias. Consecutive compo-
sition of  lforl= 1;2;:::;Nmbuilds the network map wherein Nmdesignates the number of layers.
2.3.2. Direct inversion
Logically driven by the elastography method, the direct inversion approach depicted in Fig. 1 takes advan-
tage of the leading-order physical principles underpinning the test data to recover the distribution of relevant
physical quantities in space-frequency i.e., over the measurement domain. The ML-based direct inversion
entails three steps: (a) spectral denoising and dierentiation of (n-dierentiable) waveforms ^uoverSobs
according to the (n-th order) governing PDEs in (1), (b) building appropriate MLP maps to estimate the
prole of unknown physical parameters of the forward problem and regularization parameters of the inverse
solution, and (c) learning the MLPs through regularized tting of data to the germane PDEs.
Note that synthetic datasets { generated via e.g., computer modeling or the method of manufactured
solutions, may directly lend themselves to the tting process in (c) as they are typically smooth by virtue
Figure 1: Direct inversion: (a) FFT-based spatial dierentiation of the full-eld data as per operator , (b) MLP-based approx-
imation of the unknown PDE and regularization parameters ( #;) on their respective domains, and (c) training the MLPs via
minimizing the elastography loss L"according to (3).
3of numerical integration or analytical form of the postulated solution. Laboratory test data, however, are
generally contaminated by noise and uncertainties, and thus, spectral dierentiation is critical to achieve the
smoothness requirements in (c). The four-tier signal processing of experimental data follows closely that of [36,
Section 3.1] which for completeness is summarized here: (1) a band-pass lter consistent with the frequency
spectrum of excitation is applied to the measured time signals at every receiver point, (2) the obtained
temporally smooth signals are then dierentiated or integrated to obtain the pertinent eld variables, (3)
spatial smoothing is implemented at every snapshot in time via application of median and moving average
lters followed by computing the Fourier representation of the processed waveforms in space, (4) the resulting
smooth elds may be dierentiated (analytically in the Fourier space) as many times as needed based on the
underlying physical laws in preparation for the full-eld reconstruction in step (c). It should be mentioned
that the experimental data may feature intrinsic discontinuities e.g., due to material heterogeneities or contact
interfaces. In this case, the spatial smoothing in (3) must be implemented in a piecewise manner after the
geometric reconstruction of discontinuity surfaces in Sobswhich is quite straightforward thanks to the full-eld
measurements, see e.g., [36, section 3.2].
Next, the unknown PDE parameters #are approximated by a fully connected MLP network #?:=N#(;!)
as per Section 2.3.1. The network is trained by minimizing the loss function
L"(^u;#?;) =k(^u;#?)k2
L2(Sobs
T)N+k 1##?k2
L2(Sobs
)N#; (3)
where 1#indicates an all-ones vector of dimension N#1, anddesignates the (element-wise) Hadamard
product. Here, the PDE residual based on (1) is penalized by the norm of unknown parameters. Observe
that the latter is a function of the weights and biases of the neural network which may help stabilize the MLP
estimates during optimization. Such Tikhonov-type functionals are quite common in waveform tomography
applications [37, 38, 39] owing to their well-established regularizing properties [21, 22]. Within this framework,
R3>0 is the regularization parameter which may be determined by three means, namely: (i) the Morozov
discrepancy principle [40, 41], (ii) its formulation as a (constant or distributed) parameter of the #?network
which could then be learned during training, and (iii) its independent reconstruction as a separate MLP
network?:=N(;!) illustrated in Fig. 1 (b) that is simultaneously trained along with #?by minimizing (3).
In this study, direct inversion is applied to synthetic and laboratory test data with both = 0 and > 0,
based on (ii) and (iii). It was consistently observed that the regularization parameter plays a key role in
controlling the MLP estimates. This is particularly the case in situations where the eld ^uis strongly polarized
or near-zero in certain neighborhoods which brings about instability i.e., very large estimates for #?in these
areas. In light of this, all direct inversion results in this paper correspond to the case of  >0 identied by
the MLP network ?.
2.3.3. Physics-informed neural networks
By deploying the knowledge of underlying physics, PINNs [14, 15] furnish ecient neural models of complex
PDE systems with predictive capabilities. In this vein, a multitask learning process is devised according
to Fig. 2 where (a) the eld variable ^u{ i.e., measured data on Sobs
T, is modeled by the MLP
map ^u?: =N^u(;!;) endowed with the auxiliary parameter (;!;) related to the loss function (4),
(b) the physical unknowns #could be dened either as parameters of ^u?as in Fig. 2 (i), or as a separate
MLP#?: =N#(;!) as shown in Fig. 2 (ii), and (c) learning the MLPs and aliated parameters through
minimizing a measure of data mist subject to the governing PDEs as soft/hard constraints wherein the spatial
derivatives of ^u?are computed via automatic dierentiation [42]. It should be mentioned that in this study
all MLP networks are dened on (a subset of) Sobs
TwhereSobs\@=;. Hence, the initial and
boundary conditions { which could be specied as additional constraints in the loss function [15], are ignored.
In this setting, the PINNs loss takes the form
L$(^u?;#?j) =k^u ^u?k2
N(Sobs
T)N+k 1(^u?;#?)k2
L2(Sobs
T)N;N=L2;bH; 6n;(4)
where 1is aN1 vector of ones; n is the order of , and bHdenotes the adaptive Hnorm dened by
4Figure 2: Two logics for the physics-informed neural networks (PINNs) with distributed parameters: (i) the test data ^u(;!;)
are modeled by a MLP map, while the unknown physical parameters #{ onSobs
, and the loss function weight { on
Sobs
T, are dened as network parameters, and (ii) ^u(;!;) and#(;!) are identied by separate MLPs, while is a
parameter of N^u. The MLP(s) in (i) and (ii) are then trained by minimizing L$of (4) in the space of data and PDE parameters.
kk bH:=sX
16jej6ekre()k2
L2+kk2
L2;re=@jej
@e1
1@e2
2@ed
d;jej:=dX
i=1ei: (5)
Here,e:=fe1;e2;:::edgis a vector of integers ei>0. Provided that 8e; e= 1, thenbHis by denition
equal toH[43]. Note however that at high wavenumbers, His dominated by the highest derivatives re^u?,
jej=, which may complicate (or even lead to the failure of) the training process due to uncontrolled error
amplication by automatic dierentiation particularly in earlier epochs. This issue may be addressed through
proper weighting of derivatives in (5). In light of the frequency-dependent Sobolev norms in [44, 37], one
potential strategy is to adopt the wavenumber-dependent weights as the following
e=1
e1
1e2
2ed
d2
;16jej6;
whereiniis a measure of wavenumber along ifor i = 1;:::;d . In this setting, the weighted norms of
derivatives in (5) remain approximately within the same order as the L2norm of data mist. Another way to
automatically achieve the latter is to set the reference scale `such thati1. Note that the bHnorms directly
inform the PINNs about the \expected" eld derivatives { while preventing their uncontrolled magnication.
This may help stabilize the learning process as such derivatives are intrinsically involved in the PINNs loss via
(^u?;#?). It should be mentioned that when N=bHin (4), the \true" estimates for derivatives re^umay
be obtained via spectral dierentiation as per Section 2.3.2.
The Lagrange multiplier [45, 46] (;!;) in (4) is critical for balancing the loss components during
training. Its optimal value, however, highly depends on (a) the nature of  [12], and (b) the distribution
of unknown parameters #. It should be mentioned that setting = 1 led to failure in almost all of the
synthetic and experimental implementations of PINNs in this study. Gauging of loss function weights has
been the subject of extensive recent studies [12, 25, 47, 26, 27, 28]. One systematic approach is the adaptive
SA-PINNs [12] where the multiplier (;!;) is a distributed parameter of ^u?whose value is updated in
each epoch according to a minimax weighting paradigm. Within this framework, the data (and parameter)
networks are trained by minimizing L$with respect to ^u?and#?, while maximizing the loss with respect to
as shown in Fig. 2.
Depending on the primary objective for PINNs, one may choose nonadaptive or adaptive weighting. More
specically, if the purpose is high-delity forward modeling via neural networks where #is known a-priori and
PINNs are intended to serve as predictive surrogate models of , then ideas rooted in constrained optimization
e.g., minimax weighting is theoretically sound. However, if the inverse solution i.e., identication of #(;!)
from \real-world" or laboratory test data is the main goal particularly in a situation where any assumption on
the smoothness of #and/or applicability of  may be (at least locally) violated e.g., due to unknown material
5heterogeneities or interfacial discontinuities, then trying to enforce  everywhere on Sobs
T(via point-
wise adaptive weighting) may lead to instability and failure of data inversion. In such cases, nonadaptive
weighting may be more appropriate. In light of this, in what follows, is a non-adaptive weight specied by
taking advantage of the PDE structure to naturally balance the loss objectives.
3. Synthetic implementation
Full-eld characterization via the direct inversion and physics-informed neural networks are examined
through a set of numerical experiments. The waveform data in this section are generated via a FreeFem++ [48]
code developed as part of [49].
3.1. Problem statement
Plane-strain wave motion in two linear, elastic, piecewise homogeneous, and isotropic samples is modeled
according to Fig. 3 (a). On denoting the frequency of excitation by !, let`r=2
!p
r=r,r= 1, andr= 1
be the reference scales for length, mass density, and stress, respectively. In this framework, both specimens
are of size 1616 and uniform density = 1. The rst sample 1R2is characterized by the constant Lam e
parameters = 1 and= 0:47, while the second sample 2R2is comprised of four perfectly bonded
homogenous components 2jofj=jandj= 2j=3,j=f1;2;3;4gsuch that 2=S4
j=12j. Accordingly,
the shear and compressional wave speeds read c
s= 1, c
p= 1:57 in 1, and cj
s=pj, cj
p= 1:63pjin2j.
Every numerical experiment entails an in-plane harmonic excitation at != 3:91 via a point source on Sinc
(the perimeter of a 14 14 square centered at the origin). The resulting displacement eld u= (u
1;u
2),
= 1;2, is then computed in overSobs(a concentric square of dimension 8 8) such that
u() + (+)rru() +!2u() =( x)d;2;x2Sinc;

ru()I2+ 2rsymu()
n() = 0; 2@;(6)
wherexanddrespectively indicate the source location and polarization vector; nis the unit outward normal
to the specimen's exterior, and
(
=; =;  = 1
=j; =j;  = 2^22j2f1;2;3;4g:
Figure 3: synthetic experiments simulating plane-strain wave motion in homogeneous (top-left) and heterogeneous (bottom-left)
specimens: (a) testing conguration where the model is harmonically excited at frequency !by a point source on Sinc, and the
induced displacement eld uis computed over Sobsalong1and2as shown in (b) and (c), respectively.
6When = 2, the rst of (6) should be understood as a shorthand for the set of four governing equations
over2j,j=f1;2;3;4g, supplemented by the continuity conditions for displacement and traction across
@2jn@2as applicable.
In this setting, the generic form (1) may be identied as the following
 =  := + (+)rr +!2I2; = 1;2;
^u=u(;!;);#= [;](;!);2Sobs; !2
;2T;(7)
whereinI2is the second-order identity tensor; = (x;d)2SincB1=TwithB1denoting the unit circle
of polarization directions. Note that is treated here as a known parameter.
In the numerical experiments, Sinc(resp.Sobs) is discretized by a uniform grid of 32 ( resp. 5050) points,
while 
 and B1are respectively sampled at != 3:91 andd= (1;0).
All inversions in this study are implemented within the PyTorch framework [50].
3.2. Direct inversion
The three-tier logic of Section 2.3.2 is employed to reconstruct the distribution of and,= 1;2,
overSobs, entailing: (a) spectral dierentiation of the displacement eld uin order to compute  uand
rruas per (6), (b) construction of three positive-denite MLP networks ?,?, and?; each of which
is comprised of one hidden layer of 64 neurons, and (c) training the MLPs by minimizing L"as in (3)
and (7) by way of the ADAM algorithm [51]. To avoid near-boundary errors aliated with the one-sided FFT
dierentiation in  uandrru, a concentric 4040 subset of collocation points sampling Sobsis deployed
for training purposes. It should also be mentioned that in the heterogeneous case, i.e., = 2, the discontinuity
of derivatives across @2j2f1;2;3;4gcalls for piecewise spectral dierentiation. According to Section 2.3.1, the
input to P?=NP(;!),P=;, and?=N(;!) is of sizeNNN!= 1600Ns1 whereNs632
is the number of simulations i.e., source locations used to generate distinct waveforms for training. In this
setting, since the physical quantities of interest are independent of , the real-valued output of MLPs is of
dimension 16001 furnishing a local estimate of the L ame and regularization parameters at the specied
sampling points on Sobs. Each epoch makes use of the full dataset and the learning rate is 0 :005.
In this work, the reconstruction error is measured in terms of the normal mist
(q?) =kq? qkL2
kqkL1; (8)
where q?is an MLP estimate for a quantity with the \true" value q.
LetSincbe sampled at one point i.e., Ns= 1 so that a single forward simulation in ,= 1;2, generates
the training dataset. The resulting reconstructions are shown in Figs. 4 and 5. It is evident from both gures
that the single-source reconstruction fails at the loci of near-zero displacement which may explain the relatively
high values of the recovered regularization parameter ?. Table 1 details the true values as well as mean and
standard deviation of the reconstructed L ame distributions #?= (?;?) in1(resp.2jforj= 1;2;3;4)
according to Fig. 4 ( resp. Fig. 5).
This problem may be addressed by enriching the training dataset e.g., via increasing Ns. Figs. 6 and 7
illustrate the reconstruction results when Sincis sampled at Ns= 5 source points. The mean and standard
deviation of the reconstructed distributions are provided in Table 2. It is worth noting that in this case the
identied regularization parameter ?assumes much smaller values { compared to that of Figs. 4 and 5. This
is closer to the scale of computational errors in the forward simulations.
To examine the impact of noise on the reconstruction, the multisource dataset used to generate Figs. 6
and 7 are perturbed with 5% white noise. The subsequent direct inversions from noisy data are displayed in
Figs. 8 and 9, and the associated statistics are presented in Table 3. Note that spectral dierentiation as the
rst step in direct inversion plays a critical role in denoising the waveforms, and subsequently regularizing the
reconstruction process. This may substantiate the low magnitude of MLP-recovered ?in the case of noisy
data in Figs. 8 and 9. The presence of noise, nonetheless, aects the magnitude and thus composition of terms
in the Fourier representation of the processed displacement elds in space which is used for dierentiation.
This may in turn lead to the emergence of uctuations in the reconstructed elds.
7Figure 4: Direct inversion of the L ame parameters in 1using noiseless data from a single source: (a) MLP-predicted distributions
?and?, (b) reconstruction error (8) with respect to the true values = 1 and= 0:47, (c) MLP-recovered distribution of
the regularization parameter ?, and (d) loss function L"vs. the number of epochs Nein the log = log10scale.
Figure 5: Direct inversion of the L ame parameters in 2using noiseless data from a single source: (a) MLP-predicted distributions
?and?, (b) reconstruction error (8) with respect to the true values j=jandj= 2j=3,j=f1;2;3;4g, (c) MLP-recovered
regularization parameter ?, and (d) loss function L"vs. the number of epochs Ne.
Table 1: MeanhiDand standard deviation (jD) of the reconstructed L ame distributions in D=1;2j=1;2;3;4. Here,
the direct inversion is applied to noiseless data from a single source as shown in Figs. 4 and 5.
D 1 21 22 23 24
= 11= 12= 23= 34= 4
h?iD 0:998 0:991 1:983 2:825 3:835
(?jD) 0:024 0:083 0:182 0:441 0:325
= 0:471= 0:672= 1:333= 24= 2:66
h?iD 0:376 0:615 0:850 1:746 1:412
(?jD) 0:128 0:161 0:399 0:486 0:864
8Figure 6: Direct inversion of the L ame parameters in 1using noiseless data from ve distinct simulations: (a) MLP-predicted
distributions ?and?, (b) reconstruction error (8) with respect to the true values = 1 and= 0:47, (c) MLP-recovered
regularization parameter ?, and (d) loss function L"vs. the number of epochs Ne.
Figure 7: Direct inversion of the L ame parameters in 2using ve noiseless datasets: (a) MLP-predicted distributions ?and
?, (b) reconstruction error (8) with respect to the true values j=jandj= 2j=3,j=f1;2;3;4g, (c) MLP-recovered
regularization parameter ?, and (d) loss function L"vs. the number of epochs Ne.
Table 2: Mean and standard deviation of the reconstructed L ame distributions from ve distinct noiseless datasets
according to Figs. 6 and 7.
D 121222324
 1 1 2 3 4
h?iD 1:000 0:999 2:003 2:999 3:999
(?jD)0:001 0:012 0:011 0:012 0:016
 0:47 0:67 1:33 2 2:66
h?iD 0:464 0:660 1:302 1:997 2:635
(?jD)0:012 0:039 0:071 0:048 0:068
9Figure 8: Direct inversion of the L ame parameters in 1using ve datasets perturbed with 5% white noise: (a) MLP-predicted
distributions ?and?, (b) reconstruction error (8) with respect to the true values = 1 and= 0:47, (c) MLP-recovered
regularization parameter ?, and (d) loss function L"vs. the number of epochs Ne.
Figure 9: Direct inversion of the L ame parameters in 2using ve datasets perturbed with 5% white noise: (a) MLP-predicted
distributions ?and?, (b) reconstruction error (8) with respect to the true values j=jandj= 2j=3,j=f1;2;3;4g, (c)
MLP-recovered regularization parameter ?, and (d) loss function L"vs. the number of epochs Ne.
Table 3: Mean and standard deviation of the reconstructed L ame distributions from noisy data according to Figs. 8
and 9.
D 1 21 22 23 24
 1 1 2 3 4
h?iD 1:001 1:002 2:005 2:996 3:996
(?jD)0:005 0:016 0:035 0:054 0:088
 0:47 0:67 1:33 2 2:66
h?iD 0:462 0:650 1:263 2:006 2:654
(?jD)0:042 0:051 0:225 0:182 0:300
103.3. Physics-informed neural networks
The learning process of Section 2.3.3 is performed as follows: (a) the MLP network u?=Nu(;!;xj;#?)
endowed with the positive-denite parameters and#?= (?;?) is constructed such that the input xlabels
the source location and the auxiliary weight is a nonadaptive scaler, (b) ?and?may be specied as scaler
or distributed parameters of the network according to Fig. 2 (i), and (c) u?is trained by minimizing L$
in (4) via the ADAM optimizer using the synthetic waveforms of Section 3.1. Reconstructions are performed
on the same set of collocation points sampling Sobs
Tas in Section 3.2. Accordingly, the input to u?is
of sizeNN!N= 16001Ns, while its output is of dimension (1600 1Ns)2modeling the displacement
eld along1and2in the sampling region. Similar to Section 3.2, each epoch makes use of the full dataset for
training and the learning rate is 0 :005. The PyTorch implementation of PINNs in this section is accomplished
by building upon the available codes on the Github repository [52].
The MLP network u1?=u1?(;!;xj;#?) with three hidden layers of respectively 20, 40, and 20 neurons
is employed to map the displacement eld u1(in1) associated with a single point source of frequency
!= 3:91 atx=x12Sinc. The L ame constants are dened as the unknown scaler parameters of the
network i.e., #?=f?;?g, and the Lagrange multiplier is specied per the following argument. Within
the dimensional framework of this section and with reference to (7), observe that on setting =1
!2(i.e.,
= 0:065), both (the PDE residue and data mist) components of the loss function L$in 4 emerge as some
form of balance in terms of the displacement eld. This may naturally facilitate maintaining of the same scale
for the loss terms during training, and thus, simplifying the learning process by dispensing with the need to
tune an additional parameter . Keep in mind that the input to u1?is of size 160011, while its output is
of dimension (1600 11)2. In this setting, the training objective is two-fold: (a) construction of a surrogate
map foru1, and (b) identication of ?and?.
Fig. 10 showcases (i) the accuracy of PINN estimates based on noiseless data in terms of the vertical
component of displacement eld u1
2in1, and (ii) the performance of automatic dierentiation [42] in capturing
the eld derivatives in terms of components that appear in the governing PDE 7 i.e., u1
2;ij=@2u1
2=(@i@j),
i;j= 1;2. The comparative analysis in (ii) is against the spectral derivates of FEM elds according to
Section 2.3.2. It is worth noting that similar to Fourier-based dierentiation, the most pronounced errors
in automatic dierentiation occur in the near-boundary region i.e., the support of one-sided derivatives. It
is observed that the magnitude of such discrepancies may be reduced remarkably by increasing the number
of epochs. Nonetheless, the loci of notable errors remain at the vicinity of specimen's external boundary or
internal discontinuities such as cracks or material interfaces. Fig. 10 is complemented with the reconstruction
results of Fig. 11 indicating ( ?;?) = (1:000;0:486) for the homogenous specimen 1with the true L ame
constants (;) = (1;0:47). The impact of noise on training is examined by perturbing the noiseless data
related to Fig. 10 with 5% white noise, which led to ( ?;?) = (0:999;0:510) as shown in Fig. 12.
Next, the PINN u2?=u2?(;!;xj#?) with three hidden layers of respectively 120, 120, and 80 neurons
is created to reconstruct (i) displacement eld u2in the heterogeneous specimen 2, and (ii) distribution of
the L ame parameters over the observation surface. In this vein, synthetic waveform data associated with ve
point sourcesfxig2Sinc,i= 1;2;:::; 5 at!= 3:91 is used for training. Here, #?is the network's unknown
distributed parameter, of dimension (40 40)2, and the nonadaptive scaler weight= 0:065 in light of the
sample's uniform density = 1. In this setting, the input to u2?is of size 160015, while its output is
of dimension (1600 15)2. Fig. 13 provides a comparative analysis between the FEM and PINN maps of
horizontal displacement u1
2in2and its spatial derivatives computed by spectral and automatic dierentiation
respectively.
Table 4: Mean and standard deviation of the PINN-reconstructed L ame distributions from ve distinct noiseless datasets
according to Fig. 14.
D 21 22 23 24
h?iD 0:975 1:973 2:941 . 3:918
(?jD)0:054 0:123 0:135 0:226
h?iD 0:686 1:250 2:045 2:065
(?jD)0:247 0:400 0:520 0:857
11Figure 10: PINN vs. FEM maps of vertical displacement and its derivatives in 1: (a) MLP estimates, from noiseless data, for
fu1
2?;u1?
2;11;u1?
2;22;u1?
2;12gwherein the derivatives u1?
2;ij,i;j= 1;2, are obtained by automatic dierentiation, (b) FEM displacement
solution and its spectral derivatives for fu1
2;u1
2;11;u1
2;22;u1
2;12g, and (c) normal mist 8 between (a) and (b).
Figure 11: PINN reconstruction of L ame constants in the homogeneous plate 1from noiseless data: (a) ?vs. number of epochs
Ne, (b)?vs.Ne, and (c) total loss L$and its components (the PDE residue and data mist) vs.Nein log scale.
Figure 12: PINN reconstruction of L ame constants in 1from noisy data: (a) ?vs. number of epochs Ne, (b)?vs.Ne, and
(c) total loss L$and its components (the PDE residue and data mist) vs.Nein log scale.
12Figure 13: PINN vs. FEM maps of horizontal displacement and its derivatives in 2: (a) PINN estimates, from noiseless data, for
fu2
1?;u2?
1;11;u2?
1;22;u2?
1;12gwherein the derivatives u2?
1;ij,i;j= 1;2, are obtained by automatic dierentiation, (b) FEM displacement
solution and its spectral derivatives for fu2
1;u2
1;11;u2
1;22;u2
1;12g, and (c) normal mist 8 between (a) and (b).
Figure 14: PINN reconstruction of L ame parameters in 2using ve noiseless datasets: (a) PINN-predicted distributions ?and
?, (b) reconstruction error (8) with respect to the true values j=jandj= 2j=3,j=f1;2;3;4g, (c) total loss L$and its
components (the PDE residue and data mist) vs.Nein log scale.
The PINN-reconstructed distribution of PDE parameters is illustrated in Fig. 14 whose statistics is
detailed in Table 4. It is worth mentioning that the learning process is repeated for a suit of weights
=f0:01;0:025;0:1;0:25;0:5;1:5;2;5;10;15g. In all cases, the results are either quite similar or worse than
that of Figs. 13 and 14.
134. Laboratory implementation
This section examines the performance of direct inversion and PINNs for full-eld ultrasonic character-
ization in a laboratory setting. In what follows, experimental data are processed prior to inversion as per
Section 2.3.2 which summarizes the detailed procedure in [36]. To verify the inversion results, quantities of
interest are also reconstructed through dispersion analysis, separately, from a set of auxiliary experiments.
4.1. Test set-up
Experiments are performed on two (homogeneous and heterogeneous) specimens: exp
1which is a 27 cm
27 cm1:5 mm sheet of T6 6061 aluminum, and exp
2composed of (a) 5 cm 27 cm1:5 mm sheet of Grade
2 titanium, (b) 2 :5 cm27 cm1:5 mm sheet of 4130 steel, and (c) 5 cm 27 cm1:5 mm sheet of 260-H02
brass, connected via metal epoxy. For future reference, the density , Young's modulus E, and Poisson's
ratiofor=fAl, Ti, St, Brgare listed in Table 5 as per the manufacturer.
Ultrasonic experiments on both samples are performed in a similar setting in terms of the sensing cong-
uration and illuminating wavelet. In both cases, the specimen is excited by an antiplane shear wave from a
designated source location Sinc, shown in Fig. 15, by a 0 :5 MHz p-wave piezoceramic transducer (V101RB by
Olympus Inc.). The incident signal is a ve-cycle burst of the form
H(fct)H(5 fct) sin 
0:2fct
sin 
2fct
; (9)
whereHdenotes the Heaviside step function, and the center frequency fcis set at 165 kHz ( resp.f80;300gkHz)
inexp
1(resp.exp
2). The induced wave motion is measured in terms of the particle velocity v,= 1;2, on the
scan grids GsamplingSobswhereSobs\Sinc=Sobs\@exp
=;. A laser Doppler vibrometer (LDV) which is
mounted on a 2D robotic translation frame (for scanning) is deployed for measurements. The VibroFlex Xtra
VFX-I-120 LDV system by Polytec Inc. is capable of capturing particle velocity within the frequency range
DC 24 MHz along the laser beam which in this study is normal to the specimen's surface.
The scanning grid G1exp
1is identied by a 2 cm 2 cm square sampled by 100 100 uniformly spaced
measurement points. This amounts to a spatial resolution of 0 :2 mm in both spatial directions. In parallel,
G2exp
2is a 2:5 cm7:5 cm rectangle positioned according to Fig. 15 (b) and sampled by a uniform grid of
18060 scan points associated with the spatial resolution of 0 :42 mm. At every scan point, the data acquisition
is conducted for a time period of 400 s at the sampling rate of 250 MHz. To minimize the impact of optical
and mechanical noise in the system, the measurements are averaged over an ensemble of 80 realizations at
each scan point. Bear in mind that both the direct inversion and PINNs deploy the spectra of normalized
velocity eldsvobsfor data inversion. Such distributions of out-of-plane particle velocity at 165 kHz ( resp. 80
kHz) in exp
1(resp.exp
2) is displayed in Fig. 15.
It should be mentioned that in the above experiments, the magnitude of measured signals in terms of
displacement is of O(nm) so that it may be appropriate to assume a linear regime of propagation. The nature
of antiplane wave motion is dispersive nonetheless. Therefore, to determine the relevant length scales in each
component, the associated dispersion curves are obtained as in Fig. 19 via a set of complementary experiments
described in Section 4.4.1. Accordingly, for excitations of center frequency ffc1;fc2;fc3g=f165;80;300gkHz,
the aliated phase velocity cand wavelength for=fAl, Ti, St, Brgis identied in Table 6.
Figure 15: Test set-ups for ultrasonic full-eld characterization: (a) an Al plate exp
1is subject to antiplane shear waves at 165
kHz by a piezoelectric transducer; the out-of-plane particle velocity eld is then captured by a laser Doppler vibrometer scanning
on a robot over the observation surface, and (b) a Ti-St-Br plate exp
2undergoes a similar test at 80 kHz and 300 kHz.
144.2. Dimensional framework
On recalling Section 2.2, let `r: =Al= 0:01 m,r: =EAl= 68:9 GPA, and r: =Al= 2700 kg/m3be
the reference scales for length, stress, and mass density, respectively. In this setting, the following maps take
the physical quantities to their dimensionless values
(;E;)!(;E;) := 1
r;1
rE;
;  =fAl, Ti, St, Brg;
(fc;;c)!(fc;;c) := 
`rrr
rfc;1
`r;rr
rc
;  = 1;2;3;
(h;f;v)!(h;f;v) := 1
`rh;`rrr
rf;rr
rv
; = 1;2;(10)
where h= 1:5 mm and frespectively indicate the specimen's thickness and cyclic frequency of wave motion.
Table 5 ( resp. Table 6) details the normal values for the rst ( resp. second) of (10). The normal thickness and
center frequencies are as follows,
ffc1;fc2;fc3g=f0:33;0:16;0:59g; h = 0:15: (11)
Table 5: Properties of the aluminum, titanium, steel and brass sheets as per the manufacturer. Here, :=E=.
physical Al Ti St Br
E[GPA] 68.9 105 199.95 110
quantity [kg/m3]2700 4510 7850 8530
 0.33 0.34 0.29 0.31
normalE 1 1.52 2.90 1.60
value 1 1.67 2.91 3.16
 1 0.91 1 0.51
Table 6: Phase velocity cand wavelength in=fAl, Ti, St, Brgatffc1;fc2;fc3g=f165;80;300gkHz as per Fig. 19,
and their normalized counterparts according to (10).
physical quantity
 Al Ti St Br
(fc1)[cm] 1     
c(fc1)[m/s] 1610:4     
(fc2)[cm]  1:4 1:4 1:17
c(fc2)[m/s]  1140 1126 936
(fc3)[cm]  0:65 0:64 0:5
c(fc3)[m/s]  1960:8 1929 1501 :6normal value
 Al Ti St Br
(fc1) 1     
c(fc1) 0:32     
(fc2)  1:4 1:4 1:17
c(fc2)  0:23 0:22 0:19
(fc3)  0:65 0:64 0:5
c(fc3)  0:39 0:38 0:3
4.3. Governing equation
In light of (11) and Table 6, observe that in all tests the wavelength-to-thickness ratio
h2[3:33 9:33],
=fAl, Ti, St, Brg. Therefore, one may invoke the equation governing exural waves in thin plates [53] to
approximate the physics of measured data. In this framework, (1) may be recast as
 =  :=h3
12(1 2
)r4 h(2f)2;  :=E
;= 1;2;
^ u =v(;f;);#=(;f);2Sobs;2Sinc; f2[0:8 1:2]fc; = 1;2;3;(12)
where;E;respectively denote the normal density, Young's modulus, and Poisson's ratio in exp
,=
1;2, andindicates the source location. Note that 0:32 according to Table 5 and , related to 1  2
,
15shows little sensitivity to small variations in the Poisson's ratio. Thus, in what follows, is treated as a
known parameter. Provided v(;f;), the objective is to reconstruct (;f).
4.4. Direct inversion
Following the reconstruction procedure of Section 3.2, the distribution of inG,= 1;2, is obtained
at specic frequencies. In this vein, the positive-denite MLP networks ?
=N(;!) and?=N(;!)
comprised of three hidden layers of respectively 20, 40, and 20 neurons are constructed according to Fig. 1.
In all MLP trainings of this section, each epoch makes use of the full dataset and the learning rate is 0 :005.
When = 1, the inversion is conducted at f1= 0:336.Sincis sampled at one point i.e., the piezoelectric
transducer remains xed during the test on Al plate, and thus, N= 1, while a concentric 60 60 subset
of collocation points sampling Sobsis deployed for training. In this setting, the input to ?
1and?is of
sizeNNN!= 36001, and their real-valued outputs are of the same size. The results are shown in
Fig. 16. When = 2, the direct inversion is conducted at f2= 0:17 andf3= 0:61. For the low-frequency
reconstruction, Sincis sampled at one point, while a 40 120 subset of scan points in G2is used for training
so that the input/output size for ?
2and?is 46001. The recovered elds and associated normal error are
provided in Fig. 17. Table 7 enlists the true values as well as mean and standard deviation of the reconstructed
distributions ?
inexp
,= 1;2, according to Figs. 16 and 17. For the high-frequency reconstruction, when
= 2,Sincis sampled at three points i.e., experiments are performed for three distinct positions of the
piezoelectric transducer, while the same subset of scan points is used for training. In this case, the input to
?
2and?is 138001, while their output is of dimension 4600 1. The high-frequency reconstruction results
are illustrated in Fig. 18, and the aliated means and standard deviations are provided in Table 8. It should
be mentioned that the computed normal errors in Figs. 16, 17, and 18 are with respect to the veried values
of Section 4.4.1. Note that the recovered ?s from laboratory test data are much smoother than the ones
reconstructed from synthetic data in Section 3.2. This could be attributed to the scaler nature of (12) with a
single unknown parameter { as opposed to the vector equations governing the in-plane wave motion with two
unknown parameters. More specically, here, ?controls the weights and biases of a single network ?
, while
in Section 3.2, ?simultaneously controls the parameters of two separate networks ?and?. A comparative
analysis of Figs. 17 and 18 reveals that (a) enriching the waveform data by increasing the number of sources
remarkably decrease the reconstruction error, (b) the regularization parameter in (3) is truly distributed
in nature as the magnitude of the recovered ?in brass is ten times greater than that of titanium and steel
which is due to the dierence in the level of noise in measurements related to distinct material surfaces, and
(c) the recovered eld ?
2{ which according to (12) is a material property E2=2, demonstrates a signicant
dependence to the reconstruction frequency. The latter calls for proper verication of the results which is the
subject of Section 4.4.1.
4.4.1. Verication
To shine some light on the nature discrepancies between the low- and high- frequency reconstructions in
Figure 16: Direct inversion of the PDE parameter 1inexp
1using test data from a single source at frequency f1= 0:336: (a) MLP-
predicted distribution 1(;f1) in2G1, (b) reconstruction error (8) with respect to the true value 1=Al= 1, (c) MLP-
recovered distribution of the regularization parameter ?, and (d) loss function L"vs. the number of epochs Nein log scale.
16Figure 17: Direct inversion of the PDE parameter 2inexp
2using test data from a single source at frequency f2= 0:17: (a) MLP-
predicted distribution 2(;f2) in2G2, (b) reconstruction error (8) with respect to the true value 22fTi;St;Brg=
f0:91;1;0:51gas per Table 5, (c) MLP-recovered distribution of the regularization parameter ?, and (d) loss function L"vs. the
number of epochs Nein log scale.
Table 7: Mean and standard deviation of the reconstructed distributions in Figs. 16 and 17 via the direct inversion of
single-source test data.
 1 2Ti 2St 2Br
 1 0:91 1 0:51
h?
iexp
1:041 0:872 0:978 0:443
(?
jexp
)0:017 0:044 0:060 0:052
Figure 18: Direct inversion of the PDE parameter 2inexp
2using test data from three source locations at frequency f3=
0:61: (a) MLP-predicted distribution 2(;f3) in2G2, (b) reconstruction error (8) with respect to the related estimates
f0:57;0:59;0:24gas per Fig. 20, (c) MLP-recovered distribution of the regularization parameter ?, and (d) loss function L"
vs. the number of epochs Nein log scale.
Table 8: Mean and standard deviation of the reconstructed distributions in Fig. 18 via the direct inversion applied to
high-frequency test data from three distinct sources.
 2Ti 2St 2Br
0
 0:57 0:59 0:24
h?
iexp
0:585 0:606 0:227
(?
jexp
)0:015 0:029 0:016
Figs. 17 and 18, a set of secondary tests are performed to obtain the dispersion curve for each component of
the test setup. For this purpose, antiplane shear waves of form (9) are induced at fcj= 50jkHz,j= 1;2;:::; 7,
17Figure 19: Experimental vs. theoretical dispersion curves f( 1
) for=fAl, Ti, St, Brg. Analytical curves (solid lines) are
computed from (13) using the pertinent properties in Table 5.
Figure 20: Discrepancy in the balance law (12) at f3= 0:61: (a) elastic force eld T1
,=fTi, St, Brg, according to (14) with
adjusted coecients fTi;St;Brg=f0:57;0:59;0:24g, (b) the inertia eld T2
, and (c) normal discrepancy D.
in 60 cm60 cm cuts of aluminum, titanium, steel, and brass sheets used in the primary tests of Fig. 15.
In each experiment, the piezoelectric transducer is placed in the middle of specimen (far from the external
boundary), and the out-of-plane wave motion is captured in the immediate vicinity of the transducer along
a straight line of length 8 cm sampled at 400 scan points. The Fourier-transformed signals in time-space
furnish the dispersion relations of Fig. 19. In parallel, the theoretical dispersion curves aliated with (12) are
computed according to
f= 2() 2s
h2
12(1 2); =E
;  =fAl, Ti, St, Brg; (13)
using the values of Table 5 for andand h= 1:5mm. A comparison between the experimental and
theoretical dispersion curves f( 1
) in Fig. 19 veries the theory and the values of Table 5 for in the low-
frequency regime of wave motion. This is also in agreement with the direct inversion results of Figs. 16 and 17.
Moreover, Fig. 19 suggests that at approximately f=f170;200;120;110gkHz for=fAl, Ti, St, Brgthe
governing PDE (12) with physical coecients fails to predict the experimental results which may provide an
insight regarding the high-frequency reconstruction results in Fig. 18. Further investigation of the balance
law (12), as illustrated in Fig. 20, shows that the test data at 312 kHz satisfy { with less than 10  20%
discrepancy depending on the material { a PDE of form (12) with modied coecients. More specically,
Fig. 20 demonstrates the achievable balance between the elastic force distribution T1
and inertia eld T2

in (12) by directly adjusting the PDE parameter 0
2to minimize the discrepancy Daccording to
T1
:=0
2h3
12(1 2
2)r4v2;T2
:=h(2f)2v2;D:=jT1
 T2
j
maxjT2j: (14)
18With reference to Table 8, the recovered coecients 0
2atf=f3= 0:61 verify the direct inversion results of
Fig. 18. This implies that the direct inversion (or PINNs) may lead to non-physical reconstructions in order to
attain the best t for the data to the \perceived"" underlying physics. Thus, it is imperative to establish the
range of validity of the prescribed physical principles in data-driven modeling. Here, the physics of the system
atf3is in transition, yet close enough to the leading-order approximation (12) that the discrepancy is less
than 20%. It is unclear, however, if this equation with non-physical coecients may be used as a predictive
tool. It would be interesting to further investigate the results through the prism of higher-order continuum
theories and a set of independent experiments for validation which could be the subject of a future study.
4.5. Physics-informed neural networks
Following Section 3.3, PINNs are built and trained using experimental test data of Section 4.4. The MLP
networkv1?=v1?(;f;xj;?
1) with six hidden layers of respectively 40, 40, 120, 80, 40, and 40 neurons is
constructed to map the out-of-plane velocity eld v1(inexp
1) related to a single transducer location x1and
frequencyf1= 0:336. The PDE parameter 1is dened as the unknown scaler parameter of the network, and
following the argument of Section 3.3, the Lagrange multiplier is specied as a nonadaptive scaler weight of
magnitude1
h(2f1)2= 1:5. The input/output dimension for v1?isNN!N= 360011, and each epoch
makes use of the full dataset for training and the learning rate is 0 :005. Keep in mind that the objective here
is to (a) construct a surrogate map for v1, and (b) identify ?
1.
Fig. 21 demonstrates (a) the accuracy of PINN-estimated eld v1?compared to the test data v1, (b)
performance of automatic dierentiation in capturing the fourth-order eld derivatives e.g., v1?
;1111that appear
in the governing PDE (12), and (c) the evolution of parameter ?
1. The comparison in (b) is with respect to the
spectral derivates of test data according to Section 2.3.2. It is no surprise that the automatic dierentiation
incurs greater errors in estimating the higher order derivatives involved in the antiplane wave motion compared
to the second-order derivatives of Section 3.3.
In addition, the PINN v2?=v2?(;f;xj;?
2) with seven hidden layers of respectively 40, 40, 120, 120, 80,
40, and 40 neurons is created to reconstruct (i) particle velocity eld v2in the layered specimen exp
2, and (ii)
distribution of the PDE parameter 2in the sampling area. The latter is dened as an unknown parameter
of the network with dimension 40 120, and the scaler weight is set to1
h(2f2)2= 5:84 for the low-frequency
reconstruction. In this setting, the input/output dimension for v2?reads 480011. Fig. 22 provides a
comparative analysis between the experimental and PINN-predicted maps of velocity and PDE parameter.
The associated statistics are provided in Table 9. It is evident from the waveform in Fig. 22 (a) that the most
pronounced errors in Fig. 22 (d) occur at the loci of vanishing particle velocity. Similar to Section 3.2, this
could be potentially addressed by enriching the test data.
5. Conclusions
The ML-based direct inversion and physics-informed neural networks are investigated for full-eld ultra-
sonic characterization of layered components. Direct inversion makes use of signal processing tools to directly
compute the eld derivatives from dense datasets furnished by laser-based ultrasonic experiments. This allows
for a simplied and controlled learning process that specically recovers the sought-for physical elds through
minimizing a single-objective loss function. PINNs are by design more versatile and particularly advantageous
with limited test data where waveform completion is desired (or required) for mechanical characterization.
PINNs multi-objective learning from ultrasonic data may be more complex but can be accomplished via
carefully gauged loss functions.
In direct inversion, Tikhonov regularization is critical for stable reconstruction of distributed PDE param-
eters from limited or multi-delity experimental data. In this vein, deep learning oers a unique opportunity
to simultaneously recover the regularization parameter as an auxiliary eld which proved to be particularly
insightful in inversion of experimental data.
In training PINNs, two strategies were remarkably helpful: (1) identifying the reference length scale by the
dominant wavelength in an eort to control the norm of spatial derivatives { which turned out to be crucial in
the case of exural waves in thin plates with the higher order PDE, and (2) estimating the Lagrange multiplier
by taking advantage of the inertia term in the governing PDEs.
19Figure 21: PINN vs. experimental maps of particle velocity and its derivatives in exp
1: (a) PINN estimates for
fv1?;v1?
;1111;v1?
;2222;v1?
;1122gwherein the derivatives are obtained by automatic dierentiation, (b) normalized LDV-captured par-
ticle velocity eld v1and its corresponding spectral derivatives, (c) normal mist 8 between (a) and (b), (d) PINN-reconstructed
PDE parameter ?
1vs. the number of epochs Ne, and (e) total loss L$and its components (the PDE residue and data mist)
vs.Nein log scale.
Laboratory implementations at multiple frequencies exposed that verication and validation are indis-
pensable for predictive data-driven modeling. More specically, both direct inversion and PINNs recover the
unknown \physical" quantities that best t the data to specic equations (with often unspecied range of va-
lidity). This may lead to mathematically decent but physically incompatible reconstructions especially when
the perceived physical laws are near their limits such that the discrepancy in capturing the actual physics
is signicant. In which case, the inversion algorithms try to compensate for this discrepancy by adjusting
the PDE parameters which leads to non-physical reconstructions. Thus, it is paramount to conduct comple-
mentary experiments to (a) establish the applicability of prescribed PDEs, and (b) validate the predictive
capabilities of the reconstructed models.
Authors' contributions
Y.X. investigation, methodology, data curation, software, visualization, writing { original draft; F.P. con-
ceptualization, methodology, funding acquisition, supervision, writing { original draft; J.S. experimental data
curation; C.W. experimental data curation.
20Figure 22: Low-frequency PINN reconstruction in exp
2using test data from a single source at f2= 0:17: (a) PINN-predicted distri-
bution of particle velocity v2?, (b) normalized LDV-captured particle velocity v2, (c) normal mist between (a) and (b), (d) PINN-
predicted distribution of the PDE parameter ?
2, and (e) total loss L$and its components (the PDE residue and data mist)
vs.the number of epochs Nein log scale.
Table 9: Mean and standard deviation of the PINN-reconstructed distributions in Fig. 22 from a single-source, low-
frequency test data.
 2Ti 2St 2Br
 0:91 1 0:51
h?
iexp
0:790 0:890 0:414
(?
jexp
)0:214 0:356 0:134
Acknowledgments
This study was funded by the National Science Foundation (Grant No. 1944812) and the University of
Colorado Boulder through FP's startup. This work utilized resources from the University of Colorado Boulder
Research Computing Group, which is supported by the National Science Foundation (awards ACI-1532235
and ACI-1532236), the University of Colorado Boulder, and Colorado State University. Special thanks are
due to Kevish Napal for facilitating the use of FreeFem++ code developed as part of [49] for elastodynamic
simulations.
References
[1] X. Liang, M. Orescanin, K. S. Toohey, M. F. Insana, S. A. Boppart, Acoustomotive optical coherence
elastography for measuring material mechanical properties, Optics letters 34 (19) (2009) 2894{2896.
[2] G. Bal, C. Bellis, S. Imperiale, F. Monard, Reconstruction of constitutive parameters in isotropic linear
elasticity from noisy full-eld measurements, Inverse problems 30 (12) (2014) 125004.
[3] B. S. Garra, Elastography: history, principles, and technique comparison, Abdominal imaging 40 (4)
(2015) 680{697.
[4] C. Bellis, H. Moulinec, A full-eld image conversion method for the inverse conductivity problem with
internal measurements, Proceedings of the Royal Society A: Mathematical, Physical and Engineering
Sciences 472 (2187) (2016) 20150488.
[5] H. Wei, T. Mukherjee, W. Zhang, J. Zuback, G. Knapp, A. De, T. DebRoy, Mechanistic models for
additive manufacturing of metallic components, Progress in Materials Science 116 (2021) 100703.
21[6] C.-T. Chen, G. X. Gu, Learning hidden elasticity with deep neural networks, Proceedings of the National
Academy of Sciences 118 (31) (2021) e2102721118.
[7] H. You, Q. Zhang, C. J. Ross, C.-H. Lee, M.-C. Hsu, Y. Yu, A physics-guided neural operator learn-
ing approach to model biological tissues from digital image correlation measurements, arXiv preprint
arXiv:2204.00205.
[8] C. M. Bishop, N. M. Nasrabadi, Pattern recognition and machine learning, Vol. 4, Springer, 2006.
[9] Y. LeCun, Y. Bengio, G. Hinton, Deep learning, nature 521 (7553) (2015) 436{444.
[10] S. Cuomo, V. S. Di Cola, F. Giampaolo, G. Rozza, M. Raissi, F. Piccialli, Scientic machine
learning through physics-informed neural networks: Where we are and what's next, arXiv preprint
arXiv:2201.05624.
[11] S. Wang, H. Wang, P. Perdikaris, Improved architectures and training algorithms for deep operator
networks, Journal of Scientic Computing 92 (2) (2022) 1{42.
[12] L. McClenny, U. Braga-Neto, Self-adaptive physics-informed neural networks using a soft attention mech-
anism, arXiv preprint arXiv:2009.04544.
[13] Z. Chen, V. Badrinarayanan, C.-Y. Lee, A. Rabinovich, Gradnorm: Gradient normalization for adaptive
loss balancing in deep multitask networks, in: International conference on machine learning, PMLR, 2018,
pp. 794{803.
[14] M. Raissi, P. Perdikaris, G. E. Karniadakis, Physics informed deep learning (part i): Data-driven solutions
of nonlinear partial dierential equations, arXiv preprint arXiv:1711.10561.
[15] M. Raissi, P. Perdikaris, G. E. Karniadakis, Physics-informed neural networks: A deep learning framework
for solving forward and inverse problems involving nonlinear partial dierential equations, Journal of
Computational physics 378 (2019) 686{707.
[16] E. Haghighat, M. Raissi, A. Moure, H. Gomez, R. Juanes, A physics-informed deep learning framework
for inversion and surrogate modeling in solid mechanics, Computer Methods in Applied Mechanics and
Engineering 379 (2021) 113741.
[17] A. Henkes, H. Wessels, R. Mahnken, Physics informed neural networks for continuum micromechanics,
Computer Methods in Applied Mechanics and Engineering 393 (2022) 114790.
[18] R. Muthupillai, D. Lomas, P. Rossman, J. F. Greenleaf, A. Manduca, R. L. Ehman, Magnetic resonance
elastography by direct visualization of propagating acoustic strain waves, science 269 (5232) (1995) 1854{
1857.
[19] P. E. Barbone, N. H. Gokhale, Elastic modulus imaging: on the uniqueness and nonuniqueness of the
elastography inverse problem in two dimensions, Inverse problems 20 (1) (2004) 283.
[20] O. A. Babaniyi, A. A. Oberai, P. E. Barbone, Direct error in constitutive equation formulation for plane
stress inverse elasticity problem, Computer methods in applied mechanics and engineering 314 (2017)
3{18.
[21] A. N. Tikhonov, A. Goncharsky, V. Stepanov, A. G. Yagola, Numerical methods for the solution of
ill-posed problems, Vol. 328, Springer Science & Business Media, 1995.
[22] A. Kirsch, et al., An introduction to the mathematical theory of inverse problems, Vol. 120, Springer,
2011.
[23] On the convergence of physics informed neural networks for linear second-order elliptic and parabolic
type pdes, Communications in Computational Physics 28 (5) (2020) 2042{2074.
22[24] S. Wang, X. Yu, P. Perdikaris, When and why pinns fail to train: A neural tangent kernel perspective,
Journal of Computational Physics 449 (2022) 110768.
[25] Z. Xiang, W. Peng, X. Liu, W. Yao, Self-adaptive loss balanced physics-informed neural networks, Neu-
rocomputing 496 (2022) 11{34.
[26] R. Bischof, M. Kraus, Multi-objective loss balancing for physics-informed deep learning, arXiv preprint
arXiv:2110.09813.
[27] H. Son, S. W. Cho, H. J. Hwang, Al-pinns: Augmented lagrangian relaxation method for physics-informed
neural networks, arXiv preprint arXiv:2205.01059.
[28] S. Zeng, Z. Zhang, Q. Zou, Adaptive deep neural networks methods for high-dimensional partial dier-
ential equations, Journal of Computational Physics 463 (2022) 111232.
[29] J. Yu, L. Lu, X. Meng, G. E. Karniadakis, Gradient-enhanced physics-informed neural networks for
forward and inverse pde problems, Computer Methods in Applied Mechanics and Engineering 393 (2022)
114823.
[30] S. Wang, Y. Teng, P. Perdikaris, Understanding and mitigating gradient ow pathologies in physics-
informed neural networks, SIAM Journal on Scientic Computing 43 (5) (2021) A3055{A3081.
[31] A. D. Jagtap, K. Kawaguchi, G. Em Karniadakis, Locally adaptive activation functions with slope recovery
for deep and physics-informed neural networks, Proceedings of the Royal Society A 476 (2239) (2020)
20200334.
[32] Y. Kim, Y. Choi, D. Widemann, T. Zohdi, A fast and accurate physics-informed neural network reduced
order model with shallow masked autoencoder, Journal of Computational Physics 451 (2022) 110841.
[33] G. I. Barenblatt, Scaling (Cambridge texts in applied mathematics), Cambridge University Press, Cam-
bridge, UK, 2003.
[34] K. Hornik, Approximation capabilities of multilayer feedforward networks, Neural networks 4 (2) (1991)
251{257.
[35] Y. Chen, L. Dal Negro, Physics-informed neural networks for imaging and parameter retrieval of photonic
nanostructures from near-eld data, APL Photonics 7 (1) (2022) 010802.
[36] F. Pourahmadian, B. B. Guzina, On the elastic anatomy of heterogeneous fractures in rock, International
Journal of Rock Mechanics and Mining Sciences 106 (2018) 259 { 268.
[37] X. Liu, J. Song, F. Pourahmadian, H. Haddar, Time-vs. frequency-domain inverse elastic scattering:
Theory and experiment, arXiv preprint arXiv:2209.07006.
[38] F. Pourahmadian, B. B. Guzina, H. Haddar, Generalized linear sampling method for elastic-wave sensing
of heterogeneous fractures, Inverse Problems 33 (5) (2017) 055007.
[39] F. Cakoni, D. Colton, H. Haddar, Inverse Scattering Theory and Transmission Eigenvalues, SIAM, 2016.
[40] V. A. Morozov, Methods for solving incorrectly posed problems, Springer Science & Business Media,
2012.
[41] R. Kress, Linear integral equation, Springer, Berlin, 1999.
[42] A. Paszke, S. Gross, S. Chintala, G. Chanan, E. Yang, Z. DeVito, Z. Lin, A. Desmaison, L. Antiga,
A. Lerer, Automatic dierentiation in pytorch.
[43] H. Brezis, Functional analysis, Sobolev spaces and partial dierential equations, Springer Science &
Business Media, 2010.
23[44] T. Ha-Duong, On retarded potential boundary integral equations and their discretization, in: Topics in
computational wave propagation, Springer, 2003, pp. 301{336.
[45] R. T. Rockafellar, Lagrange multipliers and optimality, SIAM review 35 (2) (1993) 183{238.
[46] H. Everett III, Generalized lagrange multiplier method for solving problems of optimum allocation of
resources, Operations research 11 (3) (1963) 399{417.
[47] D. Liu, Y. Wang, A dual-dimer method for training physics-constrained neural networks with minimax
architecture, Neural Networks 136 (2021) 112{125.
[48] F. Hecht, New development in freefem++, Journal of Numerical Mathematics 20 (3-4) (2012) 251{265.
URL https://freefem.org/
[49] F. Pourahmadian, K. Napal, Poroelastic near-eld inverse scattering, Journal of Computational Physics
455 (2022) 111005.
[50] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein,
L. Antiga, A. Desmaison, A. Kopf, E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner,
L. Fang, J. Bai, S. Chintala, Pytorch: An imperative style, high-performance deep learning library,
Advances in neural information processing systems 32.
[51] D. P. Kingma, J. Ba, Adam: A method for stochastic optimization, arXiv preprint arXiv:1412.6980.
[52] Pytorch implementation of physics-informed neural networks, https://github.com/jayroxis/PINNs
(2022).
[53] K. F. Gra, Wave motion in elastic solids, Courier Corporation, 2012.
24