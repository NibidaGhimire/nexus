arXiv:2401.05386v1  [eess.SP]  18 Dec 2023EMG subspace alignment and visualization for
cross-subject hand gesture classiﬁcation
Martin Colot1, Cédric Simar1,2, Mathieu Petieau2,
Ana Maria Cebolla Alvarez2, Guy Cheron2, and Gianluca Bontempi1
1Machine Learning Group - ULB, Belgium
2Laboratory of Neurophysiology and Movement Biomechanics ( LNMB) and
ULB-Neuroscience Institut (UNI) - ULB, Belgium
Abstract. Electromyograms (EMG)-based hand gesture recognition sys -
tems are a promising technology for human/machine interfac es. How-
ever, one of their main limitations is the long calibration t ime that is
typically required to handle new users. The paper discusses and anal-
yses the challenge of cross-subject generalization thanks to an original
dataset containing the EMG signals of 14 human subjects duri ng hand
gestures. The experimental results show that, though an acc urate gen-
eralization based on pooling multiple subjects is hardly ac hievable, it is
possible to improve the cross-subject estimation by identi fying a robust
low-dimensional subspace for multiple subjects and aligni ng it to a target
subject. A visualization of the subspace enables us to provi de insights
for the improvement of cross-subject generalization with E MG signals.
Keywords: EMG classiﬁcation · Cross-subject adaptation · Subspace
alignment.
1 Introduction
The recognition of hand gestures from electromyographic (E MG) signals is im-
portant for many brain-computer interfaces (BCI) applicat ions, such as robotic
hand prostheses, video game control, or sign language recog nition. The muscle
activity is recorded through surface electrodes, placed on the skin, and processed
by a machine learning model to classify instantaneous hand p ostures. These mod-
els have become very accurate when considering a single subj ect and session [8].
However, they often lack generalization across subjects. A major diﬃculty when
working with EMG signals is that they are highly person-spec iﬁc [7,6] due to
intrinsic diﬀerences in anatomical and physiological char acteristics. Also, small
shifts in the location of the electrodes can signiﬁcantly aﬀ ect the recorded signal.
In order to deal with real-world settings, EMG-based system s must tackle the
cross-subject issue, i.e., be able to generalize to other users (targets) t han the
ones used for training (sources). This is necessary since lo ng phases of labeled
data collection are not acceptable in real settings, and may even be impossible
for impaired users. We tackle this issue as an unsupervised d omain adaptation2 M. Colot et al.
(UDA) problem where labeled samples from multiple source su bjects are avail-
able, and a model has to classify unlabelled samples from a ta rget subject. In a
real-world implementation, the model would have an initial low eﬃciency with a
new user. Then, as new unlabelled samples are collected, the model parameters
would regularly be updated through UDA to improve the estima tion.
In this paper, we focus on bridging the gap between intra-sub ject (training
and testing on the same person) and cross-subject classiﬁca tion by analyzing an
original EMG dataset where 14 participants perform 4 simple hand postures. We
start by considering several dimensionality reduction str ategies to better under-
stand the dissimilarities that occur in the dataset and ﬁnd a simpler represen-
tation of the samples. We then show that a common low-dimensi onal subspace
can help to perform unsupervised domain adaptation, improv ing the classiﬁ-
cation accuracy on a target subject. The paper presents the f ollowing results:
i) an assessment of hand gesture classiﬁcation from EMG in in tra-subject and
cross-subject conﬁgurations in the original signal space, ii) the deﬁnition and
visualization of a common low-dimensional subspace, and ii i) the assessment of
subspace alignment domain adaptation with a leave-one-sub ject-out strategy.
2 Related Work
Classiﬁcation of hand gestures from EMG signals has attract ed large attention
in machine learning [8]. However, since the number of classe s, hand gestures,
and data acquisition are very heterogeneous over diﬀerent s tudies, it is hard to
deﬁne a state-of-the-art baseline accuracy. Nevertheless , it appears that, when
few classes are considered, the intra-subject classiﬁcati on accuracy is typically
above 90% [8]. EMG signals are usually classiﬁed using eithe r a shallow machine-
learning model with handcrafted features or a deep CNN with t he raw signal
[7,4]. Recently, CNN has become the primary choice for EMG cl assiﬁcation.
However, with few signs to recognize, it is often possible to obtain similar results
with a shallow neural network or handcrafted features [4].
Cross-subject classiﬁcation usually involves training a s ingle classiﬁer on
pooled samples from many source subjects, with the aim of obt aining enough
generalization to handle new subjects. However, [7] stress es that, without ﬁne-
tuning for the target subject, the accuracy stays low even wi th many sources sub-
jects. We refer to unsupervised domain adaptation as transf er learning methods
that use unlabeled samples from a target domain that is diﬀer ent but related to
the source domain. Cross-subject EMG classiﬁcation is typi cally a multi-sources
domain adaptation problem as we can access labeled samples f rom a set of source
subjects and adapt the model to a target subject using only un labeled samples.
This problem has recently attracted attention for classify ing high-density EMG
(HD-EMG) with the implementations of deep neural network-b ased methods.
In [3], the AdaBN method is used to adapt a deep convolutional neural network.
In the cross-subject conﬁguration, their method improves t he accuracy from 39%
to 55.3% with 10 subjects and 8 hand gestures. In [14], a sampl ing strategy that
aligns the marginal distributions of the sources and target domains is introduced.Cross-subject EMG subspace alignment and visualization 3
They show that it adapts the model better than AdaBN, up to clo sing the gap
between intra-subjet and cross-subject with HD-EMG.
3 The experimental setting
Our experiments are conducted with an original dataset of 14 participants. It
contains 400ms non-overlapping windows of EMG during the ho ld of 4 diﬀerent
ﬁnger postures. The data acquisition protocol is detailed i n appendix A3[1]. To
classify those samples, we use engineered features that hav e led to good EMG
classiﬁcation in related studies [4]. Those are the mean abs olute value, root mean
square, waveform length, zero crossing, Wilson amplitude, maximum absolute
amplitude, and integral. We compute them on each of the 8 EMG c hannels,
which gives us a feature vector of size 56.
4 Baseline classiﬁers
For the intra-subject baseline, we train one classiﬁer for e ach subject; we take
90% of the samples for training and 10% for testing in a 10-fol d cross-validation.
We then compute the average classiﬁcation accuracy. For cro ss-subject conﬁgu-
rations, leave-one-subject-out cross-validation is used . We pool the samples from
13 subjects to create the training set and use those from the r emaining subject
for testing. All our experiments are conducted using simila r classiﬁcation mod-
els. We use a multi-layer perceptron neural network with one hidden layer and
a logistic activation function. We keep 90% of the training s et for ﬁtting the
model and 10% as the validation set. The model is trained unti l convergence of
the classiﬁcation accuracy on the validation set, with a max imum of 1000 epochs.
The hidden layer is set to contain 100 nodes in the intra-subj ect conﬁgurations
and only 10 in the cross-subject conﬁgurations. This is set t o reduce the eﬀect
of overﬁtting in cross-subject conﬁgurations.
The baseline classiﬁcation reaches 93.1% accuracy for intr a-subject and 69.8%
for cross-subject. While this result highlights the cross-subject issue, it also as-
sesses the quality of our model as its performance is similar to the state-of-the-art
(typically above 90% for intra-subject models). For the fol lowing tests, we con-
sider that the model has access to all the unlabelled target s amples at training
time and that those samples contain only EMG samples from the 4 recognized
classes. In a real-world setting, the model should be able to discriminate between
samples that correspond to a speciﬁc gesture class or no inte nded gesture. We
simplify the problem to concentrate on highlighting the cro ss-subject issue.
5 Dimensionality reduction for cross-subject learning
This section explores the role of dimensionality reduction in improving cross-
subject generalization. The rationale of the analysis is th at the poor accuracy
3This dataset is expected to be published shortly in another p aper.4 M. Colot et al.
of the cross-subject classiﬁcation observed in the previou s section might be im-
proved by ﬁnding a subspace where the intra-subject conditi onal distributions
are more similar. We consider the following dimensionality reduction strategies:
Principal Component Analysis (PCA), Kernel PCA (KPCA) with cosine and
polynomial kernel, independent component analysis (ICA), and singular value
decomposition (SVD). The plot in Figure 1.a reports the clas siﬁcation accuracy
in intra-subject conﬁgurations, where these algorithms ar e ﬁtted on each sub-
ject separately. It appears that KPCA with a cosine kernel oﬀ ers the best data
the projection space
Intra-subject in the original space
Cross-subject in the original space
Intra-subject in the subject's subspace
Intra-subject in the common subspace
Cross-subject in the common subspace
(a)                                                                  (b)
Fig.1. (a) Intra-subject classiﬁcation accuracy for diﬀerent dimens ionality reduction
algorithms and an increasing number of dimensions of the pro jection space. (b)Clas-
siﬁcation accuracy for an increasing number of dimensions o f the KPCA subspace.
representation with few dimensions. We evaluate the qualit y of this subspace for
cross-subject estimation. Considering a leave-one-subje ct-out strategy, we ﬁt the
projection on the pooled samples from all sources subjects t o ﬁnd a common sub-
space. We project all the samples in this subspace and comput e the cross-subject
accuracy. The results are shown in Figure 1.b. The main concl usions deriving
from the conducted experiments are i) for a single subject, t he EMG signals
may be eﬀectively embedded in a low-dimensional space so tha t a classiﬁcation
model keeps high accuracy, ii) selecting a common subspace f or all subjects does
not help with the cross-subject issue. It remains however an open question: do
the subjects diﬀer in terms of subspace or in terms of distrib utions, yet over
the same subspace? In order to settle the question, we implem ent and assess a
cross-subject dimensionality reduction step. The idea is t o use all the subjects
with one set aside (leave-one-subject-out) to derive a comm on low-dimension
subspace and then test such subspace (source) on the remaini ng subject (tar-
get). Note that in this case, though the subspace has been obt ained from the
other subjects, the training set contains only the EMG signa ls of the target.
From the orange line in Figure 1.b, it appears that the intra- subject accuracy
in the common subspace falls just below the accuracy obtaine d in the targetCross-subject EMG subspace alignment and visualization 5
subject’s speciﬁc subspace. This suggests that the subspac es of diﬀerent subjects
are similar but not the same. The mapping between the feature s and labels must
be diﬀerent with each subject to explain the poor cross-subj ect accuracy.
6 Visualization of the low-dimensional subspace
We have shown in Section 5 that there is a low-dimensional KPC A subspace
that is convenient for training a classiﬁer for all the subje cts. This section uses
the ﬁrst 2 components of such projection (computed from the e ntire dataset) to
gain a visual insight into the distribution of both the poole d dataset (left side of
Figure 2.a) and the individual subjects (the right side of Fi gure 2.a shows the
ﬁrst 6 subjects). As we can see, when looking at one subject at a time, the class
clusters are often separable, even with only 2 dimensions. H owever, the shape and
positions of those clusters are very subject-dependent. Th e leftmost subﬁgure
shows that once pooled all the subjects together, the class c lusters are hardly
separable. This explains the poor accuracy obtained with cr oss-subject training
of the classiﬁcation model. To show that this eﬀect stays in h igher dimensions,
we provide a t-SNE projection of the samples in Figure 2.b. Th is projection is
computed from the 10-dimensional common subspace as it prov ides good intra-
subject classiﬁcation. This enables us to show that even whe n considering the
complete low-dimensional subspace, the class clusters are easier to separate when
looking at one subject at a time than when pooling the subject s together.
t-SNEt-SNE
(a)                                                                                                               (b)
Fig.2. (a) KPCA projections of the samples from all subjects in a common subspace.
(b)t-SNE visualization of the samples from all subjects in the c ommon KPCA subspace
7 Subspace alignment for domain adaptation
Subspace alignment (SA) [5] is a UDA method that projects the samples from
two diﬀerent but related domains into a single subspace usin g PCA projections
of the two domains. We suggest that applying this method to ou r engineered
features will yield a common subspace, with a better corresp ondence between
the source and target domains. As in section 5, cosine KPCA ga ve better results
than PCA; we adapted the simple SA to work with cosine kernel. As explained6 M. Colot et al.
in [10], the cosine similarity function is equivalent to the linear kernel (used by
PCA) if the data is L2-normalized. Hence, applying L2-norma lization on each
subject enables us to use standard SA to align the same subspa ces as the one
obtained with cosine KPCA. We implement an estimator, using all the source
subjects as a single pooled domain, and apply SA to align the c ommon KPCA
subspace of those source subjects with the target subject’s KPCA subspace.
We validate the alignment eﬃciency in leave-one-subject-o ut cross-validation.
The results in Figure 3 show that this domain adaptation meth od obtains a
better accuracy than the cross-subject’s baseline. The mod el converges to 79.5%
Intra-subject in the original space
Cross-subject in the original space
Intra-subject in the subject's subspace
Intra-subject in the common subspace
Cross-subject in the common subspace
Cross-subject with SA
Fig.3. Comparison of the classiﬁcation accuracy obtained with KPC A SA and with
the other strategies for an increasing number of dimensions of the KPCA subspace.
accuracy, obtained with only 10 dimensions of the KPCA subsp ace. The posthoc
analysis of these results using a Nemenyi test [2] (given in F igure 4) shows that
this result is signiﬁcantly better than the cross-subject b aseline. However, it
doesn’t close the gap between cross-subject and intra-subj ect.
Intra-subj ect in original space
Intra         	  a 
                   a  
Intra         	 a 
   	          a  
 
          	 
C

  	 a
  a   
           	 a 
   	         a   
         
 
C   
A
Fig.4. Average rank of the diﬀerent classiﬁers (the lower, the bett er). Classiﬁers that
are not signiﬁcantly diﬀerent are connected (at p = 0.05 found by a Nemenyi test [2]).
We ﬁnish by comparing the KPCA SA with other UDA methods. Firs t, we
test the standard PCA SA by not applying L2-normalization to see if it has any
impact on the model. After that, we test the Correlation Alig nment (CORAL)
algorithm [12]. This method aligns the second-order statis tics of the sources and
target domains. Finally, we introduce an instance-based do main adaptation al-
gorithm. The Kullback-Leibler Importance Estimation Proc edure (KLIEP) [11]Cross-subject EMG subspace alignment and visualization 7
ﬁnds a weighing of the sources samples that minimizes the diﬀ erences with the
target domain distribution. This strategy does not aﬀect th e feature space, con-
trary to SA and CORAL. CORAL and KLIEP are tested both in the or iginal
feature space (with L2-normalization) and in the common KPC A subspace found
on source subjects. We used 10 dimensions for the KPCA subspa ce as it gave
the best results in ﬁgure 3. The results in Figure 5 show that a ll of these models
are less eﬃcient than KPCA SA.
Intra-subject
Original space
(baseline)Intra-subject
T arget subject's
KPCA subspaceIntra-subject
Common
KPCA subspaceCross-subject
Original space
(baseline)Cross-subject
Common
KPCA subspaceCross-subject
KPCA SACross-subject
PCA SACross-subject
CORALCross-subject
CORAL
in KPCA subspaceCross-subject
KLIEPCross-subject
KLIEP
in KPCA subspace0.40.60.81.0Accuracy
Fig.5. Comparison of the results from the diﬀerent models
8 Conclusion
The literature on EMG-based hand gesture classiﬁcation is f ull of highly accurate
results as far as a single subject is concerned. The story cha nges when several
subjects are pooled together. This paper conﬁrms the limita tions of naive cross-
subject approaches, which simply rely on pooling together t he data of several
subjects. At the same time, our results show that it is possib le to ﬁnd a common
robust subspace in which classiﬁers can rapidly be tuned to d iﬀerent subjects.
Though such a common subspace is low-dimensional, the assoc iated classiﬁers
are competitive with the ones ﬁtted to speciﬁc individuals. Moreover, we showed
that this subspace helps improve the accuracy of cross-subj ect classiﬁers. Using
SA to align the target’s speciﬁc subspace to the common subsp ace found on
sources, we improved the accuracy from 69.8% to 79.5%.
Such a result is encouraging, but it should be considered as a ﬁrst step in the
deﬁnition of a robust methodology to solve the cross-subjec t problem of learning
from electrophysiological signals. A limitation of this st udy is the small complex-
ity of the problem as we only considered able-bodied partici pants performing
simple gestures. We showed that it is suﬃcient to highlight t he cross-subject is-
sue but future research will have to extend this analysis to m ore complex settings
by involving hand gestures with multiple degrees of freedom and an assessment
with amputee users. Finally, to further close the gap betwee n intra-subject and
cross-subject estimation, future work will focus on four as pects: i) enlarging the
dataset by including additional subjects to enhance the ass essment of the ap-
proach, ii) extending the search of a common subspace to supe rvised strategies
(e.g., feature selection based on a leave-one-subject-out criterion), iii) making
use of more recent and more eﬃcient alignment methods such as those described8 M. Colot et al.
in [13] and [9], and iv) ﬁnding a strategy to incorporate the v ariability of all the
source subjects better than naive pooling, which assumes a s ingle source domain.
Acknowledgements We gratefully thank all the members of the Laboratory
of Neurophysiology and Movement Biomechanics (ULB) for the expertise and
equipment they provided us during our data acquisition for t his work.
References
1. Colot, M., Bontempi, G., Chéron, G., Simar, C.: Hand gestu res estimation
from emg and vr a machine learning approach (2022), master Th esis, ULB.
https://mlg.ulb.ac.be/wordpress/members-2/martincol ot/
2. Demšar, J.: Statistical comparisons of classiﬁers over m ultiple data sets. The Jour-
nal of Machine learning research 7, 1–30 (2006)
3. Du, Y., Jin, W., Wei, W., Hu, Y., Geng, W.: Surface emg-base d inter-session
gesture recognition enhanced by deep domain adaptation. Se nsors17(3), 458
(2017)
4. Fajardo, J.M., Gomez, O., Prieto, F.: Emg hand gesture cla ssiﬁcation using hand-
crafted and deep features. Biomedical Signal Processing an d Control 63, 102210
(2021)
5. Fernando, B., Habrard, A., Sebban, M., Tuytelaars, T.: Su bspace alignment for
domain adaptation. arXiv preprint arXiv:1409.5241 (2014)
6. Gu, X., Guo, Y., Deligianni, F., Lo, B., Yang, G.Z.: Cross- subject and cross-modal
transfer for generalized abnormal gait pattern recognitio n. IEEE Transactions on
Neural Networks and Learning Systems 32(2), 546–560 (2020)
7. Hoshino, T., Kanoga, S., Tsubaki, M., Aoyama, A.: Compari ng subject-to-subject
transfer learning methods in surface electromyogram-base d motion recognition
with shallow and deep classiﬁers. Neurocomputing 489, 599–612 (2022)
8. Jaramillo-Yánez, A., Benalcázar, M.E., Mena-Maldonado , E.: Real-time hand ges-
ture recognition using surface electromyography and machi ne learning: A system-
atic literature review. Sensors 20(9), 2467 (2020)
9. Saito, K., Watanabe, K., Ushiku, Y., Harada, T.: Maximum c lassiﬁer discrepancy
for unsupervised domain adaptation. In: Proceedings of the IEEE conference on
computer vision and pattern recognition. pp. 3723–3732 (20 18)
10. Schutze, H., Manning, C.D., Raghavan, P.: Introduction to information retrieval.
Cambridge University Press (2008)
11. Sugiyama, M., Nakajima, S., Kashima, H., Buenau, P., Kaw anabe, M.: Direct
importance estimation with model selection and its applica tion to covariate shift
adaptation. Advances in neural information processing sys tems20(2007)
12. Sun, B., Feng, J., Saenko, K.: Return of frustratingly ea sy domain adaptation. In:
Proceedings of the AAAI conference on artiﬁcial intelligen ce. vol. 30 (2016)
13. Xu, R., Li, G., Yang, J., Lin, L.: Larger norm more transfe rable: An adaptive
feature norm approach for unsupervised domain adaptation. In: Proceedings of
the IEEE/CVF international conference on computer vision. pp. 1426–1435 (2019)
14. Zhang, X., Zhang, X., Wu, L., Li, C., Chen, X., Chen, X.: Do main adaptation with
self-guided adaptive sampling strategy: Feature alignmen t for cross-user myoelec-
tric pattern recognition. IEEE Transactions on Neural Syst ems and Rehabilitation
Engineering 30, 1374–1383 (2022)arXiv:2401.05386v1  [eess.SP]  18 Dec 20231
A Data acquisition protocol
We collected an original dataset of forearm EMG signals (usi ng 8 Cometa Pico
electrodes on the right arm) during controlled exercises of 14 participants. Each
subject was asked to keep his right hand open, then hold a spec iﬁc ﬁnger posture
(called sign) for at least two seconds before opening back to the resting pose for
at least six seconds. We included 4 signs, each demanding the participant to
close every ﬁnger except one (thumb, index, middle or little ﬁnger). Each sign
was repeated 30 times per participant. We used the motion cap ture system
from an Oculus Quest to detect the sign held by the subject and easily label
the samples. This virtual reality device also enabled placi ng the subject in a
controlled environment and showing him which gesture to per form.
To emulate a real-time hand gesture estimation model, a 400m s sliding non-
overlapping window was considered to create the samples. We only kept the
samples that were recorded during the hold of a sign, not thos e taken during the
gesture that lead to the ﬁnal posture. This sampling strateg y returns around 150
samples per sign for each participant. Each sample contains 400ms of 8 EMG
channels with a sampling frequency of 2000Hz.
The EMG electrodes were placed using a similar pattern for ea ch participant.
This pattern was chosen beforehand from a preliminary exper iment performed
with a couple of participants. We used electrical stimulati on of the forearm so
that the ﬂexion and extension of each ﬁnger (except the ring ﬁ nger) are targeted.
This pattern is shown in ﬁgure 1. Even if care was taken to plac e the electrodes
at the same location with each participant, a small location shift likely occurs
between each of them.
Fig.1. Locations of the EMG electrodes on the forearm