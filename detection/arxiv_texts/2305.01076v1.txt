Design and Evaluation of a Bioinspired Tendon-Driven 3D-Printed
Robotic Eye with Active Vision Capabilities
Hamid Osooli1, Mohsen Irani Rahaghi2and S. Reza Ahmadzadeh1
Abstract — The ﬁeld of robotics has seen signiﬁcant advance-
ments in recent years, particularly in the development of
humanoid robots. One area of research that has yet to be
fully explored is the design of robotic eyes. In this paper, we
propose a computer-aided 3D design scheme for a robotic eye
that incorporates realistic appearance, natural movements, and
efﬁcient actuation. The proposed design utilizes a tendon-driven
actuation mechanism, which offers a broad range of motion
capabilities. The use of the minimum number of servos for actu-
ation, one for each agonist-antagonist pair of muscles, makes the
proposed design highly efﬁcient. Compared to existing ones in
the same class, our designed robotic eye comprises aesthetic and
realistic features. We evaluate the robot’s performance using
a vision-based controller, which demonstrates the effectiveness
of the proposed design in achieving natural movement, and
efﬁcient actuation. The experiment code, toolbox, and printable
3D sketches of our design have been open-sourced.
I. INTRODUCTION
Despite the advancements in robotic technology, replicat-
ing the capabilities and movements of the human eye has
remained a topic of active research in recent years. To better
understand the mechanics and functionalities of the human
eye, several studies focus on creating robots that mimic its
movements and abilities [1], [2], [3].
Previous efforts to design a mechanism similar to the
human eye have been based on mechanical models, such
as the Ruete mechanical model, also known as the Oph-
talmotrope [4], [5]. The Ophtalmotrope in [4] features two
wooden eyeballs, each linked to six polypropylene Masons
Strings which represent the extra-ocular muscles.
In recent decades, researchers have designed robotic
eyes by utilizing advanced materials such as Super Coiled
Polymers [1], Folded Dielectric Elastomer Actuators [6]
and Pneumatic Artiﬁcial Muscles [7]. The disadvantage
of using advanced materials is that the system requires
additional components to measure the material properties
which increases the complexity of the whole system. For
instance measuring the electric current passing through the
super coiled polymer muscles requires an extra Raspberry
Pi [1]. Another example is measuring the orientation for
the Pneumatic Artiﬁcial Muscles by an embedded 3-Axis
Micro Electro Mechanical accelerometer in [7]. On the other
hand, robotic eyes that are too simpliﬁed, lack aesthetics and
appearance [8], [9].
1Persistent Autonomy and Robot Learning (PeARL) Lab, University
of Massachusetts Lowell, Lowell, MA 01854, USA fhamid osooli,
reza ahmadzadeh g@uml.edu
2Mechanical Engineering Department, University of Kashan, Kashan,
Isfahan, Iran irani@kashanu.ac.irEfﬁcient actuation and natural movements are among the
main features of an effective human-like robotic eye. One
technique towards creating human-like movements in robots
is the use of tendon-driven mechanisms for robot actuation.
Tendon-driven robots, in which wires (tendons) serve as
muscle-like elements, provide greater freedom of movement
compared to traditional, rigid systems [10]. The use of
tendon-driven systems for various robotic applications has
been explored by researchers [11], [12], [13]. However, there
has been limited research on the application of tendon-driven
systems to the design of the robots that mimic the mechanism
of the human eye. The drawback of the existing works
that use tendon-driven mechanism is the use of redundant
actuators in the design [1], [14].
In this paper we propose a bioinspired design for a robotic
eye that uses a minimum number of actuators to achieve
natural human-like movements. Our designed system repli-
cates human eye movements, while also using a minimum
number of actuators. We equip our robot with a vision-
based controller and evaluate its performance over the main
four movements of human eye: Saccadic, Smooth Pursuit,
Vergence, and Vestibulo-Ocular Reﬂex (VOR).
We perform eight experiments (two per movement) to
showcase the capabilities of the proposed robot. Our results
show that the proposed robot is capable of mimicking all
four categories of human eye movements by detecting and
following human face while centralizing it simultaneously.
The code for the experiments, toolbox, and the printable 3D
sketches of the proposed robotic eye are open sourced.
II. B ACKGROUND
A. The Human Eye
The human eye is a roughly spherical organ that is
composed of two main parts: the cornea and the sclera.
The cornea is the front part of the eye that is more curved,
and includes the black center of the eye (the pupil) and
the colored ring around it (the iris). The sclera is the white
part of the eyeball that contains the necessary structures for
receiving visual information. In order to see clear images, the
image must be focused on a small region called the fovea
located within the sclera. As a result, the eye must move to
bring an image into focus on the fovea [15].
Six extra-ocular muscles are responsible for rotating each
eye within the bony orbit of the skull. These muscles are
composed of four rectus muscles (superior, inferior, medial,
and lateral) and two oblique muscles (superior and inferior).
The rectus muscles attach to the eyeball at a point 55 degrees
away from the optical axis [16], and are responsible forarXiv:2305.01076v1  [cs.RO]  1 May 2023moving the eye in the horizontal and vertical directions. The
oblique muscles pass through a structure called the trochlea,
and rotate the eye around the visual axis. To move the eye, a
pair of these muscles work in an agonist-antagonist fashion;
for example, the medial rectus muscle contracts while the
lateral rectus muscle relaxes to rotate the eye towards the
nose.
B. Eye Movements
There are several motivations for eye movement. One of
the main motivations is to ﬁxate on a target in the visual ﬁeld.
Another motivation is to prevent visual adaptation to a static
scene, which can lead to a phenomenon known as neural
fading [17]. This can be prevented by small, involuntary eye
movements called micro Saccades that refresh the visual in-
put [18]. Eye movements also continue to occur during sleep,
speciﬁcally during Rapid Eye Movement (REM) sleep [19].
There are four main categories of eye movements: Sac-
cades, Smooth Pursuit, Vergence, and Vestibulo-Ocular Re-
ﬂex (VOR). Saccades are quick, jerky movements of the eyes
that bring the gaze to a new target. For example, tracking
a ﬂying insect in the air. Smooth pursuit movements are
controlled movements of the eyes that are used to track a
moving target smoothly, such as when reading a line of text.
Vergence movements involve the simultaneous movement of
the eyes in opposite directions towards each other, which
occurs when an object is located at close proximity. VOR, is
an oculomotor reﬂex that compensates for head movements
by moving the eyes in the opposite direction of the head
movement. It is dependent on the vestibular system, which
is responsible for detecting head movement.
III. B IOINSPIRED DESIGN
In this paper, we focus on the development of a robotic
eye by designing and building an accurate mechanical model
of the human eye. The resulting robotic eye could be used
in several robotics and vision applications such as stereo
cameras, humanoid robots, and active vision. To achieve
this goal, we leverage Computer Aided Design (CAD) to
construct a robotic eye. The beneﬁt of using CAD is that
we are able to 3D print the mechanical sketches using
Acrylonitrile Butadiene Styrene (ABS) ﬁlaments. In this
section, we provide a detailed description of the design
considerations for each component of our proposed robotic
eye, including the cornea, iris, and lens. We also explain how
we validate the accuracy of the model and how it can be used
in future research studies.
A. The Eyeball
The mechanical eyeball consists of a chamber, shown in
Fig. 1, to host a single-view USB camera. We selected a
Microsoft LifeCam HD-3000 webcam as it is an inexpensive
and readily available perception sensor that helps keep the
overall cost of the robot low.
To achieve this goal, we designed a 60 mm diameter
eyeball that could accommodate our USB camera. This is
more than twice the size of a typical adult human eyeball,
Fig. 1. The designed cornea (a) and sclera (b). a illustrates the camera view
opening and guide holes, while b features the camera chamber, integrated
groove, and cable output
Fig. 2. The proposed robotic eye’s orbit sections including the front (a)-(b),
and back (c)-(d) components
which varies from 21 mm to 27 mm [20]. First, we designed
the sclera, which serves as the outermost layer of the robotic
eye, and houses the camera. As shown in Fig. 1 the sclera
has an integrated groove to hold the camera and a USB path
to pass the USB cable.
Next, we add the cornea to complement the body of the
eyeball. The cornea connects to the sclera at a 55 degrees
angle with respect to the light axis, which allows the tendon-
driven cords to move the eyeball in a manner similar to
the human eye [16]. The cornea has an opening with the
maximum radius possible without obstructing the camera
view, and four guide holes on the cornea help to tighten
the cords over the eyeball. Details of the parts are shown in
Fig. 1.Fig. 3. Exploded view of the proposed robotic eye including the 3D-printed
body, two Microsoft HD-3000 cameras, four Dynamixel XL-320 servos, and
the OpenCM 9.04-C controller board.
B. The Orbit
Another key component of our robotic eye is the orbit. In
human eye it is the skull cavity in which the eye and extra-
ocular muscles are placed. Since we are only designing a
mechanical model of the eye and not a complete head, we
propose a bi-sectional orbit design to separate the chambers
that host the servos. The details of the parts can be seen in
Fig. 2.
As shown in Fig. 2(b) and 2(d), each section of the
orbit hosts a servo that actuates the robotic eye’s movement
through cords similar to the Rectus muscles in the human
eye. The cords are responsible for movement in the horizon-
tal and vertical directions. We designed one actuator for each
agonist-antagonist pair of extra-ocular muscles.
The front section of the orbit (Fig. 2(a) and Fig. 2(b))
has four contact arms placed in every 75 degrees. The
design method and polishing of the eyeball surface decreases
friction between the eyeball and orbit. The front section also
includes a path for the USB cable of the camera, and four
guide holes that cross the cords. The servo chamber behind
this section hosts the vertical actuator and stabilizes it with
three ﬁxing arms. The front section connects to the orbit
back section with a tongue and groove joint.
The back section of the orbit as shown in Fig. 2(c) and
Fig. 2(d), hosts one horizontal actuator, and connects to the
handle (details in the next section) with tongue and groove
joint. This allows the user to hold and control the robot with
ease.
C. The Handle
As shown in Fig. 3, the ﬁnal component of the robotic
eye is the handle, which provides multiple functionalities. Its
primary functionality is to keep the eyes’ locations ﬁxed in a
7 cm distance from each other, which is similar to the human
eyes’ distance, that is about 6.3 cm [21]. Considering this
distance helps to create a more realistic mechanical model
Fig. 4. The servo motor mounted within the back section of the robotic
eye’s orbit, as well as the woven bobbin with nylon-coated wires that are
placed over the servo motor
Fig. 5. The proposed robotic eye after ﬁnal assembly. The ﬁnal design is
compact and affordable, allowing for easy replication and modiﬁcation
of the human eye, and is practical when using the robot for
stereo vision.
The handle is designed to be compact and easy to hold, it
includes a chamber for the controller board which interacts
with the PC and the servos. The handle connects to the robot
using a tongue and groove joint, which ensures a secure and
stable connection.
IV. E XPERIMENTS AND RESULTS
In this section, we describe the experiments conducted
to evaluate the performance of our proposed robotic eye in
response to changes in the environment, also known as active
vision [8].
We evaluate different eye movements independently by
testing the performance of our design using a face tracker
in the MATLAB environment. In all experiments, a human
subject was present in front of the robot and the robot
cameras captured the video stream of the scene. A face
tracking algorithm in the MATLAB environment analyzesFig. 6. The proposed robotic eye during tracking the test subject’s face.
The ﬁgure includes three subﬁgures, c shows the face detection and (a)-(b)
show the face following, with the face center being highlighted
the video streams to determine the position of the test
subject’s face. As shown in Fig. 6 The datapoints used in
the controllers include the central point of the detected face
bounding box.
Fig. 8. Smooth Pursuit evaluation results. The graphs show the X and Y
coordinates of the central point of the human face as captured by the left
and right cameras of the robot.
Fig. 7. Saccadic evaluation results. The graphs show the X and Y
coordinates of the central point of the human face as captured by the left
and right cameras of the robot.
A. Assembling the Robotic Eye
Here we describe the process of constructing and assem-
bling the proposed robotic eye. The design of the eyeball
and orbit allows for their use in both the left and right eyes.
We then proceed to 3D print two sets of eyeball, eyeball
cap, front and back components of the orbit. The order of
assembly is illustrated in Fig. 3, and the placement of the
wires and bobbins on the servos can be seen in Fig. 4.
The robot uses four Dynamixel XL-320 servos as actuators
to move the two cameras. After each servo is mounted in
its designated chamber within the orbit, a bobbin should be
placed on top and the wires should be woven around it. Once
both eyes have been assembled, they are integrated into the
system using the handle.
The robot servos are connected to an OpenCM 9.04-
C controller board, which receives commands from the
computer through MATLAB. We made a MATLAB toolbox,
XL-320, speciﬁcally for the actuators of the robotic eye to
generate and simulate movements in MATLAB. The toolbox
together with the code for the experiments, and the printable
3D sketches of the proposed robotic eye have been made
open-source and publicly available1.
To support all four servos simultaneously, the controller
board requires an additional power source. Therefore, we
added a 7.2V battery to supplement the voltage through the
USB port. Fig. 5 shows the assembled robot.
To provide feedback from the environment, we used
a vision-based Proportional Integral Derivative (PID) con-
1Code and Sketches at: https://github.com/hamidosooli/
robotic_eyeFig. 9. Vergence evaluation results. The graphs show the X and Y
coordinates of the central point of the human face as captured by the left
and right cameras of the robot.
troller. The speciﬁc objective of this controller is to keep the
detected face at the center of the image. We performed sepa-
rate horizontal and vertical simulations for Saccade, Smooth
Pursuit, Vergence, and Vestibulo-Ocular Reﬂex movements.
The accompanying video shows our experiments2.
B. Saccadic Movement
Saccadic movements are rapid eye movements that allow
the eyes to quickly shift the gaze from one point to another.
To evaluate our system on Saccadic movements, the human
subject remained static in front of the robot at a ﬁxed
distance. The human’s face was initially located near the
edge of the image, simulating the scenario where the eyes
have to move a long distance towards the target. The graphs
in Fig. 7 show that the robot’s cameras move rapidly towards
the central point of the human face, mimicking the Saccadic
eye movement. However, upon analysis of the results, we
found that the proposed robot’s movements speed were not
as fast as those of the human eye for this movement. This
can be seen in the accompanying video. This limitation may
be due to the mechanical constraints of the robot’s actuators
or the control algorithms used. Further research is needed to
speed up the robot’s movements.
C. Smooth Pursuit Movement
The Smooth Pursuit movement is used to track a moving
target with smooth, continuous eye movements. To evaluate
this, we conducted an experiment where a test subject walks
or moves up and down while the robotic eye detects and
2Accompanying video: https://youtu.be/1mQl93-Jzi8
Fig. 10. VOR evaluation results. The graphs show the X and Y coordinates
of the central point of the human face as captured by the left and right
cameras of the robot.
tracks the face. Since the robot’s cameras were programmed
to follow the movement of the human face and maintain
it at the center of the image, careful attention was given
to maintaining gentle movements to ensure that the robot’s
movements are smooth and continuous. The results for this
test were captured and plotted in Fig. 8.
D. Vergence Movement
Vergence movements are used to adjust the eyes’ focus
when looking at an object at varying distances. To evaluate
this movement, the human approaches the robotic eye until
his face is no longer at the center of the image. For this
test, the robotic eye’s cameras were adjusted to track the
test subject’s movement and keep their face in focus. More
speciﬁcally, the robot’s cameras were programmed to mimic
the Vergence movement by rotating towards each other as
the test subject approached. This scenario happens when the
eyes have to adjust their focus to maintain a clear image of
the face. As shown in Fig. 9, the eyes move away from the
center and lose the central point of the test subject’s face.
E. Vestibulo-Ocular Reﬂex (VOR) Movement
Vestibulo-ocular reﬂex (VOR) is a reﬂex eye movement
that compensates for head movements in one direction by
moving the eyes in the opposite direction [22]. During this
experiment, the test subject was staying static while the robot
was moved in different directions. The robot’s cameras were
programmed to mimic the VOR movement by moving in
the opposite direction of the robot’s body movements. This
scenario happens when the head is rotated, and the VORreﬂex causes the eyes to move in the opposite direction. The
results of this experiment have been shown in Fig. 10.
V. C ONCLUSION
We designed and evaluated a robotic eye that is capable
of mimicking the main human eye movements. The robot’s
design was based on Computer-Aided Design (CAD) and
3D printing, which resulted in an accurate and affordable
prototype. Our design uses inexpensive components, 3D
printed parts, and minimum number of servos to achieve
its functionality. We evaluated our robotic eye over the main
four movements including Saccades, Smooth Pursuit, VOR
and Vergence. As our results show, the proposed design is
capable of mimicking human eye movements to a certain
extent. However, there are still some limitations that need
to be addressed in future work. For instance, our design
does not consider movements such as torsion and intorsion.
Our proposed robot can be easily modiﬁed to simulate these
movements by adding an extra servo for each eye. This will
allow the robot to mimic the movements of the oblique
muscles in addition to those of the rectus muscles. The
designed robot has a great potential in human-robot inter-
action, computer vision and cognitive science applications.
To encourage further research in this area, we have made our
design and code publicly available.
REFERENCES
[1] S. K. Rajendran, Q. Wei, and F. Zhang, “Two degree-of-freedom
robotic eye: design, modeling, and learning-based control in foveation
and smooth pursuit,” Bioinspiration & Biomimetics , vol. 16, no. 4, p.
046022, 2021.
[2] H. Osooli, A. Nikoofard, and Z. Shirmohammadi, “Game theory
for eye robot movement: Approach and hardware implementation,”
in2019 27th Iranian Conference on Electrical Engineering (ICEE) .
IEEE, 2019, pp. 1081–1085.
[3] S. K. Rajendran, Q. Wei, N. Yao, and F. Zhang, “Observability analysis
and reduced-order observer design for a super-coiled polymer-driven
robotic eye,” in 2022 IEEE 61st Conference on Decision and Control
(CDC) . IEEE, 2022, pp. 1385–1391.
[4] W. R. Pruehsner and J. D. Enderle, “The davinci group: a second
modern ophthalmotrope,” Biomed Sci Instrum , vol. 42, pp. 440–445,
2006.
[5] H. Simonsz and I. Den Tonkelaar, “19th century mechanical models
of eye movements, donders’ law, listing’s law and helmholtz’direction
circles,” Documenta Ophthalmologica , vol. 74, no. 1, pp. 95–112,
1990.
[6] F. Carpi and D. De Rossi, “Bioinspired actuation of the eyeballs
of an android robotic face: concept and preliminary investigations,”
Bioinspiration & biomimetics , vol. 2, no. 2, p. S50, 2007.
[7] X.-y. Wang, Y . Zhang, X.-j. Fu, and G.-s. Xiang, “Design and
kinematic analysis of a novel humanoid robot eye using pneumatic
artiﬁcial muscles,” Journal of Bionic Engineering , vol. 5, no. 3, pp.
264–270, 2008.
[8] X. Wang, J. van de Weem, and P. Jonker, “An advanced active vision
system imitating human eye movements,” in 2013 16th International
Conference on Advanced Robotics (ICAR) . IEEE, 2013, pp. 1–6.
[9] J. Schultz and J. Ueda, “A camera positioner driven by muscle-like
actuation,” in 2012 4th IEEE RAS & EMBS International Conference
on Biomedical Robotics and Biomechatronics (BioRob) . IEEE, 2012,
pp. 719–724.
[10] I. Mizuuchi, R. Tajima, T. Yoshikai, D. Sato, K. Nagashima, M. Inaba,
Y . Kuniyoshi, and H. Inoue, “The design and control of the ﬂexible
spine of a fully tendon-driven humanoid” kenta”,” in IEEE/RSJ inter-
national conference on intelligent robots and systems , vol. 3. IEEE,
2002, pp. 2527–2532.[11] H. Kobayashi, K. Hyodo, and D. Ogane, “On tendon-driven robotic
mechanisms with redundant tendons,” The International Journal of
Robotics Research , vol. 17, no. 5, pp. 561–571, 1998.
[12] T. Takuma, K. Takai, Y . Iwakiri, and W. Kase, “Body design of tendon-
driven jumping robot using single actuator and wire set,” in Memorias
de Congresos UTP , 2018, pp. 101–108.
[13] B. Lin, J. Wang, S. Song, B. Li, and M. Q.-H. Meng, “A modular
lockable mechanism for tendon-driven robots: Design, modeling and
characterization,” IEEE Robotics and Automation Letters , vol. 7, no. 2,
pp. 2023–2030, 2022.
[14] D. Biamino, G. Cannata, M. Maggiali, and A. Piazza, “Mac-eye: A
tendon driven fully embedded robot eye,” in 5th IEEE-RAS Interna-
tional Conference on Humanoid Robots, 2005. IEEE, 2005, pp. 62–
67.
[15] E. Perkins and H. Davson, “Human eye-anatomy,” URL https://www.
britannica. com/science/human-eye , 2015.
[16] J. M. Miller and D. A. Robinson, “A model of the mechanics of
binocular alignment,” Computers and Biomedical Research , vol. 17,
no. 5, pp. 436–470, 1984.
[17] B. Krekelberg, “Microsaccades,” Current Biology , vol. 21, no. 11, p.
R416, 2011.
[18] E. Kowler and R. M. Steinman, “Small saccades serve no useful
purpose: Reply to a letter by r. w. ditchburn,” Vision Research , vol. 20,
no. 3, pp. 273–276, 1980.
[19] J. Horne, “Why rem sleep? clues beyond the laboratory in a more
challenging world,” Biological psychology , vol. 92, no. 2, pp. 152–
168, 2013.
[20] I. Bekerman, P. Gottlieb, and M. Vaiman, “Variations in eyeball
diameters of the healthy adults,” Journal of ophthalmology , vol. 2014,
2014.
[21] N. A. Dodgson, “Variation and extrema of human interpupillary
distance,” in Stereoscopic displays and virtual reality systems XI , vol.
5291. SPIE, 2004, pp. 36–46.
[22] C. Barr, L. Schultheis, and D. Robinson, “V oluntary, non-visual control
of the human vestibulo-ocular reﬂex,” Acta oto-laryngologica , vol. 81,
no. 5-6, pp. 365–375, 1976.