BILEVEL INVERSE PROBLEMS IN NEUROMORPHIC IMAGING
HARBIR ANTIL AND DAVID SAYRE
Abstract. Event or Neuromorphic cameras are novel biologically inspired sensors that
record data based on the change in light intensity at each pixel asynchronously. They have
a temporal resolution of microseconds. This is useful for scenes with fast moving objects
that can cause motion blur in traditional cameras, which record the average light intensity
over an exposure time for each pixel synchronously. This paper presents a bilevel inverse
problem framework for neuromorphic imaging. Existence of solution to the inverse problem
is established. Second order sucient conditions are derived under special situations for this
nonconvex problem. A second order Newton type solver is derived to solve the problem.
The ecacy of the approach is shown on several examples.
1.Introduction
Event (Neuromorphic) cameras are novel biologically inspired sensors that record data
based on the change in light intensity at each pixel asynchronously [9]. If the change in
light intensity at a given pixel is greater than a preset threshold then an event is recorded
at that pixel. For this reason if there is no change to the scene, be that movement or
brightening/dimming of a light source, no events will be recorded. In contrast if a scene is
dynamic from camera movement or from the movement of an object in the scene then each
pixel of the event camera will record intensity changes with a temporal resolution on the
order of microseconds [9]. This logging of events results in a non-redundant stream of events
through the time dimension for each pixel [16]. The stream of data is exceptionally useful
for scenes with fast moving objects that can cause motion blur in traditional cameras, which
record the average light intensity over an exposure time for each pixel synchronously [13].
Figure 1 gives an illustration of the dierences between traditional and event cameras.
The prior work, [13], proposed the Event-based Double Integral (EDI) and multiple Event-
based Double integral (mEDI) algorithms to address motion blur for the underlying inverse
problem. The EDI model utilizes a single blurry standard camera image, along with as-
sociated event data, to generate one or more clear images through the process of energy
minimization. The mEDI model, an extension of the EDI model, utilizes multiple images in
conjunction with event data to produce unblurred images. The EDI and mEDI models were
an extension of the work from [16] where a continuous-time model was initially introduced.
While these algorithms represent a leap forward over earlier work, questions remain about
Date : February 7, 2023.
2010 Mathematics Subject Classication. 65K05, 90C26, 90C46, 49J20 .
Key words and phrases. Bilevel optimization, neuromorphic imaging, existence of solution, second order
sucient conditions.
This work is partially supported by NSF grants DMS-2110263, DMS-1913004, the Air Force Oce of
Scientic Research (AFOSR) under Award NOs: FA9550-22-1-0248 and FA9550-19-1-0036.
1arXiv:2302.02052v1  [math.OC]  4 Feb 20232 HARBIR ANTIL AND DAVID SAYRE
Figure 1. Comparison of the output of a standard frame-based camera and
an event camera when facing a black dot on a rotating disk. The standard
camera outputs frames at a xed rate, thus sending redundant information
when there is no motion in the scene [10].
the validity of the models in various scenarios (see below), regarding what situations solu-
tions exist and what optimization procedures are appropriate in order to nd such solutions.
In this paper we provide a mathematical foundation and further extensions to the previous
methods by extending the model and providing a bilevel inverse problem framework. In-
deed, as shown below, the EDI and mEDI models correspond to inverse problems in image
deblurring [3, 4]. In particular,
(a) We introduce a bilevel optimization problem that allows for the simultaneous opti-
mization over a desired number of frames. We also illustrate that this optimization
problem is indeed an inverse problem. Therefore, we use the terms `optimization' and
`inverse', interchangeably.
(b) We establish existence of solution to this problem. Under certain conditions, we
derive the second order sucient conditions and provide local uniqueness of solution
to these nonconvex problems.
(c) A fully implementable framework based on second order methods has been devel-
oped. The benets of the proposed approach are illustrated using multiple numerical
examples.
For completeness, we emphasize that the bilevel approaches to search for the hyperparame-
ters in traditional imaging is not new, see for instance [2, 8]. However, the problem considered
in this paper is naturally bilevel without having to search for the hyperparameters.
Outline: The remainder of the paper is organized as follows. Section 2 focuses on some
notation and preliminary results. In Section 2.1, we discuss the basics of event based cameras.
Section 2.3 focuses on existing models from [13] which serves as a foundation for the proposed
bilevel optimization based variational model in Section 3 . Existence of solution to the
proposed optimization problem is shown in Theorem 3.1. Moreover, local convexity of our
reduced functional is shown in Theorem 3.5. Section 4 rst focuses on how to prepare the
data for the algorithm. It then discuss implementation details. The problem itself is solved
using a second order Newton based method. Subsequently, several illustrative numerical
examples are provided in Section 5 .BILEVEL INVERSE PROBLEMS IN NEUROMORPHIC IMAGING 3
2.Notation and Preliminaries
Letntrepresent the number of images and nxnydenotes the number of pixels per image.
We useU2Rntnxnyto denote a tensor. We use the vector
uxy2Rnt;
to represent the ( x;y) pixel value of Ufor all times. Moreover, we use the matrix
ui2Rnxny:
to represent an image of size Rnxnyat a xed time instance i2f1;:::;ntg. We use the
scalar
ui
xy2R
to denote the value of Uat a pixel location ( x;y) and time i2f1;:::;ntg. Graphical
representations are given in Figure 2 . Finally, given quantities uxyandM2Rntfor
some2N, we dene the operation h;ias:
huxy;Mi:= (uxy)>M2R:
Figure 2. The panel describes multiple images one of those images for
instance isui2Rnxnyand it is marked in red color. The circles represent
the vectoruxy2Rntand are marked in blue color. Green circle indicates an
overlap between uianduxy.
The remainder of the section is organized as follows. First in Section 2.1, we discuss
the basic working principle behind the neuromorphic cameras. The main ideas behind the
algorithms presented in [13] are described in Section 2.3. We briey discuss some potential
limitations of this approach which motivates our algorithm in Section 3.
2.1.Neuromorphic (Event Based) Cameras.4 HARBIR ANTIL AND DAVID SAYRE
Neuromorphic Camera Basics. Neuromorphic cameras are composed of independent pixels
that detect light intensity changes in the environment as they occur. Light intensity is
sampledO(s) and events are logged if the intensity of the light is beyond a preset hardware
dened threshold, c. We denote the instantaneous light intensity at pixel location ( x;y) at
timesbyqs
xy2R. When the light intensity detected by the camera exceeds the threshold
for a given pixel located at ( x;y), at a given time s, an event is logged. Then the reference
intensity,qsref
xy, for the pixel located at ( x;y) is updated. Due to the high rate of sampling,
and independent nature of the camera's pixels neuromorphic cameras are less susceptible
to exposure issues, as well as image blurring. Figure 1 illustrates the dierence in the data
recorded between traditional and event based cameras.
Data representation. The output of an event based camera over some time interval, I, is of
the form (s;x;y;p ), with the following denitions:
s2I=fs1;s2;:::;sn:s1< s 2<< sng, whereIrepresents the exposure interval,
eachsjrepresents a discrete time at which an event occurred and nrepresents the total
number of events recorded during the interval, I. When discussing methods that involve
multiple images, we will denote the exposure interval for the i-thimage asIi. We will also
denote the set of events associated to each image iasfsi
jgni
j=1. With this notation we have
i= 1;:::;ntandj= 1;:::;niwithnirepresenting the total number of events associated
to imagei.
x;yrepresent pixel coordinates.
psj
x;y:=8
>><
>>:+1;log
qsj
xy
qsref
xy
c
 1;log
qsj
xy
qsref
xy
 cis the polarity of the event. An increase in light intensity
above a threshold, c>0, we regard as a polarity 1 and a decrease of intensity as a polarity
shift of 1. No event is logged if psj
x;y2( c;c).
We can reformulate these events into a datacube with the following denition:
ECsj
xy=psj
x;y; j = 1;:::;n; (2.1)
which results in a sparse 3-dimensional matrix with entries of 0 ;1; 1. We refer to Figure
5 for 2D and 3D examples of the datacube. Representing the data in this way allows us to
track intensity changes over time on a per pixel basis.
2.2.Inverse problems in Image Deblurring. Image deblurring is a classic example of
an inverse problem, where the goal is to reconstruct the unknown original image from a
degraded, blurred observation. In image deblurring, the degradation process can be modeled
as a interaction between the original image and a blur kernel which represents the blur caused
by various factors such as movement [19, 20].
In the context of image deblurring, the eld can be divided into two categories, blind and
non-blind, based on the amount of information known about the blur kernel [1, 15, 17, 18, 19].
In the non-blind case, the blur kernel is known which leads to a simpler ableit ill-posed inverse
problem [17, 18]. In the blind case, no information about the blur kernel is available, making
the deblurring problem more challenging as the blur kernel must be estimated from the
degraded image in addition to the original image [15, 19]. The semi-blind case is a particularBILEVEL INVERSE PROBLEMS IN NEUROMORPHIC IMAGING 5
instance of a blind image deblurring problem in that some but not all information about the
blur kernel is available [5, 12, 14]. The problems under consideration in this project are of
semi-blind type.
2.3.Existing Model, Algorithm, and Limitations. The approach discussed in this
paper is motivated by [13]. The article [13] seeks to nd latent un-blurred images using the
Event Based Double Integral (EDI) and multi-Event Based Double Integral (mEDI) models.
We briey discuss this next. This will be followed by our new proposed models.
EDI Model. In [13], the discrete events outlined in Section 2.1 are used to generate a con-
tinuous function, exy, for each ( x;y) pixel location. This is done by generating a series of
continuous unit bump functions centered at each sj:sj(t). Then we can dene exy:R!R
as:
exy(t):=X
sj2IECsj
xysj(t)2R: (2.2)
We graphically illustrate building this function for a single pixel below with the following
string of events:
[1;0;1; 1;1]:
In Figure 3 we see the function exyoverlayed onto a stem plot of events.
Figure 3. In this gure the solid line represents the function exyoverlayed
onto the a stem plot (dashed line)that represents a series of recorded events.
The red dots are used to highlight the events.
From 2.2, we dene the ` sum of events ' from time of interest tito arbitrary time tas:
Ei
xy(t;ti) =t
tiexy(r)dr; (2.3)
whereEi
xy(t;ti)2Rcorresponds to one pixel and Ei(t;ti) =fEi
xy(t;ti)gxy2Rnxnyconsists
of all the pixels. We note that ti,i= 1;:::;ntare manually chosen and represent the time
at which we wish to generate an image. In practice we will set each tito correspond to the
timestamps of the standard camera images we are using in the model. For convenience we6 HARBIR ANTIL AND DAVID SAYRE
will omittifromEi
xy(t;ti) unless needed for clarity. Introducing a scalar variable zgives us
the EDI Model:
Bi
xy=1
jIijti+jIij=2
ti jIij=2Li
xyexp 
zEi
xy(t)
dt: (2.4)
WhereBi
xy2RandBi=fBi
xygxy2Rnxnyis a standard camera image. Furthermore,
Li
xy2Ris the pixel value of the unblurred image at location ( x;y), andjIijis the exposure
time for the ithimage. We note that the superscript iinBi
xyandLi
xyare simply placeholders
for notation since the EDI model only considers a single image at a time. Taking the log
and re-arranging terms of (2.4) leads to:
vi
xy=di
xy gi
xy(z); (2.5)
where
vi
xy= log(Li
xy);di
xy= logBi
xy;
gi
xy(z) = log1
jIijti+jIij=2
ti jIij=2exp 
zEi
xy(t)
dt
:(2.6)
The formulation in (2.5) gives us the correlation between the EDI model and other semi-
blind inverse problems in image deblurring. Here Biis our blurry image, Liis our latent
unblurred image, and giis our kernel function. As shown in [1, 3, 4, 6, 7] this formulation
is common for many inverse problems. We note the EDI/mEDI models would fall into the
category of semi-blind inverse problems mentioned in Section 2.2 since the kernel, gi, is
known up to the parameter z.
mEDI Model. If we consider two latent images viandvi+1we know that event data will give
us the per pixel changes that have occurred between the two images. We can mathematically
describe this change asti+1
tiexy(s)dswhereexyis as given in (2.2) and tiare user chosen
times of interest. Incorporating the threshold variable zallows us to formulate the following
equations
vi+1
xy vi
xy=zti+1
tiexy(s)ds=:bi
xy(z): (2.7)
Combining (2.5) and (2.7) gives us the following system of equations:
0
BBBBBBBBBBBBBBBBBBB@ 1 1
 1 1
......
 1 1
 1 1
1
1
1
...
1
1
11
CCCCCCCCCCCCCCCCCCCAvxy=
bxy
dxy gxy
(2.8)BILEVEL INVERSE PROBLEMS IN NEUROMORPHIC IMAGING 7
Notice that, (2.8) gives us the mEDI model described by [13]. The size the upper half of the
submatrix in (2.8) is R(nt 1)ntand the lower half matrix is Rntnt.
mEDI Model - Optimizing for z. The variable zis found by solving the following minimization
problem for each pixel ( x;y) of an image of interest i:
min
z1
2kvi
xy(z) +gi
xy(z) di
xyk2
2: (2.9)
Herevxy,di
xy, andgi
xy(z) are as given in (2.6). We refer to [13] for their solution approach.
Notice that (2.7) is not used as constraint to the minimization problem (2.9), but (2.9) is
used to generate the image reconstructions.
Limitations of the mEDI and EDI Models. While the mEDI model uses multiple frames in
order to accurately represent de-blurred images some limitations for the model remain.
(a) Performance of the model can degrade for images that contain large variations of light
intensity within a single scene. Some examples of this are having very dark objects in
a bright room with a highly dynamic scene. In these instances we can see \shadowing"
eects where shadows appear across multiple frames. We refer to Section 5.3 for specic
examples.
(b) The optimization problem introduced (2.9) to identify zonly seeks to optimize the pixels
of one image at a time and neglects the constraints (2.7). Then uses (2.7) to reconstruct
multiple images with the same zvalue.
(c) Recall from 2.7 that bi
xy:=zti+1
tiexy(s)ds. This denition does not include any
information from the standard images Bi. Due to this the mEDI model is not well suited
for generating image reconstructions across time-spans that include multiple standard
images.
3.Proposed Model and Algorithm
3.1.Model. For each pixel ( x;y), we consider the following bilevel inverse problem
min
zxyJ(uxy;zxy):=1
2kuxy(zxy) +gxy(zxy) dxyk2
2+1
2kzxyk2
2 (3.1a)
subject to constraints
min
uxy1
2kAuxy bxy(zxy)k2
2+2
2kuxyk2
2: (3.1b)
Notice, that this is an optimization problem for one pixel across all images. By 0 < 1;2,
we denote the regularization parameters. Moreover,
A=0
BBBBB@ 1 1
 1 1
......
 1 1
 1 11
CCCCCA2R(nt 1)nt
is a submatrix of the matrix given in (2.8). Recall in Equation (2.9) that zis taken as a
scalar and the optimization is done over a single image at a time. We consider zxyas size8 HARBIR ANTIL AND DAVID SAYRE
nt1 so that we can optimize over the same pixel ( x;y) for all images simultaneously. Also,
in contrast to [13] since we have dened zxyas a vector over all images, we also modify the
variablebwith the following denition:
bi
xy(zxy):= (di+1
xy gi+1
xy(zxy)) (di
xy gi
xy(zxy))2Rnt 1: (3.2)
Wherezi
xy2Rand is thei-thcomponent of the vector zxy2Rnt. This is done so the events
associated to the i-thimage are being optimized by the i-thzxycomponent.
Notice that,Aabove is not a square matrix. For every 2>0, the lower level problem is
uniquely solvable and the solution is given by
uxy(zxy) = (A>A+2I) 1A>bxy(zxy) =K 1A>bxy(zxy) (3.3)
with
K:= (A>A+2I)2Rntnt:
Substituting, this in the upper level problem, we obtain the following reduced problem
min
zxy2ZadJ(zxy):=J(K 1A>bxy(zxy);zxy) (3.4)
which is now just a problem in zxy. Notice, that the reduced problem (3.4) is equivalent to
the full space formulation
min
zxyJ(uxy;zxy) (3.5a)
subject to constraints
Kuxy=A>bxy(zxy): (3.5b)
The next result establishes existence of solution to the reduced problem (3.4) and equivalently
to (3.5).
Theorem 3.1. There exists a solution to the reduced problem (3.4) .
Proof. The proof follows from the standard Direct method of calculus of variations. We will
omit the subscript xyfor notation simplicity. We begin by noticing that J() is bounded
below by 0. Therefore, there exists a minimizing sequence fzngn2Nsuch that
lim
n!1J(zn) = inf
zJ(z):
It then follows that
1
2lim
n!1kznk2lim
n!1J(zn) = inf
zJ(z)J(0) =C <1;
where the constant Cis independent of n2N. Thus,fzngn2Nis a bounded sequence.
Therefore, it has a convergent subsequence, still denoted by fzngn2N, such thatzn!z. It
them remains to show that zis the minimizer. Since, un:=u(zn) solves (3.3), therefore,
we have that un!u(z) andg(zn)!g(z) asn!1 . Subsequently, from the denition of
inmum and these convergence estimates, we readily obtain that
lim
n!1J(z)lim inf
n!11
2ku(zn) +g(zn) dk2
2+ lim inf
n!11
2kznk2
2=J(z):
Thus zis the minimizer and the proof is complete. 
In order to develop a gradient based solver for (3.4), we next write down the expression
of gradient ofJ.BILEVEL INVERSE PROBLEMS IN NEUROMORPHIC IMAGING 9
Lemma 3.2. The reduced objective Jis continuously dierentiable and the derivative is
given by
rJ(z) =D
K 1A>b(zxy) +g(zxy) dxy;K 1A>b0
xy(zxy) +g0
xy(zxy)E
+zxy;
whereK 1A>2Rnt(nt 1),
b0
xy(zxy) =0
BBBBB@(g1
xy)0 (g2
xy)00 0 0 0
0 (g2
xy)0 (g3
xy)00 0 0
0 0 ( g3
xy)0 (g4
xy)00 0
.....................
0 0 0 0 0 ( gnt 1
xy)0 (gntxy)01
CCCCCA2R(nt 1)nt;
andg0
xy(zxy)is a diagonal matrix given by
g0
xy(zxy) = (3.6)
0
BBBBBBBB@
I1E1
xy(t) exp(z1
xyE1
xy(t))dt
I1exp(z1xyE1xy(t))dt0 0 0 0
0
I2E2
xy(t) exp(z2
xyE2
xy(t))dt
I2exp(z2xyE2xy(t))dt0 0 0
0 0 0... 0
0 0 0 0
IntEntxy(t) exp(zntxyEntxy(t))dt

Intexp(zntxyEntxy(t))dt1
CCCCCCCCA:(3.7)
Proof. The proof follows by simple calculations. 
The next result establishes that ( gi
xy(zxy))00is bounded and strictly positive for each i,
withIidenoting the i-thexposure time interval.
Theorem 3.3. LetIidenote the i-thexposure time interval with i= 1;:::;nt. If there
existst2Ii, for alli, withEi
xy(t)being nonzero then (gi
xy(zxy))002Ris bounded and strictly
positive for all i.
Proof. First we will calculate ( gi
xy(zxy))00. Recall:
gi
xy(zxy) = log1
jIij
Iiexp(zi
xyEi
xy(t))dt
=)(gi
xy(zxy))0=
IiEi
xy(t) exp(zi
xyEi
xy(t))dt
Iiexp(zi
xyEi
xy(t))dt;
yielding
(gi
xy(zxy))00=I 
IiEi
xy(t) exp(zi
xyEi
xy(t))dt2

Iiexp(zi
xyEi
xy(t))dt2;(3.8)10 HARBIR ANTIL AND DAVID SAYRE
where I =
Iiexp(zi
xyEi
xy(t))dt
Ii
Ei
xy(t)2exp(zi
xyEi
xy(t))dt
.
Let
Iiexp(zi
xyEi
xy(t))dt
=:. Then we have the following:
I=
Ii
Ei
xy(t)2exp(zi
xyEi
xy(t))dt
=
Ii
Ei
xy(t)2exp(zi
xyEi
xy(t))
Iiexp(zi
xyEi
xy(s))ds
dt
=
Ii
Ii
Ei
xy(t)2exp(zi
xyEi
xy(t))exp(zi
xyEi
xy(s))dsdt
:
Using Fubini's Theorem and following the procedure above for the two integral products in
the numerator of (3.8) we get the following equalities:
(3.8) =I 
IiIiEi
xy(t) exp(zi
xyEi
xy(t))Ei
xy(s) exp(zi
xyEi
xy(s))dsdt

Iiexp(zi
xyEi
xy(t))dt2
=
IiIi
exp(zi
xyEi
xy(t)) exp(zi
xyEi
xy(s))
Ei
xy(t)2 Ei
xy(s)Ei
xy(t)
dsdt

Iiexp(zi
xyEi
xy(t))dt2
=
IiIi
exp(zi
xyEi
xy(t)) exp(zi
xyEi
xy(s))
1
2
Ei
xy(t) Ei
xy(s)2
dsdt

I1exp(zi
xyEi
xy(t))dt2:(3.9)
We notice that Equation (3.9) is positive for Ei
xy(t)6=Ei
xy(s) (since all terms are positive)
and the expression is 0 for t=s. By assumption there exists some t2 Iisuch that
Ei
xy(t)6= 0 which implies that an event has occurred at the pixel xyduring the interval Ii:
Without loss of generality suppose a single event occurred at time t. Recall from (2.3) that
Ei
xy(t;ti) =t
tiexy(r)dr. Then 0 =Ei
xy(ti;ti)6=Ei
xy(t;ti) which implies Ei
xy(ti)6=Ei
xy(t).
Which further impiles that (3.9) >0. Thus we conclude ( gi
xy(zxy))00>0. Next, using (3.9),
we obtain the following upper bound:
(gi
xy(zxy))00
IiIi
exp(zi
xyEi
xy(t)) exp(zi
xyEi
xy(s))
max
t;s2Ii
1
2
Ei
xy(t) Ei
xy(s)2
dsdt

Iiexp(zi
xyExy(t))dt2
= max
t;s2Ii1
2
Ei
xy(t) Ei
xy(s)2
IiIi
exp(zi
xyEi
xy(t)) exp(zi
xyEi
xy(s))
dsdt

Iiexp(zi
xyEi
xy(t))dt2
= max
t;s2Ii1
2
Ei
xy(t) Ei
xy(s)2
:BILEVEL INVERSE PROBLEMS IN NEUROMORPHIC IMAGING 11
Hence
0<(gi
xy(zxy))00max
t;s2Ii1
2
Ei
xy(t) Ei
xy(s)2
:
We now conclude that ( gi
xy(zxy))00is bounded and strictly positive. 
In order to show the local convexity of J, we study the structure of the Hessian of the
rst term in the denition of J.
Lemma 3.4. The matrix
Hess (K 1A>bxy(zxy)) +Hess (gxy(zxy));uxy(zxy) +gxy(zxy) 
dxy
is a diagonal matrix.
Proof. Without loss of generality, suppose that nt= 3. Recall by our denition:
gxy(zxy) =0
B@log(1
jI1j
I1exp(z1
xyE1
xy(t))dt)
log(1
jI2j
I2exp(z2
xyE2
xy(t))dt)
log(1
jI3j
I3exp(z3
xyE3
xy(t))dt)1
CA:
Then, recall the expression of g0
xy(zxy) from (3.7). Now to calculate the Hessian of g, we
need to take the derivative with respect to each variable once again. This will result in
Hess (gxy(zxy))2Rntntntand will be of the form:
Hess (gxy(zxy)) =8
<
:0
@(g1
xy(zxy))000 0
0 0 0
0 0 01
A;0
@0 0 0
0 (g2
xy(zxy))000
0 0 01
A;0
@0 0 0
0 0 0
0 0 (g3
xy(zxy))001
A9
=
;;
where (gi(zxy))00is dened in Theorem 3.3 . Next we consider Hess (K 1A>bxy(zxy)).
Observe:
Hess (K 1A>bxy(zxy)) =K 1A>Hess (bxy(zxy))
where
Hess (bxy(zxy)) =((g1
xy(zxy))000 0
0 0 0
;0 (g2
xy(zxy))000
0 (g2
xy(zxy))000
;(0 0 0
0 0g3
xy(zxy))00)
;
Hess (bxy(zxy))2Rnt 1ntnt;
and
K 1A>:=0
@j j
12
j j1
A2Rnt(nt 1):
Herei,i= 1:::ntrepresent the columns of K 1A>. Then we have the following:
Hess (K 1A>bxy(zxy))
=8
<
:(g1
xy(zxy))000
@j0 0
10 0
j0 01
A;(g2
xy(zxy))000
@0j 0
02 10
0j 01
A;(g3
xy(zxy))000
@0 0j
0 03
0 0j1
A9
=
;;12 HARBIR ANTIL AND DAVID SAYRE
with Hess (K 1A>bxy(zxy)2Rntntnt. Next we can add Hess (gxy(zxy)) and
Hess (K 1A>bxy(zxy)) to get:
Hess (gxy(zxy)) +Hess (K 1A>bxy(zxy))
=8
<
:(g1
xy(zxy))000
@j0 0
10 0
j0 01
A;(g2
xy(zxy))000
@0j0
020
0j01
A;(g3
xy(zxy))000
@0 0j
0 03
0 0j1
A9
=
;;
wherei2Rnt;i= 1;:::;nt. Lastly letuxy(zxy) +gxy(zxy) dxy=xy2Rnt. Then

Hess (K 1A>bxy(zxy)) +Hess (gxy(zxy));uxy(zxy) +gxy(zxy) dxy
=8
<
:(g1
xy(zxy))000
@>
1xy
0
01
A;(g2
xy(zxy))000
@0
>
2xy
01
A;(g3
xy(zxy))000
@0
0
>
3xy1
A9
=
;
=0
B@(g1
xy(zxy))00>
1xy 0 0
0 (g2
xy(zxy))00>
2xy 0
0 0 ( g3
xy(zxy))00>
3xy1
CA: (3.9)
Here=denotes the mode 1 unfolding of the
Hess (K 1A>bxy(zxy))+Hess (gxy(zxy));uxy(zxy)+
gxy(zxy) dxy
tensor. Further details of tensor matrix multiplication can be found in [11].
The proof is complete. 
Next, we establish that Jis strictly locally convex on any nite interval when 1is chosen
appropriately.
Theorem 3.5. LetIidenotes the i-thexposure time interval with i= 1;:::;nt. If there
existst2Ii, for alli, withEi
xy(t)being nonzero then for any closed ball 
 =B(0)centered
at 0 and radius , there exists 1>0such that for zxy2
,Jis strictly convex.
Proof. First we calculate Hess (J) as:
Hess (J) =
u0
xy(zxy) +g0
xy(zxy));u0
xy(zxy) +g0
xy(zxy))
+
Hess (K 1A>bxy(zxy)) +Hess (gxy(zxy));uxy(zxy) +gxy(zxy) dxy
+1I:
We notice that the term
u0
xy(zxy) +g0
xy(zxy));u0
xy(zxy) +g0
xy(zxy))
is of them form
M>M, which implies that it is symmetric positive semi-denite. Next, from Lemma 3.4 we
recall that the term
Hess (K 1A>bxy(zxy)) +Hess (gxy(zxy));uxy(zxy) +gxy(zxy) dxy
is a diagonal matrix. In the case where the diagonal entries (eigenvalues) are greater than
0, then we are done. Suppose some eigenvalue is less than 0 and let zxy2
:=B(0) which
implieskzxyk1. Given>0, choose1>0 such that
0<<1 (kk1M1kdxyk1)(2kK 1A>k1+ 1)
(kk1M1M2)(2kK 1A>k1) + 1):
WhereM2= max
imin
t2IifEi
xy(t)g;max
t2Ii
Ei
xy(t)	
andM1= max
i
max
t;s2Ii
1
2
Ei
xy(t) Ei
xy(s)2
:
Recall from Theorem 3.3 that 0 <(gi
xy(zxy))00max
t;s2Ii
1
2
Ei
xy(t) Ei
xy(s)2
, which impliesBILEVEL INVERSE PROBLEMS IN NEUROMORPHIC IMAGING 13
(gi
xy(zxy))00M1for anyi. Then using 3.9 we have the following:
k
Hess (K 1A>bxy(zxy)) +Hess (gxy(zxy));uxy(zxy) +gxy(zxy) dxy
k1
0
BBB@(g1
xy(zxy))00>
1xy 0 0 0
0 (g2
xy(zxy))00>
2xy 0 0
............
0 0 ::: (gntxy(zxy))00>
ntxy1
CCCA
1
M1kk1
kuxy(zxy)k1+kgxy(zxy)k1+kdxyk1
M1kk1
kK 1A>bxyk1+M2kzxyk1+kdxyk1
M1kk1
kK 1A>k1kbxyk1+M2kzxyk1+kdxyk1
M1kk1
kK 1A>k1(2kdxyk1+ 2M2kzxyk1) +M2kzxyk1+kdxyk1
< 1:
Here
:=0
@j j:::j
12:::nt
j j:::j1
A>
;
iandxyare dened in Equation 3.9 . Notice that M2is derived from bounds on gxy(zxy)
as follows:
gi
xy(zxy) = log1
jIij
Iiexp(zi
xyEi
xy(t))dt
zi
xymax
Ei
xy(t)	
;wherezi
xyEi
xy(t)0
and
gi
xy(zxy) = log1
jIij
Iiexp(zi
xyEi
xy(t))dt
zi
xymin
Ei
xy(t)	
;wherezi
xyEi
xy(t)0
=) jgi
xy(zxy)jjzi
xyM2j:
Recall
Hess (K 1A>bxy(zxy))+Hess (gxy(zxy));uxy(zxy)+gxy(zxy) dxy
is diagonal from
3.9 . Denote the diagonal entries as i,i= 1;:::;nt. Without loss of generality let j1jjij,
i= 2;:::;nt. Then we have the following:
jijj1j=k
Hess (K 1A>bxy(zxy))+Hess (gxy(zxy));uxy(zxy)+gxy(zxy) dxy
k1< 1:
Thusi< 1for alli. Furthermore i+1>0 for alli. We notice

Hess (K 1A>bxy(zxy)) +Hess (gxy(zxy));uxy(zxy) +gxy(zxy) dxy
+1I
is symmetric positive denite since it is a diagonal matrix with entries: i+1>0. Hence
Hess (J) is symmetric positive denite due to it being the summation of a symmetric positive
denite matrix and a symmetric positive semi-denite matrix. We conclude that for any
convex set 
 there exists 1such thatJis strictly convex over 
. 14 HARBIR ANTIL AND DAVID SAYRE
We further note that from Theorem 3.5 once an interval is chosen a lower bound for 1
can be calculated by:
1>kk1M1
kK 1A>k1(2kdxyk1+ 2M2kzxyk1) +M2kzxyk1+kdxyk1
:
4.Experimental Setup
This section focuses on how to prepare the dataset to be used in our computations.
Standardizing Bi.Depending on the event camera used, the entries of the matrix Bifrom
(2.4), where iidenties a unique standard camera image in the sequence being considered,
may take on various ranges to include [0 ;255] or [ 255;255]. We standardize Biusing
MATLAB function mat2gray. This function will map the values of Bito the range [0 ;1] on
a log scale. That being said since we dene the matrix di= log(Bi) we have to be careful
not to allowBito have any zero values. We can easily protect against this by inserting a
manual range into the mat2gray function of [min Bi ;maxBi+], for a suciently small
. In our computations we set = 1e 3. We note min Biand maxBiare the minimum
and maximum values over all values in the matrix Bi, respectively.
Building the data cube. In order to view the problem in three dimensions, we create a data
cube as shown in Figure (5). As stated in (2.1) we dene this cube by:
ECsj
xy=psj
x;y:
Since the event data is generated on a nearly continuous basis, the data cube will be of
sizeRnxnywhere:=P
iniis the total number of events used in the reconstruction
over all images. Note that niis explained in further detail in 2.1 . On average our image
reconstructions use approximately 25;000 events. It is impractical numerically to use
this data cube due to its size. This issue is resolved by reducing the size of the data cube
via time compression. Choose some r;k2Nsuch thatrkand dene a new data cube
as follows:
dc=kX
!=1+( 1)kEC!
Then we have dc2Rrnxnywherer
k, and= 1;:::;r . For our examples we have
chosenk200.
Calculateg(z).Once we have built the data cube then we can calculate the function g(z)
which is dened componentwise as:
gi
xy(zxy) = log1
jIij
Iiexp 
zi
xyEi
xy(;ti)
dt
; i= 1;:::;nt:
Numerically we approximate this using the trapezoid rule as:
gi
xy(zxy)log1
jIijrX
l=2 4l 1
2 
exp 
zi
xyEi(l 1;ti)
+ exp 
zi
xyEitxy(l;ti)
;BILEVEL INVERSE PROBLEMS IN NEUROMORPHIC IMAGING 15
wheretiis dened in (2.3) and  l 1=l l 1is the step length. We evaluate the function
b(z) as well as the derivatives of b(z) andg(z) in a similar way.
Omitting unnecessary calculations for z.We recall that zmust be calculated on a per pixel
basis. To decrease computation time we only perform an optimization for zxyover the pixels
for which event data has been captured.
Image Reconstruction. As shown in Figure 5 our method is capable of generating two image
representations. Given some value ztheurepresentation is given as: u(z) dened in (3.3).
Theurepresentation reconstructs only the dynamical part of the image. This is due to our
denition ofbin (3.2). In order to reconstruct the full image including the portion of the
image with no dynamics, we use
vi
xy=di
xy gi
xy(z);
a variation of the denition given in (2.5). In general we will refer to the latter formulation
as the reconstruction, and will specically denote the urepresentation when presented.
5.Numerical Examples
Next, we present a series of examples which establishes that the proposed approach could
be benecial in practice.
5.1.Benchmark Problem: Unit Bump. The rst example is a synthetic case where we
consider a blurred unit bump, see Figure 4 . In order to perform this analysis, we require a
baseline image for comparison, a series of consecutive images as input for the ESIM generator
[10] and our proposed method, a blurry image, and the corresponding event data. To begin,
we will construct a series of consecutive images by rst creating a white circle on a black
background (not shown). Using this initial image, we move the white circle two pixels to
the right and two pixels down eight times. This set of nine images completes our series of
images. We now generate a tenth image, the blurry image (middle in Figure 4), by averaging
the sequence of nine images. The fth image of the set is designated as our baseline image
(left in Figure 4). Lastly, to generate the associated event data, we use the ESIM generator
from [10]. The ESIM generator takes a series of images as input, and will output event data.
Recall that our model requires a series of images as well as event data in order to generate a
reconstructed image. We set B1to be the fourth image of the nine image set, B2to be the
blurry image, and B3to be the sixth image. The result of our method (right in Figure 4)
is compared to the baseline image. As shown, we obtain a high quality reconstruction with
SSIM of 0.96 and PSNR of 27.3. This example serves a benchmark for us to apply our
approach on the event based dataset.
5.2.Multiple Event Based Dataset Examples. Figures 5-7 show the application of our
method to various examples. In each of these examples three standard camera images are
used to dene the Bvariable, while the gandbvariables are calculated using the associated
event data. In each of these examples the B2image was chosen to be a blurry image. We
will refer to the B2image as the blurry image for the remainder of this section.
In Figure 5 for the chosen three image sequence 39;000 events were recorded. The
blurry image is shown (left) while our reconstruction is shown (right). Our reconstruction16 HARBIR ANTIL AND DAVID SAYRE
Figure 4. From left to right we have our baseline image, a simulated blurry
image, and nally our reconstruction. Events for this reconstruction were
produced using the ESIM generator from [10]. Using parameters 1= 1 and
2= 1e 3, we achieve an SSIM value of 0.96 and a PSNR value of 27.3.
deblurs the fence-line as well as captures the grass and tree texture that is not apparent in
the blurred image. The blurred image (left) in Figure 6 shows a person swinging a pillow.
Approximately 26,000 events were captured for this example. Our model has successfully
reconstructed the boundary of the pillow as well as the persons hand and thumb. Figure 7 is
an example of a person jumping and the three image sequence used has 16000 associated
events. Notice in the blurred image (left) the persons arm is barely visible. In contrast our
model is able to reconstruct the persons arm (right).
Figure 5. Example of our method with a night drive data set. From left
to right we have a standard camera image that contains motion blur, a 2D
representation of the event data color coded red for positive events and blue
for negative events, a 3D representation of the events over time, and nally
the reconstructed image using our bilevel optimization method. Here, we have
used1= 1 and2= 1e 3.
5.3.Event Based Problem: Shadowing Eects. As noted in Section 2.3 one of the lim-
itations to the mEDI model is the appearance of shadows in a high contrasting environment.
Examples of this shadowing eect can be seen in [13] and Figures 8 and 9. As shown in
Figures 8 and 9 our model is able to substantially reduce the shadowing eects of the EDI
and mEDI models. Figure 10 shows the behavior of ve randomly chosen pixels. We observe
the typical convergence behavior of a Newton's method.
Conclusion, Limitation, and Future Work
In this study, we introduce a novel approach to image deblurring by combining event
data and multiple standard camera images within a variational framework. Our methodBILEVEL INVERSE PROBLEMS IN NEUROMORPHIC IMAGING 17
Figure 6. From left to right we have the original blurred image from a stan-
dard camera, the urepresentation, and the reconstruction using our bilevel
method. This reconstruction was generated with 1= 0:5 and2= 1e 3.
Figure 7. From left to right we have a standard blurry camera image, the
recorded events, and nally our reconstructed image. This reconstruction was
generated with 1= 1:5 and2= 1e 3.
Figure 8. In this gure we see the shadowing eects that can occur due a high
contrast environment. From left to right we have the standard camera image,
the image produced by the mEDI method, and nally the image produced via
our bilevel optimization method with 1= 1 and2= 1e 3. Clearly, our
method helps overcome the shadowing eect.
demonstrates the existence of solutions for a locally convex problem and we apply a second
order Newton solver to several examples, showcasing the eectiveness of our approach.
Though our method does oer a systematic way to construct de-blurred images across
time there are limitations that still exist in the model.18 HARBIR ANTIL AND DAVID SAYRE
Figure 9. The panels show a second example of our method (right) used to
deblur the a standard camera image(left) resulting in a reduced amount of
shadowing compared to the existing approaches.
1 2 3
Newton Iterations10-1010-810-610-410-2100Norm of the GradientPixel 1
Pixel 2
Pixel 3
Pixel 4
Pixel 5
Figure 10. This gure shows the value krJ (z)kfor each Newton iteration
over a sample of pixels. The Newton iterations shown are from the optimiza-
tion of pixels sampled from the image reconstruction that is shown in Figure
8.
(a) Our method requires a pixel by pixel optimization and depending on the camera
resolution can run into scalability issues. This issue would be most evident with
images where dynamics occur at a majority of pixels.
(b) Manual tuning may be required of certain parameters as described in Section 4 .
To mitigate the scalability risk, we propose to lter out pixels that have signicantly lower
event counts compared to other pixels. In future work, we also plan to test the model's
robustness in a domain shift scenario, such as a camera moving in and out of water. Moreover,
we aim to develop a parameter learning framework to optimize the regularization parameters
for better performance.
Acknowledgement
The authors are grateful to Dr. Patrick O'Neil and Dr. Diego Torrejon (BlackSky) and
Dr. Noor Qadri (US Naval Research Lab, Washington DC), for bringing the neuromorphic
imaging topic to their attention and for several fruitful discussions.
References
[1] Mariana SC Almeida and Luis B Almeida. Blind and semi-blind deblurring of natural images. IEEE
Transactions on Image Processing , 19(1):36{52, 2009.BILEVEL INVERSE PROBLEMS IN NEUROMORPHIC IMAGING 19
[2] Harbir Antil, Zichao Wendy Di, and Ratna Khatri. Bilevel optimization, deep learning and fractional
laplacian regularization with applications in tomography. Inverse Problems , 36(6):064001, May 2020.
[3] Simon Arridge, Peter Maass, Ozan Oktem, and Carola-Bibiane Sch onlieb. Solving inverse problems
using data-driven models. Acta Numerica , 28:1{174, 2019.
[4] Mario Bertero, Patrizia Boccacci, and Christine De Mol. Introduction to inverse problems in imaging .
CRC press, 2021.
[5] Alessandro Buccini, Marco Donatelli, and Ronny Ramlau. A semiblind regularization algorithm
for inverse problems with application to image deblurring. SIAM Journal on Scientic Computing ,
40(1):A452{A483, 2018.
[6] Leon Bungert and Matthias J Ehrhardt. Robust image reconstruction with misaligned structural infor-
mation. IEEE Access , 8:222944{222955, 2020.
[7] Julianne Chung, Matthias Chung, and Dianne P O'Leary. Designing optimal spectral lters for inverse
problems. SIAM Journal on Scientic Computing , 33(6):3132{3152, 2011.
[8] Juan Carlos De los Reyes, Carola-Bibiane Sch onlieb, and Tuomo Valkonen. Bilevel parameter learning
for higher-order total variation regularisation models. J. Math. Imaging Vision , 57(1):1{25, 2017.
[9] Guillermo Gallego, Tobi Delbr uck, Garrick Orchard, Chiara Bartolozzi, Brian Taba, Andrea Censi, Ste-
fan Leutenegger, Andrew J. Davison, J org Conradt, Kostas Daniilidis, and Davide Scaramuzza. Event-
based vision: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence , 44(1):154{
180, 2022.
[10] Daniel Gehrig, Henri Rebecq, Guillermo Gallego, and Davide Scaramuzza. Asynchronous, photometric
feature tracking using events and frames. In Proceedings of the European Conference on Computer
Vision (ECCV) , pages 750{765, 2018.
[11] Tamara G. Kolda and Brett W. Bader. Tensor decompositions and applications. SIAM Review ,
51(3):455{500, 2009.
[12] Renaud Morin, St ephanie Bidon, Adrian Basarab, and Denis Kouam e. Semi-blind deconvolution for
resolution enhancement in ultrasound imaging. In 2013 IEEE International Conference on Image Pro-
cessing , pages 1413{1417. IEEE, 2013.
[13] Liyuan Pan, Cedric Scheerlinck, Xin Yu, Richard Hartley, Miaomiao Liu, and Yuchao Dai. Bringing a
blurry frame alive at high frame-rate with an event camera. In Proceedings of the IEEE/CVF Conference
on Computer Vision and Pattern Recognition , pages 6820{6829, 2019.
[14] Se Un Park, Nicolas Dobigeon, and Alfred O Hero. Semi-blind sparse image reconstruction with appli-
cation to mrfm. IEEE Transactions on Image Processing , 21(9):3838{3849, 2012.
[15] Pooja Satish, Mallikarjunaswamy Srikantaswamy, and Nataraj Kanathur Ramaswamy. A comprehensive
review of blind deconvolution techniques for image deblurring. Traitement du Signal , 37(3), 2020.
[16] Cedric Scheerlinck, Nick Barnes, and Robert E. Mahony. Continuous-time intensity estimation using
event cameras. CoRR , abs/1811.00386, 2018.
[17] Shu Tang, Weiguo Gong, Weihong Li, and Wenzhi Wang. Non-blind image deblurring method by local
and nonlocal total variation models. Signal processing , 94:339{349, 2014.
[18] Shipeng Xie, Xinyu Zheng, Wen-Ze Shao, Yu-Dong Zhang, Tianxiang Lv, and Haibo Li. Non-blind
image deblurring method by the total variation deep network. IEEE Access , 7:37536{37544, 2019.
[19] Zhengrong Xue. Blind image deblurring: a review. CoRR , abs/2201.10522, 2022.
[20] Min Zhang, Georey S Young, Yanmei Tie, Xianfeng Gu, and Xiaoyin Xu. A new framework of designing
iterative techniques for image deblurring. Pattern Recognition , 124:108463, 2022.
H. Antil. The Center for Mathematics and Artificial Intelligence and Department of
Mathematical Sciences, George Mason University, Fairfax, VA 22030, USA.
Email address :hantil@gmu.edu
D. Sayre. The Center for Mathematics and Artificial Intelligence and Department of
Mathematical Sciences, George Mason University, Fairfax, VA 22030, USA.
Email address :dsayre@gmu.edu