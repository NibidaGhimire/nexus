arXiv:2401.00060v3  [astro-ph.IM]  4 Oct 2024Version October 8, 2024
Preprint typeset using L ATEX style openjournal v. 09/06/15
ASSESSING YOUR OBSERVATORY’S IMPACT:
BEST PRACTICES IN ESTABLISHING AND MAINTAINING OBSERVATOR Y BIBLIOGRAPHIES
Raffaele D’Abrusco1,Monique Gomez2,Uta Grothkopf3,Sharon Hunt4,Ruth Kneale5,Mika Konuma6,
Jenny Novacescu7,∗,Luisa Rebull8,Elena Scire9,Erin Scott1,Richard Shaw7,Donna Thompson10,
Lance Utley11,Christopher Wilkinson7, andSherry Winkelman1
1Chandra Data Archive, Chandra X-ray Center (CXC) / Center fo r Astrophysics, Harvard & Smithsonian, 60 Garden Street,
Cambridge, MA 02138, USA
2Instituto de Astrof´ ısica de Canarias (IAC), V´ ıa L´ actea, s/n E-38205, La Laguna - Tenerife, Spain
3European Southern Observatory (ESO), Karl-Schwarzschild -Straße 2, 85748 Garching bei M¨ unchen, Germany
4NSF NOIRLab, 950 N Cherry Ave, Tucson, AZ 85719, USA
5National Solar Observatory (NSO)/DKIST, retired, 3665 Dis covery Drive, Boulder, CO 80303, USA
6National Astronomical Observatory of Japan (NAOJ), 2-ch¯ o me-21-1 ¯Osawa, Mitaka, Tokyo 181-8588, Japan
7Space Telescope Science Institute (STScI), 3700 San Martin Dr., Baltimore, MD 21218, USA
8Infrared Science Archive (IRSA), IPAC, MS 100-22, Caltech, 1200 E. California Blvd, Pasadena, CA 91125, USA
9IPAC, Mail Code 314-6, Caltech, 1200 E. California Blvd. Pas adena, CA 91125, USA
10ADS / Center for Astrophysics, Harvard & Smithsonian, 60 Gar den Street, Cambridge, MA 02138, USA and
11National Radio Astronomy Observatory (NRAO), 520 Edgemont Road Charlottesville, VA 22903-2475, USA
Version October 8, 2024
Abstract
Observatoriesneedtomeasureandevaluatethescientiﬁcoutput andoverallimpactoftheirfacilities.
Observatory bibliographies are one of many valuable methods to ass ess impact. An observatory
bibliography consists of the papers published using that observato ry’s data, typically gathered by
searching the major journals for relevant keywords. Recently, t he volume of literature and methods
by which the publications pool is evaluated have increased. Eﬃcient a nd standardized procedures are
necessarytoassignmeaningfulmetadata,enableuser-friendlyr etrieval,andprovidetheopportunityto
derive reports, statistics, and visualizations to impart a deeper un derstanding of the research output.
In 2021, a group of observatory bibliographers from around the w orld convened online to continue
the discussions presented in Lagerstrom (2015). We worked to extract general guidelines from our
experiences, techniques, and lessons learned. This paper explore s the development, application, and
current status of telescope bibliographies and future trends. Th e paper brieﬂy describes the method-
ologies employed in constructing the databases, along with the vario us bibliometric techniques used to
analyzeandinterpretthem. Weexplainreasonsfornon-standard izationandwhyit isessentialforeach
observatory to identify metadata and metrics that are meaningfu l for them; caution the (over-)use of
comparisons among various facilities that are, ultimately, not compa rable through bibliometrics; and
highlight the beneﬁts of telescope bibliographies, both for researc hers within the astronomical com-
munity and for stakeholders beyond the speciﬁc observatories. T here is tremendous diversity in the
ways bibliographers track publications and maintain databases, due to parameters such as resources
(personnel, time, budget, IT capabilities), type of observatory, historical practices, and reporting re-
quirements to funders and outside agencies. However, there are also common sets of Best Practices.
This paper describes some of the results from our collaborative disc ussions.
Subject headings: Astronomy Databases (83), Astronomical reference materials ( 90), Observatories
(1147), Telescopes (1689)
1.INTRODUCTION
It has become increasingly important for astronomical
observatories to measure and evaluate the scientiﬁc out-
put, overallimpact, and generalsuccess oftheir facilities.
Manymethods exist to doso. Acommonlyused oneis to
createdatabaseswith descriptionsofthescientiﬁc papers
that have been published using data from the observa-
tory facilities. The resulting compilations are typically
referredto astelescope orobservatorybibliographiesand
the technique of interpreting and analyzing them as bib-
∗E-mail: jnovacescu@stsci.eduliometrics. In many observatories, librarians and archive
specialists manage these information resources. These
staﬀ also play a deﬁning role in the further development
of the bibliographies to ensure their continued value for
the speciﬁc observatory including its management, gov-
erning bodies, and project and instrument scientists, as
well as the wider astronomy community.
Observatory bibliographies may include telescope data
publications, data products publications, data services
publications, staﬀ publications, mission bibliographies,
archival products bibliographies, etc. They are typically
compiled by scanning the major journals for scientiﬁc2
papers that use or analyze data generated by the respec-
tive observatories. During recent years, there has been a
constant increase in not only the volume of astronomical
literature ( Chen et al. 2022a ) but also the number and
methods by which a pool of publications is evaluated
(van Raan 2019 ). Eﬃcient and standardized procedures
are necessary to assign rich and meaningful metadata,
enable user-friendly retrieval, and provide the opportu-
nity to derive reports, statistics, and visualizations that
enable a deeper understanding of the research output
from various perspectives.
Astronomy has a long-standing history of sharing and
exchangingpapers,data,andsoftware. Despite(orpossi-
bly because of) the large geographical distances between
observatories, collaboration has always been a vital el-
ement to staying informed about recent developments
and building on the results of peer researchers. This is
equally true for astronomy librarians, with their series
of meetings, such as the Library and Information Ser-
vices in Astronomy (LISA) conferences1, and other for-
mal and informal ways of exchanging best practices in a
fair, transparent, and collaborative way. It is therefore
not surprising that astronomy librarians, data scientists,
and archive specialists have been discussing observatory
bibliographies for many years. Many papers describing
individual observatories’ bibliographies have been pub-
lished (see Appendix B), along with articles about Best
Practices ( Lagerstrom 2015 ;Chen et al. 2022b ).
In 2021, a group of observatory bibliographers from
around the world convened online to continue the discus-
sions and eﬀorts presented in Lagerstrom (2015). Many
oftheinstitutionsrepresentedinthatpaperarethesame,
although individuals have changed, and representatives
from additional institutions were added to broaden the
astronomy disciplines managing observatory bibliogra-
phies. We formed the Observatory Bibliographers Col-
laboration (OBC), with the goals of sharing transparent
and fair bibliography methods and standards and creat-
ing shared documentation and processes. The group has
worked to extract generally applicable guidelines from
the experiences, techniques, and lessons learned of the
various observatories.
Over the course of our discussions, a few key actions
emerged that shape the objectives of this paper. We aim
to:
•cover all aspects of observatory bibliographies to
identify commonalities and to present the creative
ways in which observatory bibliographers have met
their challenges despite limited resources;
•provide some lessons learned with a focus on the
most serious errors over time and how they were
addressed; and
•provide updated standards/recommendations, rec-
ognizing that as science changes, so must observa-
tory bibliographies.
The best practices that we outline in this paper are
intended to serve as guidelines to both new and expe-
rienced bibliographers. We hope that we can provide
1http://www.eso.org/sci/libraries/lisa.htmlguidance to those needing to create new observatorybib-
liographies because, as we discovered, a quick-and-dirty
approach can lead to incomplete or wrong conclusions
and may ultimately be worse than no bibliography at
all. For those individuals tasked with maintaining ob-
servatory bibliographies who are not credentialed librar-
ians, the descriptions and recommendations contained in
this paper are intended to ﬁll gaps in their knowledge
of library practices. In addition, those individuals who
use and assess the metrics generated from observatory
bibliographies can gain an understanding of how these
bibliographies are constructed and their constraints.
In this paper, we explorethe development, application,
and current status of observatory bibliographies and the
direction in which they are moving. We brieﬂy describe
the methodologies employed in constructing the bibli-
ographies, alongwith the various bibliometric techniques
used to analyze and interpret the papers collected within
these bibliographies. We explain the reasons for non-
standardization, i.e., why it is essential for each observa-
tory to identify the metadata and metrics that are mean-
ingful for them; caution on the (over-)use of comparisons
among various facilities that are, ultimately, not compa-
rable through bibliometrics; and highlight the beneﬁts of
observatory bibliographies, both for researchers within
theastronomicalcommunityandforstakeholdersbeyond
the speciﬁc observatories. The paper concludes with a
look at essential skills for observatory bibliographers, as
well as a glimpse towards future trends and technologies
thatwillinﬂuence thecreation, maintenance, andfurther
development of observatory bibliographies.
2.IDENTIFYING CANDIDATE PUBLICATIONS
To begin the bibliographyprocess, most bibliographers
rely on automated and/or semi-manual keyword match-
ing against the full-text ﬁles of publications provided by
the publishers. Bibliographers then scan the literature
visually and/or aided by text-mining software to identify
candidate publications for inclusion in their observatory
bibliography.
2.1.SAO Astrophysics Data System (ADS)
The SAO Astrophysics Data System (ADS), funded
by NASA, is a digital index operated by the Smithso-
nian Astrophysical Observatory (SAO) under NASA Co-
operative Agreement 80NSSC21M00561( Eichhorn 2004 ;
Chyla et al. 2015 ). ADS currently contains more than
15 million records that cover the NASA Science Mission
Directorate (SMD) disciplines of astrophysics, planetary
science, heliophysics, and earth science. ADS will soon
become the NASA Science Explorer(SciX), and any new
bibliographicprojectsshould be started on that platform
when released. NASA-funded research in biological and
physical sciences is also being added to SciX. Currently,
the records are grouped among four primary collections:
astronomy and astrophysics, physics, earth science, and
general science. The bibcodes that ADS currently uses
to identify publications are 19 digit, human-readable,
unique identiﬁers that describe the article with a year,
journal, volume, and page, e.g., 2022ApJS..260....5C.
Many(thoughnotall)oftheobservatorybibliographyin-
frastructures are built around these bibcodes. Abstracts
and full text of major astronomy and physics publica-
tions are indexed and searchable within ADS, and arXiv3
e-prints are ingested daily as well. The ADS website of-
fers help pages as well as a blog and news updates.
Observatory bibliographers use the ADS database and
its functionalities extensively to identify and track obser-
vatory publications. They can query the ADS database
using either the ADS web submission search forms or
the system’s application programming interface (API) to
identify publications to be assessed for inclusion in ob-
servatory bibliographies. Users can search in a variety
of ﬁelds, including full text, author, aﬃliation, keyword,
publication name or abbreviation, and date. It is also
possible to string together multiple search terms to de-
velop a query. Users can create libraries of ADS records
forspeciﬁc telescopes, dataproducts, missions, andother
subjects. Theselibrariescanbekeptprivate, sharedwith
speciﬁc collaborators, or made public for viewing by any
ADS user. With assistance from ADS curators, many
institutions have created publicly shared ADS libraries
that can be set as unique bibliographic groups in ADS
such asbibgroup:chandra andbibgroup:GALEX . Updates
to these bibliographic groups can be set automatically
or done manually on a quarterly, annual, or other regu-
lar cadence. Publicly accessible, curated bibliographies,
which are datasets in themselves, are important compo-
nents of open science and align with the current Trans-
form to Open Science (TOPS) initiative at NASA2.
2.2.Crossref
Crossref3is a non-proﬁt organization and aggregator
for publication information. More than 17,000 orga-
nizational members and publishers deposit metadata
about their journals, ebooks, conference proceedings,
and other publications through Crossref. With the
appropriate licenses and a Crossref agreement in place,
an observatory can mine the full-text ﬁles for a set of
journals, similar to full-text ﬁeld searching in ADS.
Crossref oﬀers its own RestAPI4. We encourage those
interested in processing large volumes of full-text ﬁles
for bibliographic work to explore Crossref in addition to
ADS.
2.3.Keyword Searching
To comprehensively search through thousands of ar-
ticles per year, bibliographers must consider all com-
mon forms of keywords, telescope names, instruments,
high-proﬁle programs, etc., and search acronyms, for-
mer names, accepted colloquial forms, and community-
accepted spelling and punctuation variations in addition
to the oﬃcial name form.
Comprehensive search and discovery using keywords
are complicated by simple typos or misspellings not
caught during the editorial process and diﬀerences in hy-
phenation and punctuation. While ADS does an excel-
lent job of mapping synonymous terms and name forms
in the background, they cannot be held responsible for
identifying every variation, including newly created ones.
Asanexample, theTwoMicronAllSkySurvey(2MASS)
can also be found written as Two-Micron All Sky Sur-
vey, Two Micron All-Sky Survey, 2MASS, 2-MASS, and
2https://science.nasa.gov/open-science/
3https://www.Crossref.org
4https://www.Crossref.org/documentation/retrieve-met adata/rest-api/2 MASS. Another example is the National Solar Obser-
vatory’s (NSO) Daniel K. Inouye Solar Telescope obser-
vatory, DKIST. It was previously called the Advanced
Technology Solar Telescope (ATST), and in its begin-
ning, the acronym did not include the ﬁrst T, so was
just AST. It is also referred to as Inouye, Inouye Solar
Telescope,andDKISolarTelescope. Therearepublished
papers using every one of these variations.
For the Chandra X-ray Observatory, the keyword set
includes Chandra, CXO, and AXAF and their variants.
The European Southern Observatory (ESO) uses regu-
lar expressions to retrieve program IDs and data DOIs
in papers and also searches for over 200 keywords; many
of them are acronyms as well as long versions of facil-
ity and telescope names. Often acronyms reveal unre-
lated homonyms. An overview of the experience gained
through more than 20 years of the ESO telescope bibli-
ography is provided in Grothkopf et al. (2018).
Common acronyms are diﬃcult to manage, and they
add to the time needed to assess papers ( Scire et al.
2022). In the case of HST and JWST, respectively, the
acronyms for the Cosmic Origins Spectrograph (COS)
and the Near Infrared Spectrograph (NIRSpec) were re-
moved entirely from bibliography search strings due to
the number of false hits. NIRSPEC (typically in capital-
ized form) is also used to identify an instrument on one
of the telescopes at the W. M. Keck Observatory. Some
mitigation strategies to deal with common keywords and
acronyms in the literature include keyword pairs, such
acronym 1 AND (keyword 1 OR keyword 2), e.g., NIR-
Spec AND (“James Webb Space Telescope” OR JWST),
written parenthetically in ADS. Some acronyms can also
be limited to certain journals. For example, a search can
be created to ignore instances of the acronym ACS in
SPIE Proceedings , where ACS can refer to multiple con-
cepts across sciences rather than its intended meaning –
Advanced Camera for Surveys – more commonly found
in astronomy journals.
NSF NOIRLab keywords include instruments, tele-
scopes, surveys, the archive, and data products and ser-
vices such as the Astro Data Lab. Searching for the
Blanco and Mayall telescopes is complex, since individ-
uals use a variety of names to refer to these long-lived
telescopes. For example, the Victor R. Blanco Telescope
is referred to as the Blanco, the CTIO 4m, the 4m tele-
scopeatCTIO,andthe CerroTololo4-meter/4m/4m/4-
m. In addition, the name Blanco appears often in ref-
erence lists and in star names so many false positives
are retrieved when doing a search solely on the key-
word Blanco. Similarly, the Legacy programs SIMPLE,
GOALS, Taurus, Cygnus-X, which use large volumes of
Spitzer Space Observatory data, were removed from the
search terms due to the common use of these words in
the literature ( Scire et al. 2010 ).
ForSpitzer, thekeywordsetincludedtheshortnameof
the observatory (Spitzer), acronyms for the instruments
(IRAC, MIPS, IRS), and acronyms for the Legacy, Ex-
plorationScience,andFrontierLegacyprograms. Spitzer
has since been handed over to the Infrared Science
Archive (IRSA), which searches on a subset of these
terms. Searching by instrument names and acronyms
in addition to telescope and observatory names is neces-
sary because some papers may only cite the instrument
without mentioning the observatory itself. For IRSA, it4
is not possible to track all papers using all datasets that
havevaryingnamesandacronyms. Becauseoflimitedre-
sources, onlypapersforcertaindatasetsaretracked,typ-
ically the most popular such as WISE, Planck, 2MASS,
and IRAS. Accounting for all of the papers that emerge
from diverse datasets can be challenging, particularly
when the publication does not specify the name of the
observatory or even the instruments used to obtain the
data.
2.4.Alternatives to Keyword Searching and Limitations
One might think that an alternative and more accu-
rate search could be accomplished by looking for cita-
tions of key publications. The 2MASS project requests
that people cite Skrutskie et al. (2006), the journal arti-
cle describing 2MASS, but many people cite instead the
delivery document, Cutri et al. (2003). For Spitzer, only
62% of papers that use data from the observatory cited
oneofthe keypublicationsabout the observatoryorused
the acknowledgment statement correctly (see Scire et al.
2022, ﬁg. 2).
Searching by a standard acknowledgement phrase to
identify candidate papers is not a comprehensive solu-
tion, even when authors remember to include one. The
2MASS project has been around for nearly two decades
and has been fundamental to many papers; the words
in the requested acknowledgement seem to be “carried
along” in the template LaTeX for many authors. There
are many examples of papers that acknowledge 2MASS
but do not appear to actually use 2MASS data, even for
calibration,intheanalysispresentedtherein. Ifthosepa-
pers were not manually excluded by checking each one,
they would artiﬁciallyinﬂate publication statistics. Like-
wise, while it may be helpful to search the Acknowledge-
ments section for mentions of grants, the existence of a
grants statement does not guarantee that new, original
analysis was done using that data. Counting instances
of grant statements should not be relied on as a primary
method to identify science papers attributed to a partic-
ular observatory. Still, the presence of a data acknowl-
edgement statement can be a strong indicator to the bib-
liographer that they may be assessing a science/data pa-
per.
2.5.Communicating Data Citation Policies
Observatories are advised to clearly communicate
the data citation policy(ies) relative to their observa-
tory(ies). Such policies should state when and how au-
thorsmustacknowledgeuseoftheobservatory’sdataand
provide standard verbiage that can be cut and pasted
into a manuscript. Some suggestions for disseminat-
ing this information include posting on the observatory’s
public website, providing verbiage within calls for pro-
posals, linking or re-posting on the landing page for
the data archive, and sharing such policies in person-
to-personcommunicationswith investigatorsand archive
users. Some examples of data citation policies and sug-
gested acknowledgments can be found on the IRSA,
NAOJ, ESO, NOIRLab, Chandra, and STScI websites,
as well as most other observatories.
3.EVALUATION OF PUBLICATIONS FOR INCLUSION IN
OBSERVATORY BIBLIOGRAPHIESAfter a candidate paper for inclusion is identiﬁed, the
bibliographer analyzes the paper for inclusion in the ob-
servatory bibliography. Papers are commonly examined
“by eye”, following the guidelines set out in this paper.
Most papers are still tagged and categorized in a semi-
manual fashion by bibliographers, requiring human re-
view to determine whether publications that mention a
telescope, observatory, instrument, data product, or sur-
vey in the full text do in fact qualify as reportable “sci-
ence”, “data”, or “observational” papers.
3.1.Science Papers
A critical component to enabling fair comparisons and
benchmarking of observatory publications is a common
deﬁnition for “science”, “data”, or “observational” pa-
pers. When a paperis classiﬁedas one ofthese, it is typi-
callyincludedintheoﬃciallistofpublicationsattributed
to an observatory and tabulated in internal and external
reporting metrics. Classiﬁcation as “non-science” is dis-
cussed later in this section.
The OBC agrees on the following criteria for tag-
gingpapersweroughlycategorizeas“science”, otherwise
called “data” or “observational”papers at some observa-
tories. Each observatory may interpret these guidelines
in slightly diﬀerent ways, but the spirit of what deﬁnes a
science publication is consistent acrossour observatories.
1.To qualify as a science paper, it must be ap-
parent that data or data product(s) from the
observatory were used and that the data or
data product(s) formed the basis for reach-
ing a new scientiﬁc conclusion. Whether
your observatory includes only publications
that appear to use “raw” data or also publi-
cations that cite compiled catalogs and high-
level products must be clariﬁed within your
organization and should be communicated in
both internal- and external-facing metrics.
Data and/or data products referenced in a pub-
lication can be from a single telescope or many
observatories. Borrowing from the NOAO Inclu-
sion Criteria document: “The amount of ... data
analyzed does not have a bearing upon inclusion;
if a small amount of ... data in relation to the
total amount of data sets in the paper is used in
the conclusions, the paper is included.” In another
example, if the 2MASS data were being used to
calibrate the astrometry and/or the ﬂux for data
obtained by authors at another observatory, and
that other secondary observatory’s data were used
to reach a new scientiﬁc conclusion, the paper may
still be included in the 2MASS/IRSA bibliography,
even if the 2MASS data were not the basis for the
new conclusion.
2.“Data” can be deﬁned in a number of ways
– it may be original data taken by the
author(s) as part of their proposal(s) or
archival data reduced or analyzed anew by
the author(s).
Like the 2MASS example, the data might not be
observational data but rather position or ﬂux cal-
ibration for some observatories or datasets. Sci-5
ence papers may also rely on enhanced data prod-
ucts such as catalogs (including source catalogs) or
spectra that combine processed telescope data in
a meaningful format for the greater astronomical
community, so long as it is apparent these reﬁned
data products were a component of the author’s
analysis. Spitzer tagged all papers that used en-
hanced data products, which is useful in measuring
the popularity of the advanced data products.
Bibliographers generally do not count publications
that cite or acknowledge an observatory without
actually having used its data. For many observa-
tories, it is not uncommon to ﬁnd a paper in which
the author(s) acknowledge an observatory or one
of its data products, e.g., 2MASS, HST grant num-
ber, orESOprojectnumber,withoutactuallyusing
their data in the paper.
3.To qualify as a science paper, it does not
matter if the observations have been pub-
lished before, so long as the way the results
are presented constitute new analysis or use.
A simpliﬁed summary or quote mentioning how
others used or analyzed data in an earlier publi-
cation generally does not constitute new use. A
statement such as “Smith & Doe found the same
using the VLT” would not qualify, whereas a state-
ment such as “see Bain et al. (2009), Table 3, for
a list of VLT observations used in our analysis”
would constitute reanalysis.
4.Further reﬁnement of science papers is pos-
sible.
For pointed observatories in particular, what con-
stitutes a science paper depends on the mission-
speciﬁc deﬁnitions of what constitutes “citable”
science data. The types of scientiﬁc data avail-
able can evolve with time as the archive grows and
the data lend themselves to scientiﬁc results based
on higher-level processing and analysis. One goal
of the mission bibliography is to expand and up-
date the deﬁnitions of a “science paper” to keep
step with the evolution of how data are used and
the scientiﬁc results produced by the astronomical
community during the lifetime of the mission and
possibly beyond.
The Chandra X-ray Center (CXC) tags their sci-
ence papers as either “direct” or “indirect”. In
CXC’s deﬁnition, a Chandra Science Paper (CSP)
is one in which Chandra data make a signiﬁ-
cant contribution to the scientiﬁc conclusions of
the paper. “CSP-direct” papers start with data
products that can be retrieved from the Chandra
archive. “CSP-indirect” papers present new anal-
ysis of Chandra data starting from the results in
a referenced paper or use high-level, science-ready
data products derived from lower-level, archival
observations. Indirect papers are predominantly
based on catalogs comprised of Chandra single ob-
servations and the Chandra Source Catalog, which
combinesandprocessessingleChandraarchivalob-
servations to provide access to science-ready prop-
erties and data products for all X-ray sources de-tected by Chandra. Both CSP-direct and CSP-
indirect are included in the annual science paper
statistics and qualify as science papers from the
point of view of other observatories, even though
other bibliographies may not separate “direct” and
“indirect” science in the same way.
The Space Telescope Science Institute (STScI) and
Hubble Mission Oﬃce decided to track the use
of non-reprocessed HST data, in particular from
catalogs, calibration studies, etc., in the literature
and created a new paper classiﬁcation called data-
inﬂuenced in 2018. These papers are not included
in the annual science paper metrics since they do
not present a (re-)analysis of HST data. They are
signiﬁcant to the Mission Oﬃce, however, because
they present another use case for how the telescope
enables astrophysical research, even if not counted
among the oﬃcial statistics.
As the nature of astrophysical research changes,
the policies and guidelines for inclusion of papers
need to be updated regularly and adapted. As in
the Chandra and HST examples, rules for the use
of catalogs may have to be established to properly
distinguish between papers that merely cite mea-
surements or results from the literature and those
that actually relied on downloaded (archival) data
or (re-)analyzed them to achieve new scientiﬁc re-
sults.
5.Each observatory makes the decision on
whether refereed and non-refereed publica-
tions are counted as oﬃcial science papers.
Some observatories include non-refereed publica-
tions in their oﬃcial science paper count while oth-
ers do not. NSO includes SPIE non-refereed publi-
cations in their oﬃcial count; the rest of the publi-
cations in their bibliography are refereed. STScI
generally does not include non-refereed publica-
tions in its oﬃcial science paper count, with the
exception of some major conference proceedings
(IAU, ASP, AIP, SPIE), constituting less than 4%
of HST science papers through 2021. The CXC
bibliography ingests all data and catalog papers it
ﬁnds in the worldwide literature, refereed or not.
Chandra also includes some circulars (e.g., the As-
tronomer’s Telegram) that supply the full content
of the article as an abstract to the ADS. Those
publications are considered full articles for the in-
ternal bibliography, but are not tabulated in ex-
ternal metric reports. Some proceedings publish
only the abstract as the complete contents. Those
publications are not considered to be full articles
and are not entered into the CXC internal bibli-
ography ( Rots et al. 2012 ). NOIRLab excludes all
non-refereed publications in its oﬃcial science pa-
per count, as do Spitzer and IRSA.
Dissertations are another variable in science paper
bibliographies. Some observatory bibliographers
include them in reportable metrics, while others
do not. In some cases, dissertations may be their
own reportable metric, separate from the oﬃcial
bibliography. The inclusion of dissertations can be
particularly important as they represent a metric6
(althoughindirect)ofhowmissionsimpactyounger
generations of astronomers and help educate our
community. Dissertations should be maintained as
a separate category in the bibliography since often
they represent, or will represent, scientiﬁc results
later published in a refereed journal article. Not all
dissertations are published in ADS so the bibliog-
rapher will need to mine other databases, such as
ProQuest Dissertations & Theses, for these publi-
cations.
3.2.Non-science Papers
The following list describes some common examples of
attributes of papers that may be tagged as non-science
publications, referredto asa“mention”byvariousobser-
vatories. This list is not exhaustive, but represents the
most common scenarios when bibliographers may choose
not to classify a paper as pure “science” or “data”.
•Lack of New Analysis : Compares previously pub-
lished results and scientiﬁc conclusions to results
in current paper without new analysis. Uses only
values extracted from observational data without
new processing or analysis of the data. This in-
cludes instances where a paper uses measurements
or results from the existing literature.
•Background Content : Cites observatories or mis-
sions in the history, background, or introduction of
a research paper to summarize other people’s re-
search or the entire body of literature.
•Fields and Locations : Uses a deﬁned ﬁeld ﬁrst ob-
served by the telescope to select where to point an-
other telescope, without further discussion or proof
that data from original observations in that ﬁeld
were analyzed beyond processed results in an ear-
lier publication. Uses ﬁnalized results from an ear-
lier publication to determine source selection and
location of observations presented in the paper.
Uses data to calibrate positions or ﬂuxes for data
from other telescopes, e.g., 2MASS.
•Instrumentation and/or Software : Describes in-
strumentation or software. Some observatories,
such as NSO, include these papers in their oﬃcial
science paper count. Spitzer tracked these papers,
but unless they used observational data from the
observatory, they were not included in the oﬃcial
science paper counts. NOIRLab tracks instrumen-
tation papers, but does not include them in their
oﬃcial science paper count, nor does STScI.
•Archival Tools : Describes tools or protocols at
archives for astronomers to use. Some institutions,
such as IRSA, may choose to include these papers
in their oﬃcial science paper count.
•Future Observations : Proposes future observations
with telescopes or instruments by creating models
or simulations, using data merely as examples or to
validate a proposed model’s output. These may be
tabulated in a diﬀerent way that is more signiﬁcant
than a passing “mention”, but are generally not
counted as oﬃcial “science” papers.•Images as References : Shows images as a visual
reference or as an overlay with other telescopes’ vi-
suals without further discussion. This is typically
done to layer observations from other parts of the
spectrum or to indicate regions of the sky consid-
ered in a paper. A publication that uses visuals to
achieve scientiﬁc results or provides additional de-
tails about visuals and their underlying data may
qualify as a science publication.
•Nested Catalogs : For most observatories, only pa-
pers citing the original catalog and demonstrating
use of the original catalog are included in the sci-
ence papers. Papers citing a catalog that absorbed
processed data from the original catalog are typ-
ically not included. Nested catalogs are common
in extragalactic deep ﬁelds. To illustrate the sub-
tleties, IRSA will count papers if they use data
from sources that were downloaded from IRSA (or
couldhavebeendownloadedfromIRSA), including
catalogs, but not products derived from catalogs,
e.g., extinction maps, unless also served by IRSA.
The Spitzer bibliography counted papers that ex-
plicitly stated they used the catalogs produced by
the large surveyLegacy orExplorationScience and
Frontier Legacy programs, as those programs were
supported by the observatory’s data analysis fund-
ing for the speciﬁc purpose ofcreatingthe catalogs.
•Review Articles : These generally summarize the
literature rather than present new science results.
Some may qualify as new research, but this is rare.
•Advance Access Articles : Advanced electronic ver-
sions of papers that later appear as a ﬁnal publi-
cation are not included. This includes, for exam-
ple, arXiv, MNRAS.tmp, and Natur.tmp bibcodes
from ADS. These preprints may be tracked inter-
nally, but are not reported in external metrics as
oﬃcial science papers unless they later appear in
refereed form.
•Standard Stars : Published standard stars for cali-
bration purposes are generally not considered new
science.
•Enhanced Data Products : Catalogs and other en-
hanced data products created by the community
using data from programs not speciﬁcally funded
to produce these high-level products. For exam-
ple, on Spitzer, some programs resulted in the cre-
ation of enhanced data products, but are not of-
ﬁcial Legacy5or Exploration Science6programs.
The Spitzer bibliographer did not count papers us-
ing these products because Spitzer did not neces-
sarily host the enhanced products, and producing
the enhanced products was not part of the fund-
ing that was explicitly allocated. However, IRSA
does count these for some programs. The HST and
JWST bibliographies tend to include papers that
cite catalogs and other High-Level Science Prod-
ucts7hosted by the Mikulski Archive for Space
5https://irsa.ipac.caltech.edu/data/SPITZER/docs/spi tzermission/observingprograms/legac 
6https://irsa.ipac.caltech.edu/data/SPITZER/docs/spi tzermission/observingprograms/es/
7https://archive.stsci.edu/hlsp7
Telescopes (MAST) because part of MAST’s mis-
sionistocollectandcuratecommunity-contributed
products based on MAST data to make them avail-
able to the wider community for reuse.
4.JOURNAL COVERAGE
Journal coverage is an important consideration in any
discussion of bibliometric best practices. The set of jour-
nals searched impacts end counts for the number of sci-
encepapersincludedinanobservatorybibliography. Dif-
ferent institutions search diﬀerent sets of journals to ﬁnd
science papers. Important factors in choosing the list
of journals to cover include the historical publication
record, the science areas covered by instruments or mis-
sions, and the resources available at an institution.
We tallied the representation of each ADS-indexed
journal in our institutional bibliographies to gauge the
historical record, reporting on the number of papers
found in speciﬁc journalsasa percentageofourtotalbib-
liographicdataset. The overwhelmingmajorityofpapers
ineveryinstitution’s historicbibliographycamefromone
of ﬁve core journals, and fewer than a dozen other titles
are signiﬁcantly represented. Among all the possible ti-
tles available in ADS, only a small subset is statistically
signiﬁcant to the various bibliographies maintained by
the OBC members. The list of the most common jour-
nals across institutions is provided in Appendix A. The
historical record makes a compelling argument for where
to focus journal coverage in new or future bibliographies
when staﬀ and labor limitations dictate a curated ap-
proach from the start.
An important consideration in choosing journals to
search is subject coverage. Certain ﬁelds in astronomy
are inherently diﬀerent from one another; for example,
extragalacticversussolar astronomyor planetary science
versuscosmologyandmayrelyondiﬀerentsubdisciplines
(Henneken & Kurtz 2019 ). The journals that are rele-
vant to these ﬁelds will vary. For example, Icarusis
better suited to planetary missions and their resulting
publications, as are some American Geophysical Union
(AGU) titles. Other journals such as Astronomy & As-
trophysics are steady sources of new research on extra-
galacticand stellartopics. If aninstitution’s instruments
or missions are particularly focused on one area of prac-
tice within astronomy, this should inform the journals
that a bibliographer searches for science papers. It is in-
cumbent on a bibliographer to determine which journals
are relevant for their observatory’s data.
Bibliographers need to consider the resources available
for their eﬀorts – software, tools, staﬀtime – when decid-
ing which journals to search. The more journals included
in a search and the more terms, keywords, or acronyms
searched, the more results there will be for candidate
papers. Tools, technology, and a considered approach
to query strings will reduce the time required to review
results.
Therearethreemainstrategiesabibliographercanem-
ploy when choosing which journals to search. The ﬁrst
is the broadest use of ADS where all available journals
are searched, either using the API or manually running
searches on the ADS site. The second strategy is to con-
duct a focused search on only a select list of journals,
either through ADS or through the individual journals.
The third strategyis a full-text searchofspeciﬁc journalsusing text mining or other technologies, which may rely
on Crossref. A combination of strategies may be best
depending on the speciﬁc circumstances. At times, there
are beneﬁts to casting a broad net to determine if data
and discoveries by an observatory are impacting other
disciplines in astronomy. Many observatory bibliogra-
phers use a curated approach throughout the year, then
run a wider search against negative results at year’s end
to identify relevant papers that may not have been found
using the more precise criteria. One example is combin-
ing designated JWST keywords with NOT bibgroup:jwst
in ADS, scouring through additional refereed journals
after known JWST papers have been tagged from the
pre-deﬁned journal set for the year.
The choice of journal coverage at an institution is spe-
ciﬁc to that institution’s current needs, historical record,
subject areas within astronomy, and available resources.
Just as no two observatories or telescopes are identical,
journal coveragethat is the basis ofan institution’s bibli-
ographywillbediﬀerent. Itiscriticalthatbibliographers
andthose who usecurated bibliographiesunderstand not
all institutions are considering the same pools of journal
coverage. If an institution beginning a new bibliography
is unsure which journals to begin focusing on, we rec-
ommend considering the core list of journals highlighted
in Appendix A. Other best practices in journal cover-
age we recommend are to use only refereed journals to
build your count of science papers and to strive to attain
a 90% capture rate of those papers before considering
non-refereed publications in ADS.
5.METADATA
Once a publication is chosen for inclusion in an institu-
tion’s bibliography, the bibliographer must assign meta-
data relevant to their observatoryto that publication. In
this section, we present guidelines and considerations for
developing and applying metadata tags to publications
in an observatory bibliography.
5.1.Core Metadata Set
Below is a list of the core set of ﬁelds the OBC rec-
ommends that a new observatory considers collecting for
local analysis. An existing observatory may consider us-
ing the recommendations to backﬁll their metadata for
analysis and reporting, in order to develop a deeper un-
derstanding ofscience trends over time. This set is based
on our shared experience of metadata that we 1) have
founduseful from the startandcontinueto ﬁnd useful, 2)
wish we had collected in the past and continued collect-
ing, or 3) consider worth backﬁlling in our observatory
bibliographies. Each observatory should make its own
determination as to which of the core metadata ﬁelds
are relevant for its purposes.
Bibliographers should regularly review this set of core
metadataﬁeldsto keepup with publicationpracticesand
to identify changes in how the astronomical community
uses data produced by their observatory. Expanding or
refocusing the scope of bibliographic metadata collection
is an unavoidable step when a new category of papers
(covering, for example, new types of data products or
software produced by an observatory) is being collected
and classiﬁed.
Many of the recommended metadata ﬁelds are avail-
able in ADS, so documentation of them in an internal8
observatory bibliography may not be necessary. It is
possible to analyze and retrieve these data from ADS
without storing the metadata locally. Fields available in
ADS are marked with an asterisk*.
Identiﬁers
•ADS bibcode*
•proposal/program ID(s) or observation ID(s)
•associated principal investigators (PIs) and co-
investigators (Co-Is)
•ORCID(s) for author(s), when available*
•data product, dataset(s), or dataset(s) DOI(s); ex-
actly how the data is bundled or cited will vary
according to the data archive
•software programs used in paper analysis
Bibliographic Information
•paper title*
•publication/journal title*
•publication date*
•publication volume, issue, and pages*
•published article DOI (version of record)*
•optional: preprint DOI or identiﬁer*
Author Information
•ﬁrst author name*
•ﬁrst author aﬃliation(s)*
•ﬁrst author country/ies*
•additional author name(s)*
•additional author(s) aﬃliation(s)*
•additional author(s) country/ies*
•observatorystaﬀ publication (if tracked by your in-
stitution)
•author(s) category/ies (e.g., postdoc, visitor, stu-
dent)
Publication Type
•refereed / non-refereed* (if including both types in
bibliography)
•thesis/dissertation(often, but not alwaysin ADS)*
•paper classiﬁcation: science, non-science/mention,
data-inﬂuenced, instrument, engineering, etc.
Telescope and Instrumentation
•telescope/observatory (for bibliographies that cap-
ture more than one telescope’s data)
•instrument(s), mode(s), channel(s), etc.•ﬁlters(s) and wavelength(s)
Data Products and Services
•archival ﬂag (PI/observer vs. archival use)
•observatory data services or high-level products
used (for example, NOIRLab’s Astro Data Lab, or
the Chandra Source Catalog)
Surveys/Missions
•survey observatory or pointed / object-speciﬁc ob-
servatory
5.2.Additional Metadata for Inclusion
Each observatory has unique characteristics, needs,
and reporting requirements, which may necessitate the
inclusion of additional metadata ﬁelds. As examples, the
followingmetadataﬁeldsmaybeconsideredforinclusion:
•Page charges paid by observatory
•Data analysis funding/grant information
•Length of time to publish since data were obtained
or released
•Names of other observatorieswhose data were used
(for multi-mission papers)
6.ADS BIBGROUPS
ADS oﬀers bibliographers the option to create biblio-
graphicgroups (called bibgroups in the ADS web submis-
sionformandAPI)tocollatepublicationsthatusedtheir
observatory’sdata. Bibgroupsalsomakeiteasiertoiden-
tify multimission/multiwavelength papers that use data
frommultiple telescopesorobservatories. TheUnion, In-
tersection, and Diﬀerence functions for ADS Libraries8
can augment discovery and arrangement of new paper
sets focused on two or more observatories. Some real-life
examples include searching for papers on a particular
scientiﬁc topic, e.g., proper motions and astrometry for
stellar clusters using HST data only, Gaia data only, or
combined HST and Gaia data. A researcher planning a
newproposalfocusedonAGNs, quasars,orneutronstars
might also use the bibgroup:chandra in combination with
bibgroup:NOIRLab to understand what past researchhas
been done on their intended target(s).
For new bibgroups, ADS recommends that you create
an ADS account for your group to manage the bibliogra-
phy. While loggedinto this account, execute yoursearch.
Then proceed to add your results to a private libraryand
set it to public. These libraries can be shared with other
team members, and they will contain the canonical bib-
codes for the publications contained in them. Bibliogra-
phers can maintain multiple libraries and use powerful
tools to generate one master library from the individ-
ual libraries or provide the ADS team with all individual
libraries to be combined into one bibgroup. After you
have created the library or libraries for your bibliogra-
phy, send the URL(s) to adshelp@cfa.harvard.edu. ADS
staﬀ will formally create the bibgroup in ADS. From this
point on, you can manage your bibliography directly by
8https://ui.adsabs.harvard.edu/help/libraries/9
adding or removing items to the related library(ies), and
ADS users will have access to the most recent updates.
For the ADS libraries and bibgroups to be useful, each
observatory must maintain the contents of its own bib-
group(s) and provide ADS with the parameters of its
bibliographywhenﬁrstsettingupanewbibgroup. More-
over, maintaining one bibgroup per telescope ratherthan
per organization makes combined searches easier to ex-
ecute. Ideally, bibgroups for active observatories are
maintained through the most recently completed calen-
dar year, or the one prior, so that more complex searches
are possible.
7.REPORTS AND METRICS
Publicationlists and metrics arevaluable data that are
often included in reports to funding agencies, governing
bodies, and the astronomical community to demonstrate
the scientiﬁc output and value of the observatory. An
observatory’s annual report typically includes this infor-
mation; in some cases, partial information is included in
monthly and/or quarterly reports as well.
In addition, observatorybibliographers are often asked
to provide publication counts and lists on-demand for a
speciﬁc topic or a subset of programs, as required by
research staﬀ, funders, and other stakeholders. A recent
examplefromSTScIisaninternalassessmentofthenum-
berandtypesofpapersusingULLYSESlegacyprogram9
data, gathered by trained bibliographers as opposed to
publications loosely associated with the single keyword
ULLYSES in an ADS full-text search.
Beyond ADS bibgroups, graphical representations of
publication metrics are useful additions to observatory
websites. For example, NRAO maintains online graphs
that show refereed paper totals by instrument and year,
as well as citation totals by year for the most recent 10
years. Chandra maintains online graphs showing the to-
tal number of observational papers per year and links
the tables used to create the plots, both in total and
broken down by metrics such as quarter, category of tar-
get, grant type, etc. NOIRLab has a dynamic publica-
tions dashboard that shows publication counts for each
of their telescopes for the past 10 years which links to its
ADS public libraries for individual telescopes and data
products. The public interface of ESO’s telescope bib-
liography provides a large variety of options to export
and visualize search results. ESO librarians combine the
most frequently requested reports and publish them on
the web10. STScI provides visual representations as well
aspublic-facingnumericcountsthroughthe previouscal-
endar year for both HST and JWST.
There are risks attached to reporting on metrics, espe-
cially when trying to interpret those maintained by an-
other observatory. See section 8for a discussion on why
comparing publication numbers among observatories is
problematic. It is vital that each bibliographer makes
the Criteria for Inclusion evident so that the metrics can
be evaluated appropriately.
8.CAVEATS OF COMPARING BIBLIOGRAPHIES
8.1.Intra-observatory Comparison
9https://archive.stsci.edu/hlsp/ullyses
10https://www.eso.org/libraries/pubstatsAn intra-observatory comparison is any comparative
assessment for the period of time during which the ob-
servatoryhas been operating, for example, lookingat the
number and types of science publications using Spitzer
data before and after the start of its warm mission11.
Often, technical events can visibly modify the biblio-
graphic landscape for a period of time. As an example,
one of the Chandra instruments – the High Resolution
Camera (HRC) – stopped functioning in February 2022.
The engineering team managed to bring it back to life
in April 202312. Without this background information,
someone could interpret the reduction in number of pa-
pers using HRC data during and following the HRC hia-
tus as a decrease in the scientiﬁc utility or interest in the
detector, due to the amount of time it takes from data
collection to publication. In reality, the dip is caused
by the fact that no HRC observations were being taken
for approximately 14 months. The CXC bibliographers
are anticipating a statistically signiﬁcant increase in the
number of papers using HRC sometime in the future
(2024–2025),as a result of the larger number of HRC ob-
servations (relative to normal scheduling) that have been
taken by Chandra since resumption of HRC operations.
Without context and an understanding of observatory
operations, the dip and peak could be misinterpreted
as being real “bibliographic” phenomena when instead
these extremes often reﬂect technical issues experienced
by a facility.
Similarly, the HST saw declines in the total number
of data publications in the periods of time leading up to
andsometimesfollowingthevariousservicingmissions13.
Therewasa notable decline in 1998–1999(ServicingMis-
sion 3A) and again in 2008–2009 (Servicing Mission 4),
shownclearlyintheannualHSTPublicationStatistics14.
The number of papers that rely on data obtained using a
particular instrument(s) is closely tied to each servicing
mission and the suite of instruments installed or decom-
missioned during each mission. This in turn impacts the
typeofarchivalobservationstowhichthecommunityhas
access as instruments are placed online or taken oﬄine.
In short, observatory bibliographies are never indepen-
dent of what is happening on the ground or in space and
are closely linked to the operational status of the facility.
Tracking the use of purely or partially archival data is
another common use of intra-observatory comparisons.
Bytrackingthegradualincreaseinarchivaldatause, itis
possible to advocate for ongoing support and funding for
the dataarchivewhile the community continuestoaccess
and rely on that data to make new scientiﬁc discoveries,
often in combination with fresh guest observer data or
other observatories’ data. Having an archive seems to
doubletheamountofarticlesproducedbyanobservatory
(Scire et al. 2022 ), something that is known speciﬁcally
because of publication tracking.
8.2.Inter-observatory Comparison
It is diﬃcult to compare bibliographies between obser-
vatories, even ones that seem like they might be com-
parable. As discussed in sections 2.3(Keywords) and 4
11https://www.jpl.nasa.gov/news/nasas-spitzer-begins- warm-mission
12https://groups.google.com/a/cfa.harvard.edu/g/chand ra-announce/c/Z ggkSlEV2w
13https://science.nasa.gov/mission/hubble/observatory /missions-to-hubble/
14https://archive.stsci.edu/hst/bibliography/pubstat. html10
(Journals), the search criteria applied by each observa-
tory can also have an outsized impact on the bibliog-
raphy, making it diﬃcult to conduct true comparisons
between diﬀerent facilities. Below we identify other is-
sues the OBC members have encountered when asked
to complete inter-observatory comparisons and our col-
lected experiences trying to fairly compare observatories
when required to do so.
Some journals do not update all of their article meta-
dataorfull-text ﬁlesforuptothreemonths, whichmakes
searching for candidate papers diﬃcult until the follow-
ing quarter. Therefore, one cannot compare the yield
of articles in 2024 until April 2025 at the earliest, for
example, if a comprehensive annual bibliography is ex-
pected. It is important to ask: “Is the information I
have, especially from outside my observatory, up-to-date
for the investigation I have in mind?”. While it is pos-
sible to search and limit to a speciﬁc observatory’s bib-
liography using the ADS bibgroups, and then limit by
refereed/non-refereed status as needed, generating equi-
table comparisons can prove problematic. All too often
well-meaning staﬀ use partial or incomplete data made
availablethrough an ADS bibgroup orpublic-facing page
for a diﬀerent institution and falsely assume it is “cur-
rent”throughtheyearormonthforwhichtheassessment
is being done. This has resulted in uninformed, inaccu-
rate, and misleading comparisons across institutions and
observatories. Due to staﬃng and the manual nature of
bibliographic work at present, many bibliographies run
six months to multiple years behind in assessment.
For this reason, the OBC recommends contacting the
bibliography staﬀ at peer institutions whenever stake-
holders or funders request an inter-observatory compari-
son. By understanding the limitations of your own pub-
lications database and those of peer institutions, you can
more clearly state the caveats attached to the compar-
ative metrics you provide and do your best to show a
like-for-like comparison.
In its overviewofbasic publication statistics, ESOpro-
vides a number of prepared statistics and graphs about
their facilities’ science papers. One of them (“ESO
and Other Observatories”) puts ESO’s research output
in context by showing publication numbers from other
observatories. However, ESO explicitly points to the
caveats arising from such a comparison. Comparing the
numbers of publications is the most simplistic way of
comparing facilities, and it favors large institutions with
many telescopes and instruments over smaller ones. A
more meaningful investigation would normalizethe num-
bers in some way, e.g., by number of observing hours, by
actualshareofdatausedin thepapers(sincemanyscien-
tiﬁcarticlesusedatafrommorethanoneobservatory),or
by budget. The “ESO and Other Observatories” section
also states that when comparing publication statistics
among diﬀerent observatories, it is essential to assess the
selection criteria applied by each observatory and that
comparison data and graphs have to be used with ut-
most care.
An example of when cross-observatory metrics can be
useful, even in broad stroke comparisons, is with regards
to larger societal or economic trends. In 2020 and 2022,
the Basic Publication Statistics maintained in ESO’s tel-
bib database showed a marked decline in both 2020 and
2022 across multiple observatories, which correlates withthe initial shutdown of facilities in early 2020 and the
transition back to on-site operations through 2022 dur-
ing the COVID-19 pandemic. While such metrics can
rarely demonstrate causation, they do give stakeholders
pause when trying to understand observatory operations
in the wider context beyond the astrophysicscommunity.
8.2.1.Survey vs. pointed missions
When proposing surveys that require many hours of
observations, astronomers need to make a strong case
that the survey data will be useful enough to warrant
the allocation. This tends to result in programs that a
broader range of astronomers support and use and data
that are used for other purposes long past when they
were taken.
For example, for Spitzer, the Legacy programs were
large, coherent investigations proposed prior to launch
and carried out early in the mission. The teams were
funded prior to launch speciﬁcally to enable both rapid
data reduction and delivery of high-level data products
back to IRSA15. The surveys that were done in the ﬁrst
2.5 years of the mission produced a much higher “papers
perhourofdata”rate(0.37)thanthenon-surveyGeneral
Observerobservations(0.17)takenatthesametime–see
ﬁg. 9 in Scire et al. (2022). As time passes, the survey
programsfromthatobservatorycontinuetoprovidemost
ofthe papersasobservationsfrom thosesurveyprograms
are republished ( Scire et al. 2022 , ﬁg. 6a and 10). The
Legacyprogramswererecognizedto be sosuccessful that
the community continued to propose large investigations
that promised deliveries back to IRSA. These ready-to-
use data products continue to generate substantial use of
Spitzer data and citations.
All-sky surveys such as Gaia, 2MASS, or (NEO)WISE
can be used for nearly any investigation, provided the
targets are bright enough. Observatories that are pri-
marily focused on pointed observations (such as Chan-
dra, Hubble, Spitzer, or JWST) will not necessarily have
data at any given location on the sky. By their very na-
ture, then, all-sky surveys have the potential to generate
more publications and citations than pointed observato-
ries.
8.2.2.Large collaboration papers vs. small research groups
Missions that started with large international collabo-
rations will often result in more papers referencing origi-
nal collaborative publications and may accrue more cita-
tions compared to observatories that traditionally have
smaller teams observing and using data.
Similarly, Guaranteed Time Observations (GTO) pro-
grams often result in proportionally more papers, since
the teams of researchers are funded over a longer time
span, often lasting for two or more years/cycles. The in-
ﬂuence of accumulated volumes of data on observatory
bibliographies is discussed further in Blecksmith et al.
(2005) for Chandra and shown in ﬁg. 9 of Scire et al.
(2022) with regards to Spitzer.
8.2.3.Science topics and community size
Observations focused on topics that are less widely
studied or have smaller research communities, such
15https://irsa.ipac.caltech.edu11
as masers, or specialized methods or topics, like IR
spectroscopy of Galilean satellites, will inherently have
smaller bibliographic counts. Observations of targets
that are more popular in the public sphere or have been
observedfor a longerperiod of time, e.g., M31, can result
in a greater number of publications and more citations.
Searching for the object M31 in the HST bibgroup using
ADS yields over 1,800 results, accounting for more than
12% of the entire HST bibliography to date.
Even just within the Spitzer archive, which should be
similar in terms of people interested in the wavelength
regime and consequent astrophysics, the spectra from
IRS have a lower publication per hour rate than the
two imaging instruments, IRAC and MIPS ( Scire et al.
2022). Some of that likely arises from the fact that an
imagecanserendipitouslycaptureobjectswhereasallthe
spectroscopy must be deliberately pointed, but it is also
likely that more specialized knowledge is required to an-
alyze the spectroscopy, and therefore intrinsically fewer
people attempt it.
Spitzer also provides a ready-made lesson on the
change in publication rate per observing hour when it
comes to the nature of the observations. Early in the
mission, many of the large time allocations were given
to projects covering relatively large areas of sky. Those
projects’datacontinuetoaccumulatemyriadcitationsas
scientistsusedatafromthosesurveysinconjunctionwith
more recent observations. Later in the mission, after the
cryogen was exhausted and only the shortest two chan-
nels of IRAC were still working, a much higher fraction
of the observing time was devoted to projects that were
monitoring targets for time variability – that is, staring
at one place on the sky. Once a paper is written pre-
senting the light curve (brightness as a function of time),
future investigators cite that paper, rather than reusing
the original data. This results in far lower publications
per hour of observing time, given the strict deﬁnition
for science papers; see further discussion in Scire et al.
(2022).
9.TECHNOLOGY CONSIDERATIONS & STANDARD
TOOLS
An automated tool for searching journals or text min-
ing can substantially reduce the number of staﬀ hours
required to review a list of journals for candidate papers.
Questions to ask about opportunities to apply technolo-
gies at your institution should include the following:
•What expertiseisavailabletocodeandcuratetools
to ensurethey remaineﬀective forpaperdiscovery?
•Is it better to a) search journal tables of contents,
b) search within full-text papers using the ADS
GUI, or c) use an API such as those from ADS or
Crossref to search journals’ full-text content? In
the event a publication falls outside of the ADS’
current holdings and there is a strong incentive for
inclusion on behalf of the astrophysics community,
the bibliographer should reach out to the ADS to
request it be included.
•Are all the necessary publisher licenses in place to
allow access to papers in full for text-mining and
detailed evaluation, whether using ADS, Crossref,
publisher web forms, or APIs?•How should my entry point(s) for full-text search-
ing inform the design of my automation and tools,
including the program or database in which I track
veriﬁed science papers?
•How will I retain a list of papers I consciously ig-
nored or keep track of which journals and volumes
I have already evaluated?
Beyond the search tools and search methodology, you
will need to ask yourself the following:
•What additional metadata, beyond what is avail-
able in ADS, does my observatorywish to maintain
alongside each publication record?
•Do I need to include publications that fall outside
ADS, and if so, how will I ingest metadata from
thosepublications,andisthemetadatacomparable
to what is found in the bulk of the literature in
ADS?
•How will paper categorization aﬀect design? For
example, if tracking non-science papers in addition
to pure science papers, should those non-science
papers be split between historical references and
forward-facing simulations?
•How often will my stakeholders want reports on
publication metrics and how might that inﬂuence
design and processes? Which metadata ﬁelds and
values will be necessary to track to satisfy report-
ing needs? See section 5, Metadata, for further
discussion.
•Am I (or the appropriate software development
team) expected to build a public-facing component
speciﬁc to my observatory in addition to an ADS
library or bibgroup? If so, how will it be updated
from the internal bibliography tool(s)?
•Am I (or the appropriate software development
team) prepared to maintain the database and con-
tinually develop it in response to outside systems
such as ADS and Crossref?
•Am I (or the appropriate software development
team) prepared to maintain ongoing documenta-
tion and versioningof the observatorybibliography
software?
9.1.Standard Tools: Low to High Investment
Although many commercial products exist for manag-
ing bibliographies, no known oﬀ-the-shelf software exists
for building or maintaining an observatory bibliography,
and adoptinganother institution’s applicationfrequently
requires a great deal of modiﬁcation and technical ex-
pertise to ﬁt your observatory’s needs. To manage a
sustainable bibliography, the bibliographer (or your in-
stitution)mayneedtocreatein-housetoolstogetthejob
done. Here we present multiple options, from basic, low-
investment spreadsheets and ADS libraries to complex
databases integrated with an institution’s data archive.
Some observatoriesmay ﬁnd they need to rely on a ba-
sic approach because of restrictions on resources and IT
support. Varying levels of IT support, limited access to12
software developers within your organization, time, and
the bibliographer’s skills and training may all impact de-
sign decisions when creating a new bibliography. It is
important to bear in mind that without dedicated and
ongoing support, observatories cannot easily add com-
plexity, adjust their metadata model and paper catego-
rization, or make signiﬁcant changes to the software un-
derpinning the database.
A perfectly usable, low-investment option is a basic
MS Excel workbook or spreadsheets, tracking the ADS
bibcodes or other unique identiﬁer of papers that qualify
as science and non-science papers (if also tracked) that
are associated with your observatory. A related ADS
library and bibgroup can be established and updated in
tandem or at regularintervals. This is the approachused
by NOIRLab and is how most observatorybibliographies
begin. In addition, NOIRLab built a web interface for
bibliography metrics, which pulls directly from ADS.
The DKIST Observatorybibliographyat NSO is main-
tained in an MS Access database. Other observatories,
such NRAO, use a slightly more complex, homegrown
multi-table database. NRAO uses a browser-based mid-
dleware application to interface with the data stored in
a MySQL database, which reduces the need for library
staﬀ to have expertise in SQL and performs simulta-
neous transactions more eﬃciently than running multi-
table queries. MySQL is used most often for queries to
gather metrics requested by staﬀ. NRAO also operates a
faceted search tool running on Blacklight and Solr that
the public can use to search for papers in the bibliogra-
phy. Two dynamic graphs produced by a separate API
show paper totals and historic citation totals.
Spitzer made an upfront investment in its bibliography
early in the mission’s lifetime. Until it was decommis-
sioned in 2020 and the data transferred to IRSA, Spitzer
used a MySQL database with Shell and Perl scripts to
interact with the database and three tables for pend-
ing, valid, and rejected papers. For more information
seeScire et al. (2010). The Spitzer database did not in-
clude an internal general user interface (GUI) like some
other observatory bibliography databases, but did allow
the bibliographer to associate program IDs with papers.
Tables were used to populate the Spitzer Biographical
Database web search interface which was public facing.
Other observatories have invested more time or soft-
ware development resources in recent years and manage
observatory bibliography software that is highly com-
plex, with multiple relationships and dependencies be-
tween ADS and their institution’s data archive. Exam-
ples of more complex bibliography tools can be found
at the Chandra X-ray Center, ESO, and STScI, all of
which oﬀer a UI for bibliographers who are not adept at
software engineering in their day-to-day work. All three
link the associated data from their respective archives to
publication records in ADS.
ESO’s telescope bibliography (telbib) started in 1995.
Its predecessor was a simple list of observatory papers
compiled for the Annual Report. Since then, telbib has
evolved into a sophisticated system with many features
and facets. For the current system, ESO has developed a
web application called FUSE (a fulltext search tool using
PHP/MySQL) that queries ADS via their API in order
to identify relevant papers. The telbib software is man-
aged through another web interface (PHP/Sybase). Itallows rich tagging with metadata, a large variety of ex-
port options, and reports in various formats. In addition
to these internal applications, there is a public interface
(PHP/Solr) that allows searching, exporting, and visu-
alizing data via a web interface or an API.
The Chandra bibliography is managed through a
graphical user interface written in Perl and SQL and
is accessible through a web interface. Due to the level
of customization, especially for managing metadata and
connections between CXC systems, it may be diﬃcult to
revise the bibliography software for other missions in fu-
ture. In hindsight, the CXC bibliographer team stated
it would have designed a database with less technical
complexity so it is more adaptable for other Center for
Astrophysics (CfA) needs.
The STScI and MAST bibliographies are managed
through a front-end graphical user interface used daily
by archive scientists and bibliographers, with underly-
ing code rendered in Python and SQL. The local tool
is called PaperTrack, and it was rebuilt in 2018-2019 to
take full advantage of the ADS API released alongside
the ADS 2.0 platform.
PaperTrack is used for three main purposes. Paper-
Track stores bibliographic information about publica-
tions found in ADS that use mission data (Science),
are related to mission engineering or instruments (Engi-
neering/Instrument), or reference MAST missions/data
already published (Mention/Supermention/Data-
Inﬂuenced). Secondarily, the tool provides institutional
benchmarking numbers to STScI; its mission oﬃces;
NASA; its parent organization, AURA; and external
bodies. Annual counts of refereed science publications
are reported as one measure of scientiﬁc output. Lastly,
STScI commits to an annual update for its mission
metrics in late spring of each year in order to provide
other observatories and science centers a record of
publications that use or reference MAST mission data
for their own benchmarking measures. This last use
is discussed in more detail in sections 7, Reports &
Metrics, and 8, Caveats of Comparing Bibliographies.
To identify papers, STScI relies on the ADS API to
look for relevant keywords in the full-text ﬁles housed
in ADS. Not every publisher deposits its full-text ﬁles
at a regular cadence with ADS, which limits the utility
of the ADS API, through no fault of the ADS team.
Candidate papers are manually assessed to determine
if they only mention one of its three ﬂagship missions
in passing, or clearly used data to reach a new sci-
entiﬁc conclusion. The HST, JWST, and the Nancy
Grace Roman Space Telescope (RST; NGRST) com-
prise the ﬂagship mission searches. The same assess-
ment occurs for over 15 MAST missions including TESS,
GALEX, Kepler, IUE, and many others. Searching
the literature for candidate papers using MAST mis-
sions’ data is managed by the MAST archive scien-
tists. MAST oﬀers a public facing, external database,
but for reasons expressed in section 8, Caveats of Com-
paring Bibliographies, it is always advisable to contact
the STScI bibliographers for assistance gathering the
metrics you need. The database can be accessed at
https://archive.stsci.edu/publishing/bibliography#/ . It
allows external users to view information about mission
publications for previous years, ﬁnd papers using their
HST or JWST program data, and gather basic publica-13
tion metrics information.
When designing bibliography software or choosing to
implementalow-techoption,considertowhatdegreeyou
are willing to rely on other technology. Scraping full-text
html, for example, even if permitted by the publisher,
will require intervention each time a publisher’s journal
platform changes. If the ADS API undergoes a major
re-haul, it may break existing scripts that allow you to
searchfull-textﬁlesandingestcandidatepapermetadata
into your database. Consider reducing unnecessary de-
pendencies on other systems whenever possible to ensure
long-term maintenance. It is critical that those involved
in building new bibliography software or enhancing ex-
isting software communicate proactively with the groups
who manage related systems, such as your institution’s
data archive, ADS, and publishers.
10.STAFFING
An observatory bibliographer works with a diverse
groupoftechnical, scientiﬁc, andnon-technicalpersonnel
bothwithintheobservatoryandatoutsideresearchinsti-
tutions, funding agencies, publishers, and observatories.
Strongcommunicationskills,aknowledgeofthescientiﬁc
literature, and proﬁciency in database searching are all
important competencies for observatory bibliographers.
Many bibliographers are either the sole staﬀ or part of a
small team performing these tasks, so a commitment to
professional networking is a valuable asset.
One of the advantages of having dedicated staﬀ is con-
tinuity and a homogeneity for classiﬁcation and applied
metadata across large sets of papers. While researchers
and archive scientists may comprise the entire classiﬁ-
cation team, or be a key part of it, they may not be
immediately comfortable with or skilled in classiﬁcation.
The task of classifying papers for mission bibliographies
requires signiﬁcant training and specialization that can-
not be improvised. Archive scientists and research staﬀ
may understand which datasets and observations were
used in papers, but the way a scientist reads and un-
derstands a paper is diﬀerent from what is required of a
classiﬁer, though the same individual may serve in both
roles with adequate training. Documentation outlining
the various paper categories, metadata ﬁelds captured in
the bibliography, and the process for evaluating a paper
from a bibliographic standpoint are imperative.
An observatory bibliographer’s roles and responsibili-
ties typically include the following:
•Searching the literature to identify papers that use
data from an observatory’s telescope(s) or that
were published by observatory staﬀ
•Reviewing the literature for inclusion in the obser-
vatory bibliography, according to the observatory’s
criteria
•Tagging relevant publications with the appropriate
metadata in the database(s)
•Investigatingandsolvingproblemsrelatedtometa-
data, linked archival data, and ADS index records
•Updating and improving data citation and meta-
data standards on a continual basis•Educating users on how to use and interpret bibli-
ography tools and reports
•Explaining the publication tracking process to bib-
liography stakeholders and observatory staﬀ
•Interpreting publication metrics and preparing re-
portsthat presentnumeric andvisualdataforboth
recurring and ad hoc needs
11.FUTURE TRENDS & TECHNOLOGIES
Eﬀorts are underway to implement an automated pa-
per classiﬁcation system at STScI/MAST to identify sci-
ence papers within a set of candidate papers; however,
even if this product comes to fruition in the 2020s, it
is expected that human intervention will be needed to
extract additional information about each paper to com-
plete certain metadata ﬁelds such as program ID(s), in-
strument, and observing mode (for JWST). Additional
workto understand howthis system will handle false hits
on papers that contain keywords or phrases of interest,
but have nothing to do with MAST or ﬂagship missions,
is underway. A summary of the pilot, its accuracy and
completeness, and remaining challenges is expected to
be released in 2024 (Pegues et al., in progress). The ﬁrst
alpha release for the automated classiﬁer is anticipated
in 2025. It is expected that only a portion of the papers
can be conﬁdently tagged as science papers. A sizable
portion may still require human review to accurately as-
sign a paper classiﬁcation such as science, mention, engi-
neering, etc. Moreover, not all publishers are willing to
provide access to entire full-text ﬁles, even for nonproﬁt,
internal, non-generative purposes; the automation tool
might only be possible for use with content from certain
publishers until licensing agreements can be reached to
allow for use of additional content in machine learning
(ML) tools. Licensing restrictions generally apply to full
text obtained via the publisher’s online platform in html
or pdf form, as well as the full-text JSON ﬁles available
through Crossref.
Similar eﬀorts are also taking place at other observato-
ries. Forinstance,anMLapproachtoidentifydatainsci-
entiﬁc papers for inclusion into NED (the NASA/IPAC
Extragalactic Database) has recently been described by
Chen et al. (2022a). Similar to STScI and MAST’s ex-
perience, staﬀ at NED expect that their ML tool will
provide a partial solution but are still seeing a return on
investment: “This ML application on both subject and
content classiﬁcations has been in operations since Jan-
uary 2021, and has gained the team about 0.4 FTE, i.e.,
the equivalent of 4 person-years of labor over a decade of
NED operations”. At ESO, an AI interest group is using
the observatorybibliographyasan example tostudy how
algorithms can enhance the process of properly classify-
ing research articles.
While all of these eﬀorts hold promise for more ef-
ﬁcient, complete, and timely paper classiﬁcation and
metadata extraction, it will be essential to keep a bal-
anced view of the role of new and emerging technolo-
gies in observatory bibliographies vis-a-vis human con-
trol. Per Chen et al. (2022a): “It is worth noting that
this ML approachdoes not completely removehuman in-
volvement in the process. Human expertise and learning
are needed for marginal cases that are not resolved by14
existing capabilities. Further, the trained model is ap-
plied to a domain-shifted dataset for predictions. Newly-
emerged data content, variations in formats and rep-
resentations can all contribute to deteriorating perfor-
mance over time. Hence, there needs to be a continuing
education program for retraining and updating the clas-
siﬁer models with new literature, which will require new
labels identiﬁed by human experts periodically”.
12.LESSONS LEARNED
Over the course of our discussions, we have formulated
some lessons learnedand guidelines to help others under-
stand the work that goes into observatory bibliographies
and their purpose. We also anticipate this article will
help those starting new bibliographies, as well as those
interested in revising current ones. Bibliographies pro-
vide value to their institutions, individual researchers,
and data archives, as well as oversight committees and
funding agencies.
•To Institutions , they demonstrate scientiﬁc out-
put, provide data on telescope/instrument/archive
use, and act as templates for either new or revised
observatory bibliographies.
•To Researchers , they show their research teams’
impact and reach, aid in understanding how their
work ﬁts within the astronomical community, help
identify areas of interest and potential collabora-
tions for ongoing work, lead to suggestions for
new facilities and missions, and support current
projects and upcoming proposals. Researchers
use observatory bibliographies to enable mission
and/or data archive-oriented searching in ADS by
combining the ﬁelds for bibgroup,data, and/or ob-
ject. The search results may reveal research on an
object or class of objects previously observed with
one or more facilities or wavelengths. For example,
a researcher can conduct the search object:hd22879
data:eso toﬁndandthenassessearlierobservations
when writing a new proposal to ensure limited du-
plication and to better inform their proposal aims.
Another real-life example of how researchers have
used curated mission bibliographies is when updat-
ing a core exoplanet textbook. A search across the
whole of the JWST bibgroup helped the authors
identify and classify exoplanet research enabled by
the observatory to date.
•To Archives , they demonstrate connections be-
tween publications and data usage over time, es-
pecially for archival data use. Many bibliographies
enrich the ADS records with links to datasets or
DOIs, making it easier for the community to lo-
cate data used in papers which leads to reuse, val-
idation of research ﬁndings, proper citation of ex-
isting data(sets), and new discoveries. Regardless
of the tool your institution develops, the OBC ad-
vises new bibliographers to manage the ﬂow of new
candidate papers and the steps involved in paper
assessment on a rolling basis. Doing so will ensure
connections between your bibliography software,
ADS, your institution’s data archive, and public
systems are functioning as expected at regular in-
tervals.•To Oversight Committees and Funding
Agencies , they demonstrate utility and level of
use of facilities, observatories, and archives by the
astronomical community; show return on invest-
ments; inform support priorities; illustrate how ob-
servatories are advancing science; and guide deci-
sions for future facilities and archivesdevelopment,
especially through reports to Visiting Committees,
User Groups, and Decadal Survey eﬀorts.
Some common insights and shared considerations
across observatory bibliographies are as follows:
•ADS:ADS (soon to be SciX) is an important tool
for searching the scientiﬁc literature, deriving met-
rics, and maintaining public bibliographies.
•Criteria for Inclusion: Each institution should
document their Criteria for Inclusion and make
these publicly availableto guide bibliographicwork
and inform users of the bibliography and its pa-
rameters. Institutions and bibliographers need to
evaluate and revise their bibliographic policies and
procedures regularly to account for changes in ar-
eas such as reportingrequirements, missions, goals,
keywords, and technology. There is tremendous di-
versity among bibliographies related to the unique
characteristics, goals, and subject area focus of
each observatory. The criteria should clearly ex-
plain the observatory’s preferences and rationale
for what is captured in their bibliography.
•Science Publications: Most bibliographies focus
on refereed “science” papers. A “science” paper is
one where 1) data or data product(s) from the ob-
servatory were used, and 2) the data or data prod-
uct(s) formed the basis for reachinga new scientiﬁc
conclusion. It does not matter if the observations
have been published before, so long as the way the
resultsarepresentedconstitutenewanalysisoruse.
•Journal Coverage: Thereisacoresubsetofjour-
nalsthatmostobservatoriessearchtocompiletheir
bibliographies. Diﬀerences in journals searched be-
yond this subset relate to the unique characteris-
tics, capabilities, and science goals of the observa-
tory.
•Metadata: Bibliographers need to regularly as-
sess their metadata tags as these will change over
time as science evolves and the institution trans-
forms. Having a bibliography from the start will
allow the observatory to identify which papers it
may need to reclassify or augment through a more
robustclassiﬁcationschemeinthe future. Observa-
tories should consider which data points to collect
from science publications from ﬁrst light/launch
onwards to demonstrate to funding agencies that
the observatory is making a diﬀerence in the re-
search ﬁeld(s) and enabling new ﬁndings.
•Comparing Bibliographies: Direct comparison
of the number of science papers between observato-
ries and even comparisons within a single observa-
tory maynot be the most eﬀective orequitable way
toanalyzeproductivity. Wedonotadviseassessing15
total publication output over time between facili-
ties or even within a single observatory as the pri-
mary measure of science productivity. If such com-
parisons are required to satisfy oversight commit-
tees or funding agencies, observatory bibliography
metrics should be provided with proper context.
Caveats or limitations of the data and inherent dif-
ferences in the datasets being compared should be
provided along with the metrics report(s).
•Technology: There are exciting technological ad-
vances in this ﬁeld, including the use of machine
learning to classify papers. However, it is impor-
tant to emphasize that automation is never a sub-
stitute for human evaluation. Automated classiﬁ-
cation will need to be periodically inspected and
validated by staﬀ, and language models will need
to be revised over time and then re-validated.
•Reports and Metrics: Bibliographies are regu-
larly included in reports to funding agencies and
to observatory leadership. It is vital that there is
clear documentation about how the bibliographies
were compiled and what the metrics may or may
not show.
•Staﬃng: Manybibliographersworksolooraspart
of a small staﬀ. Sharing of information, policies,
and procedures through networking among bibli-
ographers is vital to maintain the high standards,
usability, and credibility of observatory bibliogra-
phies.
•New and Revised Bibliographies: If a bibli-
ography is not initiated at ﬁrst light, it is diﬃcult
to begin one after years of observations without
investing signiﬁcant time to catch up. The exam-
ples of current observatory bibliographies shared
throughout this paper and our guidelines and ex-periences can act as templates when devising or
revising bibliographies.
13.DISCUSSION
Observatory bibliographers play a vital role in demon-
strating the scientiﬁc impact and value of an observa-
tory. Our work is aligned with the goals and mission
of our respective institutions, and consequently there is
tremendous diversity in the ways we track publications
and maintain publications databases. Our diﬀerences
are driven by parameters such as observatory resources
(personnel, time, money, IT capabilities), type of obser-
vatory, historical practices at an observatory, technical
changes and evolution, and reporting requirements to
outside agencies. Despite this diversity, there is a com-
mon set of best practices that guide our work. In this
article, we providedexamples andguidelines toconstruct
and maintain robust and valuable observatory bibliogra-
phies. We also emphasized the importance of document-
ing, evaluating, continuallyreﬁning, and sharingour bib-
liographypractices with other bibliographersand the en-
tire astronomical community. Changes implemented in
external and internal systems, such as ADS and SciX
or one’s own data archive, may necessitate changes in
observatory bibliography systems. As a result, bibliog-
raphers should expect to revise their metadata schema,
processes, and other aspects of bibliographic work on a
continual basis for the life of the bibliography.
ACKNOWLEDGMENTS
This research has made use of the Astrophysics Data
System, funded by NASA under Cooperative Agree-
ment 80NSSC21M00561. Raﬀaele D’Abrusco acknowl-
edges support from the Chandra X-ray Center, which is
operated by the Smithsonian Institution under NASA
contract NAS8-03060. In addition to the ADS team,
the authors wish to thank the anonymous reviewers for
their helpful comments, insightful questions, and recom-
mended edits.
REFERENCES
Blecksmith, S., Bright, J., Rots, A. H., et al. 2005, in
Astronomical Society of the Paciﬁc Conference Series, Vol. 347,
Astronomical Data Analysis Software and Systems XIV, ed.
P. Shopbell, M. Britton, & R. Ebert, 380.
http://aspbooks.org/custom/publications/paper/347-0 380.html
Chen, T. X., Ebert, R., Mazzarella, J. M., et al. 2022a, PASP,
134, 014501, doi: 10.1088/1538-3873/ac3c36
Chen, T. X., Schmitz, M., Mazzarella, J. M., et al. 2022b, ApJ S,
260, 5, doi: 10.3847/1538-4365/ac6268
Chyla, R., Accomazzi, A., Holachek, A., et al. 2015, in
Astronomical Society of the Paciﬁc Conference Series, Vol. 495,
Astronomical Data Analysis Software an Systems XXIV
(ADASS XXIV), ed. A. R. Taylor & E. Rosolowsky, 401,
doi:10.48550/arXiv.1503.05881
Cutri, R. M., Skrutskie, M. F., van Dyk, S., et al. 2003, 2MASS
All Sky Catalog of Point Sources. (NASA/IPAC Infrared
Science Archive).
https://irsa.ipac.caltech.edu/Missions/2mass.html
Eichhorn, G. 2004, A&G, 45, 3.07,
doi:10.1046/j.1468-4004.2003.45307.x
Grothkopf, U., Meakins, S., & Bordelon, D. 2018, in Society o f
Photo-Optical Instrumentation Engineers (SPIE) Conferen ce
Series, Vol. 10704, Observatory Operations: Strategies,
Processes, and Systems VII, ed. A. B. Peck, A. L. Seaman, &
C. R. Benn, 107040R, doi: 10.1117/12.2311667
Henneken, E., & Kurtz, M. J. 2019, in American Astronomical
Society Meeting Abstracts, Vol. 233, American Astronomica l
Society Meeting Abstracts #233, 453.01.
https://baas.aas.org/abstractsLagerstrom, J. 2015, in Astronomical Society of the Paciﬁc
Conference Series, Vol. 492, Open Science at the Frontiers o f
Librarianship, ed. A. Holl, S. Lesteven, D. Dietrich, &
A. Gasperini, 99.
http://aspbooks.org/custom/publications/paper/492-0 099.html
Rots, A. H., Winkelman, S. L., & Becker, G. E. 2012, PASP, 124,
391, doi: 10.1086/665581
Scire, E., Chan, B. H. P., Silbermann, N., & Shields, A. 2010, in
Society of Photo-Optical Instrumentation Engineers (SPIE )
Conference Series, Vol. 7737, Observatory Operations:
Strategies, Processes, and Systems III, ed. D. R. Silva, A. B .
Peck, & B. T. Soifer, 77371V, doi: 10.1117/12.857735
Scire, E., Rebull, L., & Laine, S. 2022, PASP, 134, 055001,
doi:10.1088/1538-3873/ac4959
Skrutskie, M. F., Cutri, R. M., Stiening, R., et al. 2006, AJ, 131,
1163, doi: 10.1086/498708
van Raan, A. 2019, Measuring Science: Basic Principles and
Application of Advanced Bibliometrics, Springer Handbook s
(Cham, Switzerland: Springer), 237–280,
doi:10.1007/978-3-030-02511-316
APPENDIX
APPENDIX A: MOST COMMONLY REPRESENTED JOURNALS FOR ASTRONOMY BIBLIOGR APHIES
HST(1991–2021) ESO(1996–present) NRAO(1957–present) Spitzer(2003–2020) Mid and far IR NSF NOIRLab
ApJ 43% A&A 46% ApJ 42.13% ApJ 43.4% MNRAS 35%
MNRAS 19% MNRAS 23% MNRAS 17.68% MNRAS 19.5% ApJ 26%
A&A 14% ApJ 16% A&A 17.67% A&A 19.0% AJ 14%
AJ 10% ApJL 5% AJ 8.62% AJ 6.4% A&A 10%
ApJS 2% AJ 4% ApJS 2.65% ApJS 4.1% ApJL 4%
Icar 2% A&ASuppl 1% Nature 1.6% PASJ 1.1% ApJS 4%
PASP 1% ApJS 1% PASJ 0.94% PASP 0.8% PhRvD 1%
Nature 1% Nature 1% Science 0.68% Nature and NatAs 1.1% PSJ 1%
Icar 1% Icar 0.6%
AN 1% AN, Ap&SS, Science 0.2% each
The share of Spitzer papers published in the ApJ dropped from 56.1% in 2009 to 32.2% in 2020, while the share
published in MNRAS rose from 10.4% to 28.0%. This was due to changes in the funding proﬁles for observers granted
time on the observatory. See Scire et al. (2022) for more information.
APPENDIX B: FURTHER READING ON OBSERVATORY BIBLIOGRAPHIES
1.Abt, H. A. 2005, Information Obtainable from Bibliometric Studies, c oas.conf, 2, 2005coas.conf....2A
2.Accomazzi, A., Eichhorn, G. 2004, Publishing Links to Astronomical D ata On-line, ASPC, 314, 181,
2004ASPC..314..181A
3.Accomazzi, A., et al. 2012, Telescope Bibliographies: An Essential Co mponent of Archival Data Management
and Operations, SPIE, 8448, 84480K, 2012SPIE.8448E..0KA
4.Alonso-Valdivielso, M. ´A., Antonio, E. G. 2010, Why Include Bibliometric Analysis in the Activitie s of a Library
Specialized in Astronomy? — Notes From the Libraries of INTA, ASPC, 433, 95,2010ASPC..433...95A
5.Bordelon, D., et al. 2016, Trends and Developments in VLT Data Pape rs as Seen Through telbib, SPIE, 9910,
99102B, 2016SPIE.9910E..2BB
6.Cortes, R., Depoortere, D., Malaver, L.2018, Astronomyin Chile: A ssessmentofScientiﬁc ProductivityThrough
a Bibliometric Analysis, EPJWC, 186, 05002, 2018EPJWC.18605002C
7.Crabtree, D. 2019, Canada’s Astronomy Performance Based on B ibliometrics, clrp, 2020, 14, 2019clrp.2020...14C
8.Erdmann, C., Grothkopf, U. 2010, Next Generation Bibliometrics an d the Evolution of the ESO Telescope
Bibliography, ASPC, 433, 81, 2010ASPC..433...81E
9.Grothkopf, U., Meakins, S. 2012, ESO Telescope Bibliography: New P ublic Interface, Msngr, 147, 41,
2012Msngr.147...41G
10.Grothkopf,U., Meakins,S.2015,ESOtelbib: LinkingInandReaching Out, ASPC,492,63, 2015ASPC..492...63G
11.Grothkopf, U., et al. 2004,The ESOTelescopeBibliographyonthe We b: LinkingPublicationsandObservations,
AAS, 205, 182.06, 2004AAS...20518206G
12.Grothkopf, U. 2011, Astronomy Libraries - Your Gateway to Info rmation, EAS, 49, 107, 2011EAS....49..107G
13.Grothkopf, U., Meakins, S. 2012, The ESO Telescope bibliography at Your Fingertips, SPIE, 8448, 844821,
2012SPIE.8448E..21G
14.Grothkopf, U., Novacescu, J. 2022,The Role of AstronomyLibrar iansin FAIR BibliographyCuration and Metric
Analyses, astr.conf, 3, 2022astr.confE...3G
15.Grothkopf, U., Meakins, S., Bordelon, D. 2015, If We Build It, Will The y Come? Curation and Use of the ESO
Telescope Bibliography, scop.conf, 1, 2015scop.confE..26G
16.Grothkopf, U., Lagerstrom, J. 2011, Telescope Bibliometrics 101, ASSP, 1, 109, 2011ASSP...24..109G
17.Grothkopf, U., Meakins, S., Bordelon, D. 2018, Use Cases of the ES O Telescope Bibliography, EPJWC, 186,
06001,2018EPJWC.18606001G17
18.Henneken, E. A., Kurtz, M. J. 2019, Usage Bibliometrics as a Tool to Measure Research Activity, hsti.book, 819,
2019hsti.book..819H
19.Hourcl´ e, J. 2014, Data Citation in Astronomy, lisa.conf, 21, 2014lisa.confP..21H
20.Kitt, S., Grothkopf, U. 2010, Telescope Bibliography Cookbook: Cr eating a Database of Scientiﬁc Papers That
Use Observational Data, ASPC, 433, 109, 2010ASPC..433..109K
21.Lagerstrom, J., et al. 2012, Observatory Bibliographies: Current Practices, SPIE, 8448, 84481X,
2012SPIE.8448E..1XL
22.Madrid, J. P., Macchetto, F. D. 2007, A Method to Measure the Scie ntiﬁc Output of the Hubble Space Telescope,
ASPC, 377, 79, 2007ASPC..377...79M
23.Meakins, S., Grothkopf, U. 2012, Linking Publications and Observat ions: The ESO Telescope Bibliography,
ASPC, 461, 767, 2012ASPC..461..767M
24.Meakins, S., et al. 2014, Two Uears of ALMA bibliography: Lessons Le arned, SPIE, 9149, 914926,
2014SPIE.9149E..26M
25.National Research Council. 2012. For Attribution: Developing Data Attribution and Citation Practices
and Standards: Summary of an International Workshop. Washing ton, DC: The National Academies Press
DOI:10.17226/13564
26.Perret, E., et al. 2018,Shared Nomenclatureand Identiﬁers forT elescopesand Instruments, EPJWC,186, 04002,
2018EPJWC.18604002P
27.Rots, A. H., Winkelman, S. L., Becker, G. E. 2012, Meaningful Metric s for Observatory Publication Statistics,
SPIE, 8448, 84480J, 2012SPIE.8448E..0JR
28.Savaglio, S., Grothkopf, U. 2014, Swift Publication Statistics and th e Comparison with Other Major Observato-
ries, lisa.conf, 4, 2014lisa.confP...4S
29.Schmitz, M., et al. 1995, A Uniform Bibliographic Code, VA, 39, 272, 1995VA.....39R.272S
30.Sterzik, M., et al. 2016, The Impact of Science Operations on Scienc e Return at the Very Large Telescope, SPIE,
9910, 991003, 2016SPIE.9910E..03S
31.Stevens-Rayburn, S., Grothkopf, U. 2007, Creating Telescope B ibliographiesElectronically– Are We There Yet?,
ASPC, 377, 53, 2007ASPC..377...53S
32.Winkelman, S., Rots, A. 2012, ObservatoryBibliographies: Not Just for Statistics Anymore, SPIE, 8448, 844829,
2012SPIE.8448E..29W
33.Wynholds, L. 2011, Linking to Scientiﬁc Data: Identity ProblemsofU nruly and PoorlyBounded Digital Objects,
International Journal of Digital Curation, 6, 214 DOI:10.2218/ijdc.v6i1.183
APPENDIX C: ABBREVIATIONS & ACRONYMS
2MASS : Two Micron All Sky Survey
ADS: Astrophysics Data System
AI: artiﬁcial intelligence
AIP: American Institute of Physics
AJ:Astronomical Journal
Ap&SS:Astrophysics and Space Sciences
API: application program interface
ApJ:The Astrophysical Journal
ApJL:The Astrophysical Journal Letters
ApJS:The Astrophysical Journal Supplement
ASP: Astronomical Society of the Paciﬁc
ATST: Advanced Technology Solar Telescope
AUI: Associated Universities Inc.
AURA: Association of Universities for Research Astronomy, Inc.
AXAF: Advanced X-ray Astrophysics Facility, previous name of Chandra
bibcode : bibliographic code [ADS]
bibgroup : bibliographic group [ADS]
CfA: Center for Astrophysics — Harvard & Smithsonian
CLASH : HST Legacy Program18
COS: Cosmic Origins Spectrograph [HST]
COSMOS : Cosmological Evolution Survey; HST Legacy Program
CSP: Chandra Science Paper
CTIO: Cerro Tololo Inter-American Observatory
CXC: Chandra X-ray Center
DKIST: Daniel K. Inouye Solar Telescope
DMSO: Data Science Mission Oﬃce [STScI]
DOI: digital object identiﬁer
ELT: Extremely Large Telescope
ESO: European Southern Observatory
FTE: full-time equivalent
GALEX : Galaxy Evolution Explorer
GLASS: HST Legacy Program
GOALS : Legacy Spitzer Space Telescope program
GTO: Guaranteed Time Observations
GUI: Graphical User Interface
HST: Hubble Space Telescope
IAC: Instituto de Astrof´ ısica de Canarias
IAU: International Astronomical Union
ID: identiﬁer
IRAC: Infrared Array Camera; Spitzer Space Telescope instrument
IRAS: Infrared Astronomical Satellite
IRS: Infrared Spectrograph; Spitzer Space Telescope instrument
IRSA: Infrared Science Archive
IT: Information technology
IUE: International Ultraviolet Explorer
JSON: JavaScript Object Notation
JWST: James Webb Space Telescope, formerly Next Generation Space Te lescope (NGST)
MAST: Mikulski Archive for Space Telescopes [HST]
MIPS: Multiband Imaging Photometer; Spitzer Space Telescope instrume nt
ML: machine learning
MNRAS :Monthly Notices of the Royal Astrophysical Society
NAOJ: National Astronomical Institute of Japan
NASA: National Aeronautics and Space Administration
NatAs:Nature Astronomy
NED: NASA/IPAC Extragalactic Database
NEOWISE : NASA mission
NGRST : Nancy Grace Roman Space Telescope, formerly Wide Field Infrared Telescope (WFIRST)
NGST: Next Generation Space Telescope, former name of the James Web b Space Telescope (JWST)
NIRSpec : Near Infrared Spectrograph [JWST]
NOAO: National Optical Astronomy Observatory
NOIRLab : U.S. National Science Foundation National Optical-Infrared Astr onomy Research Laboratory
NRAO: National Radio Astronomy Observatory
OBC: Observatory Bibliographers Collaboration
PASJ:Publications of the Astronomical Society of Japan
PASP:Publications of the Astronomical Society of the Paciﬁc
PI: principal investigator
postdoc : postdoctoral researcher
RTS: Roman Space Telescope, abbreviated acronym for the Nancy Gra ce Roman Space Telescope, formerly the Wide
Field Infrared Survey Telescope (WFIRST)
SAO: Smithsonian Astrophysical Observatory
SciX: NASA Science Explorer
SIMPLE : Spitzer IRAC/MUSYC Public Legacy Survey in the Extended Chandr a Deep Field South; legacy Spitzer
Space Telescope program
SMD: Science Mission Directorate
SPIE: Society of Photographic Instrumentation Engineers
STScI: Space Telescope Science Institute
TESS: Transiting Exoplanet Survey Satellite
UI: user interface
VLT: Very Large Telescope [ESO]
WFIRST : Wide Field Infrared Survey Telescope (former name of Nancy Grac e Roman Space Telescope, NGRST or
RST)
WISE: Wide-ﬁeld Infrared Survey Explorer19
This paper was built using the Open Journal of Astrophysics L ATEX template. The OJA is a journal which provides
fast and easy peer review for new papers in the astro-ph section of the arXiv, making the reviewing process simpler
for authors and referees alike. Learn more at http://astro.theoj.org .