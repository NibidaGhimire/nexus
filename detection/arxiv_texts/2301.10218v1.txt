DETECTING AND MEASURING HUMAN GASTRIC PERISTALSIS USING
MAGNETICALLY CONTROLLED CAPSULE ENDOSCOPE
Xueshen Li1;2, Yu Gan1, David Duan2, and Xiao Yang2
1Department of Biomedical Engineering, Stevens Insitute of Technology, Hoboken, USA
2AnX Robotica, Plano, USA
ABSTRACT
Magnetically controlled capsule endoscope (MCCE) is an
emerging tool for the diagnosis of gastric diseases with the
advantages of comfort, safety, and no anesthesia. In this
paper, we develop algorithms to detect and measure human
gastric peristalsis (contraction wave) using video sequences
acquired by MCCE. We develop a spatial-temporal deep
learning algorithm to detect gastric contraction waves and
measure human gastric peristalsis periods. The quality of
MCCE video sequences is prone to camera motion. We de-
sign a camera motion detector (CMD) to process the MCCE
video sequences, mitigating the camera movement during
MCCE examination. To the best of our knowledge, we are
the Ô¨Årst to propose computer vision-based solutions to detect
and measure human gastric peristalsis. Our methods have
great potential in assisting the diagnosis of gastric diseases
by evaluating gastric motility.
Index Terms ‚ÄîHuman gastric peristalsis, Magnetically
controlled capsule endoscopy, Deep learning
1. INTRODUCTION
Gastric motility is a process by which food travels through
the digestive tract via a series of muscular contractions called
peristalsis. Storage of ingesta, mixing and dispersion of food
particles, and expulsion of gastric contents into the duode-
num reply on gastric motility and activity [1]. Traditional
methods of evaluating gastric motility, such as manometry,
gastric emptying scintigraphy, and electrogastrography have
their limitations. Manometry involves intranasal intubation
protocols, which may cause discomfort to patients and lead
to use of sedation [2]. Nuclear medicine is required for gas-
tric emptying scintigraphy, which leads to the risk of radia-
tion exposure to patients [3]. Electrogastrography has many
variations in the recording system. The lack of standards in
analysis methods makes the electrogastrography hard to inter-
pret [4]. Magnetically controlled capsule endoscope (MCCE)
is an emerging tool for diagnosis of gastric diseases [5], pos-
sessing advantages of comfort, safety, and no anesthesia [6].
Moreover, MCCE provides real-time, true-color visualization
of gastric environments that is easy to interpret.
Fig. 1 . A video frame sequence of gastric contraction wave
captured by MCCE. The contraction wave has spatial features
within single frames and temporal features across the frame
sequence. The sequence is temporally undersampled by eight
for better visualization. The red arrows highlight the contrac-
tion wave.
The median gastric examination and transit time using
MCCE takes around one hour in clinical applications [7]. An
example of gastric contraction wave captured by MCCE is
shown in Figure 1. For evaluating gastric motility, consis-
tent attention from doctors and experts are required during
the whole examination process. There is a need to develop
computer vision-based algorithms for analyzing MCCE video
sequences and evaluating gastric motility. During the gas-
tric examination, the MCCE capsules have Ô¨Åve controlled de-
grees of freedom (two rotational and three translational) and
one uncontrolled degree of freedom (rotation along the long
axis of the capsule). Action recognition from moving cam-
eras poses signiÔ¨Åcant challenges [8]. To mitigate the sudden
movement of the MCCE capsule camera in the six degrees
of freedom, we develop a camera motion detector (CMD)
for processing MCCE video sequences. We evaluate gastric
motility from two aspects. First, we detect the presence of
contraction waves in MCCE video sequences. Then, we mea-
sure the period of contraction waves. We use convolutional
neural network (CNN) and long short-term memory (LSTM)
for contraction wave detection. Moreover, we develop a pe-
riodical detector that measures the periods of human gastric
contraction waves.
Using the CMD, we process more than 100,000 MCCE
video frames. We generate a dataset with a stable camera
view for training the CNN+LSTM model. We apply our algo-
rithms to 30 MCCE video sequences, independent of training,
for detecting and measuring the period of gastric contraction
waves. Our methods have great potential in assisting the di-arXiv:2301.10218v1  [eess.IV]  24 Jan 2023agnosis of gastric diseases by evaluating gastric motility.
2. METHOD
2.1. MCCE data collection
MCCE video sequences were provided by the research de-
partment of Ankon Technologies Co Ltd (Shanghai, China).
NaviCam¬ÆMCCE system was used to collect video se-
quences from healthy internal volunteers in Ankon. The
MCCE system consists of a swallowable capsule endoscope
(11.8√ó27 mm), a guidance magnetic robot, a data recorder,
and a computer workstation with softwares. The video frames
were captured and recorded at two frames per second (fps).
The size of video frames were 480 480 pixels.
2.2. Camera motion detector design
Algorithm 1 The camera motion detector
Input: Frame N ,Frame N - 1 , and threshold T.
Output: A boolean variable ifStable forFrame N .
1:Calculate the residual image Rbetween Frame N andFrame N
- 1.
2:Calculate histogram Hof the residual image R.
3:Calculate HMby applying a mask Mto the histogram.
4:Calculate score Sby summing all the components in the masked
histogram HM.
5:if S>T then
6: ifStable =False
7:else
8: ifStable =True
9:end if
The CMD is capable of detecting whether or not a frame
N is captured in a stable MCCE camera view. The details of
our CMD are described in Algorithm 1. A normalized Gaus-
sian function with at 128 andat 20 is adopted as the mask
M. T is set to be 200.
2.3. Detecting human contraction waves using CNN,
LSTM, and CMD
The human gastric contraction waves present features in both
spatial and temporal domains. In the spatial domain, the
waves have morphological shapes; in the temporal domain,
the shape of waves changes over time. We use CNN architec-
ture to extract time-domain features and LSTM architecture
to aggregate the features in the temporal domain. Moreover,
we adopt bi-directional LSTM so the model is capable of
capturing the temporal features of contraction waves in both
future and past directions. The details of our implementation
of CNN+LSTM model are shown in Figure 2 (a).
The workÔ¨Çow of training and prediction (testing) of the
deep learning model is shown in Figure 2 (b). During train-
ing, the CMD serves as a pre-processing step to standardize
Fig. 2 . (a) Design of our CNN+LSTM model for gastric con-
traction wave detection. N frames of capsule video records
are fed to the CNN model. Then the extracted features from
CNN are fed to LSTM cells. Outputs of LSTM cells are
sent to a fully connected (FC) layer for binary classiÔ¨Åcation
of ‚ÄôWave‚Äô and ‚ÄôNowave‚Äô. We use EfÔ¨ÅcientNet-B7 [9] as the
CNN. We implement bidirectional LSTM (BiLSTM) layers
which acquire sequence information in both future and past
directions. (b) WorkÔ¨Çow of our ensemble of EfÔ¨ÅcientNet-B7,
BiLSTM, and CMD for training and prediction stage of con-
traction wave detection.
input images as stable MCCE video sequences. The MCCE
video sequences with unstable camera views will be removed.
During testing, a similar idea of motion detection is involved
in the post-processing step to select reliable prediction results
of the CNN(EfÔ¨ÅcientNet-B7)+(Bi)LSTM model. If Frame N
fails to pass the stable status detection (i.e., ifStable=False),
the prediction results of the previous Frame N-1 will be
adopted. This post-processing step is repeated until a valid
frame that passes the stable status detection is found. As the
starting location of imaging is selected by the operator of
MCCE, we assume that the Ô¨Årst frame is always stable. For
post-processing, the CMD runs after the second frame as the
Ô¨Årst frame is always stable.
2.4. Periodical detector for human contraction waves
The human contraction waves present a periodical pattern
[10]. During clinical examination, the MCCE device may
capture multiple contraction waves in a single frame. Thus,
the wave periods cannot be simply measured by the pres-
ence of gastric contraction waves. We design a periodical
detector for measuring periods of human contraction waves
using MCCE video sequences. The details of the periodical
detector are shown in Algorithm 2. We set intervals from 5 s
to 50s, with an incremental of 0.5 s(2fps). The Tlis set toAlgorithm 2 The periodical detector
Input: Intervals [1,2...I] ,MCCE Sequence [1,2...N] , thresh-
oldTl, andTr.
Output: The period Pfor human contraction wave captured by
MCCE Frames .
1:Starting from MCCE Frame 1 , use interval ito calculate CMD
score S1:S1=CMD (Frame 1 ,Frame 1 + 1 i).
2:Calculating S2:S2=CMD (Frame 1 + 1 x i ,Frame 1 + 2 i).
3:Calculating Snuntil 1 + n i>=N.
4:Calculating the mean value Smean
i of [S1,S2...Sn] for interval i.
5:Repeating the previous steps, calculating Smean
i forIntervals
[1,2...I] .
6:Finding the local minimal PofSmean
i between interval Tland
Tr.
10sandTris set to 40s.
3. EXPERIMENTAL DESIGN AND RESULTS
3.1. Training details
We implement the EfÔ¨ÅcientNet-B7+BiLSTM model on Py-
Torch. The BiLSTM sequence is set to 5,10 and 20 frames.
We use Adam optimizer for training for 100 epochs. The
cross-entropy loss is adopted during training. The EfÔ¨ÅcientNet-
B7 parameters are pre-trained on ImageNet. The Ô¨Årst 5
epochs are warm-up epochs, in which the BiLSTM cells are
frozen and only the EfÔ¨ÅcientNet-B7 model is trained. The
learning rate is initialized as 10 4, followed by half decay
for every 10 epochs. Each batch contains 8 MCCE video
sequences. The experiments are carried out in a single RTX
3080 GPU. The training procedure takes for approximately 4
hours.
3.2. Evaluation setup and metrics
3.2.1. Detecting human contraction waves
We process a large collection with more than 100,000 MCCE
frames from 30 subjects. Using the CMD, we acquire 32,431
stable MCCE frames for training. For testing, we use 30
MCCE records from 11 subjects. The length of each testing
record is longer than 50 seconds and independent from the
training set. Upon the completion of training, we evaluated
the detection performance using accuracy, F1 score, and Area
Under Curve (AUC) on the testing set.
3.2.2. Measuring frequency of human contraction waves
We apply the periodical detector to the testing set of 30
MCCE sequences. The detected periods, P, are compared
with manually counted periods. The ground truth is obtained
from experienced readers. For each MCCE sequence, the
period of each contraction wave is counted starting from the
Ô¨Årst frame of the current wave to the Ô¨Årst frame of the next
Fig. 3 . An example of applying the periodical detector on an
MCCE video sequence (case2 in the testing set). For each
interval value ifrom 5s to 50s, the periodical detector will
generate a corresponding score Smean
i . Thei(between pre-
deÔ¨ÅnedTlandTr) with local minimum Smean
i will be identi-
Ô¨Åed as the detected period P. In this case, Pis 17.5s(denoted
as red line). The manually counted period (denoted as green
line) is 19.2s
Table 1 . Performance of multiple variations of EfÔ¨ÅcientNet-
B7+BiLSTM(x), where x represents length of BiLSTM.
MethodsMetricsAccuracy F1 AUC
EfÔ¨ÅcientNet-B7 0.8347 0.7608 0.8964
EfÔ¨ÅcientNet-B7+BiLSTM5 0.8570 0.7840 0.9294
EfÔ¨ÅcientNet-B7+BiLSTM10 0.8716 0.7961 0.9335
EfÔ¨ÅcientNet-B7+BiLSTM20 0.8882 0.8192 0.9400
wave. The average period of waves in a record is adopted as
the manually counted period. We compare the automatically
detected and manually counted periods by a deÔ¨Åned error:
jDetected period - Counted period j/ Counted period * 100 %.
3.3. Results
3.3.1. Detecting human contraction waves
We train the EfÔ¨ÅcientNet-B7+BiLSTM model using the BiL-
STM with lengths of 5, 10, and 20 for a comparative study.
We apply the trained model with EfÔ¨ÅcientNet-B7 to detect
the contraction waves. The results are shown in Table 1. We
observed that longer lengths of BiLSTM leads to higher ac-
curacy, F1, and AUC scores. This experiment demonstrates
that features in the temporal domain are important for the de-
tection of contraction waves in the MCCE sequences.
3.3.2. Measuring period of human contraction waves
To accurately extract the periods of contraction waves, we de-
velop the periodical detector as described in Algorithm 2. AnFig. 4 . Detected (denoted by blue color) and counted (denoted by orange) period of human contraction waves for the testing set
of 30 MCCE video sequences.
Fig. 5 . Representative MCCE frames with the presence of
mucus in case23 of the testing set. The mucus has shape fea-
tures and motions different than the contraction waves, which
may deteriorate the performance of the periodical detector.
The red arrows highlight the clusters of mucus.
example of using the periodical detector is shown in Figure 3.
The periodical detector is capable of measuring the periods
of contraction waves and providing results that are close to
that of manually counting. In this case, we achieve an error of
8.85%. The results of applying the periodical detector on the
30 MCCE records are shown in Figure 4. The mean, standard
deviation (std), median, max, and min values of errors be-
tween the detected and counted period of contraction waves
are shown in Table 2. Our periodical detector achieves a mean
error of 10:05% and a median error of 8:50% on the 30 testing
records. It is worth mentioning that in case23, a substantial
amount of mucus is presented on the gastric, which might be
the reason leading to a high error of 45:38%. We consider itTable 2 . The mean, standard deviation (std), median, max,
and min values of the error between detected and counted
period of human contraction waves for the testing set of 30
MCCE recordings.
Mean Std Median Max Min
10.05% 8.27% 8.50% 45.38% 0.93%
as an outlier caused by a rare case of clustered mucus exis-
tence. Some representative MCCE frames with the presence
of mucus are shown in Figure 5.
4. CONCLUSIONS
We have developed a CNN(EfÔ¨ÅcientNet-B7)+(Bi)LSTM
model and a periodical detector for detecting and measur-
ing periods of human gastric contraction waves captured by
MCCE video sequences. Also, we have developed a CMD
that is capable of processing MCCE video sequences. Our
algorithms can work together during human gastric exami-
nation using MCCE, proving both qualitative (detection) and
quantitative (period measuring) analysis of gastric motility.
To the best of our knowledge, we are the Ô¨Årst to propose
computer vision-based solutions for studying human gastric
motility.
In the future, we will improve the robustness of our al-
gorithms, especially for cases where mucuses are present in
the gastric. Also, we will extend our work by performing
clinical experiments and recruiting subject groups with more
diversity other than healthy. Moreover, we will extract more
information, such as the frequency and amplitude, of gastric
contraction waves to support clinical decision-making.5. COMPLIANCE WITH ETHICAL STANDARDS
This research was conducted retrospectively using MCCE
data collected in the research department of Ankon Technolo-
gies and its collaboration hospitals. The MCCE data were
de-identiÔ¨Åed. Written consent for reusing each data record
was acquired from volunteers. IRB approval was not required
as conÔ¨Årmed by the doctors.
6. ACKNOWLEDGMENTS
This research was sponsored by AnX Robotica. This work
was done during Xueshen Li‚Äôs internship at AnX Robot-
ica. Xiao Yang and David Duan are employed by AnX
Robotica. The views expressed are those of the authors
and do not necessarily reÔ¨Çect the ofÔ¨Åcial opinions or views
of AnX Robotica. The algorithms described in this work
are not ofÔ¨Åcial products of AnX Robotica. The authors de-
clare no conÔ¨Çicts of interest. The correspondence author:
xiao.yang@anxrobotics.com.
7. REFERENCES
[1] A. Hall Jean and J. Washabau Robert, ‚ÄúDiagnosis and
treatment of gastric motility disorders,‚Äù Veterinary Clin-
ics of North America: Small Animal Practice , vol. 29,
no. 2, pp. 377‚Äì395, 1999.
[2] Kaci E. Christian, John D. Morris, Guofeng Xie, and
Yoshiro Kawahara, ‚ÄúEndoscopy- and monitored anes-
thesia care-assisted high-resolution impedance manom-
etry improves clinical management,‚Äù Case Reports
in Gastrointestinal Medicine , vol. 2018, pp. 9720243,
2018.
[3] Palash Kar, Karen L. Jones, Michael Horowitz, Mari-
anne J. Chapman, and Adam M. Deane, ‚ÄúMeasurement
of gastric emptying in the critically ill,‚Äù Clinical Nutri-
tion, vol. 34, no. 4, pp. 557‚Äì564, 2015.
[4] Full-Young Chang, ‚ÄúElectrogastrography: Basic knowl-
edge, recording, processing and its clinical applica-
tions,‚Äù Journal of Gastroenterology and Hepatology ,
vol. 20, no. 4, pp. 502‚Äì516, 2005.
[5] Federico Carpi, Stefano Galbiati, and Angelo Carpi,
‚ÄúMagnetic shells for gastrointestinal endoscopic cap-
sules as a means to control their motion,‚Äù Biomedicine
& pharmacotherapy = Biomedecine & pharmacothera-
pie, vol. 60, no. 8, pp. 370‚Äì374, 2006.
[6] Yaoping Zhang, Yanning Zhang, and Xiaojun Huang,
‚ÄúDevelopment and application of magnetically con-
trolled capsule endoscopy in detecting gastric lesions,‚Äù
Gastroenterology research and practice , vol. 2021, pp.
2716559, 2021.[7] Ya-Wei Liu, Yuan-Chen Wang, Jia-Hui Zhu, Xi Jiang,
Wei Zhou, Jie Zhang, Zhuan Liao, and En-Qiang
Linghu, ‚ÄúMagnetically controlled capsule endoscopy
in one-time gastro-small intestinal joint examination: a
two-centre experience,‚Äù BMC Gastroenterology , vol. 22,
no. 1, pp. 222, 2022.
[8] Shandong Wu, Omar Oreifej, and Mubarak Shah, ‚ÄúAc-
tion recognition in videos acquired by a moving camera
using motion decomposition of lagrangian particle tra-
jectories,‚Äù in 2011 International Conference on Com-
puter Vision , 2011, pp. 1419‚Äì1426.
[9] Mingxing Tan and Quoc Le, ‚ÄúEfÔ¨Åcientnet: Rethink-
ing model scaling for convolutional neural networks,‚Äù
inProceedings of the 36th International Conference
on Machine Learning , Kamalika Chaudhuri and Ruslan
Salakhutdinov, Eds. 2019, vol. 97 of Proceedings of Ma-
chine Learning Research , pp. 6105‚Äì6114, PMLR.
[10] Sushil K. Sarna, ‚ÄúThe gold standard for interpretation of
slow wave frequency in in vitro and in vivo recordings
by extracellular electrodes,‚Äù The Journal of physiology ,
vol. 591, no. 18, pp. 4373‚Äì4374, 2013.