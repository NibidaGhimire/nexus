Direct and indirect evidence of compression of word lengths.
Zipf’s law of abbreviation revisited.
Sonia Petrini1(0000-0002-0514-6223), Antoni Casas-i-Muñoz2(0000-0001-5690-316X), Jordi
Cluet-i-Martinell2(0000-0003-4188-6728), Mengxue Wang2(0000-0002-8262-9333), Christian
Bentz3(0000-0001-6570-9326), Ramon Ferrer-i-Cancho1*(0000-0002-7820-923X)
1Quantitative, Mathematical and Computational Linguistics Research Group. Departament de Ciències de la
Computació, Universitat Politècnica de Catalunya (UPC), Barcelona, Catalonia, Spain.
2Universitat Politècnica de Catalunya (UPC), Barcelona School of Informatics, Barcelona, Catalonia, Spain.
3Department of Linguistics, University of Tübingen, Tübingen, Germany.
*Corresponding author’s email: rferrericancho@cs.upc.edu
DOI: Here will be added DOI number by Glottometrics.
Abstract
Zipf’slawofabbreviation,thetendencyofmorefrequentwordstobeshorter,isoneofthemostsolid
candidates for a linguistic universal, in the sense that it has the potential for being exceptionless or
withanumberofexceptionsthatisvanishinglysmallcomparedtothenumberoflanguagesonEarth.
SinceZipf’spioneeringresearch,thislawhasbeenviewedasamanifestationofauniversalprinciple
of communication, i.e. the minimization of word lengths, to reduce the effort of communication.
Here we revisit the concordance of written language with the law of abbreviation. Crucially, we
provide wider evidence that the law holds also in speech (when word length is measured in time),
in particular in 46 languages from 14 linguistic families. Agreement with the law of abbreviation
provides indirect evidence of compression of languages via the theoretical argument that the law
of abbreviation is a prediction of optimal coding. Motivated by the need of direct evidence of
compression, we derive a simple formula for a random baseline indicating that word lengths are
systematically below chance, across linguistic families and writing systems, and independently of
the unit of measurement (length in characters or duration in time). Our work paves the way to
measure and compare the degree of optimality of word lengths in languages.
Keywords: word length, compression, law of abbreviation
1 Introduction
It has been argued that linguistic universals are a myth (Evans and Levinson, 2009), but this neglects
the statistical regularities that the quantitative linguistic community has been investigating for many
decades. A salient case is Zipf’s law of abbreviation, the tendency of more frequent words to be
Glottometrics XX, 20XXarXiv:2303.10128v2  [cs.CL]  27 May 2023Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
shorter (Zipf, 1949). It holds across language families (), writing systems () and modalities (), and
also when word length in characters is replaced by word duration in time (Hernández-Fernández et al.,
2019). Furthermore, the number of species where a parallel of this law has been confirmed in animal
communicationisgrowingovertime(Sempleetal.,2022). 1Inlanguagesciences,researchonthelawof
abbreviation in languages measures word length in discrete units (e.g., characters) whereas, in biology,
researchonthelawinotherspeciestypicallyusesdurationintime. Here,weaimtoreducethegulfthat
separates these two traditions by promoting research on the law of abbreviation on word durations.
G. K. Zipf believed that the law of abbreviation constituted indirectevidence of the minimization of the
cost of using words (Zipf, 1949). At present, Zipf’s view is supported by standard information theory
anditsextensions: themainargumentisthattheminimizationof 𝐿,themeanwordlength,thatisindeed
a simplification of Zipf’s cost function, 2leads to the law of abbreviation (). Using the terminology
of information theory, the minimization of mean word length is known as compression. Using the
terminology of quantitative linguistics, 𝐿is the average length of tokens from a repertoire of 𝑛types,
that is defined as
(1) 𝐿=𝑛∑︁
𝑖=1𝑝𝑖𝑙𝑖,
where𝑝𝑖and𝑙𝑖are,respectively,theprobabilityandthelengthofthe 𝑖-thtype. Inpracticalapplications,
𝐿is calculated replacing 𝑝𝑖by the relative frequency of a type, that is
𝑝𝑖=𝑓𝑖/𝑇,
where𝑓𝑖is the absolute frequency of a type and 𝑇is the total number of tokens, i.e.
𝑇=𝑛∑︁
𝑖=1𝑓𝑖.
This leads to a definition of 𝐿that is
𝐿=1
𝑇𝑛∑︁
𝑖=1𝑓𝑖𝑙𝑖.
Atpresent,themathematicallinkbetweenthelawofabbreviationandcompressionhasbeenestablished
under the assumption that words are coded optimaly so as to minimize 𝐿. If words are coded optimaly,
the correlation between the frequency of a word and its duration cannot be positive (Ferrer-i-Cancho
et al., 2019). Thus, a lack of correlation between the frequency of a word and its duration does not
implyabsenceofcompression. Furthermore,itisnotawarrantedassumptionthatlanguagescodewords
optimaly. Therefore,anapproachtofind directevidenceofcompressiongettingridoftheassumptionof
optimal coding is required.
1The interested reader can check the latest discoveries on this law in “Bibliography on laws of language outside human
language” at https://cqllab.upc.edu/biblio/laws/.
2He referred to the cost function as “minimum equation” (Zipf, 1949).
2Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
As a first approach, one could compare the value of 𝐿of a language against 𝐿𝑚𝑎𝑥, the maximum value
that𝐿could achieve in this language. The larger the gap between 𝐿and𝐿𝑚𝑎𝑥, the higher the level of
compression in the language. However, the problem is that 𝐿𝑚𝑎𝑥can be infinite a priori. To fix that
problem,onecouldrestrict 𝐿𝑚𝑎𝑥tobefinitebutthenthisraisesthequestionofwhatshouldbethefinite
value of𝐿𝑚𝑎𝑥and why. For these reasons, here we resort to the notion of random baseline, that here is
defined assuming some random mapping of word types into strings. In previous research, the random
baselinewasdefinedbytheaveragewordlengthresultingfromashufflingofthecurrentlength/duration
of types so as to check if 𝐿was smaller than expected by chance in that random mapping (). Critically,
an exact method to compute the random baseline, namely the expected word length in these shufflings,
is missing.
The remainder of the article is organized as follows. In Section 2, we introduce the definition of 𝐿𝑟, the
random baseline, that we will use to explore direct evidence of compression. In particular, we derive
a simple formula for 𝐿𝑟that will simplify future research on compression in natural communication
systems. In Section 3 and Section 4, we present, respectively, the materials and methods that will be
used to provide further evidence of compression and the law of abbreviation in real languages with
emphasis on word durations. In Section 4, we present a new unsupervised method to exclude words
with foreign characters in line with good practices for research on linguistic laws and communicative
efficiency(MeylanandGriffiths,2021). InSection5,weshowthatthelawofabbreviationholdswithout
exceptions in a wide sample of languages, independently of the unit of measurement of word length,
namely characters or duration in time, providing further indirect evidence of compression in languages.
In addition, the random baseline indicates that word lengths are systematically below chance, across
linguisticfamiliesandwritingsystems,independentlyoftheunitofmeasurement(lengthincharactersor
durationintime),providingdirectevidenceofcompression. Finally,inSection6,wediscussthefindings
in relation to the potential universality of the law of abbreviation and the universality of compression in
languages. We also make proposals for future research.
2 A random baseline revisited
Inourstatisticalsetting,thenullhypothesisstatesthatcompression(minimizationofwordlengths)hasno
effectonwordlengths. Thealternativehypothesisstatesthatcompressionhasaneffectonwordlengths
as Zipf hypothesized. If the null hypothesis is rejected then word lengths are shorter than expected by
chance.
Consider a matrix with two columns, 𝑓𝑖and𝑙𝑖, that are used to compute the average word length 𝐿.
The matrix in Table 1 gives 𝐿=235
125=1.88. We consider the null hypothesis of a random mapping of
probabilitiesintolengths,namelythattheorderingofthe 𝑓𝑖’sorthe𝑙𝑖’sinTable1isarbitraryandresults
3Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
Table 1: Matrix indicating the frequency and length of three types. The mean type length is 𝐿=235
125=1.88.
𝑖 𝑓 𝑖𝑙𝑖
1 100 2
2 20 1
3 5 3
fromarandomshufflingofoneofthesevariablesorboth. Weuse 𝑓′
𝑖,𝑙′
𝑖and𝑝′
𝑖forthenewvaluesof 𝑓𝑖,
𝑙𝑖and𝑝𝑖that result from one of these shufflings.
Thisnullhypothesiswasintroducedinresearchoncompressioninhumanlanguageandanimalcommuni-
cationtotestif 𝐿issignificantlysmallusingapermutationtest(). Later,itwasusedtoestimatethedegree
of optimality of word lengths (). Our new contribution here is a precise mathematical characterization
of the null hypothesis and the derivation of a simple formula the expected word length.
In the context of computing average word length, the matrix in Table 1 is equivalent to a matrix where
the column𝑓𝑖is replaced by a column with 𝑝𝑖thanks to
𝑝′
𝑖=𝑓′
𝑖
𝑇.
Indeed, the null hypothesis has three variants
1. Single column shuffling. Only the column of 𝑓𝑖or𝑝𝑖is shuffled.
2. Single column shuffling. Only the column of 𝑙𝑖is shuffled.
3. Dual column shuffling. The column of 𝑓𝑖or𝑝𝑖and the column of 𝑙𝑖are both shuffled.
In each of the variants, all random shufflings of a specific column are equally likely. In case of dual
shuffling, the shuffling of one column is independent of the shuffling of the other column. The outcome
of a dual shuffling on Table 1 is shown in Table 2.
Table 2: Matrix indicating the frequency and length of three types. The mean type length is 𝐿=345
125=2.76.
𝑖 𝑓′
𝑖𝑙′
𝑖
1 20 2
2 100 3
3 5 1
The random baseline, 𝐿𝑟, is the expected value of 𝐿under the null hypothesis. 3𝐿𝑟can be defined in
more detail in two main equivalent ways:
3Notice that𝐿is indeed the expected value of the length of a token but under a distinct setting (a distinct null hypothesis),
where one picks a token uniformly at random over all tokens of a text and looks at its length.
4Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
1. Thevalueof 𝐿thatisexpectedif 𝐿isrecomputedafterpairingthe 𝑓𝑖’sandthe𝑙𝑖’satrandomand
recomputing 𝐿. Thenewvalueof 𝐿dependsonthevariantofthenullhypothesis. Whenshuffling
the column for 𝑓𝑖in the matrix (Table 1), the new 𝐿is
𝐿′=1
𝑇𝑛∑︁
𝑖=1𝑓′
𝑖𝑙𝑖.
When shuffling the column for 𝑙𝑖and recomputing 𝐿, the new𝐿is
𝐿′=1
𝑇𝑛∑︁
𝑖=1𝑓𝑖𝑙′
𝑖.
When shuffling both columns, the new 𝐿is
𝐿′=1
𝑇𝑛∑︁
𝑖=1𝑓′
𝑖𝑙′
𝑖.
2. The average value of 𝐿that is expected over all possible shufflings in one of the variants of the
null hypothesis. In the example in Table 3, on shuffling only the 𝑙𝑖column,
𝐿𝑟=155
125+170
125+235
125+265
125+330
125+345
125
6=155+170+235+265+330+345
125·6=2.
We use E[𝑋]to refer to the expected value of a random variable 𝑋under some variant of the null
hypothesis above. Then
𝐿𝑟=E[𝐿′],
where𝐿′is the value of 𝐿resulting from some shuffling.
In quantitative linguistics, the mean length of tokens ( 𝐿) is also known as dynamic word length (Chen
et al., 2015) and corresponds to the mean length of the words in a text. The mean length of types ( 𝑀),
defined as
𝑀=1
𝑛𝑛∑︁
𝑖=1𝑙𝑖,
isalsoknownasthestaticwordlengthandcorrespondstoaveragelengthoftheheadwordsinadictionary
(Chen et al., 2015). Interestingly, the following property states that 𝐿𝑟turns out to be 𝑀independently
of the variant of the null hypothesis under consideration.
Property 2.1. The expected value of 𝐿′under any variant of the null hypothesis is 𝐿𝑟=𝑀.
Proof.We analyze E[𝐿′]under each of the variants of the null hypothesis.
Dual shuffling. Applying the linearity of expectation and independence between the shuffling of the 𝑝𝑖
5Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
column of the that of the 𝑙𝑖column, we obtain
E[𝐿′
1]=E"𝑛∑︁
𝑖=1𝑝′
𝑖𝑙′
𝑖#
=𝑛∑︁
𝑖=1E[𝑝′
𝑖𝑙′
𝑖]
=𝑛∑︁
𝑖=1E[𝑝′
𝑖]E[𝑙′
𝑖].
Noting that
E[𝑝′
𝑖]=1
𝑛𝑛∑︁
𝑖=1𝑝𝑖=1
𝑛
E[𝑙′
𝑖]=1
𝑛𝑚∑︁
𝑖=1𝑙𝑖=𝑀,
we finally obtain
(2) E[𝐿′]=𝑛∑︁
𝑖=1𝑀
𝑛=𝑀.
Singleshufflingofthe 𝑙𝑖column. Applyingthelinearityofexpectationandthefactthatthecolumnof 𝑝𝑖
remains constant, we obtain
E[𝐿′
1]=E"𝑛∑︁
𝑖=1𝑝𝑖𝑙′
𝑖#
=𝑛∑︁
𝑖=1𝑝𝑖E[𝑙′
𝑖].
Recalling E[𝑙′
𝑖]=𝑀, we finally obtain
(3) E[𝐿′]=𝑀𝑛∑︁
𝑖=1𝑝𝑖=𝑀.
Singleshufflingofthe 𝑝𝑖column. Applyingthelinearityofexpectationandthefactthatthecolumnof 𝑙𝑖
remains constant, we obtain
E[𝐿′
1]=E"𝑛∑︁
𝑖=1𝑝′
𝑖𝑙𝑖#
=𝑛∑︁
𝑖=1E[𝑝′
𝑖]𝑙𝑖.
Recalling E[𝑝′
𝑖]=1
𝑛, we finally obtain
(4) E[𝐿′]=1
𝑛𝑛∑︁
𝑖=1𝑙𝑖=𝑀.
The previous finding indicates that the random baseline for 𝐿is equivalent to assuming that all word
types are equally likely, namely, replacing each 𝑝𝑖by1/𝑛.
6Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
Table 3: All the 3!=6permutations of the column 𝑙𝑖in Table 1 that can be produced. Each permutation is indicated with
letters from A to F. 𝐿′, the mean length of types in a shuffling, is shown at the bottom for each permutation.
A B C D E F
𝑖 𝑓 𝑖𝑙′
𝑖𝑙′
𝑖𝑙′
𝑖𝑙′
𝑖𝑙′
𝑖𝑙′
𝑖
1 100 1 1 2 2 3 3
2 20 2 3 1 3 1 2
3 5 3 2 3 1 2 1
𝐿′ 155
125=1.24170
125=1.36235
125=1.88265
125=2.12330
125=2.64345
125=2.76
3 Material
3.1 General information about corpora and languages
We investigate the relationship between the frequency of a word and its length in languages from two
collections: Common Voice Forced Alignments (Section 3.2.1), hereafter CV, and Parallel Universal
Dependencies (Section 3.2.2), hereafter PUD.
All the preprocessed files used to produce the results from the original collections are available in the
repository of the article. 4
PUD comprises 20 distinct languages from 7 linguistic families and 8 scripts (Table 4). CV comprises
46languagesfrom14linguisticfamilies(weinclude’Conlang’,i.e. ’constructedlanguages’,asafamily
for Esperanto and Interlingua) and 10 scripts (Table 5). Both PUD and CV are biased towards the
Indo-European family and the Latin script. The typological information (language family) is obtained
from Glottolog 4.6 5. The writing systems are determined according to ISO-15924 codes 6. In Table 4
andTable5,weshowthescriptsusingtheirstandardEnglishnames. Forexample,mostlanguagesfrom
the Indo-European family are written in Latin scripts. We also categorize Chinese Pinyin and Japanese
Romaji as Latin scripts.
4In thedatafolder of https://github.com/IQL-course/IQL-Research-Project-21-22.
5https://glottolog.org/
6https://unicode.org/iso15924/iso15924-codes.html
7Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
Table 4: Summary of the main characteristics of the languages in the PUD collection. For each language, we show the
linguistic family, the writing system (namely script name according to ISO-15924) and various numeric parameters: 𝐴, the
observed alphabet size (number of distinct characters), 𝑛, the number of word types, and 𝑇, the number of word tokens.
Language Family Script 𝐴 𝑛 𝑇
Arabic Afro-Asiatic Arabic 20 3309 11667
Indonesian Austronesian Latin 23 4501 16702
Russian Indo-European Cyrillic 23 4666 11749
Hindi Indo-European Devanagari 44 4343 20071
Czech Indo-European Latin 33 7073 15331
English Indo-European Latin 25 5001 18028
French Indo-European Latin 26 5214 20407
German Indo-European Latin 28 6116 18331
Icelandic Indo-European Latin 32 6035 16209
Italian Indo-European Latin 24 5606 21266
Polish Indo-European Latin 31 7188 15191
Portuguese Indo-European Latin 38 5661 21855
Spanish Indo-European Latin 32 5750 21067
Swedish Indo-European Latin 25 5624 16378
Japanese Japonic Japanese 1549 4852 24737
Japanese-strokes Japonic Japanese 1549 4852 24737
Japanese-romaji Japonic Latin 24 4849 24734
Korean Koreanic Hangul 379 6218 12307
Thai Kra-Dai Thai 50 3573 20860
Chinese Sino-Tibetan Han (Traditional variant) 2038 4970 17845
Chinese-strokes Sino-Tibetan Han (Traditional variant) 2038 4970 17845
Chinese-pinyin Sino-Tibetan Latin 50 4970 17845
Turkish Turkic Latin 28 6587 13799
Finnish Uralic Latin 24 6938 12701
8Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
Table5: SummaryofthemaincharacteristicsofthelanguagesintheCVcollection. Foreverylanguageweshowitslinguistic
family, the writing system (namely script name according to ISO-15924) and various numeric parameters: 𝐴, the observed
alphabet size (number of distinct characters), 𝑛, the number of word types, and, 𝑇, the number of word tokens. ’Conlang’
stands for ’constructed language’, that is an artificially created language. This is not a family in the proper sense as Conlang
languages are not related in the common linguistic family sense.
Language Family Script 𝐴 𝑛 𝑇
Arabic Afro-Asiatic Arabic 31 6397 45825
Maltese Afro-Asiatic Latin 31 8058 44112
Vietnamese Austroasiatic Latin 41 370 938
Indonesian Austronesian Latin 22 3768 44210
Esperanto Conlang Latin 27 27759 406261
Interlingua Conlang Latin 20 5126 30504
Tamil Dravidian Tamil 29 1210 6439
Persian Indo-European Arabic 38 13115 1662508
Assamese Indo-European Assamese 43 971 1813
Russian Indo-European Cyrillic 32 31827 637686
Ukrainian Indo-European Cyrillic 34 14337 120760
Panjabi Indo-European Devanagari 37 84 98
Modern Greek Indo-European Greek 33 5813 37880
Breton Indo-European Latin 28 4228 38237
Catalan Indo-European Latin 39 79112 3294206
Czech Indo-European Latin 33 15518 147582
Dutch Indo-European Latin 23 10225 316498
English Indo-European Latin 28 173023 9828713
French Indo-European Latin 49 160243 3729370
German Indo-European Latin 30 148436 4230565
Irish Indo-European Latin 23 2251 22593
Italian Indo-European Latin 34 54996 811783
Latvian Indo-European Latin 27 7251 29456
Polish Indo-European Latin 32 25340 595411
Portuguese Indo-European Latin 27 11509 283048
Romanian Indo-European Latin 29 6423 33341
Romansh Indo-European Latin 26 9614 43792
Slovenian Indo-European Latin 24 5937 26304
Spanish Indo-European Latin 33 75010 1842474
Swedish Indo-European Latin 25 4371 62951
Welsh Indo-European Latin 22 11143 539621
Western Frisian Indo-European Latin 30 8383 63073
Oriya Indo-European Odia 41 764 1700
Dhivehi Indo-European Thaana 27 111 1284
Georgian Kartvelian Georgian 25 6505 12958
Basque Language isolate Latin 21 24748 458071
Mongolian Mongolic Mongolian 31 14608 70217
Kinyarwanda Niger-Congo Latin 26 133815 1939810
Abkhazian Northwest Caucasian Cyrillic 28 119 156
Hakha Chin Sino-Tibetan Latin 23 2499 17776
Chuvash Turkic Cyrillic 22 4311 13583
Kirghiz Turkic Cyrillic 30 10130 61844
Tatar Turkic Cyrillic 34 21823 144356
Yakut Turkic Cyrillic 28 7904 22577
Turkish Turkic Latin 31 8926 107686
Estonian Uralic Latin 23 28691 121549
9Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
3.2 The datasets
We measure word length in two main ways: duration in time andlength in characters . Concerning
Chinese and Japanese, we additionally consider the number of strokes and the number of characters of
their romanization (i.e. Pinyin for Chinese and Romaji for Japanese).
Giventhesedatasets,worddurationsareobtainedonlyfromCV.Wordlengthsincharactersareobtained
from both CV as well as from PUD. Word lengths in strokes, and word lengths in characters after
romanization, are obtained only from PUD.
3.2.1 Common Voice Forced Alignments
The Common Voice Corpus 7is an open source dataset of recorded voices uttering sentences in many
different languages. The amount of data, as well as the source and topic of each sentence, depends
considerably on the language and the corpus version. Specifically, the Common Voice Corpus 5.1
contains information on 54 languages and dialects.
Common Voice Forced Alignments (CVFA) 8were created by Josh Meyer using the Montreal Forced
Aligner 9ontopoftheCommonVoiceCorpus5.1. Kabyle,UpperSorbianandVoticwereleftoutofthe
alignments for an undocumented reason. Therefore, CVFA contains information on 51 languages.
In our analyses, Japanese and the three Chinese dialects were excluded as the forced aligner failed to
correctly extract words from sentences. In addition, both Romansh dialects were fused into a single
Romanshlanguage. Indeed,giventhenatureofthiscorpus,alllanguagesarelikelytoberepresentedby
more than one dialect.
Notice that Abkhazian, Panjabi, and Vietnamese have a critically low number of tokens ( 𝑇 < 1000in
Table 5). However, we decided to include them in the analyses so as to understand their limitations
related to corpus size.
3.2.2 Parallel Universal Dependencies
TheUniversalDependencies(UD) 10collectionisanopensourcedatasetofannotatedsentences,inwhich
theamountofdatadependsoneachlanguage. TheParallelUniversalDependencies(PUD)collectionis
a parallel subset of 20 languages from the UD collection, consisting of 1000 sentences. It allows for a
cross-language comparison, controlling for content and annotation style.
In Table 4, we show the characteristics of the languages in PUD. For traditional Chinese and Japanese,
7https://commonvoice.mozilla.org/en/datasets
8https://github.com/JRMeyer/common-voice-forced-alignments
9https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner
10https://universaldependencies.org/
10Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
wealsoincludewordlengthsinromanizations(PinyinandRomajirespectively),aswellaswordlengths
measured in strokes, resulting in a total of 24 language files. Notice that three Japanese words that are
hapax legomena could not be romanized and thus the number of tokens and types varies slightly with
respect to the original Japanese characters (Table 4).
4 Methodology
All the code used to produce the results is available in the repository of the article. 11
4.1 The units of length
4.1.1 Duration
The duration of a word for a given language is estimated by computing the median duration in seconds
across all its occurrences in utterances in the CV corpus. All words with equal orthographic form are
assumedtobethesametype. Themedianispreferredoverthemeanasitislesssensitivetooutliers(that
may be produced by forced alignment errors) and better suited to deal with heavy-tailed distributions
(Hernández-Fernández et al., 2019). Given the oral nature of the data, we do expect to observe some
variation in the duration of words, due to differences between individuals, and variation within a single
individual. This is more generally in line with speakers acting as complex dynamical systems (Kello
et al., 2010). For these reasons, median duration is preferred for research on the law of abbreviation in
acoustic units ().
4.1.2 Length in characters
Word length in characters is measured by counting every Unicode UTF-8 character present in a word.
Special characters such as “=” were removed. Characters with stress accents are considered as different
fromtheirnon-stressedcounterpart(e.g. “a”and“à”areconsideredseparatecharacters). Followingbest
practices from (Meylan and Griffiths, 2021), characters were always kept in UTF-8.
4.1.3 Length in strokes
JapaneseKanjiandChineseHanziwereturnedintostrokesusingthe cihaiPythonlibrary. 12InJapanese
charactersotherthanKanji,namelyJapaneseKana,thenumberofstrokesinprintedversushand-written
modality can differ (Chinese Hanzi and Japanese Kanji have the same number of strokes in printed
versionorhand-writtenversion). Herewecountedthenumberofstrokesinprintedform. JapaneseKana
wereconvertedintoprintedstrokesbyusingahand-craftedcorrespondencetable,sinceKanaisnotpart
11In thecodefolder of https://github.com/IQL-course/IQL-Research-Project-21-22.
12https://github.com/cihai/cihai
11Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
of the CJK unified character system. This table was created by us and checked by a native linguist (S.
Komori from Chubu University, Japan). It is available in the repository of the article. 13
In case of discrepancies on the number of strokes for a given character, the most typical printed version
was chosen.
4.1.4 Length in Pinyin and Romaji
ChinesePinyinwasobtainedusingthe cihaipackageasabove,whiletheJapaneseRomajiwasobtained
with the cutletPython library. 14The latter uses Kunrei-shiki romanization (since it is the one used
officially by the government of Japan) and the spelling of foreign words is obtained in its native reading
(e.g. “カレー” is romanized as “karee” instead of “curry”). There are some particularities with the
romanizationofKanjicharactersby cutlet. Forexample,inthecaseoftheword“year”( 年),itchosethe
reading of “Nen” instead of “Tosi”, which would be the expected one.
A more systematic issue with Japanese romanization is that it does not provide means to indicate pitch
accents, which are implicitly present in Kanji. For example, “ 日本” “Ni↑hon” (“Japan”) is romanized
as simply “Nihon”. Therefore, the alphabet size of romanized Japanese is smaller than it should be,
comparedtootherlanguageswhere,asstatedbefore,stressaccentsarecountedasdistinctivefeaturesof
characters.
4.2 Tokenization
Tokenization is already given in each dataset and we borrow it for our analyses. Thus tokenization
methods are not uniform for CV and PUD and are not guaranteed to be uniform among languages even
within each of these datasets.
4.3 Filtering of tokens
Examining our datasets, we noticed that in some text files there was a considerable number of unusual
character strings, as well as foreign words (written in different scripts). These need to be filtered out
in order to obtain a “clean” set of word types. To this end we filter out tokens following a two step
procedure:
1.Mandatory elementary filtering . This filter consists of:
•Commonfiltering . Inessence,itconsistsoftheoriginaltokenizationandtheremovaloftokens
containing digits. In each collection, the original tokenizer yields tokens that may contain
certainpunctuationmarks. DuetothenatureoftheCVdataset,thebulkofpunctuationwas
13In thedata/other folder of https://github.com/IQL-course/IQL-Research-Project-21-22.
14https://github.com/polm/cutlet
12Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
alreadyremovedviatheMontrealForcedAlignerwithsomeexceptions. Forinstance,single
quotation(inparticular“”’)isapunctuationsignthatiskeptwithinawordtokeninCV,asit
is necessary for the formation of clitics in multiple languages, such as in English or French.
InPUD,asapartofUD,contractionsaresplitintotwowordtypes. “can’t”issplitinto“ca”
“n’t” (in CV “can’t” would remain as just one token). In both collections, words containing
ASCII digits are removed because they do not reflect phonemic length and can be seen as
another writing system.
•Specificfiltering. IncaseofthePUDcollection,weexcludedalltokenswithPart-of-Speech
(POS) tag ‘PUNCT’. In case of the CV collection, we removed tokens tagged as <unk> or
null tokens, namely tokens that either could not be read or that represent pauses.
•Lowercasing. Every character is lowercased. In the case of CV, this is already given by the
Montreal Forced Aligner, while in the case of PUD, tokens are lowercased by means of the
spaCyPython package. 15
2.Optional filtering . This is a new method that is applied after the previous filter and described in
Section 4.4.
4.4 A new method to filter out unusual characters
Ithasbeenpointedoutthat“chunk”wordsandloanwordscandistorttheresultsofquantitativeanalyses
ofwordlengths(Meylan andGriffiths,2021). Indeed,especiallythefilesof theCommonVoiceCorpus
featureaconsiderablenumberofwordtokenswhichdonotconsistofcharactersbelongingtotheprimary
alphabet of the respective writing system. Meylan and Griffiths (2021) proposed to use dictionaries to
exclude such anomalous words. However, this is not feasible for our multilingual datasets, as loanword
dictionaries are not available for this large number of diverse languages (Table 4 and Table 5). The
Intercontinental Dictionary Series, 16for example, contains only around half of the languages in our
analysis, so it is not applicable to many of them. Hence, this approach would lead to a non-uniform
treatmentofdifferentlanguagesandtexts. Selectingamatchedsetofsemanticconceptsacrosslanguages
using a lexical database is also infeasible due to similar reasons.
Against this backdrop, we decided to develop an unsupervised method to filter out words which contain
highlyunusualcharacters. Foragivenlanguage,themethodstartsbyassumingthatthestrings(afterthe
mandatoryfilteringillustratedabove)containcharactersoftwotypes: charactersoftheworking/primary
alphabetaswellasothercharacters. Wehypothesizethatthelatteraremuchlessfrequentthantheformer.
15https://spacy.io/
16https://ids.clld.org/
13Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
Following this rationale, we apply the 𝑘-means algorithm of the Ckmeans R package 17to split the set of
charactersintothetwogroupsbasedonthelogarithmofthefrequencyofthecharacters. 18Tomaximize
thepoweroftheclusteringmethod,weusetheexactmethodwith 𝑘=2foronedimensioninsteadofthe
customary approximate method. We then keep the high frequency cluster as the real working alphabet
and filter out the word tokens that contain characters not belonging to this high frequency cluster.
WeillustratethepowerofthemethodbyshowingworkingalphabetsthatareobtainedonCV,thatisthe
noisiest one of the collections.
InEnglish,theworkingalphabetisdefinedbythe26Englishlettersandquotationmarks(“”’,“”’). These
quotation marks are used often in clitics, and as such are correctly identified as part of the encoding,
since, for example, “can’t” and “cant” are different words in meaning, with “can’t” meaning “can not”,
while “cant” is a statement on a religious or moral subject that is not believed by the person making
the statement, with the differentiating feature being the “”’. Therefore, the working alphabet becomes 5
vowels (“a”, “e”, “i”, “o”, “u”), 21 consonants (“b”, “c”, “d”, “f”, “g”, “h”, “j”, “k”, “l”, “m”, “n”, “p”,
“q”, “r”, “s”, “t”, “v”, “w”, “x”, “y”, “z”) and 2 kinds of quotation marks (“”’, “”’).
In Russian, the working alphabet comprises 9 vowels ( “ a”, “ o”, “ u”, “ y”, “ ”, “ ”, “ ”, “ i”, “ e”), a
semivowel / consonant “ ”, 20 consonants ( “ b”, “ v”, “ g”, “ d”, “ ”, “ z”, “ k”, “ l”, “ m”, “ n”, “ p”, “ r”,
“ s”, “ t”, “ f”, “ h”, “ c”, “ q”, “ x”, “ w”) and 2 modifier letters (“ ”, “ ~”).
In Italian, it comprises 5 vowels (“a”, “e”, “i”, “o”, “u”), 21 consonants (“b”, “c”, “d”, “f”, “g”, “h”,
“j”, “k”, “l”, “m”, “n”, “p”, “q”, “r”, “s”, “t”, “v”, “w”, “x” , “y”, “z”) and 6 instances of the 5 vowels
containing a diacritic mark (“à”, “è”, “é”, “ì”, “ò”, “ù”).
The unsupervised filter method filter is not applied to Chinese, Japanese and Korean as, given their
nature, this would exclude letters that actually belong to the real alphabet. In Section B.1 we analyze
the impact of the optional filter and provide arguments for not applying the unsupervised filter to these
languages. As a compensation, strings that contain non-CJK characters are filtered out in Chinese and
Japaneseasapartoftheoptionalfilter. InKorean,onlyafewcharactersarenotproperHangulandthus
such a complementary filtering is not necessary.
17https://cran.r-project.org/web/packages/Ckmeans.1d.dp/index.html
18The motivation for taking logarithms of frequencies is three-fold: First, this brings observations closer together. Note
that the𝑘-means algorithm prefers high-density areas. Second, this transforms the frequencies into a measure of surprisal,
followingstandardinformationtheory(Shannon,1948). Third,manualinspectionsuggeststhatthelogarithmictransformation
is required to produce an accurate split.
14Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
4.5 Immediate constituents in writing systems
When measuring word length in written languages, we are using immediate constituents of written
words. In Romance languages, the immediate constituents are letters of the alphabet, which are a
proxy for phonemes. For syllabic writing systems (as Chinese in our dataset), these are characters that
correspond to syllables. In addition, for Chinese and Japanese, we are considering two other possible
units for word length, which are not immediate constituents, but alternative ways of measuring word
lengthswhichcouldprovideusefulinsights: strokesandlettersinLatinscriptromanizations. Thatmeans
that for each of these languages words are unfolded into three systems, one for each unit of encoding
(original characters, strokes, romanized letters/characters). In the hierarchy from words to other units,
only the original characters are immediate constituents.
4.6 Statistical testing
4.6.1 Correlation
When measuring the association between two variables, we use both Pearson correlation and Kendall
correlation(Conover,1999). NotethatthetraditionalviewofPearsoncorrelationasameasureoflinear
association and thus not suitable for non-linear association has been challenged (van den Heuvel and
Zhan, 2022).
4.6.2 How to test for the law of abbreviation
We used a left-sided correlation test to verify the presence of the law of abbreviation. In a purely
exploratory or atheoretic exploration, one should use a two-sided test. In an exploration guided by
theory, namely regarding the law of abbreviation as a manifestation of compression, the test should be
left-sided as theory predicts that 𝜏(𝑝,𝑙)cannot be positive in case of optimal coding (Ferrer-i-Cancho
et al., 2019).
4.6.3 How to test for compression
Inthecontextofthenullhypothesisofarandommappingoftypeprobabilitiesintotypelengths,testing
that compression (minimization of 𝐿) has some effect on actual word lengths is easy because 𝐿is a
linearfunctionof 𝑟,thePearsoncorrelationbetweenwordlengthandwordprobability(AppendixA).In
particular,
𝐿=𝑎𝑟+𝐿𝑟,
where𝑎=(𝑛−1)𝑠𝑝𝑠𝑙,being𝑛thenumberoftypesand 𝑠𝑝and𝑠𝑙,respectively,thestandarddeviationof
type probabilities and type lengths. In such random mappings, 𝐿𝑟,𝑠𝑝and𝑠𝑙remain constant and then
testing if𝑟is significantly small is equivalent to testing if 𝐿is significantly small (notice 𝑎≥0).
15Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
4.6.4 Controlling for multiple testing
Whenperformingmultiplecorrelationtestsatthesametime,itbecomeseasiertorejectthenullhypothesis
simply by chance. To address this problem we used a Holm-Bonferroni correction to p-values. 19We
applied the correction when checking the law of abbreviation in the languages of a collection, so as to
exclude the possibilitythat the law of abbreviation isfound many times simply because weare testing it
in many languages.
5 Results
In Section 1, we highlighted the importance of distinguishing between direct and indirect evidence of
compression. Against this theoretical backdrop, here we first investigate the presence of Zipf’s law of
abbreviation in languages. Then we investigate direct evidenceof compression with the help of the new
random baseline.
5.1 The law of abbreviation revisited
We investigate the presence of the law of abbreviation by means of left-sided correlation tests for the
association between frequency and length. We use both Kendall correlation, as suggested by theory on
the origins of the law (Ferrer-i-Cancho et al., 2019), and Pearson’s. For each language, we show the
significance level of the relationship, color-coded by the value of the correlation coefficient. Figure 1
(a,b) indicates that the law holds in all languages – regardless of the definition of word length – when
Kendall𝜏correlationisused. Inbothcollections,wefindKendall 𝜏correlationcoefficientssignificantat
the99%confidencelevel,exceptforDhivehiintheCVcollectionwhenlengthismeasuredincharacters,
and Abkhazian, Dhivehi, Panjabi and Vietnamese when length is measured in duration. However, note
that these are all still significant at the 95% confidence level. When Pearson correlation is used instead,
Figure 1 (c) shows that the picture remains the same in PUD. The main findings are the same also in
CV (Figure 1 (d)), but when length is measured in duration Panjabi ceases to be significant at the 95%
confidencelevel. Overall,weonlyfailtofindthelawofabbreviationinPanjabigivenworddurations,and
using Pearson correlation. This is most probably related to undersampling, as this particular language
only features 98 tokens (Table 5).
19https://stat.ethz.ch/R-manual/R-devel/library/stats/html/p.adjust.html
16Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
(a)
***
***
*********
***
************
******
***
******
*********
******
******
***
***
TurkishThaiSwedishSpanishRussianPortuguesePolishKoreanJapanese−strokesJapanese−romajiJapaneseItalianIndonesianIcelandicHindiGermanFrenchFinnishEnglishCzechChinese−strokesChinese−pinyinChineseArabic
characters
length definitionlanguage
−0.25−0.20−0.15−0.10corr (b)
***
******
***
***
******
******
*********
******
***
***
************
******
***************
***
******
******
***
*********
***
************
***
******
********
******
***
******
******
******
***
******
***
***
*********
******
***
*********
************
***
******
******
*********
******
******
********
**
**
**
YakutWestern FrisianWelshVietnameseUkrainianTurkishTatarTamilSwedishSpanishSlovenianRussianRomanshRomanianPortuguesePolishPersianPanjabiOriyaMongolianModern GreekMalteseLatvianKirghizKinyarwandaItalianIrishInterlinguaIndonesianHakha ChinGermanGeorgianFrenchEstonianEsperantoEnglishDutchDhivehiCzechChuvashCatalanBretonBasqueAssameseArabicAbkhazian
characters duration
length definitionlanguage
−0.3−0.2−0.1corr
(c)
******
***
*********
******
***
***
******
***
***
***
************
*********
***
***
TurkishThaiSwedishSpanishRussianPortuguesePolishKoreanJapanese−strokesJapanese−romajiJapaneseItalianIndonesianIcelandicHindiGermanFrenchFinnishEnglishCzechChinese−strokesChinese−pinyinChineseArabic
characters
length definitionlanguage
−0.16−0.14−0.12−0.10corr (d)
******
******
************
******
***
******
***
******
******
*********
***
***
***
*********
***
******
*********
***
******
******
******
******
*********
***
*********
***
*********
***************
******
***
***
******
*********
******
***
***
******
*********
*********
******
******
***
***
*********
******
*
YakutWestern FrisianWelshVietnameseUkrainianTurkishTatarTamilSwedishSpanishSlovenianRussianRomanshRomanianPortuguesePolishPersianPanjabiOriyaMongolianModern GreekMalteseLatvianKirghizKinyarwandaItalianIrishInterlinguaIndonesianHakha ChinGermanGeorgianFrenchEstonianEsperantoEnglishDutchDhivehiCzechChuvashCatalanBretonBasqueAssameseArabicAbkhazian
characters duration
length definitionlanguage
−0.3−0.2−0.1corr
Figure 1: The correlation between frequency and length across languages. ’***’ indicates a Holm-Bonferroni corrected
𝑝-valuelowerthanorequalto0.01,’**’indicateslowerthanorequalto0.05butsmallerthan0.1and’*’indicateslowerthan
or equal to 0.1. Here ’*’ symbols are not used to indicate significance but p-value ranges. (a) Kendall 𝜏correlation in PUD
(word length in characters). (b) Kendall 𝜏correlation in CV (left: word length in characters; right: word length in duration).
(c) Same as (a) with Pearson 𝑟correlation. (d) Same as (b) with Pearson 𝑟correlation.
17Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
5.2 Real word lengths versus the random baseline
We investigate the relationship between the actual mean word length ( 𝐿) and the random baseline ( 𝐿𝑟).
Wefindthat 𝐿 < 𝐿 𝑟foralllanguagesineverycollection(Figure2andTablesB3,B4,B5). Interestingly,
thereisalargegapbetween 𝐿and𝐿𝑟inthemajorityoflanguages,whichismorecompellinginCVwith
word durations (Figure 2). Exceptions to the large gap – as in the case of Panjabi and Abkhazian when
length is measured in duration – mainly concern languages with reduced sample sizes. The result holds
even when alternative units of measurement are considered for Chinese and Japanese.
Figure 2 is reminiscent of Figure 4 of Pimentel et al. (2021) but our setting is much simpler (it only
involves𝐿and𝐿𝑟).
18Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
(a)
ArabicIndonesian Russian
HindiCzech
German Icelandic
ItalianPolish
Swedish
JapaneseJapanese−strokes
Japanese−romaji
KoreanThai
ChineseChinese−strokes
TurkishFinnish
4812
5 10 15 20
LrL (b)
ArabicMaltese
VietnameseIndonesian
Esperanto
InterlinguaTamil
PersianAssameseRussian
Ukrainian
PanjabiModern Greek
BretonCatalan Czech
DutchEnglishFrenchGerman
IrishItalian
LatvianPolish
PortugueseRomanian Romansh
SlovenianSpanish
SwedishWelshWestern Frisian
Oriya
DhivehiGeorgian
Basque
MongolianKinyarwanda
Abkhazian
Hakha ChinChuvashKirghiz
TatarYakut
TurkishEstonian
4567
5 7 9
LrL
(c)
Arabic
Maltese
VietnameseIndonesianEsperanto
InterlinguaTamil
PersianAssamese RussianUkrainianPanjabi
Modern Greek
BretonCatalanCzech
DutchEnglish
FrenchGerman
IrishItalian LatvianPolish
PortugueseRomanianRomanshSlovenian
Spanish
SwedishWelsh
Western FrisianOriya
DhivehiGeorgian
Basque
MongolianKinyarwandaAbkhazian
Hakha ChinChuvashKirghiz
TatarYakut
TurkishEstonian
0.30.40.50.60.7
0.4 0.5 0.6 0.7 0.8
LrL
Figure 2: Mean word length ( 𝐿) as a function of the random baseline ( 𝐿𝑟) in languages. Every point stands for a language.
The diagonal (long dashed line) indicates the line 𝐿=𝐿𝑟. Languages with 𝐿 < 𝐿 𝑟are located below the diagonal. (a)
Languages in PUD with word length measured in characters (or strokes for Chinese and Japanese). (b) Languages in CV with
word length measured in characters. (c) Languages in CV with word length measured in duration (seconds).
5.3 Impact of disabling the filter of words that contain “foreign” characters
Allresultspresentedinthissectionhavebeenobtainedafterapplyingthenewmethodtofilterouthighly
unusual characters and words described in Section 4.4. If the filter is disabled, we obtain some slight
changes in the values, but the qualitative results summarized above remain the same.
19Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
6 Discussion
6.1 The universality of Zipf’s law
The first step of our analysis consisted in checking the universality of the law of abbreviation in the
languagesofoursamplesthroughaKendall 𝜏correlationtest. Here,weintroducedtwomethodological
improvements with respect to previous research: using the Bonferroni-Holm correction for 𝑝-values, as
well as word length in time given spoken utterances, rather than just characters in written form (Bentz
and Ferrer-i-Cancho, 2016). We also computed Pearson correlations for two reasons: (a) to verify the
robustness of the conclusions and (b) to check the significance of the gap between 𝐿and𝐿𝑟(the case
of (b) is addressed in the next subsection). We find that the law of abbreviation holds in nearly all
languages in our sample at a 95% confidence level, independently from how word length is measured,
andevenaftercontrollingformultipletesting. TheonlyexceptionisPanjabiinCV,butonlywhenlength
is measured in duration and Pearson 𝑟correlation is used. Panjabi is also the language suffering most
from under-sampling (only 98 tokens). Therefore, Panjabi cannot be considered a true exception to the
law of abbreviation.
Given the rather scarce evidence of the law of abbreviation in word durations in human language (Torre
et al., 2019), we have taken step forward by providing evidence of it in 46 languages from 14 linguistic
families. The massive agreement of the law of abbreviation even when orthographic word lengths are
replaced by word durations in human languages provides stronger support for the law of abbreviation
as a potentially universal pattern of human languages with respect to previous research relying on word
lengthincharacters(BentzandFerrer-i-Cancho,2016)andoftenonasmallnumberoflinguisticfamilies
().
6.2 Direct evidence of compression
Wehavefoundthatwordlengthsareshorterthanexpectedbychance( 𝐿 < 𝐿 𝑟)inalllanguagesinevery
collection (Figure 2). Such a systematic finding is unlikely to be accidental and strongly indicates that
compression is acting in all languages in our sample. Crucially, the finding holds independently of how
wordlengthismeasured. Theampleevidenceofcompressionevenwhenorthographicwordlengthsare
replacedbyworddurationsinhumanlanguagesprovidesstrongersupportforcompressionasauniversal
principle of the organization of languages with respect to previous research relying on word length in
characters (Ferrer-i-Cancho et al., 2013).
It could be argued that these findings constitute evidence of compression in ensembles of language but
not in individual languages. The reason is that 𝐿 < 𝐿 𝑟does not imply that the difference between the
actual word length and the random baseline is statistically significant for a single language. However,
20Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
we have shown that the Pearson correlation is indeed a linear function of 𝐿and𝐿𝑟(Appendix A) and
thus𝐿is significantly small in every language where the law of abbreviation has been confirmed using
a Pearson correlation test.
Finally, the direct correspondence we have established between the average length of types ( 𝑀) and the
random baseline sheds new light on previous research. For instance, it has been shown that 𝑀 < 𝐿in
Chinesecharactersinsixtimeperiodsspanningtwomillennia(Chenetal.,2015,Fig. 4),whichnowcan
be reinterpretedas asign of compressionof wordlengths inChinese in lightof ourtheoretical findings.
Future research
In this article, we have introduced a new random baseline and unveiled a systematic gap between that
randombaselineandrealmeanwordlengthsthatwehaveinterpretedasdirectevidenceofcompression.
Figure 2 suggests that the gap is wider when word lengths are measured in duration rather than in
characters. However, we have not quantified the magnitude of that gap and we have neither taken into
consideration the gap between actual mean words lengths and the minimum baseline, that would be
definedastheminimumwordlengththatcouldbeachievedundercertainconstraints(). Futureresearch
should quantify the first gap in relation to the minimum baseline. As the random baseline is crucial
to asses the degree of optimality of word lengths, we have paved the way for exploring the degree of
optimality of word lengths in characters or duration in languages.
Authors’ contributions
SP:Conceptualization,FormalAnalysis,Investigation,Software,Supervision,Validation,Visualization,
Writing-original draft, Writing-review & editing; ACM: Data curation, Resources, Software; JCM:
Writing-review & editing, Resources; MW: Writing-review & editing; CB: Conceptualization, Writing-
review & editing; RFC: Conceptualization, Formal analysis, Funding acquisition, Methodology, Project
Administration, Supervision, Writing-original draft, Writing-review & editing.
Acknowledgments
This article is one of the products of the research project of the 1st edition of the master degree course
“Introduction to Quantitative Linguistics” at Universitat Politècnica de Catalunya. We are specially
grateful to two students of that course: L. Alemany-Puig for helpful discussions and computational
support,andM.Michauxforcommentsonearlyversionsofthemanuscript. WethankM.FarrúsandA.
Hernández-Fernándezforadviceonvoicedatasets. WealsothankS.KomoriforadviceonJapanese,Y.
M.OhforadviceonKoreanandS.SempleforhelpingustoimproveEnglish. Lastbutnotleast,weare
very grateful to an anonymous reviewer for very helpful comments.
21Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
SP is funded by the grant ’Thesis abroad 2021/2022’ from the University of Milan. CB was partly
funded by the Deutsche Forschungsgemeinschaft (FOR 2237: Words, Bones, Genes, Tools - Tracking
Linguistic, Cultural and Biological Trajectories of the Human Past), and the Schweizerischer National-
fonds zur Förderung der Wissenschaftlichen Forschung (Non-randomness in Morphological Diversity:
AComputationalApproachBasedonMultilingualCorpora,176305). RFCissupportedbyarecognition
2021SGR-Cat (01266 LQMC) from AGAUR (Generalitat de Catalunya).
References
Balasubrahmanyan, V. K., Naranan, S. (1996). Quantitative linguistics and complex system studies. Journal of
Quantitative Linguistics ,3(3), 177–228. https://doi.org/10.1080/09296179608599629
Bentz, C., Ferrer-i-Cancho, R. (2016). Zipf’s law of abbreviation as a language universal. In C. Bentz, G. Jäger,
I. Yanovich (Eds.), Proceedings of the Leiden Workshop on Capturing Phylogenetic Algorithms for Linguistics .
University of Tübingen. http://hdl.handle.net/10900/68639
Börstell, C., Hörberg, T., Östling, R. (2016). Distribution and duration of signs and parts of speech in Swedish
Sign Language. Sign Language & Linguistics ,19, 143–196. https://doi.org/10.1075/sll.19.2.01bor
Chen, H., Liang, J., Liu, H. (2015). How does word length evolve in written Chinese? PLOS ONE ,10(9), 1–12.
https://doi.org/10.1371/journal.pone.0138567
Conover, W. J. (1999).Practical nonparametric statistics [3rd edition]. Wiley.
Cover, T. M., Thomas, J. A. (2006).Elements of information theory [2nd edition]. Wiley.
Deng,W.,Allahverdyan,A.E.,Li,B.,Wang,Q.A. (2014).Rank–frequencyrelationforChinesecharacters. The
European Physical Journal B ,87(2), 47. https://doi.org/10.1140/epjb/e2014-40805-2
Evans, N., Levinson, S. C. (2009). The myth of language universals: Language diversity and its importance for
cognitive science. Behavioral and Brain Sciences ,32, 429–492. https://doi.org/10.1017/s0140525x0999094x
Ferrer-i-Cancho, R., Bentz, C., Seguin, C. (2019). Optimal coding and the origins of Zipfian laws. Journal of
Quantitative Linguistics ,29(2), 165–194. https://doi.org/10.1080/09296174.2020.1778387
Ferrer-i-Cancho, R., Hernández-Fernández, A., Lusseau, D., Agoramoorthy, G., Hsu, M. J., Semple, S.
(2013). Compression as a universal principle of animal behavior. Cognitive Science ,37(8), 1565–1578. https:
//doi.org/10.1111/cogs.12061
Heesen, R., Hobaiter, C., Ferrer-i-Cancho, R., Semple, S. (2019). Linguistic laws in chimpanzee gestural
communication. Proceedings of the Royal Society B: Biological Sciences ,286, 20182900. https://doi.org/10.
12775/3991-1.039
Hernández-Fernández,A.,G.Torre,I.,Garrido,J.-M.,Lacasa,L. (2019).Linguisticlawsinspeech:Thecase
of Catalan and Spanish. Entropy,21(12). https://doi.org/10.3390/e21121153
22Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
Hernández-Fernández,A.,Torre,I.G. (2022).CompressionprincipleandZipf’sLawofbrevityininfochemical
communication. Biology Letters ,18, 20220162. https://doi.org/10.1098/rsbl.2022.0162
Kello, C. T., Brown, G. D. A., Ferrer-i-Cancho, R., Holden, J. G., Linkenkaer-Hansen, K., Rhodes, T.,
Orden, G. C. V. (2010). Scaling laws in cognitive sciences. Trends in Cognitive Sciences ,14(5), 223–232.
https://doi.org/10.1016/j.tics.2010.02.005
Koplenig, A., Kupietz, M., Wolfer, S. (2022). Testing the relationship between word length, frequency, and
predictability based on the German reference corpus. Cognitive Science ,46(6), e13090. https://doi.org/10.1111/
cogs.13090
Levshina, N. (2022). Frequency, informativity and word length: Insights from typologically diverse corpora.
Entropy,24(2). https://doi.org/10.3390/e24020280
Meylan, S. C., Griffiths, T. L. (2021). The challenges of large-scale, web-based language datasets: Word length
and predictability revisited. Cognitive Science ,45(6), e12983. https://doi.org/10.1111/cogs.12983
MorenoFernández,J. (2021).Theoptimalityofwordlengths[Master’sthesis,BarcelonaSchoolofInformatics].
http://hdl.handle.net/2117/361054
Naranan,S.,Balasubrahmanyan,V.K. (1993).Informationtheoreticmodelforfrequencydistributionofwords
and speech sounds (phonemes) in language. Journal of Scientific and Industrial Research ,52, 728–738.
Piantadosi,S.T.,Tily,H.,Gibson,E. (2011).Wordlengthsareoptimizedforefficientcommunication. Proceed-
ings of the National Academy of Sciences ,108(9), 3526–3529. https://doi.org/10.1073/pnas.1012551108
Pimentel, T., Nikkarinen, I., Mahowald, K., Cotterell, R., Blasi, D. (2021). How (non-)optimal is the lexicon?
NorthAmericanChapteroftheAssociationforComputationalLinguistics .https://doi.org/10.18653/v1/2021.naacl-
main.350
Sanada, H. (2008).Investigations in japanese historical lexicology . Peust & Gutschmidt Verlag.
Semple, S., Ferrer-i-Cancho, R., Gustison, M. (2022). Linguistic laws in biology. Trends in Ecology and
Evolution ,37(1), 53–66. https://doi.org/10.1016/j.tree.2021.08.012
Shannon, C. E. (1948). A mathematical theory of communication. Bell Systems Technical Journal ,27, 379–423,
623–656.
Torre, I. G., Luque, B., Lacasa, L., Kello, C. T., Hernández-Fernández, A. (2019). On the physical origin of
linguistic laws and lognormality in speech. Royal Society Open Science ,6(8), 191023. https://doi.org/10.1098/
rsos.191023
van den Heuvel, E., Zhan, Z. (2022). Myths about linear and monotonic associations: Pearson’s 𝑟, Spearman’s
𝜌, and Kendall’s 𝜏.The American Statistician ,76(1), 44–52. https://doi.org/10.1080/00031305.2021.2004922
Wang,Y.,Chen,X. (2015).StructuralcomplexityofsimplifiedChinesecharacters.InA.TuzziJ.M.M.Benesová
(Eds.),Recent contributions to quantitative linguistics (pp. 229–239). De Gruyter. https://doi.org/10.1515/
9783110420296-019
23Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
Watson,S.K.,Heesen,R.,Hedwig,D.,Robbins,M.M.,Townsend,S.W. (2020).AnexplorationofMenzerath’s
law in wild mountain gorilla vocal sequences. Biology Letters ,16, 20200380. https://doi.org/10.1098/rsbl.2020.
0380
Zipf, G. K. (1949).Human behaviour and the principle of least effort . Addison-Wesley.
Appendices
Appendix A Theory
Here we review the relationship between 𝐿,𝐿𝑟and Pearson correlation
Given two random variables 𝑥and𝑦and a sample of 𝑛points,{(𝑥1,𝑦1),...,(𝑥𝑖,𝑦𝑖),...,(𝑥𝑛,𝑦𝑛)}, the
sample covariance is defined as
𝑠𝑥𝑦=1
𝑛−1 𝑛∑︁
𝑖=1𝑥𝑖𝑦𝑖−𝑛¯𝑥¯𝑦!
,
where ¯𝑥is the sample mean of 𝑥and¯𝑦is the sample mean for 𝑦, i.e.
¯𝑥=1
𝑛𝑛∑︁
𝑖=1𝑥𝑖
¯𝑦=1
𝑛𝑛∑︁
𝑖=1𝑦𝑖.
Now consider than the random variables are 𝑝(the probability of a type) and 𝑙(the length/duration of a
type)insteadof 𝑥and𝑦. Thenoursampleof 𝑛pointsis{(𝑝1,𝑙1),...,(𝑝𝑖,𝑙𝑖),...,(𝑝𝑛,𝑙𝑛)},onepointper
type. Accordingly, the covariance between 𝑝and𝑙in a sample of points is
𝑠𝑝𝑙=1
𝑛−1 𝑛∑︁
𝑖=1𝑝𝑖𝑙𝑖−𝑛¯𝑝¯𝑙!
.
Recalling the definition of 𝐿(Equation 1) and noting that ¯𝑝=1
𝑛and¯𝑙=𝑀=𝐿𝑟(recall Property 2.1),
we finally obtain
𝑠𝑝𝑙=1
𝑛−1(𝐿−𝐿𝑟).
The sample Pearson correlation is
𝑟=𝑠𝑥𝑦
𝑠𝑥𝑠𝑦,
where𝑠𝑥and𝑠𝑦are the sample standard deviation of 𝑥and𝑦, i.e.
𝑠𝑥=vt
1
𝑛−1𝑛∑︁
𝑖=1(𝑥𝑖−¯𝑥)2
𝑠𝑦=vt
1
𝑛−1𝑛∑︁
𝑖=1(𝑦𝑖−¯𝑦)2.
24Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
Proceeding as we did for the covariance, we find that the Pearson correlation between 𝑝and𝑙is
𝑟=𝐿−𝐿𝑟
(𝑛−1)𝑠𝑝𝑠𝑙.
Then it is easy to see that 𝐿is a linear function of the Pearson correlation 𝑟or𝑠𝑝𝑙. For instance,
𝐿=𝑎𝑟+𝑏,
where
𝑎=(𝑛−1)𝑠𝑝𝑠𝑙
𝑏=𝐿𝑟.
Other linear relationships can be shown similarly.
Appendix B Analysis
We here present complementary analyses, tables and plots.
B.1 The impact of the unsupervised filter
Table B1 and Table B2 show the impact of the unsupervised filter in the optional filter. PUD is a
controlled setting for the impact of the filter because it is a collection where tokens are of high quality
compared to CV. Thus we expect that the impact of the optional filter is low in PUD. Unexpectedly,
the number of tokens reduces substantially (a reduction of the order of thousands) in Chinese, Japanese
and Korean. An additional drastic reduction in the observed alphabet size in these languages strongly
suggests that the optional filter is not adequate for them. For these reasons, we believe we should not
apply the unsupervised filter to these languages because their writing system is essentially a syllabary.
We suspect that the actual need for the exclusion could be a combination of sampling problems relating
toalargealphabetsize(comparedtotheLatinscript)andaheavy-tailedrankdistributionthatbreaksthe
optional filter. It is well-known that the rank distribution of Chinese characters is long-tailed, spanning
two orders of magnitude (Deng et al., 2014), while that of phonemes (the counterpart of letters in many
languages using the Latin script) is exponential-like (). However, that issue should be the subject of
future research.
In CV, we find that the optional filter has a similar impact in languages concerning the reduction in
the number of tokens but higher impacts concerning the reduction of the alphabet sizes, suggesting that
presence of strings with strange characters. The three languages with the most marked reduction in
alphabet size are French, Spanish, German and Italian, with an alphabet size greater then 100.
25Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
Table B1: The impactof the unsupervisedfilter in thePUD collection. For everylanguage, we showits linguistic family, the
writing system (namely script name according to ISO-15924) and various numeric parameters after applying the mandatory
filter but before applying the unsupervised filter, that are 𝐴, the observed alphabet size (number of distinct characters), 𝑛, the
number of types, and, 𝑇, the number of tokens. 𝐴′,𝑛′and𝑇′are the respective values of 𝐴,𝑛and𝑇after applying the
unsupervised filter.
Language Script Family 𝐴 𝐴′𝑛 𝑛′𝑇 𝑇′
Arabic Arabic Afro-Asiatic 47 39 6600 6596 18214 18201
Indonesian Latin Austronesian 39 23 4596 4501 16819 16702
Russian Cyrillic Indo-European 61 31 7358 7113 15870 15588
Hindi Devanagari Indo-European 84 50 4920 4716 21184 20796
Czech Latin Indo-European 49 33 7360 7073 15700 15331
English Latin Indo-European 39 25 5082 5001 18135 18028
French Latin Indo-European 48 26 5593 5214 21084 20407
German Latin Indo-European 39 28 6215 6116 18446 18331
Icelandic Latin Indo-European 43 32 6175 6035 16385 16209
Italian Latin Indo-European 42 24 5944 5606 21815 21266
Polish Latin Indo-European 47 31 7329 7188 15386 15191
Portuguese Latin Indo-European 47 38 5678 5661 21873 21855
Spanish Latin Indo-European 39 32 5765 5750 21083 21067
Swedish Latin Indo-European 39 25 5842 5624 16653 16378
Japanese Japanese Japonic 1549 609 4990 3345 24899 22538
Japanese-strokes Japanese Japonic 1549 609 4852 3345 24737 22538
Japanese-romaji Latin Japonic 23 19 4984 4860 24892 24743
Korean Hangul Koreanic 1002 401 8031 6424 14475 12540
Thai Thai Kra-Dai 89 52 3818 3599 21642 21121
Chinese Han (Traditional variant) Sino-Tibetan 2038 814 5224 3154 18129 15436
Chinese-strokes Han (Traditional variant) Sino-Tibetan 2038 814 4970 3154 17845 15436
Chinese-pinyin Latin Sino-Tibetan 49 44 5224 5038 18129 17885
Turkish Latin Turkic 42 28 6793 6587 14092 13799
Finnish Latin Uralic 39 24 7076 6938 12853 12701
26Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
Table B2: The impact of the unsupervised filter in the CV collection. The content is the same as in Table B1. ’Conlang’
stands for ’constructed language’, that is an artificially created language. This is not a family in the proper sense as Conlang
languages are not related in the common linguistic family sense.
Language Script Family 𝐴 𝐴′𝑛 𝑛′𝑇 𝑇′
Arabic Arabic Afro-Asiatic 44 31 7497 6397 49448 45825
Maltese Latin Afro-Asiatic 40 31 8148 8058 44272 44112
Vietnamese Latin Austroasiatic 86 41 574 370 1300 938
Indonesian Latin Austronesian 28 22 3817 3768 44336 44210
Esperanto Latin Conlang 38 27 27932 27759 406725 406261
Interlingua Latin Conlang 27 20 5552 5126 31428 30504
Tamil Tamil Dravidian 44 29 1525 1210 7580 6439
Persian Arabic Indo-European 105 38 13240 13115 1665428 1662508
Assamese Assamese Indo-European 60 43 1115 971 2000 1813
Russian Cyrillic Indo-European 54 32 31921 31827 638782 637686
Ukrainian Cyrillic Indo-European 44 34 14399 14337 120984 120760
Panjabi Devanagari Indo-European 48 37 95 84 110 98
Modern Greek Greek Indo-European 46 33 5834 5813 37926 37880
Breton Latin Indo-European 41 28 4322 4228 38493 38237
Catalan Latin Indo-European 67 39 79213 79112 3294506 3294206
Czech Latin Indo-European 44 33 16032 15518 150312 147582
Dutch Latin Indo-European 41 23 10666 10225 320992 316498
English Latin Indo-European 97 28 173522 173023 9829660 9828713
French Latin Indo-European 244 49 162740 160243 3732822 3729370
German Latin Indo-European 152 30 150362 148436 4235094 4230565
Irish Latin Indo-European 31 23 2311 2251 22751 22593
Italian Latin Indo-European 110 34 55480 54996 812604 811783
Latvian Latin Indo-European 35 27 7792 7251 30358 29456
Polish Latin Indo-European 38 32 25365 25340 595613 595411
Portuguese Latin Indo-European 41 27 13049 11509 295042 283048
Romanian Latin Indo-European 36 29 6449 6423 33370 33341
Romansh Latin Indo-European 40 26 9801 9614 44192 43792
Slovenian Latin Indo-European 28 24 5994 5937 26402 26304
Spanish Latin Indo-European 186 33 75617 75010 1843646 1842474
Swedish Latin Indo-European 30 25 4454 4371 63282 62951
Welsh Latin Indo-European 43 22 11488 11143 547345 539621
Western Frisian Latin Indo-European 42 30 8419 8383 63127 63073
Oriya Odia Indo-European 59 41 921 764 1929 1700
Dhivehi Thaana Indo-European 40 27 155 111 1388 1284
Georgian Georgian Kartvelian 34 25 7945 6505 15481 12958
Basque Latin Language isolate 28 21 24998 24748 460188 458071
Mongolian Mongolian Mongolic 36 31 14844 14608 70638 70217
Kinyarwanda Latin Niger-Congo 96 26 135328 133815 1945038 1939810
Abkhazian Cyrillic Northwest Caucasian 37 28 150 119 189 156
Hakha Chin Latin Sino-Tibetan 28 23 2515 2499 17806 17776
Chuvash Cyrillic Turkic 36 22 5565 4311 16270 13583
Kirghiz Cyrillic Turkic 38 30 10497 10130 62687 61844
Tatar Cyrillic Turkic 47 34 22313 21823 145458 144356
Yakut Cyrillic Turkic 42 28 8041 7904 22795 22577
Turkish Latin Turkic 37 31 8957 8926 107910 107686
Estonian Latin Uralic 34 23 30135 28691 123895 121549
B.2 Mean word length and the law of abbreviation
In Table B3, Table B4 and Table B5, we show the mean word length ( 𝐿) and the random baseline ( 𝐿𝑟)
as well as the outcome of the correlation test between length and frequency for PUD and for CV when
length is measured in characters and also in duration, respectively.
27Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
TableB3: MeanwordlengthandthecorrelationbetweenfrequencyandlengthinPUD.Wordlengthismeasuredinnumberof
characters. Mean word length ( 𝐿) is followed by the random baseline ( 𝐿𝑟). Each correlation statistic (Kendall 𝜏or Pearson𝑟)
is followed by p-values after applying Holm-Bonferroni correction (rather than being the direct output of the correlation test).
language family script 𝐿 𝐿 𝑟𝜏 𝜏 𝑝𝑣𝑎𝑙𝑢𝑒 𝑟 𝑟 𝑝𝑣𝑎𝑙𝑢𝑒
Arabic Afro-Asiatic Arabic 4.03 5.54 -0.13 8.32×10−32-0.13 1.12×10−20
Czech Indo-European Latin 5.44 7.27 -0.22 1.20×10−113-0.15 2.47×10−36
English Indo-European Latin 4.87 7.00 -0.20 2.52×10−66-0.12 6.98×10−17
French Indo-European Latin 4.81 7.47 -0.16 2.44×10−49-0.12 4.24×10−19
German Indo-European Latin 5.74 8.56 -0.23 1.25×10−108-0.12 3.85×10−21
Indonesian Austronesian Latin 5.96 7.35 -0.11 6.37×10−21-0.12 6.53×10−15
Italian Indo-European Latin 4.85 7.64 -0.16 4.09×10−54-0.13 8.45×10−23
Polish Indo-European Latin 6.07 8.00 -0.19 1.12×10−80-0.13 2.78×10−26
Portuguese Indo-European Latin 4.35 7.47 -0.20 9.96×10−67-0.12 1.12×10−17
Russian Indo-European Cyrillic 6.04 8.08 -0.19 4.58×10−88-0.13 4.85×10−26
Spanish Indo-European Latin 4.83 7.59 -0.16 4.10×10−51-0.11 1.89×10−17
Swedish Indo-European Latin 5.41 7.99 -0.23 3.99×10−101-0.13 6.28×10−21
Turkish Turkic Latin 6.43 7.94 -0.24 4.26×10−124-0.12 4.20×10−23
28Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
TableB4: MeanwordlengthandthecorrelationbetweenfrequencyandlengthinCV.Wordlengthismeasuredinnumberof
characters. Content is the same as in B3. ’Conlang’ stands for ’constructed language’, that is an artificially created language.
This is not a family in the proper sense, and Conlang languages are not related in the common family sense.
language family script 𝐿 𝐿 𝑟𝜏 𝜏 𝑝𝑣𝑎𝑙𝑢𝑒 𝑟 𝑟 𝑝𝑣𝑎𝑙𝑢𝑒
Abkhazian Northwest Caucasian Cyrillic 5.94 6.42 -0.32 4.48×10−5-0.29 1.43×10−3
Arabic Afro-Asiatic Arabic 4.10 5.06 -0.14 5.32×10−43-0.14 2.04×10−28
Assamese Indo-European Assamese 4.57 5.36 -0.31 4.73×10−31-0.27 3.09×10−17
Basque Language isolate Latin 6.41 8.89 -0.16 2.68×10−262-0.11 6.95×10−69
Breton Indo-European Latin 3.97 6.31 -0.24 4.93×10−86-0.19 4.09×10−35
Catalan Indo-European Latin 4.90 8.58 -0.15 0.00 -0.05 9.53×10−51
Chuvash Turkic Cyrillic 6.00 7.35 -0.22 5.49×10−74-0.21 3.80×10−43
Czech Indo-European Latin 4.83 7.17 -0.22 1.75×10−295-0.13 1.69×10−58
Dhivehi Indo-European Thaana 3.32 7.61 -0.16 1.65×10−2-0.31 1.24×10−3
Dutch Indo-European Latin 4.72 8.26 -0.28 0.00 -0.10 1.35×10−24
English Indo-European Latin 4.61 7.79 -0.07 0.00 -0.03 3.45×10−45
Esperanto Conlang Latin 4.83 7.73 -0.18 0.00 -0.08 1.12×10−41
Estonian Uralic Latin 6.16 8.85 -0.24 0.00 -0.09 2.55×10−48
French Indo-European Latin 5.04 8.13 -0.04 3.57×10−85-0.04 8.56×10−46
Georgian Kartvelian Georgian 7.17 8.22 -0.12 3.67×10−31-0.10 3.47×10−15
German Indo-European Latin 5.73 10.30 -0.12 0.00 -0.04 4.21×10−59
Hakha Chin Sino-Tibetan Latin 3.29 5.29 -0.29 4.31×10−72-0.15 3.88×10−13
Indonesian Austronesian Latin 5.37 7.24 -0.20 1.13×10−59-0.16 2.73×10−21
Interlingua Conlang Latin 4.43 7.43 -0.24 8.95×10−101-0.16 7.39×10−31
Irish Indo-European Latin 4.20 6.58 -0.21 2.38×10−41-0.17 5.18×10−15
Italian Indo-European Latin 5.29 8.16 -0.06 2.24×10−67-0.06 4.19×10−49
Kinyarwanda Niger-Congo Latin 6.13 9.20 -0.19 0.00 -0.06 3.32×10−117
Kirghiz Turkic Cyrillic 6.01 7.78 -0.19 1.45×10−141-0.16 6.13×10−57
Latvian Indo-European Latin 4.79 7.09 -0.26 5.81×10−160-0.18 1.36×10−53
Maltese Afro-Asiatic Latin 5.07 7.35 -0.20 2.32×10−107-0.14 1.58×10−36
Modern Greek Indo-European Greek 4.85 7.64 -0.24 3.73×10−124-0.16 1.77×10−34
Mongolian Mongolic Mongolian 5.47 7.31 -0.23 1.73×10−263-0.15 2.31×10−76
Oriya Indo-European Odia 4.21 5.35 -0.33 2.00×10−28-0.31 2.94×10−17
Panjabi Indo-European Devanagari 3.68 3.88 -0.32 8.69×10−4-0.26 8.60×10−3
Persian Indo-European Arabic 3.80 5.49 -0.21 2.38×10−229-0.12 2.06×10−45
Polish Indo-European Latin 5.27 7.87 -0.17 8.03×10−292-0.10 2.47×10−58
Portuguese Indo-European Latin 4.53 7.49 -0.19 1.09×10−168-0.13 1.21×10−41
Romanian Indo-European Latin 5.03 7.67 -0.21 3.27×10−97-0.17 6.46×10−41
Romansh Indo-European Latin 4.94 7.56 -0.24 5.91×10−184-0.15 5.42×10−48
Russian Indo-European Cyrillic 6.31 9.00 -0.13 7.75×10−225-0.09 3.03×10−52
Slovenian Indo-European Latin 4.56 6.43 -0.21 1.47×10−88-0.15 4.71×10−29
Spanish Indo-European Latin 5.01 7.92 -0.03 5.95×10−32-0.04 3.48×10−29
Swedish Indo-European Latin 4.04 6.87 -0.28 6.91×10−129-0.15 1.62×10−22
Tamil Dravidian Tamil 5.68 7.08 -0.28 1.01×10−35-0.23 5.21×10−16
Tatar Turkic Cyrillic 5.41 7.45 -0.24 0.00 -0.16 3.15×10−118
Turkish Turkic Latin 6.00 8.09 -0.22 1.32×10−158-0.16 2.51×10−48
Ukrainian Indo-European Cyrillic 5.52 7.67 -0.16 3.01×10−136-0.14 1.74×10−61
Vietnamese Austroasiatic Latin 3.24 3.47 -0.19 2.98×10−5-0.20 1.96×10−4
Welsh Indo-European Latin 4.17 7.05 -0.21 2.40×10−185-0.12 4.39×10−38
Western Frisian Indo-European Latin 4.38 7.99 -0.29 1.19×10−244-0.13 2.62×10−33
Yakut Turkic Cyrillic 6.32 7.99 -0.26 5.48×10−185-0.19 2.12×10−65
29Petrini, Casas-i-Muñoz, Cluet-i-Martinell, Wang, Bentz & Ferrer-i-Cancho Direct and indirect evidence of compression of word lengths.
Table B5: Mean word length and the correlation between frequency and length in CV. Word length is measured in duration.
Content is the same as in B4.
language family script 𝐿 𝐿 𝑟𝜏 𝜏 𝑝𝑣𝑎𝑙𝑢𝑒 𝑟 𝑟 𝑝𝑣𝑎𝑙𝑢𝑒
Abkhazian Northwest Caucasian Cyrillic 0.74 0.81 -0.20 1.23×10−2-0.21 2.52×10−2
Arabic Afro-Asiatic Arabic 0.46 0.58 -0.12 1.75×10−40-0.15 2.00×10−31
Assamese Indo-European Assamese 0.43 0.50 -0.22 1.25×10−17-0.19 3.14×10−9
Basque Language isolate Latin 0.44 0.63 -0.21 0.00 -0.12 1.29×10−78
Breton Indo-European Latin 0.31 0.51 -0.25 1.92×10−107-0.20 4.94×10−39
Catalan Indo-European Latin 0.35 0.68 -0.21 0.00 -0.06 8.70×10−69
Chuvash Turkic Cyrillic 0.44 0.54 -0.26 1.18×10−116-0.22 6.89×10−49
Czech Indo-European Latin 0.37 0.57 -0.21 6.40×10−295-0.14 5.07×10−70
Dhivehi Indo-European Thaana 0.32 0.71 -0.17 2.40×10−2-0.24 1.51×10−2
Dutch Indo-European Latin 0.29 0.55 -0.28 0.00 -0.12 1.47×10−33
English Indo-European Latin 0.33 0.67 -0.17 0.00 -0.04 4.83×10−62
Esperanto Conlang Latin 0.49 0.81 -0.18 0.00 -0.09 1.25×10−47
Estonian Uralic Latin 0.39 0.58 -0.23 0.00 -0.09 4.65×10−55
French Indo-European Latin 0.32 0.63 -0.21 0.00 -0.04 7.25×10−71
Georgian Kartvelian Georgian 0.52 0.61 -0.15 6.51×10−51-0.12 9.17×10−21
German Indo-European Latin 0.37 0.76 -0.22 0.00 -0.05 1.57×10−96
Hakha Chin Sino-Tibetan Latin 0.29 0.44 -0.25 9.56×10−64-0.14 1.10×10−11
Indonesian Austronesian Latin 0.38 0.52 -0.22 1.29×10−76-0.17 8.41×10−26
Interlingua Conlang Latin 0.40 0.69 -0.24 9.77×10−114-0.18 3.80×10−36
Irish Indo-European Latin 0.30 0.47 -0.24 1.42×10−55-0.19 1.02×10−19
Italian Indo-European Latin 0.38 0.65 -0.19 0.00 -0.08 4.19×10−87
Kinyarwanda Niger-Congo Latin 0.44 0.72 -0.21 0.00 -0.06 7.54×10−101
Kirghiz Turkic Cyrillic 0.44 0.57 -0.20 1.38×10−159-0.16 1.63×10−55
Latvian Indo-European Latin 0.39 0.59 -0.23 1.70×10−141-0.19 4.58×10−60
Maltese Afro-Asiatic Latin 0.35 0.54 -0.21 9.96×10−140-0.15 3.89×10−42
Modern Greek Indo-European Greek 0.38 0.63 -0.21 3.20×10−105-0.17 1.46×10−37
Mongolian Mongolic Mongolian 0.36 0.48 -0.25 0.00 -0.15 3.12×10−73
Oriya Indo-European Odia 0.39 0.49 -0.33 2.21×10−31-0.32 1.59×10−18
Panjabi Indo-European Devanagari 0.70 0.73 -0.18 4.63×10−2-0.15 8.44×10−2
Persian Indo-European Arabic 0.36 0.54 -0.25 0.00 -0.14 4.66×10−58
Polish Indo-European Latin 0.38 0.57 -0.17 0.00 -0.12 2.88×10−82
Portuguese Indo-European Latin 0.35 0.61 -0.22 1.15×10−243-0.15 4.38×10−59
Romanian Indo-European Latin 0.36 0.57 -0.23 2.49×10−127-0.17 2.82×10−43
Romansh Indo-European Latin 0.41 0.66 -0.26 7.70×10−248-0.17 2.06×10−64
Russian Indo-European Cyrillic 0.42 0.60 -0.15 2.13×10−299-0.10 5.30×10−75
Slovenian Indo-European Latin 0.44 0.63 -0.25 3.37×10−146-0.17 3.04×10−40
Spanish Indo-European Latin 0.36 0.62 -0.14 0.00 -0.05 2.05×10−41
Swedish Indo-European Latin 0.27 0.52 -0.29 1.03×10−156-0.18 4.76×10−32
Tamil Dravidian Tamil 0.54 0.66 -0.31 2.06×10−48-0.22 5.35×10−14
Tatar Turkic Cyrillic 0.38 0.52 -0.26 0.00 -0.17 8.68×10−141
Turkish Turkic Latin 0.41 0.54 -0.21 7.11×10−158-0.16 9.43×10−50
Ukrainian Indo-European Cyrillic 0.43 0.59 -0.18 3.01×10−176-0.16 3.53×10−86
Vietnamese Austroasiatic Latin 0.29 0.33 -0.07 4.63×10−2-0.14 1.40×10−2
Welsh Indo-European Latin 0.32 0.58 -0.20 6.25×10−197-0.15 3.21×10−58
Western Frisian Indo-European Latin 0.32 0.61 -0.31 0.00 -0.15 8.59×10−43
Yakut Turkic Cyrillic 0.43 0.54 -0.25 2.41×10−186-0.18 9.50×10−58
30