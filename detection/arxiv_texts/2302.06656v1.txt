Enhancing User Personalization in Conversational
Recommenders
Allen Lin
Texas A&M University
College Station, Texas, USA
al001@tamu.eduZiwei Zhu
George Mason University
Fairfax, Virginia, USA
zzhu20@gmu.edu
Jianling Wang
Texas A&M University
College Station, Texas, USA
jlwang@tamu.eduJames Caverlee
Texas A&M University
College Station, Texas, USA
caverlee@tamu.edu
ABSTRACT
Conversational recommenders are emerging as a powerful tool
to personalize a user‚Äôs recommendation experience. Through a
back-and-forth dialogue, users can quickly hone in on just the right
items. Many approaches to conversational recommendation, how-
ever, only partially explore the user preference space and make
limiting assumptions about how user feedback can be best incor-
porated, resulting in long dialogues and poor recommendation
performance. In this paper, we propose a novel conversational rec-
ommendation framework with two unique features: (i) a greedy
NDCG attribute selector , to enhance user personalization in the inter-
active preference elicitation process by prioritizing attributes that
most effectively represent the actual preference space of the user;
and (ii) a user representation refiner , to effectively fuse together the
user preferences collected from the interactive elicitation process
to obtain a more personalized understanding of the user. Through
extensive experiments on four frequently used datasets, we find the
proposed framework not only outperforms all the state-of-the-art
conversational recommenders (in terms of both recommendation
performance and conversation efficiency), but also provides a more
personalized experience for the user under the proposed multi-
groundtruth multi-round conversational recommendation setting.
CCS CONCEPTS
‚Ä¢Information systems ‚ÜíRecommender systems .
KEYWORDS
Conversational Recommender System, User Personalization
1 INTRODUCTION
Conversational recommender systems (CRSs) have attracted in-
creasing attention in the research community due to their wide
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
WWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA
¬©2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-9416-1/23/04. . . $15.00
https://doi.org/10.1145/3543507.3583192range of potential applications and promising functionality [ 2,12,
25,30]. Rather than inferring from past user-item interactions,
a CRS directly engages with the user through a conversation to
learn the user‚Äôs current and fine-grained preferences. Such a con-
versational approach can provide recommendations that are both
highly personalized and justifiable. While several settings have
been proposed to formulate the task of conversational recommen-
dation, in this work, we focus on the multi-round conversational
recommendation (MCR) setting, which is widely perceived to be
the most realistic setting so far [ 2,12,17,30,34]. Under the MCR
setting, a conversational recommender system starts with the in-
teractive preference elicitation process in which the system explores
the preference space of the user, via asking the user‚Äôs preferences
on certain attributes (e.g., are you looking for country music?), to
obtain an accurate estimation of the user‚Äôs current interests. Based
on the learned preferences of the user, the system recommends the
top-ùëòitems that best match the user‚Äôs current interests.
The MCR setting has shown promising results across many rec-
ommendation tasks (e.g., music recommendations [ 25,30], business
recommendations [ 12,13], and E-Commerce [ 2]), yet it makes a
strict assumption ‚Äì that a user only has one target-item in mind
when interacting with the system. In reality, users often have di-
verse preferences which makes them simultaneously interested in a
wide variety of items [ 21,22,26,36]. Take music recommendations
as an example, while Alice likes the popstyle song ‚ÄòShape of You‚Äô,
she also finds a country style song ‚Äì such as ‚ÄòSomebody like you‚Äô
‚Äì enjoyable to listen. In this situation, designing and evaluating
a CRS with such a strong single-groundtruth assumption greatly
limits the generalizability of the system.
Hence, we extend the MCR setting to the multi-groundtruth
multi-round conversational recommendation (MGMCR) setting,
under which the CRS is designed and evaluated with the realistic
formulation that a user could be simultaneously interested in a
variety of items. This MGMCR setting is more challenging than
the traditional MCR setting, as the CRS now aims to discover all
the groundtruth items of the user. The key in achieving promis-
ing recommendation performance lies in the effectiveness of user
personalization in the system. Specifically, we identify two key chal-
lenges that existing works face under the MGMCR setting:
(1)lack of user personalization in interactive preference elicitation :
During the interactive preference elicitation process, a CRS aims to
explore a user‚Äôs preference space by asking the user‚Äôs preferencearXiv:2302.06656v1  [cs.IR]  13 Feb 2023WWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA Allen Lin, Ziwei Zhu, Jianling Wang, and James Caverlee
on a set of domain specific attributes. Since every user has unique
preferences, a CRS must prioritize on asking the attributes that the
user would consider relevant in expressing her actual preference
space. Although there are some differences among how existing
CRSs decide on which attribute(s) to prioritize for a specific user,
most of them rely heavily on the use of entropy , which does not
provide sufficient granularity for the system to identify the most
relevant attribute(s) for the user. Such an issue could even be exacer-
bated under the MGMCR setting given the user now has a broader
preference space. In turn, the asked attributes often result in a
sub-optimal representation of the user‚Äôs actual preference space,
resulting in poor recommendation performance.
(2)lack of user personalization in preference fusion : To achieve per-
sonalized recommendations for the user, a CRS must fuse together
the user‚Äôs preferences ‚Äì collected in the interactive preference elic-
itation process ‚Äì to form a personalized understanding of the user.
To do that, many existing works [ 2,12,13,30] have adopted the use
ofattribute-filtering in which the system treats every item that does
not align perfectly with the collected preferences as a mismatch for
the user. This approach has two limitations under the MGMCR set-
ting. First, many groundtruth items could be mistakenly considered
as mismatches. For instance, Alice is interested in both the action
movie, Top Gun: Maverick, and the comedy movie, Despicable Me.
So when the system asks Alice if she is looking for a comedy movie,
Alice will respond with a confirmation. However, with the attribute
comedy added to her set of collected preference, Top Gun: Maverick
would now be considered as a mismatch for Alice since it does not
contain the attribute comedy . Second, it does not take the user‚Äôs past
interests into consideration, overlooking the scenario where the
same preference could indicate different signals for different users.
For a user who has rarely watched horror movies, a confirmation
on the attribute horror could indicate a stronger shift in preference
compared to a user who has frequently watched horror movies.
To address the aforementioned challenges, we propose a novel
framework for enhancing userpersonalization in conversational
recommendation systems (UpsRec). To enhance user personaliza-
tion in the interactive preference elicitation process, the framework
adopts an NDCG-oriented greedy attribute selection strategy in
which the system directly prioritizes on asking the attributes that
most effectively personalize the recommended items for each user.
And to enhance user personalization in fusing the collected user
preferences, the framework deploys a user representation refiner to
iteratively refine the initial user representation learned from past
interactions. With the refined representation being a more accurate
reflection of the user‚Äôs current interests, items no longer need to
be filtered to ease the difficulty of ranking, avoiding the scenario
of mistakenly excluding groundtruth items. In summary, the main
contributions of this work are as follows:
‚Ä¢We are the first to comprehensively study the MGMCR scenario
for conversational recommendation, which is more realistic and
generalizable than the existing MCR setting.
‚Ä¢We propose the UpsRec framework with unique features de-
signed to provide personalized experiences for the users and
effectively guide them to their items of interest.‚Ä¢We show the proposed UpsRec framework significantly outper-
forms state-of-the-art CRS methods by an average of 23%, while
requiring fewer interactions with the user.
2 PRELIMINARIES
In this section, we provide a brief introduction on multi-round
conversational recommendation (MCR), which is the most widely
adopted setting for conversational recommendation [ 2,12,13,30].
Formally, let ùëâdenote the itemset, and ùëÉ=(ùëù0,ùëù1,...,ùëùùëö)de-
note a set of ùëödomain-specific attributes that describe an item
ùë£‚ààùëâ. During each conversation session, a CRS aims to first learn
the user‚Äôs fine-grained preferences on the asked attributes, then
provides personalized recommendations. A conversation session
starts by the user specifying an attribute ùëù0contained in the target
item(s) that she is asking the system to find (e.g., Can you find me
some country music?). Next, a CRS calls upon its conversation com-
ponent to decide whether to ask the user more attributes or make a
recommendation. If the policy agent decides not enough preference
evidence has been collected, it will pick one attribute ùëùfrom the set
of unasked attributes ùëÉùëêùëéùëõùëë to prompt the user. If the user likes the
asked attribute, then policy agent updates the set of collected pref-
erences of the user, ùëÉùë¢, by adding ùëùtoùëÉùë¢; otherwise ùëÉùë¢remains
unchanged. If the policy agent decides enough information has
been collected after ùë°turns of interaction, the CRS then calls upon
its recommender component to make a list of recommendations.
The recommender component would then rank all the items in
the candidate itemset ùëâùëêùëéùëõùëë ‚Äì the itemset that contains only items
with attributes perfectly matching all specified preferences in ùëÉùë¢‚Äì
then recommends the top-K ranked items to display to the user. If
the user accepts the recommendation, then the system quits. If the
user rejects all the recommended items, the system first removes
the rejected item ùëâùëüùëíùëófromùëâùëêùëéùëõùëë then repeats the cycle by calling
upon its conversational component to decide the next action to
take. This process continues until the user quits due to impatience
or a predefined maximum number of turns has been reached.
Multi-round Multi-Groundtruth Setting. Although MCR is cur-
rently perceived as one of the most realistic settings for conversa-
tional recommendation, it makes the limiting assumption that a
user only has one item of interest when interacting with the sys-
tem. Therefore, we propose the new multi-round multi-groundtruth
(MGMCR) setting, which makes the following changes: (1). when
being asked by the system on the preference towards an attribute ùëù,
the user is now assumed to answer according to the attributes asso-
ciated with allher groundtruth items (i.e., can be one or multiple),
which more realistically mimics how a user would interact with
a CRS; and (2). the system now only generates one conversation
session for each user ùë¢, instead of a new conversation session for
each observed user-item interaction pair of the user.
3 PROPOSED FRAMEWORK
In this section, we introduce a novel framework for enhancing
userpersonalization in conversational recommendation systems,
namely UpsRec. UpsRec is designed to tackle two key challenges: (i)
how to bring user personalization to interactive preference elicita-
tion; and (ii) how to bring user personalization to preference fusion.Enhancing User Personalization in Conversational Recommenders WWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA
Specifically, we design a greedy NDCG attribute selector that per-
sonalizes the interactive preference elicitation process by utilizing
an NDCG-oriented attribute selection strategy to prioritize on at-
tributes that most effectively represent the actual preference space
of the user. Then, to effectively fuse together the user preferences
collected from the interactive preference elicitation process, a user
representation refiner is deployed to iteratively refine the current
representation of the user.
The framework starts with the latent interest estimation stage
where the system builds an initial predictive model to estimate the
interest of users by learning a set of latent representations from the
historical user-item interactions. Then a reinforcement learning
based policy agent, integrated with both the greedy NDCG attribute
selector and the user representation refiner , is deployed to decide how
to interact with the user. Together, the entire flow of the proposed
UpsRec framework is detailed in Algorithm 1.
Algorithm 1: UpsRec
Input : the user-item interaction matrix M; the
item-attribute information Dictionary Dùëù; userùë¢;
a matrix containing the adjacent attributes of all
users Pùëéùëëùëó(see Section 3.2 for details); all items ùëâ;
the number of items to recommend ùëò; the
maximum number of turns ùëá
Output: k recommended items
1Set:Rùëà,Rùëâ,RùëÉ=Latent Interest Estimation (M,Dùëù)
2Initialize: rùë¢0=Rùëà[ùë¢];rùë¢ùë°=Rùëà[ùë¢]
3Initialize:ùëÉùë¢={};ùëÉùëêùëéùëõùëë =Pùëéùëëùëó[ùë¢];ùëâùëêùëéùëõùëë=ùëâ
4forturnùë°=1,2,3...ùëádo
5 Policy Agent selects an action ùëé
ifùëé==ùëéùëéùë†ùëòthen
6ùëùùëéùë†ùëò=Greedy NDCG Attribute Selector (rùë¢0,rùë¢ùë°,ùëÉùë¢,
ùëÉùëêùëéùëõùëë)
Update:ùëÉùëêùëéùëõùëë =ùëÉùëêùëéùëõùëë\pùëéùë†ùëò
ifùë¢acceptsùëùùëéùë†ùëòthen
7 Update:ùëÉùë¢=ùëÉùë¢‚à™pùëéùë†ùëò
Set:rùë¢ùë°=User Representation Refiner (rùë¢0,ùëÉùë¢)
8 else
9 Rank all items in ùëâùëêùëéùëõùëë
10 Recommends the top ùëòranked items, ùëâùëüùëíùëê, toùë¢;
11 ifùë¢acceptsùëâùëüùëíùëêthen
12 Returnùëâùëüùëíùëê; Exit.
13 else
14 Update :ùëâùëêùëéùëõùëë=ùëâùëêùëéùëõùëë\ùëâùëüùëíùëê
15 end if
16 end if
17end for
3.1 Latent Interest Estimation
The goal of the Latent Interest Estimation stage is to learn an initial
set of latent representations for all users, items, and attributes ‚Äì de-
noted respectively as Rùëà,Rùëâ,RùëÉ‚Äì that will later be used through-
out the framework. Following [ 12,13,29], we adopt a factorization
machine [ 23] (FM) as the predictive model. Given user ùë¢, the user‚Äôscollected preferences ùëÉùë¢, and an item ùë£,ùë¢‚Äôs predicted interest in ùë£
is computed as:
ùë¶(ùë¢,ùë£,ùëÉùë¢)=rùëá
ùë¢rùë£+‚àëÔ∏Å
ùëùùëñ‚ààùëÉùë¢rùëá
ùë£rùëùùëñ (1)
where rùë¢andrùë£respectively denote the latent representation of
userùë¢and itemùë£, and rùëùùëñdenotes the latent representation for at-
tributeùëùùëñ‚ààùëÉùë¢. As shown in [ 15], re-weighting an item‚Äôs relevance
based on its frequency in the training set results in more effective
learned latent representations. Therefore, we modify the standard
pairwise Bayesian Personalized Ranking (BPR) objective function
[24] to a weighted variation as follows:
ùêø=1
ùëíùëõ1ùëìùëñ[‚àíùëôùëõùúé(ùë¶(ùë¢,ùë£,ùëÉùë¢))‚àíùúé(ùë¶(ùë¢,ùë£‚Ä≤,ùëÉùë¢))]+ùëíùëõ2ùëìùëñ||v||2
+ùúÜ^ùúÉ(||ÀÜùúÉ||2)(2)
whereùëídenotes the natural log; ùëìùëñdenotes the interaction fre-
quency of the item ùë£;1
ùëíùëõ1ùëìùëñcontrols the relevance of the item ùë£to
the loss function; and ùëíùëõ2ùëìùëñcontrols the scale of the regularization
on the item‚Äôs learned latent representation v. Andùëõ1andùëõ2de-
note hyperparameters that control the impact of the interaction
frequency on ùë£‚Äôs relevance and regularization scale, and ùúÜùúÉdenotes
the regularization parameter to prevent overfitting.
3.2 Greedy NDCG Attribute Selector
Once the conversation begins, how do we personalize the elicita-
tion of a user‚Äôs preferences? To achieve this, we propose a greedy
NDCG attribute selector which utilizes an NDCG-oriented attribute
selection strategy to help the CRS identify the attributes that most
effectively represent the current preference space of the user. Since
the eventual goal of a CRS is to make accurate recommendations
for the user, we consider the effectiveness of an attribute equivalent
to how much it can increase the recommendation performance.
That is, after being asked by the system, how much can knowing
the user‚Äôs preference on that particular attribute contribute to the
refinement of the user‚Äôs recommendations? To this end, the NDCG-
oriented greedy attribute selection strategy identifies the attribute
with the highest expected increase in recommendation performance
(measured in NDCG), from the user‚Äôs unasked adjacent attributes
ùëÉùëêùëéùëõùëë, to ask the user. The workflow of the proposed greedy NDCG
attribute selector is illustrated in Algorithm 2.
It is worth noting ùëÉùëêùëéùëõùëë contains only the unasked adjacent
attributes of the user ‚Äì attributes that are contained in the user‚Äôs
interacted items and have not been asked before ‚Äì which signifi-
cantly reduces the search space [ 13]. To start, the attribute selector
takes in the initial representation of the user learned from past
interactions rùë¢0, the current representation of the user rùë¢ùë°, the set
of collected preferences of the user ùëÉùë¢, and the set of candidate
attributesùëÉùëêùëéùëõùëë as inputs. Then for every unasked candidate at-
tributeùëùinùëÉùëêùëéùëõùëë, we compute its expected NDCG gain. First, we
addùëùtoùëÉùë¢to simulate the scenario that the asked attribute, ùëù, will
be liked by the user. Then based on the updated ùëÉùë¢, denoted as
ÀÜùëÉùë¢, we use the user representation refiner to compute the refined
representation rùë¢ùë°+1which reflects the system‚Äôs understanding of
the user after knowing the user‚Äôs preference on ùëù. Then, we use
rùë¢ùë°+1andrùë¢ùë°to compute the NDCGs of the user, both before andWWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA Allen Lin, Ziwei Zhu, Jianling Wang, and James Caverlee
Algorithm 2: Greedy NDCG Attribute Selector
Input : the initial representation of the user rùë¢0; the
current representation of the user at the ùë°-th turn
rùë¢ùë°; collected preferences of the user ùëÉùë¢; the
unasked adjacent attributes of the user ùëÉùëêùëéùëõùëë
Output: the attribute to ask next ùëùùëéùë†ùëò
1Initialize:ùëùùëéùë†ùëò=ùúô;ùëöùëéùë•_ùëõùëëùëêùëî =0
2forùëùinùëÉùëêùëéùëõùëë do
3 Set:ÀÜùëÉùë¢=ùëÉùë¢‚à™ùëù
4 Refine the initial user representation with ÀÜùëÉùë¢:
5 rùë¢ùë°+1=User Representation Refiner (rùë¢0,ÀÜùëÉùë¢)
6 Set:ùëù_ùëõùëëùëêùëî =NDCG (rùë¢ùë°+1) -NDCG (rùë¢ùë°)
7 ifùëù_ùëõùëëùëêùëî >ùëöùëéùë• _ùëõùëëùëêùëî then
8ùëöùëéùë•_ùëõùëëùëêùëî =ùëù_ùëõùëëùëêùëî
9ùëùùëéùë†ùëò=ùëù
10end for
11returnùëùùëéùë†ùëò
after knowing the user‚Äôs preference on ùëù, and use the difference
to serve as the expected NDCG gain for ùëù. Once we have com-
puted the expected NDCG gains for all the candidate attributes in
ùëÉùëêùëéùëõùëë, we pick the attribute with the highest expected NDCG gain
to be asked next, ùëùùëéùë†ùëò. It is important to note that the NDCG of
a user is computed on the validation set , instead of the testing
set. Specifically, we first rank all the items that are not included
the training samples of the user by taking the dot product of the
item‚Äôs representation (learned in Section 3.1) with the input user
representation . Then we use the ranked items of the user to compute
the DCG and the groundtruth items of the user (in the validation
set) to compute the Ideal DCG, which together give us the NDCG
of the user.
3.3 User Representation Refiner
After eliciting a user‚Äôs preferences, a natural next question is how
do we personalize the system‚Äôs model of the user? To provide a
personalized fusion for the collected preferences from the interac-
tive preference elicitation process, we deploy a user representation
refiner to refine the initial latent representation of the user, rùë¢0,
to be a more accurate reflection of the user‚Äôs current interests, by
considering the collected preferences of the user, ùëÉùë¢. Formally, we
have:
F(rùë¢0,ùëÉùë¢)=ÀÜrùë¢
whereFdenotes the user representation refiner which maps the
initial representation of the user, rùë¢0, to the refined representation,
ÀÜrùë¢, based on the collected preferences of the user, ùëÉùë¢.
Input Layer: To fuse the collected preferences in a personalized
manner, the user representation refiner takes both the past and
thecurrent interests of the user, respectively encoded in rùë¢0and
ùëÉùëêùëéùëõùëë, into consideration. First to construct the inputs, we fetch,
from RùëÉ(learned in Section 3.1), the latent representations of all
specified preferences in ùëÉùë¢, denoted as{rùëùùëñ|1‚â§ùëñ‚â§ |ùëÉùë¢|}, and
stack them together into a matrix Rùëùùë¢‚ààR|ùëÉùë¢|√óùëë, whereùëëis the
dimensionality of the latent representation.Preference Aggregation Layer: Then to account for the contex-
tual consistency of the neighboring preferences, an attention-based
preference aggregation layer is applied to Rùëùùë¢. Following [ 27], we
have:
ÀÜRùëùùë¢=ùë†ùëúùëìùë°ùëöùëéùë•(Rùëùùë¢WùëûRùëáùëùùë¢Wùëò
‚àö
ùëë)Rùëùùë¢Wùë£
where ÀÜRùëùùë¢‚ààR|ùëÉùë¢|√óùëëdenotes a set of preference representations
refined by incorporating the contextual information of the neigh-
boring preferences. And Wùëû,Wùëò, and Wùë£denote the projection
matrices. Next, we apply the weighted-sum to aggregate all the re-
fined preference representations to construct a new representation
that comprehensively represents the collected preferences of the
user as an entity:
zùëùùë¢=‚àëÔ∏Å
ùëñ‚àà|ùëÉùë¢|ùõºùëñ¬∑ÀÜrùëùùëñ
where zùëùùë¢denotes the aggregated representation that comprehen-
sively represents all the specified preferences in ùëÉùë¢as an entity;
ÀÜrùëùùëñdenotes a particular updated preference representation in ÀÜRùëùùë¢.
Andùõºùëñis the weight learned by the vanilla attention network:
ùõºùëñ=rùëá
ùë¢0ùë°ùëéùëõ‚Ñé(Wùëêrùëùùëñ+b1)ùõºùëñ=ùëíùë•ùëù(ùõºùëñ)√ç
ùëõ‚ààùëÄùëíùë•ùëù(ùõºùëõ)
whereùõºùëñis a scalar that represents the relevance of the representa-
tion of a particular attribute, ÀÜrùëùùëñ,Wùëêis the projection matrix, and
b1is the bias vector. Note that the initial latent representation of
the user, rùë¢0, is directly used as the ‚Äòquery‚Äô in calculation of ùõºùëñto
enhance personalization in the calculation of the relevance of a par-
ticular attribute, ùõºùëñ, to the user. In this way, ùõºùëñis learned by taking
into account ‚Äì (1) the intrinsic properties of individual attributes;
(2) the contextual consistency of the neighboring attributes; and (3)
the user‚Äôs general past interests ‚Äì so that zùëùùë¢is a comprehensive
representation of ùëÉùë¢.
Update Layer: Once zùëùùë¢has been computed, we concatenate it
with the user‚Äôs initial latent representation, rùë¢0, to obtain a concate-
nated representation rùë¢ùëêùëéùë°that contains information of the user‚Äôs
past and current interests:
rùë¢ùëêùëéùë°=zùëùùë¢‚äïrùë¢0
Then, a one-layer feed-forward neural network is applied to obtain
the refined representation of the user ÀÜrùë¢:
ÀÜrùë¢=Wrùë¢ùëêùëéùë°+b2
where Wis the weight matrix of the neural network and b2is the
bias vector.
Objective Function: Since the intention of the user representa-
tion refiner is to enhance personalization in fusing the collected
preferences of the user ( ùëÉùë¢), the refined representation of the user,
ÀÜrùë¢, should have higher predicted affinity scores (calculated using
dot-product) with items that align well with ùëÉùë¢. To this end, we
adopt the standard pairwise Bayesian Personalized Ranking (BPR)
objective function for optimizing the user representation refiner as
a personalized ranking algorithm. Note we did not use the weighted
variation of the BPR loss, Equation (2), since it is not applicable in
this situation. Formally, we have:
ùêøùëèùëùùëü=‚àëÔ∏Å
(ùë£,ùë£‚Ä≤,ùëÉùë¢)‚ààD‚àíùëôùëõùúé(ÀÜùë¶(ùë¢,ùë£,ùëÉùë¢)‚àíÀÜùë¶(ùë¢,ùë£‚Ä≤,ùëÉùë¢))+ùúÜùúÉ||ùúÉ||2Enhancing User Personalization in Conversational Recommenders WWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA
withÀÜùë¶(ùë¢,ùë£,ùëÉùë¢)is computed as:
ÀÜùë¶(ùë¢,ùë£,ùëÉùë¢)=F(rùë¢0,ùëÉùë¢)ùëáv (3)
Here,Dis a set of pairwise instances for the BPR training, ùë¢is the
user whose embedding is being updated, ùúéis the sigmoid function,
ùúÜùúÉis the regularization parameter to prevent overfitting, rùë¢0is
the initial user representation, and Fis the user representation
refiner. Note, Equation (3) involves the use of Fin its computation,
which allowsFto be trained through back-propagation. In addition,
Equation (3) drops the second item-attribute affinity term used in
Equation (1). This is because the attribute information has already
been fused into the refined user presentation, ÀÜrùë¢, making the item-
attribute affinity term redundant.
Pairwise Instances Sampling: In this section, we introduce the
pairwise instances sampling strategy used to construct D, for train-
ing the user representation refiner. For each user ùë¢, we randomly
sample one of ùë¢‚Äôs interacted items to serve the positive sample,
ùë£. Then, we randomly keep ùëõ, whereùëá‚àí1‚â•ùëõ‚â•1(T being the
maximum allowed turns of interaction), attribute(s) from the ùë£‚Äôs
list of attributes to serve as ùëÉùë¢. Lastly, we randomly sample one
ofùë¢‚Äôs non-interacted items, whose attributes share a low Jaccard
Similarity withùëÉùë¢, to serve as the negative sample, ùë£‚Ä≤. Compared
to the standard pairwise instance sampling where ùëÉùë¢would beùë£‚Äôs
entire list of attributes, we randomly select n attributes to keep
the user representation refiner robust to a wide variety of attribute
combinations. Note, ùë£‚Ä≤is specifically chosen to be an item that
share few attribute(s) with ùë£to emphasize the importance of ùëÉùë¢.
3.4 Action Selection Policy Learning
Following [ 13], we adopt a two-layer feed forward neural network
as the policy network and use the standard Deep Q-Learning [ 19]
for optimization. As shown by previous works [ 2,13], massive
action space hinders both the training and the performance of
RL-based policy networks; thus, we define our action space to be
A={ùëéùëéùë†ùëò,ùëéùëüùëíùëê}. During each interaction with the user, the policy
network takes in the state vector sùë°and outputs the Q-values for
bothùëéùëéùë†ùëòandùëéùëüùëíùëêto be their estimated rewards. The CRS will then
choose the action with higher reward and interact with the user
accordingly. The state vector sùë°is a concatenation of two vectors:
sùë°=rùë¢0‚äïs‚Ñéùëñùë†
ùë°
where rùë¢0denotes the initial user representation, which is expected
to add personalization into the policy network, and s‚Ñéùëñùë†
ùë°denotes the
conversation history up until turn ùë°, which is expected to guide the
system to act more wisely ‚Äì e.g., if multiple asked attributes have
been accepted, the system might be ready to recommend. Extending
from [ 13], we define the five kinds of rewards used for training
the policy network: (1) ùëüùëüùëíùëê_ùë†ùë¢ùëê, a NDCG-oriented positive reward
when recommendation succeeds; (2) ùëüùëüùëíùëê_ùëìùëéùëñùëô, a negative reward
when the user rejects the recommendation; (3) ùëüùëéùë†ùëò_ùë†ùë¢ùëê, a slightly
positive reward when the user confirms the asked attribute; and
(4)ùëüùëéùë†ùëò_ùëìùëéùëñùëô, a negative reward when the user rejects the asked
attribute, and (5). ùëüùë†ùë°ùëúùëù, a strongly negative reward when reaching
the maximum number of turns.Table 1: Dataset statistics
Dataset #users #items #interactions #attributes
Lastfm 1,801 7,432 76,693 33
Lastfm* 1,801 7,432 76,693 8,432
Yelp 27,675 70,311 1,368,606 29
Yelp* 27,675 70,311 1,368,606 590
4 EXPERIMENTS
In this section, we showcase experiments over multiple datasets
to evaluate the performance of the proposed UpsRec approach to
answer three key research questions: RQ1 . How does the recom-
mendation performance of the proposed framework compare to
existing CRS approaches? RQ2 . Does the proposed greedy NDCG
attribute selector enhance user personalization in the interactive
preference elicitation process? RQ3 . Does the proposed user rep-
resentation refiner enhance user personalization in the preference
fusion process?
4.1 Experiments Setup
Dataset. We evaluate the proposed framework on four benchmark
datasets that are widely adopted to evaluate multi-round conversa-
tional recommender systems [2, 12, 13, 25, 30].
‚Ä¢Lastfm andYelp . Lastfm is a dataset used to evaluate music
artist recommendation and Yelp is used to evaluate business
recommendation. In [ 12], Lei et al. manually categorize the orig-
inal 8,432 attributes in Lastfm into 33 coarse-grained categories,
and construct a 2-layer taxonomy to reduce the original 590
attributes to 29 first-layer categories for Yelp.
‚Ä¢Lastfm*1andYelp*2. In [13], Lei et al. propose it is unrealistic
to manually merge attributes for practical applications, so they
adopt the original attributes for these two datasets. For a fair
comparison, we conduct experiments on both versions.
All datasets contain only the implicit (binary) feedback from the
user (e.g. whether a user has interacted with the item or not). Fol-
lowing previous works [ 6,12], we keep users with at least 10 inter-
actions to alleviate data sparsity. Statistics of all the datasets are
summarized in Table 1.
Baselines. To examine the proposed framework, we compare its
performance with the following start-of-the-art baseline conversa-
tional recommendation approaches.
‚Ä¢Matrix Factorization (MF) : MF is a collaborative filtering al-
gorithm that is widely used for many static recommendation
tasks. We report its performance to demonstrate the general
effectiveness of CRSs.
‚Ä¢Max Entropy (MaxEnt) : MaxEnt is a rule-based attribute se-
lection strategy. At each turn, the policy agent selects the at-
tribute with the highest entropy to ask. Recommendation is
made either when the candidate space is small enough, or the
policy agent runs out of attributes.
‚Ä¢CRM [25] : CRM is a CRS that uses a belief tracker to record
a user‚Äôs preference conveyed, and trains a policy network via
1https://grouplens.org/datasets/hetrec-2011/
2https://www.yelp.com/dataset/WWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA Allen Lin, Ziwei Zhu, Jianling Wang, and James Caverlee
reinforcement learning to decide how to interact with the user.
We follow [ 12] to adapt it to the multi-round conversational
setting for fair comparison.
‚Ä¢EAR [12] : Similar to CRM, EAR also learns a predictive model
to estimate a user‚Äôs preference and trains a policy network to
determine whether to ask more attributes or make recommen-
dations. In addition, it also considers the feedback from the user
to further fine-tune the learned predictive model.
‚Ä¢SCPR [13] : Extending from EAR, SCPR leverages the concept
of adjacent attributes to construct a knowledge graph to reduce
the search space of attributes and uses Deep Q-Learning [ 19]
to learn a more efficient policy network.
‚Ä¢UNICORN [2] : Unicorn is the current state-of-the-art CRS. It
applies a dynamic-weighted-graph based RL approach to inte-
grate the conversation and the recommendation components
and deploys an weighted-entropy action selection strategy to
reduce the candidate action space.
Since all baselines are initially proposed under the MCR setting,
for a fair comparison, we retrain the conversational components
of all baseline models to adapt to the proposed MGMCR setting
as introduced in Section 2 and adopt a NDCG-oriented reward
function to optimize the policy networks of all baseline models.
Metrics. To evaluate a CRS under the MGMCR setting, we adopt
the Top-K metrics: Hit Rate (HT@K) and Normalized Discounted
Cumulative Gain (NDCG@K). HT@K could be considered as an ex-
tension of the widely adopted [ 2,12,25,30] Success Rate (SR) metric
under the MCR setting. Instead of measuring if the one groundtruth
item exists in the K recommended items, HT@K measures what
fraction of the K recommended items are of the groundtruth items.
To provide a more comprehensive evaluation, NDCG@K is also
adopted to account for the rank order in recommendations. In addi-
tion, we also report Average Turns (AT) to evaluate the efficiency
of the system. If the conversation session reaches the predefined
maximum turn T, then the turn count for the session is T.
Training Details. Following [ 12], we split the user-item interac-
tions in the ratio of 7:2:1 for training, validation, and testing, and set
the size of the recommendation list ùëòto 10 and the maximum turn ùëá
to 15. The training process is divided into offline and online stages.
The offline training is intended for building: (i) the predictive model
(FM) for estimating the latent interests of the user; and (ii) the user
representation refiner for incorporating the collected preferences
to iteratively refine the representation of the user. Afterwards, we
follow the user simulation process, introduced in Section 2, to con-
duct online training to optimize the policy agent (network) on how
to best interact with the user via reinforcement learning. We tune
all hyper-parameters on the validation set and set them as follows:
the dimensionality, ùëë, of all the user, item, attribute representations
are set to 64. SGD is used for optimizing the weighted BPR loss
adopted in the predictive model used in Section 3.1, with ùëõ1set to 7,
ùëõ2set to 8,ùúÜset to .001. Adam is used for optimizing the standard
BPR loss adopted in the user representation refiner, with ùúÜset to
.002. For constructing the pairwise instance D, we collect 15,000
pairwise samples for each user with the Jaccard Similarity threshold
set to 0.33. For training the policy network, we set the experiencereplay memory size to 50,000, the sample batch size to 256, and the
discount factor ùõæto 0.95.
4.2 Performance Comparison (RQ1)
As shown in Table 2, UpsRec significantly outperforms all the base-
line models in both recommendation performance (measured in
both NDCG@10 and HT@10) and conversation efficiency (mea-
sured in AT). This validates our hypothesis that enhancing user per-
sonalization, in both the interactive preference elicitation process
and the preference incorporation process, is an effective strategy
to build a CRS. We also make the following observations:
(1). All conversational recommendation approaches significantly
outperform the static matrix factorization (MF) model, showing the
promising functionality of CRSs in general.
(2). For all baseline models, we observe a significant gap between the
two recommendation performance metrics, especially on the Lastfm
and the Lastfm* datasets. In general, the measured NDCG@10 is
significantly lower than the measured HT@10. This is because
NDCG@10 is measured by taking the rank order of the groundtruth
items into account. Since baseline models only rely on attribute-
filtering to fuse the collected preferences of the user, the user repre-
sentation ‚Äì used for ranking the candidate items to calculate NDCG
‚Äì is often not an accurate reflection of the user‚Äôs current prefer-
ence space, since it has never been updated after learned from the
past user-item interactions. As a result, even when the groundtruth
items can be successfully recommended, they are usually ranked
low on the recommendation list. Compared to the baseline models,
UpsRec show similar recommendation performance measured in
both NDCG@10 and HT@10. This is because UpsRec integrates
theuser representation refiner to iteratively update a user‚Äôs repre-
sentation whenever a new preference has been collected. In turn,
the user representation used for ranking the candidate items will be
a more realistic reflection of the user‚Äôs current interests, resulting
in groundtruth items being ranked higher on the recommendation
list when they are successfully recommended.
(3). Comparing to all other baseline CRSs, UpsRec shows consis-
tently higher conversational efficiency (measured by AT) and rec-
ommendation performance (measured by both NDCG@10 and
HT@10) across all four tested datasets, especially on the Yelp*
dataset. This indicates that UpsRec can scale up to both large at-
tribute spaces (8,432 attributes in Lastfm* v.s. 29 attributes in Yelp)
and larger number of user-item interactions (1,368,606 interactions
in Yelp* v.s. 76,693 interactions in Lastfm), which is critical for
deploying CRSs in practice.
4.3 Enhancing User Personalization in
Interactive Preference Elicitation (RQ2)
To determine whether the proposed greedy NDCG attribute selector
enhances user personalization in the interactive preference elicita-
tion process, we examine both the effectiveness and the efficiency of
the asked attributes in representing user‚Äôs actual preference space.
Since the goal of a CRS is to make highly personalized recom-
mendations, we consider the effectiveness of an asked attribute
equivalent to how much it can increase the recommendation per-
formance. As shown in Figure 1, knowing the user‚Äôs preferences on
the attributes ‚Äì selected by the proposed greedy NDCG attributeEnhancing User Personalization in Conversational Recommenders WWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA
Table 2: Overall Recommendation Performance Comparison, with NDCG@10 ‚Üë, HT@10‚Üë, and AT‚Üìused as evaluation metrics.
Boldface indicates statistically significant improvement ( ùúå< 0.01) over all baselines.
Lastfm Lastfm* Yelp Yelp*
NDCG@10 HT@10 AT NDCG@10 HT@10 AT NDCG@10 HT@10 AT NDCG@10 HT@10 AT
MF .0415 .0684 NA .0392 .0679 NA .0199 .0419 NA .0165 .0305 NA
MaxEnt .1033 .1289 12.80 .1819 .2253 8.36 .2668 .2870 8.44 .1694 .2041 13.10
CRM .1359 .2006 11.13 .1710 .2237 7.60 .2422 .2920 7.24 .1072 .1289 13.69
EAR .1455 .2111 10.75 .1765 .2283 7.55 .2503 .3012 7.11 .1095 .1307 13.71
SCPR .1671 .2407 9.94 .2079 .2752 6.90 .2529 .3016 7.09 .3031 .2924 12.77
Unicorn .1982 .2808 8.95 .2239 .2818 6.84 .2557 .3041 6.99 .3118 .2977 12.92
UpsRec .3144 .3358 5.99 .3278 .3437 5.89 .3631 .3805 5.72 .3853 .3754 6.57
Figure 1: CRS Performance vs Conversation Turns
Figure 2: Asking Likelihood of the Top 40 Most Frequently
Asked Attributes in UpsRec and UNICORN
selector ‚Äì brings significantly higher increments in recommen-
dation performance than knowing the user‚Äôs preferences on the
attributes selected by all the baseline CRSs. This indicates that the
proposed greedy NDCG attribute selector selects attributes that are
more relevant to the user, such that knowing the user‚Äôs preferences
on these attributes helps the system gain a more comprehensive
understanding of the user‚Äôs current interests. Next, we consider
the efficiency of the attributes selected by the greedy NDCG at-
tribute selector. From Figure 1, for UpsRec, we observe a strong
diminishing increase in recommendation performance after asking
five attributes. This indicates that the asked attributes are highly
efficient in representing the user‚Äôs actual preference space, suchthat knowing the user‚Äôs preferences on four asked attributes helps
the system to achieve roughly 80% of its best recommendation per-
formance on the Lastfm* dataset or nearly 90% on the Yelp* dataset.
Compared to UpsRec, all other baselines show marginal increases in
recommendation performance after knowing the user‚Äôs preference
on the first few asked attributes (Figure 1). This is due to the lack of
user personalization in the interactive preference elicitation. Com-
pared to the proposed NDCG-oriented attribute selection strategy,
the entropy-based attribute selection strategy adopted by exist-
ing works cannot precisely identify the set of attributes that most
efficiently represent the user‚Äôs actual preference space. To better
illustrate, we compare the averaged asking likelihood of the top-40
most frequently asked attributes in both UNICORN and UpsRec
(Figure 2). The asking likelihood of an attribute can be interpreted
as the percentage of users that the system predicts will find the
asked attribute relevant. For instance, the top-three most frequently
asked attributes in UNICORN have an average asking likelihood of
0.7. That is, UNICORN thinks that 70% of the users will consider
these three attributes important in expressing their preferences.
However, due to the lack of user personalization in the weighted-
entropy attribute selection, such prediction is often inaccurate. As
can be observed in Figure 2, UNICORN exhibits a higher asking
likelihood for almost all the top-40 most frequently asked attributes,
on both the LastFM* and the Yelp* dataset (Table 2). This indicates
that many of the asked attributes in UNICORN are inefficient in rep-
resenting the user‚Äôs actual preference space. A sample conversation
of such, on the Yelp* business recommendation dataset, is shown
in Figure 4. While the attributes Restaurant and affordable have
high calculated weighted-entropy, knowing the user preference on
them has virtually no contribution to the recommendation perfor-
mance of the system. Compared to the weighted-entropy attribute
selection strategy used in UNICORN, the proposed NDCG-oriented
attribute selection strategy identifies attributes that more efficiently
represent the preference space of the user.WWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA Allen Lin, Ziwei Zhu, Jianling Wang, and James Caverlee
Figure 3: AUC Scores on GroundTruth(GT) Item Predic-
tion and GT Attribute Prediction at Different Conversation
Turns
4.4 Enhancing User Personalization in Fusing
Preferences (RQ3)
A personalized preference fusing process aims to consistently in-
crease the system‚Äôs understanding of the user by providing a per-
sonalized modeling based on the user‚Äôs collected preferences. There-
fore, to determine the effectiveness of the proposed user represen-
tation refiner in enhancing user personalization in the collected-
preference incorporation process, we examine whether the refined
representation of the user more precisely reflects the user‚Äôs actual
items of interest and attributes of interest, compared to the current
state-of-the-art CRS ‚Äì UNICORN. To examine if the refined user
representation more precisely reflects the user‚Äôs actual items of
interest, we compare the AUC Scores on groundtruth item predic-
tion (computed following [ 24]) between UpsRec and UNICORN.
As shown in Figure 3, by iteratively refining the representation
of the user once a new preference of the user has been collected,
UpsRec‚Äôs AUC gradually increases as the conversation goes on.
Note UNICORN adopts a different strategy for learning the initial
user representations which results in different AUC scores at turn
0; however, since UNICORN (and all baselines) performs no refine-
ment on the learned initial user representations, its AUC remains
constant and is surpassed by UpsRec‚Äôs in one turn. This indicates
that compared to the attribute-filtering approach used in UNICORN,
the proposed user representation refiner is able to help the system
obtain a uniquely personalized modeling of the user, which more
precisely reflects the user‚Äôs items of interests. A similar pattern is
also observed in (Figure 3). As the conversation goes on, UpsRec‚Äôs
AUC on groundtruth attributes prediction also gradually surpasses
the AUC of UNICORN. Note, the AUC score on groundtruth at-
tributes prediction is computed by treating all the attributes that
exist in any of the groundtruth items as the positive attributes and
the attributes that do not as the negative attributes. A higher AUC
score indicates that the proposed user representation refiner is able
to help the system establish a more personalized modeling of the
user, which facilitates the process of identifying the attributes that
the user would find relevant in expressing her preference space.5 RELATED WORK
Traditional recommender systems challenges of (i) how to cap-
ture a user‚Äôs precise preferences; and (ii) how to provide a human-
interpretable justification for their recommendations [ 3,8]. Many
existing works have approached these challenges with auxiliary
data to better interpret user intentions [ 1,5,29,33,35]. In another
direction, the emergence of conversational recommenders that dy-
namically interact with users through real-time interactions are
able to elicit current and detailed preferences directly from users
[8]. In this way, a CRS can precisely learn a user‚Äôs interests along
with a series of actions that provide justification evidence.
In general, a CRS is composed of two components ‚Äì the con-
versation component and the recommendation component. The
conversation component decides which action (further collecting
user preference or calling upon the recommender component to
make recommendations) to take during each interaction with the
user. The recommendation component learns a set of user, item,
and attribute embeddings for ranking all the candidate items. While
early works on CRSs primarily rely on template or choice-based
conversation components for collecting user preferences [ 4,9,41],
recent works have explored the possibilities of more effective pref-
erence elicitation methods and conversational strategies with the
help of reinforcement learning. For example, CRM [ 25] proposes a
deep reinforcement-based conversation component that builds a
personalized preference elicitation process. Inspired by CRM, EAR
[12] proposes a novel optimization function to enhance the rich-
ness of the embeddings learned by the recommendation component,
then designs a three-stage framework that further strengthens the
interaction between the recommender component and the conversa-
tion component. While sharing the same recommender component,
SCPR [ 13] integrates knowledge graphs to improve the reasoning
ability of the conversation component. Further utilizing the infor-
mativeness of knowledge graphs, UNICORN [ 2] proposes a dynamic
weighted graph based reinforcement approach that systematically
integrate the recommendation and the conversation components.
However, the above-introduced approaches [ 2,12,13,25,30] all
adopt an entropy-based attribute-selection strategy which limits
user personalization in the preference elicitation process. In addi-
tion, these approaches only make coarse uses of the obtained user
preferences, refraining the system from gaining a deeper under-
standing of the user. In this work, we propose a novel attribute-
selection and a preference fusion strategy that jointly address these
two issues. Note that while there are other research directions in
CRSs including dialogue understanding [ 10,14,28,37,40], response
generation [16, 18, 20, 39], and exploration-exploitation trade-offs
[7, 11, 31, 32, 38] those are not the focus of this work.
6 CONCLUSION
In this work, we propose a novel framework, named UpsRec, with
two unique features aiming to enhance user personalization in both
the interactive preference elicitation process and the preference
fusion process. The experimental results on four frequently adopted
conversational recommendation datasets show that the proposed
framework not only outperforms all baseline CRS methods but also
brings a more personalized experience for the user under the more
realistic and generalizable MGMCR setting.Enhancing User Personalization in Conversational Recommenders WWW ‚Äô23, May 1‚Äì5, 2023, Austin, TX, USA
Figure 4: Sample Conversations by UNICORN and UpsRec
REFERENCES
[1]Zhiyong Cheng, Xiaojun Chang, Lei Zhu, Rose C Kanjirathinkal, and Mohan
Kankanhalli. 2019. MMALFM: Explainable recommendation by leveraging re-
views and images. ACM Transactions on Information Systems (TOIS) 37, 2 (2019),
1‚Äì28.
[2]Yang Deng, Yaliang Li, Fei Sun, Bolin Ding, and Wai Lam. 2021. Unified conversa-
tional recommendation policy learning via graph-based reinforcement learning.
InProceedings of the 44th International ACM SIGIR Conference on Research and
Development in Information Retrieval . 1431‚Äì1441.
[3]Chongming Gao, Wenqiang Lei, Xiangnan He, Maarten de Rijke, and Tat-Seng
Chua. 2021. Advances and challenges in conversational recommender systems:
A survey. AI Open 2 (2021), 100‚Äì126.
[4]Mark P. Graus and Martijn C. Willemsen. 2015. Improving the User Experience
during Cold Start through Choice-Based Preference Elicitation. In RecSys .
[5]Xiangnan He, Tao Chen, Min-Yen Kan, and Xiao Chen. 2015. Trirank: Review-
aware explainable recommendation by modeling aspects. In Proceedings of the
24th ACM international on conference on information and knowledge management .
1661‚Äì1670.
[6]Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng
Chua. 2017. Neural collaborative filtering. In Proceedings of the 26th international
conference on world wide web . 173‚Äì182.
[7]Andrea Iovine, Pasquale Lops, Fedelucio Narducci, Marco de Gemmis, and Gio-
vanni Semeraro. 2022. An empirical evaluation of active learning strategies for
profile elicitation in a conversational recommender system. Journal of Intelligent
Information Systems (2022), 1‚Äì26.
[8]Dietmar Jannach, Ahtsham Manzoor, Wanling Cai, and Li Chen. 2021. A survey
on conversational recommender systems. ACM Computing Surveys (CSUR) 54, 5
(2021), 1‚Äì36.
[9]Hai Jiang, Xin Qi, and He Sun. 2014. Choice-based recommender systems: a
unified approach to achieving relevancy and diversity. In Operations Research .
[10] Xisen Jin, Wenqiang Lei, Zhaochun Ren, Hongshen Chen, Shangsong Liang, Yi-
hong Zhao, and Dawei Yin. 2018. Explicit state tracking with semi-supervisionfor
neural dialogue generation. In Proceedings of the 27th ACM International Confer-
ence on Information and Knowledge Management . 1403‚Äì1412.
[11] Hoyeop Lee, Jinbae Im, Seongwon Jang, Hyunsouk Cho, and Sehee Chung. 2019.
Melu: Meta-learned user preference estimator for cold-start recommendation.
InProceedings of the 25th ACM SIGKDD International Conference on Knowledge
Discovery & Data Mining . 1073‚Äì1082.
[12] Wenqiang Lei, Xiangnan He, Yisong Miao, Qingyun Wu, Richang Hong, Min-
Yen Kan, and Tat-Seng Chua. 2020. Estimation-action-reflection: Towards deep
interaction between conversational and recommender systems. In WSDM .
[13] Wenqiang Lei, Gangyi Zhang, Xiangnan He, Yisong Miao, Xiang Wang, Liang
Chen, and Tat-Seng Chua. 2020. Interactive path reasoning on graph for conver-
sational recommendation. In KDD .
[14] Jiwei Li, Will Monroe, Alan Ritter, Michel Galley, Jianfeng Gao, and Dan Jurafsky.
2016. Deep reinforcement learning for dialogue generation. arXiv preprint
arXiv:1606.01541 (2016).
[15] Allen Lin, Jianling Wang, Ziwei Zhu, and James Caverlee. 2022. Quantifying and
mitigating popularity bias in conversational recommender systems. In Proceedings
of the 31st ACM International Conference on Information & Knowledge Management .
1238‚Äì1247.
[16] Chin-Yew Lin. 2004. Rouge: A package for automatic evaluation of summaries.
InText summarization branches out . 74‚Äì81.
[17] Shuo Lin, Ziwei Zhu, Jianling Wang, and James Caverlee. 2022. Towards Fair
Conversational Recommender Systems. arXiv preprint arXiv:2208.03854 (2022).[18] Zeming Liu, Haifeng Wang, Zheng-Yu Niu, Hua Wu, Wanxiang Che, and Ting
Liu. 2020. Towards conversational recommendation over multi-type dialogs.
arXiv preprint arXiv:2005.03954 (2020).
[19] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A Rusu, Joel Veness,
Marc G Bellemare, Alex Graves, Martin Riedmiller, Andreas K Fidjeland, Georg
Ostrovski, et al .2015. Human-level control through deep reinforcement learning.
nature 518, 7540 (2015), 529‚Äì533.
[20] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a
method for automatic evaluation of machine translation. In Proceedings of the
40th annual meeting of the Association for Computational Linguistics . 311‚Äì318.
[21] Lijing Qin, Shouyuan Chen, and Xiaoyan Zhu. 2014. Contextual combinatorial
bandit and its application on diversified online recommendation. In Proceedings
of the 2014 SIAM International Conference on Data Mining . SIAM, 461‚Äì469.
[22] Tian Qiu, Chi Wan, Xiao-Fan Wang, and Zi-Ke Zhang. 2019. User interest
dynamics on personalized recommendation. Physica A: Statistical Mechanics and
its Applications 525 (2019), 965‚Äì977.
[23] Steffen Rendle. 2010. Factorization machines. In 2010 IEEE International conference
on data mining . IEEE, 995‚Äì1000.
[24] Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme.
2012. BPR: Bayesian personalized ranking from implicit feedback. arXiv preprint
arXiv:1205.2618 (2012).
[25] Yueming Sun and Yi Zhang. 2018. Conversational recommender system. In SIGIR .
[26] Qiaoyu Tan, Jianwei Zhang, Jiangchao Yao, Ninghao Liu, Jingren Zhou, Hongxia
Yang, and Xia Hu. 2021. Sparse-interest network for sequential recommendation.
InProceedings of the 14th ACM International Conference on Web Search and Data
Mining . 598‚Äì606.
[27] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, ≈Åukasz Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. Advances in neural information processing systems 30 (2017).
[28] Jianling Wang, Ya Le, Bo Chang, Yuyan Wang, Ed H Chi, and Minmin Chen. 2022.
Learning to Augment for Casual User Recommendation. In Proceedings of the
ACM Web Conference 2022 . 2183‚Äì2194.
[29] Yikun Xian, Zuohui Fu, Shan Muthukrishnan, Gerard De Melo, and Yongfeng
Zhang. 2019. Reinforcement knowledge graph reasoning for explainable rec-
ommendation. In Proceedings of the 42nd international ACM SIGIR conference on
research and development in information retrieval . 285‚Äì294.
[30] Kerui Xu, Jingxuan Yang, Jun Xu, Sheng Gao, Jun Guo, and Ji-Rong Wen. 2021.
Adapting user preference to online feedback in multi-round conversational rec-
ommendation. In Proceedings of the 14th ACM international conference on web
search and data mining . 364‚Äì372.
[31] Tong Yu, Yilin Shen, and Hongxia Jin. 2019. A visual dialog augmented interactive
recommender system. In Proceedings of the 25th ACM SIGKDD international
conference on knowledge discovery & data mining . 157‚Äì165.
[32] Xiaoying Zhang, Hong Xie, Hang Li, and John CS Lui. 2020. Conversational
contextual bandit: Algorithm and application. In Proceedings of the web conference
2020. 662‚Äì672.
[33] Yongfeng Zhang, Xu Chen, et al .2020. Explainable recommendation: A survey
and new perspectives. Foundations and Trends ¬Æin Information Retrieval 14, 1
(2020), 1‚Äì101.
[34] Yongfeng Zhang, Xu Chen, Qingyao Ai, Liu Yang, and W. Bruce Croft. 2018.
Towards Conversational Search and Recommendation: System Ask, User Respond.
InCIKM .
[35] Yongfeng Zhang, Guokun Lai, Min Zhang, Yi Zhang, Yiqun Liu, and Shaoping
Ma. 2014. Explicit factor models for explainable recommendation based on
phrase-level sentiment analysis. In Proceedings of the 37th international ACM
SIGIR conference on Research & development in information retrieval . 83‚Äì92.
[36] Yiming Zhang, Lingfei Wu, Qi Shen, Yitong Pang, Zhihua Wei, Fangli Xu, Bo
Long, and Jian Pei. 2022. Multiple Choice Questions based Multi-Interest Policy
Learning for Conversational Recommendation. In Proceedings of the ACM Web
Conference 2022 . 2153‚Äì2162.
[37] Yinhe Zheng, Rongsheng Zhang, Minlie Huang, and Xiaoxi Mao. 2020. A pre-
training based personalized dialogue generation model with persona-sparse data.
InProceedings of the AAAI Conference on Artificial Intelligence , Vol. 34. 9693‚Äì9700.
[38] Chunyi Zhou, Yuanyuan Jin, Xiaoling Wang, and Yingjie Zhang. 2020. Con-
versational music recommendation based on bandits. In 2020 IEEE International
Conference on Knowledge Graph (ICKG) . IEEE, 41‚Äì48.
[39] Kun Zhou, Wayne Xin Zhao, Shuqing Bian, Yuanhang Zhou, Ji-Rong Wen, and
Jingsong Yu. 2020. Improving conversational recommender systems via knowl-
edge graph based semantic fusion. In Proceedings of the 26th ACM SIGKDD
International Conference on Knowledge Discovery & Data Mining . 1006‚Äì1014.
[40] Jie Zou, Yifan Chen, and Evangelos Kanoulas. 2020. Towards question-based rec-
ommender systems. In Proceedings of the 43rd international ACM SIGIR conference
on research and development in information retrieval . 881‚Äì890.
[41] Lixin Zou, Long Xia, Yulong Gu, Xiangyu Zhao, Weidong Liu, Jimmy Xiangji
Huang, and Dawei Yin. 2020. Neural interactive collaborative filtering. In Proceed-
ings of the 43rd International ACM SIGIR Conference on Research and Development
in Information Retrieval . 749‚Äì758.