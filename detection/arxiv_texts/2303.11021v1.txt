GENERIC COLORIZED JOURNAL, VOL. XX, NO. XX, XXXX 2023 1
Once upon a time step: A closed-loop approach
to robust MPC design
Anilkumar Parsi, Marcell Bartos, Amber Srivastava, Sebastien Gros, Roy S. Smith, Fellow, IEEE
Abstract — A novel perspective on the design of robust
model predictive control (MPC) methods is presented,
whereby closed-loop constraint satisfaction is ensured us-
ing recursive feasibility of the MPC optimization. Necessary
and sufﬁcient conditions are derived for recursive feasibil-
ity, based on the effects of model perturbations and distur-
bances occurring at one time step . Using these conditions
and Farkas’ lemma, sufﬁcient conditions suitable for design
are formulated. The proposed method is called a closed-
loop design, as only the existence of feasible inputs at
the next time step is enforced by design. This is in con-
trast to most existing formulations, which compute control
policies that are feasible under the worst-case realizations
of all model perturbations and exogenous disturbances in
the MPC prediction horizon. The proposed method has an
online computational complexity similar to nominal MPC
methods while preserving guarantees of constraint satis-
faction, recursive feasibility and stability. Numerical simu-
lations demonstrate the efﬁcacy of our proposed approach.
Index Terms — Predictive control for linear systems, Ro-
bust control, Uncertain systems, Constrained control
I. INTRODUCTION
MODEL predictive control (MPC) is one of the popular
control strategies in use today. Owing to the modeling
and computational ﬂexibility, MPC has been successfully
implemented in a diverse range of applications — such as
oil reﬁneries [1], autonomous vehicles [2], robotics [3], and
supply chain management [4]. A distinctly highlighting feature
of MPC is its ability to efﬁciently handle constraints on the
system states and control inputs, while also guaranteeing the
stability of the system [5]. In particular, MPC poses decision
making as an optimization problem, where one optimizes an
objective function subject to the constraints resulting from the
system dynamics, and admissible system states and control
inputs. The optimization problem is solved at each time step
to compute an open-loop input sequence over a ﬁnite number
of time steps (called the prediction horizon), of which only the
This work was supported by the Swiss National Science Foundation
under Grant 200021 178890 and NCCR Automation Grant 180545.
Corresponding author Anilkumar Parsi.
Anilkumar Parsi, Amber Srivastava, Roy Smith and Marcell
Bartos are with the Automatic Control Laboratory, Swiss
Federal Institute of Technology (ETH Z ¨urich), 8092 Zurich,
Switzerland (e-mail: aparsi/asrivastava/rsmith@control.ee.ethz.ch,
mbartos@student.ethz.ch).
Sebastien Gros is with the Department of Engineering Cybernetics,
Norwegian University of Science and Technology (NTNU), Trondheim,
Norway (email:sebastien.gros@ntnu.no)ﬁrst input is applied in closed loop. Hence MPC produces an
optimization-based closed-loop policy from the current system
state to an input to be applied to the system. A popular
approach in practice is to use an approximate linear dynamical
model of the system, as it results in convex optimization
problems suitable for real-time implementation [6]. Such an
approximation can be compensated for, by introducing struc-
tured uncertainty and disturbances into the model.
Robust MPC algorithms explicitly consider the effects of
model uncertainties and disturbances in the controller design
so that closed-loop stability and constraint satisfaction can be
guaranteed [7]. In addition to these properties, an important
consideration for MPC is whether the optimization problem
remains feasible in closed-loop operation, which is known
as recursive feasibility [8], [9]. The design of robust MPC
thus has three desired properties: (i) constraint satisfaction,
(ii) recursive feasibility, and (iii) closed-loop stability. In this
paper, we highlight that generally (ii) already implies (i), and
use this observation to propose a novel method for designing
robust MPC schemes.
The design for (i) and (ii) is coupled and follows an
open-loop approach in most existing MPC works [10], [11],
[12]. This involves two steps. First, constraint satisfaction is
explicitly enforced on the open-loop trajectories computed
by the MPC optimizer, considering the worst-case model
perturbations and disturbances along the prediction horizon
of MPC. Second, the state of the system at the end of the
prediction horizon is driven into a precomputed terminal set,
which is robustly invariant under a known terminal controller
[7]. This strategy ensures that the open-loop trajectories do
not violate constraints for an inﬁnite time, thus achieving both
recursive feasibility and constraint satisfaction.
Although such an open-loop design approach works, a large
degree of conservatism can originate from ensuring feasibility
over multiple time steps in the prediction horizon. This is
because recursive feasibility of MPC is a one-step property.
That is, recursive feasibility only requires that under the
action of the ﬁrst control input computed by MPC at the
current time step, the MPC optimization is also feasible at the
next time step. However, the open-loop design for recursive
feasibility operates via ensuring feasibility throughout the
prediction horizon, instead of the next time step alone. The
conservatism of open-loop approaches is arguably stemming
from this discrepancy, as depicted in Figure 1.
In Figure 1, it can be seen that tube MPC approaches (such
as [13], [14]) construct a state tube which accounts for allarXiv:2303.11021v1  [eess.SY]  20 Mar 20232 GENERIC COLORIZED JOURNAL, VOL. XX, NO. XX, XXXX 2023
k-th step
xkwk;k
wk+1;k+1xk+1Constraint set
xk+2
wk+2;k+2Terminal setxk+3
Fig. 1 : Classical tube MPC methods, where the predicted
open-loop trajectories remain feasible under allmodel per-
turbations iand disturbances wioccurring in the prediction
horizon.
possible disturbances wk;wk+1;wk+2and model perturbations
k;k+1;k+2in the prediction horizon of three time steps,
before the open-loop state trajectories reach the terminal set.
In addition to the conservatism, many open-loop approaches
have a large computational complexity of online optimization.
This is because in an open-loop approach, MPC either has to
recursively outer-approximate the reachable sets under worst-
case perturbations (as in tube MPC methods), or use scenario
trees which grow exponentially along the horizon [15].
This work is motivated by the insight that under mild
conditions, recursive feasibility implies constraint satisfaction.
That is, if an MPC problem remains feasible in closed loop,
then the system constraints are also satisﬁed. Therefore, one
need not explicitly ensure constraint satisfaction along the
prediction horizon under the open-loop MPC policy. Although
this observation is not particularly difﬁcult to verify, it is not
exploited in the controller design in most existing methods.
To the best of our knowledge, this insight is not formally
presented in previous literature, but a few early robust MPC
methods implicitly use it for systems affected by additive
disturbances [16], [17], [8]. All these works study the recursive
feasibility of the MPC optimization and do not explicitly prove
constraint satisfaction, as recursive feasibility already implies
constraint satisfaction. The methods in [16] and Chapter 6.5
of [8] propose ways to robustify nominal MPC controllers,
if a robust control invariant set is known a priori. However,
these sets are very difﬁcult to compute [18], [19]. Whereas
[17] studies the problem of ensuring recursive feasibility using
set-invariance, it only provides tools for analysis of a given
robust MPC algorithm. The recent work [20] extends the ideas
from [17] for systems with multiplicative perturbations, but
also provides conditions suitable for analysis, not design. In
contrast to these early methods, most later works explicitly
design for constraint satisfaction following the open-loop
approach described earlier [10]-[14].
In this work, we present a robust MPC design which explic-
itly ensures recursive feasibility in closed-loop operation, and
hence refer to it as closed-loop robust MPC. The proposed
method in this work uses constraint tightening to design a
recursively feasible MPC. In constraint tightening methods,
the system constraints along the prediction horizon are tight-
ened to account for model uncertainty, such that if a nom-
inal trajectory satisﬁes the modiﬁed constraints, the closed-
loop trajectories remain feasible under model perturbations
and disturbances [21], [22]. Because the online optimizationk-th step
Nominal trajectory
xk
Tightened constraintsTerminal set
k+1-th step
xkwk;kxk+1
Perturbed nominal
trajectory for k+ 1-th step
Fig. 2 : Closed-loop robust MPC (our proposed approach).
Here, MPC only computes a nominal trajectory online such
that tightened constraints are satisﬁed. The tightenings are de-
signed ofﬂine such that, under perturbation kand disturbance
wkoccurring at the current (k-th) time step, the MPC problem
will be feasible at the next ( k+ 1-th) time step.
computes only the nominal trajectories, the computational
complexity is similar to that of nominal MPC schemes.
The closed-loop robust MPC proposed in this work is
depicted in Figure 2. In this approach, the robust MPC design
accounts only for the disturbance wkand model perturbation
koccurring at the current ( k-th) time step. In particular,
the MPC constraints are tightened ofﬂine such that, for any
feasible nominal trajectory at a time step k, disturbances wk
and perturbations kresult in a feasible nominal trajectory
at time step k+ 1, guaranteeing recursive feasibility. Note
that, although constraint tightening techniques already exist in
literature ([21], [22]), the tightenings therein are computed by
accounting for all perturbations and disturbances in the MPC
prediction horizon, instead of those occurring at the ﬁrst time
step as done in this work.
In this work, a constraint tightening technique is developed
for systems whose dynamics can be described by a nominal
linear model combined with a time-varying linear fractional
perturbation [23] and bounded exogenous disturbances. The
proposed algorithm has two phases: ofﬂine and online. In the
ofﬂine phase, a non-convex optimization is solved to compute
constraint tightenings. In the online phase, a nominal MPC
problem with tightened constraints is solved at each time step
to compute the control inputs. The proposed framework is
designed to ensure recursive feasibility, constraint satisfaction
and input-to-state stability. Numerical examples demonstrate
that the proposed design results in an order of magnitude re-
duction in online computation time and improved performance
compared to state-of-the-art methods.
Our work has three novel contributions. First, we formally
present the conditions under which recursive feasibility of
MPC optimization implies closed-loop constraint satisfaction.
Second, necessary and sufﬁcient conditions for recursive fea-
sibility are presented for systems affected by linear fractional
perturbations and disturbances. Third, recursive feasibility isPARSI et al. : ONCE UPON A TIME STEP: A CLOSED-LOOP APPROACH TO ROBUST MPC DESIGN 3
formulated as a design constraint on the robust MPC con-
troller, by analyzing only the effects of perturbations and
disturbances occurring at one time step.
A. Notation
The sets of real numbers is denoted by Rand the sequence
of integers from n1ton2byNn2n1. For a vector b,kbk2
represents the 2 norm. Theithrow of a matrix Ais denoted
by[A]i. The notation aljkdenotes the value of aat time step
k+lcomputed at the time step k. The identity matrix of
sizennis denoted by In. A block of zeros of size nm
inside a larger matrix will be denoted by 0n;mwhen the size
cannot be inferred from the other blocks, and 0otherwise. The
minimum eigenvalue of a matrix Ais denoted as min(A).
The Kronecker product of two matrices AandBis denoted
byA
B, and cofgrepresents the convex hull operator.
A continuous function :R0!R0is aKfunction if
(0) = 0 ,(s)>0for alls>0and it is strictly increasing;
it is aK1function if it is a Kfunction and (s)!1 as
s!1 . A continuous function :R0N1
0!R0is a
KLfunction if(s;t)is aKfunction in sfor everyt0,
it is strictly decreasing in tfor everys >0and(s;t)!0
whent!1 .
II. P ROBLEM FORMULATION
We consider uncertain linear, time-invariant systems of the
form:
xk+1=Axk+Buk+Bppk+Bwwk; (1a)
qk=Dxxk+Duuk+Dwwk; (1b)
pk= kqk; (1c)
wherexk2Rnxrepresents the state of the system, uk2
Rnurepresents the control input, and wk2Rnwrepresents
an exogenous disturbance acting on the system’s state. In
addition, the model uncertainty is captured using a linear
fractional transformation (see [23]), described by pk;qk2Rnp
and the matrix k2Rnpnp. The vectors pk;qkand the
matrix kcannot be measured, but kis known to lie inside
the set
P:=cof1;2;:::; ng; (2)
wherenrepresents the number of vertices deﬁning the
convex hullP.
The exogenous disturbance wkis assumed to lie within a
compact set containing the origin, deﬁned as
W:=fw2RnwjHwwhwg; (3)
whereHw2RnHwnwandhw2RnHw.
Moreover, the states and inputs of the system are required to
lie in a compact polytopic constraint set containing the origin,
deﬁned as
C:=f(x;u)2RnxRnujFx+Gubg; (4)
whereF2Rncnx;G2Rncnuandb2Rnc. The control
task is subject to a stage cost function of the form l(x;u),
whose cumulative sum has to be minimized over a (possibly)inﬁnite horizon. Directly minimizing this cost is intractable,
as it requires optimization over inﬁnite number of variables
and constraints.
Instead, model predictive control (MPC) is used to ﬁnd
suboptimal input sequences [24]. In this approach, a receding
horizon strategy is used where the control inputs over the
nextNtimesteps (called the prediction horizon) are optimized
while also ensuring that the state after Ntimesteps reaches a
terminal setXN:=fxjYxzgwhich contains the origin.
In this work, robustness is ensured using constraint tightening
[21], [22]. That is, the MPC optimization problem only uses
a nominal model of the system, and tightens the constraints
(4) to ensure robustness in closed loop.
Thus, an optimization problem of the following form is
solved at each time step kusing the available state measure-
mentxk,
min
^xk;^uklN(^xNjk) +N 1X
i=0l(^xijk;^uijk) (5a)
s.t.A^xijk+B^uijk= ^xi+1jk;^x0jk=xk; (5b)
F^xijk+G^uijkb ti; i2NN 1
0; (5c)
Y^xNjkz tN; (5d)
where ^xk:=[^x|
0jk;:::; ^x|
Njk]|and ^uk:=[^u|
0jk;:::; ^u|
N 1jk]|
represent the nominal state and input trajectories, as predicted
by the nominal dynamics in (5b). In addition, (5d) is a terminal
constraint imposed on the last state in the prediction horizon,
andlN()is a terminal cost function. The terms ftigN
i=0are
tightenings imposed on the constraints along the prediction
horizon and the terminal set. The MPC components lN(),
Y,zandftigN
i=0are design choices, and must be computed
ofﬂine, i.e, before (5) is solved.
Let the optimal solution to (5) be deﬁned by the superscript
()on the optimization variables. The MPC control law is then
deﬁned as(xk) = ^u
0jk. That is, only the ﬁrst control input
from ^u
kis applied to the system, and (5) is solved again at
the following time step.
In order to achieve desired closed-loop properties, relevant
design criteria must be imposed on the MPC components
lN(),Y,zandftigN
i=0. The following sections present
methods formulating such design criteria.
III. C ONSTRAINT SATISFACTION USING RECURSIVE
FEASIBILITY
Two main properties that are desired to be satisﬁed by robust
MPC controllers are (i) constraint satisfaction and (ii) recursive
feasibility. Existing robust MPC methods are designed by
explicitly accounting for both (i) and (ii), for example, in [21].
In this work, a novel design strategy is proposed such that
satisfying (ii) implicitly ensures that (i) is satisﬁed. For this
purpose, the notion of recursive feasibility (RF) is formally
presented [9].
Deﬁnition 1 (Recursive feasibility) .An MPC controller is
recursively feasible if, for any state xksuch that the MPC
optimization is feasible, the optimal control input computed
by MPC when applied to the system results in a state xk+1
which is also feasible for the MPC optimization problem.4 GENERIC COLORIZED JOURNAL, VOL. XX, NO. XX, XXXX 2023
In the context of the system (1)-(3) and the MPC (5), RF
means that for every xksuch that (5) is feasible, the MPC
(5) is also feasible for the state xk+1under the control law
(xk) = ^u
0jkand for any realization of wk2W andk2P.
Note that(xk)uses the optimal solution of (5), which
cannot be easily expressed as an explicit function of xk. Thus,
RF is difﬁcult to use as a design criterion or even verify [9]. In
the light of these difﬁculties, it is useful to consider a stronger
condition, pertaining to only the feasibility of MPC, which
will ensure that RF is satisﬁed.
Deﬁnition 2 (Strong recursive feasibility) .An MPC controller
is strongly recursively feasible if, for any state xksuch
that MPC optimization is feasible, any feasible control input
computed by MPC when applied to the system results in a
statexk+1which is also feasible for the MPC optimization
problem.
Note that strong recursive feasibility (SRF) is a sufﬁcient
condition for RF, and has been referred to in literature as
strong recursive feasibility [9, Deﬁnition 2.2], or robust strong
feasibility [17, Deﬁnition 12]. Because SRF does not depend
on the optimality of the control input, it can be used in the
design of MPC controllers. Although using SRF for design
could lead to conservatism, it must be noted that most existing
robust MPC methods satisfy SRF [12], [14].
In the context of the system (1)-(3) and the MPC (5), SRF
can be formalized as follows. Let U(xk)be the set of input
sequences such that (5b)-(5d) are satisﬁed for a given state xk.
Additionally, deﬁne U0(xk)as the set of feasible inputs at the
ﬁrst predicted time step, that is,
U0(xk) :=
^u0jkj9f^uljkgN 1
l=02U(xk)	
: (6)
The MPC (5) is said to be SRF if, for every state xksuch that
(5) is feasible, under any control input uk2U0(xk), and for
any realization of wk2W andk2P, the optimization (5)
is also feasible for the state xk+1following the dynamics (1).
In this paper, we will rely on the fact that, under very mild
conditions, RF implies closed-loop constraint satisfaction.
That is, if the MPC scheme is recursively feasible, then the
conditions under which constraints (4) are always satisﬁed by
the closed-loop trajectories are trivial. These statements are
formalized for the closed loop (1)-(5) in the following theorem.
Theorem 1. Let the optimization (5)be recursively feasible
and also be feasible at time k= 0. In addition, let t00.
Then, the closed-loop trajectories resulting from the dynamics
(1)and MPC control policy (xk) = ^u
0j0never violate the
constraints (4).
Proof. Because the optimization (5) is feasible at time step
k=0andt00, the applied input u0= ^u
0j0satisﬁes
Fx0+Gu0b t0b: (7)
Therefore, (4) is satisﬁed at time k=0. Moreover, because RF
is satisﬁed, the optimization (5) always remains feasible under
the MPC control law (x). By using a similar argument as the
one presented above for k=0, (4) is satisﬁed for all k0.It can be useful to stress here that Theorem 1 – beyond
RF – requires only that problem (5) is initially feasible, and
that the initial constraint (5c) is “properly” tightened, i.e. that
t00. The latter requirement is arguably trivial.
Remark 1. Theorem 1 relies only on the feasibility of the
solutions to (5)and not on their optimality. As a consequence,
a straightforward corollary is that Theorem 1 also holds under
SRF . Hence, SRF of the closed loop (1)-(5)will guarantee
constraint satisfaction under any control input uk2U0(xk).
That is, even if problem (5)cannot be solved to optimality,
constraint satisfaction is guaranteed by SRF .
Most robust MPC methods explicitly build outer bounds
on worst-case trajectories of the system to ensure constraint
satisfaction [21], [10], which can be interpreted as open-loop
approaches to robust MPC design. This is because trajectories
the predicted by MPC in open loop are designed to lie
inside the system constraints even with perturbations acting
along the prediction horizon. Theorem 1 enables a design
which circumvents this construction altogether, and is the key
element of the closed-loop design presented in this work.
In the following sections, the MPC components
Y;z;ftigN
i=0andlN()will be designed such that SRF
is satisﬁed. The objective is formulate the design of these
components as an optimization problem that needs to be
solved only once, ofﬂine. This ofﬂine optimization will be
presented in Section VI.
IV. N ECESSARY AND SUFFICIENT CONDITIONS FOR SRF
In order to utilize Theorem 1 for design, the SRF of (5)
needs to be guaranteed. In this section, necessary and sufﬁcient
conditions for SRF are derived. The constraints (5b)-(5d) can
be compactly written as
HxuSskb t; (8)
where
sk=h
x|
k^u|
ki|
;Hxu=IN
F0IN
G
0Y 0
;
S=2
66666664I 0::: ::: 0
AB 0::: 0
...............
AN 1AN 2B ::: B 0
ANAN 1B ::: AB B
0 INnu3
77777775=SxSu
b=h
1|
N
b|z|i|
;andt= [t0t1::: tN]|: (9)
One can readily observe that the vector skcollects the initial
statexkand input trajectory ^uk. The matrix Smaps the initial
statexkand input trajectory ^uk, i.e., sk, to the predicted
state-input trajectories; more precisely, Ssk= [^x|
k^u|
k]|. The
matrix Hxumaps the predicted state-input trajectories ( Ssk)
into the left-hand side of constraints (5c)-(5d). Vectors band
tcollect the right-hand side of constraints (5c)-(5d). Let P0
denote the set of all feasible vectors sksatisfying (8), that is,
P0:=fs2Rnx+NnujHxuSsb tg: (10)PARSI et al. : ONCE UPON A TIME STEP: A CLOSED-LOOP APPROACH TO ROBUST MPC DESIGN 5
Observe that SRF is satisﬁed if, for every sk2P0, and for
all possible realizations of xk+1under the control input uk=
^u0jk, disturbance wk2W and perturbation k2P , there
exists an input sequence ^uk+1satisfying
HxuSsk+1b t; (11)
where sk+1= [x|
k+1^u|
k+1]|. Note that (11) can be expressed
in terms of sk,wk, and kby re-writing the state-input
trajectories Ssk+1as
Ssk+1=Sxxk+1+Su^uk+1;
=Sx(Axk+Buk) +Sx 
Bwwk+Bpk(Dxxk
+Duuk+Dwwk)
+Su^uk+1
= (L+SxBpkDxu)sk
+Sx(Bw+BpkDw)wk+Su^uk+1
=Cssk+Cwwk+Su^uk+1; (12)
where
Cs=L+SxBpkDxu;Cw=Sx(Bw+BpkDw);
L=2
666664A B 0nx;(N 1)nu
A2AB 0nx;(N 1)nu.........
AN+1ANB0nx;(N 1)nu
0Nnu;nx+Nnu3
777775;Dxu=2
4Dx
Du
0np;(N 1)nu3
5:
(13)
Note that the matrix Csmapsskinto the predicted state-input
trajectories at time k+ 1. Similarly, Cwprovides the gain
from disturbance wkat timekto the predicted state-input
trajectories at time k+ 1.
Using the above deﬁnitions, necessary and sufﬁcient condi-
tions for SRF are presented in the following theorem.
Theorem 2. The closed loop system (1)-(5)satisﬁes SRF if,
and only if, for all sk2P0,wk2W, andj2Nn
1, there exist
^uj
k+1such that
Hxu
Cj
ssk+Cj
wwk+Su^uj
k+1
b t; (14)
where Cj
s=L+SxBpjDxu, and Cj
w=Sx(Bw+
BpjDw).
Proof. The idea of the proof is brieﬂy described ﬁrst. By
deﬁnition, SRF requires that for every sk2P0,wk2W and
k2P, there exists an input sequence ^uk+1satisfying (11).
Note that the qualiﬁer for all k2P can be rewritten as
for allj2Nn
1, with k=j. Thus, existence of independent
input sequences ^uj
k+1, each corresponding to k=j, ensures
SRF. Using (11) and (12), this condition can be written as (14).
The detailed proof follows.
Sufﬁciency:
Let there exist inputs ^uj
k+1such that (14) is satisﬁed for all
sk2P0,wk2W, andj2Nn
1. Moreover, let the true perturba-
tionkbe given as
k=nX
j=1jj; (15)wherePn
j=1j= 1 andj0. Such a representation is
possible as klies insidePdeﬁned in (2). Consider the input
candidate sequence ^uk+1=Pn
j=1j^uj
k+1for verifying (11).
Then, using (12),
Ssk+1
= (L+SxBpkDxu)sk+Su^uk+1+Sx(Bw+BpkDw)wk
= (L+SxBpnX
j=1jjDxu)sk+SunX
j=1j^uj
k+1+
Sx(Bw+BpnX
j=1jjDw)wk
=nX
j=1j 
(L+SxBpjDxu)sk+Su^uj
k+1+
Sx(Bw+BpjDw)wk
=nX
j=1j
Cj
ssk+Su^uj
k+1+Cj
wwk
: (16)
Therefore, using (14) and (16),
HxuSsk+1=HxunX
j=1j
Cj
ssk+Su^uj
k+1+Cj
wwk
=nX
j=1jHxu
Cj
ssk+Su^uj
k+1+Cj
wwk
nX
j=1j(b t) =b t; (17)
where the inequality is obtained as (14) is satisﬁed by the
inputs ^uj
k+1. Thus, (11) is satisﬁed for all k2P,sk2P0, and
wk2W, and the closed-loop satisﬁes SRF.
Necessity:
Let the closed-loop (1)-(5) satisfy SRF. That is, for all sk2P0,
k2Pandwk2W, there exists ^uk+1satisfying (11). Then,
consider that for each j2Nn
1,^uj
k+1represents the feasible
input sequences for (11) when k=j, and for sk2P0,
wk2W. Using (11) and (12), one obtains
Hxu(L+SxBpjDxu)sk+Su^uj
k+1+
Sx(Bw+BpjDw)wkb t
=)Hxu
Cj
ssk+Cj
wwk+Su^uj
k+1
b t;(18)
proving that (14) is satisﬁed for all j2Nn
1.
Although Theorem 2 provides necessary and sufﬁcient
conditions for the characterization of SRF, (14) is difﬁcult to
directly use in the design of the MPC components Y,zand
t. The difﬁculty arises as one must guarantee the existence of
input sequences satisfying (14) for each sk2P0andwk2W .
Theorem 2 explicitly captures the conditions under which
SRF holds. Whereas Theorem 2 formulates these conditions
as existence of input sequences, the criteria can be written
as set inclusions using ideas from set-invariance [25]. The
early work [17] presents necessary and sufﬁcient conditions to
achieve SRF when uncertainty occurs as additive disturbances.
However, the resulting conditions are not suited for design.6 GENERIC COLORIZED JOURNAL, VOL. XX, NO. XX, XXXX 2023
Recently, analogous conditions were formulated for multi-
plicative perturbations in [20], where polytope projections
were used to verify SRF, given the MPC parameters.
V. S UFFICIENT CONDITIONS FOR SRF USING FEEDBACK
Theorem 2 is difﬁcult to directly use as a design condition
because of the requirement to guarantee the existence of input
sequences. In this section, such a guarantee is achieved by
parameterizing the inputs using feedback gains.
Note that Theorem 2 allows one to design independent input
sequences ^uj
k+1for each j. This is a powerful feature, and
differs from most existing open-loop strategies, where a single
feedback law is designed to compensate for all perturbations
and disturbances [12]. Exploiting the fact that nindependent
input sequences are sufﬁcient to ensure SRF, for each j2
Nn
1, the input sequences ^uj
k+1are parameterized as
^uj
ijk+1= ^uj
i+1jk+Mj
iBwwk+Kj
i;yk;8i2NN 2
0;
^uj
N 1jk+1=Kj^xNjk+Mj
N 1Bwwk+Kj
N 1;yk;(19)
whereyk=x|
ku|
k|, and forj2Nn
1andi2NN 1
0,
Kjrepresents a terminal state feedback gain, Mj
irepresents a
disturbance feedback gain and Kj
i;represents a perturbation
feedback gain. The use of disturbance feedback gains is com-
mon in robust MPC [26]. Moreover, each Kj
i;compensates
for the effect of jon the nominal trajectory. The term ykis
used for feedback as the effect of the perturbation kon the
nominal trajectories also depends on yk(see (12)).
Condition (14) can now be rewritten as the existence of
suitable feedback gains, which can be solved for ofﬂine. The
following notation is introduced to account for the newly
introduced feedback gains. Let for all j2Nn
1
Aj
K:=A+BKj;Mj:=h
Mj
0|Mj
1|::: Mj
N 1|i|
;
Kj
:=h
Kj
0;|Kj
1;|::: Kj
N 1;|i|
;
Lj
K:=2
666666666664A B 0::: 0
A2AB B ::: 0
...............
ANAN 1B AN 2B ::: B
Aj
KANAj
KAN 1B Aj
KAN 2B ::: Aj
KB
0 0 I(N 1)nu
KjANKjAN 1B KjAN 2B ::: KjB3
777777777775;
Cj
K:=Lj
K+SxBpjDxu+
SuKj

Inx+nu0nx+nu;nu(N 1)
;
Cj
M:=Sx(Bw+BpjDw) +SuMjBw: (20)
Here matrix Lj
Kmaps a pair of initial state and the nominal
input trajectory (that is, sk) into the corresponding nominal
predicted state-input trajectory at the next time step, under
the parameterization (19). Matrix Cj
Kmaps skinto a per-
turbed state-input trajectory at the next time step, when the
perturbation k= jand the input is parameterized as (19).
Similarly, Cj
Mmaps the effects of a disturbance wkon the
state-input trajectory at the next time step.P1
sk2P0w2 W
proj(P1) =P0
(a)P1
sk+12P0Pj
2
Under (1),(19),
andk= j
(b)
Fig. 3 : (a) Projection of P1on the space of skoverlaps with P0
by deﬁnition. (b) Pj
2contains all (sk;wk)such thatsk+12P0
holds under the dynamics (1), with k= j,wk2W and
input parameterization (19).
Consider the following polytopes in Rnx+Nnu+nw
P1:=s
wHxuS 0
0Hws
w
b t
hw
;
andPj
2:=s
wHxu
Cj
KCj
Ms
w
b t
;(21)
forj2Nn
1. Polytopes P1andPj
2are depicted in Figure 3,
and can be interpreted in the following manner. Recall that
P0is the set of feasible states and input sequences for MPC,
as deﬁned in (10). Then, P1is the augmentation of P0with
the set of possible disturbances (3). Moreover, Pj
2is the set of
states, inputs and disturbances acting at time step ksuch that,
ifk=j,sk+1lies inside P0. That is, Pj
2is the pre-image
ofP0under the dynamics (1) with k=j,wk2W anduk
as in (19).
Therefore, it can be seen that, if P1Pj
2andk=j, for
anysk2P0andwk2W ,sk+1lies inside P0. Using this
approach, polytopic set inclusions can be deﬁned to guarantee
SRF as shown in the following theorem.
Theorem 3. Consider the polytopes P1andfPj
2gn
j=1pro-
posed in (21). Then, the closed loop (1)-(5)satisﬁes SRF
if there exist feedback gains fKjgn
j=1,ffMj
ign
j=igN 1
i=0 and
ffKj
i;gn
j=igN 1
i=0such that
P1Pj
2;8j2Nn
1: (22)
Proof. For (5) to be strongly recursively feasible, (11) must
be satisﬁed for everys|
kw|
k|2P1andk2P.
Letkbe deﬁned as in (15) and a candidate control input
sequence be deﬁned as ^uk+1=Pn
j=1j^uj
k+1, where ^uj
k+1
are parameterized according to (19). Substituting the candidate
sequence in (12),
Ssk+1= (L+SxBpnX
j=1jjDxu)sk
+Sx(Bw+BpnX
j=1jjDw)wk+SunX
j=1j^uj
k+1(23a)
=nX
j=1j
Lj
K+SxBpjDxuPARSI et al. : ONCE UPON A TIME STEP: A CLOSED-LOOP APPROACH TO ROBUST MPC DESIGN 7
+SuKj

Inx+nu0nx+nu;nu(N 1)
sk
+Sx 
Bw+BpjDw
wk+SuMjBwwk
(23b)
=nX
j=1j
Cj
Ksk+Cj
Mwk
: (23c)
In (23), (23b) is obtained by substituting the control law (19)
in (23a) and using the deﬁnition of Lj
K. Using (23), it can be
seen that
HxuSsk+1=HxunX
j=1j
Cj
Ksk+Cj
Mwk
(24a)
=nX
j=1jHxu 
Cj
Ksk+Cj
Mwk
(24b)
nX
j=1j(b t)b t; (24c)
where (24c) is obtained because anys|
kw|
k|inside P1
also lies inside Pj
2from (22). Therefore, (11) is satisﬁed for
all feasible realizations of sk,kandwkunder the proposed
feedback if (22) holds, and so the closed loop (1)-(5) satisﬁes
SRF.
Observe that unlike (14), (22) does not depend on the state
xk. Thus, (22) can be used to compute the MPC components
ofﬂine. The following result based on Farkas’ Lemma will be
used to reformulate (22).
Lemma 1. [7, Lemma 5.6] Let Xi=fxjHixhigfor
i= 1;2be two polytopes. Then, X1X2is satisﬁed if, and
only if, there exists a matrix such that
0;H1=H2;h1h2: (25)
Note that the ﬁrst inequality in (25) is element-wise.
Proposition 1. The set inclusions (22) are satisﬁed if, and
only if, there exist matrices fjgn
j=1such that
j0;jb t
hw
b t; (26a)
j
HxuS 0
0Hw
=Hxu
Cj
KCj
M
;8j2Nn
1:(26b)
Proof. The proof follows from a direct application of Lemma
1 to each set inclusion in (22).
Conditions (26) will be used in the following section to
build a robust MPC scheme satisfying SRF.
VI. D ESIGN OF ROBUST MPC SATISFYING SRF
In this section, (26) will be used as constraints in the
design of the MPC components to ensure SRF and therefore
constraint satisfaction. We present viable algorithmic solutions
to enforce (26) while minimizing the tightening of the con-
straints, so as to promote a larger region of attraction for the
closed-loop problem.A. Terminal components
It can already be seen that Theorem 1 imposes the constraint
t00. Additionally, Proposition 1 explicitly formulates
constraints under which the MPC problem satisﬁes SRF. The
MPC components in (5) which are to be computed are Y;z;t,
and the terminal cost lN(). The design for SRF does not
depend on the choice of the cost function, and hence, lN()
will be deﬁned later.
Ideally, all the components Y;z;twould be set as decision
variables in the ofﬂine design problem. However, this would
result in large number of bilinear constraints in (26), as Y
is a component of Hxudeﬁned in (9). Thus, in this work, a
popular strategy from the literature is used to choose Yandz
a priori [7]. Speciﬁcally, they are chosen to be of the structure
of maximal robust positively invariant sets under a terminal
feedback law KY, given as
Y:=2
6664F+GKY
(F+GKY)(A+BKY)
...
(F+GKY)(A+BKY)k03
7775;z:=2
6664b
b
...
b3
7775; (27)
whereKYis a feedback chosen such that A+BKYis Schur
stable, and k0is a positive scalar chosen by the designer
depending on the desired ﬂexibility. Although the components
Yandzare ﬁxed, the tightenings tNallow the optimizer to
modify the terminal set.
B. Ofﬂine optimization for constraint tightening
Given an uncertain model (1)-(3) and constraint set (4), the
terminal set is computed as in (27), and the following opti-
mization problem can be solved to compute the tightenings,
t.
min
t;
fKj;j;Mj;Kj
gn
j=1lt(t)
s.t. (26); t00; ft(t)0:(28)
In (28),lt()represents an objective function, and ft()
represents additional constraints which can be imposed on
the tightenings based on the desired goal of the control
application. Moreover, the constraint t00needs to be
explicitly enforced, so that recursive feasibility of (5) results
in robust constraint satisfaction, as shown in Theorem 1. Note
that the guarantees derived in Theorem 3 and Proposition 1
are independent of lt()andft(), as long as the constraints
(26) are satisﬁed.
Here, we describe one possible strategy of choosing lt()
andft(), where the design objective is to maximize the
region of attraction (ROA) of the closed-loop system. The
ROA is deﬁned by the feasible region of the state for the
MPC optimization (5), and thus is a convex polytope. Because
the volume of a generic polytope is difﬁcult to compute even
when the hyperplanes are known a priori [27], maximizing
ROA is a difﬁcult task. Under the chosen structure of the
optimization problem (5), minimization of ktk2
2can be used
as an approximation for maximizing ROA as proposed in [22].
However, solely approximating ROA maximization with
minimization ofktk2
2can sometimes lead to poor results.8 GENERIC COLORIZED JOURNAL, VOL. XX, NO. XX, XXXX 2023
In this work, the approximation is improved by additionally
maximizing the size of an l1-norm ball that can ﬁt inside the
feasible region of the state space. Consider the vertices of the
unit-l1-norm ball in Rnx, represented byfxig2nx
i=1, which lie
on the positive and negative directions of the principal axes
of the state space. For each vertex of the l1-norm ball, deﬁne
the corresponding MPC optimization variable si
as
si
=xi
ui
;8i2N2nx
1 (29)
whereis a positive scalar deﬁning the size of the l1-norm
ball, and uirepresents a feasible input sequence for the ith
vertex. Then, the ofﬂine optimization problem can be written
as
min
t;;fuig2nx
i=1;
fj;Kj;Mj;Kj
gn
j=1ktk2
2  (30a)
s.t. j0; > 0; t 00; (30b)
jHxuS 0
0Hw
=Hxu
Cj
KCj
M
; (30c)
jb t
hw
b t;8j2Nn
1; (30d)
HxuSsi
b t;8i2N2nx
1; (30e)
whereis a positive weighting factor between minimizing
ktk2and maximizing . Additionally, (30e) represent the
feasibility constraints for each vertex of the l1-norm ball.
The optimization problem (30) is non-convex, due to the
presence of bilinear constraints (30d). Although this increases
the complexity of design, problem (30) needs to be solved only
once, in the ofﬂine phase. Note that the number of bilinearities
is greatly reduced because Yandzare chosen beforehand, and
consequently (30c) are afﬁne constraints. Moreover, given a
good initial guess of the tightenings t, feasible solutions to all
the other optimization variables can be computed by solving
a convex optimization problem (by ﬁxing tin (30)). This
provides a simple way to initialize non-convex optimization
techniques which can solve (30).
Remark 2 (Initial guess) .It can be difﬁcult to compute a
feasible initial guess for the tightenings tin(30), as the
tightenings are problem dependent. In practice, one strategy
which produced good results was to use an existing constraint
tightening technique, such as [21] or [22] to guess t. Note
that these techniques were designed for systems affected by
additive disturbances alone, and may not always result in
feasible initial guesses for t.
C. Cost functions and online optimization
Whereas the constraints in (5) are designed to ensure recur-
sive feasibility, the cost function must be chosen to guarantee
closed-loop stability. A quadratic tracking cost formulation is
presented here for simplicity, but the method proposed here
can easily be extended to economic cost functions. Consider
the stage cost deﬁned as
l(x;u) =x|Qxx+u|Quu; (31)where the matrices Qx;Quare positive deﬁnite. The design
task is to choose a terminal cost of the form lN(x) =x|QNx
such that the closed-loop system is stable. This can be achieved
by choosing QNto be a positive deﬁnite matrix satisfying
8j2Nn
1
(1 +)Cj|
KQsCj
K S|QsS Px0
0Pu
= P; (32)
whereQs:=diagfQx
IN;QN;Qu
INg,2R>0is
a design parameter and Px2Rnxnx,Pu2RNnuNnu
are positive deﬁnite matrices. The values of andPaffect
the resulting stability margin as will be shown Section VI-
D. For a given and known values of the feedback gains
fKj;Mj;Kj
gn
j=1, constraints (32) are linear matrix inequal-
ities in the variables QNandP. There are multiple strategies
which can be used to choose QNsuch that (32) holds, for
example, by minimizing the trace of QNor minimizing the
deviation of QNfrom the inﬁnite horizon LQR gain.
The online optimization can then be written as
min
^xk;^uk^x|
NjkQN^xNjk+N 1X
i=0
^x|
ijkQx^xijk+ ^u|
ijkQu^uijk
(33a)
s.t.A^xijk+B^uijk= ^xijk+1;^xk;0=xk; (33b)
F^xijk+G^uijkb ti; i2NN 1
0; (33c)
Y^xNjkz tN: (33d)
The computational complexity of (33) is the same as that of
a nominal MPC problem. This enables a large computational
advantage compared to existing robust MPC methods, such as
tube MPC [14].
D. Algorithm and properties
Using the ofﬂine (30) and online (33) optimization prob-
lems, a robust MPC algorithm is formally described in Al-
gorithm 1. It can be seen that the ofﬂine phase involves the
computation of tby solving (30), and subsequently choosing
the terminal cost matrix such that (32) holds. Although a less
conservative approach would be to include (32) as an addi-
tional constraint in (30), this results in a semi-deﬁnite program
with bilinear constraints, and is difﬁcult to solve. An alterna-
tive approach is to ﬁrst compute QNandfKj;Mj;Kj
gn
j=1
satisfying (32), and then solving (30) with the resulting control
gains.
Algorithm 1 Closed-loop robust MPC
Ofﬂine:
1:ChooseN;KY, and compute Yandz
2:Chooseand
3:Solve (30) to compute tand control gains
4:ChooseQNsatisfying (32)
Online: At each time-step k0:
1:Obtain the measurement xk
2:Solve (33)
3:Apply(xk) = ^u
k;0PARSI et al. : ONCE UPON A TIME STEP: A CLOSED-LOOP APPROACH TO ROBUST MPC DESIGN 9
The properties of the proposed algorithm will now be
discussed. For this purpose, the notion of regional input-to-
state stability (ISS) is ﬁrst deﬁned.
Deﬁnition 3 (Regional ISS in X[28]) .Given a system with
dynamics (1)-(3)and a compact set XRnxincluding the
origin as an interior point, the system is said to be regionally
ISS inXwith respect to wkifXis a robust positively invariant
set and if there exist a KLfunction(;)and aKfunction
1()such that, for all x02Xandk0
kxkk(kx0k;k) +1(w[0:k 1]); (34)
wherew[0:k 1]= supi2Nk 1
0kwik.
A sufﬁcient condition to guarantee ISS of a system is the
existence of an ISS Lyapunov function [28], deﬁned below.
Deﬁnition 4. Consider the system (1)-(3)and a compact set
XRnxincluding the origin as an interior point. A function
V:Rn!R0is called an ISS Lyapunov function in Xwith
respect towkif there existK1functions1();2();3()
and aKfunction2()such that8xk2X
1(kxkk)V(xk)2(kxkk); (35a)
V(xk+1) V(xk) 3(kxkk) +2(wk): (35b)
Theorem 4. Let the ofﬂine optimization problem (30) be feasi-
ble, the cost function satisfy (32), and the online optimization
(33) have a feasible solution at time k= 0. Moreover, let P0;x
be the projection of P0on the ﬁrstnxelements of sk, and let
the origin be an interior point of P0;x. Then, the closed loop
formed by a system with dynamics (1)-(3)and the robust MPC
controller in Algorithm 1 satisﬁes the following properties:
(a) The problem (33) remains feasible for all k>0.
(b) The constraints (4)are satisﬁed for all k>0.
(c) The closed-loop system is ISS in P0;xwith respect to wk.
Proof. In order to prove property (a), note that the constraints
in Proposition 1 are satisﬁed because the ofﬂine optimization
(30) is feasible. Therefore, the set inclusions (22) are satisﬁed,
and Theorem 3 implies that the online MPC optimization (33)
is strongly recursively feasible. Moreover, because (33) admits
a feasible solution at time k= 0, it remains feasible for all
k>0.
The property (b) follows from Theorem 1. This is because
the ofﬂine optimization (30) explicitly enforces t00, and
SRF implies RF.
The proof of (c) can be seen as follows. Let the optimal
MPC cost function be a candidate ISS Lyapunov function
denoted by
V(xk) = ^x|
NjkQN^x
Njk+N 1X
i=0
^x|
ijkQx^x
ijk+ ^u|
ijkQu^u
ijk
=s|
kS|QsSs
k:
(36)
In the following, it will be shown that V(x)satisﬁes (35).
Consider1(kxk) =min(Qx)kxk2, which is guaranteed to
be a lower bound of V(x). Moreover, V(x)is a continuous
and piecewise quadratic function in P0;xas shown in [29].Therefore, the existence of 2()satisfying (35a) is a direct
consequence of [28, Lemma 4].
In order to show (35b), let the perturbation kbe given as
(15) and consider the candidate input sequences in (19). The
cost function satisﬁes
V(xk+1) V(xk) =s|
k+1S|QsSs
k+1 s|
kS|QsSs
k
nX
j=1j
Cj
Ks
k+Cj
Mwk|
QsnX
l=1l
Cl
Ks
k+Cl
Mwk
 s|
kS|QsSs
k (37a)

1 +1

(w|
kCM()|QsCM()wk) +
(1 +) (s|
kCK()|QsCK()s
k) s|
kS|QsSs
k(37b)
2(wk) +s|
k((1 +)CK()|QsCK() S|QsS)s
k
(37c)
where CK() :=Pn
j=1jCj
KandCM() :=Pn
j=1jCj
M,
and (37b) is obtained by applying Cauchy-Schwarz theorem
and Fenchel’s inequality [30], by which, kx+wk  (1 +
)kxk+ (1 +1
)kwkfor any>0. The function 2(wk)in
(37c) can chosen as the ﬁrst term in (37b). Moreover, using
(32), it can be seen that
S|QsS P (1+)Cj|
KQsCj
K0;8j2Nn
1 (38a)
=)(1+) 1Q 1
s Cj
K
Cj|
K S|QsS P
0;8j2Nn
1;
(38b)
=)2
66664nX
j=1j(1+) 1Q 1
snX
j=1jCj
K
nX
j=1jCj|
KnX
j=1j(S|QsS P)3
777750;
(38c)
=)(1+) 1Q 1
s CK()
CK()|(S|QsS P)
0; (38d)
=)S|QsS P (1+)CK()|QsCK()0;(38e)
where the Schur complement lemma [31] is used to obtain
(38b) and (38e). Using (37c) and (38e),
V(xk+1) V(xk)2(wk) s|
kPs
k
2(wk) x|
kPxxk=2(wk) 3(kxkk):(39)
Thus,V(x)satisﬁes (35), and is an ISS Lyapunov function of
the system. Therefore, applying [32, Lemma 3.5], the closed-
loop system is ISS.
It can be seen that is used to deﬁne 2(), which affects
the function 1()in (34) [32]. Thus, the choice of affects
the stability margin of the robust MPC controller, and can be
used as a tuning parameter by the designer.
E. Discussion
The central idea of this work is that RF is a one-step
property, and can be used to guarantee constraint satisfaction
in closed loop as shown in Theorem 1. However, barring a few
results in early MPC literature such as [21], [17], this idea has10 GENERIC COLORIZED JOURNAL, VOL. XX, NO. XX, XXXX 2023
not been fully utilized. Hence, some discussion is warranted
on interesting research directions.
1) Beyond constraint tightening: Theorem 1 does not restrict
the robust MPC optimization to be of the structure (33), which
is a characteristic of constraint tightening techniques. The
theorem is also valid for any MPC optimization of the form
min
^xk;^uk^x|
NjkQN^xNjk+PN 1
i=0^x|
ijkQx^xijk+ ^u|
ijkQu^uijk
(40a)
s.t. ^xk;0=xk; (40b)
A^xijk+B^uijk= ^xijk+1;8i2NN 1
0; (40c)
F^x0jk+G^u0jkb; (40d)
x^x0jk+ u^uk; (40e)
where x;uandcan be chosen by the designer. In (40),
the system constraints (4) are only imposed on the ﬁrst state
and input in the prediction horizon in (40d), which can be
seen as selecting t0= 0 in (5). Using a similar approach as
in Theorem 3 and Proposition 1, sufﬁcient conditions can also
be derived for SRF of (40). However, in practice, solving the
resulting non-convex optimization problem is harder, due to
the higher number of bilinearities.
2) Robust control invariance: A key concept which is known
in control literature is that of robust control invariance (RCI)
[25], [8]. As opposed to robust invariance (RI), which consid-
ers invariance of autonomous systems subject to uncertainty,
RCI considers controlled dynamical systems. For this reason,
computation of RCI sets is challenging [18], [19].
RCI provides an alternative interpretation of Theorem 2.
A necessary and sufﬁcient condition for strong recursive
feasibility of MPC is that the feasible region is RCI. Because
generic RCI sets are difﬁcult to compute, the proposed method
uses parameterized feedback laws to formulate the problem as
computation of the resulting parameterized RI sets. Note that
all RI sets are also RCI sets, and are easier to compute in
practice.
VII. I LLUSTRATIVE EXAMPLE
In this section, Algorithm 1 will be used to generate a
controller for a mass-spring-damper system, where two masses
are connected to each other by a spring and a damper, and the
spring constant and damping coefﬁcient are uncertain.
The example has been adapted from [12], where similar
systems with increasing number of masses are considered, and
a tube MPC strategy was used to design the controller. The
state of the system is a vector of the position and velocity of
each mass, and the control input is a vector of forces acting
on each mass. The system dynamics can be represented in
discrete time by
A=2
6641Ts 0 0
 k12Ts
m1 c12Ts
m1+1k12Ts
m1c12Ts
m1
0 0 1 Ts
k12Ts
m2c12Ts
m2 k12Ts
m2 c12Ts
m2+13
775;
Bp=2
6640 0
kuTs
m1cuTs
m1
0 0
 kuTs
m2 cuTs
m23
775;B=2
6640 0
Ts
m10
0 0
0Ts
m23
775;Bw=wbB;Dx= 1 0
0 1
; Du= 0; Dw= 0; (41)
wherem1=m2= 0:2kg is the mass, k12= 0:5Nm 1
andc12= 0:5Nsm 1are the nominal spring constant and
damping coefﬁcient. In addition, Ts= 0:1srepresents the
sampling time used for discretization, and wb= 0:2represents
the bound on a disturbance acting on the velocity states. The
magnitudes of all the states and inputs are bounded by 2. The
termsku=0:04k12andcu= 0:02c12model the structured
uncertainty matrix Bp. The matrices jdeﬁningPin (2) were
chosen as diagonal matrices of size 22with1on each
diagonal entry, modeling a 4%uncertainty for the spring
constant, and2%uncertainty for the damping coefﬁcient.
Two controllers are designed for the system. The ﬁrst uses
Algorithm 1, and is referred to as CLR, for closed-loop robust
MPC. The second uses the method proposed in [12], where
an ellipsoidal tube is constructed at each time step by the
controller to bound the states and inputs in the prediction
horizon. This method will be referred to as ET, for ellipsoidal
tube MPC. Both the controllers use N= 5 time steps. The
terminal constraints of CLR are computed using KYchosen as
the LQR gain, and k0= 2. The constants andwere chosen
as 2 and 0.1 respectively. The terminal cost is computed such
that it satisﬁes (32) and its deviation from the inﬁnite horizon
LQR gain is minimized.
The initial state of the system is chosen to be x0=
[1:9;0:5; 1:7;1:7]|. The disturbance affecting the system is
the same for both the controllers, and is sampled from a
uniform distribution in W. The simulations were performed for
25 realizations of the spring constants, damping coefﬁcients
and disturbance sequences chosen using a uniform distribution
within the speciﬁed bounds.
It was observed that CLR requires higher ofﬂine com-
putation time compared to ET, and a much lower online
computation time. This is because the ET algorithm solves
semi deﬁnite programs ofﬂine and online, whereas CLR solves
a non-convex optimization ofﬂine and a quadratic program
online. All the optimization problems were solved on a laptop
with Intel i7-8550U processor, and formulated using YALMIP
[33]. The convex optimization problems were solved using
Gurobi [34] and MOSEK [35], and the non-convex optimiza-
tion using IPOPT [36]. The ofﬂine computation time for the
CLR controller is 45:1s, whereas that for ET is 0:06s. For
solving (30), an initial guess for the tightenings was computed
as follows. Ignoring the perturbation from k, the approach
from [22] was used to obtain a tightening. This tightening was
then scaled by a factor of 1.7, which was a feasible initial
guess for (30). The average online computation time for CLR
is2:2ms, whereas that for ET is 53:9ms.
The closed-loop trajectories of the system are shown in
Figure 4, where highlighted regions show the upper and
lower bounds of state and input variables at each time step
in closed loop over all the simulations. It can be seen that
both controllers successfully regulate the state to the origin
without constraint violations. However, the ET controller is
aggressive at the start of the simulation, because the initial
position is too close to the constraint, and the corresponding
velocity is positive. Moreover, the ET controller recursivelyPARSI et al. : ONCE UPON A TIME STEP: A CLOSED-LOOP APPROACH TO ROBUST MPC DESIGN 11
Fig. 4 : Upper and lower bounds on the closed-loop trajectories
with CLR and ET MPC algorithms over 25 random realiza-
tions of disturbances and true system parameters.
outer-approximates the effect of worst-case perturbations on
state trajectories over the prediction horizon, resulting in the
aggressive behavior. The average closed-loop cost achieved by
CLR is 83.0 and that for ET is 93.7, which is a 11:4%cost
reduction.
VIII. C ONCLUSIONS
A novel design approach was presented for robust MPC, us-
ing the property that recursive feasibility can imply constraint
satisfaction in closed loop. Recursive feasibility is a one-step
property, meaning that it depends on perturbations occurring at
onetime step. Moreover, recursive feasibility only requires the
existence of a feasible input sequence at the subsequent time
step, as the MPC optimizer can compute the input sequence in
closed loop. Exploiting these ideas, it was shown that recursive
feasibility can be imposed as a constraint in the robust MPC
design. Such a design reduces the conservatism of most
existing MPC methods, which ensure constraint satisfaction
by computing feasible open-loop trajectories under multiple
perturbations and disturbances occurring along the prediction
horizon.
REFERENCES
[1] S. J. Qin and T. A. Badgwell, “A survey of industrial model predictive
control technology,” Control engineering practice , vol. 11, no. 7, pp.
733–764, 2003.
[2] G. Williams, P. Drews, B. Goldfain, J. M. Rehg, and E. A. Theodorou,
“Information-theoretic model predictive control: Theory and applications
to autonomous driving,” IEEE Transactions on Robotics , vol. 34, no. 6,
pp. 1603–1622, 2018.
[3] R. Pieters, S. Lombriser, A. Alvarez-Aguirre, and B. J. Nelson, “Model
predictive control of a magnetically guided rolling microrobot,” IEEE
Robotics and Automation Letters , vol. 1, no. 1, pp. 455–460, 2016.
[4] F. Lejarza and M. Baldea, “Economic model predictive control for robust
optimal operation of sparse storage networks,” Automatica , vol. 125, p.
109346, 2021.[5] J. B. Rawlings and D. Q. Mayne, Model predictive control: theory,
computation, and design . Nob Hill Publishing Madison, WI, 2009.
[6] M. L. Darby and M. Nikolaou, “MPC: Current practice and challenges,”
Control Engineering Practice , vol. 20, no. 4, pp. 328–342, 2012.
[7] B. Kouvaritakis and M. Cannon, Model predictive control: Classical,
robust and stochastic . New York, NY: Springer International Publishing,
2015.
[8] E. C. Kerrigan, “Robust constraint satisfaction: Invariant sets and pre-
dictive control,” Ph.D. dissertation, University of Cambridge UK, 2001.
[9] J. L ¨ofberg, “Oops! I cannot do it again: Testing for recursive feasibility
in MPC,” Automatica , vol. 48, no. 3, pp. 550–555, 2012.
[10] J. Fleming, B. Kouvaritakis, and M. Cannon, “Robust tube MPC for
linear systems with multiplicative uncertainty,” IEEE Transactions on
Automatic Control , vol. 60, no. 4, pp. 1087–1092, 2014.
[11] J. Hu and B. Ding, “Output feedback robust MPC for linear systems
with norm-bounded model uncertainty and disturbance,” Automatica ,
vol. 108, p. 108489, 2019.
[12] A. Parsi, A. Iannelli, and R. S. Smith, “Scalable tube model predictive
control of uncertain linear systems using ellipsoidal sets,” International
Journal of Robust and Nonlinear Control , 2022, doi: 10.1002/rnc.6485.
[13] D. Q. Mayne, M. M. Seron, and S. V . Rakovi ´c, “Robust model predic-
tive control of constrained linear systems with bounded disturbances,”
Automatica , vol. 41, no. 2, pp. 219–224, 2005.
[14] L. Schwenkel, J. K ¨ohler, M. A. M ¨uller, and F. Allg ¨ower, “Model
predictive control for linear uncertain systems using integral quadratic
constraints,” IEEE Transactions on Automatic Control , 2022.
[15] M. Maiworm, T. B ¨athge, and R. Findeisen, “Scenario-based model pre-
dictive control: Recursive feasibility and stability,” IFAC-PapersOnLine ,
vol. 48, no. 8, pp. 50–56, 2015.
[16] L. Chisci and G. Zappa, “Robustifying a predictive controller against
persistent disturbances,” in 1999 European Control Conference (ECC) ,
1999, pp. 2419–2424.
[17] E. C. Kerrigan and J. M. Maciejowski, “Robust feasibility in model
predictive control: necessary and sufﬁcient conditions,” in Proceed-
ings of the 40th IEEE Conference on Decision and Control (Cat.
No.01CH37228) , vol. 1, 2001, pp. 728–733 vol.1.
[18] S. V . Rakovic, E. C. Kerrigan, D. Q. Mayne, and K. I. Kouramas,
“Optimized robust control invariance for linear discrete-time systems:
Theoretical foundations,” Automatica , vol. 43, no. 5, pp. 831–841, 2007.
[19] M. Rungger and P. Tabuada, “Computing robust controlled invariant sets
of linear systems,” IEEE Transactions on Automatic Control , vol. 62,
no. 7, pp. 3665–3670, 2017.
[20] Y . Abdelsalam, S. Subramanian, and S. Engell, “Synthesis of compu-
tationally efﬁcient recursively feasible multi-stage predictive controllers
for uncertain linear systems,” IEEE Control Systems Letters , vol. 6, pp.
1796–1801, 2021.
[21] L. Chisci, J. A. Rossiter, and G. Zappa, “Systems with persistent
disturbances: Predictive control with restricted constraints,” Automatica ,
vol. 37, no. 7, pp. 1019–1028, 2001.
[22] A. Parsi, P. Anagnostaras, A. Iannelli, and R. S. Smith, “Computationally
efﬁcient robust MPC using optimized constraint tightening,” in 61st
IEEE Conference on Decision and Control , 2022.
[23] J. Doyle, A. Packard, and K. Zhou, “Review of LFTs, LMIs, and mu,”
inProceedings of the 30th IEEE Conference on Decision and Control ,
vol. 2, 1991, pp. 1227–1232.
[24] F. Borrelli, A. Bemporad, and M. Morari, Predictive control for linear
and hybrid systems . Cambridge University Press, 2017.
[25] F. Blanchini and S. Miani, Set-theoretic methods in control . Boston:
Birkh ¨auser, 2008.
[26] P. J. Goulart, E. C. Kerrigan, and J. M. Maciejowski, “Optimization over
state feedback policies for robust control with constraints,” Automatica ,
vol. 42, no. 4, pp. 523–533, 2006.
[27] J. Lawrence, “Polytope volume computation,” Mathematics of compu-
tation , vol. 57, no. 195, pp. 259–271, 1991.
[28] D. Limon, T. Alamo, D. M. Raimondo, D. M. D. L. Pena, J. M.
Bravo, A. Ferramosca, and E. F. Camacho, “Input-to-state stability:
A unifying framework for robust model predictive control,” Nonlinear
model predictive control , pp. 1–26, 2009.
[29] A. Bemporad, M. Morari, V . Dua, and E. Pistikopoulos, “The explicit
linear quadratic regulator for constrained systems,” Automatica , vol. 38,
no. 1, pp. 3–20, 2002.
[30] S. Boyd and L. Vandenberghe, Convex optimization . Cambridge
university press, 2004.
[31] F. Zhang, The Schur complement and its applications . Springer Science
& Business Media, 2006, vol. 4.
[32] Z. Jiang and Y . Wang, “Input-to-state stability for discrete-time nonlinear
systems,” Automatica , vol. 37, no. 6, pp. 857–869, 2001.12 GENERIC COLORIZED JOURNAL, VOL. XX, NO. XX, XXXX 2023
[33] J. L ¨ofberg, “YALMIP : A toolbox for modeling and optimization in
MATLAB,” In Proceedings of the CACSD Conference , 2004.
[34] Gurobi Optimization, LLC, “Gurobi Optimizer Reference Manual,”
2022. [Online]. Available: https://www.gurobi.com
[35] MOSEK ApS, The MOSEK optimization toolbox for
MATLAB manual. Version 9.0. , 2019. [Online]. Available:
http://docs.mosek.com/9.0/toolbox/index.html
[36] A. W ¨achter and L. T. Biegler, “On the implementation of an interior-
point ﬁlter line-search algorithm for large-scale nonlinear programming,”
Mathematical programming , vol. 106, no. 1, pp. 25–57, 2006.