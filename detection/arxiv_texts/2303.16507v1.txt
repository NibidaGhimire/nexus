Improving Object Detection in Medical Image Analysis through Multiple Expert
Annotators: An Empirical Investigation
Hieu H. Pham
Coordinated Science Laboratory, UIUC
VinUni-Illinois Smart Health Center & CECS, VinUniversity
hieu.ph@vinuni.edu.vnKhiem H. Le
VinUniversity
khiem.lh@vinuni.edu.vn
Tuan V . Tran
VinUniversity
tuan.tv@vinuni.edu.vnHa Q. Nguyen
Vingroup Big Data Institute
v.hanq3@vinbigdata.org
1. Introduction
The work discusses the use of machine learning algo-
rithms for anomaly detection in medical image analysis and
how the performance of these algorithms depends on the
number of annotators and the quality of labels. To address
the issue of subjectivity in labeling with a single annota-
tor, we introduce a simple and effective approach that ag-
gregates annotations from multiple annotators with varying
levels of expertise. We then aim to improve the efﬁciency
of predictive models in abnormal detection tasks by estimat-
ing hidden labels from multiple annotations and using a re-
weighted loss function to improve detection performance.
Our method is evaluated on a real-world medical imaging
dataset and outperforms relevant baselines that do not con-
sider disagreements among annotators. This work1has been
accepted for publication by IEEE Access and its full form
can be found in [7]. We also released the dataset and the
code used in this study2.
2. Learning from multiple annotators
Existing works that are highly related to our work, in-
cluding learning from multiple annotators [4–6, 8, 20–22,
24, 25, 27, 29, 29, 31, 33–35] and weighted training tech-
niques [1–3,9,23,26,32]. Unlike any approaches above, we
aggregated annotations from multiple annotators and pro-
pose a re-weighted loss function that assigns more weights
to more conﬁdent examples that determine by the consen-
sus of multiple annotators. Figure 1 shows an overview of
our method. Speciﬁcally, we ﬁrst estimate the actual la-
bels using WBF algorithm [28]. They are then used to train
a typical object detector with a re-weighted loss function.
1This is a short version submitted to the Midwest Machine Learning
Symposium (MMLS 2023), Chicago, IL, USA.
2https://vindr.ai/datasets/cxr .Note a general form of the loss function for those detectors
can be written as
L(p;p;t;t) =Lcls(p;p) +I(t)Lloc(t;t)
I(t) =1ifIoUfa;ag>
0otherwise:(1)
wheretandtare the predicted and ground truth box co-
ordinates,pandpare the class category probabilities, re-
spectively; IoUfa;agdenotes the Intersection over Union
(IoU) between the anchor aand its ground truth a;is an
IoU threshold for objectness, i.e. the conﬁdence score of
whether there is an object or not; is a constant for balanc-
ing two loss terms LclsandLloc[36]. We use fused boxes
conﬁdence scores ci
kobtained from WBF algorithm [28] to
get a re-weighted loss function that emphasizes boxes with
high annotators agreement. The new loss function can now
be written as
L(p;p;t;t) =cLcls(p;p) +cI(t)Lloc(t;t):(2)
Figure 1. Illustration of the proposed approach.
3. Experiments and Results
We validated our method on VinDr-CXR [11], a real-
world chest X-ray dataset with labels provided by multiple
1arXiv:2303.16507v1  [cs.CV]  29 Mar 2023radiologists for a typical task medical imaging [10, 12–19,
30]. It consists of 18,000 chest X-ray scans, with 15,000 for
training and 3,000 for testing sets. We compared the per-
formance of the proposed method against (1) Baseline
using all annotations as the ground truth; models trained
on annotations provided by each annotator independently
(Annotators #1, #2, #3 ) and (3) an ensemble of
independent models trained on separate radiologists’ an-
notation sets. Table 1 reports the experimental results in
mAP@0.4 score. Our method outperforms the baselines,
individual models, and even the ensemble of individual ex-
perts’ models. Experimental results validated the effective-
ness of the proposed method.
Table 1. Experimental results on the VinDr-CXR dataset.
Method mAP@0.4
Baseline 0.148
Annotator #1 0.121
Annotator #2 0.132
Annotator #3 0.124
Ensemble of all annotators 0.154
Ours 0.158
4. Discussions and Conclusion
The proposed method is the ﬁrst effort to train an im-
age detector from labels provided by multiple annotators.
We empirically showed a notable improvement in terms of
mAP scores by estimating the true labels and then integrat-
ing the implicit annotators’ agreement into the loss function
to emphasize the accurate bounding boxes over the impre-
cise ones. The idea is simple but effective, allowing the
overall framework can be applied in training any machine
learning-based detectors. However, the overall architecture
is not end-to-end. It may not fully exploit the beneﬁts of
combining truth inference and training the desired image
detector.
References
[1] Devansh Arpit, Stanisław Jastrzundeﬁnedbski, Nico-
las Ballas, David Krueger, Emmanuel Bengio, Maxin-
der S. Kanwal, Tegan Maharaj, Asja Fischer, Aaron
Courville, Yoshua Bengio, and Simon Lacoste-Julien.
A closer look at memorization in deep networks.
InProceedings of the 34th International Confer-
ence on Machine Learning , ICML’17, page 233–242.
JMLR.org, 2017. 1
[2] Yoshua Bengio, J ´erˆome Louradour, Ronan Collobert,
and Jason Weston. Curriculum learning. In Proceed-
ings of the 26th Annual International Conference on
Machine Learning , ICML ’09, page 41–48, New York,NY , USA, 2009. Association for Computing Machin-
ery. 1
[3] N. Dalal and B. Triggs. Histograms of oriented gradi-
ents for human detection. In IEEE Computer Society
Conference on Computer Vision and Pattern Recogni-
tion, volume 1, pages 886–893 vol. 1, 2005. 1
[4] A. Dawid and A. Skene. Maximum likelihood es-
timation of observer error-rates using the em algo-
rithm. Journal of The Royal Statistical Society Series
C-applied Statistics , 28:20–28, 1979. 1
[5] Yuan Jin, Mark Carman, Ye Zhu, and Yong Xiang.
A technical survey on statistical modelling and design
methods for crowdsourcing quality control. Artiﬁcial
Intelligence , page 103351, 2020. 1
[6] David Karger, Sewoong Oh, and Devavrat Shah. Iter-
ative learning for reliable crowdsourcing systems. Ad-
vances in Neural Information Processing Systems , 24,
2011. 1
[7] Khiem H Le, Tuan V Tran, Hieu H Pham, Hieu T
Nguyen, Tung T Le, and Ha Q Nguyen. Learning from
multiple expert annotators for enhancing anomaly de-
tection in medical image analysis. IEEE Access ,
11:14105–14114, 2023. 1
[8] Jingzheng Li, Hailong Sun, Jiyi Li, Zhijun Chen, Ren-
shuai Tao, and Yufei Ge. Learning from multiple an-
notators by incorporating instance features, 2021. 1
[9] Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming
He, and Piotr Doll ´ar. Focal loss for dense object detec-
tion. In Proceedings of the IEEE International Con-
ference on Computer Vision , pages 2980–2988, 2017.
1
[10] Huy Ngoc Nguyen, Hieu Pham, Thanh Tran, Tuan
Nguyen, and Quy Ha Nguyen. Vindr-pcxr: An open,
large-scale chest radiograph dataset for interpretation
of thoracic diseases in children. medRxiv , pages 2022–
03, 2022. 2
[11] Ha Q Nguyen, Khanh Lam, Linh T Le, Hieu H Pham,
Dat Q Tran, Dung B Nguyen, Dung D Le, Chi M
Pham, Hang TT Tong, Diep H Dinh, et al. VinDr-
CXR: An open dataset of chest X-rays with radiolo-
gist’s annotations. arXiv preprint arXiv:2012.15029 ,
2020. 1
[12] Hieu Trung Nguyen, Ha Quy Nguyen, Hieu Huy
Pham, Khanh Lam, Linh Tuan Le, Minh Dao, and Van
Vu. Vindr-mammo: A large-scale benchmark dataset
for computer-aided diagnosis in full-ﬁeld digital mam-
mography. MedRxiv , pages 2022–03, 2022. 2
[13] Hieu T Nguyen, Hieu H Pham, Nghia T Nguyen,
Ha Q Nguyen, Thang Q Huynh, Minh Dao, and Van
Vu. Vindr-spinexr: A deep learning framework for
2spinal lesions detection and classiﬁcation from radio-
graphs. In Medical Image Computing and Computer
Assisted Intervention–MICCAI 2021: 24th Interna-
tional Conference, Strasbourg, France, September 27–
October 1, 2021, Proceedings, Part V 24 , pages 291–
301. Springer, 2021. 2
[14] Ngoc Huy Nguyen, Ha Quy Nguyen, Nghia Trung
Nguyen, Thang Viet Nguyen, Hieu Huy Pham, and
Tuan Ngoc-Minh Nguyen. A clinical validation of
vindr-cxr, an ai system for detecting abnormal chest
radiographs. arXiv preprint arXiv:2104.02256 , 2021.
2
[15] Ngoc Huy Nguyen, Ha Quy Nguyen, Nghia Trung
Nguyen, Thang Viet Nguyen, Hieu Huy Pham, and
Tuan Ngoc-Minh Nguyen. Deployment and validation
of an ai system for detecting abnormal chest radio-
graphs in clinical settings. Frontiers in Digital Health ,
page 130, 2022. 2
[16] Thao Nguyen, Tam M V o, Thang V Nguyen, Hieu H
Pham, and Ha Q Nguyen. Learning to diag-
nose common thorax diseases on chest radiographs
from radiology reports in vietnamese. Plos one ,
17(10):e0276545, 2022. 2
[17] Hieu H Pham, Dung V Do, and Ha Q Nguyen. Dicom
imaging router: An open deep learning framework for
classiﬁcation of body parts from dicom x-ray scans.
medRxiv , 2021. 2
[18] Hieu H Pham, Tung T Le, Dat Q Tran, Dat T Ngo,
and Ha Q Nguyen. Interpreting chest X-rays via
CNNs that exploit hierarchical disease dependencies
and uncertainty labels. Neurocomputing , 437:186–
194, 2021. 2
[19] Hieu H Pham, Ha Q Nguyen, Hieu T Nguyen, Linh T
Le, and Lam Khanh. An accurate and explainable
deep learning system improves interobserver agree-
ment in the interpretation of chest radiograph. arXiv
preprint arXiv:2208.03545 , 2022. 2
[20] Anil Ramakrishna, Rahul Gupta, Ruth B Grossman,
and Shrikanth S Narayanan. An expectation maxi-
mization approach to joint modeling of multidimen-
sional ratings derived from multiple annotators. In In-
terspeech , pages 1555–1559, 2016. 1
[21] Vikas C. Raykar, Shipeng Yu, Linda H. Zhao, Anna
Jerebko, Charles Florin, Gerardo Hermosillo Valadez,
Luca Bogoni, and Linda Moy. Supervised learning
from multiple experts: Whom to trust when everyone
lies a bit. In Proceedings of the 26th Annual Interna-
tional Conference on Machine Learning , ICML ’09,
page 889–896, New York, NY , USA, 2009. Associa-
tion for Computing Machinery. 1
[22] Filipe Rodrigues and Francisco Pereira. Deep learning
from crowds. In Proceedings of the Association for theAdvancement of Artiﬁcial Intelligence Conference on
Artiﬁcial Intelligence , volume 32, 2018. 1
[23] Robert E Schapire. Explaining AdaBoost. In Empiri-
cal Inference , pages 37–52. Springer, 2013. 1
[24] Victor S. Sheng, Foster Provost, and Panagiotis G.
Ipeirotis. Get another label? Improving data qual-
ity and data mining using multiple, noisy labelers. In
Proceedings of the 14th ACM SIGKDD International
Conference on Knowledge Discovery and Data Min-
ing, KDD ’08, page 614–622, New York, NY , USA,
2008. Association for Computing Machinery. 1
[25] Victor S. Sheng and Jing Zhang. Machine learning
with crowdsourcing: A brief summary of the past re-
search and future directions. Proceedings of the AAAI
Conference on Artiﬁcial Intelligence , 33(01):9837–
9843, Jul. 2019. 1
[26] Abhinav Shrivastava, Abhinav Gupta, and Ross Gir-
shick. Training region-based object detectors with on-
line hard example mining. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recogni-
tion, pages 761–769, 2016. 1
[27] Padhraic Smyth, Usama Fayyad, Michael Burl, Pietro
Perona, and Pierre Baldi. Inferring ground truth
from subjective labelling of venus images. In Pro-
ceedings of the 7th International Conference on Neu-
ral Information Processing Systems , NIPS’94, page
1085–1092, Cambridge, MA, USA, 1994. MIT Press.
1
[28] Roman Solovyev, Weimin Wang, and Tatiana Gabru-
seva. Weighted boxes fusion: Ensembling boxes from
different object detection models. Image and Vision
Computing , 107:104117, Mar 2021. 1
[29] Ryutaro Tanno, Ardavan Saeedi, Swami Sankara-
narayanan, Daniel C Alexander, and Nathan Silber-
man. Learning from noisy labels by regularized esti-
mation of annotator confusion. In Proceedings of the
IEEE/CVF Conference on Computer Vision and Pat-
tern Recognition , pages 11244–11253, 2019. 1
[30] Thanh T Tran, Hieu H Pham, Thang V Nguyen,
Tung T Le, Hieu T Nguyen, and Ha Q Nguyen. Learn-
ing to automatically diagnose multiple diseases in
pediatric chest radiographs using deep convolutional
neural networks. In Proceedings of the IEEE/CVF
International Conference on Computer Vision , pages
3314–3323, 2021. 2
[31] Jacob Whitehill, Ting-fan Wu, Jacob Bergsma, Javier
Movellan, and Paul Ruvolo. Whose vote should count
more: Optimal integration of labels from labelers of
unknown expertise. Advances in Neural Information
Processing Systems , 22:2035–2043, 2009. 1
3[32] Chiyuan Zhang, Samy Bengio, Moritz Hardt, Ben-
jamin Recht, and Oriol Vinyals. Understanding
deep learning (still) requires rethinking generalization.
Communications of the ACM , 64(3):107–115, 2021. 1
[33] Le Zhang, Ryutaro Tanno, Mou-Cheng Xu, Chen Jin,
Joseph Jacob, Olga Cicarrelli, Frederik Barkhof, and
Daniel Alexander. Disentangling human error from
ground truth in segmentation of medical images. In
H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan,
and H. Lin, editors, Advances in Neural Information
Processing Systems , volume 33, pages 15750–15762.
Curran Associates, Inc., 2020. 1
[34] Le Zhang, Ryutaro Tanno, Mou-Cheng Xu, Chen Jin,
Joseph Jacob, Olga Cicarrelli, Frederik Barkhof, and
Daniel Alexander. Disentangling human error from
ground truth in segmentation of medical images. In
H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan,
and H. Lin, editors, Advances in Neural Information
Processing Systems , volume 33, pages 15750–15762.
Curran Associates, Inc., 2020. 1
[35] Yudian Zheng, Guoliang Li, Yuanbing Li, Caihua
Shan, and Reynold Cheng. Truth inference in crowd-
sourcing: Is the problem solved? Proc. VLDB Endow. ,
10(5):541–552, Jan. 2017. 1
[36] Zhengxia Zou, Zhenwei Shi, Yuhong Guo, and Jieping
Ye. Object detection in 20 years: A survey. arXiv
preprint arXiv:1905.05055 , 2019. 1
4