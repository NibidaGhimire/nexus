Priorities for more effective tech regulation
Konrad Kollnig
Department of Computer Science, University of Oxford
Ample research has demonstrated that compliance with data protection principles re-
mains limited on the web and mobile [1–10]. For example, almost none of the apps on
the Google Play Store fulﬁl the minimum requirements regarding consent under EU and
UK law, while most of them share tracking data with companies like Google/Alphabet
and Facebook/Meta and would likely need to seek consent from their users [1]. In-
deed, recent privacy efforts and enforcement by Apple have had – in some regards –
a more pronounced effect on apps’ data practices than the EU’s ambitious General
Data Protection Regulation (GDPR) [11, 12]. Given the current mismatch between the
law on the books and data practices in reality, iterative changes to current legal prac-
tice will not be enough to meaningfully tame egregious data practices. Hence, this
technical report proposes a range of priorities for academia, regulators and the inter-
ested public in order to move beyond the status quo. This work is an excerpt from my
PhD dissertation at the University of Oxford under the supervision of Sir Nigel Shadbolt.
Overview
Priority 1: Make consent meaningful – or abandon it 2
Priority 2: Better, bolder communication 3
Priority 3: Clear technical standards, visualisations and reference code 3
Priority 4: Sufﬁcient resources for authorities 4
Priority 5: Embrace regulatory technologies 6
Priority 6: Evolve ‘legacy’ legislation and provide support for research 7arXiv:2302.13950v1  [cs.CY]  27 Feb 2023Priority 1: Make consent meaningful – or abandon it
Although often claimed otherwise, the GDPR does not require a broad implementa-
tion of ‘cookie banners’. EU and UK data protection principles have hardly changed
since the GDPR came into force in May 2018 and were already part of the Data Pro-
tection Directive 1995. The requirements regarding ‘cookie banners’ additionally result
from Art 5(3) of the ePrivacy Directive as amended in 2009, not from the GDPR.
The recent ﬂood of cookie banners can rather be explained by the fact that the
potential sanctions for data protection violations have drastically increased with the
GDPR, causing discontent within the online data industry. The conditions for consent
have also been tightened and existing standards have been clariﬁed in line with case
law. User consent must now be ‘freely given, speciﬁc, informed and unambiguous’
(Recital 32 GDPR). However, this is rarely the case in practice [1, 7, 8, 13]. A signiﬁcant
proportion of current ‘cookie banners’ are thus in violation of the GDPR.
The designation of those consent banners as ‘cookie banners’ can further be inter-
preted as misinformation. For example, Facebook implements a pop-up on its website
titled ‘Allow the use of cookies from Facebook in this browser?’ It is only in the ac-
companying Cookie Policy that Facebook clariﬁes that ‘cookies’ do not only refer to
cookies but also that other ‘technologies, including data that we store on your web
browser or device, identiﬁers associated with your device and other software, are used
for similar purposes.’ The online advertising industry today uses a variety of technolo-
gies to track user activity across various apps and websites – such as ﬁngerprinting
(i.e. using browser characteristics such as time zone, language and operating system)
and email hashing (i.e. sending email addresses from non-Facebook websites to Face-
book even if the user does not use Facebook). This collection of data about websites
and apps – tracking – is widespread, as found by numerous pieces of research [2, 14,
15]. Meanwhile, the term ‘cookie’ sounds innocuous and is widely used by the industry.
Overall, a considerable part of the ‘cookie banners’ on the internet aims to misin-
form and frustrate internet users vis- `a-vis the GDPR rather than to implement the law’s
requirements [10].
There remains signiﬁcant work to do for authorities and other organisations to tackle
incompliant implementations of consent and make it meaningful. Indeed, ample re-
search suggests that this is not possible at all [16–18], in part because individuals will
never be sufﬁciently ‘informed’ – as is required by GDPR – about the opaque data
practices of large technology companies [19].
2Priority 2: Better, bolder communication
Due to the continued uncertainty and misinformation regarding the GDPR, the current
way of working of data protection and other public authorities has created a vacuum
of knowledge and authority that has been successfully occupied by third parties with
strong self-interests. This way of working in the EU is often characterised as bureau-
cratic and apolitical, resulting from a lack of a transnational public sphere in Europe.
However, without a European public sphere and debate, political legitimacy in the
Habermasian sense is difﬁcult, if not impossible.
The end result is problematic for data protection because it fuels a negative and
dismissive mood among citizens – including those individuals who are responsible for
the practical implementation of the GDPR – towards the competence of public au-
thorities in digital matters. Data protection and other public authorities should counter
this perception boldly and decisively. This applies both to new digital initiatives and
existing laws such as the GDPR.
Priority 3: Clear technical standards, visualisations and reference
code
As part of better communication, clear, reliable and actionable technical standards
should be considered. Unfortunately, developers do often not know how to com-
ply [20–22], so there is a need to clarify what forms of data processing are permitted
and how this should be implemented in software.
Currently, the expectation from the authorities is that software developers will resolve
important issues related to the implementation of the GDPR themselves – by studying
the relevant legislation and rulings. This assumption is unrealistic, at least for smaller
software companies [22]. In addition, the European Data Protection Board and the
ICO regularly publish explanatory notes on important aspects of the GDPR. This usually
involves the publication of long texts of legalese. The target audience of these publi-
cations is thus primarily legal, especially courts, but not the individuals tasked with the
practical implementation of the law.
It is certainly important to explain the legal dimensions of the GDPR and to pursue this
through legal methodology, particularly by publishing explanatory legal texts. At the
same time, it seems that authorities too often hide their lack of authority and technical
3expertise behind overly formal communication and shy away from clear speciﬁcations.
As a result, a signiﬁcant part of the interpretation of the GDPR currently falls to the
courts. Unfortunately, this approach undermines a swift and effective implementation
of the GDPR and is unsuitable to keep pace with rapid technological change. Code
can be changed and rolled out to users worldwide in a matter of minutes. For effective
IT regulation, the (ambitious) goal must be to act similarly agile.
From a technical perspective, it is almost na ¨ıve to assume that legal text could be
translated more or less directly into code. Instead, in IT, requirements speciﬁcation
provides a decades-old approach to describing and building IT systems. A common
standard was ﬁrst published by the IEEE (Institute of Electrical and Electronic Engineers)
in 1984; the latest version is ISO/IEC/IEEE 29148:2018 from 2018. Requirements can be
both technical and non-technical as well as speciﬁc and less speciﬁc. There is no
reason why similar requirements cannot be formulated for core elements of the GDPR
and other IT law. This could be done in particular for the implementation of consent
and should be accompanied by visualisations and reference code where possible. In
the context of the amendment of the ePrivacy Directive in 2009, the EU even provided
visualisations and reference code in the past, but did not maintain them over the years
and discontinued them after the introduction of the GDPR.
Priority 4: Sufﬁcient resources for authorities
There are many reasons for the lack of implementation of the GDPR in practice. One
important reason is the continued lack of resources of data protection authorities [23,
24]. This refers to both ﬁnancial resources and (technical) expertise. For example,
there has been virtually no action by the responsible authorities against the docu-
mented data protection problems in mobile apps. A second reason is the one-stop-
shop approach of the GDPR in the EU. This approach currently leads to a race to the
bottom between member states in terms of negligent implementation of the GDPR. In
particular, Ireland, where most of the major tech companies in Europe are based (in-
cluding Microsoft, Alphabet/Google and Meta/Facebook), has been criticised in this
regard [25, 26]. A third reason is the still-evolving case law in the courts.
The problem of the lack of practical enforcement of the GDPR has been recognised
by lawmakers and is being addressed in new EU digital legislation. Ireland is no longer
a single point of failure of legal enforcement in DMA and DSA against big tech, as it
4was de facto under the GDPR, but rather the EU Commission. In addition, technology
companies will be required to subsidise enforcement ﬁnancially.
A key challenge will remain recruiting the necessary technical talent for public in-
stitutions, most of whom currently work for the same technology companies and are
needed to keep pace with private industry in terms of expertise and technical under-
standing. In the past, European legislators have not always maintained an air of tech-
nical competence. One example is the planned EU AI Act, which is supposed to regu-
late AI applications. However, the deﬁnition of AI applications in the Commission’s ﬁrst
proposal was so broad that it covered almost any computer application. The planned
AI rules are derived from EU product safety legislation. This creates the risk of missing the
core of AI, which rather lies in the inputs and outputs of the model rather than the prod-
uct/technology itself. Doubts about the EU legislator’s deep technical understanding
also arise when reading the GDPR. The law, like its 1995 predecessor, distinguishes be-
tween controllers and processors in the processing of personal data. Controllers are
those that alone or jointly with others determine the purposes and means of the pro-
cessing of personal data (Art 4 GDPR). Processors, on the other hand, usually only act
at the instruction of the controller. However, today’s IT systems are the product of the
combined work of many different actors, both large and small. This often makes it al-
most impossible to distinguish between controllers and processors. This distinction is,
however, important because controllers face many more obligations than processors.
Moreover, whether and to what degree software development – rather than direct
data processing – entails obligations under the GDPR is not clear [27, 28]. As a result
of these deﬁnitions, which only peripherally deal with the usual processes and distribu-
tion of tasks in software development, there are a number of concluded and pending
cases regarding the deﬁnition of the role of data controller [29–32]. One solution to
this phenomenon was proposed by the Belgian DPA [32] in its case against IAB Europe:
the DPA decided to deﬁne almost all actors in the online advertising business as con-
trollers, i.e. thousands of different companies. IAB Europe has appealed and the case
is currently pending before the ECJ. As an alternative approach, China’s Personal In-
formation Protection Law (PIPL) from 2021 only foresees processors of personal data,
but no controllers.
Of course, the GDPR is not limited to IT but covers many other areas of our daily lives
that involve personal data. Therefore, one could argue that criticism of the GDPR’s
lack of focus on software development misses the point of the law. However, it is also
5the case that without technological developments, there would have been little mo-
tivation for a revision of EU data protection law (see also Recital 6 GDPR).
Priority 5: Embrace regulatory technologies
There are two dominant approaches to enforcing data protection rules in digital sys-
tems. The ﬁrst one is taken by data protection authorities who tend to focus their efforts
on a few select cases and companies. The hope is that this will tame the most egre-
gious data practices and that there will be spillover effects across the data practices
by other organisations. The second approach is taken by gatekeepers, such as app
stores, who conduct some enforcement of data protection rules at scale (e.g. through
their (automated) app review), but publish limited public information about this en-
forcement, including the number and nature of decisions taken [33]. Given the scale
of the digital ecosystem and the extent of current violations of data protection rules (as
observed in this and other work), both approaches are insufﬁcient. Without the help of
regulatory technologies in ensuring compliance in the digital ecosystem, it will be im-
possible to scale operations across the vastness of these digital ecosystems, to fulﬁl the
expectations of individuals in keeping them safe online, and to protect fundamental
rights and freedoms.
In the app ecosystem, an important, persisting issue that emerged from my analysis
across iOS and Android is the lack of transparency around apps’ data practices. This
conﬂicts with the strict transparency requirements for the processing of personal data
laid out in the GDPR. Design decisions by Apple and Google currently impede research
efforts, such as the application of copyright protection to every iOS app – even free
ones. This is why it is important to develop and maintain transparency tools . A starting
point could be expanding my PlatformControl toolkit ( https://platformcontrol :org),
and give more up-to-date and detailed insights into apps’ privacy and compliance
properties. As part of this, an important ﬁeld for further study is the development of a
cross-platform app instrumentation tool. Automatic app compliance analysis tools are
not widely available nor used by regulators and the interested public (though it might
be easy to conduct such automatic checks if the regulators deﬁned more explicit rules
regarding privacy and app design), but would help keep up with the vastness of the
app ecosystem. Such analysis tools would require reliable and computable metrics
for compliance . While most of this work has been on the situation in Europe, there
6have been emerging many promising new pieces of technology regulation across the
globe, which need further investigation.
Priority 6: Evolve ‘legacy’ legislation and provide support for
research
Much research efforts have been devoted to analysing privacy in mobile apps. Such
research remains challenging, as the creation of the necessary data is associated with
high investments of time and scarce technical expertise [34]. The fact that analysing
privacy issues in apps and in other software products is so difﬁcult has an impact not
only on my research but also on the work of other researchers and data protection au-
thorities aiming to protect fundamental rights in digital systems [34]. For example, most
data protection authorities themselves currently do not possess independent expertise
to analyse compliance issues in mobile apps.
The EU Digital Services Act makes promising progress in supporting research in rela-
tion to online platforms and search engines. Its Article 40, for example, obliges ‘very
large online platforms’ and ‘very large online search engines’ to allow researchers to
analyse ‘systemic risks’. The concrete implications for research practice, however, re-
main to be seen. I have, in the context of app research, elaborated on these new
legal requirements in a recent pre-print [34]. It can, however, be expected that clar-
iﬁcations of the law by the highest courts will be necessary and that many years will
pass before the law will lead to major changes to the status quo.
Despite all the debates about new IT laws, one must not lose sight of existing laws,
such as copyright, patent, and IT security law. Even if such legislation may be less at-
tractive for public and academic debate and thus receives less attention, there is also
a great need for improvement here. This was also demonstrated by the research in my
PhD thesis, which conducted the ﬁrst large-scale study into iOS app privacy in about 10
years and avoided legal challenges around Apple’s application of DRM to iOS apps [2,
11]. The used methods are freely available at https://platformcontrol :org.
Acknowledgements This report is inspired by previous submissions to the UK competi-
tion authority [35] and the Department for Digital, Culture, Media and Sport [36] from
my research group. An earlier version of this report was published in the Ad Legendum
journal of the University M ¨unster (in German) [37].
7References
[1] K. Kollnig, R. Binns, P . Dewitte, M. Van Kleek, G. Wang, D. Omeiza, H. Webb, and
N. Shadbolt. “A Fait Accompli? An Empirical Study into the Absence of Consent
to Third-Party Tracking in Android Apps”. In: Seventeenth Symposium on Usable
Privacy and Security (SOUPS 2021) . USENIX Association, Aug. 2021, pp. 181–196.
ISBN: 978-1-939133-25-0. URL:https://www.usenix.org/conference/soups2021/
presentation/kollnig .
[2] K. Kollnig, A. Shuba, R. Binns, M. Van Kleek, and N. Shadbolt. “Are iPhones Really
Better for Privacy? A Comparative Study of iOS and Android Apps”. In: Proceed-
ings on Privacy Enhancing Technologies 2022.2 (2022), pp. 6–24. DOI:10.2478/
popets-2022-0033 .
[3] K. Kollnig, R. Binns, M. Van Kleek, U. Lyngs, J. Zhao, C. Tinsman, and N. Shadbolt.
“Before and after GDPR: Tracking in Mobile Apps”. In: Internet Policy Review 10.4
(2021). DOI:10.14763/2021.4.1611 .
[4] I. Reyes, P . Wijesekera, J. Reardon, A. Elazari, A. Razaghpanah, N. Vallina-
Rodriguez, and S. Egelman. ““Won’t Somebody Think of the Children?” Exam-
ining COPPA Compliance at Scale”. In: Proceedings on Privacy Enhancing Tech-
nologies 2018.3 (June 2018), pp. 63–83. DOI:10.1515/popets-2018-0021 .
[5] S. Zimmeck, P . Story, D. Smullen, A. Ravichander, Z. Wang, J. Reidenberg, N. C.
Russell, and N. Sadeh. “MAPS: Scaling Privacy Compliance Analysis to a Million
Apps”. In: Proceedings on Privacy Enhancing Technologies 2019.3 (June 2019),
pp. 66–86. DOI:10.2478/popets-2019-0037 .
[6] E. Okoyomon, N. Samarin, P . Wijesekera, A. Elazari, N. Vallina-Rodriguez, I. Reyes,
´A. Feal, and S. Egelman. “On The Ridiculousness of Notice and Consent: Contra-
dictions in App Privacy Policies”. In: The Workshop on Technology and Consumer
Protection (ConPro ’19) (2019). URL:https://www.ieee-security.org/TC/SPW2019/
ConPro/papers/okoyomon-conpro19.pdf .
[7] “Share First, Ask Later (or Never?) Studying Violations of GDPR’s Explicit Consent
in Android Apps”. In.
[8] M. Nouwens, I. Liccardi, M. Veale, D. Karger, and L. Kagal. “Dark Patterns af-
ter the GDPR: Scraping Consent Pop-Ups and Demonstrating Their Inﬂuence”. In:
Proceedings of the 2020 CHI Conference on Human Factors in Computing Sys-
8tems . Chi ’20. New York, NY , USA: Association for Computing Machinery, 2020.
DOI:10.1145/3313831.3376321 .
[9] E. Mass ´e.Two Years under GDPR . Implementation Progress Report. Access Now,
2020. URL:https://www.accessnow.org/cms/assets/uploads/2020/05/Two-Years-
Under-GDPR.pdf .
[10] M. Veale, M. Nouwens, and C. Santos. “Impossible Asks: Can the Transparency
and Consent Framework Ever Authorise Real-Time Bidding After the Belgian DPA
Decision?” In: Technology and Regulation 2022 (Feb. 2022), pp. 12–22. DOI:10.
26116/techreg.2022.002 .
[11] K. Kollnig, A. Shuba, M. Van Kleek, R. Binns, and N. Shadbolt. “Goodbye Track-
ing? Impact of IOS App Tracking Transparency and Privacy Labels”. In: 2022 ACM
Conference on Fairness, Accountability, and Transparency . FAccT ’22. New York,
NY , USA: Association for Computing Machinery, 2022, pp. 508–520. DOI:10.1145/
3531146.3533116 .
[12] K. Kollnig and R. Binns. The Cost of the GDPR for Apps? Nearly Impossible to Study
without Platform Data . 2022. arXiv: 2206.09734 [cs] .
[13] C. Matte, N. Bielova, and C. Santos. “Do Cookie Banners Respect my Choice?
Measuring Legal Compliance of Banners from IAB Europe’s Transparency and
Consent Framework”. In: 2020 IEEE Symposium on Security and Privacy (SP)
(2019), pp. 791–809. DOI:10.1109/sp40000.2020.00076 .
[14] R. Binns, U. Lyngs, M. Van Kleek, J. Zhao, T. Libert, and N. Shadbolt. “Third Party
Tracking in the Mobile Ecosystem”. In: Proceedings of the 10th ACM Conference
on Web Science - WebSci ’18 . the 10th ACM Conference. WebSci ’18. New York,
NY , United States: ACM Press, May 2018, pp. 23–31. ISBN: 978-1-4503-5563-6. DOI:
10.1145/3201064.3201089 .
[15] A. Razaghpanah, R. Nithyanand, N. Vallina-Rodriguez, S. Sundaresan, M. Allman,
C. Kreibich, and P . Gill. “Apps, Trackers, Privacy, and Regulators: A Global Study
of the Mobile Tracking Ecosystem”. In: Proceedings 2018 Network and Distributed
System Security Symposium . San Diego, CA: Internet Society, 2018. ISBN: 978-1-
891562-49-5. DOI:10.14722/ndss.2018.23353 .
[16] D. J. Solove. “Privacy Self-Management and the Consent Dilemma”. In: Harvard
Law Review 126 (2012). URL:https://harvardlawreview.org/wp-content/uploads/
pdfs/vol126_solove.pdf .
9[17] S. Barocas and H. Nissenbaum. “On notice: The trouble with notice and con-
sent”. In: Proceedings of the engaging data forum: The ﬁrst international forum
on the application and management of personal electronic information . 2009.
URL:https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2567409 .
[18] E. Bietti. “Consent as a Free Pass: Platform Power and the Limits of the Informa-
tional Turn”. In: Pace Law Review (2020). URL:https://digitalcommons.pace.edu/
cgi/viewcontent.cgi?article=2013&context=plr .
[19] Norwegian Consumer Council. Out of Control: How Consumers Are Exploited
by the Online Advertising Industry . Tech. rep. 2020. URL:https : / / fil .
forbrukerradet.no/wp-content/uploads/2020/01/2020-01-14-out-of-control-
final-version.pdf .
[20] A. Ekambaranathan, J. Zhao, and M. Van Kleek. ““Money makes the world go
around”: Identifying Barriers to Better Privacy in Children’s Apps From Developers’
Perspectives”. In: Conference on Human Factors in Computing Systems (CHI ’21) .
The 2021 CHI Conference. ACM Press, 2021. DOI:10.1145/3411764.3445599 .
[21] A. H. Mhaidli, Y . Zou, and F . Schaub. ““We Can’t Live Without Them!” App Devel-
opers’ Adoption of Ad Networks and Their Considerations of Consumer Risks”. In:
Proceedings of the Fifteenth Symposium on Usable Privacy and Security (2019).
[22] S. Sirur, J. R. Nurse, and H. Webb. “Are We There Yet?: Understanding the
Challenges Faced in Complying with the General Data Protection Regulation
(GDPR)”. In: Proceedings of the 2nd International Workshop on Multimedia Pri-
vacy and Security - MPS ’18 . the 2nd International Workshop. ACM Press, Jan.
2018, pp. 88–95. ISBN: 978-1-4503-5988-7. DOI:10.1145/3267357.3267368 .
[23] European Data Protection Board. Overview on resources made available by
Member States to the Data Protection Supervisory Authorities . 2022. URL:https:
/ / edpb . europa . eu / system / files / 2022 - 09 / edpb _ overviewresourcesmade _
availablebymemberstatestosas2022%5C_en.pdf .
[24] O. Lynskey. “Grappling with “Data Power”: Normative Nudges from Data Protec-
tion and Privacy”. In: Theoretical Inquiries in Law 20.1 (2019), pp. 189–220. DOI:
10.1515/til-2019-0007 .
[25] T. J. McIntyre. “Regulating the Information Society: Data Protection and Ireland’s
Internet Industry”. In: The Oxford Handbook of Irish Politics . Ed. by D. M. Farrell
10and N. Hardiman. Oxford University Press, Sept. 2021. ISBN: 978-0-19-882383-4. DOI:
10.1093/oxfordhb/9780198823834.013.39 .
[26] Irish Council for Civil Liberties. Europe’s enforcement paralysis . 2021. URL:https:
//www.iccl.ie/digital-data/2021-gdpr-report/ .
[27] L. A. Bygrave. “Data Protection by Design and by Default: Deciphering the EU’s
Legislative Requirements”. In: Oslo Law Review 1 (Aug. 2017), pp. 105–120. DOI:
10.18261/issn.2387-3299-2017-02-03 .
[28] L. Jasmontaite, I. Kamara, G. Zanﬁr-Fortuna, and S. Leucci. “Data Protection by
Design and by Default: Framing Guiding Principles into Legal Obligations in the
GDPR”. In: European Data Protection Law Review 4 (June 2018), pp. 168–189.
DOI:10.21552/edpl/2018/2/7 .
[29] Court of Justice of the European Union. Unabh ¨angiges Landeszentrum f ¨ur Daten-
schutz Schleswig-Holstein v Wirtschaftsakademie Schleswig-Holstein GmbH . 2018.
URL:http://curia.europa.eu/juris/liste.jsf?num=C-210/16 .
[30] Court of Justice of the European Union. Tietosuojavaltuutettu . 2018. URL:http:
//curia.europa.eu/juris/document/document.jsf?docid=203822%5C&doclang=EN .
[31] Court of Justice of the European Union. Fashion ID GmbH & Co. KG v Ver-
braucherzentrale NRW e. V . 2019. URL:http://curia.europa.eu/juris/liste.
jsf?num=C-40/17 .
[32] Gegevensbeschermingsautoriteit. Decision on complaint relating to Trans-
parency & Consent Framework (case number DOS-2019-01377) .https://www.
gegevensbeschermingsautoriteit.be/publications/beslissing-ten-gronde-nr.-
21-2022-english.pdf . Feb. 2022.
[33] J. van Hoboken and R. ´O. Fathaigh. “Smartphone platforms as privacy regula-
tors”. In: Computer Law & Security Review 41 (2021). DOI:10.1016/j.clsr.2021.
105557 .
[34] K. Kollnig and N. Shadbolt. Ready for the EU Digital Services Act? How Decisions
by Apple and by Google Impede App Privacy . SSRN Scholarly Paper. Rochester,
NY, Jan. 2023. DOI:10.2139/ssrn.4343640 .
[35] K. Kollnig, R. Binns, and N. Shadbolt. Response to the public consultation by the
UK Competition and Markets Authority . 2022. URL:https://assets.publishing.
service . gov . uk / media / 6229ac9b8fa8f526cf29aa2f / Konrad _ Kollnig _ _Reuben _
11Binns _ _Nigel _ Shadbolt _ _Department _ of _ Computer _ Science _ _University _ of _
Oxford.pdf .
[36] Researchers from the Human Centred Computing Research Group, Department
of Computer Science, University of Oxford. Response to the Public Consultation
on Reforms to the UK’s Data Protection Regime by the Department for Digital,
Culture, Media & Sport . Tech. rep. 2021.
[37] K. Kollnig. “Lehren Aus Der DSGVO: F ¨unf Priorit ¨aten F ¨ur Wirksame IT-Regulierung”.
In:Ad Legendum 2023.2 (2023).
12