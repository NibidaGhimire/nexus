Trajectory-User Linking via Hierarchical Spatio-Temporal Attention
Networks
WEI CHEN, Ocean University of China, China
CHAO HUANG, The University of Hong Kong, China
YANWEI YUâˆ—,Ocean University of China, China
YONGGUO JIANG, Ocean University of China, China
JUNYU DONG, Ocean University of China, China
Trajectory-User Linking (TUL) is crucial for human mobility modeling by linking different trajectories to users with the
exploration of complex mobility patterns. Existing works mainly rely on the recurrent neural framework to encode the
temporal dependencies in trajectories, have fall short in capturing spatial-temporal global context for TUL prediction. To fill
this gap, this work presents a new hierarchical spatio-temporal attention neural network, called AttnTUL , to jointly encode
the local trajectory transitional patterns and global spatial dependencies for TUL. Specifically, our first model component is
built over the graph neural architecture to preserve the local and global context and enhance the representation paradigm
of geographical regions and user trajectories. Additionally, a hierarchically structured attention network is designed to
simultaneously encode the intra-trajectory and inter-trajectory dependencies, with the integration of the temporal attention
mechanism and global elastic attentional encoder. Extensive experiments demonstrate the superiority of our AttnTUL
method as compared to state-of-the-art baselines on various trajectory datasets. The source code of our model is available at
https://github.com/Onedean/AttnTUL.
CCS Concepts: â€¢Information systems â†’Spatial-temporal systems ;â€¢Computing methodologies â†’Learning latent
representations ;Neural networks .
Additional Key Words and Phrases: Trajectory-user linking, attention neural networks, trajectory representation learning,
spatio-temporal data
ACM Reference Format:
Wei Chen, Chao Huang, Yanwei Yu, Yongguo Jiang, and Junyu Dong. 2023. Trajectory-User Linking via Hierarchical Spatio-
Temporal Attention Networks. ACM Trans. Knowl. Discov. Data. 1, 1 (December 2023), 23 pages. https://doi.org/10.1145/3635718
1 INTRODUCTION
The development of mobile computing techniques enables the collection of massive mobility data from various
sources, including location-based social networks, geo-tagged social media and GPS enabled mobile applica-
tions [ 33,42]. Among various mobility modeling applications, a recently introduced Trajectory-User Linking
âˆ—Corresponding author.
Authorsâ€™ addresses: Wei Chen, onedeanxxx@gmail.com, Ocean University of China, Songling RD 238, Qingdao, Shandong, China, 266100;
Chao Huang, chaohuang75@gmail.com, The University of Hong Kong, Pokfulam, Hong Kong, China; Yanwei Yu, yuyanwei@ouc.edu.cn,
Ocean University of China, Songling RD 238, Qingdao, Shandong, China, 266100; Yongguo Jiang, jiangyg@ouc.edu.cn, Ocean University of
China, Songling RD 238, Qingdao, Shandong, China, 266100; Junyu Dong, dongjunyu@ouc.edu.cn, Ocean University of China, Songling RD
238, Qingdao, Shandong, China, 266100.
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that
copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first
page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy
otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from
permissions@acm.org.
Â©2023 Association for Computing Machinery.
1556-4681/2023/12-ART $15.00
https://doi.org/10.1145/3635718
ACM Trans. Knowl. Discov. Data.arXiv:2302.10903v2  [cs.LG]  7 Dec 20232â€¢Wei Chen et al.
(TUL) task, which aims to link anonymous trajectories to users who generate them, is crucial and beneficial for
a broad range of spatial-temporal mining applications, ranging from location-based recommendations [ 22] to
urban anomaly detection [ 13,41]. For example, vehicle-mounted terminals and ride-sharing services usually
anonymize user identities in collecting mobility data due to the privacy issue. Effective linking trajectories
with their corresponding users can not only enable accurate location-based recommendations, but also identify
abnormal events from usersâ€™ GPS traces. Therefore, the linking results between users and their anonymous
trajectories are important for advancing the business intelligence and smart city applications [5, 8].
User B
ï¼Ÿ
User A
User C
User E
User ?
User D
âˆš
Ã—
Fig. 1. An illustrated example of linking anonymous mobility trajectories with corresponding users. Based on the mobility
trajectories of five users, we find that the anonymous trajectory (red) is much closer to the trajectory of user ğ¸(dark gray).
Thus, we can link the anonymous trajectory with user ğ¸.
In this paper, we tackle the trajectory-user linking challenge via exploring the spatio-temporal movement
patterns from the mobility data. Figure 1 presents an intuitive example of linking anonymous trajectories with
the corresponding users. Our goal in this work is to link anonymous mobility trajectories to the users who are
most likely to produce them based on the historical trajectories. Due to the strong representation ability of deep
learning techniques, existing studies attempt to solve the TUL problem based on various trajectory representation
learning models [ 11,24,47]. For example, TULVAE [ 47] incorporates VAE model into the TUL problem to learn
hierarchical semantics of check-in trajectories with RNN to improve the prediction accuracy. DeepTUL [ 24]
proposes to integrate recurrent networks with attention mechanism to model higher-order and multi-periodic
mobility patterns by learning from historical traces. AdattTUL [ 9] and TGAN [ 48] utilize Generation Adversarial
Network (GAN) to study the TUL problem with adversarial mobility modeling. Besides, SML-TUL [ 46] uses
contrastive learning to encode the predictive representations from the user mobility itself constrained by spatio-
temporal factors. Recently, there has been a surge in the development of graph-based models [ 3,6,45] that aim
to enhance the acquisition of trajectory representations for TUL problem by adeptly capturing intricate user
visitation preferences, discerning patterns of transition between check-in points, and delving into other pertinent
contextual factors.
Despite their effectiveness, four key limitations exist in these methods. First, all existing methods still suffer
from data sparsity , and cannot learn quality representations over low-sampling trajectories ( e.g., check-ins of
ACM Trans. Knowl. Discov. Data..Trajectory-User Linking via Hierarchical Spatio-Temporal Attention Networks â€¢3
inactive users). Second , existing methods generally rely on the recurrent neural frameworks to model trajectory
sequence, and thus can hardly capture the long-term dependencies among the long sequence mobility traces [ 19].
Previous approaches show sub-optimal performance when dealing with long sequence data in our evaluation.
Third , most of existing works are limited to inject the global spatial and temporal context into the intra- and
inter-trajectory pattern modeling. In practical scenarios, human trajectory are often exhibited with hierarchical
mobility patterns across different time granularities [ 47].Lastly , few of previous approaches incorporate the rich
external contextual features into the representation of human mobility data.
To address the aforementioned challenges, we propose AttnTUL, a hierarchical spatio-temporal attention net-
work, to realize high predictability for TUL problem. Particularly, AttnTUL is built on a graph neural architecture
to encode both local and global trajectory transitional patterns. Our graph-based message passing paradigm is
able to alleviate the data sparsity issue by effectively performing knowledge transfer among geographical regions
and trajectories based on our generated hierarchical spatial graphs. To capture the intra-trajectory transitional
regularities, we develop a temporal self-attention mechanism to encode the long-term mobility dependencies.
To model the inter-trajectory relationships, AttnTUL enhances the trajectory representation paradigm by pre-
serving the spatial context across the entire urban space, with the introduced global elastic attentive encoder.
The integrated local and global embeddings will be fed into the prediction layer for linking trajectories to their
corresponding users. With the design of local and global hierarchical modeling, our proposed AttnTUL method is
general and robust for both dense GPS trajectory data and sparse check-in trajectory data
In our evaluation, experimental results on three types of real-life mobility datasets show that our model
significantly outperforms several strong baselines ( 9.20% ACC@1 gain and 12.73 % Macro-F1 gain on average) in
TUL task on both sparse and dense trajectory data. Additionally, our perform ablation study to justify the model
design rationale with component-wise effect investigation.
Our contributions can be summarized as follows:
â€¢We propose AttnTUL, a hierarchical spatio-temporal attention network model to solve the TUL problem.
Our AttnTUL simultaneously models local and global spatial and temporal characteristics of usersâ€™ mobility
trajectories over a graph neural architecture.
â€¢We design a hierarchical spatio-temporal attention network which contains a temporal self-attention
encoder to learn the local sequential dependencies within trajectory, and a global elastic attention encoder
to capture the complex inter-trajectory dependencies.
â€¢We conduct extensive experiments on three types of real-life mobility datasets. Results show that our model
significantly outperforms state-of-the-art baselines by 6.04% âˆ¼14.07% and 6.56%âˆ¼29.54% improvements in
terms of ACC@1 and Macro-F1.
2 RELATED WORK
In literature, measuring the similarity or distance between trajectories which is essential to trajectory pattern
mining. Similarity measures, e.g., Dynamic Time Warping (DTW) [ 18], Longest Common Sub-Sequence (LCSS)
[38], Trajectory-Hausdorff Distance [ 1], Spatio-Temporal Linear Combine distance [ 27], and Spatiotemporal
Signature [ 16], are often used to discover the user similarity from their trajectories. However, such approaches are
artificially designed, and thus only suitable for specific scenario. Recently, deep representation learning has been
used for trajectory similarity computation [ 21,35â€“37,40].However, these methods focus more on improving the
efficiency of trajectory similarity computation. Trajectory classification is another way to understand mobility
patterns. Existing trajectory classification works focus on labeling trajectories as different motion patterns, such
as Driving, Biking and Walking in transportation classification [ 43] and Occupied, Non-occupied and Parked
in taxi status inference [ 50]. These approaches mainly rely on extraction of spatio-temporal characteristics of
trajectories.
ACM Trans. Knowl. Discov. Data..4â€¢Wei Chen et al.
TUL problem was recently introduced in [ 11], which links trajectories to their generating-users, and gradually
becomes a hot topic in spatio-temporal data mining by classifying trajectories by users. Due to its broad range of
applications in personalized recommendation systems, location-based services and urban planning, it gradually
becomes a hot topic in spatio-temporal data mining. Several methods have been proposed to solve the TUL
problem [ 11,24,28,39,47]. TULER [ 11] utilizes RNN based models to learn sequential transition patterns from
trajectories, and links them to users. It first uses word embedding to learn the representations for locations in
the trajectories and feed them into RNN model to capture mobility patterns for TUL. However, the standard
RNN based models suffer from data sparsity problem and lacking of understanding hierarchical semantics of
human mobility. In their follow-up work [ 47], TULVAE is proposed to improve the prediction accuracy by
incorporating VAE into TUL task to learn hierarchical semantics of check-in sequences. However, it fails to utilize
existing abundant features and also do not consider multi-periodic mobility regularities. DeepTUL [ 24] proposes
using the attentive recurrent network in TUL to alleviate the data sparsity problem by leveraging historical
data, and capture multi-periodic regularities of human mobility to improve prediction accuracy. AdattTUL [ 9]
and TGAN [ 48] introduce Generation Adversarial Network (GAN) to deal with the TUL problem. Recently,
SML-TUL [ 46] uses contrastive learning to learn the predictive representations from the user mobility itself
constrained by the spatio-temporal factors. After that, MainTUL [ 4] attempts to alleviate the trajectory user
linking problem on sparse check-in data sets by introducing distillation technology and using historical trajectory
information. Nevertheless, these methods use RNNs for modeling or prediction, which cannot effectively model
long-term dependencies of trajectories, and all above methods ignore the contribution of global spatial modeling to
TUL prediction.
Given the multifaceted nature of the data within Location-Based Social Networks (LBSN), an array of scholarly
endeavors [ 3,6,45] pertaining to TUL problem have undertaken the exploration of user preferences through
the discernment of influences stemming from diverse sources, including user relationships, temporal factors,
geographical factors, and so on. Such endeavors are geared towards mitigating challenges such as data sparsity
problem. Notably, the incorporation of graph-based models [10, 15], which inherently excel in capturing intricate
and diverse relationships, has recently been introduced into the realm of TUL problem, further enriching the
methodological landscape. GNNTUL [ 45] first propose a novel end-to-end model, composed of a graph neural
network (GNN) module and a classifier, to learn human mobility and associate the traces to the users effectively
and efficiently. After that, S2TUL [ 6] captures more complex movement relationships by constructing different
homogeneous and heterogeneous graphs, and integrates them into a unified semi-supervised framework for
the TUL problem. Contemporaneously, ANES [ 3] introduces a aspect-oriented network embedding for social
link inference, a novel approach that leverages user trajectory data and bipartite graphs to learn aspect-oriented
relations between users and Points-of-Interest(POI). Still and all, the above methods only emphasize partial
relational information, neglecting the integration and synergy of local and global information. In this study, we
initiated a comprehensive effort to carefully cover all possible factors, constructing corresponding graph action modules
for different granularity trajectory information for the first time, and unifying them in one framework.
In addition, a few recent works are proposed to identify users across different mobility datasets [ 7,8]. DPLink [ 8]
is designed to model the correlations between trajectories to measure the trajectory similarity from different data
source. Recently, attention mechanism [ 2] has also been studied in spatio-temporal data mining. Researchers
combine attention with RNN for mobility modeling, such as mobility prediction [ 10] and mobility inference [ 49],
and personalized route recommendation [ 31]. Thanks to the characteristics of attention mechanism, it can make
up for the deficiency of RNN in capturing long-term dependencies to some extent. Different from the previous
studies, to our best knowledge, we are the first to abandon RNN and adopt the fully attention neural network to solve
TUL problem.
ACM Trans. Knowl. Discov. Data..Trajectory-User Linking via Hierarchical Spatio-Temporal Attention Networks â€¢5
3 PRELIMINARIES
In this section, we first introduce some preliminary concepts and then formally define the problem of TUL.
LetU={ğ‘¢1,ğ‘¢2,...,ğ‘¢ğ‘–}denote a set of moving users.
Definition 1 (Spatio-Temporal Point). A spatio-temporal point is a uniquely entity in the form of âŸ¨ğ‘¡,â„“âŸ©, where
ğ‘¡is the visited timestamp, and â„“represents the geographical coordinates of the point (i.e., longitude and latitude).
Definition 2 (Trajectory). A trajectory is a sequence of spatio-temporal points (âŸ¨ğ‘¡1,â„“1âŸ©,âŸ¨ğ‘¡2,â„“2âŸ©,...,âŸ¨ğ‘¡ğ‘š,â„“ğ‘šâŸ©)
generated by user ğ‘¢ğ‘–in chronological order during a certain time interval ğœ, which is denoted by ğ‘‡ğ‘Ÿğœ
ğ‘¢ğ‘–.
The time interval can be one hour, one day, one week or even one month. A trajectory is called unlinked , if we
do not know the user who generated it. Let ğ‘‡denote the whole time interval. The known trajectories generated
in previous time intervals by all users, i.e., linked trajectories, are denoted by ğ‘‡ğ‘Ÿğ‘¢={ğ‘‡ğ‘Ÿğœ
ğ‘¢ğ‘–|ğ‘¢ğ‘–âˆˆUâˆ§ğœâˆˆğ‘‡}.
Based on the above definitions, we now state our studied problem as below:
Problem (Trajectory-User Linking). Given a set of unlinked trajectories ğ‘‡ğ‘Ÿgenerated by users Uand cor-
responding linked trajectories ğ‘‡ğ‘Ÿğ‘¢, our goal is to learn a mapping function ğ‘“:ğ‘‡ğ‘Ÿâ†’U that links anonymous
trajectories to users.
Key notations used in the paper are summarized in Table 1.
Table 1. Main notations and their definitions.
Notation Definition
U the set of moving users
âŸ¨ğ‘¡,â„“âŸ© a spatio-temporal point
ğ‘‡ğ‘Ÿğ‘– a trajectory
ğ‘š the number of spatio-temporal points in ğ‘‡ğ‘Ÿğ‘–
ğœ the time interval
ğ‘‡ğ‘Ÿğœ
ğ‘¢ğ‘–a trajectory generated by ğ‘¢ğ‘–
ğ‘‡ the whole time interval
ğ‘‡ğ‘Ÿğ‘¢ the set of linked trajectories
ğ‘‡ğ‘Ÿ the set of unlinked trajectories
Gğ‘™=(Vğ‘™,Eğ‘™) the local spatial graph
Ağ‘™ the adjacency matrix of local spatial graph
Xğ‘™ the feature matrix of local spatial graph
Gğ‘”=(Vğ‘”,Eğ‘”) the global spatial graph
Ağ‘” the adjacency matrix of global spatial graph
Xğ‘” the feature matrix of global spatial graph
Hğ‘™ the embeddings of all grids
Hğ‘” the global embeddings of all trajectories
ğ‘§ğ‘™
ğ‘–the local representation for ğ‘‡ğ‘Ÿğ‘–
ğ‘§ğ‘”
ğ‘–the global representation for ğ‘‡ğ‘Ÿğ‘–
ACM Trans. Knowl. Discov. Data..6â€¢Wei Chen et al.
4 METHODOLOGY
In this section, we present the details of our neural network model AttnTUL (as shown in Figure 2), consisting
of four key components: (1) local and global graph modeling , (2)spatial convolutional networks , (3)hierarchical
spatio-temporal attention networks , and (4) linking layer .First, we construct a local graph and a global graph
to model micro and macro spatial relationships for all trajectories, respectively. Second , we present the spatial
convolutional networks on the two graphs to learn initial embedding for each divided grid and each trajectory.
Third , we employ a multi-head temporal self-attention network to capture the temporal dependency in local
embeddings of each trajectory and fuse the local embeddings. We also design an global elastic attention encoder
to obtain global representation. Finally , we use a linking layer to classify trajectories by users.
ğ‘‡ğ‘Ÿğ‘–ğ‘”ğ‘–1ğ‘”ğ‘–2 ğ‘”ğ‘–ğ‘š
ğ‘…ğ‘ğ‘¤
ğ‘‡ğ‘Ÿğ‘ğ‘—ğ‘’ğ‘ğ‘¡ğ‘œğ‘Ÿğ‘–ğ‘’ğ‘ ğ¿ğ‘œğ‘ğ‘ğ‘™ğºğ‘Ÿğ‘ğ‘â„
3
1
7
8
4
5
6
9
2
ğºğ‘™ğ‘œğ‘ğ‘ğ‘™ğºğ‘Ÿğ‘ğ‘â„
TrATrBTrCTrDğ¿ğ‘œğ‘ğ‘ğ‘™ -ğ‘†ğ‘ğ‘ğ‘¡ğ‘–ğ‘ğ‘™
ğ¶ğ‘œğ‘›ğ‘£ğ‘œğ‘™ğ‘¢ğ‘¡ğ‘–ğ‘œğ‘›
ğµğ‘™ğ‘œğ‘ğ‘˜
ğ‘‡ğ‘’ğ‘šğ‘ğ‘œğ‘Ÿğ‘ğ‘™
ğ‘†ğ‘’ğ‘™ğ‘“ğ´ğ‘¡ğ‘¡ğ‘’ğ‘›ğ‘¡ğ‘–ğ‘œğ‘› ğµğ‘™ğ‘œğ‘ğ‘˜
ğ¿ğ‘œğ‘ğ‘ğ‘™ğ‘ğ‘›ğ‘‘ğºğ‘™ğ‘œğ‘ğ‘ğ‘™ğ‘€ğ‘œğ‘‘ğ‘’ğ‘™ğ‘–ğ‘›ğ‘” ğ»ğ‘–ğ‘’ğ‘Ÿğ‘ğ‘¡ğ‘â„ğ‘–ğ‘ğ‘ğ‘™ ğ´ğ‘¡ğ‘¡ğ‘’ğ‘›ğ‘¡ğ‘–ğ‘œğ‘› ğ‘ğ‘’ğ‘¡ğ‘¤ğ‘œğ‘Ÿğ‘˜ğ‘ ğ‘ ğ‘¡ğ‘ğ‘ğ‘˜Ã—ğ‘
ğ¸ğ‘™ğ‘ğ‘ ğ‘¡ğ‘–ğ‘
ğ´ğ‘¡ğ‘¡ğ‘’ğ‘›ğ‘¡ğ‘–ğ‘œğ‘› ğµğ‘™ğ‘œğ‘ğ‘˜ğ‘§ğ‘–1ğ‘§ğ‘–2ğ‘§ğ‘–ğ‘š
âŠ•
âŠ•
ğ¿ğ‘–ğ‘›ğ‘˜ğ‘–ğ‘›ğ‘”ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿğ‘‡ğ‘Ÿğ´,ğ‘‡ğ‘Ÿğµ,ğ‘‡ğ‘Ÿğ¶âˆˆğ‘¢1
ğ‘‡ğ‘Ÿğ·âˆˆğ‘¢2
{ğ‘‡ğ‘Ÿğ´,ğ‘‡ğ‘Ÿğµ,ğ‘‡ğ‘Ÿğ·}âˆˆğ‘‡rainğ‘†ğ‘’ğ‘¡
ğ‘ƒğ‘œğ‘œğ‘™ğ‘–ğ‘›ğ‘”ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ
2
4
6
3
CA DB
6
6
6ğ‘†ğ‘¡ğ‘ğ‘¡ğ‘’ğ¸ğ‘›ğ‘ğ‘œğ‘‘ğ‘’ğ‘Ÿ
ğ‘‡ğ‘–ğ‘šğ‘’ğ¸ğ‘›ğ‘ğ‘œğ‘‘ğ‘’ğ‘Ÿ
ğ‘ƒğ‘œğ‘ ğ‘–ğ‘¡ğ‘–ğ‘œğ‘› ğ¸ğ‘›ğ‘ğ‘œğ‘‘ğ‘’ğ‘Ÿ
(ğ‘“ğ‘–ğ‘¥ğ‘’ğ‘‘)
ğ»ğ‘”(ğ‘–)
ï¼Ÿğ¸ğ‘šğ‘ğ‘’ğ‘‘ğ‘‘ğ‘–ğ‘›ğ‘”
ğ¿ğ‘œğ‘œğ‘˜ğ‘¢ğ‘ğ‘‡ğ‘ğ‘ğ‘™ğ‘’
âŠ•
âŠ•
âŠ•
âŠ•ğ‘¡ğ‘–1ğ‘¡ğ‘–2ğ‘¡ğ‘–ğ‘šğ‘ ğ‘–1ğ‘ ğ‘–2ğ‘ ğ‘–ğ‘š
âŠ•ğºğ‘™ğ‘œğ‘ğ‘ğ‘™ -ğ‘†ğ‘ğ‘ğ‘¡ğ‘–ğ‘ğ‘™
ğ¶ğ‘œğ‘›ğ‘£ğ‘œğ‘™ğ‘¢ğ‘¡ğ‘–ğ‘œğ‘›
ğµğ‘™ğ‘œğ‘ğ‘˜ğ´ğ‘‘ğ‘‘ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿ
ğ‘§ğ‘–ğ‘”ğ‘§ğ‘–ğ‘™
96TrATrB
5421378
ğ‘¢1ğ‘¢2ğ’¢ğ‘™
ğ’¢ğ‘”ğ‡ğ‘™
ğ‡ğ‘”âŠ•âˆ¶ğ‘ğ‘œğ‘›ğ‘ğ‘ğ‘¡
ğ²ğ’Š
Fig. 2. The overview of the proposed framework
4.1 Local and Global Graph Modeling
In this section, we introduce how to construct local and global spatial graphs.
4.1.1 Preprocessing. To facilitate the construction of local spatial graph, we employ a gridding technique to divide
the geographic space of all trajectories into discrete grids. More specifically, given grid size ğ‘ , the whole geographic
space is divided into ğ‘›grids. Consequently, we constrict a grid mapping function ğ‘“ğ‘”:â„“ğ‘–â†’ğ‘”ğ‘–, so that each trajectory
ğ‘‡ğ‘Ÿ=(âŸ¨ğ‘¡1,â„“1âŸ©,âŸ¨ğ‘¡2,â„“2âŸ©,...,âŸ¨ğ‘¡ğ‘š,â„“ğ‘šâŸ©)can be mapped to a grid sequence ğ‘‡ğ‘Ÿâ€²=(âŸ¨ğ‘¡1,ğ‘”1âŸ©,âŸ¨ğ‘¡2,ğ‘”2âŸ©,...,âŸ¨ğ‘¡ğ‘š,ğ‘”ğ‘šâŸ©).
4.1.2 Local Spatial Graph Construction. To capture the correlations among spatial locations in all trajectories,
we first construct a local spatial graph Gğ‘™=(Vğ‘™,Eğ‘™), where each grid is a node in Gğ‘™, and edges indicate the
connectivity between grids. That is, an edge is created between grid ğ‘”ğ‘–and gridğ‘”ğ‘—if a trajectory contains a
consecutive snippet from ğ‘”ğ‘–\ğ‘”ğ‘—toğ‘”ğ‘—\ğ‘”ğ‘–. In high-sampling trajectories, some consecutive spatio-temporal points
may be mapped to same grid. For this case, we remove the self-loop edges in Gğ‘™. The weight on edge ğ‘’ğ‘–,ğ‘—âˆˆEğ‘™is
defined as the number of trajectories that contains the consecutive snippet (ğ‘”ğ‘–\ğ‘”ğ‘—â†’ğ‘”ğ‘—\ğ‘”ğ‘–).
Furthermore, the semantic context of nodes can be expressed by a feature matrix. In this paper, we adopt a
one-hot vector (the length is the number of grids) for each node ğ‘”ğ‘–to express the uniqueness of its location in
ACM Trans. Knowl. Discov. Data..Trajectory-User Linking via Hierarchical Spatio-Temporal Attention Networks â€¢7
the feature matrix. We use Ağ‘™andXğ‘™to denote the adjacency matrix and feature matrix of local spatial graph,
respectively.
4.1.3 Global Spatial Graph Construction. To model spatial correlations between trajectories and known linkages
between users and trajectories, we next construct a global spatial graph Gğ‘”=(Vğ‘”,Eğ‘”), which is a heterogeneous
graph that contains the above two relationships.
Specifically,Gğ‘”includes two types of nodes â€“ trajectory nodes and user nodes, i.e., each trajectory is treated as
a node and each user is also regarded as a node. If two trajectories share common grids, then an edge is created
between these two trajectory nodes. The weight of the edge between two trajectory nodes is defined as the
number of shared grids in two trajectories. In addition, the labeled trajectories are connected to their users, and
the weights on the edges between user node and trajectory node are uniformly defined as the maximum weight
between trajectory nodes, which indicates that the relationship strength between labeled trajectories and their
users is maximized, and further the relationship between the trajectories of the same user is also strengthened.
For each trajectory node ğ‘‡ğ‘Ÿğ‘–and user node ğ‘¢ğ‘—, we encode its spatial features (passed grids) into a multi-hot
vector (the length is the number of grids) to represent their spatial characteristics. We use Ağ‘”andXğ‘”to denote
the adjacency matrix and feature matrix of global spatial graph, respectively.
Notably, when the number of trajectories is very large, if the traversal method is used to search for pairs of
interactive trajectories ( i.e., share common grids), the construction of the global spatial graph is actually very time-
consuming. To improve the construction efficiency and reduce the time cost, we propose a fast implementation
trick. We first use grid coding to represent each trajectory, that is, use one hot coding, for each grid, if the
trajectory contains the grid, then the code is 1, otherwise 0. Thus we can obtain the grid coding matrix of all
trajectories, denoted by Cğ‘”. Therefore, the adjacency matrix Ağ‘”can be calculated directly by: Ağ‘”=Cğ‘”Â·Cğ‘”T.
4.2 Spatial Graph Convolutional Networks
4.2.1 Local Graph Convolution. GCNs have been widely used in graph representation learning to capture graph
topological structure by aggregating neighbor features and have achieved great success [ 12,34]. We employ GCN
on the local spatial graph and global spatial graph constructed by different granularities to learn the hierarchical
embeddings of trajectories.
To jointly capture the topological structures and spatial location information among grids, we first perform
convolution operation on local graph ğºğ‘™. Following [ 20], multi-layer spatial convolution network performs
following layer-wise propagation rule:
H(ğ‘–+1)
ğ‘™=ReLU
ËœDâˆ’1
2
ğ‘™ËœAğ‘™ËœDâˆ’1
2
ğ‘™H(ğ‘–)
ğ‘™W(ğ‘–)
ğ‘™
, (1)
where W(ğ‘–)
ğ‘™is a layer-specific trainable weight matrix, ËœAğ‘™=Ağ‘™+I, and ËœDğ‘™ğ‘–ğ‘–=Ã
ğ‘—ËœAğ‘™ğ‘– ğ‘—.H(0)
ğ‘™=Xğ‘™, where Xğ‘™is the
feature matrix ofGğ‘™.H(ğ‘–)
ğ‘™âˆˆRğ‘›Ã—ğ‘‘is the output of ğ‘–-th layer where ğ‘‘is the embedding dimension, denoting the
initial embeddings of all grids.
4.2.2 Global Graph Convolution. Although local graph convolution can learn the embeddings for all grids, it may
not be able to capture the correlations between trajectories and between users and their produced trajectories from
a global perspective. Therefore, to learn the embeddings of trajectories and users, we next perform convolution
operation on global spatial graph:
H(ğ‘–+1)
ğ‘”=ReLU
ËœDâˆ’1
2ğ‘”ËœAğ‘”ËœDâˆ’1
2ğ‘”H(ğ‘–)
ğ‘”W(ğ‘–)
ğ‘”
, (2)
ACM Trans. Knowl. Discov. Data..8â€¢Wei Chen et al.
where W(ğ‘–)
ğ‘”is a layer-specific trainable weight matrix, and H(0)
ğ‘”=Xğ‘”. We can learn the embedding for each
trajectory and each user via global graph convolutional network, which captures the key spatial characteristics
of trajectories from the whole.
4.3 Hierarchical Spatio-Temporal Attention Networks
4.3.1 Semantic Location Encoder. In addition to spatial information, contextual features in mobility data, e.g.,
motion state and time feature, can be considered into location embedding for trajectory sequence modeling.
Therefore, location encoder is a multi-modal embedding module. Following [ 32], we divide the motion state
into(ğ‘–)speed-related operations ( i.e., acceleration, deceleration, and constant speed) and (ğ‘–ğ‘–)direction-related
operations ( i.e., turning left, turning right, and moving straight), and combine them into nine motion states.
For time feature, we divide the whole time into time windows according to a certain time granularity ( e.g., 10
minutes). Figure 3 shows an example of state encoder and time encoder in semantic location encoder.
Specifically, we design two sparse linear embedding layers to encode motion state ğ‘ ğ‘–and time window ğ‘¡ğ‘–
(e.g., one-hot), and then concatenate the corresponding grid embedding to obtain an ensemble vector ğ‘¥ğ‘–. The
formulation of location encoder is as follows:
ğ‘¥ğ‘–=Tanh(ğ¹ğ¶([Wğ‘¡ğ‘¡ğ‘–+ğ‘ğ‘¡;Wğ‘ ğ‘ ğ‘–+ğ‘ğ‘ ;Hğ‘™(ğ‘”ğ‘–)])), (3)
where Wğ‘¡,Wğ‘ ,ğ‘ğ‘¡andğ‘ğ‘ are learnable parameters of embedding layers, Hğ‘™(ğ‘”ğ‘–)denotes the local embedding of
gridğ‘”ğ‘–, and[; ;]denotes the concatenate function. Tanh(Â·)is the non-linear activation function, and ğ¹ğ¶(Â·)is a
fully connected layer.
ğ‘‡ğ‘Ÿğ‘–
ğ¿ğ‘œğ‘ğ‘ğ‘™ğ¸ğ‘šğ‘ğ‘’ğ‘‘ğ‘‘ğ‘–ğ‘›ğ‘”
ğ¿ğ‘œğ‘œğ‘˜ğ‘¢ğ‘ğ‘‡ğ‘ğ‘ğ‘™ğ‘’
ğ‡ğ‘™
ğ‘†ğ‘¡ğ‘ğ‘¡ğ‘’ğ¸ğ‘›ğ‘ğ‘œğ‘‘ğ‘’ğ‘Ÿğ¶ğ‘œğ‘›ğ‘ğ‘ğ‘¡
ğ¿ğ‘ğ‘¦ğ‘’ğ‘Ÿğ‘ 1
ğ‘†ğ‘¡ğ‘ğ‘¡ğ‘’
Encoder
ğ‘‡ğ‘–ğ‘šğ‘’
Encoderğ‘ ğ‘–1
ğ‘ ğ‘–2
ğ‘ ğ‘–ğ‘š
ğ‘¡ğ‘–1
ğ‘¡ğ‘–2
ğ‘¡ğ‘–ğ‘šğ‘ 2ğ‘ 3
ğ‘ 4ğ‘ 5ğ‘ 6
ğ‘ 7ğ‘ 8ğ‘ 9
ğ‘”ğ‘–1
ğ‘”ğ‘–2
ğ‘”ğ‘–ğ‘š
ğ‘‡ğ‘–ğ‘šğ‘’ğ¸ğ‘›ğ‘ğ‘œğ‘‘ğ‘’ğ‘Ÿ8:12
7:50
â€¦â€¦
7:180â€¦010
0â€¦100
â€¦â€¦
0â€¦100ğ—ğ‘–Semantic Location
Encoder
Fig. 3. State/time encoder in semantic location encoder
4.3.2 Temporal Self-Attention Encoder. To capture the long-term temporal dependencies in trajectory sequence
which is difficult to model and learn by RNN-based models, we employ a multi-head temporal self-attention
mechanism to learn the intra-trajectory correlations.
ACM Trans. Knowl. Discov. Data..Trajectory-User Linking via Hierarchical Spatio-Temporal Attention Networks â€¢9
To supplement sequence information, the input first adds the position encoding:
Mğ‘–=Xğ‘–+P, (4)
where Xğ‘–={ğ‘¥1,ğ‘¥2,...,ğ‘¥ğ‘š}are location embeddings for all grids in trajectory ğ‘‡ğ‘Ÿğ‘–, and Pdenotes the position
encoding, which aims to distinguish the sequence position. Notice that Pis fixed and defined as in [30].
Then, Mğ‘–is then sent to the self-attention module to integrate the sequence information:
(Qğ‘–,Kğ‘–,Vğ‘–)T=Mğ‘–
Wğ‘„,Wğ¾,Wğ‘‰T
,
Zğ‘–=Softmax 
Qğ‘–KT
ğ‘–âˆš
ğ‘‘!
Vğ‘–,(5)
where Wğ‘„,Wğ¾,Wğ‘‰âˆˆRğ‘‘Ã—ğ‘‘are learnable projection matrices. The spatiotemporal correlation is calculated by
dot product. Softmax(Â·)is used to normalize the spatiotemporal dependencies, and the scaleâˆš
ğ‘‘prevents the
saturation led by Softmax function. Besides, we also employ a residual connection to solve the problem of network
degradation, followed by layer normalization.
In addition, multiple dependency patterns from location embeddings in a single trajectory can be learned
through a multi-head attention mechanism:
Zğ‘–=ğ¹ğ¶(concat(Z(1)
ğ‘–,Z(2)
ğ‘–,..., Z(#â„ğ‘’ğ‘ğ‘‘)
ğ‘–)), (6)
By stacking multiple temporal self-attention layers, we can effectively capture the complex temporal depen-
dencies in trajectory sequence.
Furthermore, the updated location embeddings Zğ‘–={ğ‘§1
ğ‘–,
ğ‘§2
ğ‘–,...,ğ‘§ğ‘š
ğ‘–}of trajectory ğ‘‡ğ‘Ÿğ‘–are sent to a pooling layer to extract important location information in the trajectory:
ğ‘§ğ‘™
ğ‘–=Pooling ğ‘§1
ğ‘–,ğ‘§2
ğ‘–,...,ğ‘§ğ‘š
ğ‘–, (7)
ForPooling , we select the Max-Pooling to detect the significant information. Consequently, the local represen-
tationğ‘§ğ‘™
ğ‘–âˆˆRğ‘‘for trajectory ğ‘‡ğ‘Ÿğ‘–is obtained by fusing the local location information.
4.3.3 Global Elastic Attention Encoder. Inspired by [ 23,25], we design an elastic attention module to select the
most relevant global information. Specifically, we first find the global embedding Hğ‘”(ğ‘–)for given trajectory ğ‘‡ğ‘Ÿğ‘–,
and the attention score w.r.t. trajectoryğ‘‡ğ‘Ÿğ‘—is defined as:
ğ‘ğ‘ 
ğ‘–,ğ‘—=Hğ‘”(ğ‘–)Hğ‘”(ğ‘—)T
âˆ¥Hğ‘”(ğ‘–)âˆ¥Hğ‘”(ğ‘—)T,
Ağ‘ 
ğ‘–={ğ‘ğ‘ 
ğ‘–,1,ğ‘ğ‘ 
ğ‘–,2,...,ğ‘ğ‘ 
ğ‘–,âˆ¥ğ‘‡ğ‘Ÿâˆ¥},
Wğ‘”
ğ‘–=Sparsemax Ağ‘ 
ğ‘–,(8)
whereâˆ¥ğ‘‡ğ‘Ÿâˆ¥is the number of trajectories, and Sparsemax is an alternative to Softmax which tends to yield sparse
probability distributions:
Sparsemax(ğ’™)=argmin
ğ’‘âˆˆÎ”ğ‘‘âˆ¥ğ’‘âˆ’ğ’™âˆ¥2, (9)
where Î”ğ‘‘=
ğ’‘âˆˆRğ‘‘:ğ’‘â‰¥0,âˆ¥ğ’‘âˆ¥1=1	
. The predictive distribution ğ’‘âˆ—=Sparsemax(ğ’™)is likely to assign exactly
zero probability to low-scoring choices, which retains the most important factors.
Finally, the output of global elastic attention encoder is the weighted sum of the global embedding vectors
based on attention weights Wğ‘”
ğ‘–:
ğ‘§ğ‘”
ğ‘–=Wğ‘”
ğ‘–Hğ‘”, (10)
ACM Trans. Knowl. Discov. Data..10 â€¢Wei Chen et al.
whereğ‘§ğ‘”
ğ‘–âˆˆRğ‘‘is the global representation of trajectory ğ‘‡ğ‘Ÿğ‘–.
4.4 Linking Layer
The linking layer aims to obtain the probability distribution of users (labels) from the representations learned
by hierarchical spatio-temporal attention networks. The linking layer first concatenates ğ‘§ğ‘™
ğ‘–andğ‘§ğ‘”
ğ‘–for each
trajectory to obtain a higher-level representation. Then, a fully connected layer is used to project the high-level
representation into a vector with |U|dimension. The formulation is as follows:
yğ‘–=
ğ‘Šğ‘
ğ‘§ğ‘™
ğ‘–
ğ‘§ğ‘”
ğ‘–
+ğ‘ğ‘
(11)
where Wğ‘âˆˆR|U|Ã— 2ğ‘‘andğ‘ğ‘âˆˆR|U|are learnable weight matrix and bias, and the vector yğ‘–is the estimated
probability of users for trajectory ğ‘‡ğ‘Ÿğ‘–.
To train our model, we apply cross-entropy as loss function and use back propagation algorithm to optimize
our model. We define our cross-entropy-based loss function as follows:
L(Î˜)=âˆ’1
ğœğœâˆ‘ï¸
ğ‘–=1ğ‘ğ‘–log(ğœ(yğ‘–))+ğœ†
2âˆ¥Î˜âˆ¥2(12)
whereğ‘ğ‘–is the one-hot ground truth label of trajectory ğ‘‡ğ‘Ÿğ‘–,ğœ(Â·)is the softmax function, ğœis the number of
training trajectories, and Î˜is the set of all trainable parameters. ğœ†is an L2 regularization hyperparameter to
alleviate overfitting.
4.5 Algorithm Pseudo-Code
Algorithm 1 shows the pseudo-code of our proposed AttnTUL framework guided by the above objective function
(i.e., Eq. (12)).
Algorithm 1 The Learning Process of AttnTUL
Input: Input local spatial graph Gğ‘™, global spatial graph Gğ‘”, feature matrix Xğ‘™andXğ‘”, embedding dimension ğ‘‘,
the number of convolution layers ğ‘™ğ‘›
Output: Model parameters Î˜
1:while ! convergence do
2: Perform graph convolutional networks
3:forğ‘–=1toğ‘™ğ‘›do
4: H(ğ‘–)
ğ‘™â†ReLU
ËœDâˆ’1
2
ğ‘™ËœAğ‘™ËœDâˆ’1
2
ğ‘™H(ğ‘–âˆ’1)
ğ‘™W(ğ‘–âˆ’1)
ğ‘™
;
5: H(ğ‘–)
ğ‘”â†ReLU
ËœDâˆ’1
2ğ‘”ËœAğ‘”ËœDâˆ’1
2ğ‘”H(ğ‘–âˆ’1)
ğ‘”W(ğ‘–âˆ’1)
ğ‘”
;
6:end for
7: Xâ†Tanh(ğ¹ğ¶([Wğ‘¡ğ‘¡+ğ‘ğ‘¡;Wğ‘ ğ‘ +ğ‘ğ‘ ;Hğ‘™]));
8: Getğ‘§ğ‘™
ğ‘–using Eqs. (4)-(7);
9: Getğ‘§ğ‘”
ğ‘–using Eqs. (9)-(10);
10: yğ‘–â† ğ‘Šğ‘
ğ‘§ğ‘™
ğ‘–;ğ‘§ğ‘”
ğ‘–
+ğ‘ğ‘
11: CalculateLusing Eq. (12);
12: Back propagation and update parameters in AttnTUL;
13:end while
14:Return Î˜;
ACM Trans. Knowl. Discov. Data..Trajectory-User Linking via Hierarchical Spatio-Temporal Attention Networks â€¢11
We now analyze the time complexity of our model. The time consumption of our model mainly lies in spatial
GCNs, temporal self-attention encoder, and global elastic attention encoder. First, the time complexity of spatial
GCN block is ğ‘‚(|E|ğ‘‘)andğ‘‚(|V|2ğ‘‘)for the GCN operation and the spatial attention operation, respectively, for
every iteration. Second, for each trajectory, the time complexity of temporal self-attention encoder is ğ‘‚(ğ‘š2ğ‘‘)for
the multi-head self-attention operation for each layer. It is clear that the time complexity of the global elastic
attention encoder is much smaller than that of the temporal self-attention encoder. Therefore, the time complexity
of our model is mainly composed of the spatial GCNs and the temporal self-attention encoder, and also depends
on the number of layers of networks, the number of trajectories, and the average length of trajectories.
5 EXPERIMENTS
In this section, we evaluate our proposed model on three types of real-world mobility datasets. The following
research questions (RQs) are used to guide our experiments:
â€¢RQ1. How does our AttnTUL perform in TUL problem on real-world datasets compared to existing
methods?
â€¢RQ2. How does each component contribute to the performance of the proposed AttnTUL?
â€¢RQ3. How does AttnTUL perform with different parameter settings ( e.g., grid sizeğ‘ , dimension ğ‘‘, and time
window size)?
â€¢RQ4. Whether the trajectory representation learned by our AttnTUL is better than DNN-based baselines?
â€¢RQ5. How does our AttnTUL perform efficiently compared to existing methods?
5.1 Datasets
We conduct extensive experiments on three publicly available real-world datasets: Gowalla1, PrivateCar2, and
GeoLife3.
â€¢Gowalla [11] is a user check-in dataset from a location based social network service. For each user, we
concatenate all check-in locations to form a trajectory which will be further divided into sub-trajectories
based on given time interval.
â€¢PrivateCar [14] is a GPS trajectory dataset of private cars collected in Shenzhen, China from January 1 to
January 15 in 2016. The sampling rate of the private car trajectory dataset is relatively high, 1 âˆ¼60 seconds
(average: 15.3 seconds and standard deviation: 7.8 seconds).
â€¢GeoLife [44] is a GPS trajectory dataset collected in Beijing from April 2007 to August 2012. This dataset
includes a broad range of usersâ€™ outdoor movements, including sightseeing, hiking, cycling and so on. 91%
of the trajectories are logged densely, e.g., every 1âˆ¼5 seconds or every 5 âˆ¼10 meters per point.
1http://snap.stanford.edu/data/loc-gowalla.html
2https://github.com/HunanUniversityZhuXiao/PrivateCarTrajectoryData
3https://www.microsoft.com/en-us/research/project/geolife-building-social-networks-using-human-location-history/
Table 2. Statistics of the datasets. ğ‘™ğ‘’ğ‘›: average length of trajectories, and H: hour(s).
Datasets #users #trajectories #points #POIsğœğ‘™ğ‘’ğ‘›
Gowalla547 38,567 15,967 15,892 6H 2
222 18,808 11,979 11,960 6H 3
PrivateCar71 4,178 135,085 10,493 1H 32
42 2,797 87,719 7,514 1H 31
GeoLife90 6,035 945,971 23,369 3H 157
56 4,064 768,533 19,384 3H 189
ACM Trans. Knowl. Discov. Data..12 â€¢Wei Chen et al.
Notice that our model does not requires POI data. Some baselines ( e.g., TULER and TULVAE) are designed
to work on sparse check-in data. To ensure fair comparison, we map GPS trajectories to POI check-in data to
make these baselines can handle GPS trajectory data. To fairly reproduce the results of baselines, we crawl POIs
in Shenzhen and Beijing from BaiduMap4as the additional geographical context for PrivateCar and GeoLife
datasets.
In order to check the robustness of our model, we select two different number of users from each dataset. The
statistics of these datasets are summarized in Table 2. Following [ 11],ğœis set as a reasonable time interval on
different datasets ( i.e., 6 hours, 1 hour and 3 hours for Gowalla, PrivateCar and GeoLife datasets, respectively).
5.2 Baselines
In our evaluation, we compare our AttnTUL against the following two categories of baselines.
5.2.1 Classic models.
â€¢LCSS [38] â€“ It adopts LCSS to compute trajectory similarity, and searches the most similar trajectory in
training set to find the corresponding user.
â€¢LDA [26] â€“ We apply Linear Discriminant Analysis (LDA) to TUL task by embedding trajectories into
one-hot vectors and using SVD to decompose the within-class scatter matrix.
â€¢DT[15] â€“ Decision Tree (DT) is a classic classification method for trajectory data. We use entropy as the
criterion in TUL problem, which shows better performance than Gini index.
â€¢SR[16,17] â€“ Signature Representation (SR) is a state-of-the-art trajectory similarity measure for moving
object linking.
5.2.2 Deep neural network models.
â€¢TULER [11] â€“ This is the original RNN model for solving TUL task. There are three variants: RNN
with Gated Recurrent Unit ( TULER-G ), Long Short-Term Memory ( TULER-L ) and bidirectional LSTM
(Bi-TULER ).
â€¢TULVAE [47] â€“ It utilizes VAE to learn the hierarchical semantics of trajectory with stochastic latent
variables that span hidden states in RNN.
â€¢DeepTUL [24] â€“ This is a recurrent network with attention mechanism to solve TUL problem, which is a
state-of-the-art method. It learns from labeled historical trajectory to capture multi-periodic nature of user
mobility and alleviate the data sparsity problem.
â€¢DPLink [7,8] â€“ DPLink is a state-of-the-art method to link user accounts from heterogeneous mobility
data.
â€¢T3S [35] â€“ T3S is a state-of-the-art trajectory representation learning method for trajectory similarity
computation.
â€¢GNNTUL [45] â€“ GNNTUL is the first GNN-based human mobility learning model exploiting implicit
transition patterns behind sparse user traces in online social networks while extracting usersâ€™ unique
movement features and discriminating the different trajectories.
Notice that we extend T3S with multi-class classification supervision to support TUL prediction. DPLink also
cannot be directly applied to TUL problem, thus we extend it to perform user identification in a single mobility
dataset in our experiments. The source code of our model is available at https://github.com/Onedean/AttnTUL.
4https://map.baidu.com/
ACM Trans. Knowl. Discov. Data..Trajectory-User Linking via Hierarchical Spatio-Temporal Attention Networks â€¢13
5.3 Evaluation Metrics
We use the widely used ğ´ğ¶ğ¶ @ğ‘˜, Macro-P, Macro-R and Macro-F1 to evaluate the performance, which are common
metrics in multi-classification task. Specifically, ğ´ğ¶ğ¶ @ğ¾is used to evaluate the accuracy of TUL prediction as:
ğ´ğ¶ğ¶ @ğ¾=|{ğ‘‡ğ‘Ÿğ‘–âˆˆğ‘‡ğ‘Ÿ:ğ‘¢âˆ—(ğ‘‡ğ‘Ÿğ‘–)âˆˆUğ¾(ğ‘‡ğ‘Ÿğ‘–)}|
|ğ‘‡ğ‘Ÿ|, (13)
whereğ‘¢âˆ—(ğ‘‡ğ‘Ÿğ‘–)is the ground truth user, and Uğ¾(ğ‘‡ğ‘Ÿğ‘–)is the predicted top- ğ¾user set. It is considered correct if the
ground truth user ğ‘¢âˆ—(ğ‘‡ğ‘Ÿğ‘–)lies within the predicted top-k user set Uğ¾(ğ‘‡ğ‘Ÿğ‘–).
Macro-F1 is regarded as an overall performance indicator, taking into account the precision and recall across
all classes in multi-classification task, which is defined as:
ğ‘€ğ‘ğ‘ğ‘Ÿğ‘œ â€“ğ‘ƒ=1
|ğ‘||ğ‘|âˆ‘ï¸
ğ‘–=1ğ‘ƒğ‘–,
ğ‘€ğ‘ğ‘ğ‘Ÿğ‘œ â€“ğ‘…=1
|ğ‘||ğ‘|âˆ‘ï¸
ğ‘–=1ğ‘…ğ‘–,
ğ‘€ğ‘ğ‘ğ‘Ÿğ‘œ â€“ğ¹1=1
|ğ‘||ğ‘|âˆ‘ï¸
ğ‘–=12Ã—ğ‘ƒğ‘–Ã—ğ‘…ğ‘–
ğ‘ƒğ‘–+ğ‘…ğ‘–(14)
where|ğ‘|is number of classes, and ğ‘ƒğ‘–andğ‘…ğ‘–areprecision andrecall of each class (user in TUL) respectively.
5.4 Experimental Settings
In our experiments, we use the first 60% of each userâ€™s trajectories as the training set on all datasets, the following
20% as the validation set, and the remaining 20% as test set.
We use the source code released by authors for baselines, and use the parameter setting recommended in the
original paper and fine-tune them on each dataset to be optimal. In the experiment, we set embedding dimension
ğ‘‘to 128, grid size ğ‘ to 40 meters on Gowalla and 120 meters on the other two datasets, the length of time window
to 2 hours, 10 minutes and 20 minutes on Gowalla, PrivateCar and GeoLife, the number of GCN layers to 2,
the number of self-attention layers to 3, #â„ğ‘’ğ‘ğ‘‘ to 4, andğœ†to5ğ‘’-4 for our AttnTUL. For fair comparison, for all
learning methods, we set epoch to 80, batch size to 16, dropout to 0.5, tune learning rate from 0.0001 to 0.01, use
early stopping mechanism, and set patience to 10 to avoid over fitting. In each experiment, we repeat 10 runs and
report the average.
All experiments for model efficiency evaluation are conducted on a machine with Intel Xeon Gold 6126@2.60GHz
12 cores CPU, 192GB memory, and NVIDIA Tesla V100-SXM2 (16GB) GPU.
Notice that all the user personal information in our datasets are anonymized to protect userâ€™s privacy.
5.5 Experiment Results
5.5.1 Overall Performance (RQ1). We first evaluate the overall performance of the proposed model on three
categories of trajectory datasets in comparison with state-of-the-art baselines. The overall performance is
reported in Table 3, where the best is shown in bold and the second best is shown as underlined . We also show
the comparison with classic models in Figure 4.
Notice that SML-TUL [ 46] and TGAN [ 48] are not compared in our experiments because there are no publicly
available source codes for them. However, according to the results reported in [ 46], our AttnTUL significantly
outperforms SML-TUL and TGAN in terms of Acc@ ğ‘˜and Macro-F1 on Gowalla, even though our AttnTUL links
ACM Trans. Knowl. Discov. Data..14 â€¢Wei Chen et al.
Table 3. Performance comparison with deep neural network models on three real-world datasets.
Data MethodsACC@1 ACC@5 Macro-P Macro-R Macro-F1 ACC@1 ACC@5 Macro-P Macro-R Macro-F1
|U|=222 |U|=547GowallaTULER-L 41.67% 51.23% 43.45% 34.11% 36.03% 37.61% 46.97% 40.96% 32.47% 34.24%
TULER-G 41.56% 50.96% 41.06% 33.08% 34.64% 38.88% 48.61% 42.20% 33.69% 35.15%
Bi-TULER 41.19% 50.36% 41.88% 33.92% 35.83% 36.88% 46.85% 41.09% 32.20% 33.80%
TULVAE 40.13% 49.72% 39.71% 32.01% 33.68% 37.18% 46.44% 40.39% 32.30% 33.67%
DeepTUL 42.36% 51.87% 43.81% 35.32% 37.22 % 37.99% 48.16% 41.15% 32.96% 34.48%
DPLink 41.51% 52.94 %41.32% 35.36% 36.15% 37.19% 49.72% 36.11% 33.18% 32.65%
T3S 40.80% 50.04% 44.52 % 33.68% 35.77% 34.53% 45.97% 35.58% 30.76% 30.50%
GNNTUL 42.61 %52.45% 41.41% 36.27 % 35.82% 41.28 %50.74 %42.63 % 34.90 % 36.72 %
AttnTUL 46.17 %55.44 %45.92 %39.54 %40.03 %44.90 %54.72 %45.40 %38.44 %39.63 %PrivateCar|U|=42 |U|=71
TULER-L 21.92% 44.90% 19.41% 21.05% 18.42% 15.43% 32.12% 15.20% 12.47% 12.16%
TULER-G 21.92% 45.94% 19.35% 19.61% 18.01% 16.13% 32.77% 15.96% 14.37% 13.29%
Bi-TULER 22.46% 47.79% 21.52% 21.54% 19.76% 16.57% 36.62% 15.76% 15.14% 13.80%
TULVAE 23.98% 50.44% 25.34% 20.34% 20.45% 16.89% 31.81% 16.92% 15.38% 14.59%
DeepTUL 22.99% 49.71% 22.95% 22.53% 20.16% 17.65% 33.09% 15.68% 16.97% 14.24%
DPLink 23.47% 47.12% 25.36% 23.32% 22.23% 20.71% 41.79% 19.14% 16.83% 15.27%
T3S 26.53% 47.90% 31.30 % 25.07% 25.59% 21.28% 39.45% 24.13% 20.05% 20.01%
GNNTUL 32.84 %56.89 %30.94% 28.58 % 27.71 % 29.47 47.80 %28.78 % 30.89 % 28.35 %
AttnTUL 35.11 %60.40 %33.24 %32.80 %31.49 %31.25 %54.74 %32.25 %32.24 %30.21 %GeoLife|U|=56 |U|=90
TULER-L 41.79% 71.81% 33.78% 34.94% 31.70% 36.84% 60.28% 32.91% 30.41% 29.32%
TULER-G 43.93% 70.08% 37.09% 36.50% 33.33% 35.51% 61.24% 33.88% 31.73% 30.25%
Bi-TULER 44.50% 74.09% 38.14% 35.82% 33.76% 37.99% 61.85% 35.82% 33.16% 32.12%
TULVAE 46.04% 70.99% 42.32% 39.73% 36.87% 39.27% 64.30% 36.23% 33.83% 32.31%
DeepTUL 51.23% 79.19% 45.84% 41.82% 39.36% 44.92% 69.93% 38.19% 38.35% 35.99%
DPLink 53.80 %80.03 %48.23 % 46.63 % 45.03 % 47.83% 73.95% 43.93% 40.80% 39.63%
T3S 51.10% 77.40% 45.47% 43.84% 43.13% 44.33% 70.65% 40.18% 39.52% 38.18%
GNNTUL 52.78% 76.13% 46.08% 45.14% 44.23% 48.56 %75.86 %46.74 % 43.89 % 43.40 %
AttnTUL 61.37 %85.87 %59.20 %59.59 %58.53 %53.92 %79.47 %49.94 %50.29 %48.24 %
more users on the same Gowalla dataset. The specific results are as follows::::::::AttnTUL vs. SML-TUL vs. TGAN:
:::::46.17% vs. 45.71% vs. 43.79% in ACC@1, and::::::40.03% vs 36.15% vs. 33.06% in Macro-F1 on Gowalla.
From the results in Figure 4, our AttnTUL significantly outperforms all classic baseline methods in terms of
all evaluation metrics, achieving 23.22%, 67.02%, 17.44% improvements in terms of ACC@1 over SR method on
Gowalla, PrivateCar, and Geolife datasets, respectively. SR performs better than other classic baselines in terms
of ACC@1, ACC@5, and Macro-F1 on three datasets as it considers the similarity of two trajectories from four
representation strategies ( i.e., sequential, temporal ,spatial and spatiotemporal). However, SR is still based on the
defined distance calculation, and cannot automatically learn the similarity or dependency between trajectories
based on the relationship among trajectories on different mobility datasets.
ACM Trans. Knowl. Discov. Data..Trajectory-User Linking via Hierarchical Spatio-Temporal Attention Networks â€¢15
/uni00000024/uni00000026/uni00000026/uni00000023/uni00000014 /uni00000024/uni00000026/uni00000026/uni00000023/uni00000018 /uni00000030/uni00000044/uni00000046/uni00000055/uni00000052/uni00000010/uni00000029/uni00000014
/uni0000002a/uni00000052/uni0000005a/uni00000044/uni0000004f/uni0000004f/uni00000044/uni00000003/uni0000000b/uni0000005fU/uni0000005f/uni00000020/uni00000015/uni00000015/uni00000015/uni0000000c/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b
/uni0000002f/uni00000026/uni00000036/uni00000036
/uni0000002f/uni00000027/uni00000024
/uni00000027/uni00000037
/uni00000036/uni00000035
/uni00000024/uni00000057/uni00000057/uni00000051/uni00000037/uni00000038/uni0000002f
/uni00000024/uni00000026/uni00000026/uni00000023/uni00000014 /uni00000024/uni00000026/uni00000026/uni00000023/uni00000018 /uni00000030/uni00000044/uni00000046/uni00000055/uni00000052/uni00000010/uni00000029/uni00000014
/uni00000033/uni00000055/uni0000004c/uni00000059/uni00000044/uni00000057/uni00000048/uni00000026/uni00000044/uni00000055/uni00000003/uni0000000b/uni0000005fU/uni0000005f/uni00000020/uni0000001a/uni00000014/uni0000000c/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b
/uni0000002f/uni00000026/uni00000036/uni00000036
/uni0000002f/uni00000027/uni00000024
/uni00000027/uni00000037
/uni00000036/uni00000035
/uni00000024/uni00000057/uni00000057/uni00000051/uni00000037/uni00000038/uni0000002f
/uni00000024/uni00000026/uni00000026/uni00000023/uni00000014 /uni00000024/uni00000026/uni00000026/uni00000023/uni00000018 /uni00000030/uni00000044/uni00000046/uni00000055/uni00000052/uni00000010/uni00000029/uni00000014
/uni0000002a/uni00000048/uni00000052/uni0000004f/uni0000004c/uni00000049/uni00000048/uni00000003/uni0000000b/uni0000005fU/uni0000005f/uni00000020/uni0000001c/uni00000013/uni0000000c/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni0000002f/uni00000026/uni00000036/uni00000036
/uni0000002f/uni00000027/uni00000024
/uni00000027/uni00000037
/uni00000036/uni00000035
/uni00000024/uni00000057/uni00000057/uni00000051/uni00000037/uni00000038/uni0000002f
Fig. 4. Performance comparison with classic models.
From the results in Table 3, we can see that AttnTUL achieves the best performance in terms of all metrics
on three different categories of trajectory datasets. This is because our designed local and global graph model
effectively captures both micro- and macro-spatial features for spatio-temporal trajectories. In addition, our
hierarchical spatio-temporal attention network can learn the long-term dependencies in time dimension and
adaptively fuse the local and global representations. This is main reason that our AttnTUL performs the best
on both sparse check-in dataset ( i.e., Gowalla) and dense GPS trajectory datasets ( i.e., PrivateCar and GeoLife).
Results in Table 3 show that our model significantly outperforms state-of-the-art baselines by 6.04% âˆ¼14.07%
and 6.56%âˆ¼29.54% improvements in terms of ACC@1 and Macro-F1. Specifically, AttnTUL achieves average
gains of 9.20% ACC@1 and 12.73% Macro-F1 score in comparison to the best performed baseline across all
datasets. Considering that the performance gain in TUL prediction reported in recent works [ 24,47] is usually
around 2.74-9.26% ACC@1 and 1.11-11.00% Macro-F1, this performance improvement achieved by our AttnTUL is
significant. Among various baselines, GNNTUL performs the second best on most of metrics, because they extract
comprehensive trajectory features. However, our AttnTUL consistently outperforms GNNTUL by 6.04-16.28%
ACC@1 and 6.56-31.88% Macro-F1 score across all datasets, which suggests the rationality of our designed
hierarchical spatio-temporal attention network architecture. Although GNNTUL uses graph-based representation
models, it is still limited by the only consideration of the information within the trajectory, and do not consider
the complex cross-trajectory correlations.
We also observe that model performance on data with fewer users is better than that on data with more
users. This is intuitive as the more users the more difficult the classification becomes. Among all baselines,
GNNTUL perform best in terms of ACC@1 and Macro-F1 on both Gowalla and PrivateCar datasets, and DPLink
performs the best in terms of ACC@1 and Macro-F1 on GeoLife dataset. However, our AttnTUL achieves more
improvement over the best performed baseline in terms of ACC@1 and Macro-F1 on data with more users, e.g.,
on Gowalla, 8.77% improvement in ACC@1 for |U|=547vs. 8.35% improvement for |U|=222, and 7.92%
improvement in Macro-F1 for |U|=574vs. 7.55% improvement for |U|=222.
5.5.2 Ablation Study (RQ2). To validate the effectiveness of each component in AttnTUL, we further conduct
the ablation study. We compare our AttnTUL with five carefully designed variants. Despite the changed part(s),
all variants have the same framework structure and parameter settings.
â€¢TUL-L â€“ It removes the whole local spatial module to demonstrate the importance of local modeling.
â€¢TUL-G â€“ It removes the whole global spatial module to demonstrate the importance of global modeling.
ACM Trans. Knowl. Discov. Data..16 â€¢Wei Chen et al.
Table 4. Results of ablation study. Mac: Macro.
Datasets Methods ACC@1 ACC@5 Macro-P Macro-R Macro-F1
Gowalla
(|U|=222)TUL-L 43.66% 53.28% 45.14% 37.95% 38.56%
TUL-G 41.87% 52.61% 37.03% 33.31% 33.29%
TUL-SA 43.20% 52.70% 45.82 % 36.58% 37.99%
TUL-EA 39.99% 51.58% 37.12% 31.73% 32.08%
TUL-TS 44.01 % 54.13 % 45.47% 38.72 % 39.92 %
AttnTUL 46.17 % 55.44 % 45.92 % 39.54 % 40.03 %
PrivateCar
(|U|=71)TUL-L 19.83% 44.74% 18.26% 20.86% 16.01%
TUL-G 30.09% 53.14% 27.50% 31.05% 27.16%
TUL-SA 28.31% 53.92 % 27.40% 27.67% 24.97%
TUL-EA 28.49% 52.12% 28.36 % 24.54% 23.64%
TUL-TS 30.58 % 53.20% 26.96% 31.52 % 27.41 %
AttnTUL 31.25 % 54.74 % 32.25 % 32.24 % 30.21 %
GeoLife
(|U|=90)TUL-L 49.51% 78.43% 45.49% 45.48% 43.04%
TUL-G 48.97% 75.46% 43.82% 43.61% 42.03%
TUL-SA 51.06% 78.65% 47.01% 47.15% 44.01%
TUL-EA 46.38% 74.35% 41.98% 40.56% 38.59%
TUL-TS 52.07 % 79.25 % 47.58 % 47.41 % 45.02 %
AttnTUL 53.92 % 79.47 % 49.94 % 50.29 % 48.24 %
â€¢TUL-SA â€“ It removes the self attention module and directly sends the location embeddings to pooling
layer to fuse local information.
â€¢TUL-EA â€“ It uses Softmax to replace our proposed elastic attention in global module.
â€¢TUL-TS â€“ In this variant, we remove the time and state encoders to verify the importance of them.
The results of ablation study on three datasets are shown in Table 4. As we can see, AttnTUL outperforms
all variants on three datasets, which demonstrates that our key components all contribute to performance
improvement of AttnTUL. A noteworthy phenomenon is that TUL-TS performs the second best on three datasets.
A potential reason is that time information is not as important as spatial information in TUL problem. Similar
conclusion has also been verified in [16, 17].
The comparison between TUL-L and AttnTUL highlights the effectiveness of the proposed local modeling for
capturing intra-trajectory dependencies in TUL problem. The comparison between TUL-G and AttnTUL reflects
the effectiveness of the proposed global modeling for extracting inter-trajectory corrections in TUL problem.
Compared to AttnTUL, TUL-L and TUL-G perform much worse demonstrating the importance of both local and
global modelling in our model.
In addition, we can see that TUL-SA performs much worse than AttnTUL in terms of ACC@1 on PrivateCar and
GeoLife, indicating that our designed temporal self-attention network could better capture long-term dependencies
for long sequence trajectories. Nevertheless, TUL-SA also performs worse than AttnTUL on Gowalla datasets,
which demonstrates that the self-attention mechanism can also capture temporal dependencies for sparse check-in
trajectories. Furthermore, we also find an important observation that TUL-EA produces worse results than TUL-G
in terms of most metrics on three datasets. This adequately demonstrates the crucial role of our designed elastic
attention of global module in extracting relevant global representation for TUL prediction.
ACM Trans. Knowl. Discov. Data..Trajectory-User Linking via Hierarchical Spatio-Temporal Attention Networks â€¢17
/uni00000017/uni00000013 /uni0000001b/uni00000013 /uni00000014/uni00000015/uni00000013 /uni00000014/uni00000019/uni00000013 /uni00000015/uni00000013/uni00000013
/uni0000002a/uni00000055/uni0000004c/uni00000047/uni00000003/uni00000036/uni0000004c/uni0000005d/uni00000048/uni00000013/uni00000011/uni00000015/uni00000013/uni00000013/uni00000011/uni00000015/uni00000018/uni00000013/uni00000011/uni00000016/uni00000013/uni00000013/uni00000011/uni00000016/uni00000018/uni00000013/uni00000011/uni00000017/uni00000013/uni00000013/uni00000011/uni00000017/uni00000018/uni00000013/uni00000011/uni00000018/uni00000013
/uni00000024/uni00000026/uni00000026/uni00000023/uni00000014
/uni00000030/uni00000044/uni00000046/uni00000055/uni00000052/uni00000010/uni00000033
/uni00000030/uni00000044/uni00000046/uni00000055/uni00000052/uni00000010/uni00000029/uni00000014
/uni00000016/uni00000015 /uni00000019/uni00000017 /uni00000014/uni00000015/uni0000001b /uni00000015/uni00000018/uni00000019 /uni00000018/uni00000014/uni00000015
/uni00000027/uni0000004c/uni00000050/uni00000048/uni00000051/uni00000056/uni0000004c/uni00000052/uni00000051/uni00000013/uni00000011/uni00000015/uni00000013/uni00000013/uni00000011/uni00000015/uni00000018/uni00000013/uni00000011/uni00000016/uni00000013/uni00000013/uni00000011/uni00000016/uni00000018/uni00000013/uni00000011/uni00000017/uni00000013/uni00000013/uni00000011/uni00000017/uni00000018/uni00000013/uni00000011/uni00000018/uni00000013
/uni00000024/uni00000026/uni00000026/uni00000023/uni00000014
/uni00000030/uni00000044/uni00000046/uni00000055/uni00000052/uni00000010/uni00000033
/uni00000030/uni00000044/uni00000046/uni00000055/uni00000052/uni00000010/uni00000029/uni00000014
/uni00000015 /uni00000016 /uni00000017 /uni00000018 /uni00000019
/uni00000006/uni0000004b/uni00000048/uni00000044/uni00000047/uni00000013/uni00000011/uni00000015/uni00000013/uni00000013/uni00000011/uni00000015/uni00000018/uni00000013/uni00000011/uni00000016/uni00000013/uni00000013/uni00000011/uni00000016/uni00000018/uni00000013/uni00000011/uni00000017/uni00000013/uni00000013/uni00000011/uni00000017/uni00000018/uni00000013/uni00000011/uni00000018/uni00000013
/uni00000024/uni00000026/uni00000026/uni00000023/uni00000014
/uni00000030/uni00000044/uni00000046/uni00000055/uni00000052/uni00000010/uni00000033
/uni00000030/uni00000044/uni00000046/uni00000055/uni00000052/uni00000010/uni00000029/uni00000014
/uni00000016/uni00000013 /uni00000019/uni00000013 /uni00000014/uni00000015/uni00000013 /uni00000014/uni0000001b/uni00000013 /uni00000015/uni00000017/uni00000013
/uni00000037/uni0000004c/uni00000050/uni00000048/uni00000003/uni0000003a/uni0000004c/uni00000051/uni00000047/uni00000052/uni0000005a/uni00000013/uni00000011/uni00000015/uni00000013/uni00000013/uni00000011/uni00000015/uni00000018/uni00000013/uni00000011/uni00000016/uni00000013/uni00000013/uni00000011/uni00000016/uni00000018/uni00000013/uni00000011/uni00000017/uni00000013/uni00000013/uni00000011/uni00000017/uni00000018/uni00000013/uni00000011/uni00000018/uni00000013
/uni00000024/uni00000026/uni00000026/uni00000023/uni00000014
/uni00000030/uni00000044/uni00000046/uni00000055/uni00000052/uni00000010/uni00000033
/uni00000030/uni00000044/uni00000046/uni00000055/uni00000052/uni00000010/uni00000029/uni00000014
(a) Gowalla
/uni00000017/uni00000013 /uni0000001b/uni00000013 /uni00000014/uni00000015/uni00000013 /uni00000014/uni00000019/uni00000013 /uni00000015/uni00000013/uni00000013
/uni0000002a/uni00000055/uni0000004c/uni00000047/uni00000003/uni00000036/uni0000004c/uni0000005d/uni00000048/uni00000013/uni00000011/uni00000013/uni00000018/uni00000013/uni00000011/uni00000014/uni00000013/uni00000013/uni00000011/uni00000014/uni00000018/uni00000013/uni00000011/uni00000015/uni00000013/uni00000013/uni00000011/uni00000015/uni00000018/uni00000013/uni00000011/uni00000016/uni00000013/uni00000013/uni00000011/uni00000016/uni00000018
/uni00000024/uni00000026/uni00000026/uni00000023/uni00000014
/uni00000030/uni00000044/uni00000046/uni00000055/uni00000052/uni00000010/uni00000033
/uni00000030/uni00000044/uni00000046/uni00000055/uni00000052/uni00000010/uni00000029/uni00000014
/uni00000016/uni00000015 /uni00000019/uni00000017 /uni00000014/uni00000015/uni0000001b /uni00000015/uni00000018/uni00000019 /uni00000018/uni00000014/uni00000015
/uni00000027/uni0000004c/uni00000050/uni00000048/uni00000051/uni00000056/uni0000004c/uni00000052/uni00000051/uni00000013/uni00000011/uni00000013/uni00000018/uni00000013/uni00000011/uni00000014/uni00000013/uni00000013/uni00000011/uni00000014/uni00000018/uni00000013/uni00000011/uni00000015/uni00000013/uni00000013/uni00000011/uni00000015/uni00000018/uni00000013/uni00000011/uni00000016/uni00000013/uni00000013/uni00000011/uni00000016/uni00000018
/uni00000024/uni00000026/uni00000026/uni00000023/uni00000014
/uni00000030/uni00000044/uni00000046/uni00000055/uni00000052/uni00000010/uni00000033
/uni00000030/uni00000044/uni00000046/uni00000055/uni00000052/uni00000010/uni00000029/uni00000014
/uni00000015 /uni00000016 /uni00000017 /uni00000018 /uni00000019
/uni00000006/uni0000004b/uni00000048/uni00000044/uni00000047/uni00000013/uni00000011/uni00000013/uni00000018/uni00000013/uni00000011/uni00000014/uni00000013/uni00000013/uni00000011/uni00000014/uni00000018/uni00000013/uni00000011/uni00000015/uni00000013/uni00000013/uni00000011/uni00000015/uni00000018/uni00000013/uni00000011/uni00000016/uni00000013/uni00000013/uni00000011/uni00000016/uni00000018
/uni00000024/uni00000026/uni00000026/uni00000023/uni00000014
/uni00000030/uni00000044/uni00000046/uni00000055/uni00000052/uni00000010/uni00000033
/uni00000030/uni00000044/uni00000046/uni00000055/uni00000052/uni00000010/uni00000029/uni00000014
/uni00000015 /uni00000018 /uni00000014/uni00000013 /uni00000015/uni00000013 /uni00000016/uni00000013
/uni00000037/uni0000004c/uni00000050/uni00000048/uni00000003/uni0000003a/uni0000004c/uni00000051/uni00000047/uni00000052/uni0000005a/uni00000013/uni00000011/uni00000013/uni00000018/uni00000013/uni00000011/uni00000014/uni00000013/uni00000013/uni00000011/uni00000014/uni00000018/uni00000013/uni00000011/uni00000015/uni00000013/uni00000013/uni00000011/uni00000015/uni00000018/uni00000013/uni00000011/uni00000016/uni00000013/uni00000013/uni00000011/uni00000016/uni00000018
/uni00000024/uni00000026/uni00000026/uni00000023/uni00000014
/uni00000030/uni00000044/uni00000046/uni00000055/uni00000052/uni00000010/uni00000033
/uni00000030/uni00000044/uni00000046/uni00000055/uni00000052/uni00000010/uni00000029/uni00000014
(b) PrivateCar
Fig. 5. Parameter sensitivity w.r.t. grid sizeğ‘ , embedding dimensionality ğ‘‘, the number of attentive representation heads
#â„ğ‘’ğ‘ğ‘‘ and time window length ğ‘‡ğ‘Šon Gowalla and PrivateCar data. Performances are measured by ACC@1, Macro-P,
Macro-F1.
5.5.3 Robustness Analysis (RQ3). We also evaluate the robustness of AttnTUL w.r.t. different settings of grid
sizeğ‘ , embedding dimension ğ‘‘, the number of heads #â„ğ‘’ğ‘ğ‘‘ and the length of time window ğ‘‡ğ‘Š. The results in
terms of ACC@1, Macro-P and Macro-F1 on both sparse Gowalla ( |U|=222) and dense PrivateCar ( |U|=71)
are depicted in Figure 5.
The effect of the grid size. From two left sub-figures in Figure 5, we find that the performance of AttnTUL
decreases as ğ‘ increases on Gowalla, while first increases and then decreases with the growth of ğ‘ from 40 to 200
meters. This phenomenon is easy to understand. Recall that Gowalla is a sparse check-in data, while PrivateCar
is a dense GPS trajectory data. If grid is too large, the spatial information would be lost, which is reflected
more obvious on sparse Gowalla than on dense PrivateCar. If grid is too small, some spatial interactions among
trajectories would not be reflected, which affects the prediction performance.
The effect of the embedding dimension. As shown in the two sub-figures of the second group, the performance
of AttnTUL first increases and then decreases on both Gowalla and PrivateCar as ğ‘‘increases, reaching the best
atğ‘‘=64andğ‘‘=128on Gowalla and PrivateCar, respectively. This is because Gowalla is very sparse, and thus
few grids are involved. The lower embedding dimensionality has little effect on it, while PrivateCar is denser.
When the dimensionality is very low, it has a greater impact on the prediction performance. However, larger
embedding dimensionality may contain superfluous information which hurts the TUL prediction performance.
The effect of the number of heads. To investigate the effect of the number of heads in temporal self-attention
encoder, we show the evaluation results with the settings of different head numbers in the third group of sub-
figures in Figure 5. As we can see, the performance of AttnTUL has little effect w.r.t. the number of heads #â„ğ‘’ğ‘ğ‘‘
on Gowalla, first increases and then decreases on PrivateCar as #â„ğ‘’ğ‘ğ‘‘ increases, and the model performance
achieves the best when #â„ğ‘’ğ‘ğ‘‘ =4on PrivateCar. The possible reason is that sub-trajectories in Gowalla are too
ACM Trans. Knowl. Discov. Data..18 â€¢Wei Chen et al.
sparse, so the intra-trajectory dependencies are not complicated, and thus the effect of multi-head attention
mechanism is not obvious. While sub-trajectories in PrivateCar are relatively dense, and the use of multi-head
attention mechanism effectively captures the complex temporal dependencies within the trajectory.
The effect of the length of time window. From two right sub-figures in Figure 5, we can see that the model
performance also first increases and then decreases as the length of time window increases on both Gowalla and
PrivateCar datasets. Considering the sparsity of Gowalla, denseness of PrivateCar, and the length of trajectories
in these two datasets, we vary the length of time window from 30 to 240 minutes on Gowalla and from 2 to
30 minutes on PrivateCar. Specifically, the model performance achieves the best when ğ‘‡ğ‘Šis set to 2 hours on
Gowalla and 10 minutes on PrivateCar. That is, on the sparse check-in mobility data Gowalla, when two-hour
time window is set to the same encoding, the best results are obtained, indicating that check-ins within such
a length of time can be considered to be indistinguishable in time. Similarly, on the dense GPS trajectory data
PrivateCar, the best performance is achieved with the same encoding for the spatial-temporal points within 10
60
 40
 20
 0 20 4060
40
20
0204060TULER-L
(a) TULER-L
60
 40
 20
 0 20 40 6040
20
02040 TULER-G (b) TULER-G
60
 40
 20
 0 20 4060
40
20
02040 Bi-TULER (c) Bi-TULER
40
 20
 0 20 40 6060
40
20
02040TULVAE
(d) TULVAE
40
 20
 0 20 40 6060
40
20
0204060
DPLink (e) DPLink
40
 20
 0 20 4040
20
0204060 T3S (f) T3S
40
 20
 0 20 40 6060
40
20
0204060DeepTUL
(g) DeepTUL
20
 10
 0 10 2040
30
20
10
0102030 GNNTUL (h) GNNTUL
40
 20
 0 20 40 6060
40
20
0204060
AttnTUL (i) AttnTUL
Fig. 6. Spatial-temporal representation visualization of trajectories learned by AttnTUL and other baselines on Gowalla.
ACM Trans. Knowl. Discov. Data..Trajectory-User Linking via Hierarchical Spatio-Temporal Attention Networks â€¢19
60
 40
 20
 0 20 40 6040
20
02040TULER-L
(a) TULER-L
40
 20
 0 20 4040
20
02040TULER-G (b) TULER-G
60
 40
 20
 0 20 4040
20
0204060Bi-TULER (c) Bi-TULER
60
 40
 20
 0 20 4060
40
20
0204060 TULVAE
(d) TULVAE
40
 20
 0 20 4060
40
20
0204060 DPLink (e) DPLink
60
 40
 20
 0 20 40 60 8040
20
02040T3S (f) T3S
60
 40
 20
 0 20 40 6060
40
20
0204060
DeepTUL
(g) DeepTUL
15
 10
 5
 0 5 10 1515
10
5
0510GNNTUL (h) GNNTUL
40
 20
 0 20 40 6040
20
0204060
AttnTUL (i) AttnTUL
Fig. 7. Spatial-temporal representation visualization of trajectories learned by AttnTUL and other baselines on GeoLife.
minutes, which also shows that there is no temporal difference between the different sub-trajectories in 10-minute
time window.
5.5.4 Visualization (RQ4). To further verify the effectiveness of our model in learning spatiotemporal represen-
tation of trajectories, we adopt a visualization way to compare the representation vectors of trajectories learned
by different models.
To this end, we use t-SNE [ 29] to plot the latent space of trajectories learned by DNN-based models. Specifically,
we randomly select 20 users and their corresponding trajectories from Gowalla and GeoLife. The learned
representation of each trajectory is projected to the 2D space. The visualization results of learned trajectory
reorientation on Gowalla ( |U|=222) and GeoLife (|U|=90) are shown in Figure 6 and Figure 7, where points
with the same color represent trajectories from the same user.
From Figures 6 and 7, we can observe that the trajectory representations generated by our AttnTUL show an
apparent clustering effect, and the clustering is tighter than other methods ( i.e., Figure 6(i) and Figure 7(i)). This
ACM Trans. Knowl. Discov. Data..20 â€¢Wei Chen et al.
indicates that AttnTUL is able to effectively distinguish trajectories generated by different users, which is crucial
for TUL prediction task. Although GNNTUL and DeepTUL can also distinguish some clusters (users), there are
obviously plenty of trajectories from different users intertwined together, and thus it is difficult to identify the
correct users for these trajectories.
Furthermore, we also observe that all baselines perform poorly on sparse check-in dataset ( i.e., Gowalla)
compared to the easily distinguishable dense GeoLife dataset, while our model effectively distinguishes the
trajectories produced by most users (see Figure 6(i)).
5.5.5 Model Efficiency Analysis (RQ5). We also compare the efficiency of our AttnTUL with all baselines on
Gowalla (|U|=222) data. We report the experiment results w.r.t. classic methods and DNN-based methods in
Figure 8.
Since classic methods have no training time, we only compare the running time. As can be seen from Figure 8(a),
the prediction time of our AttnTUL is much less than the running time of classic methods. This is because the
classic methods need to calculate a large number of distances between trajectories, so the time cost is relatively
high. For example, LCSS, LDA, and DT all consume more than 300 times the prediction time of our model.
From the results in Figure 8(b), we can see that the running time ( i.e., the testing time) of DNN-based models is
much less than that of classic methods. Although the testing time of our model is not the best, it is faster than
state-of-the-art GNNTUL, and the testing time is also less than 1 seconds. Since we adopt the early stopping
mechanism for all DNN-based models, the number of rounds of early stopping is different for different models.
For a fair comparison, we report the average training time per each epoch. In terms of model training time, the
efficiency of our AttnTUL is in the middle level, better than state-of-the-art models ( i.e., TULVAE, T3S, DeepTUL,
and GNNTUL), and worse than the simple TUL models ( i.e., TULER and its variants) and DPLink. It takes around
5.6 seconds for each epoch on Gowalla using a Tesla V100 GPU card. Specifically, our AttnTUL is 2.4 times and
7.3 times faster than TULVAE and DeepTUL per epoch, respectively. The potential reason is that DeepTUL needs
to use historical trajectory data, so a large number of trajectory distances need to be calculated, while TULVAE
needs to use variational inference, which requires expensive time cost.
/uni00000015/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013/uni00000019/uni00000013/uni00000013/uni0000001b/uni00000013/uni00000013/uni00000037/uni0000004c/uni00000050/uni00000048/uni00000003/uni0000000b/uni00000056/uni0000000c/uni00000035/uni00000058/uni00000051/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000057/uni0000004c/uni00000050/uni00000048
/uni0000002f/uni00000026/uni00000036/uni00000036 /uni0000002f/uni00000027/uni00000024/uni00000027/uni00000037 /uni00000036/uni00000035
/uni00000024/uni00000057/uni00000057/uni00000051/uni00000037/uni00000038/uni0000002f/uni00000013/uni00000014/uni00000015
(a) Classic models
TULER-LTULER-GBi-TULERTULVAEDeepTLUDPLinkT3S
GNNTULAttnTUL0246810121416Time(s)Training Time / per epoch
Running Time (b) DNN models
Fig. 8. Model Efficiency Evaluation
ACM Trans. Knowl. Discov. Data..Trajectory-User Linking via Hierarchical Spatio-Temporal Attention Networks â€¢21
6 CONCLUSION
In this paper, we present a novel hierarchical spatio-temporal attention network, called AttnTUL, for TUL
problem. AttnTUL effectively learns the local and global representations for each trajectory by the designed
hierarchical spatio-temporal attention network to classify trajectories by users. AttnTUL first employs GCN on
the constructed local and global graphs to learn embeddings for grids and trajectories. Then, it uses a hierarchical
spatio-temporal attention network to obtain the local and global representations for each trajectory, respectively.
Eventually, a linking layer is designed to fuse the two representation to classify trajectories by users. Experiments
on three real-world mobility datasets demonstrate that our model significantly outperforms state-of-the-art
baselines in terms of all metrics for TUL problem. For future work, we plan to enhance our proposed AttnTUL
model with the ability of handling streaming mobility trace data for real-time trajectory-user linking scenario.
ACKNOWLEDGMENT
This work is partially supported by the National Natural Science Foundation of China under grant Nos. 62176243,
61773331 and 41927805.
REFERENCES
[1]Stefan Atev, Grant Miller, and Nikolaos P. Papanikolopoulos. 2010. Clustering of Vehicle Trajectories. IEEE Transactions onIntelligent
Transportation Systems 11, 3 (2010), 647â€“657. https://doi.org/10.1109/TITS.2010.2048101
[2]Dzmitry Bahdanau, Kyung Hyun Cho, and Yoshua Bengio. 2015. Neural machine translation by jointly learning to align and translate.
InICLR.
[3]Hyungho Byun, Younhyuk Choi, and Chong-Kwon Kim. 2023. Aspect-oriented unsupervised social link inference on user trajectory
data. Information Sciences 626 (2023), 249â€“261.
[4]Wei Chen, Shuzhe Li, Chao Huang, Yanwei Yu, Yongguo Jiang, and Junyu Dong. 2022. Mutual Distillation Learning Network for
Trajectory-User Linking. In IJCAI.
[5]Yudong Chen, Xin Wang, Miao Fan, Jizhou Huang, Shengwen Yang, and Wenwu Zhu. 2021. Curriculum Meta-Learning for Next POI
Recommendation. In KDD. 2692â€“2702.
[6]Liwei Deng, Hao Sun, Yan Zhao, Shuncheng Liu, and Kai Zheng. 2023. S2TUL: A Semi-Supervised Framework for Trajectory-User
Linking. In Proceedings oftheSixteenth ACM International Conference onWeb Search andData Mining. 375â€“383.
[7]Jie Feng, Yong Li, Mingyang Zhang, Zeyu Yang, Huandong Wang, Han Cao, and Depeng Jin. 2020. User Identity Linkage via Co-Attentional
Neural Network From Heterogeneous Mobility Data. TKDE (2020), 1â€“1. https://doi.org/10.1109/TKDE.2020.2989732
[8]Jie Feng, Mingyang Zhang, Huandong Wang, Zeyu Yang, Chao Zhang, Yong Li, and Depeng Jin. 2019. Dplink: User identity linkage via
deep neural network from heterogeneous mobility data. In WWW. 459â€“469.
[9]Qiang Gao, Fengli Zhang, Fuming Yao, Ailing Li, Lin Mei, and Fan Zhou. 2020. Adversarial mobility learning for human trajectory
classification. IEEE Access 8 (2020), 20563â€“20576.
[10] Qiang Gao, Fan Zhou, Goce Trajcevski, Kunpeng Zhang, Ting Zhong, and Fengli Zhang. 2019. Predicting human mobility via variational
attention. In WWW. 2750â€“2756.
[11] Qiang Gao, Fan Zhou, Kunpeng Zhang, Goce Trajcevski, Xucheng Luo, and Fengli Zhang. 2017. Identifying Human Mobility via
Trajectory Embeddings. In IJCAI, Vol. 17. 1689â€“1695.
[12] William L Hamilton, Rex Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NeurIPS. 1025â€“1035.
[13] Chao Huang, Junbo Zhang, Yu Zheng, and Nitesh V Chawla. 2018. DeepCrime: Attentive hierarchical recurrent networks for crime
prediction. In CIKM. 1423â€“1432.
[14] Yourong Huang, Zhu Xiao, Xiaoyou Yu, Dong Wang, Vincent Havyarimana, and Jing Bai. 2019. Road network construction with complex
intersections based on sparsely sampled private car trajectory data. TKDD 13, 3 (2019), 1â€“28.
[15] Zhe Jiang. 2018. A survey on spatial prediction methods. TKDE 31, 9 (2018), 1645â€“1664.
[16] Fengmei Jin, Wen Hua, Jiajie Xu, and Xiaofang Zhou. 2019. Moving object linking based on historical trace. In ICDE . IEEE, 1058â€“1069.
[17] Fengmei Jin, Wen Hua, Thomas Zhou, Jiajie Xu, Matteo Francia, Maria Orowska, and Xiaofang Zhou. 2020. Trajectory-Based Spatiotem-
poral Entity Linking. TKDE (2020).
[18] Eamonn J Keogh and Michael J Pazzani. 2000. Scaling up dynamic time warping for datamining applications. In KDD. 285â€“289.
[19] Urvashi Khandelwal, He He, Peng Qi, and Dan Jurafsky. 2018. Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use
Context. In ACL. 284â€“294.
[20] Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR.
ACM Trans. Knowl. Discov. Data..22 â€¢Wei Chen et al.
[21] Xiucheng Li, Kaiqi Zhao, Gao Cong, Christian S Jensen, and Wei Wei. 2018. Deep representation learning for trajectory similarity
computation. In ICDE. IEEE, 617â€“628.
[22] Wei Liu, Zhi-Jie Wang, Bin Yao, and Jian Yin. 2019. Geo-ALM: POI Recommendation by Fusing Geographical Information and Adversarial
Learning Mechanism.. In IJCAI, Vol. 7. 1807â€“1813.
[23] Andre Martins and Ramon Astudillo. 2016. From softmax to sparsemax: A sparse model of attention and multi-label classification. In
ICML. PMLR, 1614â€“1623.
[24] Congcong Miao, Jilong Wang, Heng Yu, Weichen Zhang, and Yinyao Qi. 2020. Trajectory-user linking with attentive recurrent network.
InAAMAS. 878â€“886.
[25] Ben Peters, Vlad Niculae, and AndrÃ© FT Martins. 2019. Sparse Sequence-to-Sequence Models. In ACL. 1504â€“1519.
[26] Hamid Reza Shahdoosti and Fardin Mirzapour. 2017. Spectralâ€“spatial feature extraction using orthogonal linear discriminant analysis
for classification of hyperspectral data. European Journal ofRemote Sensing 50, 1 (2017), 111â€“124.
[27] Shuo Shang, Lisi Chen, Zhewei Wei, Christian SÃ¸ndergaard Jensen, Kai Zheng, and Panos Kalnis. 2017. Trajectory similarity join in
spatial networks. VLDB 10, 11 (2017).
[28] Tao Sun, Yongjun Xu, Fei Wang, Lin Wu, Tangwen Qian, and Zezhi Shao. 2021. Trajectory-User Link with Attention Recurrent Networks.
InICPR. IEEE, 4589â€“4596.
[29] Laurens Van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE. Journal ofmachine learning research 9, 11 (2008).
[30] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Åukasz Kaiser, and Illia Polosukhin. 2017.
Attention is all you need. In NeurIPS. 5998â€“6008.
[31] Jingyuan Wang, Ning Wu, Wayne Xin Zhao, Fanzhang Peng, and Xin Lin. 2019. Empowering A* search algorithms with neural networks
for personalized route recommendation. In KDD. 539â€“547.
[32] Pengyang Wang, Xiaolin Li, Yu Zheng, Charu Aggarwal, and Yanjie Fu. 2019. Spatiotemporal representation learning for driving
behavior analysis: A joint perspective of peer and temporal dependencies. TKDE (2019).
[33] Senzhang Wang, Jiannong Cao, and Philip Yu. 2020. Deep learning for spatio-temporal data mining: A survey. TKDE (2020).
[34] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. 2020. A comprehensive survey on graph
neural networks. TNNLS 32, 1 (2020), 4â€“24.
[35] Peilun Yang, Hanchen Wang, Ying Zhang, Lu Qin, Wenjie Zhang, and Xuemin Lin. 2021. T3S: Effective Representation Learning for
Trajectory Similarity Computation. In ICDE. IEEE, 2183â€“2188.
[36] Di Yao, Gao Cong, Chao Zhang, and Jingping Bi. 2019. Computing trajectory similarity in linear time: A generic seed-guided neural
metric learning approach. In ICDE. IEEE, 1358â€“1369.
[37] Di Yao, Gao Cong, Chao Zhang, Xuying Meng, Rongchang Duan, and Jingping Bi. 2020. A Linear Time Approach to Computing Time
Series Similarity based on Deep Metric Learning. TKDE (2020).
[38] Josh Jia-Ching Ying, Eric Hsueh-Chan Lu, Wang-Chien Lee, Tz-Chiao Weng, and Vincent S Tseng. 2010. Mining user similarity from
semantic trajectories. In SIGSPATIAL Workshop onLBSNs. 19â€“26.
[39] Yong Yu, Haina Tang, Fei Wang, Lin Wu, Tangwen Qian, Tao Sun, and Yongjun Xu. 2020. TULSN: Siamese Network for Trajectory-user
Linking. In IJCNN. IEEE, 1â€“8.
[40] Hanyuan Zhang, Xinyu Zhang, Qize Jiang, Baihua Zheng, Zhenbang Sun, Weiwei Sun, and Changhu Wang. 2020. Trajectory Similarity
Learning with Auxiliary Supervision and Optimal Matching. In IJCAI. AAAI, 3209â€“3215.
[41] Mingyang Zhang, Tong Li, Hongzhi Shi, Yong Li, Pan Hui, et al .2019. A decomposition approach for urban anomaly detection across
spatiotemporal data. In IJCAI.
[42] Yu Zheng. 2015. Trajectory data mining: an overview. TIST 6, 3 (2015), 1â€“41.
[43] Yu Zheng, Quannan Li, Yukun Chen, Xing Xie, and Wei-Ying Ma. 2008. Understanding mobility based on GPS data. In UbiComp .
312â€“321.
[44] Yu Zheng, Xing Xie, Wei-Ying Ma, et al .2010. Geolife: A collaborative social networking service among user, location and trajectory.
IEEE Data Eng. Bull. 33, 2 (2010), 32â€“39.
[45] Fan Zhou, Shupei Chen, Jin Wu, Chengtai Cao, and Shengming Zhang. 2021. Trajectory-user linking via graph neural network. In ICC
2021-IEEE International Conference onCommunications. IEEE, 1â€“6.
[46] Fan Zhou, Yurou Dai, Qiang Gao, Pengyu Wang, and Ting Zhong. 2021. Self-supervised human mobility learning for next location
prediction and trajectory classification. Knowledge-Based Systems (2021), 107214.
[47] Fan Zhou, Qiang Gao, Goce Trajcevski, Kunpeng Zhang, Ting Zhong, and Fengli Zhang. 2018. Trajectory-User Linking via Variational
AutoEncoder. In IJCAI. 3212â€“3218.
[48] Fan Zhou, Ruiyang Yin, Goce Trajcevski, Kunpeng Zhang, Jin Wu, and Ashfaq Khokhar. 2021. Improving human mobility identification
with trajectory augmentation. GeoInformatica 25, 3 (2021), 453â€“483.
[49] Fan Zhou, Xiaoli Yue, Goce Trajcevski, Ting Zhong, and Kunpeng Zhang. 2019. Context-aware variational trajectory encoding and
human mobility inference. In WWW. 3469â€“3475.
ACM Trans. Knowl. Discov. Data..Trajectory-User Linking via Hierarchical Spatio-Temporal Attention Networks â€¢23
[50] Yin Zhu, Yu Zheng, Liuhang Zhang, Darshan Santani, Xing Xie, and Qiang Yang. 2012. Inferring taxi status using gps trajectories. arXiv
preprint arXiv:1205.4378 (2012).
ACM Trans. Knowl. Discov. Data..