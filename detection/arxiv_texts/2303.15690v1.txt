MNRAS 000, 1‚Äì14 (2023) Preprint 29 March 2023 Compiled using MNRAS L ATEX style Ô¨Åle v3.0
Estimating Stellar Parameters from LAMOST Low-resolution
Spectra
Xiangru Li1?, and BoYu Lin1
1School of Computer Science, South China Normal University, No. 55 West of Yat-sen Avenue, Guangzhou 510631, China
Accepted XXX. Received YYY; in original form ZZZ
ABSTRACT
The Large Sky Area Multi-Object Fiber Spectroscopic Telescope (LAMOST) has acquired tens of millions of low-
resolution spectra of stars. This paper investigated the parameter estimation problem for these spectra. To this end,
we proposed a deep learning model StarGRU network (StarGRUNet). This network was further applied to estimate
the stellar atmospheric physical parameters and 13 elemental abundances from LAMOST low-resolution spectra. On
the spectra with signal-to-noise ratios greater than or equal to 5, the estimation precisions are 94K and 0:16dex on
Teffandloggrespectively, 0:07dex to 0:10dex on [C/H], [Mg/H], [Al/H], [Si/H], [Ca/H], [Ni/H] and [Fe/H], and
0:10dex to 0:16dex on [O/H], [S/H], [K/H], [Ti/H] and [Mn/H], and 0:18dex and 0:22dex on [N/H] and [Cr/H]
respectively. The model shows advantages over available models and high consistency with high-resolution surveys.
We released the estimated catalog computed from about 8.21 million low-resolution spectra in LAMOST DR8, code,
trained model, and experimental data for astronomical science exploration and data processing algorithm research
respectively.
Key words: methods: data analysis, methods: statistical, stars: abundances, stars: fundamental parameters.
1 INTRODUCTION
In recent years, a series of large-scale sky survey programs
have been conducted to acquire massive spectra of stars, such
as the Apache Point Observatory Galactic Evolution Experi-
ment (APOGEE) (Prieto et al. 2010), the Galactic Archaeol-
ogy with HERMES Survey (GALAH) (De Silva et al. 2015),
the Large Sky Area Multi-Object Fibre Spectroscopic Tele-
scope (LAMOST) Experiment for Galactic Understanding
and Exploration (LEGUE) (Deng et al. 2012; Zhao et al.
2012), The Gaia-ESO Public Spectroscopic Survey (Gaia-
ESO) (Gilmore et al. 2012), the Sloan Extension for Galac-
tic Understanding and Exploration (SEGUE) (Yanny et al.
2009), the RAdial Velocity Experiment (RAVE) (Steinmetz
et al. 2006) and so on. Stellar spectra contain rich celestial
information, such as the motions of the objects, atmospheric
physical parameters, elemental abundances, etc. Stellar spec-
tra information can be used in exploring stellar evolution,
galaxy dynamics, etc. Therefore, the estimation of stellar
atmospheric physical parameters and elemental abundances
from spectra is vital in large-scale spectroscopic surveys.
Large-scale low-resolution and medium-resolution surveys
are typically distinguished by its massive amount, much data
with relatively low signal-to-noise ratios, and an extensive
range of data quality. These diÔ¨Éculties challenge the compu-
tational eÔ¨Éciency of traditional spectral parameter estima-
?E-mail: xiangru.li@gmail.comtion methods and their robustness to spectral quality. There-
fore, spectral parameter estimation research based on ma-
chine learning has attracted much attention (Li et al. 2015;
Xiang et al. 2016; Bu & Pan 2018; Zhang et al. 2020; Xiang
et al. 2021). The basic idea of such methods is to represent
theparameterestimationproblemasamappingfromspectral
feature information to the parameters under being estimated.
The model parameters for this mapping are determined by
calculating a batch of empirical data. The parameters of each
of these observed spectra are known. These parameters are
usually deÔ¨Åned based on high-quality, high-resolution spectra
with the equivalent widths (EWs) method or the calculation
of chemical elemental absorption lines (Jofr√© et al. 2019).
The traditional machine learning methods for estimating
stellar spectral parameters usually consist of two key proce-
dures: feature extraction and mapping learning. The feature
extraction procedure learns an appropriate representation for
stellar spectra. The spectral feature representation not only
determines the interpretability and accuracy limits of the pa-
rameter estimation model, but also aÔ¨Äects the learning diÔ¨É-
culty of the mapping relationship (Li et al. 2014, 2015). The
mapping learning procedure provides the mapping relation-
ship from the spectral information to the parameters to be
estimated. Typical feature extraction methods are wavelet
analysis, and wavelet packet decomposition (Li et al. 2015),
auto-encoder neural network (Yang & Li 2015), Least Ab-
solute Shrinkage and Selection Operator (LASSO) (Li et al.
2014),principalcomponentanalysis(PCA)(Bu&Pan2018),
kernel-based principal component analysis (KPCA) (Xiang
¬©2023 The AuthorsarXiv:2303.15690v1  [astro-ph.SR]  28 Mar 20232Li et al.
et al. 2016), etc. The commonly used machine learning meth-
ods in stellar spectral parameter estimation are support vec-
tor machines (Li et al. 2014; Zhang et al. 2020), linear regres-
sion (Li et al. 2015), Gaussian process regression (Bu & Pan
2018), and neural networks (Li et al. 2014). The limitation
of the traditional machine learning stellar spectral parameter
estimation scheme is that the feature learning and mapping
learning of the spectra are performed as two separate proce-
dures. This characteristics results in some diÔ¨Éculties in de-
signing this kind scheme and some potential improvements
on parameter estimation performance.
With the advent of artiÔ¨Åcial intelligence and the big data
era, deep learning methods have become the dominant meth-
ods for estimating parameters from stellar spectra, such as
StarNet(Fabbro et al. 2018; Zhang et al. 2019), AstroNN (Le-
ung & Bovy 2018), SPCANet(Wang et al. 2020), and so on.
These methods combine feature learning and mapping learn-
ing into a single procedure by utilizing neural networks. The
procedure combination simpliÔ¨Åes the designing of parame-
ter estimation scheme and improves prediction performance.
Therefore, neural networks promote the research and appli-
cation of spectral parameter estimation of stars.
This paper investigates the problem of estimating the at-
mospheric physical parameters of stars and elemental abun-
dances from low-resolution spectra of the Large Sky Area
Multi-Object Fiber Spectroscopic Telescope (LAMOST).
LAMOST, also referred to as the Guo Shoujing Telescope, is
attheXinglongNationalAstronomicalObservatoryinHebei,
China. It is a special reÔ¨Çecting Schmidt telescope with 4;000
optical Ô¨Åbers on the focal plane. This telescope can simulta-
neously observe up to 4;000targets in a view of a 20-square-
degree Ô¨Åeld. Since 2015, LAMOST has released several ver-
sionsofdatafromDR1toDR8.Amongthem,LAMOSTDR8
is the latest version of LAMOST data. The LAMOST DR8
consists of 11;214;076low-resolution stellar spectra cover-
ing a wavelength range of 3690√Ö-9100√Ö, with a resolution of
about 1800 at 5;500√Ö.
To estimate the parameters from LAMOST low-resolution
stellarspectra,aseriesofstudieshavebeencarriedout.These
studies have also experienced the explorations from tradi-
tional machine learning schemes to deep learning solutions.
Some representative studies based on traditional machine
learning schemes are KPCA (Xiang et al. 2016), The Cannon
(Ting et al. 2017; Ho et al. 2017), SLAM (Zhang et al. 2020),
SCDD (Xiang et al. 2021) and LASSO-MLPNet (Li et al.
2022b,a). Some typical investigations of deep learning meth-
ods are GSN (Rui et al. 2019a), StarNet (Zhang et al. 2019),
DD-Payne (Xiang et al. 2019), HotPayne (Xiang, Maosheng
et al. 2022), astroNN (Li et al. 2022c) and Coord-DenseNet
(Caietal.2023)).Withtheincreasingofdatavolumeandthe
development of artiÔ¨Åcial intelligence methods, deep learning
methods have been more and more widely applied to esti-
mate stellar parameters from low-resolution spectra. How-
ever, among the methods for estimating the stellar parame-
ters from the low-resolution spectra of LAMOST DR8, Wang
et al. (2022) focused only on the spectra with higher signal-
to-noise ratio ( S=N LAMOST>80andS=N APOGEE>70),
Li et al. (2022a,b) estimated the Teff,loggand [Fe/H] from
the spectra repectively with 20S=N LAMOST30and
5S=N LAMOST80. These constraints lead to a very lim-
ited number of samples in the reference set. On the other
hand, Li et al. (2022c) only estimated stellar parametersfor giant stars, Cai et al. (2023) only predicted the lithium
abundance for some of the giant star spectra. Therefore,
they only estimated the stellar parameters from a relatively
small number of a small variety of parameters. Therefore, our
study covers a broader range of spectral signal-to-noise ratios
(S=N LAMOST5), estimates a wider variety of parameters
(16),andincludesamoresigniÔ¨Åcantnumberofstellarspectra
(about 8:21million).
Todeterminethestellarparameters(eÔ¨Äectivetemperature,
surface gravity, and metal abundance) for the vast amount
of LAMOST spectral data, researchers developed the LAM-
OST Stellar Parameter Pipelines (LASP) (Luo et al. 2015).
LASP provides parameter estimation results for LAMOST
DR8 low-resolution spectra using the ELODIE spectral li-
brary as templates and a 2minimization method based on
the ULySS procedure (Wu et al. 2011). However, our prelim-
inary study shows that the precision of the LASP estimation
results decreases rapidly with the decline of the signal-to-
noise ratio (SNR) of spectra. In the case of 5S=N g<8,
8S=N g<10,10S=N g<20, and 20S=N g<30, the
mean absolute of error (MAE) of LASP are 178:5K,179:0K,
146:3K, and 135:3K onTeff,0:446dex,0:356dex,0:256dex,
and0:217dex on logg,0:148dex, 0:150dex, 0:107dex, and
0:087dex on [Fe/H], while the standard deviation of error ( )
are257:8K,292:2K,200:6K, and 176:5K onTeff,0:635
dex, 0:534dex, 0:372dex, and 0:325dex on logg,0:194dex,
0:211dex, 0:157dex, and 0:125dex on [Fe/H]. Therefore, Li
et al. (2022a,b) correspondingly conducted some investiga-
tions and improved the precision of the parameter estimates
compared to LASP (Figure 1). However, Li et al. (2022a,b)
and LASP are limited to estimating three stellar atmospheric
physical parameters, Teff,loggand [Fe/H]. Therefore, this
paper focused on further improving the precision of stellar
atmospheric physical parameter estimation while also inves-
tigating the measurement of 13 more elemental abundances
([C/H], [Mg/H], [Al/H], [Si/H], [Ca/H], [N/H], [O/H], [S/H],
[Ti/H], [Cr/H], [Mn/H], [Ni/H], and [K/H]).
The implementation code of the proposed neural networks
in this paper are done in TensorÔ¨Çow. The full project and its
documentation are available at http://doi.org/10.12149/
101216afteracceptanceforpublication.Thisprojectincludes
the estimated catalog computed from about 8:21million low-
resolution spectra in LAMOST DR8, code, trained models,
and experimental data for astronomical science exploration
and data processing algorithm research, respectively. The
project documentation will provide a detailed description of
the overall project architecture.
The remainder of this paper is organized as following. Sec-
tion2presentsthedatausedinthispaper;Section3describes
the proposed methodology, its evaluation, and model uncer-
tainty analysis; Section 4 shows our application results on
approximately 8:21millionlow-resolutionspectrafromLAM-
OST; Section 5 gives some conclusions.
2 REFERENCE DATASETS AND THEIR
PREPROCESSING
The proposed scheme in this paper is one of machine learn-
ing methods. This kind method need a reference data set
(referred to as a reference set). The reference set is used for
learning the model parameters in the mapping from the spec-
MNRAS 000, 1‚Äì14 (2023)3
5-88-1010-2020-3030-4040-5050-6060-7070-8080100120140160180MAE
Teff
LASP-Payne
LASSO-MLPNet-Payne
5-88-1010-2020-3030-4040-5050-6060-7070-800.100.150.200.250.300.350.400.45
logg
LASP-Payne
LASSO-MLPNet-Payne
5-88-1010-2020-3030-4040-5050-6060-7070-800.040.060.080.100.120.14
[Fe/H]
LASP-Payne
LASSO-MLPNet-Payne
5-88-1010-2020-3030-4040-5050-6060-7070-80125150175200225250275300
Teff
LASP-Payne
LASSO-MLPNet-Payne
5-88-1010-2020-3030-4040-5050-6060-7070-800.20.30.40.50.6
logg
LASP-Payne
LASSO-MLPNet-Payne
5-88-1010-2020-3030-4040-5050-6060-7070-800.080.100.120.140.160.180.20
[Fe/H]
LASP-Payne
LASSO-MLPNet-Payne
Figure 1. Parameter estimation situations of LAMOST low-resolution spectra: the dependencies of the MAE error of the estimations
from LASP (Luo et al. 2015) and LASSO MLPNet (Li et al. 2022b) on the SNR. MAE: mean absolute of error. : standard deviation of
error. LASP: LAMOST Stellar Parameter Pipeline.
tral information to the stellar parameters to be estimated.
Therefore,thereferencesetisaknowledgecarrierforthestel-
lar parameter estimation problem, consists of the observed
spectraandtheirstellaratmosphericphysicalparametersand
elemental abundances. The observed spectra in the reference
setareobtainedfromtheLAMOSTDR8low-resolutionspec-
tral library. The stellar atmospheric parameters and elemen-
tal abundances of the observed spectra are obtained from the
APOGEE DR17 catalog. The spectral parameters estimated
in this work include the eÔ¨Äective temperature Teff, surface
gravity logg, and 14 elemental abundances [X/H] (X refers
to C, N, O, Mg, Al, Si, S, K, Ca, Ti, Cr, Mn, Fe, Ni).
2.1 APOGEE and APOGEE DR17 catalog
LAMOST spectra have a low resolution, and the SNR of a
large fraction of them is below 30. These characteristics re-
sult in a considerable improvement space for the estimation
precision of the LASP estimation from LAMOST spectra.
Moreover, LASP does not give abundance estimates for ele-
ments other than [Fe/H]. One possible solution is to transfer
parameter information from other high-resolution and high-
quality survey spectral libraries to the LAMOST spectral li-
brary based on the spectra from common sources.
The Apache Point Observatory Galactic Evolution Exper-
iment (APOGEE) (Prieto et al. 2010) is a high-resolution in-
frared sky survey based on the Sloan telescope, with a band
coverage from 1:51mto1:70m. ASPCAP (The APOGEE
Stellar Parameter and Chemical Abundances Pipeline) gives
estimates of Teff,logg, and chemical elemental abundances
for APOGEE spectra. APOGEE DR17 catalog published the
atmospheric parameters ( Teff,logg, [Fe/H]) and elemen-
tal abundances for 475,144 stars. The ranges of the stellar
atmospheric parameters in the APOGEE DR17 catalog are
[3500;7000]K forTeff,[ 0:5;5]dex for logg, and [ 2:0;0:5]
dex for [Fe/H].
Therefore, this paper builds a reference dataset by cross-
matching the APOGEE DR17 catalog and the LAMOSTDR8 low-resolution spectral library. Each sample in this
dataset consists of one LAMOST low-resolution spectrum
and the estimations from the common source observation in
APOGEE DR17. The Ô¨Ånal reference set consists of 240;448
observed spectra and their corresponding stellar parameters.
The spectral parameters explored in this paper include the
stellar atmospheric physical parameters Teff,log g, [Fe/H],
and13elemental abundances [X/H], where X refers to C, N,
O, Mg, Al, Si, S, K, Ca, Ti, Cr, Mn, and Ni.
It is shown that there is a diÔ¨Äerence in the eÔ¨Äective fea-
tures of parameter estimation between low S/N spectra and
high S/N spectra. To increase the parameter estimation per-
formance by detecting the spectral features adaptive to the
spectral quality, therefore, the reference set are further di-
vided into two subsets SlS=NandShS=Nbased on the signal-
to-noise ratio criterion 5S=N g50andS=N g>50. The
sample sizes of these two reference subsets are 96;200and
144;248, respectively. For the reference set SlS=N, we ran-
domly divide it into a training set SlS=N
tr, a validation set
SlS=N
valand a test set SlS=N
tein the ratio of 7:1:2. The sam-
ple sizes of SlS=N
tr,SlS=N
valandSlS=N
teare67;340,9;620, and
19;240, respectively. These three reference sets were used re-
spectively for training, hyperparameter selection, and perfor-
mance evaluation for the parameter estimation model used
on the spectra with low S=N g. Similarly, we randomly divide
the reference set ShS=Ninto three subsets ShS=N
tr,ShS=N
valand
ShS=N
te, which are used for training, hyperparameter selec-
tion and performance evaluation for the parameter estima-
tion model used on the spectra with high S=N g. The sample
numbers of ShS=N
tr,ShS=N
valandShS=N
teare100;973,14;425
and28;850, respectively.
2.2 Data preprocessing
The observed spectra are negatively aÔ¨Äected by many fac-
tors, such as redshift, noise, and skylight. These factors can
decrease the precision and stability of parameter estimation,
MNRAS 000, 1‚Äì14 (2023)4Li et al.
and the demand for more reference data (Xiong et al. 2022).
Therefore, the stellar spectral data must be preprocessed be-
fore input into the parameter estimation model. The speciÔ¨Åc
preprocessing steps are as follows.
Wavelength correction. We used radial velocity (RV)
for wavelength correction to move each spectrum to its rest
frame:
0=
1 +RV=c; (1)
where0,,candRVrespectivelydenotethecorrectedwave-
length, the original wavelength, the speed of light, and the
radialvelocity.Inthispaper,thewavelengthcorrectionisper-
formedusingtheradialvelocityestimatesgivenbytheoÔ¨Écial
LAMOST stellar parameter estimation pipeline (LASP).
Linear interpolation resampling. We utilized the
maximum common wavelength range [3841√Ö;5699√Ö]and
[5901√Ö;8798√Ö]respectively for the blue end and red end of
all spectra. Based on the common wavelength range, we re-
sampled each spectrum using a linear interpolation method
with a resampling step size 0:0001dex in logarithmic space.
Denoising. The observed spectra are usually contami-
natedwithbadpixelsandimpulsenoise,whichcannegatively
aÔ¨Äect the mapping learning of the model. Therefore, the ob-
served spectra need to be denoised. To this end, we used the
medianÔ¨Ålteringmethodtoreducethespectralnoise. Thesize
of the Ô¨Åltering window is 3 pixels.
Continuum normalization. Since the spectrophotomet-
ric correction applied to these spectra is only an approxi-
mation, the observed Ô¨Çuxes at diÔ¨Äerent wavelengths are not
accurate in an absolute sense. Therefore, continuum normal-
ization (Fiorentin et al. 2007; Wang et al. 2020; Li et al.
2022b) is required prior to parameter estimation. The basic
step of continuum normalization is to estimate the contin-
uum of every spectrum by curve Ô¨Åtting Ô¨Årst. This estimated
continuum is referred to as a pseudo-continuum. Then, each
pixelofaspectrumisdividedbytheÔ¨Çuxofthecorresponding
pseudo-continuum.Thepseudo-continuumisanestimationof
the trend in the dependencies of the spectral Ô¨Çuxes on wave-
length(Figure2b).Thecontinuumisgenerallyestimatedbya
polynomial Ô¨Åtting method (Fiorentin et al. 2007; Wang et al.
2020; Li et al. 2022b). In this paper, the pseudo-continuums
are estimated separately for the blue-end and red-end spectra
using a 5th-order polynomial Ô¨Åtting.
Secondary denoising and spectrum-wise-
normalization. After continuum normalization, there
exist negative eÔ¨Äects from some aberrant variation range
on Ô¨Çuxes between various spectra, and some interferences
from non-impulse noises. The presence of non-impulse noise
reduces the sensitivity of the algorithm to weak spectral
features. Therefore, each continuum-normalized spectrum
x= (x1;;xD)Tis further processed as follows: in case of
a Ô¨Çux is smaller than  3or larger than + 3, this Ô¨Çux
is replaced by ; and each spectral Ô¨Çux xiis transformed as
follows:
zi=xi 
;i= 1;;D; (2)
where=DP
i=1xi=Dand
=vuutDX
i=1(xi )2=D:Table 1. The BGANet network. In step 1), there is a model pa-
rametert, which indicates the numbers of wavelength subbands;
in step 2), there are parameters nandl1;;ln, which indicate
the numbers of Bi-GRU layers and the feature dimension of each
Bi-GRU learning layer, respectively.
Steps Calculations
Input Pre-processed spectra
1)Dividing each spectrum into tsubbands
with equal wavelength width.
2) A series of Bi-GRU learning layers
3) A Self-Attention learning layer
4) A fully connected learning layer
Output An estimated spectral parameter
Figure 2 shows a spectrum and its preprocessing results. It
is shown that the spectral features are signiÔ¨Åcantly enhanced
after pre-processing.
3 STELLAR SPECTRAL PARAMETER
ESTIMATION METHOD STARGRUNET AND
ITS EVALUATIONS
3.1 StarGRUNet
The proposed stellar spectral parameter estimation scheme
is an artiÔ¨Åcial neural network (NN). The NN is a hierarchi-
cally organized computational model. More about NN can
be found in (Goodfellow et al. 2016; Li et al. 2022b). The
proposed NN is presented in Table 1. Compared with the
previous work (Li et al. 2022b), the BGANet model is fur-
ther equipped with some Bi-GRU learning layers and a self-
attention learning layer. The Bi-GRU learning is to exploit
the correlation information between various wavelength sub-
bands, and the Self-Attention learning module is to discover
parameter-sensitive features of diÔ¨Äerent types of spectra au-
tomatically. For more information about Bi-GRU and Self-
Attention learning, please refer to Niu et al. (2021).
Due to the inÔ¨Çuence of random factors in model initial-
ization and the learning process, the generalization ability of
individual BGANet generally can be improved further. One
solution is to employ an ensemble learning strategy to com-
bine the learning results of several BGANet models. The fun-
damental idea of ensemble learning is to improve prediction
performance by training multiple BGANet learners and ex-
ploiting their complementary capabilities. The typical meth-
ods for combining the regression prediction results of several
learners are simple average, weighted average, and learning
techniques.
Thedistinctivecharacteristicsofthestellarspectralparam-
eter estimation problem studied in this paper are the large
size of the reference dataset and the large amount of model
parameters. These characteristics require that the ensemble
learning strategy should be easy to be implemented, eÔ¨Écient,
and stable. Therefore, we adopted the Blending learning
strategy‚Äìa simpliÔ¨Åed version of the Stacking learning method
(Wolpert 1992) and formed the StarGRUNet method, whose
principle can be found in Figure 3.
MNRAS 000, 1‚Äì14 (2023)5
3700 4600 5500 6400 7300 8200 9099
Wavelength(√Ö)0200400600800Flux
(a) A LAMOST spectrum.
3841 4151 4461 4771 5081 5391 5699
Wavelength_blue(√Ö)100300500700Flux
5901 6384 6867 7350 7833 8316 8798
Wavelength_red(√Ö)100300500700
(b) The blue-end spectrum and the red-end spectrum after wavelength correction, linear interpolation resam-
pling, and denoising. The dashed line indicates the estimated continuum.
3841 4151 4461 4771 5081 5391 5699
Wavelength_blue(√Ö)0.51.01.52.0Flux
5901 6384 6867 7350 7833 8316 8798
Wavelength_red(√Ö)0.51.01.52.0
(c) The blue-end spectrum and the red-end spectrum after continuum normalization.
3841 4151 4461 4771 5081 5391 5699
Wavelength_blue(√Ö)3
2
1
0123Flux
5901 6384 6867 7350 7833 8316 8798
Wavelength_red(√Ö)3
2
1
0123
(d) The blue-end spectrum and the red-end spectrum after secondary denoising and spectrum-wise normaliza-
tion.
Figure 2. A LAMOST DR8 low-resolution spectrum (spec-55863-M31_011N40_B1_sp08-198) and its pre-processing results. The hori-
zontal and vertical coordinates characterize the wavelength and Ô¨Çux, respectively.
Taking the estimation of parameter Teffas an example,
the training steps of StarGRUNet are as follows. Suppose
Sval=f(xi;yi);i= 1;;sgis a validation set. First, for
eachspectrum xi2Sval,weestimatedits Teffusingntrained
BGANet models and computed a vector zi= (z1
i;;zn
i)T.
Second, treat S`val=f(zi;yi);i= 1;;sgas a training set
to learn the secondary learner using a multiple linear regres-
sor. The secondary learner is to fuse the estimations from
nBGANet models. The models for estimating other stellar
parameters can be trained similarly.3.2 Model Selection and Model Training
Model hyperparameters can signiÔ¨Åcantly aÔ¨Äect predictive
performance. There are two sets of hyperparameters in the
BGANet model. The Ô¨Årst set of hyperparameters consists
of the number of wavelength subbands tand the number of
Bi-GRU layers n. In the Bi-GRU module, we index the sub-
bands with i= 1;2;3;:::;tfrom left to right. In case of a
smallt, there is less communication between diÔ¨Äerent wave-
length subbands, and it is necessary to take a smaller value
fornto reduce the risk of overÔ¨Åtting. In case of a big t, more
MNRAS 000, 1‚Äì14 (2023)6Li et al.
Table 2. The proposed conÔ¨Åguration for the hyperparameters of
three BGANets in the proposed StarGRUNet.
Model n tl1 l2l3
BGANet1 2 5 64 32 ...
BGANet2 3 10 128 64 32
BGANet3 3 15 128 64 32
Figure 3. The principles of the proposed StarGRUNet.
communication and more complex interdependencies are in-
vestigated between various wavelength subbands. Therefore,
larger values of nare needed to enhance the model complex-
ity by exploiting more complex cross-band correlations and
complementarities. Besides, the choice of tandnis theoret-
ically related to the size of the training set. The larger the
parameters tandn, the higher the model complexity and the
more training data are needed for model learning. This work
suggests several conÔ¨Ågurations of 2or3fornand5,10, or
15fortbased on experimental experiences (Table 2).
The second set of hyperparameters is the dimensions
flj;j= 1;;ngof the features extracted from various Bi-
GRU layers, where jis the index of a Bi-GRU layer. A neg-
ative correlation should be maintained between ljandj. A
smalljindicatesthatthecorrespondingBi-GRUlayerisclose
to the input end of the BGANet, and a large ljshould be
set in this case to eÔ¨Äectively extract the spectral features as
possible. Similarly, a large jindexes indicates that the cor-
responding Bi-GRU layer is close to the output end of the
BGANet, and a small ljshould be set to reduce noises, re-
dundancies, and the risk of overÔ¨Åtting in mapping learning.
In addition, the parameters flj;j= 1;;ngalso determine
the complexity of the BGANet model. A BGANet with a
smallljhas relatively few model parameters and a low model
complexity; on the contrary, the BGANet with more model
parameters is more complex.
Based on the above-mentioned principles and some exper-
imental experiences, we selected three BGANet models with
excellent prediction results on the validation set (Table 2).
We took these models as primary learners for StarGRUNet.
To estimate each spectral parameter, we built a StarGRUNet
model respectively for the spectra with low SNR and high
SNR.
Figure 4. Comparison between the StarBRUNet predictions and
APOGEE DR17 catalog on the test set. The left subplot shows
the results from the APOGEE DR17 catalog, and the right subplot
shows the estimated results from StarGRUNet. The colors indicate
the [Fe/H] abundances. The solid line, the dashed line, and the
dottedlinerespectivelyindicatethreeMISTstellarisochroneswith
stellar ages of 7 Gyr.
3.3 Model Evaluation
In this subsection, we evaluated the performance of Star-
GRUNetonthetestset.Theevaluationsareconductedbased
on the following metrics: - the mean of the diÔ¨Äerence be-
tween StarGRUNet predictions and the APOGEE DR17 cat-
alog,- the standard deviation of the diÔ¨Äerence, and MAE
- the mean of the absolute of diÔ¨Äerence. Among them, in-
dicates the deviation or inconsistency between the prediction
result and the reference. measures the degree of dispersion
or instability of the consistency between the prediction re-
sults and the reference. And MAE is a cumulative measure
of the diÔ¨Äerence on all test samples and describes the overall
inconsistency.
To evaluate the performance of StarGRUNet, we compared
its estimation results with the APOGEE DR17 catalog in
Teff loggspace (Figure 4). For easy comparison, three
MIST stellar isochrones with stellar ages of 7Gyr were pre-
sentedinthisÔ¨Ågure.ItisshownthattheStarGRUNetpredic-
tions not only reconstruct APOGEE DR17‚Äôs Teffandlogg
nicely but also match the MIST stellar isochrones well. These
phenomena indicate a strong consistency between the pre-
dictions of stellar atmospheric parameters from StarGRUNet
and the APOGEE DR17 catalog.
The prediction performance of StarGRUNet can also be
measured by the dependence of the diÔ¨Äerence between its
predictions and APOGEE DR17 catalog on the signal-to-
noise ratio (Figure 5). The experiments in Figure 5 inves-
tigate the dependence of the prediction error of StarGRUNet
on the signal-to-noise ratio for the abundance of 13elements.
The results show that the increase of S=N gcan eÔ¨Äectively
reduce the MAE and of StarGRUNet prediction, but is
almostalwaysstableat0.Thesephenomenaindicatethatim-
proving data quality can eÔ¨Äectively reduce the error of Star-
GRUNet without aÔ¨Äecting the overall consistency between
StarGRUNet and APOGEE DR17 catalog. Therefore, the
prediction results of StarGRUNet are very robust. In con-
clusion, the results of Figure 4 and 5 demonstrate the ex-
cellent prediction performance of StarGRUNet for all stellar
parameters.
Finally, we compared the prediction results of Star-
GRUNet, StarNet, and ResNet (He et al. 2016). StarNet
MNRAS 000, 1‚Äì14 (2023)7
58102030405080100
S/Ng050100150200250
Teff
58102030405080100
S/Ng0.00.10.20.30.40.5
logg
58102030405080100
S/Ng0.0000.0250.0500.0750.1000.1250.1500.175
[Fe/H]
58102030405080100
S/Ng0.000.050.100.150.20
[C/H]
58102030405080100
S/Ng0.000.050.100.150.200.25
[N/H]
58102030405080100
S/Ng0.0000.0250.0500.0750.1000.1250.1500.175
[O/H]
58102030405080100
S/Ng0.0000.0250.0500.0750.1000.1250.150
[Mg/H]
58102030405080100
S/Ng0.0000.0250.0500.0750.1000.1250.1500.175
[Al/H]
58102030405080100
S/Ng0.0000.0250.0500.0750.1000.1250.150
[Si/H]
58102030405080100
S/Ng0.0000.0250.0500.0750.1000.1250.1500.175
[S/H]
58102030405080100
S/Ng0.000.050.100.150.20
[K/H]
58102030405080100
S/Ng0.0000.0250.0500.0750.1000.1250.150
[Ca/H]
58102030405080100
S/Ng0.000.050.100.150.20
[Ti/H]
58102030405080100
S/Ng0.000.050.100.150.200.25
[Cr/H]
58102030405080100
S/Ng0.000.050.100.150.20
[Mn/H]
58102030405080100
S/Ng0.0000.0250.0500.0750.1000.1250.150
[Ni/H]
Figure 5. The dependence of the consistency between the StarGRUNet predictions and APOGEE DR17 catalog on the spectral signal-
to-noise ratio.N,andrepresent, MAE and of the prediction uncertainty.
consists of several convolutional layers and several fully con-
nected layers. Therefore, it is a typical convolutional neural
networkforstellarspectralparameterestimation.ResNetcan
mine the deep, longitudinal features of the spectrum. This is
a sharp contrast to the cross-wavelength subbands feature
extraction capability of StarGRUNet. Therefore, it helps us
observe the advantages of cross-wavelength subband infor-
mation extraction and fusion to compare these two methods
with StarGRUNet. Table 3 presents the experimental results
of these three models. To fairly compare the experimental re-
sults of them, the three methods share the training set, vali-
dation set, and test set. The experimental results in Table 3
indicate that StarGRUNet has an undeniable advantage. As
for StarNet, its performance is much inferior to StarGRUNet.
This is because the network structure of StarNet is relatively
simple. Therefore, it is diÔ¨Écult to achieve better performance
of parameter estimation on LAMOST low-resolution spec-
tra. As for ResNet, although it can longitudinally exploit the
weak features of the spectrum, it fails to extract the cross-
band information horizontally, and the result of the failure
is the ResNet‚Äôs insuÔ¨Éciency on resistance to noise. In con-
trast, the prediction results of StarGRUNet are more accu-
rate and robust. These results are not only due to the extrac-
tion and fusion of various cross-band feature information by
the BGANet model but also due to the advantageous integra-
tionofthemappingresultsundermultiplefeatureexpressions
by StarGRUNet.3.4 Model Uncertainty
Model uncertainty analysis is another way to test the predic-
tion performance of StarGRUNet. Gal & Ghahramani (2016)
demonstrated that a neural network with a Dropout mecha-
nismisanapproximationtoaBayesianneuralnetworkwitha
Gaussian distribution and can be employed to estimate pre-
diction uncertainty. Leung & Bovy (2018) introduced this
idea into a stellar spectral parameters estimation model, As-
troNN, to estimate the uncertainty. Since BGANet comes
with a Dropout mechanism in each of the hidden feature vec-
tors, it supports our assessment of the model uncertainty. We
repeatedly estimated each spectral parameter for Ô¨Åve times
from each stellar spectrum, and computed the standard devi-
ation of the Ô¨Åve prediction as the model uncertainty of Star-
GRUNet.
Figures 6 and 7 present the dependence of StarGRUNet
uncertainty on Teffand [Fe/H], respectively. It is shown
that the parameter estimation uncertainty of StarGRUNet
on the spectra of metal-poor star ([Fe/H]<-1.00dex), cold
star (Teff<4000K) and hot star ( Teff>6000K) is generally
greater than that on other types of spectra. These trends are
in general consistent with Leung & Bovy (2018). The reason
for this phenomenon is the small number and weak spectral
features of metal-poor, cool, and hot stars. These character-
istics reduce the performance of the learned model on spectra
of these stars. Therefore, we recommend using the results in
these above-mentioned ranges with caution.
MNRAS 000, 1‚Äì14 (2023)8Li et al.
Table 3. Comparisons: StarGRUNet, StarNet, and ResNet.
Model StarGRUNet StarNet ResNet
Error   MAE  MAE   MAE
Teff(K) 0.935 93.77 49.28 -33.41 518.66 416.97 -16.80 150.04 87.69
logg(dex) 0.000 0.162 0.084 -0.014 0.984 0.877 0.023 0.250 0.146
[Fe/H](dex) 0.001 0.070 0.041 -0.003 0.294 0.224 -0.008 0.098 0.058
[C/H](dex) 0.001 0.090 0.055 -0.002 0.312 0.218 0.003 0.115 0.070
[N/H](dex) 0.000 0.182 0.109 -0.002 0.375 0.286 0.008 0.200 0.122
[O/H](dex) 0.000 0.104 0.068 -0.002 0.239 0.176 -0.002 0.116 0.075
[Mg/H](dex) 0.001 0.073 0.045 -0.001 0.246 0.178 -0.004 0.094 0.059
[Al/H](dex) 0.001 0.089 0.052 -0.002 0.311 0.213 0.009 0.131 0.079
[Si/H](dex) 0.001 0.074 0.045 -0.002 0.258 0.192 -0.004 0.095 0.059
[S/H](dex) 0.002 0.121 0.080 -0.001 0.236 0.174 0.005 0.139 0.088
[K/H](dex) 0.002 0.141 0.082 0.000 0.276 0.194 -0.031 0.236 0.115
[Ca/H](dex) 0.000 0.081 0.050 -0.002 0.255 0.191 0.003 0.094 0.058
[Ti/H](dex) 0.002 0.161 0.101 -0.001 0.329 0.246 0.028 0.226 0.125
[Cr/H](dex) 0.003 0.215 0.126 -0.002 0.384 0.281 0.013 0.226 0.134
[Mn/H](dex) 0.001 0.101 0.060 -0.003 0.372 0.280 -0.006 0.126 0.077
[Ni/H](dex) 0.000 0.082 0.050 0.000 0.326 0.241 0.002 0.108 0.064
4 APPLICATIONS ON LAMOST DR8
LOW-RESOLUTION SPECTRA AND
VALIDATIONS ON OTHER SURVEYS
4.1 Applications on LAMOST DR8 Low-resolution
Spectra
InSection3,weperformedacomprehensiveevaluationonthe
performance of StarGRUNet and a series of experimental re-
sults indicate its eÔ¨Äectiveness and robustness. Therefore, we
utilized the trained StarGRUNet models to estimate the stel-
lar parameters Teffandlogg,14chemical elemental abun-
dances, and 1uncertainties for about 8.21 million LAMOST
low-resolution spectra with S=N g5, and generated the
StarGRUNet-LAMOST catalog. In subsections 4.2, 4.3 and
4.4, we evaluated the reliability of StarGRUNet-LAMOST
catalog.
4.2 Consistencies with GALAH Survey
It is an eÔ¨Äective way to verify the reliability of the computed
StarGRUNet-LAMOST catalog to investigate its consis-
tency one one high-resolution catalog. GALAH DR3 (Buder
et al. 2021) provides reliable stellar parameters and elemen-
tal abundances for 588,571 stars, including 383,088 dwarfs,
200,927 giant stars, and 4,556 unclassiÔ¨Åed stars. We cross-
matched the GALAH DR3 catalog with the StarGRUNet-
LAMOST catalog and obtained 27,527 common sources.
Based on these common sources, we computed the consis-
tency between the StarGRUNet-LAMOST catalog and the
GALAH DR3 catalog (Figure 8). It is shown that there exists
a high consistency between the StarGRUNet-LAMOST cat-alog and the GALAH DR3 catalog. The systematic biases on
Teff,loggand [Fe/H] are 44:48K,0:004dex, and 0:037dex,
respectively. The corresponding dispersions are 224:26K,
0:222dex, and 0:149dex, respectively. The corresponding
MAEs are 109:39K,0:128dex, and 0:095dex, respectively.
The biases, the deviations, and the MAEs of other elemen-
tal abundances are also similarly small. These experimental
results show excellent consistency between the StarGRUNet-
LAMOSTcatalogandtheGALAHDR3catalog,andindicate
the reliability of the StarGRUNet-LAMOST catalog.
Figure9andFigure10showthedistributionofDwarfstars
and Giant stars in [X/Fe]-[Fe/H] space, respectively. [X/Fe]
represents the abundance of element X relative to Fe, and
is computed as [X/Fe] = [X/H] - [Fe/H]. In general, the el-
emental abundances of the StarGRUNet-LAMOST catalog
are relatively tight, and most of the StarGRUNet-LAMOST
elemental abundances are consistent with the GALAH DR3
catalog. However, there are still some evident diÔ¨Äerences be-
tween the StarGRUNet-LAMOST catalog and the GALAH
DR3catalogonsomeelementalabundances,suchas[Ti/H]of
the Dwarfs. Such diÔ¨Äerences may be due to the severe lack of
metal lines of these elements in the low-resolution, blue-end
spectra of LAMOST. Therefore, the precision of the Ti abun-
dance of Dwarfs in the StarGRUNet-LAMOST catalog may
be inferior to that in the GALAH DR3 catalog and should
be used with caution.
MNRAS 000, 1‚Äì14 (2023)9
3500 4000 4500 5000 5500 6000 65000.000.020.040.06logg
3500 4000 4500 5000 5500 6000 65000.0000.0050.0100.0150.0200.025 [Fe/H]
3500 4000 4500 5000 5500 6000 65000.000.010.020.03 [C/H]
3500 4000 4500 5000 5500 6000 65000.000.010.020.030.040.05 [N/H]
3500 4000 4500 5000 5500 6000 65000.0000.0050.0100.0150.0200.025 [O/H]
3500 4000 4500 5000 5500 6000 65000.0000.0050.0100.0150.0200.025 [Mg/H]
3500 4000 4500 5000 5500 6000 65000.000.010.020.03 [Al/H]
3500 4000 4500 5000 5500 6000 65000.0000.0050.0100.0150.0200.025 [Si/H]
3500 4000 4500 5000 5500 6000 65000.0000.0050.0100.0150.0200.025 [S/H]
3500 4000 4500 5000 5500 6000 65000.000.010.020.030.04 [K/H]
3500 4000 4500 5000 5500 6000 65000.000.010.02 [Ca/H]
3500 4000 4500 5000 5500 6000 65000.000.010.020.03 [Ti/H]
3500 4000 4500 5000 5500 6000 65000.000.010.020.03 [Cr/H]
3500 4000 4500 5000 5500 6000 65000.000.010.020.03 [Mn/H]
3500 4000 4500 5000 5500 6000 6500
Teff(K)0.0000.0050.0100.0150.0200.025 [Ni/H]
Figure 6. The dependencies of StarGRUNet prediction uncertainty on Teff. The dependencies are presented using box plots. The black
dots inside the box represent the mean of prediction uncertainties. The dashed line inside the box represents the second quartile of the
prediction uncertainty Q2(namely the median). The lower bottom of the box represents the Ô¨Årst quartile Q1. The upper bottom of the
box represents the third quartile Q3. The diÔ¨Äerence between Q3andQ1is calledIQR(interquartile range): IQR =Q3 Q1. The lines
above and below the box are called the upper and lower limits, corresponding to the values Q3+ 1:5IQRandQ1 1:5IQR, respectively.
The height of the box and the distance between the upper limit and the lower limit can reÔ¨Çect the degree of uncertainty dispersion to
some extent.
4.3 Comparisons with Other Catalogs based on
LAMOST Low-resolution Spectra
To evaluate the eÔ¨Äectiveness of the StarGRUNet-LAMOST
catalog, this work compared it with three catalogs based on
LAMOST low-resolution spectra. The three catalogs are the
LASP catalog (Luo et al. 2015), the GSN catalog (Rui et al.
2019b), and the LASSO-MLPNet catalog (Li et al. 2022b).
The LASP catalog is computed by the LAMOST oÔ¨Écial
pipeline and consists of the estimations of the stellar atmo-
spheric parameters Teff,logg, and [Fe/H]. The GSN catalog
is a set of the estimates of the stellar atmospheric parameters
Teff,logg, [Fe/H], and [ /Fe]. The LASSO-MLPNet catalog
consists of the estimates of the stellar atmospheric parame-
tersTeff,logg, and [Fe/H] from 4;828;190LAMOST DR8
low-resolution stellar spectra with 5S=N g80and3500KTeff6500K. Since these catalogs are computed from
LAMOST low-resolution spectra, they are very comparable
with the StarGRUNet-LAMOST catalog.
In the experiment of Figure 11, we compared the
StarGRUNet-LAMOST catalog with the LASP catalog, the
GSN catalog (Rui et al. 2019b), and the LASSO-MLPNet
catalog (Li et al. 2022b) using the mean of the error, the
standard deviation of the error, and MAE of the prediction
error. It is shown that for each stellar atmosphere parame-
ter, the estimation performance measures jj,, and MAE of
StarGRUNet are evidently lower than those of LASP, GSN,
and LASSO-MLPNet on the whole. These results indicate
that the error between the StarGRUNet-LAMOST catalog
and the APOGEE DR17 catalog is smaller than that of other
catalogs. Therefore, the StarGRUNet-LAMOST catalog can
MNRAS 000, 1‚Äì14 (2023)10 Li et al.
-1.50 -1.25 -1.00 -0.75 -0.5 0 0.25 0.50102030Teff
-1.50 -1.25 -1.00 -0.75 -0.5 0 0.25 0.50.000.020.040.060.08logg
-1.50 -1.25 -1.00 -0.75 -0.5 0 0.25 0.50.000.020.040.06 [C/H]
-1.50 -1.25 -1.00 -0.75 -0.5 0 0.25 0.50.000.020.040.06 [N/H]
-1.50 -1.25 -1.00 -0.75 -0.5 0 0.25 0.50.000.010.020.030.040.05 [O/H]
-1.50 -1.25 -1.00 -0.75 -0.5 0 0.25 0.50.000.010.020.030.040.05 [Mg/H]
-1.50 -1.25 -1.00 -0.75 -0.5 0 0.25 0.50.000.020.040.06 [Al/H]
-1.50 -1.25 -1.00 -0.75 -0.5 0 0.25 0.50.000.010.020.030.04 [Si/H]
-1.50 -1.25 -1.00 -0.75 -0.5 0 0.25 0.50.000.020.04 [S/H]
-1.50 -1.25 -1.00 -0.75 -0.5 0 0.25 0.50.000.020.040.06 [K/H]
-1.50 -1.25 -1.00 -0.75 -0.5 0 0.25 0.50.000.010.020.030.040.05 [Ca/H]
-1.50 -1.25 -1.00 -0.75 -0.5 0 0.25 0.50.000.020.040.06 [Ti/H]
-1.50 -1.25 -1.00 -0.75 -0.5 0 0.25 0.50.000.020.040.06 [Cr/H]
-1.50 -1.25 -1.00 -0.75 -0.5 0 0.25 0.50.000.020.040.06 [Mn/H]
-1.50 -1.25 -1.00 -0.75 -0.5 0 0.25 0.5
[Fe/H](dex)0.000.020.040.06 [Ni/H]
Figure 7. The dependencies of StarGRUNet prediction uncertainty on [Fe/H]. The dependencies are presented using box plots. The black
dots inside the box represent the mean of prediction uncertainties. The dashed line inside the box represents the second quartile of the
prediction uncertainty Q2(namely the median). The lower bottom of the box represents the Ô¨Årst quartile Q1. The upper bottom of the
box represents the third quartile Q3. The diÔ¨Äerence between Q3andQ1is calledIQR(interquartile range): IQR =Q3 Q1. The lines
above and below the box are called the upper and lower limits, corresponding to the values Q3+ 1:5IQRandQ1 1:5IQR, respectively.
The height of the box and the distance between the upper limit and the lower limit can reÔ¨Çect the degree of uncertainty dispersion to
some extent.
more accurately recover the stellar atmospheric parameters
from LAMOST low-resolution spectra.
4.4 Uncertainty Analysis Based on Repeated
Observation: Observation Uncertainty
We explored the model uncertainty of StarGRUNet based on
the dropout technique in subsection 3.4. In addition, LAM-
OST produced some repeated observations by carrying out
multiple observations on some stars at various times and un-
der diÔ¨Äerent conditions. The parameters of this kind spectra
from a common source can be assumed to be constant over
the time span in which we carry out the observations. There-
fore, such repeated observations provide us with an alterna-
tive option for analyzing the uncertainty of the StarGRUNet-
LAMOSTcatalog.Forconvenience,wenamethisuncertainty
as observation uncertainty. Suppose the number of repeated
observations of a star is nobs, and the corresponding repeated
spectraare{ x1;x2;:::;x nobs}.Thus,foranyonestellarparam-
eter, StarGRUNet computed nobsestimates. The observationuncertainty is measured using the standard deviation of these
nobsestimates in this work. To ensure the reliability of the es-
timated uncertainty, we only keep the target stars with more
than six repeated observations ( 26;459in total).
Figure 12 demonstrates the dependence of the observation
uncertainty on the signal-to-noise ratio. Overall, the observa-
tionuncertaintyofStarGRUNet-LAMOSTcatalogislowand
has a clear decreasing trend with the increasing of spectrum
quality. In the case of S=N g2[5;10), the uncertainties of Teff
andloggestimations are 182K and 0:34dex, respectively,
andtheuncertaintyofelementalabundanceestimationis 0:07
dex-0:17dex. In the case of S=N g150, the uncertainty of
Teffandloggestimates drop to 139K and 0:29dex, respec-
tively,andtheuncertaintyofelementalabundanceestimation
drop to 0:06dex to 0:15dex. These phenomena indicate that
the results of the StarGRUNet-LAMOST catalog are very
robust.
MNRAS 000, 1‚Äì14 (2023)11
Figure 8. Consistency between StarGRUNet-LAMOST catalog and GALAH DR3 catalog. In each subplot, the horizontal axis indicates
the results provided by GALAH DR3 catalog, and the vertical axis indicates the diÔ¨Äerence between the StarGRUNet-LAMOST catalog
and the GALAH DR3 catalog. The dashed line corresponds to = 0, indicating the theoretical consistency. The lower left corner labels
the bias and dispersion. The color characterizes the density of the samples.
5 CONCLUSION
In this paper, a novel spectral parameter estimation neu-
ral network, BGANet, is designed based on Bi-GRU and
Self-Attention mechanism. The parameter estimation perfor-
mance is further improved by introducing an ensemble learn-
ing method StarGRUNet based on the BGANet. The com-
petitiveness of the proposed method was evaluated by com-
paring it with the typical methods RNN, GRU, Bi-GRU, and
StarNet.
By cross-matching the LAMOST DR8 low-resolution spec-
tral library with the APOGEE DR17 catalog, we established
a training set, a validation set, and a test set. These datasets
are released for algorithm research, and used for learning and
testing the proposed scheme. On the spectra with S=N g5,
the precisions of StarGRUNet for Teffandloggare94K
and0:16dex, respectively. The precisions of elemental abun-
dances [X/H] are 0:07dex0:16dex (except 0:18dex for
[N/H] and 0:22dex for [Cr/H]). The test results show that
StarGRUNet has higher accuracy and robustness compared
with other catalog and neural networks on the whole.
To facilitate the use in astronomical science researches, this
paper applied the trained StarGRUNet model to 8;208;332
LAMOST-DR8 low-resolution spectra, computed the estima-
tions forTeff, logg, and 14 elements ([C/H], [Mg/H], [Al/H],
[Si/H], [Ca /H], [Fe/H], [N/H], [O/H], [S/H], [Ti/H], [Cr/H],
[Mn/H], [Ni/H], [K/H]). The estimates are also publicly re-
leased, and their URLs are available in the Acknowledgments
section.
ACKNOWLEDGEMENTS
ThisworkissupportedbytheNationalNaturalScienceFoun-
dation of China (Grant No. 11973022), the Natural ScienceFoundation of Guangdong Province (No. 2020A1515010710),
the Major projects of the joint fund of Guangdong, and the
National Natural Science Foundation (Grant No. U1811464).
The authors are deeply grateful to Yu Lu, Jinqu Zhang, and
Hui Li for their discussions in polishing this article.
LAMOST, a multi-target optical Ô¨Åber spectroscopic tele-
scope in the large sky area, is a major national engineer-
ing project built by the Chinese Academy of Sciences. Fund-
ing for the project is provided by the National Development
andReformCommission.LAMOSTisoperatedandmanaged
by the National Astronomical Observatory of the Chinese
Academy of Sciences.
DATA AND CODE AVAILABILITY
The experimental dataset, estimated catalog, experimental
code, and trained models are available at http://doi.org/
10.12149/101216 .
REFERENCES
Bu Y., Pan J., 2018, Monthly Notices of the Royal Astronomical
Society, pp 256‚Äì265
Buder S., et al., 2021, Monthly Notices of the Royal Astronomical
Society, 506, 150
Cai B., Kong X., Shi J., Gao Q., Bu Y., Yi Z., 2023, The Astro-
nomical Journal, 165, 52
De Silva G. M., et al., 2015, Monthly Notices of the Royal Astro-
nomical Society, 449, 2604
Deng L.-C., et al., 2012, Research in Astronomy and Astrophysics,
12, 735
Fabbro S., Venn K., O‚ÄôBriain T., Bialek S., Kielty C. L., Jahandar
F., Monty S., 2018, Monthly Notices of the Royal Astronomical
Society, 475
MNRAS 000, 1‚Äì14 (2023)12 Li et al.
Figure 9. Distribution of dwarfs ( logg >4) in [X/Fe]-[Fe/H] space. The two left columns are the estimation results of the GALAH
catalog, and the two right columns are the estimation results of the StarGRUNet-LAMOST catalog. The color characterizes the density
of the sample distribution.
Fiorentin P. R., Bailer-Jones C., Lee Y. S., Beers T. C., Sivarani
T., Wilhelm R., Prieto C. A., Norris J., 2007, Astronomy &
Astrophysics, 467, 1373
Gal Y., Ghahramani Z., 2016, in Balcan M. F., Weinberger
K. Q., eds, Proceedings of Machine Learning Research Vol.
48, Proceedings of The 33rd International Conference on
Machine Learning. PMLR, New York, New York, USA, pp
1050‚Äì1059, doi:10.48550/arXiv.1506.02142, https://doi.org/
10.48550/arXiv.1506.02142
Gilmore G., et al., 2012, Messenger, 147
Goodfellow I., Bengio Y., Courville A., 2016, Deep Learning. MITPress
He K., Zhang X., Ren S., Sun J., 2016, in Proceedings of the IEEE
conferenceoncomputervisionandpatternrecognition.pp770‚Äì
778, doi:10.1109/CVPR.2016.90, https://doi.org/10.1109/
CVPR.2016.90
Ho A. Y. Q., et al., 2017, The Astrophysical Journal, 836, 5
Jofr√© P., Heiter U., Soubiran C., 2019, Annual Review of Astron-
omy and Astrophysics, 57, 571
Leung H. W., Bovy J., 2018, Monthly Notices of the Royal Astro-
nomical Society, 483, 3255
Li X., Wu Q. M. J., Luo A., Zhao Y., Lu Y., Zuo F., Yang T.,
MNRAS 000, 1‚Äì14 (2023)13
Figure 10. Distribution of giants ( logg<4) in the [X/Fe]-[Fe/H] space. The two left columns are the estimation results of the GALAH
catalog, and the two right columns are the estimation results of the StarGRUNet-LAMOST catalog. The color characterizes the density
of the sample distribution.
Wang Y., 2014, The Astrophysical Journal, 790, 105
Li X., Lu Y., Comte G., Luo A., Zhao Y., Wang Y., 2015, The
Astrophysical Journal Supplement Series, 218, 3
Li X., Wang Z., Zeng S., Liao C., Du B., Kong X., Li H., 2022a,
Research in Astronomy and Astrophysics, 22, 065018
Li X., Zeng S., Wang Z., Du B., Kong X., Liao C., 2022b, Monthly
Notices of the Royal Astronomical Society, 514, 4588
LiZ.,ZhaoG.,ChenY.,LiangX.,ZhaoJ.,2022c,MonthlyNotices
of the Royal Astronomical Society, 517, 4875
Luo A.-L., et al., 2015, Research in Astronomy and Astrophysics,
15, 1095Niu Z., Zhong G., Yu H., 2021, Neurocomputing, 452, 48
Prieto C. A., Majewski S. R., Schiavon R., Cunha K., Wilson J.,
2010, Astronomische Nachrichten, 5, 428
Rui W., et al., 2019a, Publications of the Astronomical Society of
the PaciÔ¨Åc, 131, 024505
Rui W., et al., 2019b, Publications of the Astronomical Society of
the PaciÔ¨Åc, 131, 024505
Steinmetz M., et al., 2006, AJ, 132, 1645
Ting Y.-S., Rix H.-W., Conroy C., Ho A. Y. Q., Lin J., 2017, The
Astrophysical Journal Letters, 849, L9
Wang R., Luo A.-L., Chen J.-J., Hou W., Zhang S., Zhao Y.-H.,
MNRAS 000, 1‚Äì14 (2023)14 Li et al.
58102030405080100100
75
50
25
0255075
Teff
LASP-APOGEE
GSN-APOGEE
LASSO_MLPNet-APOGEE
StarGRUNet-APOGEE
581020304050801000.02
0.000.020.040.060.080.100.120.14
logg
LASP-APOGEE
GSN-APOGEE
LASSO_MLPNet-APOGEE
StarGRUNet-APOGEE
581020304050801000.03
0.02
0.01
0.000.010.020.03
[Fe/H]
LASP-APOGEE
GSN-APOGEE
LASSO_MLPNet-APOGEE
StarGRUNet-APOGEE
581020304050801005075100125150175200225250
 LASP-APOGEE
GSN-APOGEE
LASSO_MLPNet-APOGEE
StarGRUNet-APOGEE
581020304050801000.10.20.30.40.5
LASP-APOGEE
GSN-APOGEE
LASSO_MLPNet-APOGEE
StarGRUNet-APOGEE
581020304050801000.0500.0750.1000.1250.1500.1750.2000.225
LASP-APOGEE
GSN-APOGEE)
LASSO_MLPNet-APOGEE
StarGRUNet-APOGEE
58102030405080100
S/Ng406080100120140160180MAE
LASP-APOGEE
GSN-APOGEE
LASSO_MLPNet-APOGEE
StarGRUNet-APOGEE
58102030405080100
S/Ng0.050.100.150.200.250.300.350.40
LASP-APOGEE
GSN-APOGEE
LASSO_MLPNet-APOGEE
StarGRUNet-APOGEE
58102030405080100
S/Ng0.020.040.060.080.100.120.14
LASP-APOGEE
GSN-APOGEE
LASSO_MLPNet-APOGEE
StarGRUNet-APOGEE
Figure 11. Dependencies of the prediction errors on the spectral signal-to-noise ratio for the StarGRUNet-LAMOST catalog, the LASP
catalog(Luoetal.2015),theGSNcatalog(Ruietal.2019b),andtheLASSO-MLPNetcatalog(Lietal.2022b).Thehorizontalcoordinates
represent the S=Ngintervals [5,8), [8,10), [10,20), [20,30), [30,40), [40,50), [50,80), [80,100), and [100,+ 1), respectively. The Ô¨Årst, second
and third columns represent Teff,loggand [Fe/H], respectively. The Ô¨Årst, second, and third rows respectively represent the mean , the
standard deviation , and the mean of the absolute error MAE of the diÔ¨Äerence between (LASP catalog, GSN catalog, LASSO MLPNet
catalog, StarGRUNet catalog) and APOGEE DR17 catalog. N,,andindicate the evaluation results for the LASP catalog, the GSN
catalog, the LASSO-MLPNet catalog, and the StarGRUNet-LAMOST catalog, respectively. It should be noted that the LASSO-MLPNet
catalog only gives estimates for spectra with 5S=Ng80. Therefore, the curves of the LASSO-MLPNet catalog disappear on the last
twoS=Ngintervals.
Li X.-R., and Y.-H. H., 2020, The Astrophysical Journal, 891,
23
Wang C., Huang Y., Yuan H., Zhang H., Xiang M., Liu X., 2022,
The Astrophysical Journal Supplement Series, 259, 51
Wolpert D. H., 1992, Neural networks, 5, 241
Wu Y., et al., 2011, Research in Astronomy and Astrophysics, 11,
924
Xiang, Maosheng et al., 2022, A&A, 662, A66
Xiang M.-S., et al., 2016, Monthly Notices of the Royal Astronom-
ical Society, 464, 3657
Xiang M., et al., 2019, The Astrophysical Journal Supplement Se-
ries, 245, 34
Xiang G., Chen J., Qiu B., Lu Y., 2021, Publications of the As-
tronomical Society of the PaciÔ¨Åc, 133, 024504
Xiong S., Li X., Liao C., 2022, ApJS, 261, 36
Yang T., Li X., 2015, Monthly Notices of the Royal Astronomical
Society, 452, 158
Yanny B., Rockosi C., Newberg H. J., Knapp G. R., Wadadekar
Y., 2009, The Astronomical Journal, 137
Zhang X., Zhao G., Yang C. Q., Wang Q. X., Zuo W. B., 2019,
Publications of the Astronomical Society of the PaciÔ¨Åc, 131,
094202
Zhang B., Liu C., Deng L.-C., 2020, The Astrophysical Journal
Supplement Series, 246, 9
Zhao G., Zhao Y.-H., Chu Y.-Q., Jing Y.-P., Deng L.-C., 2012,
Research in Astronomy and Astrophysics, 12, 723This paper has been typeset from a T EX/LATEX Ô¨Åle prepared by
the author.
MNRAS 000, 1‚Äì14 (2023)15
51030507090110130150140150160170180
510305070901101301500.300.32
510305070901101301500.1100.1110.112
510305070901101301500.1180.1200.1220.124
510305070901101301500.1100.1150.120
510305070901101301500.0660.0680.0700.0720.074
510305070901101301500.0840.0860.088Uncertainty of StarGRUNet
510305070901101301500.0900.0920.0940.096
510305070901101301500.0820.0840.0860.088
510305070901101301500.08250.08500.08750.09000.0925
510305070901101301500.0900.0920.094
510305070901101301500.0920.0940.0960.098
510305070901101301500.1000.1050.110
51030507090110130150
S/Ng0.1310.1320.133
51030507090110130150
S/Ng0.1320.1340.1360.138
51030507090110130150
S/Ng0.0800.0850.090
Teff
 logg
  [Fe/H]
 [C/H]
  [N/H]
  [O/H]
 [Mg/H]
  [Al/H]
  [Si/H]
 [S/H]
  [K/H]
  [Ca/H]
 [Ti/H]
  [Cr/H]
  [Mn/H]
 [Ni/H]
Figure 12. Observation uncertainty of StarGRUNet-LAMOST. The horizontal axis represents the signal-to-noise ratio of the spectra.
Each subplot is labeled with the name of the corresponding stellar parameter or elemental abundance in the upper right corner.
MNRAS 000, 1‚Äì14 (2023)