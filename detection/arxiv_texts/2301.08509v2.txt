Generative Logic with Time:
Beyond Logical Consistency and Statistical Possibility
Hiroyuki Kido
Cardiff University
KidoH@cardiff.ac.uk
Abstract
This paper gives a simple theory of inference to logically
reason symbolic knowledge fully from data over time. We
take a Bayesian approach to model how data causes symbolic
knowledge. Probabilistic reasoning with symbolic knowl-
edge is modelled as a process of going the causality forwards
and backwards. The forward and backward processes corre-
spond to an interpretation and inverse interpretation of for-
mal logic, respectively. The theory is applied to a localisation
problem to show a robot with broken or noisy sensors can
efﬁciently solve the problem in a fully data-driven fashion.
1 Introduction
There is growing evidence that the brain is a generative
model of environments. The image A shown in Figure 1
(Pellicano and Burr 2012) would make one perceive a white
triangle on the three black circles and one white triangle. A
well-accepted explanation of the illusion is that our brains
are trained to unconsciously use past experience to see what
is likely to happen. The image would come as just a surprise
if the sensory information eventually suppresses the predic-
tion. In contrast, many illusions including the ones in Figure
1 cause an unusual situation where the prediction keeps sup-
pressing the sensory information. Those illusions tell us the
importance of prior expectations in human perception.
Much empirical work suggests Bayesian (i.e., probabilis-
tic generative) models as an appropriate computational ap-
proach to reconcile (top-down) prediction and (bottom-up)
sensory information in perception. Knill (Knill and Richards
1996) says ‘perception as Bayesian inference’, and Ho-
hwy (Hohwy 2014) says ‘there is converging evidence that
the brain is a Bayesian mechanism’. Free-energy princi-
ple (Friston 2010) uses a variational Bayesian method to
account not only for perception but for human action. Ac-
cording to Friston (Friston 2010), Bayesian brain hypothesis
(Knill and Pouget 2004) is ‘the idea that the brain uses in-
ternal probabilistic (generative) models to update posterior
beliefs, using sensory information, in an (approximately)
Bayes-optimal fashion’, and predictive coding (Rao and Bal-
lard 1999) is ‘a tool used in signal processing for represent-
ing a signal using a linear predictive (generative) model’.
Bayes’ theorem derived from probability theory tells how
the belief from past experience ought to be updated in light
Figure 1: (Pellicano and Burr 2012) A. The Kanizsa triangle illu-
sion: It looks as if a white triangle overlays the other objects. B.
The hollow-face illusion: A strong bias towards the natural convex
face (left) suppresses the perception of the concave mask (right)
even with the atypical light source from the bottom. C. Shepard’s
table illusion: The two-dimensional images of the tabletop paral-
lelograms are identical. A strong bias towards a 3D interpretation
causes a perception of the further depth of the table on the left.
of sensory inputs. The mutual information (or Kullback-
Leibler (KL) divergence) between the prior and posterior
distributions is known as the Bayesian surprise (Itti and
Baldi 2009), which is a measure of how surprising the sen-
sory inputs are. Computational psychiatry (Adams, Huys,
and Roiser 2016; Pellicano and Burr 2012) uses Bayesian
models to explain several symptoms of mental disorders
such as schizophrenia and autism.
The success of Bayesian models of brain function makes
us think that there is a Bayesian model of how people per-
form logical reasoning, in a broad sense, including not only
deductive reasoning but ampliative reasoning. Such a view
would allow us to see commonsense reasoning, for instance,
as a reconciliation between top-down prediction and bottom-
up sensory information, just as the illusions shown in Figure
1 can be seen as a commonsense perception. This view of
linking logical reasoning with perception is consistent with
Mountcastle’s discovery (Mountcastle 1982) summarised by
Hawkins (Hawkins 2021). Hawkins writes that ‘every part
of the neocortex works on the same principle and that all the
things we think of as intelligence—from seeing, to touch-
ing, to language, to high-level thought—are fundamentally
the same’. This is evidenced by the experiment result (von
Melchner, Pallas, and Sur 2000) that ferrets learn to see with
their eyes rewired to the auditory cortex and to hear with
their ears rewired to the visual cortex.
All the above discussions motivate us to ask how formal
logic, as the laws of human thought, can be seen in terms ofarXiv:2301.08509v2  [cs.AI]  15 Mar 2023Bayesian models. The generative logic (Kido 2022) uses a
Bayesian method to model how data cause symbolic knowl-
edge. Probabilistic reasoning with symbolic knowledge is
modelled as a process of going the causality forwards and
backwards with a linear time complexity with respect to the
number of data. In a nutshell, the generative logic solves
an inverse problem of the interpretation of formal logic, re-
ferred to as an inverse interpretation, as opposed to the in-
verse entailment (Nienhuys-Cheng and Wolf 1997) and in-
verse deduction (Domingos 2015). Its probabilistic reason-
ing is equivalent to the maximum likelihood estimation and
is a reﬁnement of the classical consequence relation with
maximal consistent sets, which evidence statistical and log-
ical correctness, respectively.
The generative logic especially tackles the following
three fundamental assumptions of the existing prominent
approaches including Bayesian networks (Pearl 1988), the
probabilistic relational model (PRM) (Friedman et al. 1996),
probabilistic logic programming (PLP) (Sato 1995) and
Markov logic networks (MLN) (Richardson and Domingos
2006). First, the generative logic needs no conditional inde-
pendence assumption, which imposes each random variable
of probabilistic systems to depend only on a small num-
ber of other random variables for computational tractabil-
ity. Second, it needs no consistency assumption, which im-
poses logical systems to have consistent background knowl-
edge, otherwise everything is derived due to the principle
of explosion. Third, it needs no disconnection assumption,
which imposes probabilistic logic systems to have both sta-
tistical and logical machineries. The statistical machinery is
in charge of learning probabilities of logical sentences from
data whereas the logical machinery is in charge of reasoning
with the learnt logical sentences.
However, the generative logic still lacks a full logical
characterisation. The above-mentioned relation to maximal
consistent sets holds under the assumption that no model of
formal logic has a probability of zero. The assumption can
be ideal but too strict in practice as it implies that every state
of the world can occur. The assumption needs to be removed
to see the theoretical limits of the generative logic. More-
over, no justiﬁcation is given for the extensibility of the gen-
erative logic. As evidenced by hidden Markov models and
Kalman ﬁlters, Bayesian networks are extensible for tem-
poral reasoning. The theory needs to be discussed in light
of a real-world problem to see the practical prospect of the
combination of Bayesian models and formal logic.
In this paper, we give a simple theory of inference to rea-
son logically fully from data over time, and then fully char-
acterise the theory in terms of a logical consequence relation
introduced in this paper. Let dt
k,mt
nandtbe thekth data
at timet,nth model at time tand the truth value of the logi-
cal sentence at timet, respectively. We will formalise the
following probabilistic process of how dynamic data causes
symbolic knowledge via temporal models.
p(t) =X
np(tjmt
n)p(mt
n)
=X
np(tjmt
n)X
kp(mt
njdt
k)p(dt
k);
Figure 2: A schematic diagram of the generative model for tempo-
ral symbolic reasoning. Each top layer is a probability distribution
over data, each middle layer is over models of formal logic, and
each bottom layer is over symbolic knowledge. A darker colour
indicates a higher probability. A lower layer is an abstraction (i.e.,
selective ignorance) of the upper layer. Time runs discretely from
the left hierarchy to the right.
Figure 2 illustrates how to see the calculation as a gener-
ative process causing symbolic knowledge (on the bottom)
from dynamic data (on the top layer). Let tbe the set
of truth values of logical sentences. We will look at the
fact that the conditional probability, given as p(tjt) =P
np(tjmt
n)p(mt
njt), reﬁnes logical consequence rela-
tions. Here, p(tjmt
n)intuitively represents the probability
thatis true inmnat timet, i.e., an interpretation, and
p(mt
njt)the probability that the model making all the sen-
tences in true ismat timet, i.e., an inverse interpretation.
We theoretically analyse the logical and statistical correct-
ness of the probabilistic reasoning.
This paper contributes to interdisciplinary ﬁelds. In for-
mal logic, the two major approaches to logical consequence
relations are model checking and theorem proving (Russell
and Norvig 2020). The Bayesian model introduced in this
paper falls into another category that can be referred to as
data checking. The time complexity of data checking is lin-
ear with respect to the number of data (see Equation 1). This
is in contrast to the time complexity of model checking,
which is exponential with respect to the number of sym-
bols in propositional logic and is unbounded in predicate
logic. The improvement comes as a result of the fact that
data checking ignores all the models without data. Data
checking is thus intrinsically a better approach to a con-
sequence relation for commonsense reasoning (see Section
4). In AI, most of the modern systems across logic and
probability theory (e.g., (Pearl 1988; Friedman et al. 1996;
Sato 1995; Richardson and Domingos 2006)) treat learning
and reasoning separately. The Bayesian model introduced
in this paper uniﬁes statistical learning from dynamic data
and a sort of logical reasoning from temporal models. Prob-
abilistic reasoning with the Bayesian model corresponds to
a sort of logical reasoning with uncertain knowledge (see
Corollary 1) obtained by the maximum likelihood estima-
tion (see Equations 2, 3 and 4). Finally, we provide the neu-
roscience community with a new fully data-driven Bayesian
model (see Theorems 1, 2, 3 and 4). As discussed above,
the exact posterior distribution can be calculated using the
Bayesian model with a linear time complexity. This fact
challenges the motivation behind the use of approximateBayesian methods in neuroscience, e.g., the Markov chain
Monte Carlo method (Sanborn and Chater 2016) and the
variational Bayesian method (Friston 2010). Neuroscience
validation, however, is beyond the scope of this paper.
In the next section, we discuss a Bayesian model for tem-
poral logical reasoning. In Section 3, we look at the sta-
tistical and logical correctness of the model and then deﬁne
several inference patterns for temporal inference tasks. In
Section 4, we apply the inference patterns to discuss a local-
isation problem. Section 5 summarises the results.
2 Generative Logic with Time
2.1 Temporal Probabilistic Models
LetD=fd1;d1;:::;dKgbe a ﬁnite multiset of sequences
of data, where dk= (d1
k;d2
k;:::;dT
k)is a ﬁnite sequence of
data anddt
kis thekth data at time t, for allkandtsuch
that1kKand1tT.Dis a random variable
of data whose realisations are elements of D. For all dk2
D, we deﬁne the probability of dkasp(D=dk) =1
K.
The probability distribution over Ksequential data is thus a
uniform distribution.
The formal language we assume in this paper is a propo-
sitional language denoted by L.M=fm1;m2;:::;mNg
is a set of models of L.Dis assumed to be complete with
respect toM. It means that each data in dkis an instance
of a single model in M, for allksuch that 1kK. We
use function mthat maps dkto the sequence of such single
models.m(dk)trefers to the tth element of m(dk).Mtis
a random variable of models at time twhose realisations are
elements ofM, for alltsuch that 1tT. For all mod-
elsmn2M at any timetand data dk2D, we deﬁne the
conditional probability of mngivendkas follows.
p(Mt=mnjD=dk) =1ifmn=m(dk)t
0otherwise
Thus, the probability of model mnat timetgiven data dkis
one if and only if the kth data at time t, i.e.,dt
k2dk, is an
instance of the model mn.
Next, we give a probabilistic representation of the inter-
pretation of formal logic. Ordinary formal logics consider an
interpretation on each model.1The interpretation is a func-
tion that maps each formula to a truth value, which repre-
sents knowledge of the world. The truth value of a logical
formula depends on time. For any formula 2L,tis a
random variable of at timetwhose realisations are 0 and 1,
denoting false and true, respectively. We introduce variable
2[0;1]to denote the extent to which each model inﬂu-
ences the interpretation2. Concretely, denotes the proba-
bility that a formula is interpreted as being true (resp. false)
in a model where it is true (resp. false). 1 is therefore the
probability that a formula is interpreted as being true (resp.
false) in a model where it is false (resp. true). We assume
that each formula is a random variable whose realisations are
1In this paper, ‘model’ means a model of a state of the world,
whereas ‘interpretation’ means an interpretation of a sentence.
2We will see that more interesting discussions emerge with 
approaching 1, i.e., !1, rather than = 1.0 and 1, denoting false and true, respectively. For all mod-
elsmn2M and formulae t, we deﬁne the conditional
probability of each truth value of tgivenmn, as follows.
p(t= 1jMt=mn) = ifmn2Jt= 1 K
1 otherwise
p(t= 0jMt=mn) = ifmn2Jt= 0 K
1 otherwise
Here, Jt= 1 Kdenotes the set of all models in which is
true, and Jt= 0 Kthe set of all models in which is false.
The above expressions can be simply written as a Bernoulli
distribution with parameter 2[0;1], i.e.,
p(tjMt=mn) =JtKmn(1 )1 JtKmn:
Here, JtKmnis a function such that JtKmn= 1 ifmn2
JtKand JtKmn= 0otherwise. Recall that tis a random
variable, and so JtKmnis either Jt= 0 KmnorJt=
1Kmn.
In ordinary formal logics, the truth value of each formula
is independently determined given a model. In probability
theory, this means that the truth values of any two formulae
t
1andt
2are conditionally independent given a model mn,
i.e.,p(t
1;t
2jMt=mn) =p(t
1jMt=mn)p(t
2jMt=
mn), for allt. Note that the conditional independence holds
not only for atomic formulae but for compound formulae.
However, the independence p(t
1;t
2) =p(t
1)p(t
2)gen-
erally holds neither for atomic nor compound formulae. Let
 be a multisetf1;2;:::;Jgof formulae inL. We use
symbol  tto represent the multiset ft
1;t
2;:::;t
Jgof the
random variables at time t. The probability of  tis given as
follows.
p( tjMt=mn) =JY
j=1p(t
jjMt=mn)
Figure 3 shows the graphical model of the generative logic
we deﬁned in this section. It shows that sequential data is
sliced by time and then fed into the corresponding mod-
els. For the sake of simplicity, we use symbols X1:tto de-
note the setfX1;X2;:::;Xtgof random variables Xt, and
we omit 1 :tift=T. Given a value of the parameter
, they provide the full joint distribution over all the ran-
dom variables, i.e., p( ;M;D). In this paper, we refer to
fp( jM;),p(MjD),p(D)gas a generative logic.
Proposition 1. p(t= 0) =p(:t= 1) holds, for all t
and2L.
Proof. From the deﬁnition, we have
p(:t= 1) =X
np(:t= 1jMt=mn)p(Mt=mn)
=X
n[ [:t=1] ]Mt=mn(1 )1 [ [:t=1] ]Mt=mnp(Mt=mn)
=X
n[ [t=0] ]Mt=mn(1 )1 [ [t=0] ]Mt=mnp(Mt=mn)
=X
np(t= 0jMt=mn)p(Mt=mn) =p(t= 0):
This proof holds regardless of the value of .Figure 3: The generative logic is about a formal representation of
problem-independent logical interpretation and its inversion. It is
not about a formal representation of problem-dependent uncertain
domain knowledge.
In what follows, we therefore replace t= 0by:t= 1
and then abbreviate :t= 1 to:t. We also abbreviate
Mt=mntomnandD=dktodkfor simplicity.
Example 1. Letfp( jM;= 1);p(MjD);p(D)gbe a
generative logic built on D=fdt
kj1k5;1t
3g. Suppose that dt
kis data about weather r(meaning
‘rain’) and ground condition w(meaning ‘wet’) collected
on daytby personk. Supposem(d1) = (m1;m1;m2),
m(d2) = (m2;m4;m3),m(d3) = (m1;m4;m4),
m(d4) = (m1;m2;m4)andm(d5) = (m3;m2;m2)where
m1satisﬁes neither rnorw,m2satisﬁes only w,m3satis-
ﬁes onlyr, andm4satisﬁes both randw.
p(w3jr3) =P4
n=1P5
k=1p(w3jmn)p(r3jmn)p(mnjdk)P4
n=1P5
k=1p(r3jmn)p(mnjdk)
=P5
k=1p(w3jm(dk)3)p(r3jm(dk)3)P5
k=1p(r3jm(dk)3)
=P5
k=1Jw3Km(dk)3Jr3Km(dk)3
P5
k=1Jr3Km(dk)3=2
3
In line 1, we brought all the random variables and then
cancelledp(dk) = 1=5, for allk. In line 2, we usedP
np(tjmn)p(mnjdk) =p(tjm(dk)t), for allandt.
As demonstrated in Example 1, the summation over mod-
els can be eliminated by the assumption that data are com-
plete with respect to the models. In general, we have
p(t) =KX
k=1p(dk)NX
n=1p(tjmn)p(mnjdk) (1)
=KX
k=11
KNX
n=1[ [t] ]m(dk)tp(mnjdk) =1
KKX
k=1[ [] ]m(dk)t:
The number of models increases exponentially with respect
to the number of symbols in propositional logic and un-
bounded in predicate logic. Equation (1) thus guarantees
the scalability of the generative logic.
3 Theoretical Correctness
3.1 Maximum Likelihood Estimation
Letfp( jM;);p(MjD);p(D)gbe a temporal generative
logic. We look at the statistical properties of the probabil-
ity distribution over models over time. Let mt
nandmu
obethenth model at time tandoth model at time u, respec-
tively. Their joint probability given by the temporal genera-
tive logic can be written as
p(mt
n;mu
o) =X
dp(mt
njd)p(mu
ojd)p(d)
=1
KX
dp(mt
njd)p(mu
ojd) =Kn;o
K;(2)
whereKis the total number of data and Kn;ois the number
of data in the model mnat timetand in the model moat
timeu(see Table 1).
Now, we ask how the joint distribution p(Mt;Mu)can be
characterised in terms of maximum likelihood estimation,
which is the most often used method to estimate a proba-
bility distribution only from data. As illustrated in Table 1,
the joint distribution can be seen as a categorical distribu-
tion with parameter  = (1;1;1;2;:::;N;N). Assuming
that each data is independent and identically distributed, the
parameter maximising the likelihood of data, denoted by
ML, can be written as follows.
ML= arg max
p(Dj) = arg max
K1;1
1;1K1;2
1;2:::
:::KN;N 1
N;N 1(1 1;1 1;2 ::: N;N 1)KN;N:
maximises the likelihood p(Dj)if and only if it max-
imises its log-likelihood L()given as follows.
L() =K1;1log1;1+K1;2log1;2+:::+KN;N 1
logN;N 1+KN;Nlog(1 1;1 1;2 ::: N;N 1):
maximising the log-likelihood can be found by solving
the simultaneous equations given as follows, for all nando.
@L()
@n;o=Kn;o
n;o KN;N
1 1;1 1;2 ::: N;N 1= 0
The solution to the simultaneous equations turns out to be
ML=K1;1
K;K1;2
K;:::;KN;N
K
: (3)
We thus have p(Mt;Mu) = ML. Namely,p(mt
n;mu
o) =
Kn;o=Kis the ratio of the number of data in the model mn
at timetand the model moat timeuto the total number of
data. It is observed that Equation (2) we derived using the
temporal generative logic is the maximum likelihood esti-
mate. In general, the joint distribution over models given by
the temporal generative logic can be written as
p(m1
n;m2
o;:::;mT
p) =Kn;o;:::;p
K;
whereKn;o;:::;p
Kis the maximum likelihood estimate, and
thusKn;o;:::;p is the number of data in mnat time 1,mo
at time 2,mpat timeT, and so on.
We next look at the statistical properties of the probabil-
ity distribution over formulae over time. On the temporalTable 1:  = (n;oj1n;oN)is the joint probability distri-
bution over the models with time tandu, i.e.,p(Mt;Mu).Kn;o
is the number of data such that it is in the model mnat timetand
in the model moat timeu.Kn=P
oKn;ois the number of data
inmnatt, andK=P
n;oKn;ois the total number of data.
mu
1 mu
o mu
N
mt
11;1(K1;1)1;o(K1;o)1;N(K1;N)
...
mt
nn;1(Kn;1)...n;o(Kn;o)...n;N(Kn;N)
...
mt
NN;1(KN;1)N;o(KN;o)N;N(KN;N)
generative logic, we have
p(t;u) =X
mtnX
muop(t;ujmt
n;mu
o)p(mt
n;mu
o)
=X
mtnX
muop(tjmt
n;mu
o)p(ujmt
n;mu
o)p(mt
n;mu
o)
=X
mtnp(tjmt
n)X
muop(ujmu
o)p(mt
n;mu
o):
The second equation holds as tanduare conditionally
independent given mt
nandmu
o. The third equation holds as
t(resp.u) is conditionally independent of mu
o(resp.mt
n)
givenmt
n(resp.mu
o). Given= 1or!1, we have
p(t;u) =X
mtn2[ [t] ]X
muo2[ [u] ]p(mt
n;mu
o)
=X
mtn2[ [t] ]X
muo2[ [u] ]Kn;o
K: (4)
Probability theory and propositional logic are typically com-
bined so that it satisﬁes p() =P
mn2[ [] ]p(mn), for all
propositional sentences (Russell and Norvig 2020). In
Equation (4), the ﬁrst equation guarantees a natural exten-
sion of the classical approach. The second equation shows
that the probabilities of the models are equal to the maxi-
mum likelihood estimate (see Equation (3)). In general, the
joint distribution over formulae given by the temporal gen-
erative logic can be written as
p(1;2;:::;T) =X
m1n2[ [1] ]X
m2o2[ [2] ]:::X
mTp2[ [T] ]Kn;o;:::;p
K:
This result implies p(t;t;:::;t) =P
mtn2[ [t;t;:::;t] ]Kn
K, which is the static case discussed in
the paper (Kido 2022). It is obvious from Equation (4) that
a conditional probability distribution over time is given by
p(ujt) =p(u;t)
p(t)=P
muo2[ [u] ]P
mtn2[ [t] ]p(mu
o;mt
n)
P
mtn2[ [t] ]p(mtn)
=P
muo2[ [u] ]P
mtn2[ [t] ]Kn;oP
mtn2[ [t] ]Kn:3.2 Empirical Consequence Relation
Letfp( jM;);p(M jD);p(D)gbe a generative logic.
From the above-mentioned assumption that each data is
complete with respect to models, we have
p( ) =X
dX
mp( jm;)p(mjd)p(d)
=X
dp( jm(d);)p(d):
Considerfp0( jD;),p(D)gwherep0( jD;)is deﬁned
asp( jm(D);). Given a value of , it gives the joint distri-
butionp( ;D). It is thus another generative logic excluding
the random variables of models. We have now
p0( ) =X
dp0( jd;)p(d) =X
dp( jm(d);)p(d):
The above result shows that fp( jM;);p(M jD);p(D)g
is equivalent tofp0( jD;),p(D)gin terms of the prob-
ability distribution over a set of formulae. In this section,
we write the latter generative logic simply as fp( jD;),
p(D)gand use it without distinction. We also omit time tif
it is obvious from the context.
Deﬁnition 1 (Evidence) .Letd2D andL.dis an
evidence of ifis true inm(d), for all2.
In this paper, we assume that any subset of the multiset D
is also a multiset. For 2L, we use symbolhhiito denote
the set of the evidences of , i.e.,hhii=fd2Djdis an
evidence of g. We refer to as founded ifhhii6=;and
unfounded otherwise.
Deﬁnition 2 (Maximal founded sets) .LetL.S
is a maximal founded subset of ifhhSii6=;andhhS[
fgii=;, for all2nS.
We use the symbol MFS () to denote the set of the
cardinality-maximal founded subsets of and the symbol
jXjto denote the number of elements in a set X. We
use symbolhhii0to denote the set of the evidences of the
cardinality-maximal founded subsets of , i.e.,hhii0=S
S2MFS ()hhSii. Obviously,hhii=hhii0ifhhii6=;.
The following theorem relates the conditional probability
distribution to the evidence of the formulae.
Theorem 1. Letfp( jD;);p(D)gbe a generative logic
such that!1. For all 
;L such thathhii06=;,
p(
j) =jhh
ii\hh ii0j
jhhii0j:
Proof. We use symboljXjm(d)to denote the number of
formulae in Xthat are true in m(d), i.e.jXjm(d)=P
t2X[ [t] ]m(d)t. Dividing data in hhii0and the others,
we have
p(
j) = lim
!1P
dp(
jd;)p(jd;)P
dp(jd;)= lim
!1
X
^d2hhii0p(
j^d;)p(j^d;) +X
d=2hhii0p(
jd;)p(jd;)
X
^d2hhii0p(j^d;) +X
d=2hhii0p(jd;):Now,p(Xjm)can be developed as follows, for all d.
p(Xjd) =Y
2Xp(jd) =Y
2X[ [] ]m(d)(1 )1 [ [] ]m(d)
=P
2X[ [] ]m(d)(1 )P
2X(1 [ [] ]m(d))
=jXjm(d)(1 )jXj jXjm(d)
We havep(
j) = lim!1P
^d2hhii0W+P
d=2hhii0XP
^d2hhii0Y+P
d=2hhii0Zwhere
W=j
jm(^d)(1 )j
j j
jm(^d)jjm(^d)(1 )jj jjm(^d)
X=j
jm(d)(1 )j
j j
jm(d)jjm(d)(1 )jj jjm(d)
Y=jjm(^d)(1 )jj jjm(^d)
Z=jjm(d)(1 )jj jjm(d):
Now, if d=2 hhii0thendis an evidence of a subset of
that is not a cardinality-maximal founded subset of .
Therefore, there is ^d2hhii0such thatjjm(d)<jjm(^d).
jjm(^d1)=jjm(^d2)by deﬁnition, for all ^d1;^d22hhii0.
The fraction thus can be simpliﬁed by dividing the denom-
inator and numerator by (1 )jj jjm(^d). We thus have
p(
j) = lim!1P
^d2hhii0W0+P
d=2hhii0X0
P
^d2hhii0Y0+P
d=2hhii0Z0where
W0=j
jm(^d)(1 )j
j j
jm(^d)jjm(^d)
X0=j
jm(d)(1 )j
j j
jm(d)jjm(d)(1 )jjm(^d) jjm(d)
Y0=jjm(^d)
Z0=jjm(d)(1 )jjm(^d) jjm(d):
Applying the limit operation, we can cancel out X0andZ0
and have
p(
j) =P
^d2hhii01j
jm(^d)0j
j j
jm(^d)1jjm(^d)
P
^d2hhii01jjm(^d)
=P
^d2hhii00j
j j
jm(^d)
P
^d2hhii01=jhh
ii\hh ii0j
jhhii0j:(5)
In line 2, we used the fact that 0j
j j
jm(^d)= 1 iffj
j=
j
jm(^d), and 0j
j j
jm(^d)= 0iffj
j>j
jm(^d).
To logically characterise the conditional probability, we
deﬁne another consequence relation based on data.
Deﬁnition 3 (Empirical consequence) .Let;
L .
is an empirical consequence of , denoted by  pP
, if
hhiihh 
ii.
The following corollary shows that the empirical con-
sequence relation with maximal founded sets characterises
probabilistic reasoning on the generative logic.
Corollary 1. Letfp( jD;);p(D)gbe a generative logic
such that!1. For all 
;L such thathhii06=;,
p(
j) = 1 iffS pP
, for all maximal founded subsets S
of.Proof. From Equation (5), p(
j) = 1 iffhhii0
hh
ii. Sincehhii0=S
S2MFS ()hhSii,p(
j) = 1 iffS
S2MFS ()hhSiihh 
ii.
The following theorem shows that probabilistic reasoning
on the generative logic is reasonable even when there is no
evidence of any formula in the condition.
Theorem 2. Letfp( jD;);p(D)gbe a generative logic
such that!1. For all 
;L such thathhii0=;,
p(
j) =p(
).
Proof. Sincehhii0=;, we have
p(
j) = lim
!1P
d=2hhii0p(
jd;)p(jd;)p(d)
P
d=2hhii0p(jd;)p(d)
Now,hhii0=S
S2MFS ()hhSii=;iff no data is an evi-
dence of any singleton of . We thus have
p(jd;) =Y
t2p(tjd;) =Y
t2[ [t] ]m(d)t(1 )1 [ [t] ]m(d)t
=P
t2[ [t] ]m(d)t(1 )P
t2(1 [ [t] ]m(d)t)=0(1 )jj:
Therefore, we have
p(
j) = lim
!1P
d=2hhii0p(
jd;)0(1 )jjp(d)
P
d=2hhii00(1 )jjp(d)
= lim
!1P
d=2hhii0p(
jd;)p(d)
P
d=2hhii0p(d)= lim
!1P
dp(
jd;)p(d)P
dp(d)
= lim
!1X
dp(
jd;)p(d) =p(
):
All the above properties discussed in this section are about
the relationship between formulae. The following two theo-
rems show how the distribution over data is updated in light
of the observation of formulae.
Theorem 3. Letfp( jD;);p(D)gbe a generative logic
such that!1. For all L such thathhii06=;,
p(Dj) =(
1
jhhii0jifD2hhii0
0 otherwise.
Proof. Again, we use symbols jjandjjm(d)to denote
the number of formulae in and the number of formulae in
that are true in m(d), i.e.,jjm(d)=P
t2[ [t] ]m(d)t,
respectively.
p(Dj) = lim
!1Q
t2[ [t] ]m(D)t(1 )1 [ [t] ]m(D)t
P
dQ
t2[ [t] ]m(d)t(1 )1 [ [t] ]m(d)t
= lim
!1jjm(D)(1 )jj jjm(D)
P
djjm(d)(1 )jj jjm(d)Separating the models in hhii0and the others, we have
p(Dj) = lim!1XP
^d2hhiiY+P
d=2hhiiZwhere
X=jjm(D)(1 )jj jjm(D)
Y=jjm(^d)(1 )jj jjm(^d)
Z=jjm(d)(1 )jj jjm(d):
Dividing the denominator and numerator by
(1 )jj jjm(^d), we have p(Dj) = lim !1
X0P
^d2hhiiY0+P
d=2hhiiZ0where
X0=jjm(D)(1 )jjm(^d) jjm(D)
Y0=jjm(^d)
Z0=jjm(d)(1 )jjm(^d) jjm(d):
jjm(^d)>jjm(d). Applying the limit operation, we have
p(Dj) =1jjm(D)0jjm(^d) jjm(D)
P
^d2hhii1jjm(^d)=0jjm(^d) jjm(D)
P
^d2hhii1
0jjm(^d) jjm(D)= 1ifD2hhii0and0otherwise. Thus,
p(Dj) =(
1
jhhii0jifD2hhii0
0 otherwise.
The following theorem shows that probabilistic reasoning
for data is reasonable even when there is no evidence of any
formula in the condition.
Theorem 4. Letfp( jD;);p(D)gbe a generative logic
such that!1. For all L such thathhii0=;,
p(Dj) =p(D).
Proof. Sincehhii0=;, we have
p(Dj) = lim
!1p(jD;)p(D)P
d=2hhii0p(jd;)p(d)
Now,hhii0=S
S2MFS ()hhSii=;iff no data is an evi-
dence of any singleton of . For all d, we thus have
p(jd;) =Y
t2p(tjd;) =Y
t2[ [t] ]m(d)t(1 )1 [ [t] ]m(d)t
=P
t2[ [t] ]m(d)t(1 )P
t2(1 [ [t] ]m(d)t)=0(1 )jj:
Therefore, we have
p(Dj) = lim
!10(1 )jjp(D)P
d=2hhii00(1 )jjp(d)
Dividing the denominator and numerator by (1 )jjand
then applying the limit operation, we have
p(Dj) =p(D)P
d=2hhii0p(d)=p(D)P
dp(d)=p(D):3.3 Temporal Inference Patterns: = 1
Letfp( jM;= 1) ,p(MjD),p(D)gbe a generative logic
with= 1. This section introduces several patterns of prob-
abilistic reasoning to handle temporal inference tasks. In
Section 4, we will apply the concepts to temporal inference
tasks in a localisation problem.
Prediction and smoothing Let1;:::;t;
u . The
following conditional probability allows us to discuss sev-
eral important inference tasks.3
p(
uj1:t)/p(
u;1:t)
/X
kX
np(
ujmn)p(mnjdk)tY
i=1X
np(ijmn)p(mnjdk)
=X
kp(
ujm(dk)u)tY
i=1p(ijm(dk)i)
=X
k[ [
u] ]m(dk)utY
i=1[ [i] ]m(dk)i
Symbol/in lines 1 and 2 means ‘be proportional to.’ In line
2, we brought all the random variables and then excluded
p(dk) = 1=K, for allk. Obviously, mnin the ﬁrst and
second factors of the multiplication is a realisation of Mu
whereasmnin the third and forth is a realisation of Mi.
Line 3 holds due to the previously-mentioned assumption
that data is complete with respect to the models, and line 4
holds due to = 1.
Suppose that tis the current time and u=t+lwhere
l0. We then have p(
t+lj1:t)that corresponds to pre-
diction. It concerns the knowledge about the current or a
future point of time derived by combining data, distributed
at the root node in Figure 3, and knowledge observed to
date at the leaf nodes. Given u=t lwherel >0, we
havep(
t lj1:t)that corresponds to smoothing (Russell
and Norvig 2020). It concerns knowledge about a past point
of time derived from the data and knowledge to date. Note
that reasoning about past, current and future points of time
depends on the same mathematical formulation available on
the temporal generative logic.
Most likely explanation Let!ibe a realisation of 
i, for
allisuch that 1it. Most likely explanation (Russell
and Norvig 2020) is another useful inference task we can
model in this paper as follows.
arg max
!1:tp(!1:tj1:t) = arg max
!1:tp(!1:t;1:t)
= arg max
!1:tX
ktY
i=1p(!ijm(dk)i)p(ijm(dk)i)
= arg max
!1:tX
ktY
i=1[ [!i;i] ]m(dk)i
3We assumep(1:t)6= 0 in this section because otherwise
= 1causes a division by zero. The general case with p(1:t) =
0is discussed using !1in the next section.Reference The probability distribution over data changes
due to observations over time. Reference is another useful
inference task we introduce in this paper as follows.
p(Dj1:t)/p(D;1:t) =tY
i=1X
np(ijmn)p(mnjD)
=tY
i=1p(ijm(D)i) =tY
i=1[ [i] ]m(D)i:
3.4 Temporal Inference Patterns: !1
Letfp( jM;!1),p(MjD),p(D)gbe a generative
logic with!1. This section extends the discussion in
the previous section.
Prediction and smoothing Supposehh1:tii06=;. The
prediction and smoothing discussed in the previous section
can be extended using Theorem 1 as follows.
p(
uj1:t) =jhh
uii\hh1:tii0j
jhh1:tii0j
=jhh
uii\S
S2MFS (1:t)hhSiij
jS
S2MFS (1:t)hhSiij
Ifhh1:tii0=;, those patterns can be extended using The-
orem 2 asp(
uj1:t) =p(
u). Note thathh1:tii0=;is
a rare situation because it holds iff no data is an evidence of
any singleton of 1:t.
Most likely explanation Ifhh1:tii06=;, the most likely
explanation discussed in the previous section can be ex-
tended using Theorem 1 as follows.
arg max
!1:tp(!1:tj1:t) = arg max
!1:tjhh!1:tii\hh1:tii0j
jhh1:tii0j
= arg max
!1:tjhh!1:tii\hh1:tii0j
= arg max
!1:tjhh!1:tii\[
S2MFS (1:t)hhSiij
Ifhh1:tii0=;, this task can be extended using Theorem
2 as arg max!1:up(!1:uj1:t) = arg max!1:up(!1:u).
Again,hh1:tii0=;is a rare situation because it holds iff
no data is an evidence of any singleton of 1:t.
Reference Ifhh1:tii06=;, the reference discussed in the
previous section can be extended using Theorem 3 as fol-
lows.
p(Dj1:t) =(
1
jhh1:tii0jifD2hh1:tii0
0 otherwise.
Ifhh1:tii0=;, the reference can be extended using Theo-
rem 4 asp(Dj1:t) =p(D).
4 An Application to Localisation
Consider a robot located somewhere in the maze shown on
the leftmost panel in Figure 4. The task of the robot is to
ﬁnd its location in the maze only using potentially noisy datacoming from its sensors that detect obstacles in the north,
east, south and west neighbour rooms.
We assume propositional atoms N;E;S;W2Lto repre-
sent the presence (1) or absence (0) of obstacles in the north,
east, south and west, respectively. The propositional atom
Lx2L represents the presence (1) or absence (0) of the
robot inx2fa;b;:::;qg. For the sake of simplicity, we use
symbolLto represent the location of the robot.
We assume no map of the maze for the robot, which
makes the localisation problem in this paper harder than the
typical one (Russell and Norvig 2020). We instead assume
that the robot has potentially noisy data about the maze. The
data is assumed to be collected by the robot via its sensors
before it is located somewhere in the maze. Suppose the
robot has dataD=fd1,d2,d3,d4,d5gwhere
d1= ((a;1;0;1;1);(b;1;1;0;0);(e;0;0;1;1))
d2= ((c;1;0;1;1);(d;1;1;0;0);(g;0;1;0;1))
d3= ((k;1;0;1;1);(l;1;0;1;0);(m;0;1;0;0))
d4= ((q;0;1;1;0);(p;1;0;1;0);(o;0;0;1;1))
d5= ((q;0;1;1;0);(n;0;1;0;1);(j;0;1;0;0)):
Here,dt
kis a sequence of realisations of (Lt,Nt,Et,St,
Wt). For simplicity, we assumed no noise in the data. We
use symbolOtto denote (Nt,Et,St,Wt)and omit com-
mas. For example, d2
1=b1100 means that the robot sensed
obstacles only in the north and east in room bat time 2.
Now, given the generative logic fp( jM;= 1) ,
p(MjD),p(D)gdeﬁned onD, we can apply the inference
tasks we formalised in Section 3.3. We ﬁrst ask the proba-
bility of the current, future and past locations of the robot.
The second panel in Figure 4 shows the probability of each
robot location at time 1 when the robot perceives nothing at
time 1. The distribution is reasonable in terms of Dbecause
the robot has been to a,candkonce, but to qtwice at time
1. The third, fourth and ﬁfth panels show examples of pre-
diction discussed in Section 3.3. It is observed that sensory
inputs over time help the robot identify its location. The 6th
panel shows another example of prediction about a future
location, and the 7th shows an example of smoothing.
Given the sensory inputs O1= 1011 ,O2= 1100 ,O3=
0011 , we have the following most likely explanation.
arg max
l1:3p(l1:3jO1= 1011;O2= 1100;O3= 0011)
= (L1=a;L2=b;L3=e)
The following shows examples of reference, which allows
us to refer to the data whose probability distribution is up-
dated in light of sensory inputs.
p(D) =h1=5;1=5;1=5;1=5;1=5i
p(DjO1= 1011) =h1=3;1=3;1=3;0;0i
p(DjO1= 1011;O2= 1100) =h1=2;1=2;0;0;0i
p(DjO1= 1011;O2= 1100;O3= 0011) =h1;0;0;0;0i
Now, supposeD=fd1,d2,d3,d4,d5gwhere d1=
(a1011 ,b1100 ,e0011) ,d2= (c1011;d1100;g0101) ,d3=
(k1011 ,l1010 ,m0100) ,d4= (q0110 ,p1010 ,o0011) andFigure 4: A map of the maze and probability distributions over robot locations, where O1= 1011 ,O2= 1100 andO3= 0011 .
d5= (q0110 ,n0101 ,j0100) . Given the generative logic
fp( jM;!1),p(MjD),p(D)gdeﬁned onD, consider
that the robot is not aware of the fact that the north and east
sensors usually sense the absence of obstacles due to sensor
trouble. Let NESW1(=O1) = 0011 andNESW2(=
O2) = 0000 . No data instantiate the models. Now, we have
p(L2jO1;O2) =jhhL2ii\hhO1= 0011;O2= 0000ii0j
jhhO1= 0011;O2= 0000ii0j
=jhhL2ii\S
S2MFS (fO1=0011;O2=0000g)hhSiij
jS
S2MFS (fO1=0011;O2=0000g)hhSiij:
MFS (fO1= 0011;O2= 0000g) =fS1;S2gwhereS1=
fESW1= 011 ,SW2= 00gandS2=fESW1= 011 ,
EW2= 00g. We thus have
p(L2jO1;O2) =jhhL2ii\(hhS1ii[hhS2ii)j
jhhS1ii[hhS2iij
=jhhL2ii\(fd1;d2g[fd3g)j
jfd1;d2g[fd3gj=jhhL2ii\fd1;d2;d3gj
jfd1;d2;d3gj:
Therefore, we have
p(L2jO1= 0011;O2= 0000) =1=3ifL2=b;d;l
0 otherwise:
Using the previous data without noise, we saw that the robot
had a certain belief about its location using the correct sen-
sory inputs. The above result shows that a broken or noisy
sensory input is still useful for the robot to reduce the uncer-
tainty of the location.
Suppose that the robot additionally collects another sen-
sory input at time 2. Consider NESW2(=O2) = 0100 . To
distinguish the ﬁrst sensory input at time 2 from the second,
we writeNESW2
1(=O2
1) = 0000 andNESW2
2(=O2
2) =
0100 . This requires reasoning from inconsistency because
E2= 0inO2
1whereasE2= 1inO2
2. Now, we have
p(L2jO1;O2
1;O2
2) =jhhL2ii\hhO1;O2
1;O2
2ii0j
jhhO1;O2
1;O2
2ii0j
=jhhL2ii\S
S2MFS (fO1=0011;O2
1=0000;O2
2=0100g)hhSiij
jS
S2MFS (fO1=0011;O2
1=0000;O2
2=0100g)hhSiij:
MFS (fO1= 0011;O2
1= 0000;O2
2= 0100g) =fSg
whereS=fESW1= 011 ,SW2
1= 00 ,ESW2
2= 100g.
We thus have
p(L2jO1;O2
1;O2
2) =jhhL2ii\hhSiij
jhhSiij=jhhL2ii\fd1;d2gj
jfd1;d2gj:Therefore, we have
p(L2jO1;O2
1;O2
2) =1=2ifL2=b;d
0 otherwise:
The above result shows that an inconsistent sensory input is
useful for the robot to reduce the uncertainty of the location.
In addition to NESW1(=O1) = 0011 ,NESW2
1(=
O2
1) = 0000 andNESW2
2(=O2
2) = 0100 assumed in the
previous section, suppose NESW3(=O3) = 0011 . Given
O1:3, the most likely explanation is obtained as follows.
arg max
l1:3p(l1:3jO1:3) = arg max
l1:3jhhl1:3ii\hhO1:3ii0j
= arg max
l1:3jhhl1:3ii\[
S2MFS (O1:3)hhSiij
MFS (O1:3) =fSgwhereS=fESW1= 011 ,SW2
1=
00,ESW2
2= 100 ,NESW3= 0011g. We thus have
arg max
l1:3p(l1:3jO1:3) = arg max
l1:3jhhl1:3ii\hhSiij
= arg max
l1:3jhhl1:3ii\fd1gj:
Therefore, we have
arg max
l1:3p(l1:3jO1:3) =1ifL1:3= (a;b;e )
0otherwise:
The above result shows that the robot reduced the uncer-
tainty about its location path over time.
Finally, consider the reference p(DjO1;O2
1)where
NESW1(=O1) = 0011 andNESW2
1(=O2
1) = 0000 .
MFS (fO1;O2g) =fS1;S2gwhereS1=fESW1= 011 ,
SW2= 00gandS2=fESW1= 011 ,EW2= 00g. We
thus havehhS1ii=fd1;d2gandhhS2ii=fd3g. Therefore,
p(DjO1;O2
1) =1
3ifD=d1;d2;d3
0 otherwise.
The above result shows that reference tells which stored data
the robot should imagine from potentially impossible and in-
consistent sensory inputs. The ability of the robot to perform
the reference task is thus related to explainable AI.
5 Conclusions
This paper presented a simple theory of inference to reason
logically fully from data over time. We showed the statisti-
cal and logical correctness of the model and then introduced
several inference patterns that are useful to handle tempo-
ral inference tasks. The theory was applied to a localisation
problem to show that a robot with broken or noisy sensors
can efﬁciently solve the problem in a fully data-driven fash-
ion.References
Adams, R. A.; Huys, Q. J. M.; and Roiser, J. P. 2016. Com-
putational psychiatry: towards a mathematically informed
understanding of mental illness. Journal of Neurology, Neu-
rosurgery & Psychiatry 87(1):53–63.
Domingos, P. 2015. The Master Algorithm: How the Quest
for the Ultimate Learning Machine Will Remake Our World .
Allen Lane.
Friedman, N.; Getoor, L.; Koller, D.; and Pfeffer, A. 1996.
Learning probabilistic relational models. In Proc. 16th Int.
Joint Conf. on Artif. Intell. , 1297–1304.
Friston, K. 2010. The free-energy principle: a uniﬁed brain
theory? Nature Reviews Neuroscience 11:127–138.
Hawkins, J. 2021. A Thousand Brains: A New Theory of
Intelligence . Basic Books.
Hohwy, J. 2014. The Predictive Mind . Oxford University
Press.
Itti, L., and Baldi, P. 2009. Bayesian surprise attracts human
attention. Vision Research 49(10):1295–1306.
Kido, H. 2022. Generative logic models for data-based sym-
bolic reasoning. In Proc. 8th International Workshop on Ar-
tiﬁcial Intelligence and Cognition , 1–14.
Knill, D. C., and Pouget, A. 2004. The bayesian brain: the
role of uncertainty in neural coding and computation. Trends
in Neurosciences 27:712–719.
Knill, D. C., and Richards, W. 1996. Perception as Bayesian
Inference . Cambridge University Press.
Mountcastle, V . B. 1982. An organizing principle for cere-
bral function: the unit module and the distributed system .
MIT Press, revised ed. edition edition. 7–50.
Nienhuys-Cheng, S. H., and Wolf, R. D. 1997. Foundation
of Inductive Logic Programming . Springer.
Pearl, J. 1988. Probabilistic Reasoning in Intelligent Sys-
tems: Networks of Plausible Inference . Morgan Kaufmann.
Pellicano, E., and Burr, D. 2012. When the world be-
comes ’too real’: a bayesian explanation of autistic percep-
tion. Trends in Cognitive Sciences 16(10):504–510.
Rao, R. P. N., and Ballard, D. H. 1999. Predictive cod-
ing in the visual cortex: a functional interpretation of some
extra-classical receptive-ﬁeld effects. Nature Neuroscience
2:79–87.
Richardson, M., and Domingos, P. 2006. Markov logic
networks. Machine Learning 62:107–136.
Russell, S., and Norvig, P. 2020. Artiﬁcial Intelligence : A
Modern Approach, Fourth Edition . Pearson Education, Inc.
Sanborn, A. N., and Chater, N. 2016. Bayesian brains with-
out probabilities. Trends in Cognitive Sciences 20:883–893.
Sato, T. 1995. A statistical learning method for logic pro-
grams with distribution semantics. In Proc. 12th int. conf.
on logic programming , 715–729.
von Melchner, L.; Pallas, S. L.; and Sur, M. 2000. Visual
behaviour mediated by retinal projections directed to the au-
ditory pathway. Nature 404(6780):871–876.