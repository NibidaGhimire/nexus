R ES E A R C H A RT IC L E
P re p r i n t Ve r s i o n
Reliability Scores from Saliency Map Clusters for
Improved Image-based Harvest-Readiness
Prediction in Cauliﬂower
Jana Kierdorf1| Ribana Roscher1,2
1Remote Sensing Group, Institute of
Geodesy and Geoinformation, University of
Bonn, Germany
2Data Science for Crop Systems, Institute
of Bio- and Geosciences, IBG-2: Plant
Sciences, Forschungszentrum Jülich GmbH
Correspondence
Jana Kierdorf, Remote Sensing Group,
Institute of Geodesy and Geoinformation,
University of Bonn,d Germany
Email: jkierdorf@uni-bonn.de
Funding information
European Agriculture Fund for Rural
Development with contributions from
North-Rhine Westphalia (17-02.12.01 -
10/16 – EP- 0004617925-19-001);
Deutsche Forschungsgemeinschaft (DFG,
German Research Foundation)
(RO4839/7-1 | STO 1087/2-1); DFG under
Germany’s Excellence Strategy – EXC 2070
– 390732324A B S T R A C T
Cauliﬂower is a hand-harvested crop that must fulﬁll high-quality
standards in sales making the timing of harvest important. How-
ever, accurately determining harvest-readiness can be challenging
due to the cauliﬂower head being covered by its canopy. While
deep learning enables automated harvest-readiness estimation, er-
rors can occur due to ﬁeld-variability and limited training data. In
this paper, we analyze the reliability of a harvest-readiness classi-
ﬁer with interpretable machine learning. By identifying clusters of
saliency maps, we derive reliability scores for each classiﬁcation re-
sult using knowledge about the domain and the image properties.
For unseen data, the reliability can be used to (i) inform farmers
to improve their decision-making and (ii) increase the model pre-
diction accuracy. Using RGB images of single cauliﬂower plants
at diﬀerent developmental stages from the GrowliFlower dataset
[1], we investigate various saliency mapping approaches and ﬁnd
that they result in diﬀerent quality of reliability scores. With the
most suitable interpretation tool, we adjust the classiﬁcation re-
sult and achieve a 15.72% improvement of the overall accuracy to
88.14% and a 15.44% improvement of the average class accuracy
to 88.52% for the GrowliFlower dataset.
K E Y W O R D S
Harvest prediction, spectral clustering, reliability, interpretability,
saliency mapping
1arXiv:2305.15149v1  [cs.CV]  24 May 20232 Preprint Version of Reliability Scores from Saliency Map Clusters for Improved Image-based Harvest-Readiness Prediction
in Cauliﬂower
1|INTRODUCTION
Accurate harvest time forecasts are crucial for crop
quantity and proﬁtability in agriculture. For cauliﬂower,
high-quality requirements for sale further complicate
this process. To meet these standards, harvesting
must be precisely timed within a short window. Since
cauliﬂower growth is highly aﬀected by climate, ﬁelds
planted at diﬀerent times may be ready for harvest si-
multaneously, and plants may develop diﬀerently within
a single ﬁeld. Therefore, it is a common agricultural prac-
tice that workers harvest plants individually by hand at
diﬀerent times. As the cauliﬂower head is covered by
its canopy, the workers touch the head inside the plant
and estimate the size, making harvesting highly time-
consuming.
In digital agriculture, ﬁeld monitoring is supported by
satellite or UAV imagery [2] to observe plant develop-
ment throughout the entire growth period. Machine
learning methods increasingly form the basis for ana-
lyzing the acquired data, for example, to classify crop
ripeness on a large scale [3] or to provide detailed predic-
tions about harvest ripeness, the amount of harvest, or
the date of harvest-readiness [4]. Predicting crop traits
related to harvest is of economic beneﬁt to farmers, so
the model must be reliable, and the farmer should be
able to have conﬁdence in the model’s decision.
We address the task of harvest-readiness estimation
of single cauliﬂower plants and aim to derive a relia-
bility score for the model’s output that can be used
to support the farmer in their decision-making process.
To reach our goal, we use saliency mapping to iden-
tify image regions that have distinctive characteristics
important for the model decision [5, 6]. We extend
the clustering approach of saliency maps by [7] and
combine the maps with knowledge about our applica-
tion domain and the image properties to derive relia-
bility scores of the model’s output. Similar to our ap-
proach, some previous works also aim to improve the
model through the integration of interpretations and ex-
planations [8, 9, 10]. However, these works present ad
hoc frameworks where the interaction between model
and explanation is either learned during training or inte-grated through human interactions via retraining. Our
work diﬀers in that we propose a framework for deriv-
ing a reliability score for classiﬁcation predictions that
operates post-hoc during inference time without human
interaction. Thus, the system can be applied to already
trained models without changing the model architecture
and without the need for re-training.
The main contributions of this paper are:
•a versatile post-hoc approach to derive intuitive relia-
bility scores without time-consuming human interac-
tion;
•a use case where the reliability scores are used
to improve harvest-readiness predictions on the
GrowliFlower dataset by 15.73% to an overall accu-
racy of 88.14% and by 15.44% to an average class
accuracy of 88.52%.
2|MATERIALS AND METHODS
2.1 |Framework
We solve the task of estimating the harvest-readiness
of single cauliﬂower plants with deep learning-based im-
age classiﬁcation and combine it with an estimation of
the reliability of the classiﬁcation through clustering of
saliency maps. Fig. 1 shows an overview of the ﬁve-step
framework.
(1)Classiﬁcation: In the ﬁrst step, images are classi-
ﬁed into the classes Ready andNot ready for harvest
within three days. We use a ResNet18 network [11],
however, the framework is ﬂexible regarding the clas-
siﬁer.
(2)Saliency mapping: In the second step, we com-
pute saliency maps for validation and test data post-
hoc using the learned classiﬁer. We consider Gradient-
weighted Class Activation Mapping (Grad-CAM) [12],
Occlusion Sensitivity Mapping (OSM) [13], and Local In-
terpretable Model-Agnostic Explanations (LIME) [14].
(3)Clustering: We employ spectral clustering to iden-
tify groups of saliency maps computed on the validation
data and derive reliability scores. The mean saliency
map per cluster, denoted as prototype, is further ana-Preprint Version of Reliability Scores from Saliency Map Clusters for Improved Image-based Harvest-Readiness Prediction in
Cauliﬂower3
F I G U R E 1 Our framework. The diﬀerent numbers represent (1) the classiﬁcation step, (2) the saliency mapping
step, and (3) the clustering step of saliency maps with the assignment of reliability to the clusters by relating the
conﬁdence scores of the model to the corresponding saliency maps. (4) represents the dissemination to the farmer
how reliable the model is while (5) represents the adjustment step, where the predictions of (1) are improved by
using the reliability score of (3).
lyzed. Test data can be assigned a reliability score by
assigning its saliency map to the nearest cluster.
(4)Dissemination: The reliability score is intuitively us-
able due to its value range between 0 and 1 and is com-
municated to the user together with the classiﬁcation
result.
(5)Adjustment: In our use case, the classiﬁcation
results are adjusted based on the cluster assignments
of the saliency maps to determine the ﬁnal predicted
classes. The decision depends on the summed percent-
age of false positives (FP) and false negatives (FN) per
cluster. The evaluation of the classiﬁcation step pro-
vides the assignments to FP and FN.
The framework does not require human interaction
and can be applied to diﬀerent models. However, hu-
man interaction is possible to further improve the clas-
siﬁcation results and reliability measures by analyzing
and evaluating the human-understandable clusters of
saliency maps.
2.2 |Data
We use the images of the GrowliFlowerR dataset [1]
of Field 2 from the dates 2021_08_23,2021_08_25,
2021_08_30,2021_09_03with given information about
the harvest-readiness within the next three days. Three
days is a compromise between harvest-readiness predic-
tion accuracy and practicability of data acquisition. Wedivide the data into the classes Not ready andReady .
The plants representing both classes show a high sim-
ilarity within the same day of acquisition but also be-
tween diﬀerent days. The size of its head determines
the ripeness, however, in most images, the canopy cov-
ers the head. The plant’s stem is centered within the
image, but depending on the plant’s growth, the center
of the cauliﬂower head can vary up to 20cm from the
stem.
We use the training, validation, and test set as de-
scribed in [1]. If the plant shown in an image is already
harvested, we exclude the image from the dataset. This
results in a preliminary training set of 541 images, a val-
idation set of 196 images, and a test set of 194 images.
We apply standard augmentations like ﬂipping and rota-
tion on the training data. For images of class Not ready ,
we apply augmentations 50% more often than for im-
ages of class Ready to get a more balanced data distri-
bution. After data augmentation, the training set con-
tains 6224 images, 2432 of class Not ready , and 3792
images of class Ready .
For each image, we compute corresponding saliency
maps. The datasets result in pairs of image and map.
Thus, all target information of the images are also valid
for the corresponding saliency maps.4 Preprint Version of Reliability Scores from Saliency Map Clusters for Improved Image-based Harvest-Readiness Prediction
in Cauliﬂower
2.3 |Classiﬁcation
We use a ResNet18 [11] architecture with cross-entropy
loss, softmax activation, and two classes as output. We
compute the model over 25 epochs and use an Adam
optimizer with a weight decay of 0.0001. The learning
rate starts at 0.0001 and is reduced with a learning rate
scheduler with a step size of 5 and factor γof 0.1.
2.4 |Saliency maps
Saliency maps aim to explain a model’s decision by iden-
tifying important regions in the image. In our case,
saliency maps highlight which image regions are impor-
tant for predicting the classes Ready andNot ready , al-
lowing conclusions about the reliability using the prior
knowledge that the center of the image is important
for the decision and the background should not play
a role in the harvest-readiness estimation. We con-
sider three local approaches,that represent the basic
principles of saliency mapping, namely a gradient-based
approach, Grad-CAM, and two permutation-based ap-
proaches, OSM and LIME, where LIME diﬀers in that it
uses surrogate models, as our focus is not on the used
methods.
Grad-CAM is a gradient-based model-speciﬁc
method developed by Selveraju et al. [12] that uses
gradient information to determine from which image
regions the convolutional layer takes the information
for prediction. The resulting map depends on the
employed layer, where we follow the suggestions of
Selveraju et al. [12] to use the last convolutional layer
as it highlights object-level regions in the image, which
are also easier to interpret. Grad-CAM provides infor-
mation about the class of interest but no information
about other classes.
The second approach, OSM, is a perturbation-based
model-agnostic method developed by Zeiler et al. [13].
This method evaluates sensitivity towards occlusion. It
uses a sliding window approach with patchsize pand
stridesto permute the input by masking patches and,
thus, determine the inﬂuence of the occlusion on the
predicted model score. A blue pixel in the map indicatesthat the score after occlusion is lower than the origi-
nal score, i.e., this pixel indicates the presence of the
examined class. A red pixel indicates that the score af-
ter occlusion is higher than the original score, indicating
a diﬀerent class. Note that the smaller s, the ﬁner the
map’s resolution. In our experiments, we chose s= 2
andp= 11.
Like OSM, the third approach, LIME, is a
perturbation-based model-agnostic method devel-
oped by Ribeiro et al. [14]. LIME perturbs the input and
computes the prediction for these perturbed samples
with the original model. Perturbation is applied by
changing components in images that are meaningful to
humans, such as superpixels. After perturbation, a local
surrogate model is learned using the perturbed samples.
In our work, we use a least squares linear regression
model.
2.5 |Spectral Clustering
We follow the idea of Lapuschkin et al. [7] by using Spec-
tral Clustering (SC) introduced by Ng et al. [15] to clus-
ter the resulting saliency maps, which provides a better
understanding of the model decision by taking into ac-
count image features other than RGB. SC involves clus-
tering data based on a similarity measure derived from a
new representation of the data. As similarity, we chose
Gaussian similarity function with a kernel scale of 0.2
based on the Euclidean distance. Before we apply SC
on our saliency maps, we perform principal component
analysis on the vectorized data to reduce the dimen-
sions of the data from 65536 to 50. We decided on a
dimension of 50 to obtain 95% of the variance because
there is no unique eigenvalue diﬀerence, i.e. successive
eigenvalues have no signiﬁcant diﬀerence. We apply SC
to the validation set and assign the closest cluster IDs
to test data using kNN with k= 5. For our approach, we
set the number of clusters q= 8to be representative
and generalizable to other datasets.Preprint Version of Reliability Scores from Saliency Map Clusters for Improved Image-based Harvest-Readiness Prediction in
Cauliﬂower5
2.6 |Evaluation metrics
To evaluate the adjustment step, the summed percent-
age of FP and FN is considered in the calculated clusters
q. We deﬁne this percentage as reliability score rq. The
higher the reliability score the more unreliable is a pre-
diction in a speciﬁc cluster. If rqexceeds a threshold t
in clusterqof the validation set, we swap the predicted
class for all samples in cluster qand update the confu-
sion matrix. We choose t= 75% based on a signiﬁcant
improvement in the validation set’s accuracy. Threshold
tis variable and selectable based on experience. Based
on the updated confusion matrix, we adjust the overall
and average class accuracy. We store the identiﬁed clus-
ters for swapping and apply the same to the test data,
followed by updating the test confusion matrix and ac-
curacies.
3|RESULTS AND DISCUSSION
We run our experiments on an AMD EPYC 7742 64-
Core processor and an NVIDIA A100 for PCIe graphic
card with 40 GB hBM2 RAM.
3.1 |General discussion
Our experiments ﬁnd that clusters and harvest-
readiness classes do not correlate. This is expected in
the case of binary decision-making, where both classes
may end up in the same cluster since they ideally use
the same features. Instead, we focus on whether data
within a cluster are correctly classiﬁed or not, which
allows conclusions to be drawn about the reliability of
the result. We use the confusion matrix for analysis.
To assist the farmer in making harvesting decisions,
we exploit the fact that the saliency maps of plant
images end up in clusters whose classiﬁcation result
is primarily on the main diagonal of the confusion
matrix (TP or TN) and maps that are associated with
incorrect classiﬁcation results (FP or FN) tend to end
up in separate clusters.
F I G U R E 2 Resulting saliency maps for the used
approaches (b) Grad-CAM, (c) OSM, and (d) LIME for a
RGB input image (a) which is visualized in the maps’
background.
3.2 |Classiﬁcation of harvest-readiness
On the validation set, we achieve an overall accuracy of
76.32% and an average class accuracy of 77.21%. For
inference, we achieve an overall accuracy in classiﬁca-
tion of 72.41% and an average class accuracy of 73.08%.
That means we are able to predict the harvest-readiness
of approx. 3 out of 4 plants correctly.
3.3 |Local analysis: Saliency maps of
single sample inputs
In some of the resulting Grad-CAM maps, a hotspot
near the center is highlighted in the image as shown
in Fig. 2 b). In other maps, the highlighted regions are
located near the edges or scattered in the image. It is
easy to analyze which regions have an inﬂuence on the
model’s decisions since compact regions are highlighted.
A considerable amount of the OSM results resemble
noise regardless of stride and patchsize for occlusion.
Only a minor portion of the results show larger con-
nected regions that are important for decision, as shown
in Fig. 2 c). These are located in the area of the image
that shows, among other things, the hidden cauliﬂower
head or highlighted leaf regions. Many maps show sev-
eral smaller highlighted regions which are diﬃcult to ex-
plain because they do not indicate a unique plant trait.
The ability of a simple explanation of the results varies
more than for Grad-CAM.
In LIME maps, we see that the computed superpixels
are not able to summarize pixels to semantically mean-
ingful regions. This could be caused by the structure or
the strong overlap of neighboring plants. Due to this,
LIME saliency maps are diﬃcult to connect to general6 Preprint Version of Reliability Scores from Saliency Map Clusters for Improved Image-based Harvest-Readiness Prediction
in Cauliﬂower
statements about the reliability of classiﬁcation outputs.
An example of a sample analyzed by LIME is shown in
Fig. 2 d). We consider LIME not suitable for our applica-
tion.
Based on the assessment of single saliency maps, we
consider Grad-CAM and OSM to be the most suitable
approaches in our framework.
3.4 |Global analysis: Clustering of
saliency maps and reliability derivation
Fig. 3 show the absolute number of Grad-CAM map
assignments of the clustering results for 8 clusters. A
distinction is made between the validation and test set.
The confusion matrix entries are diﬀerentiated by color.
Our experiments have shown that 8 clusters produce a
good separability between false and correct predictions.
Furthermore, depending on the amount of data, there
are enough data points per cluster to make a reliable
statement. Based on the distribution of validation data
in Fig. 3 a), it becomes evident that cluster 5 contains
about 95% false predictions, which are equally divided
between FP and FN. This means that over 70% of all
FN and FP belong to cluster 5. The cluster with the sec-
ond highest proportion of false predictions is cluster 6.
It is worth mentioning that the percentage is only 30%,
which corresponds to only six images. The other clus-
ters contain less than 20% false predictions. The cluster-
ing analysis allows saying with high conﬁdence that sam-
ples assigned to cluster 5 are equivalent to a false predic-
tion and should be adjusted. The reliability of the clas-
siﬁcation results of the saliency maps assigned to this
cluster is, therefore, low and should be disseminated to
the farmer. This is underlined in particular by the clus-
ter assignments of the test data (Fig. 3 b). We observe
that 80% of the false predicted test data are assigned
to cluster 5. The proportion of false predictions in the
other clusters is comparable to those within the valida-
tion data.
The prototypes of Grad-CAM are shown in Fig. 4.
Half of the prototypes (2,3,7,8) highlight the region
in the center of the image. This is the location in
the RGB input images of cauliﬂower heads covered by
F I G U R E 3 Clustering of Grad-CAM results.
Absolute number of (a) validation (val) images and (b)
test images per cluster.
F I G U R E 4 Grad-CAM prototypes computed by
mean saliency map per cluster (1) – (8).
leaves, which are the indicators of cauliﬂower harvest-
readiness. Even though the cauliﬂower head is not di-
rectly visible in the images, the model identiﬁes the cen-
ter of the plant as an essential feature for the classi-
ﬁer to determine the harvest-readiness. The interpre-
tation of the classiﬁcation results is straightforward and
understandable for these clusters. The previously no-
ticed cluster 5 also varies in this representation to the
other clusters. In the image data assigned to the cluster,
the classiﬁcation model ﬁnds no distinctive features for
determining the harvest-readiness. The visualization of
the prototypes thus supports the model’s reliability in
addition to the cluster assignment since the visual rep-
resentation is easier for the user to understand and in-
terpret.
The clustering of the OSM maps shows a uniform dis-
tribution of false predictions in all clusters (Fig. 5 a). The
percentage ranges from 10% to 30%. Based on the OSM
cluster results, no statement can be made about the re-
liability of the results. The probability that a false pre-
diction occurs in one of the clusters is similar for all clus-
ters. The cluster assignment of the test data shows a
similar distribution (Fig. 5 b). Only cluster 7 stands out.
It should be noted that the assignment to this cluster
corresponds to a single image only.
The prototypes also suggest no clear trend in termsPreprint Version of Reliability Scores from Saliency Map Clusters for Improved Image-based Harvest-Readiness Prediction in
Cauliﬂower7
F I G U R E 5 Clustering of OSM results. Absolute
number of (a) validation (val) images and (b) test images
per cluster.
F I G U R E 6 OSM prototypes computed by mean
saliency map per cluster (1) – (8).
of what the model uses as an informative feature in the
RGB images (Fig. 6). Clusters 1 and 5 show a hotspot
near the center, which, just like Grad-CAM, suggests
that the model is paying partial attention to the canopy
covering the head. Clusters 4, 6, and 8 give a hint of
this. Comparing the prototypes of the OSM approach
with those of the Grad-CAM approach, we see that for
our scenario, the Grad-CAM approach results in more in-
terpretable maps than the ones of OSM. Since no clear
diﬀerentiation between false and correct prediction can
be made in the data for OSM, the adjustment step in-
troduced in this work is only applied to the Grad-CAM
results. Adjusting the classiﬁcation results based on the
clustering results would worsen rather than improve the
model results.
In summary, the combination of saliency map analy-
sis and clustering provides information about the reliabil-
ity of classiﬁcation results. Nevertheless, some thought
should be given to the saliency mapping approach to be
used.
3.5 |Adjustment of model predictions
With regard to applying the adjustment step to Grad-
CAM maps as explained in Sec. 2.6, we achieve a
13.99% improvement in overall accuracy to 90.31% anda 13.39% improvement in average class accuracy to
90.60% for classiﬁcation on the validation set. For in-
ference, we achieve a 15.73% improvement in overall
accuracy to 88.14% and a 15.44% improvement in aver-
age class accuracy to 88.52%.
4|CONCLUSION AND FUTURE DI-
RECTIONS
This work proposes a framework to derive a reliabil-
ity score for cauliﬂower harvest-readiness estimations
that operates post-hoc during inference time without
the need for human interaction. Our work combines
a ResNet18 classiﬁcation model with an unsupervised
Spectral Clustering approach of saliency maps to derive
a reliability score for classiﬁcation predictions. Since the
reliability value is in a ﬁxed range between 0 and 1, it is
intuitive and can be provided to the farmer as a deci-
sion support. In addition, the classiﬁcation predictions
can be adjusted, and the accuracy can be improved. We
compare three saliency mapping approaches: Gradient-
weighted Class Activation Mapping, Occlusion Sensitiv-
ity Mapping, and Local Interpretable Model-Agnostic Ex-
planations. Grad-CAM proves to be the most useful in
our scenario.
For our use case, our approach enables the correct
harvest-readiness estimation on GrowliFlowerR, a sub-
set of the GrowliFlower dataset, of approx. 4 out of 5
cauliﬂowers compared to the state-of-the-art approach
ResNet18 which achieves only approx. 3 out of 4 cor-
rect predictions. Our framework oﬀers the advantage
of not requiring any interaction with the training process
and it can be applied to already trained models without
accessing or modifying the model architecture. We pro-
vide interpretable visualizations and a reliability score
for the model’s decision. Since we only consider false
predictions in our framework, the approach can also be
used for reliability dissemination in multi-class tasks.8 Preprint Version of Reliability Scores from Saliency Map Clusters for Improved Image-based Harvest-Readiness Prediction
in Cauliﬂower
Acknowledgements
This project was funded by the European Agriculture
Fund for Rural Development with contributions from
North-Rhine Westphalia (17-02.12.01 - 10/16 – EP-
0004617925-19-001) and by the Deutsche Forschungs-
gemeinschaft (DFG, German Research Foundation) (RO
4839/7-1 |STO 1087/2-1). In addition, this work was
supported in part by the DFG under Germany’s Excel-
lence Strategy – EXC 2070 – 390732324.
references
[1] Kierdorf J, Junker-Frohn LV, Delaney M, Olave MD,
Burkart A, Jaenicke H, et al. GrowliFlower: An
image time-series dataset for GROWth analysis of
cauLIFLOWER. J Field Robot 2022;. 1, 3
[2] Fountas S, Espejo-García B, Kasimati A, Mylonas
N, Darra N. The Future of Digital Agriculture:
Technologies and Opportunities. IT Professional
2020;22(1):24–28. 2
[3] Lary DJ, Alavi AH, Gandomi AH, Walker AL. Machine
learning in geosciences and remote sensing. Geosci
Front 2016;7(1):3–10. 2
[4] Klompenburg TV, Kassahun A, Catal C. Crop yield pre-
diction using machine learning: A systematic literature
review. Comput Electron Agric 2020;177:105709. 2
[5] Roscher R, Bohn B, Duarte MF, Garcke J. Explain It
to Me–Facing Remote Sensing Challenges in the Bio-
and Geosciences With Explainable Machine Learning.
ISPRS Ann Photogramm Remote Sens Spat Inf Sci
2020;3:817–824. 2
[6] Brahimi M, Arsenovic M, Laraba S, Sladojevic S,
Boukhalfa K, Moussaoui A. Deep learning for plant
diseases: detection and saliency map visualisation. In:
Human and machine learning Springer; 2018.p. 93–
117. 2
[7] Lapuschkin S, Wäldchen S, Binder A, Montavon G,
Samek W, Müller KR. Unmasking clever hans predic-
tors and assessing what machines really learn. Nat
Commun 2019;10(1):1–8. 2, 4
[8] Weber L, Lapuschkin S, Binder A, Samek W. Be-
yond explaining: Opportunities and challenges of XAI-
based model improvement. Information Fusion 2022;.
2[9] Schramowski P, Stammer W, Teso S, Brugger A, Her-
bert F, Shao X, et al. Making deep neural networks
right for the right scientiﬁc reasons by interacting with
their explanations. Nat Mach Intell 2020;2(8):476–
486. 2
[10] Kim T, Kim H, Baik K, Choi Y. Instance-Aware
Plant Disease Detection by Utilizing Saliency Map and
Self-Supervised Pre-Training. Agriculture 2022;12(8).
https://www.mdpi.com/ 2077 -0472 /12/8/1084. 2
[11] He K, Zhang X, Ren S, Sun J. Deep residual learning
for image recognition. In: Proc. IEEE Conf. Comput.
Vis. Pattern Recognit.; 2016. p. 770–778. 2, 4
[12] Selvaraju RR, Cogswell M, Das A, Vedantam R, Parikh
D, Batra D. Grad-cam: Visual explanations from deep
networks via gradient-based localization. In: Proc.
IEEE Int. Conf. Comput. Vis.; 2017. p. 618–626. 2,
4
[13] Zeiler MD, Fergus R. Visualizing and understand-
ing convolutional networks. In: Comput. Vis. ECCV
Springer; 2014. p. 818–833. 2, 4
[14] Ribeiro MT, Singh D, Guestrin C. "Why should i trust
you?" Explaining the predictions of any classiﬁer. In:
Proc. of the 22nd ACM SIGKDD intern. conf. on KDD;
2016. p. 1135–1144. 2, 4
[15] Ng AY, Y MIJ, Weiss. In: Adv. Neural. Inf. Process. Syst.;
2002. p. 849–856. 4